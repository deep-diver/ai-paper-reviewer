{"importance": "This paper is important for researchers because **Dita streamlines robot learning with a simple, scalable architecture**, achieving strong results with minimal data and opening new possibilities for generalist robotic policies in complex environments.", "summary": "Dita: Scales a diffusion transformer for generalist robot policies, enabling 10-shot learning in complex, real-world tasks.", "takeaways": ["Dita, a Diffusion Transformer, achieves strong performance by directly denoising continuous action sequences with in-context conditioning.", "The model exhibits strong zero-shot and few-shot generalization across diverse simulation benchmarks and real-world tasks.", "Dita uses a lightweight (334M parameters), open-source architecture, establishing a versatile baseline for generalist robot policy learning."], "tldr": "Recent robot vision-language-action models show generalization, but action heads limit adaptability to diverse action spaces. **The models' reliance on compact action heads constrains adaptability to heterogeneous action spaces**. Addressing this, Dita introduces a framework for directly denoising continuous action sequences using a multimodal diffusion process. Dita leverages Transformer architectures to enhance scalability, integrating diverse datasets across sensors, tasks & action spaces. \n\nUnlike prior methods with shallow networks, **Dita uses in-context conditioning for fine-grained alignment between denoised actions & raw visual tokens**, modeling action deltas & environmental nuances. Evaluations show state-of-the-art performance in simulation & robust real-world adaptation with only 10-shot finetuning, making Dita a versatile & lightweight baseline for generalist robot policy learning.", "affiliation": "Shanghai AI Lab", "categories": {"main_category": "AI Applications", "sub_category": "Robotics"}, "podcast_path": "2503.19757/podcast.wav"}