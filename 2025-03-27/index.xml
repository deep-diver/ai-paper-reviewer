<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-27s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/</link><description>Recent content in 2025-03-27s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Wed, 26 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/index.xml" rel="self" type="application/rss+xml"/><item><title>ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20756/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20756/</guid><description>ADS-Edit: Empowering autonomous driving with multimodal knowledge editing!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20756/cover.png"/></item><item><title>Beyond Words: Advancing Long-Text Image Generation via Multimodal Autoregressive Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20198/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20198/</guid><description>LongTextAR advances long-text image generation via a novel tokenizer, enabling accurate, controllable, and high-fidelity text rendering in images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20198/cover.png"/></item><item><title>BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20672/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20672/</guid><description>BIZGEN: Article-level Visual Text Rendering for Infographics Generation</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20672/cover.png"/></item><item><title>DINeMo: Learning Neural Mesh Models with no 3D Annotations</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20220/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20220/</guid><description>DINeMo: Learns 3D models with no 3D annotations, leveraging pseudo-correspondence from visual foundation models for enhanced pose estimation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20220/cover.png"/></item><item><title>MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20757/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20757/</guid><description>MCTS-RAG: Combines Monte Carlo Tree Search with Retrieval-Augmented Generation to enhance small LMs&amp;rsquo; reasoning on complex tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20757/cover.png"/></item><item><title>Open Deep Search: Democratizing Search with Open-source Reasoning Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20201/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20201/</guid><description>Open Deep Search (ODS): Democratizing Search with Open-source Reasoning Agents.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20201/cover.png"/></item><item><title>Unconditional Priors Matter! Improving Conditional Generation of Fine-Tuned Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20240/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20240/</guid><description>Fixing fine-tuned diffusion models! By using richer, unconditional priors, they generate better images and videos.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20240/cover.png"/></item><item><title>ViLBench: A Suite for Vision-Language Process Reward Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20271/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.20271/</guid><description>VILBENCH: Vision-Language Process Reward Modeling Suite</description></item><item><title>AccVideo: Accelerating Video Diffusion Model with Synthetic Dataset</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19462/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19462/</guid><description>AccVideo accelerates video diffusion by 8.5x with a synthetic dataset and trajectory-based distillation, maintaining quality and enabling higher resolution video generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19462/cover.png"/></item><item><title>Attention IoU: Examining Biases in CelebA using Attention Maps</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19846/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19846/</guid><description>Attention-IoU reveals model biases by analyzing attention maps, offering insights beyond dataset labels and improving debiasing techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19846/cover.png"/></item><item><title>Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19757/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19757/</guid><description>Dita: Scales a diffusion transformer for generalist robot policies, enabling 10-shot learning in complex, real-world tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19757/cover.png"/></item><item><title>GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19480/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19480/</guid><description>Visually perfect generations aren&amp;rsquo;t always optimal! GenHancer finds that subtly imperfect generations can greatly improve vision-centric tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19480/cover.png"/></item><item><title>LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19990/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19990/</guid><description>MLLMs still struggle with spatial reasoning! LEGO-Puzzles benchmark reveals critical deficiencies, paving the way for AI advancement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19990/cover.png"/></item><item><title>LogQuant: Log-Distributed 2-Bit Quantization of KV Cache with Superior Accuracy Preservation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19950/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19950/</guid><description>LogQuant: 2-bit quantization for KV cache, superior accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19950/cover.png"/></item><item><title>Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/</guid><description>Opt-CWM: Self-supervised motion learning via counterfactual optimization, achieving state-of-the-art without labels!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/cover.png"/></item><item><title>PathoHR: Breast Cancer Survival Prediction on High-Resolution Pathological Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17970/</link><pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17970/</guid><description>PathoHR: Boost breast cancer survival prediction with high-resolution pathology images!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17970/cover.png"/></item><item><title>Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17358/</link><pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17358/</guid><description>Motion blur, usually a problem, is now a solution! This paper estimates camera motion from motion-blurred images, acting like an IMU.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.17358/cover.png"/></item></channel></rss>