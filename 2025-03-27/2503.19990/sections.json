[{"heading_title": "LEGO for MLLM", "details": {"summary": "**LEGO construction serves as an innovative framework** for evaluating spatial reasoning in Multimodal Large Language Models (MLLMs). This approach leverages the inherent structure and sequential assembly process of LEGO models to create a comprehensive benchmark. By analyzing how MLLMs interpret and execute LEGO assembly instructions, researchers can assess their ability to understand spatial relationships, reason through multi-step processes, and generate accurate visual outputs. **LEGO-based tasks offer a balance of complexity and real-world relevance**, providing a more ecologically valid assessment compared to purely synthetic datasets. The step-by-step nature of LEGO instructions enables the creation of tasks that specifically target sequential reasoning, a crucial aspect often overlooked in existing benchmarks. **This methodology also facilitates the creation of diverse and scalable datasets**, as a single LEGO model can generate numerous unique evaluation questions. Overall, employing LEGO construction as a basis for MLLM evaluation represents a promising avenue for advancing the development of more capable and reliable AI systems in spatial understanding."}}, {"heading_title": "Multi-step Limits", "details": {"summary": "While the provided text doesn't explicitly contain a section titled \"Multi-step Limits,\" we can infer potential limitations concerning multi-step spatial reasoning in MLLMs based on the observed weaknesses. The main challenge lies in **compounding errors** through sequential steps, where each inference introduces potential deviations. This is exacerbated by the models' difficulty in maintaining coherent visual memory across multiple steps, unlike language-based memory in LLMs. **Rotation perception and relative spatial relationship understanding** also pose hurdles. The tasks become harder when several steps is involved in reasoning to achieve the final output. There exists a need for improving **spatially grounded visual-memory representations** and enhancing the ability to follow long chain of dependencies. Also **lack of training data** is a significant hurdle. The models also need to be better at following prompts to generate structured outputs."}}, {"heading_title": "Visual Richness", "details": {"summary": "**Visual richness** plays a vital role in spatial reasoning tasks. Datasets with simple geometric shapes(e.g., CLEVR) simplify the challenges MLLMs face in real-world scenarios. **LEGO-Puzzles** improves **visual complexity and diversity**, using real-world images to challenge MLLMs' spatial understanding and sequential reasoning. High visual richness can expose limitations of MLLMs with the ability to discern subtle cues, handle occlusions, and understand the intricacies present in realistic settings. Datasets with rich visual content present complex spatial relationships that demand advanced reasoning capabilities, enhancing evaluation of models."}}, {"heading_title": "Image Generation", "details": {"summary": "The paper evaluates the image generation capabilities of various MLLMs, focusing on tasks like **rotation and multi-view synthesis**, as well as **generating subsequent steps in LEGO assembly**. A key finding is that existing MLLMs struggle to maintain both appearance consistency and instruction adherence. Open-source models exhibit limitations in sequential visual transformations, while proprietary models like Gemini-2.0-Flash demonstrate some success in appearance fidelity but struggle with fine-grained reasoning. Further investigation is needed to improve spatial understanding and reasoning-aware image generation."}}, {"heading_title": "CoT's Diminishing", "details": {"summary": "The research explores the limitations of the Chain-of-Thought (CoT) prompting technique in multi-step sequential reasoning tasks, particularly within LEGO-Puzzles. The findings indicate that while CoT can offer some initial benefits, its effectiveness diminishes as the complexity (number of steps, 'k') increases. Several factors contribute to this 'CoT's Diminishing' effect. **Firstly**, the compounding of errors across multiple reasoning steps leads to inconsistencies in final predictions. **Secondly**, MLLMs might lack a robust visual memory, hindering their ability to coherently track changes. **Thirdly**, some models fail to perform genuine step-by-step reasoning in their CoT responses. These findings underscore the need for alternative prompting strategies to improve multi-step sequential reasoning in MLLMs. Future research should focus on developing methods that mitigate error accumulation, enhance visual memory, and encourage genuine step-by-step reasoning."}}]