<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ðŸ¤— 24-10-21 on AI Paper Reviews by AI</title>
    <link>http://localhost:1313/ai-paper-reviewer/tags/-24-10-21/</link>
    <description>Recent content in ðŸ¤— 24-10-21 on AI Paper Reviews by AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Â© 2024 AI Paper Reviews by AI</copyright>
    <lastBuildDate>Fri, 18 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/ai-paper-reviewer/tags/-24-10-21/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14677/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14677/</guid>
      <description>AI text detectors struggle in real-world scenarios despite high benchmark scores; this study reveals dataset quality issues and proposes evaluation methods for better AI detection.</description>
      
    </item>
    
    <item>
      <title>BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14672/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14672/</guid>
      <description>BiGR: Unifying image generation and discrimination using compact binary codes for superior quality and representation.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14672/cover.png" />
    </item>
    
    <item>
      <title>How Do Training Methods Influence the Utilization of Vision Models?</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14470/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14470/</guid>
      <description>Training methods dramatically impact vision model utilization: some boost early layers, others prioritize deeper ones, revealing crucial insights into neural network functionality.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14470/cover.png" />
    </item>
    
    <item>
      <title>Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14208/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14208/</guid>
      <description>MONTESSORI-INSTRUCT: A novel data synthesis framework tailors synthetic data generation to student learning preferences, significantly improving student model performance.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14208/cover.png" />
    </item>
    
    <item>
      <title>NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14669/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14669/</guid>
      <description>NaturalBench: A new benchmark exposes VLMs&amp;rsquo; weaknesses on natural adversarial samples, revealing significant biases and highlighting the need for improved visio-linguistic skills.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14669/cover.png" />
    </item>
    
    <item>
      <title>Teaching Models to Balance Resisting and Accepting Persuasion</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14596/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14596/</guid>
      <description>LLMs can now better resist manipulation while also learning from helpful advice, thanks to a new training method that balances resisting misinformation with accepting helpful persuasion!</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14596/cover.png" />
    </item>
    
    <item>
      <title>DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13726/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13726/</guid>
      <description>DAWN generates high-quality, dynamic talking head videos at unprecedented speeds using a non-autoregressive diffusion model, overcoming limitations of previous autoregressive methods.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13726/cover.png" />
    </item>
    
    <item>
      <title>Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13674/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13674/</guid>
      <description>Boosting AI model accuracy with synthetic-to-real image generation via image-guided diffusion, addressing challenges of scarce or low-quality data.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13674/cover.png" />
    </item>
    
    <item>
      <title>DPLM-2: A Multimodal Diffusion Protein Language Model</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13782/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13782/</guid>
      <description>DPLM-2: a new multimodal model generating compatible protein sequences and 3D structures, revolutionizing protein design!</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13782/cover.png" />
    </item>
    
    <item>
      <title>FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion Model</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13925/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13925/</guid>
      <description>FiTv2, an upgraded diffusion model, generates images of any resolution and aspect ratio, exceeding prior models in speed and quality.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13925/cover.png" />
    </item>
    
    <item>
      <title>Looking Inward: Language Models Can Learn About Themselves by Introspection</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13787/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13787/</guid>
      <description>LLMs can learn about themselves through introspection; self-prediction surpasses cross-prediction, suggesting internal knowledge beyond training data.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13787/cover.png" />
    </item>
    
    <item>
      <title>MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13370/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13370/</guid>
      <description>MagicTailor: Precisely personalize images by controlling individual visual components in text-to-image models, overcoming semantic pollution and imbalance for superior results.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13370/cover.png" />
    </item>
    
    <item>
      <title>SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13276/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13276/</guid>
      <description>SeerAttention learns attention sparsity, boosting LLMs&amp;rsquo; efficiency and scalability by up to 5.67x with minimal accuracy loss.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13276/cover.png" />
    </item>
    
    <item>
      <title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14059/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14059/</guid>
      <description>UCFE benchmark evaluates LLMs&amp;rsquo; financial expertise via user-centric tasks, revealing performance gaps and highlighting the need for dynamic, human-aligned AI.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.14059/cover.png" />
    </item>
    
    <item>
      <title>Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13232/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13232/</guid>
      <description>Boosting LLM-based web agents: World-Model-Augmented agents simulate action outcomes, improving decision-making and efficiency.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.13232/cover.png" />
    </item>
    
    <item>
      <title>Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.12791/</link>
      <pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.12791/</guid>
      <description>KeyNMF, a novel topic modeling approach using transformer-based embeddings, reveals significant information dynamics in Chinese diaspora media, uncovering trends linked to major political events.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.12791/cover.png" />
    </item>
    
    <item>
      <title>Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.11190/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.11190/</guid>
      <description>Mini-Omni2: Open-source GPT-40-like model with vision, speech, and duplex capabilities, enabling real-time multi-modal interactions.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.11190/cover.png" />
    </item>
    
    <item>
      <title>SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.11331/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.11331/</guid>
      <description>Shakti: A 2.5B parameter language model, optimized for efficiency and low-resource environments, enabling high-performance NLP on edge devices.</description>
      
    </item>
    
    <item>
      <title>HART: Efficient Visual Generation with Hybrid Autoregressive Transformer</title>
      <link>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.10812/</link>
      <pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.10812/</guid>
      <description>HART: A groundbreaking autoregressive model generates high-quality 1024x1024 images at unprecedented speed, surpassing existing diffusion models in efficiency.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/paper-reviews/2410.10812/cover.png" />
    </item>
    
  </channel>
</rss>
