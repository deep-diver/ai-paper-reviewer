{"references": [{"fullname_first_author": "Antonio Alliegro", "paper_title": "Polydiff: Generating 3d polygonal meshes with diffusion models", "publication_date": "2023-12-11", "reason": "This paper is relevant because it's the most relevant approach since it trains a class-conditioned discrete diffusion model, which is the closest to the approach in MeshCraft."}, {"fullname_first_author": "Sijin Chen", "paper_title": "Meshxl: Neural coordinate field for generative 3d foundation models", "publication_date": "2024-05-31", "reason": "This is an important reference because MeshCraft compares its performance against MeshXL."}, {"fullname_first_author": "Yawar Siddiqui", "paper_title": "Meshgpt: Generating triangle meshes with decoder-only transformers", "publication_date": "2024-06-12", "reason": "This paper is important because it's a key baseline that MeshCraft compares against and improves upon, particularly in terms of speed and control over the number of faces."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This is an important reference as it's a foundational paper on denoising diffusion probabilistic models (DDPM), a core technology used in MeshCraft."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This is a key paper for 3D scene representation, as MeshCraft works in the broader context of leveraging recent advances in 3D representations."}]}