[{"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.2.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.1\">\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.1.2\">Gemma 2 9B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.1.3\">GPT-4o</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.1.4\">Gemini 2.0 Flash</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.1\">KOFFVQA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.2\">0.398</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.3\">0.171</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.4\">0.127</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.1\">KOFFVQA-V</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.2\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.3\">0.208</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.4\">0.254</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.1\">KOFFVQA-GT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.2\">0.584</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.3\">0.456</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.4\">0.476</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.2.1.5.1\">KOFFVQA-GT-V</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.2.1.5.2\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.2.1.5.3\">0.452</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.2.1.5.4\">0.426</td>\n</tr>\n</table>", "caption": "Table 1: Selected evaluation results for the top scoring 21 VLMs out of the 47 total models tested on our benchmark. A larger model size does not necessarily correspond to better performance, and models that excel in some subcategories may not do well in others. Due to the page limit, we show the entire model\u2019s result in https://huggingface.co/spaces/maum-ai/KOFFVQA-Leaderboard", "description": "This table presents the performance of the top 21 out of 47 large vision-language models (VLMs) evaluated using the KOFFVQA benchmark.  The models are ranked by their overall scores, which are calculated across multiple subcategories assessing various aspects of VLM performance.  The results show that model size does not directly correlate with better performance, and that models might excel in certain subcategories while underperforming in others.  For a complete list of results for all 47 models, refer to the Hugging Face space link provided.", "section": "4.1. Evaluation of Existing Models"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.2.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.1\">\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.1.2\">Gemma 2 9B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.1.3\">GPT-4o</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.1.4\">Gemini 2.0 Flash</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.1\">KOFFVQA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.2\">89.3%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.3\">95.8%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.4\">93.0%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.2.1.3.1\">KOFFVQA-V</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.2.1.3.2\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.2.1.3.3\">92.9%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.2.1.3.4\">91.8%</td>\n</tr>\n</table>", "caption": "Table 2: Mean standard deviation of scores for 5 repeated evaluations for each question across 275 sampled responses. These are based on individual scores that range from 0 to 10.", "description": "This table presents the mean standard deviation of scores obtained from five repeated evaluations for each of the 275 sampled questions in the KOFFVQA benchmark.  Each score ranges from 0 to 10, representing the objective evaluation of a model's response based on pre-defined grading criteria. The standard deviation indicates the consistency of the LLM judge's scoring across multiple trials for each question.", "section": "4.2 Comparison with Other Evaluation Methods"}]