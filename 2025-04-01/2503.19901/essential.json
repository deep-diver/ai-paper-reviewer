{"importance": "This paper is important for researchers because it presents a novel framework **TokenHSI** for synthesizing human-scene interactions. The method's **versatility, adaptability, and extensibility** improve the way of modeling and learning HSI tasks. It opens new avenues for creating more realistic and interactive virtual environments, impacting fields such as computer animation, robotics, and embodied AI.", "summary": "TokenHSI: Unified Transformer for Physical Human-Scene Interactions through Task Tokenization.", "takeaways": ["TokenHSI is a novel transformer-based controller integrating versatile HSI skills.", "The approach allows flexible and efficient adaptation to novel HSI tasks.", "A dedicated tokenizer is proposed to encode proprioception, facilitating multi-task training and policy adaptation."], "tldr": "Current methods for Human-Scene Interactions (HSI) often use separate controllers for specific tasks, limiting their ability to handle complex tasks requiring multiple skills. Existing unified controllers also struggle with dynamic scenarios and adapting to novel scenes, constraining their adaptability.\n\nThis paper introduces a single, unified, transformer-based policy called **TokenHSI** capable of multi-skill unification and flexible adaptation. It models the humanoid proprioception as a separate shared token combined with distinct task tokens via a masking mechanism. The framework can adapt to new tasks by training additional task tokenizers. Experiments demonstrate significantly improved versatility, adaptability, and extensibility in various HSI tasks.", "affiliation": "Shanghai AI Laboratory", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.19901/podcast.wav"}