{"references": [{"fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (vpt): Learning to act by watching unlabeled online videos", "publication_date": "2022-06-11", "reason": "This paper introduces Video Pretraining (VPT), a method for learning to act by watching unlabeled online videos, and is a crucial baseline for embodied agents in Minecraft."}, {"fullname_first_author": "Shalev Lifshitz", "paper_title": "Steve-1: A generative model for text-to-behavior in minecraft", "publication_date": "2023-06-01", "reason": "This work provides a generative model for text-to-behavior in Minecraft and is a strong baseline, used for comparison and data collection in this paper."}, {"fullname_first_author": "Guanzhi Wang", "paper_title": "Voyager: An open-ended embodied agent with large language models", "publication_date": "2023-05-16", "reason": "This paper introduces Voyager, an open-ended embodied agent with large language models, and it has been widely used as a baseline and is a source of inspiration for this work."}, {"fullname_first_author": "William H Guss", "paper_title": "Minerl: a large-scale dataset of minecraft demonstrations", "publication_date": "2019-01-01", "reason": "This paper introduces the MineRL dataset, a large-scale dataset of Minecraft demonstrations, and it serves as a fundamental resource for training and evaluating embodied agents in Minecraft."}, {"fullname_first_author": "Xinlong Wang", "paper_title": "Emu3: Next-token prediction is all you need", "publication_date": "2024-09-18", "reason": "This paper introduces Emu3, a method in which next-token prediction is all you need, and demonstrates autoregressive model performance."}]}