<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-04-01s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/</link><description>Recent content in 2025-04-01s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 31 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/index.xml" rel="self" type="application/rss+xml"/><item><title>Easi3R: Estimating Disentangled Motion from DUSt3R Without Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24391/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24391/</guid><description>Easi3R: Training-free 4D reconstruction via attention disentanglement, enabling dynamic scene understanding from static 3D models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24391/cover.png"/></item><item><title>Effectively Controlling Reasoning Models through Thinking Intervention</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24370/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24370/</guid><description>Thinking Intervention offers a novel paradigm for controlling reasoning in LLMs, enabling fine-grained guidance and improvements in instruction-following and safety.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24370/cover.png"/></item><item><title>Entropy-Based Adaptive Weighting for Self-Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23913/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23913/</guid><description>EAST: Prioritizing uncertainty in self-training refines reasoning of Large Language Models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23913/cover.png"/></item><item><title>Expanding RL with Verifiable Rewards Across Diverse Domains</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/</guid><description>RL with Verifiable Rewards is now expanding to diverse domains like medicine!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/cover.png"/></item><item><title>KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23730/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23730/</guid><description>KOFFVQA: Objectively evaluates Korean VLMs with a new free-form VQA benchmark, improving evaluation reliability via detailed grading criteria.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23730/cover.png"/></item><item><title>Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/</guid><description>Open-Reasoner-Zero pioneers scalable, accessible RL training for reasoning in LLMs, achieving superior performance with a minimalist approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/cover.png"/></item><item><title>Query and Conquer: Execution-Guided SQL Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24364/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24364/</guid><description>Execution-guided SQL generation enhances accuracy in text-to-SQL tasks by using execution results to select the most semantically consistent query, improving performance and reducing inference costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24364/cover.png"/></item><item><title>RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24388/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24388/</guid><description>RIG: Synergizes reasoning and imagination in an end-to-end generalist policy for embodied agents, improving sample efficiency and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24388/cover.png"/></item><item><title>TeleAntiFraud-28k: A Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24115/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24115/</guid><description>TeleAntiFraud-28k: A new audio-text dataset designed for telecom fraud detection, tackles data scarcity with innovative synthesis techniques and slow-thinking annotations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24115/cover.png"/></item><item><title>MoCha: Towards Movie-Grade Talking Character Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23307/</link><pubDate>Sun, 30 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23307/</guid><description>MoCha: Movie-Grade Talking Character Synthesis!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23307/cover.png"/></item><item><title>TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23461/</link><pubDate>Sun, 30 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23461/</guid><description>TextCrafter: Precisely renders multiple texts in complex scenes, overcoming distortion and omission issues in existing visual text generation models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23461/cover.png"/></item><item><title>Efficient Inference for Large Reasoning Models: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/</link><pubDate>Sat, 29 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/</guid><description>Survey on efficient inference methods for Large Reasoning Models, focusing on mitigating token inefficiency while preserving quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/cover.png"/></item><item><title>MeshCraft: Exploring Efficient and Controllable Mesh Generation with Flow-based DiTs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23022/</link><pubDate>Sat, 29 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23022/</guid><description>MeshCraft: Efficient, controllable mesh generation using flow-based DiTs, outperforming auto-regressive methods in speed and user control.</description></item><item><title>Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.21694/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.21694/</guid><description>Adapting Stable Diffusion for faster Text-to-Mesh Generation, PRD efficiently creates high-quality 3D models without needing extensive 3D training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.21694/cover.png"/></item><item><title>TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.19901/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.19901/</guid><description>TokenHSI: Unified Transformer for Physical Human-Scene Interactions through Task Tokenization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.19901/cover.png"/></item><item><title>Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.18809/</link><pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.18809/</guid><description>LLMs generate Python heuristics for classical planning, outperforming traditional methods and challenging the state-of-the-art planning techniques.</description></item><item><title>Decoupling Angles and Strength in Low-rank Adaptation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.18225/</link><pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.18225/</guid><description>DeLoRA: Decoupling angles and strength in low-rank adaptation for robust &amp;amp; efficient finetuning of large models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.18225/cover.png"/></item><item><title>UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.14941/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.14941/</guid><description>UPME: Peer review for MLLMs, minus human bias!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.14941/cover.png"/></item></channel></rss>