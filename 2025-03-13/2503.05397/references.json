{"references": [{"fullname_first_author": "Keivan Alizadeh", "paper_title": "LLM in a flash: Efficient large language model inference with limited memory", "publication_date": "2023-12-11", "reason": "This reference is important because it addresses efficient LLM inference with limited memory, a critical factor for on-device deployment."}, {"fullname_first_author": "Xinyun Chen", "paper_title": "Premise order matters in reasoning with large language models", "publication_date": "2024-02-08", "reason": "This paper is crucial because it discusses the importance of premise order in LLM reasoning, impacting how the multi-agent system's planner is designed."}, {"fullname_first_author": "Xu Huang", "paper_title": "Understanding the planning of LLM agents: A survey", "publication_date": "2024-02-02", "reason": "The reference is essential as it provides a survey on the planning aspects of LLM agents, providing insight into the design of the Action Manager component."}, {"fullname_first_author": "Xun Jiang", "paper_title": "Long term memory: The foundation of AI self-evolution", "publication_date": "2024-10-15", "reason": "This paper is relevant as it explores long-term memory, crucial for personalizing the healthcare assistant's responses."}, {"fullname_first_author": "Timo Schick", "paper_title": "Toolformer: Language models can teach themselves to use tools", "publication_date": "2023-02-04", "reason": "This reference is important as it describes how language models can learn to use tools, influencing the design of the Action Manager and Caller agents."}]}