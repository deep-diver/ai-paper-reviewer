<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-04s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/</link><description>Recent content in 2025-02-04s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 03 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/index.xml" rel="self" type="application/rss+xml"/><item><title>Almost Surely Safe Alignment of Large Language Models at Inference-Time</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01208/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01208/</guid><description>InferenceGuard ensures almost-sure safe LLM responses at inference time by framing safe generation as a constrained Markov Decision Process in the LLM&amp;rsquo;s latent space, achieving high safety rates witho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01208/cover.png"/></item><item><title>DeepRAG: Thinking to Retrieval Step by Step for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01142/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01142/</guid><description>DeepRAG enhances LLM reasoning by strategically integrating retrieval, modeled as an MDP, improving accuracy by 21.99% and retrieval efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01142/cover.png"/></item><item><title>FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01068/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01068/</guid><description>FastKV: A novel KV cache compression method speeds up long-context LLM processing 2x by selectively propagating tokens and using GQA-aware compression, maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01068/cover.png"/></item><item><title>Improved Training Technique for Latent Consistency Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01441/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01441/</guid><description>Researchers significantly enhance latent consistency models&amp;rsquo; performance by introducing Cauchy loss, mitigating outlier effects, and employing novel training strategies, thus bridging the gap with dif&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01441/cover.png"/></item><item><title>Improving Transformer World Models for Data-Efficient RL</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01591/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01591/</guid><description>AI agents now master complex tasks with improved Transformer World Models, achieving a new state-of-the-art in data-efficient reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01591/cover.png"/></item><item><title>Lifelong Sequential Knowledge Editing without Model Degradation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01636/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01636/</guid><description>ENCORE enables lifelong sequential knowledge editing in LLMs without performance loss, achieving 10,000 edits while maintaining downstream accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01636/cover.png"/></item><item><title>OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01061/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01061/</guid><description>OmniHuman-1: Scaling up one-stage conditioned human animation through novel mixed-condition training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01061/cover.png"/></item><item><title>PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01584/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01584/</guid><description>New benchmark challenges LLMs with general knowledge puzzles, revealing reasoning gaps and suggesting improvements for future models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01584/cover.png"/></item><item><title>Process Reinforcement through Implicit Rewards</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01456/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01456/</guid><description>PRIME (Process Reinforcement through IMplicit rEwards) revolutionizes LLM training by efficiently using implicit process rewards from online policy rollouts and outcome labels, significantly boosting &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01456/cover.png"/></item><item><title>The Differences Between Direct Alignment Algorithms are a Blur</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01237/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01237/</guid><description>Direct alignment algorithms are a blur, but this paper shows how a simple SFT phase and a scaling parameter significantly improve alignment quality, regardless of the specific reward function used.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01237/cover.png"/></item><item><title>The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01081/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01081/</guid><description>GPT models&amp;rsquo; multimodal reasoning abilities are tracked over time on challenging visual puzzles, revealing surprisingly steady improvement and cost trade-offs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01081/cover.png"/></item><item><title>ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01100/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01100/</guid><description>LLMs struggle with complex logical reasoning; ZebraLogic benchmark reveals a &amp;lsquo;curse of complexity&amp;rsquo;, highlighting inherent limitations and guiding future research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.01100/cover.png"/></item><item><title>A Study on the Performance of U-Net Modifications in Retroperitoneal Tumor Segmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.00314/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.00314/</guid><description>ViLU-Net, a novel U-Net modification using Vision-xLSTM, achieves superior retroperitoneal tumor segmentation accuracy and efficiency, exceeding existing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2502.00314/cover.png"/></item><item><title>Current Pathology Foundation Models are unrobust to Medical Center Differences</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18055/</link><pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18055/</guid><description>Current pathology foundation models struggle with center variations; this paper introduces a robustness index to quantify this, revealing model biases and advancing robust model development.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18055/cover.png"/></item><item><title>SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18636/</link><pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18636/</guid><description>SafeRAG: A new benchmark exposes critical security vulnerabilities in Retrieval-Augmented Generation (RAG) systems by introducing four novel attack types and a comprehensive dataset for evaluation, re&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-04/2501.18636/cover.png"/></item></channel></rss>