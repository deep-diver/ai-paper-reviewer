{"importance": "This paper is crucial because it **directly addresses the critical question of generalization in foundation models**, a major hurdle in AI development.  The findings challenge existing assumptions about SFT and RL, **suggesting a paradigm shift** in how we approach model post-training. This opens exciting avenues for improving the robustness and generalizability of AI systems.", "summary": "Reinforcement learning (RL) surpasses supervised fine-tuning (SFT) in fostering generalization in foundation models, while SFT aids RL's stability; a comparative study across text and visual domains reveals this.", "takeaways": ["RL excels at improving model generalization, particularly in complex, multimodal tasks.", "SFT primarily leads to memorization rather than generalization.", "SFT is beneficial for stabilizing RL training, despite RL's superior generalization ability."], "tldr": "The effectiveness of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) in improving the generalization of foundation models remains unclear.  This paper investigates whether these methods enhance generalization or primarily lead to memorization of the training data.  It focuses on text-based and visual environments and uses carefully designed tasks to separate memorization from the acquisition of transferable principles. \nThis research used two tasks: GeneralPoints, an arithmetic reasoning card game; and V-IRL, a real-world navigation environment. They compared the performance of models trained with SFT and RL on these tasks, evaluating both in-distribution and out-of-distribution generalization.  The study finds that RL generally leads to better generalization, especially when outcome-based rewards are used, while SFT often memorizes the training data and struggles to generalize to unseen scenarios.  Furthermore, the research reveals that RL training improves the model's underlying visual recognition capabilities, and that SFT plays a supporting role in stabilizing RL training.", "affiliation": "UC Berkeley", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2501.17161/podcast.wav"}