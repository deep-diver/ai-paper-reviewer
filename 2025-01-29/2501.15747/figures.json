[{"figure_path": "https://arxiv.org/html/2501.15747/x1.png", "caption": "Figure 1: IndicMMLU-Pro Dataset Construction and Evaluation Pipeline. The diagram illustrates the end-to-end process of creating and validating the IndicMMLU-Pro dataset across nine Indic languages. Starting with the English MMLU-Pro dataset, content is translated using IndicTrans2 (1B parameters) and undergoes rigorous quality assurance through back-translation and multiple metric evaluations (chrF++, BLEU, METEOR, TER, and SacreBLEU). Only translations meeting quality thresholds proceed to the final dataset. The workflow also shows the comprehensive evaluation process including expert proofreading involving 13 reviewers who assess semantic accuracy, fluency, and linguistic style. This systematic approach ensures the creation of a high-quality, multilingual benchmark dataset that maintains the integrity of the original MMLU-Pro while adapting to the linguistic nuances of Indic languages.", "description": "This figure details the creation and validation pipeline for the IndicMMLU-Pro dataset.  Starting with the English MMLU-Pro dataset, a machine translation model (IndicTrans2) translates the content into nine Indic languages.  Rigorous quality checks are then performed, including back-translation to English and evaluation using multiple metrics (chrF++, BLEU, METEOR, TER, SacreBLEU).  Only translations passing these quality thresholds are included in the final dataset. Finally, 13 expert reviewers assess the semantic accuracy, fluency, and linguistic style of the translations, ensuring high quality and cultural sensitivity. This process creates a multilingual benchmark that retains the integrity of the original English dataset while accurately reflecting Indic language nuances.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2501.15747/x2.png", "caption": "Figure 2: The original text sample, its Hindi translation, and the corresponding back-translated text", "description": "This figure demonstrates the machine translation and back-translation process used to create the IndicMMLU-Pro dataset.  It shows an example of an English text, its translation into Hindi using the IndicTrans2 model, and the subsequent back-translation of the Hindi text back into English.  Comparing the original English text with the back-translated version helps to assess the quality and accuracy of the translation process, ensuring the integrity of the dataset.", "section": "2.2 Quality Assurance"}, {"figure_path": "https://arxiv.org/html/2501.15747/x3.png", "caption": "Figure 3: The original text sample, its Gujarati translation, and the corresponding back-translated text", "description": "Figure 3 displays a three-column comparison of text. The left column shows the original English text of a sample question from the IndicMMLU-Pro benchmark.  The middle column presents the Gujarati translation of the English text, demonstrating the machine translation process used to create the IndicMMLU-Pro dataset. The rightmost column shows the result of back-translating the Gujarati text back into English. This back-translation serves as a quality assurance check, allowing assessment of how accurately the machine translation preserved the original meaning and intent.", "section": "2.2 Quality Assurance"}, {"figure_path": "https://arxiv.org/html/2501.15747/x4.png", "caption": "Figure 4: The original text sample, its Tamil translation, and the corresponding back-translated text", "description": "Figure 4 displays the original English text of a sample question from the IndicMMLU-Pro benchmark, its translation into Tamil using the IndicTrans2 model, and the result of back-translating the Tamil version back into English. This process demonstrates the quality assurance step used to validate the accuracy of the IndicMMLU-Pro dataset. By comparing the original and back-translated English text, researchers can assess the fidelity of the translation.", "section": "2.2 Quality Assurance"}, {"figure_path": "https://arxiv.org/html/2501.15747/x5.png", "caption": "Figure 5: Model Accuracy Across Different Languages", "description": "This figure is a bar chart showing the accuracy of various language models across nine different Indic languages.  The models are represented on the y-axis, and the languages are on the x-axis.  The height of each bar represents the percentage accuracy of a given model on a particular language.  This allows for a direct comparison of model performance across languages, highlighting strengths and weaknesses of each model in handling the diverse linguistic characteristics of Indic languages.", "section": "3 Results"}, {"figure_path": "https://arxiv.org/html/2501.15747/x6.png", "caption": "Figure 6: Average Question and Option Lengths in # Words and # Tokens", "description": "This figure displays the average lengths of questions and their corresponding options (choices) across nine Indic languages in the IndicMMLU-Pro dataset.  Lengths are presented in both number of words and number of tokens, providing insights into the linguistic characteristics of the dataset and potential implications for model performance.", "section": "3 Results"}, {"figure_path": "https://arxiv.org/html/2501.15747/x7.png", "caption": "Figure 7: Additional examples showcasing the machine translation workflow, including the original text samples, their Hindi translations, and the corresponding back-translated texts.", "description": "This figure displays three sets of text: the original English text, its translation into Hindi using IndicTrans2, and the back-translation of the Hindi text back into English.  This process demonstrates the machine translation workflow and helps assess the accuracy and fluency of the translations. The comparison between the original and back-translated English texts highlights the effectiveness of the translation method in preserving meaning and linguistic integrity.", "section": "Methodology"}, {"figure_path": "https://arxiv.org/html/2501.15747/x8.png", "caption": "Figure 8: Additional examples showcasing the machine translation workflow, including the original text samples, their Gujarati translations, and the corresponding back-translated texts.", "description": "Figure 8 presents several examples illustrating the machine translation process used in the creation of the IndicMMLU-Pro dataset.  For each example, the original English text is shown alongside its Gujarati translation and the result of back-translating the Gujarati text back into English. This demonstrates the entire workflow and allows for a visual assessment of the accuracy and fidelity of the translation process. The comparison reveals how well the meaning and structure of the original English text are preserved in the translation and back-translation steps, highlighting the quality of the translation model used for creating the IndicMMLU-Pro dataset.", "section": "Methodology"}, {"figure_path": "https://arxiv.org/html/2501.15747/x9.png", "caption": "Figure 9: Additional examples showcasing the machine translation workflow, including the original text samples, their Tamil translations, and the corresponding back-translated texts.", "description": "Figure 9 presents several examples illustrating the machine translation process used in creating the IndicMMLU-Pro dataset.  For each example, the figure shows the original English text, its translation into Tamil, and the subsequent back-translation of the Tamil text into English. This allows for a visual comparison of the original and back-translated English text, demonstrating the accuracy and consistency of the translation process.  The examples highlight the system's ability to handle the nuances of the Tamil language while maintaining the semantic meaning of the original text.", "section": "3.3 Dataset Quality Assessment"}]