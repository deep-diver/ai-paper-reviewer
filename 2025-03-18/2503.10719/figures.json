[{"figure_path": "https://arxiv.org/html/2503.10719/x2.png", "caption": "Figure 1: We introduce LVAS-Agent, a multi-agent collaborative framework for end-to-end long video audio synthesis. Built on VLM and LLM-based agents, it simulates real-world dubbing workflows, enabling automatic video script generation, audio design, and high-quality audio synthesis for long videos.", "description": "Figure 1 illustrates the LVAS-Agent framework, a multi-agent system designed for end-to-end long-video audio synthesis.  The framework consists of four key agents: Storyboarder, Scriptwriter, Designer, and Generator.  Each agent plays a distinct role in the process, mimicking a real-world dubbing workflow.  The Storyboarder segments the video into scenes and identifies keyframes. The Scriptwriter generates a script based on visual analysis and dialogue extraction. The Designer refines the audio design with specifications and metadata, and the Generator synthesizes the final audio using a combination of video-to-audio and text-to-audio models. The agents collaborate through several mechanisms, including Discussion-Correction and Generation-Retrieval-Optimization, ensuring high-quality and coherent audio that aligns with the video content.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10719/x3.png", "caption": "Figure 2: Workflow of LVAS-Agent. Given the original video, Storyboarder and Scriptwriter collaborate through Discussion and Correction to create a structured video script. The Designer and Generator complete multi-layered, high-quality sound synthesis through the Generate-Retrieve-Optimize mechanism.", "description": "This figure illustrates the LVAS-Agent's workflow, a multi-agent system designed for long-video audio synthesis.  The process begins with the Storyboarder segmenting the input video into scenes and extracting keyframes, which are then used by the Scriptwriter to generate a video script. The Storyboarder and Scriptwriter collaborate iteratively through a discussion and correction mechanism to refine the script. This refined video script is then used by the Designer to create a detailed sound design, including both foreground and background audio elements. The sound design is further refined via a generation-retrieval-optimization loop between the Designer and Synthesizer agents. Finally, the Synthesizer, utilizing various audio tools, generates a high-quality multi-layered audio track synchronized with the video.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10719/x4.png", "caption": "Figure 3: Our LVAS-Bench is presented in the following parts: (a) illustrates sample data from the benchmark, (b) provides statistical distributions of audio categories and sub-categories across the dataset, and (c) presents the statistics of video categories within the dataset.", "description": "Figure 3 showcases the LVAS-Bench dataset. Part (a) displays example data points from the benchmark, offering a visual representation of the dataset's content diversity. Part (b) presents a statistical analysis of audio categories and their sub-categories, providing insights into the distribution and prevalence of various audio types within the dataset. This visualization allows for a comprehensive understanding of the audio diversity and balance in the benchmark. Part (c) focuses on the video categories, displaying the statistical distribution of videos based on their content or theme. This detailed categorization aids in evaluating the representation of diverse video scenes within LVAS-Bench and ensures its suitability for comprehensive model evaluation across a range of contexts.", "section": "4. LVAS-Bench"}, {"figure_path": "https://arxiv.org/html/2503.10719/x5.png", "caption": "Figure 4: We visualize the spectrograms of generated audio (by prior works and our method). LVAS-Agent demonstrates superior performance in synthesizing long video audio, ensuring seamless scene transitions without errors or missing sounds.", "description": "Figure 4 presents a visual comparison of spectrograms generated using existing methods and the proposed LVAS-Agent.  The spectrograms showcase the audio generated for two different video scenes: a train passing a station, and fireworks exploding. This comparison highlights LVAS-Agent's superior performance in synthesizing long-form video audio by demonstrating smoother transitions between scenes and complete audio output without missing key sounds or errors, unlike existing methods which produce incomplete or inaccurate audio.", "section": "5. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.10719/x6.png", "caption": "Figure 5: User study comparing our method with baselines across different aspects. Higher values indicate greater user preference.", "description": "This figure presents the results of a user study comparing the performance of the proposed LVAS-Agent method against two baseline methods (FoleyCrafter and MMAudio) across three key aspects of audio generation for long videos: audio quality, video-audio consistency, and overall user satisfaction.  Each aspect is rated on a scale of 1 to 5, with higher scores indicating better performance. The bar chart visually represents the average scores obtained for each method across all three aspects, allowing for a direct comparison and illustrating the superior performance of the LVAS-Agent method.", "section": "5.4. User Study"}, {"figure_path": "https://arxiv.org/html/2503.10719/x7.png", "caption": "Figure 1: Storyboarder Prompt", "description": "This figure shows the prompt used for the Storyboarder agent in the LVAS-Agent framework. The Storyboarder agent is responsible for segmenting the video into scenes and creating a storyboard, so this prompt guides the agent on how to do this.  The prompt provides instructions on how to identify scenes, segment the video, analyze the content of each segment, and decide whether to merge or correct the segments. It also specifies the input and output formats, including a JSON format for the final storyboard output. The figure shows example inputs and outputs to further clarify the expectations of the agent.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10719/x8.png", "caption": "Figure 2: Scriptwriter Prompt: full video understanding", "description": "This figure displays the prompt given to the Scriptwriter agent within the LVAS-Agent framework.  The Scriptwriter's role is to analyze a full video and provide a structured summary of its content. The prompt instructs the agent to identify the main scenes and their sequence, focusing on key events and actions. It also requires the agent to generate an approximate timeline of the video, highlighting transitions between key moments. Finally, the agent must summarize the video's content concisely and coherently.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10719/x9.png", "caption": "Figure 3: Scriptwriter Prompt: video segment understanding", "description": "This figure displays the prompt given to the \"Scriptwriter\" agent within the LVAS-Agent framework. The prompt instructs the agent on how to analyze a video segment and provide a concise textual description.  It emphasizes the importance of focusing on the video content alone, avoiding speculative additions or background information. The required output format is specified, which includes descriptions of the background, entities, actions, and a final video caption. This is a crucial step in the multi-agent collaboration process, bridging visual understanding with textual representation for audio synthesis.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10719/x10.png", "caption": "Figure 4: Designer Prompt", "description": "Figure 4 shows the prompt given to the \"Designer\" agent within the LVAS-Agent framework.  The Designer agent is responsible for creating detailed and realistic sound effect annotations for a video clip, based on its textual description. The prompt provides guidelines on identifying sound-producing entities and actions, determining background ambience, prioritizing sounds, ensuring realism, and avoiding redundancy. The input to the agent is a video's textual description, and the output is a JSON containing the identified background and main sounds.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10719/x11.png", "caption": "Figure 5: Synthesizer Prompt", "description": "This figure shows the prompt given to the Synthesizer agent in the LVAS-Agent framework.  The Synthesizer's role is to select appropriate audio labels from a predefined knowledge base, matching the input video and initial audio descriptions. The prompt guides the agent to prioritize semantic similarity when selecting labels, handling cases where an exact match isn't found by focusing on the sound type. The agent is instructed to avoid suggesting labels with human voices unless clearly specified in the video description and to adhere strictly to the available labels within the reference document. The prompt also specifies handling of 'None' labels.", "section": "3. Method"}]