[{"figure_path": "https://arxiv.org/html/2502.15007/extracted/6221089/figures/math.png", "caption": "Figure 1: An example of token-wise non-linearity visualization for Llama3-8B.", "description": "This figure displays a visualization of token-wise non-linearity for the Llama3-8B language model.  It shows how the transformation of token embeddings changes across different layers of the model, illustrating the degree of non-linearity for each token at each layer. This helps to understand how the model processes and transforms contextual information.  The visualization likely uses color or other visual cues to represent the level of nonlinearity, with darker shades representing higher nonlinearity.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.15007/extracted/6221089/figures/demo1.png", "caption": "Figure 2: Interface LLM-Microscope demo system.", "description": "The LLM-Microscope demo system interface allows users to select a language model, input text, and visualize the results of the analysis.  The visualization dashboard displays heatmaps of token-level nonlinearity and layer-wise contribution to prediction, line graphs showing average linearity scores per layer, and a heatmap showing the contextualization level of each token.  A Logit Lens visualization also displays the model's prediction evolution across layers. The interface provides an interactive way for researchers and practitioners to explore how LLMs process and transform information.", "section": "3 LLM-Microscope"}, {"figure_path": "https://arxiv.org/html/2502.15007/extracted/6221089/figures/decoder.png", "caption": "Figure 3: Prefix decoding pipeline as a contextualization assessment.", "description": "This figure illustrates the process used to assess contextual memory in LLMs.  It shows how a model's ability to reconstruct a text prefix is used to quantify how much contextual information is encoded in individual tokens. The pipeline involves encoding a sequence, pooling layer-wise embeddings, and using a trainable copy of the original model to attempt reconstruction.  The cross-entropy loss of the reconstruction process is used to measure the contextualization score. Lower scores indicate more information retained about the context.", "section": "3 LLM-Microscope"}, {"figure_path": "https://arxiv.org/html/2502.15007/x1.png", "caption": "Figure 4: Contextualization score distribution for different parts of speech.", "description": "This figure displays the distribution of contextualization scores for different parts of speech across several large language models.  The contextualization score reflects how well a model can reconstruct the preceding text using only a token's representation. Lower scores indicate the token is more central to preserving the context. The figure shows that determiners (DT) and punctuation consistently have the lowest average reconstruction loss values, suggesting they are highly contextual and important for maintaining coherent context within the models. Conversely, nouns (NN, NNS) generally show higher reconstruction loss values, indicating they are less crucial for preserving the complete context.", "section": "4. Examples and Observations"}, {"figure_path": "https://arxiv.org/html/2502.15007/extracted/6221089/figures/correlation.png", "caption": "Figure 5: The distribution of Cotextuality C\ud835\udc36Citalic_C and non-linearity scores for random fragments of text on English Wikipedia articles.", "description": "Figure 5 is a scatter plot illustrating the relationship between contextualization (C) and non-linearity scores for tokens in English Wikipedia text. Each point represents a token, with its horizontal position indicating the non-linearity score (representing the deviation from a linear transformation between layers) and its vertical position representing the contextualization score (C) (measuring how well the model can reconstruct the preceding text using only the token's representation).  The plot shows the distribution of these scores across many tokens, revealing a correlation between contextual importance and the linearity of a token's representation within the language model.", "section": "4.3 Correlation Between Nonlinearity and Context Memory"}, {"figure_path": "https://arxiv.org/html/2502.15007/extracted/6221089/figures/multilingual.png", "caption": "Figure 6: Logit lens visualisation for Llama3-8B. Input text in German: \u201ceins zwei drei vier f\u00fcnf sechs sieben,\u201d which translates into English: \u201cone two three four five six seven.\u201d", "description": "This figure visualizes the \"Logit Lens\" analysis for the Llama3-8B language model.  The input is a German sentence: \"eins zwei drei vier f\u00fcnf sechs sieben.\"  The heatmap shows the model's predicted probabilities for each word token across different layers of the model's processing.  Each row represents a layer in the model and each column represents a token position. The color intensity reflects the confidence of the model's prediction for that token at that layer.  The analysis reveals that the model initially predicts mainly English tokens, even though the input was German, before converging to the correct German translations in later layers.", "section": "3.4 Visualizing Intermediate Layer Predictions"}]