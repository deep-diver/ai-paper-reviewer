{"importance": "This paper offers insights into the relationship between reasoning and performance in LLMs, potentially influencing future model designs, scaling strategies, and evaluation methodologies. It highlights efficiency and offers a direction for test-time compute optimization. The findings prompt the development of more targeted benchmark evaluations and refined training techniques, helping researchers to better evaluate models.", "summary": "LLMs: 03-mini achieves superior accuracy without longer reasoning chains, suggesting 'thinking harder' matters more than 'thinking longer'.", "takeaways": ["More proficient LLMs can achieve higher accuracy without necessarily requiring longer reasoning chains.", "Accuracy in LLMs tends to decrease as reasoning chains grow longer, even when accounting for question difficulty.", "The decline in accuracy with longer reasoning chains is less pronounced in more capable LLMs, suggesting a more efficient use of test-time compute."], "tldr": "**Large language models** (LLMs) have shown progress in math reasoning, utilizing chain-of-thought and compute scaling. It's unclear if better performance comes from longer reasoning or efficiency, especially across generations. It remains unclear whether improved performance in newer models stems from using longer reasoning chains or from reasoning more efficiently. The paper focuses on the relationship between reasoning token usage and accuracy gains, across the series of OpenAI models. \n\nThe research systematically analyzes chain-of-thought length using the Omni-MATH benchmark, comparing 01-mini and 03-mini variants. **03-mini (m) shows better accuracy** with shorter reasoning chains than 01-mini. Accuracy generally decreases with longer reasoning chains across all models and compute setups, even when question difficulty is controlled. This decline is less in proficient models, indicating more effective compute use. Though 03-mini (h) gains marginal accuracy over 03-mini (m), it uses more tokens on all problems.", "affiliation": "Vrije Universiteit Brussel", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2502.15631/podcast.wav"}