[{"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/survey.png", "caption": "Figure 1: Timeline of the development of mainstream DL-based CD methods.", "description": "This figure shows a timeline summarizing the evolution of deep learning-based change detection (CD) methods in remote sensing.  It highlights key methods and the year they were introduced, illustrating the rapid advancements in the field over time.  The timeline visually represents the progression of algorithms, from early convolutional neural network (CNN)-based approaches to more recent transformer-based and foundational model (FM)-based techniques.", "section": "II. RELATED WORKS"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/dataset-class.png", "caption": "Figure 2: Sample images from the JL1-CD dataset. Each row, from top to bottom, represents: the image at time 1, the image at time 2, and the ground truth label. Each column corresponds to different change types: (a) Decrease in woodland; (b) Building changes; (c) Conversion of cropland to greenhouses; (d) Road changes; (e) Waterbody changes; and (f) Surface hardening (central region).", "description": "Figure 2 presents sample images from the JL1-CD dataset, a new benchmark dataset for remote sensing change detection. Each row shows a pair of images acquired at two different times (Time 1 and Time 2) along with the corresponding ground truth change mask, which highlights the changed areas.  The six columns showcase six distinct change types frequently observed in remote sensing imagery: (a) decrease in woodland, showing deforestation or natural dieback; (b) building changes, depicting construction, demolition, or modification of structures; (c) conversion of cropland to greenhouses, indicating changes in land use; (d) road changes, such as road construction, widening, or other modifications; (e) waterbody changes, which may involve changes in lake size, river flow, or the appearance of new water bodies; and (f) surface hardening, showing areas where natural surfaces like soil or vegetation have been paved or otherwise hardened.", "section": "III. JL1-CD DATASET"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/pipeline.png", "caption": "Figure 3: Overview of the training (green boxes) and testing (pink boxes) pipelines of the proposed Origin-Partition (O-P) strategy and Multi-Teacher Knowledge Distillation (MTKD) framework.", "description": "Figure 3 illustrates the workflows for training and testing change detection models using two proposed methods: Origin-Partition (O-P) and Multi-Teacher Knowledge Distillation (MTKD).  The O-P strategy initially trains a model on the full dataset, then partitions the data based on the Change Area Ratio (CAR) to train specialized models for different CAR levels (small, medium, large).  The MTKD framework builds upon O-P by training a student model that learns from these specialized models (teachers) using knowledge distillation. The student model benefits from the strengths of each teacher but requires only a single inference step, improving efficiency.  The figure visually distinguishes training steps (green boxes) from testing steps (pink boxes) for both strategies.", "section": "IV. Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/dataset.png", "caption": "Figure 4: Sample images with different change area ratios (CAR). Each column represents a specific CAR: (a) 0.00%; (b) 19.98%; (c) 39.93%; (d) 59.96%; (e) 80.25%; and (f) 100.00%.", "description": "Figure 4 displays a series of image pairs illustrating varying change area ratios (CARs) within the JL1-CD dataset.  Each row presents a different scene, showcasing the evolution from a completely unchanged area (0% CAR) to an area with a complete change (100% CAR). Intermediate columns show progressive increases in CAR. This figure visually demonstrates the diverse range of change levels present in the dataset and highlights the challenge of creating a change detection model robust enough to handle such variation.  The images illustrate different types of changes such as land cover shifts, construction, and deforestation.", "section": "IV. Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/CAP.png", "caption": "Figure 5: CAR distribution of the training, validation and test sets in JL1-CD.", "description": "This figure shows the distribution of Change Area Ratio (CAR) values across the training, validation, and test sets of the JL1-CD dataset. The x-axis represents the CAR, ranging from 0.0 to 1.0, and the y-axis represents the frequency of images with that CAR.  The distributions are shown as histograms, with separate plots for each set.  This visualization helps to understand the balance of different change amounts in the dataset, which is important for evaluating the performance of change detection models.  For example, a dataset with a large proportion of images with low CAR values may favor models that perform well on detecting minor changes but not necessarily major changes.", "section": "III. JL1-CD DATASET"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/CAP-SYSUCD.png", "caption": "Figure 6: CAR distribution of the training and test sets in SYSU-CD.", "description": "Figure 6 is a histogram showing the distribution of Change Area Ratio (CAR) values in the training and test sets of the SYSU-CD dataset.  The x-axis represents the CAR, ranging from 0 to 1 (or 0% to 100%), indicating the proportion of changed pixels in an image. The y-axis represents the frequency of images with a given CAR value.  Separate histograms are provided for the training and testing sets, allowing for a comparison of CAR distribution between the two sets used in the training and testing of models for change detection. The figure helps to visualize the range and frequency of different change magnitudes within the SYSU-CD dataset.", "section": "V. Experiment"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/visual.png", "caption": "Figure 7: Visual comparison on the JL1-CD dataset. Each row, from top to bottom, represents the following: image at time 1, image at time 2, ground truth, output from the original model, output from the O-P strategy, and output from the MTKD framework. Red denotes missed detections (FN), while blue indicates false alarms (FP). The selected algorithms are: (a) BAN-ViT-L, (b) BIT, (c) TTP, (d) SNUNet, (e) IFN, (f) Changer-MiT-b1, (g) ChangeFormer-MiT-b1, (h) TinyCD, and (i) CGNet.", "description": "Figure 7 presents a visual comparison of change detection results on the JL1-CD dataset for nine different algorithms.  Each row displays a sample image pair (time 1 and time 2), the corresponding ground truth change mask, and change detection outputs from three different model training approaches: the original model, the model trained with the Origin-Partition (O-P) strategy, and the model trained with the Multi-Teacher Knowledge Distillation (MTKD) framework.  Red highlights missed detections (false negatives), and blue highlights false alarms (false positives). The specific algorithms shown are BAN-ViT-L, BIT, TTP, SNUNet, IFN, Changer-MiT-b1, ChangeFormer-MiT-b1, TinyCD, and CGNet, each in a separate column.", "section": "V. Experiment"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/CAR_per_Partition.png", "caption": "Figure 8: mIoU of HANet, ChangeFormer-MiT-b1, and TTP across different CAR ranges. The first and second rows show results on the validation and test sets, respectively. In each plot, the left y-axis represents CAR size, and the right y-axis represents mIoU.", "description": "Figure 8 displays the performance of three distinct change detection models (HANet, ChangeFormer-MiT-b1, and TTP) across various change area ratios (CARs).  The results are presented for both validation and test datasets, with each row representing a separate dataset. Each model's mIoU (mean Intersection over Union) score is shown as a line graph, plotted against the CAR. The left y-axis displays the CAR range (percentage of changed pixels), while the right y-axis represents the resulting mIoU. This figure effectively demonstrates how the performance of each model varies depending on the extent of the change present in an image.", "section": "V. EXPERIMENT"}, {"figure_path": "https://arxiv.org/html/2502.13407/extracted/6215536/pic/visual_sysucd.png", "caption": "Figure 9: Visual comparison on the SYSU-CD dataset. Red denotes missed detections (FN). Blue indicates false alarms (FP). (a) Image at Time 1. (b) Image at Time 2. (c) Ground Truth. (d) Changer-MiT-b1 (Original). (e) Changer-MiT-b1 (MTKD). (f) CGNet (Original). (g) CGNet (MTKD). (h) TTP (Original). (i) TTP (MTKD).", "description": "Figure 9 presents a visual comparison of change detection results on the SYSU-CD dataset using three different models: Changer-MiT-b1, CGNet, and TTP.  Each row shows a pair of images (Time 1 and Time 2), the ground truth change mask, and the change detection results from each model under two training scenarios: 'Original' (standard training) and 'MTKD' (multi-teacher knowledge distillation). Red highlights missed detections (false negatives), while blue shows false alarms (false positives). The comparison aims to visually demonstrate the impact of the MTKD framework on improving the accuracy and reducing errors in change detection.", "section": "V. Experiment"}]