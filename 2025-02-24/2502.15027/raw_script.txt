[{"Alex": "Hey everyone, and welcome to another mind-blowing episode! Today, we're diving deep into the world of AI... but not just any AI. We're talking about AIs that learn from *you*. Think you can outsmart a computer? Think again! We're tackling a fascinating paper on interactive intelligence, specifically, how Large Multimodal Models \u2013 or LMMs \u2013 get smarter with human feedback. I'm Alex, your AI guide, and I'm thrilled to have Jamie with us today.", "Jamie": "Hey Alex, super excited to be here! This sounds like AI meets user experience. So, LMMs learning from us\u2026 how exactly does *that* work?"}, {"Alex": "Great question, Jamie! In essence, this research introduces a new framework to test and improve how these powerful AI models interact with human feedback. Imagine you\u2019re teaching a robot to identify objects in a picture. If it gets it wrong, you don't just say 'no.' You explain *why* it's wrong. This framework, InterFeedback, captures that nuanced interaction and helps the AI learn more effectively.", "Jamie": "Okay, that makes sense. So it's not just a thumbs up or thumbs down, but actual, useful critiques. Umm, what's the big deal, though? Don't AIs already learn from data?"}, {"Alex": "That's where it gets interesting. Existing benchmarks largely test AI in a static way, like a multiple-choice exam. InterFeedback emphasizes the *interactive* element, mirroring real-world scenarios where AI needs to adapt and improve based on ongoing conversations and instructions. Think of a general AI assistant - it needs to understand what you want, even if you're not perfectly clear and adapt accordingly. This paper is focusing on how the models can correct themselves through human feedback in an interactive manner", "Jamie": "So it\u2019s about making AI more... adaptable? More human-like in its learning process? Hmm, that's a pretty ambitious goal. So how does InterFeedback actually *test* this interactive intelligence?"}, {"Alex": "The core of InterFeedback is a problem-solving framework using a Partially Observable Markov Decision Process \u2013 a POMDP. Basically, it simulates a conversation where the AI tries to solve a task, then receives feedback (either from another AI or a human), and then tries again. The framework assesses whether the AI can understand and utilize the feedback to improve its subsequent attempts.", "Jamie": "Okay, POMDPs... sounds complicated! But I think I get the gist. So, they\u2019re putting the AI through a series of interactive tests. What kinds of tests are we talking about here? What datasets are they using?"}, {"Alex": "They used some really interesting and challenging datasets. They used MMMU-Pro and MathVerse and they designed InterFeedback-Human, a totally new dataset. MMMU-Pro tests expert-level multimodal understanding and MathVerse tests visual mathematics problem-solving. These are challenging even for the most advanced AIs.", "Jamie": "Expert-level, huh? So, not your average image recognition task then. What does InterFeedback-Human consist of?"}, {"Alex": "InterFeedback-Human consists of 120 manually curated cases across diverse domains: visual logic, mathematics, and coding. They specifically selected tasks that require complex, multi-step reasoning to really push the limits of these LMMs.", "Jamie": "Wow, that sounds pretty comprehensive. Okay, so they've got the framework, the datasets... who or *what* is providing the feedback in these tests? Is it all humans, or are they using other AIs too?"}, {"Alex": "That's another key part of the research! They explored both AI-generated and human-provided feedback. They use advanced LMMs, like GPT-4o, to simulate human feedback in some experiments. In others, they have actual humans in the loop, providing nuanced and tailored feedback.", "Jamie": "Okay, interesting. So, AI judging AI! And then real humans stepping in to give their two cents. What were some of the biggest challenges in setting up this experiment?"}, {"Alex": "One of the biggest hurdles was ensuring that the AI-generated feedback was reliable. Even the best LMMs aren't perfect, so they developed a clever method to select instances where the feedback provider (the AI) could solve the problem correctly, while the AI being tested could not. This guaranteed the feedback was relevant and helpful.", "Jamie": "Smart. So, they're basically filtering for high-quality feedback. It sounds complex to execute. What kind of feedback were the humans instructed to give? Just, 'you're wrong,' or something more detailed?"}, {"Alex": "They designed a hierarchical feedback system with three levels. Level 1 is a basic explanation, Level 2 is an expanded explanation, and Level 3 includes the correct answer, along with a comprehensive explanation. This allows them to analyze how different levels of detail impact the AI's learning process.", "Jamie": "Ah, that makes sense. So it's not just about *if* the feedback helps, but *how much* detail is needed to make a difference. I\u2019m curious, what are the models selected? What is the performance of each model?"}, {"Alex": "Exactly! They tested ten open-source LMMs and benchmarked them against some top-tier closed source models like OpenAI-01 and Claude 3.5 Sonnet. I'll give you the big picture: They found most LMMs benefit from the interactive process, but struggle to utilize the feedback to the fullest extend. Current LMMs can correct their result with human feedback less than 50%.", "Jamie": "Less than 50%? That seems surprisingly low given all the hype around AI! What does this low score mean?"}, {"Alex": "It highlights a critical gap in current LMM development. While these models are powerful, they often lack the ability to effectively interpret and integrate feedback in a way that leads to significant improvement. The current accuracy result may not truly reflect the model's capability. The result shows that higher accuracy is not associated with higher feedback. This suggest that evaluating models solely on accuracy may not fully capture their true potential", "Jamie": "So, there is a huge gap between the capabilities and performance."}, {"Alex": "Yes, it's like having a brilliant student who struggles to learn from their mistakes! It highlights a critical area for future research: developing methods that can enhance LMMs' ability to understand, reason with, and act upon feedback.", "Jamie": "That's fascinating. Did they find that certain *types* of feedback were more effective than others?"}, {"Alex": "Absolutely. They found that even simple, binary feedback \u2013 just indicating whether an answer was right or wrong \u2013 could improve performance. This suggests that LMMs have the *potential* to learn, but may need better prompting techniques to fully unlock their capabilities. Interestingly, they also discovered that low-quality or unhelpful feedback could actually *degrade* performance compared to simple binary feedback!", "Jamie": "Wow, so bad feedback is worse than no feedback at all! That's a pretty important takeaway. Umm, what about the human feedback versus the AI feedback? Was one clearly better than the other?"}, {"Alex": "That's where it gets nuanced. While high-quality AI-generated feedback can be effective, human feedback remains crucial, particularly for complex reasoning tasks. Humans can provide tailored explanations and insights that AI often misses, especially in scenarios requiring commonsense knowledge or nuanced understanding.", "Jamie": "Okay, so humans are still safe from being completely replaced by AI *just* yet! Did the paper reveal if multiple interactions were helping with higher accuracy?"}, {"Alex": "That's an insightful question. Based on the experiments, engaging in additional iterations doesn\u2019t necessarily guarantee the derivation of correct solutions. As the interactions increases, some models just result in answer guessing.", "Jamie": "Oh.. Well then what is the next step for this InterFeedback and the team?"}, {"Alex": "That's a great question. One important question is what type of feedback would work better. This research only test the simple feedback and detailed feedback, but what about high-quality and expert human feedback? In the future, how could we train the model and improve the performance?", "Jamie": "Those are some really helpful insights. So if I understand correctly, this research is more than just another AI benchmark... it's highlighting a critical area that needs more focus."}, {"Alex": "Precisely! By focusing on interactive intelligence and the ability to learn from feedback, InterFeedback pushes us to think beyond static evaluation metrics and towards more human-centered AI development.", "Jamie": "So, what is the major discovery or highlights that you can share with the listeners?"}, {"Alex": "There were a few interesting facts. 1. InterFeedback is the first step toward exploring the interactive intelligence of LMMs in improving themselves through human feedback. 2. Interaction doesn't always guarantee the right answers since the models start guessing. 3. Quality is always better than quantity. high-quality feedback is essential, as subpar feedback can degrade performance even more than a simple binary correctness signal", "Jamie": "Great points! If the models show strong performance on coding or visual perception, can they be combined with human feedback in real use cases?"}, {"Alex": "Correct! Those results should be evaluated cautiously. For example, although InternVL2-8B achieves a higher accuracy, its correction rate is actually low! Similarly, Molmo-7B surpasses InternVL2-8B in correction rate despite having lower accuracy", "Jamie": "It's really interesting that those aspects can be improved."}, {"Alex": "Alright Jamie, that\u2019s all the time we have today. Thank you for joining me! To summarize, this research shows even the top AI doesn\u2019t learn as well from feedback as we'd expect. This paper, InterFeedback, offers a crucial framework for measuring and improving interactive intelligence. It shows the need for better methods that allow AI to truly understand and benefit from human guidance. It's not just about building smarter AI, but AI that learns *how* to get smarter. And that\u2019s a game-changer.", "Jamie": "Thanks, Alex. This was fascinating!"}]