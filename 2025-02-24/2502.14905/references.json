{"references": [{"fullname_first_author": "Z. Shao", "paper_title": "Pushing the Limits of Mathematical Reasoning in Open Language Models", "publication_date": "2024-02-03", "reason": "This paper is important as it introduces a method for improving mathematical reasoning in open language models, relevant to the LLM reasoning aspect of the cited paper."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "Deepeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "publication_date": "2025-01-01", "reason": "This is a pivotal paper because it outlines the DeepSeek R1 framework upon which the cited paper builds, particularly regarding reinforcement learning and reasoning capabilities."}, {"fullname_first_author": "Yizhong Wang", "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions", "publication_date": "2022-12-10", "reason": "This paper is significant as it introduces the concept of self-generated instructions for aligning language models, contributing to the methodology of improving LLM behavior."}, {"fullname_first_author": "P. Wang", "paper_title": "Math-Shepherd: A Labelfree Step-by-Step Verifier for LLMs in Mathematical Reasoning", "publication_date": "2023-12-12", "reason": "This paper contributes with a method for step-by-step verification for LLMs, and it is important to the reasoning quality."}, {"fullname_first_author": "Qwen Team", "paper_title": "Qwen. Qwen2.5: A Party of Foundation Models", "publication_date": "2024-01-01", "reason": "This paper introduces the Qwen models, fundamental to the cited paper as these models were used for synthetic data generation."}]}