<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-01-17s on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/</link><description>Recent content in 2025-01-17s on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 16 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/index.xml" rel="self" type="application/rss+xml"/><item><title>AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09503/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09503/</guid><description>AnyStory: A unified framework enables high-fidelity personalized image generation for single and multiple subjects, addressing subject fidelity challenges in existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09503/cover.png"/></item><item><title>CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09433/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09433/</guid><description>CaPa: Carve-n-Paint Synthesis generates hyper-realistic 4K textured meshes in under 30 seconds, setting a new standard for efficient 3D asset creation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09433/cover.png"/></item><item><title>Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09484/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09484/</guid><description>AI-powered medical consultations often struggle with the inquiry phase. This paper presents a novel patient simulator trained on real interactions, revealing that effective inquiry significantly impac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09484/cover.png"/></item><item><title>FAST: Efficient Action Tokenization for Vision-Language-Action Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09747/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09747/</guid><description>FAST: A novel action tokenization method using discrete cosine transform drastically improves autoregressive vision-language-action models&amp;rsquo; training and performance, enabling dexterous and high-freque&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09747/cover.png"/></item><item><title>Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09732/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09732/</guid><description>Boosting diffusion model performance at inference time, this research introduces a novel framework that goes beyond simply increasing denoising steps. By cleverly searching for better noise candidates&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09732/cover.png"/></item><item><title>Learnings from Scaling Visual Tokenizers for Reconstruction and Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09755/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09755/</guid><description>Scaling visual tokenizers dramatically improves image and video generation, achieving state-of-the-art results and outperforming existing methods with fewer computations by focusing on decoder scaling&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09755/cover.png"/></item><item><title>SynthLight: Portrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09756/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09756/</guid><description>SynthLight: A novel diffusion model relights portraits realistically by learning to re-render synthetic faces, generalizing remarkably well to real photographs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09756/cover.png"/></item><item><title>Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09686/</link><pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09686/</guid><description>This survey paper explores the exciting new frontier of Large Reasoning Models (LRMs), focusing on how reinforcement learning and clever prompting techniques are boosting LLMs&amp;rsquo; reasoning capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09686/cover.png"/></item><item><title>RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.08617/</link><pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.08617/</guid><description>RLHS, a novel alignment algorithm, leverages simulated hindsight feedback to mitigate misalignment in RLHF, significantly improving AI&amp;rsquo;s alignment with human values and goals.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.08617/cover.png"/></item><item><title>Do generative video models learn physical principles from watching videos?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09038/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09038/</guid><description>Generative video models struggle to understand physics despite producing visually realistic videos; Physics-IQ benchmark reveals this critical limitation, highlighting the need for improved physical r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-01-17/2501.09038/cover.png"/></item></channel></rss>