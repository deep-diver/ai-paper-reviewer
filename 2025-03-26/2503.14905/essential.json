{"importance": "This paper is crucial for researchers navigating the evolving landscape of AI-generated content. **It offers a robust method for detecting synthetic images and interpretable explanations of artifacts**, enhancing trust and transparency. The dataset provides a valuable resource, paving the way for future advancements.", "summary": "FakeVLM: A multimodal model & artifact-annotated dataset for detecting synthetic images with interpretable explanations, setting a new benchmark.", "takeaways": ["FakeVLM, a novel multimodal model, excels in detecting synthetic images and explaining artifacts.", "FakeClue, a new dataset with over 100,000 images, provides fine-grained artifact clues in natural language.", "FakeVLM achieves state-of-the-art performance in authenticity classification and artifact explanation."], "tldr": "With the rise of AI-generated content, assessing image authenticity is more challenging than ever. Existing methods often lack human interpretability and struggle with the complexity of synthetic data. This limits users' understanding of the reasons behind system's decisions, affecting the process's transparency and trustworthiness.\n\nTo address these challenges, the paper introduces **FakeVLM, a large multimodal model for synthetic image detection with artifact explanation**. Along with FakeVLM, the authors create FakeClue, a comprehensive dataset. The paper demonstrates the model's superior performance, marking a significant advancement in the field.", "affiliation": "Shanghai Artificial Intelligence Laboratory", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.14905/podcast.wav"}