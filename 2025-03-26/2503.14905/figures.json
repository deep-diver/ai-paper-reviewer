[{"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F1.png", "caption": "Figure 1: FakeVLM is a specialized large multimodal model designed for both DeepFake and general synthetic image detection tasks across multiple domains.", "description": "FakeVLM is a large multimodal model designed to identify both DeepFake and general synthetic images across a wide range of image categories, including animals, objects, humans, and scenery. It is designed to not only classify images as real or fake but also explain its classification decision through the generation of a natural language description that pinpoints specific image artifacts indicating synthesis. This figure shows an example of FakeVLM's capabilities.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F2.png", "caption": "Figure 2: Construction pipeline of FakeClue dataset, including data collection from open source and self-synthesized datasets, pre-processing with categorization, label prompt design based on category knowledge, and multiple LMMs annotation with result aggregation.", "description": "The figure illustrates the creation process of the FakeClue dataset.  It begins with data collection from both publicly available open-source datasets and data generated specifically for this project.  The collected data then undergoes preprocessing, including categorization of images into specific types (e.g., animals, objects, scenery). Subsequently, labels and prompts are designed for annotation, leveraging category-specific knowledge to guide the labeling process. Finally, the data is annotated with multiple large multimodal models (LMMs) and these annotations are aggregated to create the final FakeClue dataset. This multifaceted approach ensures a rich and diverse dataset for evaluating synthetic image detection models.", "section": "3. Dataset"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F2.jpg", "caption": "Figure 3: Comparison of synthetic image detection approaches on LOKI and FakeClue datasets: (1) QA with Frozen LMMs (no training), (2) Frozen backbone + linear probe (only linear layer trained), (3) Direct Real/Fake QA tuning, and (4) VQA with artifact explanations tuning.", "description": "This figure compares four different approaches for synthetic image detection using large multimodal models (LMMs) and evaluates their performance on the LOKI and FakeClue datasets.  The four approaches are:\n\n1. **QA with Frozen LMMs (no training):**  A pre-trained LMM is used directly for question answering (QA), without any further training. This serves as a baseline to evaluate the potential of directly using pre-trained LMMs for detection without additional fine-tuning.\n2. **Frozen backbone + linear probe (only linear layer trained):** The vision backbone of the LMM is frozen (weights remain fixed), and only a small linear layer is trained on top of the frozen backbone features. This approach helps to investigate how well the existing features can be used for detection with minimal changes.\n3. **Direct Real/Fake QA tuning:** This method involves fine-tuning the entire LMM directly using real/fake QA pairs for synthetic image detection. This assesses the effect of full LMM training for detection.\n4. **VQA with artifact explanations tuning:** This method fine-tunes the LMM for visual question answering (VQA) that focuses on identifying and explaining artifacts in synthetic images.  This explores the benefit of fine-tuning the LMM for a more nuanced, explanation-focused approach, assessing performance and interpretability.\n\nThe figure likely displays the results (e.g., accuracy, F1 score) of each approach on both datasets, comparing their relative performance and demonstrating the improvements achieved by using more sophisticated fine-tuning strategies.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F3.jpg", "caption": "Figure 4: Overview of FakeVLM, our proposed framework for detecting synthetic images and explaining their artifacts. Built upon LLaVA, FakeVLM integrates multiple captioning models to assess key visual aspects.", "description": "FakeVLM is a multimodal model built upon LLaVA, designed for synthetic image detection and artifact explanation. It uses a vision encoder (CLIP-ViT), a multi-modal projector, and a large language model (Vicuna) to process images and generate explanations for detected artifacts.  Multiple captioning models are integrated to improve the robustness and accuracy of both the detection and explanation tasks. The figure illustrates the architecture of FakeVLM, showcasing the flow of image data through the different components and the generation of a natural language response.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F4.png", "caption": "Figure 5: Comparative case analysis of synthetic image detection, covering animals, people, objects, documents, and remote sensing. FakeVLM outperforms GPT in precision, comprehensiveness, and relevance, indicating its superior detection and interpretation capabilities.", "description": "Figure 5 presents a qualitative comparison of FakeVLM and GPT's performance on synthetic image detection across various domains.  Each example shows an image and its corresponding analysis from both models. FakeVLM demonstrates superior capabilities by providing more precise, comprehensive, and relevant explanations for its judgments compared to GPT.  The diverse image types include animals (a dog), people (a woman), objects (vintage devices), documents (a document with mixed handwritten text), and remote sensing (satellite imagery).  This figure highlights FakeVLM's superior ability to not only accurately identify synthetic images but also to articulate detailed and insightful explanations of the specific image artifacts that led to that conclusion.", "section": "5.3 Universal synthetic detection"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F9.png", "caption": "Figure 6: Typical cases on DD-VQA dataset. Our model accurately identifies and explains the synthetic artifacts, demonstrating its effectiveness in fine-grained DeepFake detection and interpretation.", "description": "Figure 6 showcases example outputs from the FakeVLM model when evaluated on the DD-VQA dataset, which focuses on fine-grained DeepFake detection.  The figure presents several image examples along with the model's corresponding textual explanations. Each example highlights a specific area or artifact within the image and explains why the model classifies it as a synthetic artifact.  This demonstrates FakeVLM's ability to not only identify subtle signs of image manipulation but also to articulate the reasons behind its assessment in natural language, thereby offering both accurate detection and interpretability. The examples cover various types of facial manipulation artifacts.", "section": "5.4. DeepFake detection"}, {"figure_path": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F6.png", "caption": "Figure 7: Performance of FakeVLM on real images.", "description": "This figure shows the results of applying FakeVLM to real images.  It demonstrates FakeVLM's ability to correctly identify real images, avoiding false positives (incorrectly classifying a real image as fake). This is important because a reliable synthetic image detector should not misclassify authentic images as forgeries.  The results highlight the model's robustness and accuracy in a real-world scenario where the majority of images are genuine.", "section": "5. Experiment"}]