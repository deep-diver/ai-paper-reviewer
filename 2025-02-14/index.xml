<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-14s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/</link><description>Recent content in 2025-02-14s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 13 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/index.xml" rel="self" type="application/rss+xml"/><item><title>An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09056/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09056/</guid><description>Low-resource language LLMs gain strong reasoning abilities by merging with a high-resource reasoning model, achieving performance comparable to state-of-the-art models while maintaining target languag&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09056/cover.png"/></item><item><title>Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09619/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09619/</guid><description>ProbeLog: Zero-shot model search directly from weights, boosting efficiency and accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09619/cover.png"/></item><item><title>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09601/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09601/</guid><description>CoT-Valve dynamically adjusts reasoning chain lengths based on task difficulty, significantly reducing inference costs in large language models without substantial accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09601/cover.png"/></item><item><title>DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09614/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09614/</guid><description>DexTrack achieves highly generalizable neural tracking control for dexterous robot manipulation by iteratively training a controller using high-quality demonstrations refined via homotopy optimization&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09614/cover.png"/></item><item><title>Exploring the Potential of Encoder-free Architectures in 3D LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09620/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09620/</guid><description>Encoder-free 3D LMMs outperform state-of-the-art, achieving comparable results to significantly larger models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09620/cover.png"/></item><item><title>SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09604/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09604/</guid><description>SelfCite: A self-supervised approach boosts LLM citation accuracy via context ablation. By removing or isolating cited text, SelfCite trains LLMs to generate high-quality citations without manual ann&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09604/cover.png"/></item><item><title>SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09390/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09390/</guid><description>SQUARE, a novel prompting technique, enhances LLM reasoning by prompting self-interrogation through sequential question answering, significantly outperforming traditional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09390/cover.png"/></item><item><title>The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.08946/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.08946/</guid><description>LLMs often fail to demonstrate true understanding of concepts, acting as &amp;lsquo;stochastic parrots&amp;rsquo; – a phenomenon quantitatively proven by the PHYSICO benchmark.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.08946/cover.png"/></item><item><title>Typhoon T1: An Open Thai Reasoning Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09042/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09042/</guid><description>Typhoon T1: Open Thai reasoning model improves complex task performance by generating long chains of thought, detailed methodology, and open-source resources are provided.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.09042/cover.png"/></item><item><title>TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.06608/</link><pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.06608/</guid><description>TripoSG: High-fidelity 3D shapes synthesized via large-scale rectified flow models, pushing image-to-3D generation to new heights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.06608/cover.png"/></item><item><title>3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.05761/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.05761/</guid><description>3CAD: A new large-scale, real-world dataset with diverse 3C product anomalies boosts unsupervised anomaly detection, enabling superior algorithm development via a novel Coarse-to-Fine framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-14/2502.05761/cover.png"/></item></channel></rss>