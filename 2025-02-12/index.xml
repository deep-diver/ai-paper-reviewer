<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-12s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/</link><description>Recent content in 2025-02-12s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Tue, 11 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/index.xml" rel="self" type="application/rss+xml"/><item><title>Auditing Prompt Caching in Language Model APIs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07776/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07776/</guid><description>Researchers expose widespread prompt caching in LLMs via novel timing attacks, highlighting significant privacy risks and model architecture leakage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07776/cover.png"/></item><item><title>CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07316/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07316/</guid><description>CODEI/O: Condensing reasoning patterns from code into LLM training data for enhanced reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07316/cover.png"/></item><item><title>Enhance-A-Video: Better Generated Video for Free</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07508/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07508/</guid><description>Enhance-A-Video boosts video generation quality without retraining, by enhancing cross-frame correlations in diffusion transformers, resulting in improved coherence and visual fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07508/cover.png"/></item><item><title>LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07374/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07374/</guid><description>LLMs can be effectively taught complex reasoning via efficient fine-tuning on demonstration data focusing on &lt;em>structure&lt;/em>, not content, of the reasoning process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07374/cover.png"/></item><item><title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07701/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07701/</guid><description>Magic141 generates one-minute video clips in under a minute by cleverly factorizing the generation task and employing optimization techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07701/cover.png"/></item><item><title>VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07531/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07531/</guid><description>VidCRAFT3 enables high-quality image-to-video generation with precise control over camera movement, object motion, and lighting, pushing the boundaries of visual content creation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.07531/cover.png"/></item><item><title>Expect the Unexpected: FailSafe Long Context QA for Finance</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06329/</link><pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06329/</guid><description>FailSafeQA benchmark rigorously evaluates LLMs&amp;rsquo; resilience against diverse human-interaction variations, revealing critical weaknesses in even high-performing models, particularly regarding hallucinat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06329/cover.png"/></item><item><title>Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06589/</link><pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06589/</guid><description>Hephaestus-Forge, a new large-scale pre-training corpus, significantly boosts LLM agent capabilities in API function calling, reasoning, and adaptability through continual pre-training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.06589/cover.png"/></item><item><title>FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/</link><pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/</guid><description>FocalCodec: a single codebook, low-bitrate speech codec using focal modulation, achieves competitive performance in speech resynthesis and voice conversion.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/cover.png"/></item><item><title>Teaching Language Models to Critique via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.03492/</link><pubDate>Wed, 05 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.03492/</guid><description>LLMs learn to critique and refine their output via reinforcement learning, significantly improving code generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.03492/cover.png"/></item></channel></rss>