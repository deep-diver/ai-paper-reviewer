{"references": [{"fullname_first_author": "Jaech et al.", "paper_title": "OpenAI o1 System Card", "publication_date": "2024-12-16", "reason": "This paper introduces the o1 model, which is a central focus of the current paper's research on Long Chain-of-Thought reasoning."}, {"fullname_first_author": "Li et al.", "paper_title": "From crowdsourced data to high-quality benchmarks: Arena-Hard and BenchBuilder pipeline", "publication_date": "2024-06-11", "reason": "This paper introduces Arena-Hard, a benchmark dataset used extensively to evaluate the models in this paper."}, {"fullname_first_author": "Zheng et al.", "paper_title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena", "publication_date": "2023-06-05", "reason": "MT-Bench, another benchmark dataset used in this paper for model evaluation, is introduced in this reference."}, {"fullname_first_author": "Wang et al.", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-11", "reason": "This paper is foundational to the current paper's work, as it introduces the concept of chain-of-thought prompting, a core technique used in LongCoT models."}, {"fullname_first_author": "Jiang et al.", "paper_title": "Mistral 7B", "publication_date": "2023-10-06", "reason": "The Mistral-7B model, used in the experiments of this paper, is described in this reference."}]}