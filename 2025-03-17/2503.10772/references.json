{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model used for text encoding in FlowTok."}, {"fullname_first_author": "Yaron Lipman", "paper_title": "Flow matching for generative modeling", "publication_date": "2023-04-27", "reason": "This paper introduces flow matching, the core generative framework used in FlowTok for transforming between data distributions."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-04-25", "reason": "This paper introduces latent diffusion models, a key technique used in text-to-image generation and against which FlowTok is compared."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-06", "reason": "This paper presents the Transformer architecture, a fundamental building block used throughout FlowTok."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-05-28", "reason": "This paper introduces Vision Transformer (ViT), the core image encoding architecture used in TA-TiTok, the base of FlowTok's image tokenizer."}]}