{"importance": "This paper introduces **a streamlined architecture, FlowTok, centered on compact 1D tokens**, enhancing memory efficiency and faster sampling speeds for cross-modality generation. It serves as a strong foundation for future research in generalized cross-modality generation.", "summary": "FlowTok: Seamlessly flows across text and image tokens!", "takeaways": ["FlowTok uses a unified, compact 1D latent space for both text and images, enabling direct flow matching.", "The framework achieves state-of-the-art text-to-image generation performance with significantly fewer training resources.", "FlowTok extends to image-to-text generation with strong performance under the same minimalist framework."], "tldr": "Cross-modality generation is key, but current methods treat text as conditional and require complex mechanisms. Can we unify understanding and generation by enabling direct transitions in a shared space? This work revisits flow matching, learning a direct path enabling faster multimodal generation. Unlike diffusions, it requires source and target sharing the same shape.\n\nThis paper introduces **FlowTok**, flowing tokens for text and images. It encodes images into compact 1D tokens, reducing latent space by 3.3x at 256 resolution, removing complex conditioning. It extends to image-to-text under the same formulation. It is memory-efficient, needs fewer resources, faster sampling, and comparable SOTA performance. The code will be released!", "affiliation": "ByteDance Seed", "categories": {"main_category": "Multimodal Learning", "sub_category": "Multimodal Generation"}, "podcast_path": "2503.10772/podcast.wav"}