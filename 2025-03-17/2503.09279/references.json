{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-01", "reason": "This report is important because it details GPT-4, a large language model that serves as a foundational component for the current state-of-the-art models used for video captioning, including those used in generating the data and for comparison in the paper."}, {"fullname_first_author": "Wenhao Chai", "paper_title": "AuroraCap: Efficient, performant video detailed captioning and a new benchmark", "publication_date": "2024-10-01", "reason": "This is one of the baselines that the study compares against, and also introduces the VDCSCORE metric used to assess the results."}, {"fullname_first_author": "Lin Chen", "paper_title": "ShareGPT4Video: Improving video understanding and generation with better captions", "publication_date": "2024-06-01", "reason": "It's a related work on improving video understanding and generation using better captions with the assistance of GPT-4, thus improving the quality of video captioning."}, {"fullname_first_author": "Zhe Chen", "paper_title": "Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling", "publication_date": "2024-12-01", "reason": "It's a baselined multimodal model that competes on performance to provide context and a reference point to this study's improvements."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "publication_date": "2021-06-01", "reason": "This paper introduces LoRA, a parameter-efficient fine-tuning technique that is employed in the study."}]}