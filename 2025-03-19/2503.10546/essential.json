{"importance": "This paper is important for researchers because it **bridges the gap between VLMs and dynamics modeling**, enabling more complex robot manipulation. This opens new research avenues in areas like deformable object manipulation, dynamic task planning, and integration of VLMs with robotic control systems. KUDA could inspire more robust and versatile robotic systems.", "summary": "KUDA unifies dynamics learning and visual prompting with keypoints for open-vocabulary robot manipulation.", "takeaways": ["Keypoints can effectively bridge VLMs and dynamics learning for robot manipulation.", "A two-level closed-loop planning framework enhances robustness.", "The proposed system achieves state-of-the-art performance on diverse manipulation tasks."], "tldr": "Existing open-vocabulary robotic systems often overlook object dynamics, limiting their application to complex tasks. On the other hand, dynamics models require pre-defined targets, which are difficult to infer from language instructions. The key question is how to develop open-vocabulary manipulation systems that harness the flexibility of VLMs and the benefits of model-based planning.\n\nTo address this, the paper introduces KUDA, a novel system that uses keypoints to unify VLMs and dynamics models. KUDA takes language instructions and visual observations as input, assigns keypoints, and uses a VLM to generate target specifications. These specifications are converted into cost functions for model-based planning with learned dynamics models. KUDA demonstrates state-of-the-art performance on various tasks, including manipulating deformable objects.", "affiliation": "Tsinghua University", "categories": {"main_category": "AI Applications", "sub_category": "Robotics"}, "podcast_path": "2503.10546/podcast.wav"}