{"references": [{"fullname_first_author": "DeepSeek-AI", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-12", "reason": "This paper is important as it presents DeepSeek-R1, a key model used for comparison in the current study, and describes a method for incentivizing reasoning in LLMs."}, {"fullname_first_author": "Hurst", "paper_title": "Gpt-4o system card", "publication_date": "2024-10-21", "reason": "This paper is important as it describes the GPT-4o model, a proprietary LLM used as a baseline in the study's evaluation."}, {"fullname_first_author": "Yang", "paper_title": "Qwen2.5 technical report", "publication_date": "2024-12-15", "reason": "This paper is important because it details the Qwen-2.5 models, which are central to the benchmark and fine-tuning experiments conducted in the study."}, {"fullname_first_author": "Bai", "paper_title": "Longwriter: Unleashing 10,000+ word generation from long context llms", "publication_date": "2024-08-07", "reason": "This paper is important as it introduces LongWriter, a model specifically designed for long-form content generation, which is compared against in the current study."}, {"fullname_first_author": "Xu", "paper_title": "Wizardlm: Empowering large pre-trained language models to follow complex instructions", "publication_date": "2024-05-07", "reason": "This paper is important as it presents a methodology for improving instruction-following capabilities in large language models, a relevant area for the current study's evaluation framework."}]}