[{"figure_path": "https://arxiv.org/html/2410.22476/extracted/5940764/intro-mult-intent-fig2.png", "caption": "Figure 1: Examples of multi-label multi intent datasets (SNIPS, Facebook and BANKING)", "description": "This figure showcases examples of multi-label, multi-class intent datasets.  It illustrates how a single user query can express multiple distinct intents. The examples highlight scenarios found in three different datasets: SNIPS, Facebook, and BANKING. Each example sentence is annotated with its corresponding intents (fine and coarse-grained) and the spans of text representing those intents.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2410.22476/extracted/5940764/pnm-multiple-intentsV2-v1.drawio.png", "caption": "Figure 2: Pointer Network Based multi-label, multi-class intent detection (MLMCID) architecture", "description": "This figure illustrates the architecture of the MLMCID model, a pointer network-based approach for multi-label, multi-class intent detection.  The encoder processes input words using embeddings (BERT, RoBERTa, DistilBERT, or Electra) to generate contextualized word representations. A Bi-LSTM layer further refines these representations.  The decoder employs two pointer networks and an LSTM-based sequence generator to extract multiple intent spans from the sentence. These span locations are then passed, along with Bi-LSTM output, through feed-forward networks (FFNs) for coarse and fine intent detection. The outputs of these networks provide sextuplets: (span1, coarse label1, fine label1, span2, coarse label2, fine label2).", "section": "4 Solution Approach"}, {"figure_path": "https://arxiv.org/html/2410.22476/extracted/5940764/pmlite_coarse_combined_loss.png", "caption": "(a) Combined loss - Coarse", "description": "The figure shows the combined loss for coarse-grained intent labels across different datasets during the training process of the RoBERTa-based pointer network model. The x-axis represents the number of epochs (iterations of training), while the y-axis shows the loss value. The plot illustrates how the combined loss changes over epochs for several datasets, providing insights into the model's training progress and convergence behavior for coarse intent detection.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2410.22476/extracted/5940764/pmlite_fine_combined_loss.png", "caption": "(b) Combined Loss - Fine", "description": "The plot shows the variation of the fine-grained loss for the RoBERTa-based pointer network model in MLMCID across different datasets.  The y-axis represents the loss value, and the x-axis indicates the number of training epochs. The plot displays how the loss changes over the course of training for several datasets, illustrating the model's learning progress in terms of minimizing the fine-grained loss function for intent detection.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2410.22476/extracted/5940764/pic-2.png", "caption": "Figure 3: By RoBERTa based pointer network \n(PNM) model in MLMCID", "description": "This figure shows the training loss curves for a RoBERTa-based pointer network model used in the MLMCID framework.  Separate curves are displayed for the combined coarse and fine intent loss functions across different datasets: SNIPS, FB_en, HWU64, BANKING, and CLINC. The x-axis represents the number of training epochs, while the y-axis shows the loss value. The plot illustrates how the loss decreases during training, indicating the model's learning progress.", "section": "Experiments"}]