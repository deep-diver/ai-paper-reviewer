[{"content": "| Methods | FID(\u2193) | KID(\u2193) | Time(\u2193) |\n|---|---|---|---|\n| TEXTure (Richardson et al., 2023) | 48.31 | 48.00 | 80s |\n| Text2Tex (Chen et al., 2023b) | 49.85 | 47.38 | 344s |\n| Paint3D (Zeng, 2023) | 43.55 | 25.73 | 95s |\n| Ours | **34.53** | **11.94** | **10s** |", "caption": "Table 1. Quantitative Comparisons. FID and KID (\u00d710\u22124absentsuperscript104\\times 10^{-4}\u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT) are evaluated on multi-view renderings. Our method achieves state-of-the-art texture quality with significantly faster inference.", "description": "This table presents a quantitative comparison of different methods for 3D texture generation, evaluating their performance using the Frechet Inception Distance (FID) and Kernel Inception Distance (KID) metrics.  Lower FID and KID scores indicate better texture quality, signifying a higher similarity between generated and real textures. The metrics are calculated based on multi-view renderings of the textured 3D models, providing a more comprehensive assessment of the texture quality. The table also includes the inference time for each method, highlighting the computational efficiency of each approach.  The results show that the proposed method achieves state-of-the-art texture quality while significantly reducing inference time compared to existing methods.", "section": "5.1 Main Results and Comparisons"}, {"content": "| Methods | Paint3D | TEXTure | Text2Tex | Ours |\n|---|---|---|---|---|\n| Preference(%) \u2191 | 16.5 | 7.1 | 7.1 | **69.3** |\n| MLLM Score \u2191 | 64.8 | 69.8 | 64.8 | **74.2** |", "caption": "Table 2. Quantitative evaluation on text-condition generation. Preference refers to the comprehensive user study evaluating the alignment with the text description and the quality of the texture. For MLLM Score, Claude 3.5-sonnet\u00a0(Anthropic, 2024), a state-of-the-art MLLM, is used to calculate the text-to-texture similarity scores. To be consistent with the conclusions in\u00a0(Huang\net\u00a0al., 2023a), we use the same Chain-of-Thought prompts described in the study.", "description": "This table presents a quantitative comparison of different methods for text-conditional texture generation.  It uses two metrics: 1) Preference, which is a human-evaluated score reflecting how well the generated texture aligns with the given text description, and how high quality the texture is considered.  This score is obtained from a comprehensive user study. 2) MLLM Score, which is an objective score that uses Claude 3.5-sonnet (a state-of-the-art multi-modal large language model) to assess the similarity between the generated texture and its text description.  This metric uses the same Chain-of-Thought prompting technique from Huang et al. (2023a) to maintain consistency in evaluation methodology.", "section": "5. Experiments"}, {"content": "| Models/Metrics | FID(\u2193) | KID(\u2193) |\n|---|---|---|\n| Hybrid block (A) | **69.74** | **17.89** |\n| w/o point block (B) | 72.58 | 25.52 |\n| w/o UV block (C) | 94.22 | 159.94 |", "caption": "Table 3. Quantitative ablation results on the hybrid design. Starting from the full model, we build a UV block-only model (B) and a point block-only model (C) by replacing redundant blocks with additional ones, while maintaining the same number of model parameters. FID and KID (\u00d710\u22124absentsuperscript104\\times 10^{-4}\u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT) are evaluated on multi-view renderings.", "description": "This table presents the ablation study results on the hybrid design of the TEXGen model.  The goal is to determine the contribution of both the 2D UV block and the 3D point block to the model's performance. Three model variants were created: the full model with both UV and point blocks (A), a model with only UV blocks (B), and a model with only point blocks (C).  All three models have the same number of parameters. The performance of each model is evaluated using the Fr\u00e9chet Inception Distance (FID) and Kernel Inception Distance (KID), which are calculated based on multi-view renderings of the generated textures. Lower FID and KID scores indicate better performance. This helps quantify the impact of the individual components on the model's ability to generate high-quality and realistic textures.", "section": "5.3 Model Analysis"}, {"content": "| Metrics/\u03c9 | 1 | 1.5 | 2 | 3 | 4 | 5 | 7.5 |\n|---|---|---|---|---|---|---|---|---|\n| FID(\u2193) | 35.01 | 34.73 | **34.53** | 35.19 | 35.69 | 36.69 | 39.58 |\n| KID(\u2193) | 15.06 | 13.00 | 11.94 | **11.71** | 13.03 | 14.53 | 24.45 |", "caption": "Table 4. Ablation results of guidance weights. We use different CFG weights to evaluate TEXGen, and the results show that the weight around 2-3 is optimal.FID and KID (\u00d710\u22124absentsuperscript104\\times 10^{-4}\u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT) are evaluated on multi-view renderings.", "description": "This table presents the results of an ablation study on the classifier-free guidance (CFG) weight used in the TEXGen model.  The study varied the CFG weight and measured the Fr\u00e9chet Inception Distance (FID) and Kernel Inception Distance (KID) scores on multi-view renderings of the generated textures. Lower FID and KID scores indicate better performance. The results demonstrate that a CFG weight of around 2-3 achieves the optimal balance between the model's generation quality and its ability to adhere to input conditions.  The FID and KID scores are expressed as values multiplied by 10<sup>-4</sup>.", "section": "5.3 Model Analysis"}]