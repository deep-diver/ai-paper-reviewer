[{"content": "|   | Methods | Tank and Temples | Tank and Temples | Tank and Temples | MipNeRF360 | MipNeRF360 | MipNeRF360 | LLFF | LLFF | LLFF | DL3DV | DL3DV | DL3DV |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Single-View | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 |\n| ZeroNVS [38] | 12.31 | 0.301 | 0.567 | 15.84 | 0.327 | 0.536 | 15.62 | 0.497 | 0.354 | 12.39 | 0.251 | 0.559 |\n| ViewCrafter [61] | 15.18 | 0.499 | 0.319 | 15.65 | 0.404 | 0.378 | 17.56 | 0.620 | 0.337 | 14.78 | 0.422 | 0.417 |\n| **Ours** | **17.11** | **0.613** | **0.199** | **18.91** | **0.527** | **0.333** | **20.38** | **0.744** | **0.200** | **18.28** | **0.642** | **0.215** |\n| Sparse-View | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 |\n| DNGaussian [22] | 12.13 | 0.292 | 0.511 | 15.21 | 0.127 | 0.632 | 17.51 | 0.586 | 0.409 | 14.99 | 0.286 | 0.432 |\n| InstantSplat [10] | 18.70 | 0.634 | 0.258 | 16.80 | 0.574 | 0.296 | 22.33 | 0.818 | 0.149 | 18.30 | 0.691 | 0.222 |\n| ViewCrafter [61] | 18.76 | 0.637 | 0.216 | 18.49 | 0.691 | 0.212 | 21.60 | 0.823 | 0.155 | 19.19 | 0.686 | 0.196 |\n| **Ours** | **20.42** | **0.668** | **0.185** | **20.21** | **0.713** | **0.184** | **25.11** | **0.913** | **0.067** | **21.69** | **0.780** | **0.124** |", "caption": "Table 1: Quantitative comparison of single-view and sparse-view scenarios. Our approach outperforms other baselines in all metrics both in terms of single-view and sparse-view settings.", "description": "This table presents a quantitative comparison of different methods for 3D scene generation from single and sparse views.  The methods are evaluated using three metrics: Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS).  Higher PSNR and SSIM values indicate better image quality, while a lower LPIPS value signifies higher perceptual similarity to the ground truth. The results show that the proposed method consistently outperforms other state-of-the-art techniques in both single-view and sparse-view scenarios across all three metrics.", "section": "4.3 3D Scene Generation"}, {"content": "| Consistency \u2191 | Dynamic \u2191 | Aesthetic \u2191 |\n|---|---|---|\n| CogVideoX [58] | 93.56 | 11.76 | 57.81 |\n| Dream Machine 1.6 | 93.69 | 38.24 | 68.96 |\n| **Ours** | **97.69** | **47.06** | **70.82** |", "caption": "Table 2: Qualitative comparison for controllable video generation. Our DimensionX outperforms baseline models in all metrics, including the Consistency, Dynamic, and Aesthetic scores.", "description": "This table presents a qualitative comparison of controllable video generation methods.  Three metrics are used to evaluate the generated videos: Consistency (how well the generated video maintains visual coherence over time), Dynamic (how well the generated video captures and represents motion), and Aesthetic (overall visual quality and realism). The results show that the proposed DimensionX method significantly outperforms two baseline models (CogVideoX and Dream Machine 1.6) across all three evaluation metrics.", "section": "4.2 Controllable Video Generation"}]