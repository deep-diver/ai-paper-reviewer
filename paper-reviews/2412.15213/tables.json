[{"content": "| Method | #Params (B) | #Steps (K) | FID \u2193 | CLIP \u2191 |\n|---|---|---|---|---|\n| Standard FM (Baseline) | 1.04 | 300 | 10.79 | 0.29 |\n| CrossFlow (Ours) | 0.95 | 300 | 10.13 | 0.29 |", "caption": "Table 1: Comparison between our CrossFlow and standard flow matching with cross-attention. Both models are trained with the same settings. We find that our model slightly outperforms standard flow matching baseline in terms of zero-shot FID-30K and achieves comparable performance on the CLIP score.", "description": "This table compares the performance of the proposed CrossFlow model against a standard flow matching model that uses cross-attention. Both models were trained using identical settings (hyperparameters, datasets, training duration). The results show that CrossFlow achieves slightly better performance than the baseline model in terms of zero-shot FID (Fr\u00e9chet Inception Distance) score at 30,000 samples, indicating superior image generation quality.  However, both models exhibit comparable performance when evaluated using the CLIP (Contrastive Language\u2013Image Pre-training) score.", "section": "5.1 Text-to-Image Generation"}, {"content": "| Method | #Params. |  | FID-30K \u2193 | GenEval \u2191 |\n|---|---|---|---|---|\n| DALL\u00b7E [68] | 12.0B |  | 27.50 | - |\n| GLIDE [59] | 5.0B |  | 12.24 | - |\n| LDM [73] | 1.4B |  | 12.63 | - |\n| DALL\u00b7E 2 [69] | 6.5B |  | 10.39 | 0.52 |\n| LDMv1.5 [73] | 0.9B |  | 9.62 | 0.43 |\n| Imagen [74] | 3.0B |  | 7.27 | - |\n| RAPHAEL [88] | 3.0B |  | 6.61 | - |\n| PixArt-\u03b1 [10] | 0.6B |  | 7.32 | 0.48 |\n| LDMv3 (512\u00b2) [22] | 8.0B |  | - | 0.68 |\n| CrossFlow | 0.95B |  | 9.63 | 0.55 |", "caption": "Table 2: Comparison with recent T2I models.\nFor GenEval, we report the overall score here and provide task-specific scores in Sec.\u00a0B.1.\nCrossFlow achieves comparable performance with state-of-the-art T2I models by directly evolving text into images.", "description": "Table 2 compares the performance of the proposed CrossFlow model against other state-of-the-art text-to-image (T2I) generation models.  The comparison is based on two metrics: FID-30K (Frechet Inception Distance, a measure of image quality) and GenEval (a more holistic metric assessing various aspects of text-image alignment).  The table highlights that CrossFlow, despite its simpler architecture, achieves comparable performance to significantly larger and more complex models.  More detailed GenEval results broken down by specific subtasks are available in Section B.1 of the paper.", "section": "5.1.2 State-of-the-art Comparison"}, {"content": "| Text encoder | FID \u2193 | CLIP \u2191 |\n|---|---|---|\n| Encoder | 66.65 | 0.20 |\n| Encoder + noise | 59.91 | 0.21 |\n| Variational Encoder | 40.78 | 0.23 |", "caption": "Table 3: Ablation study on Text Variational Encoder, training objective, CFG, language models, and training strategy.\nWe conduct ablation study on our smallest model (70M), reporting zero-shot FID-10K and CLIP scores.\nFinal settings used for CrossFlow are underlined. AG: Autoguidance. *: results without applying CFG.", "description": "This ablation study analyzes the impact of different design choices in CrossFlow on text-to-image generation performance.  Using the smallest model (70 million parameters), the study evaluates various components:  the type of text encoder (Variational Encoder vs. standard encoder), the training objective function (reconstruction loss vs. contrastive loss),  the application of Classifier-Free Guidance (CFG), different large language models (LLMs), and the training strategy (joint vs. separate training of encoder and flow matching model).  Zero-shot FID-10K and CLIP scores are reported to quantify performance.  The final configurations used in the CrossFlow model are highlighted.", "section": "5.2 Ablation Study"}, {"content": "| Loss | FID \u2193 | CLIP \u2191 |\n|---|---|---|\n| T-T Recon. | 40.78 | 0.23 |\n| T-T Contrast. | 34.67 | 0.24 |\n| I-T Contrast. | 33.41 | 0.24 |", "caption": "Table 4: Image captioning on COCO Karpathy split.\nCrossFlow directly evolves from image to text, achieving comparable performance to state-of-the-art models on image captioning.\nFor a fair comparison, we only consider non-autoregressive methods that are trained without CIDEr optimization.", "description": "Table 4 presents a comparison of different image captioning models on the COCO Karpathy dataset split.  The table highlights the performance of CrossFlow, a novel approach that directly maps image data to text, against several state-of-the-art methods.  To ensure a fair comparison, only non-autoregressive models trained without CIDEr optimization are included in the comparison. The results demonstrate that CrossFlow achieves comparable performance to existing top-tier models, highlighting its effectiveness in image captioning tasks.", "section": "5.3 CrossFlow for Various Tasks"}, {"content": "| Method | FID \u2193 | CLIP \u2191 |\n|---|---|---|\n| No guidance | 33.41 | 0.24 |\n| AG | 26.36 | 0.25 |\n| CFG indicator | 24.33 | 0.26 |", "caption": "Table 5: Monocular depth estimation on KITTI and NYUv2.\nCrossFlow enables direct mapping from image to depth, achieving comparable performance to state-of-the-art models.", "description": "Table 5 presents a comparison of CrossFlow's performance on monocular depth estimation against other state-of-the-art methods.  The results are shown for two benchmark datasets: KITTI and NYUv2.  Metrics used for evaluation include Absolute Relative Error (AbsRel) and the \u03b4i metric (percentage of pixels with depth error greater than i times the ground truth). Lower AbsRel and higher \u03b4i values indicate better performance. The table demonstrates that CrossFlow, despite its relatively simple architecture, achieves comparable accuracy to more complex models, showcasing its effectiveness in directly mapping images to depth.", "section": "5.3 CrossFlow for Various Tasks"}, {"content": "| Model |  | FID \u2193 | CLIP \u2191 |\n|---|---|---|---| \n| CLIP (0.4B) |  | 24.33 | 0.26 |\n| T5-XXL (11B) |  | 22.28 | 0.27 |\n| Llama3 (7B) |  | 21.20 | 0.27 |", "caption": "Table 6: Image super-resolution on the ImageNet validation set.\nCompared with standard SR method with flow matching, our direct mapping method achieves better performance.", "description": "Table 6 presents a comparison of image super-resolution results on the ImageNet validation set.  It contrasts the performance of a standard super-resolution (SR) method using flow matching with the authors' novel 'direct mapping' approach. The results demonstrate that the direct mapping method proposed in the paper outperforms the standard flow-matching-based SR technique.", "section": "5.3 CrossFlow for Various Tasks"}, {"content": "| Train strategy | FID \u2193 | CLIP \u2191 |\n|---|---|---|\n| 2-stage separate training | 32.55 | 0.24 |\n| Joint training | 24.33 | 0.26 |\n| 2-stage w/ joint finetuning | 23.79 | 0.26 |", "caption": "Table 7: GenEval comparisons.\nOur model achieves comparable performance to state-of-the-art models such as LDM-XL and DALL\u00b7E 2, suggesting that CrossFlow is a simple and promising direction for state-of-the-art media generation.", "description": "Table 7 presents a comparison of the CrossFlow model's performance on the GenEval benchmark against several state-of-the-art text-to-image generation models, including LDM-XL and DALL-E 2.  The results demonstrate that CrossFlow achieves comparable performance, showcasing its effectiveness and efficiency as a simpler and promising approach for high-quality media generation.", "section": "5.1 Text-to-Image Generation"}, {"content": "| Method | B@4 \u2191 | M \u2191 | R \u2191 | C \u2191 | S \u2191 |\n|---|---|---|---|---|---| \n| MNIC [24] | 30.9 | 27.5 | 55.6 | 108.1 | 21.0 |\n| MIR [43] | 32.5 | 27.2 | - | 109.5 | 20.6 |\n| NAIC-CMAL [28] | 35.3 | 27.3 | 56.9 | 115.5 | 20.8 |\n| SATIC [96] | 32.9 | 27.0 | - | 111.0 | 20.5 |\n| SCD-Net [58] | 37.3 | 28.1 | 58.0 | 118.0 | 21.6 |\n| CrossFlow (Ours) | 36.4 | 27.8 | 57.1 | 116.2 | 20.4 |", "caption": "Table 8: Zero-shot depth estimation.\nBaseline results are reported by Marigold\u00a0[39].\nWe follow Marigold and train our CrossFlow on the same datasets, i.e., Hypersim\u00a0[72] and Virtual KITTI\u00a0[9].\nWe highlight the best, second best, and third best entries.\nWith just a unified framework, CrossFlow achieves comparable or even superior performance on complex zero-shot depth estimation, demonstrating the general-purpose nature of CrossFlow on various cross-modal tasks.", "description": "This table presents a comparison of zero-shot depth estimation performance across different methods.  The results are evaluated on five datasets (KITTI, NYUv2, ETH3D, ScanNet, DIODE), and the metrics used are Absolute Relative Error (AbsRel) and the \u03b41 (81) metric.  The authors' CrossFlow model is compared to several baselines, including results reported by Marigold [39], showing comparable or better performance with CrossFlow's unified framework approach. The best, second-best, and third-best results for each dataset are highlighted.", "section": "5.3 CrossFlow for Various Tasks"}, {"content": "| Method | KITTI |  | NYUv2 |  | \n|---|---|---|---|---| \n| TransDepth [89] | 0.064 | 0.956 | 0.106 | 0.900 | \n| AdaBins [6] | 0.058 | 0.964 | 0.103 | 0.903 | \n| DepthFormer [45] | 0.052 | 0.975 | 0.096 | 0.921 | \n| BinsFormer [46] | 0.052 | 0.974 | 0.094 | 0.925 | \n| DiffusionDepth [18] | 0.050 | 0.977 | 0.085 | 0.939 | \n| CrossFlow (Ours) | 0.053 | 0.973 | 0.094 | 0.928 | ", "caption": "Table 9: Ablation on text compression.\nBoth text encoder and Text Variational Encoder preserve most of the input information, despite the large compression ratio (77\u00d7768\u21921\u00d71024\u2192777681102477\\times 768\\rightarrow 1\\times 102477 \u00d7 768 \u2192 1 \u00d7 1024, 14.4\u00d714.4\\times14.4 \u00d7).", "description": "This table presents an ablation study comparing a standard text encoder against a variational text encoder in a text compression task. The goal was to determine if either method could effectively reduce the dimensionality of text embeddings from 77x768 to 1x1024 while preserving information.  The results show that both approaches maintain high reconstruction accuracy despite the significant compression ratio of 14.4 times.", "section": "5.2 Ablation Study"}]