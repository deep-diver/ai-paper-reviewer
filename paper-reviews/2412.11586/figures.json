[{"figure_path": "https://arxiv.org/html/2412.11586/x2.png", "caption": "Figure 1: We propose StrandHead, a text-driven framework for generating strand-disentangled 3D head avatars that feature high-fidelity facial details and strand-based hair.\nBy accurately capturing the internal geometry of hair strands, our approach seamlessly supports flexible hairstyle transfer and editing, as well as physics-based rendering and simulation.", "description": "Figure 1 showcases StrandHead, a framework that uses text prompts to create 3D head avatars. These avatars have highly detailed faces and realistic strand-based hair. The key feature of StrandHead is its ability to accurately represent the internal geometry of individual hair strands. This makes it possible to easily change hairstyles, edit hair details, and even simulate realistic hair movement.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.11586/x3.png", "caption": "Figure 2: Strandhead consists of two stages: (a) Under the constraints of the human-specific diffusion model and the FLAME-volving prior loss, StrandHead generates a detailed and reasonable bald head. (b) By introducing a differentiable prismatization algorithm, orientation consistency loss and curvature regularization loss inspired by hair geometric priors, StrandHead achieves diverse and realistic strand-accurate hair creation without any requiring hair training data.", "description": "StrandHead's pipeline consists of two main stages:\n(a) Bald Head Generation: This stage generates a detailed and realistic bald head model. It uses a human-specific diffusion model with a FLAME-evolving prior loss to ensure the head's fidelity and prevent unnatural geometries.  Normal and depth adapted diffusion models are utilized, combined with a prior loss related to FLAME parameters. A texture field is also used to model head appearance.\n(b) Strand-Based Hair Generation: Leveraging the generated bald head, this stage creates realistic strand-based hair using a novel differentiable prismatization algorithm.  This algorithm converts hair strands to watertight prismatic meshes, allowing the use of mesh-based renderers and losses.  Orientation consistency and curvature regularization losses, inspired by hair geometric priors, ensure realistic and diverse hair generation without requiring 3D hair training data. A strand-aware texture field models high-frequency color variations and accounts for strand orientation.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.11586/x4.png", "caption": "Figure 3: Illustration of the process of converting a hair strand into an octagonal prism mesh using the differentiable prismatization algorithm.", "description": "This figure illustrates the process of converting a single hair strand into a watertight octagonal prism mesh using the proposed differentiable prismatization algorithm.  The algorithm takes a strand of hair as input and outputs a 3D mesh that can be used for rendering and other hair modeling tasks. It does this by generating a set of normals around the hair strand and then translating the strand along these normals to create the lateral edges of the prism. This method is efficient and flexible, allowing for meshes with different numbers of sides and thickness, and its differentiable nature allows for use in deep learning tasks.", "section": "3.4. Strand-Based Hair Generation"}, {"figure_path": "https://arxiv.org/html/2412.11586/x5.png", "caption": "Figure 4: The distribution of Oorisubscript\ud835\udc42oriO_{\\text{ori}}italic_O start_POSTSUBSCRIPT ori end_POSTSUBSCRIPT and Cmeansubscript\ud835\udc36meanC_{\\text{mean}}italic_C start_POSTSUBSCRIPT mean end_POSTSUBSCRIPT in the USC-HairSalon dataset\u00a0[15].  The results indicate that (1) neighboring strand orientations are highly consistent; (2) strand curvature is strongly and positively related to the haircut curliness.", "description": "This figure visualizes the distribution of cosine similarity of adjacent hair strand orientations (CS_ori) and the average curvature (C_mean) across 343 hairstyles in the USC-HairSalon dataset.  Two key observations are highlighted: (1) High Consistency of Neighboring Strand Orientations: The distribution of CS_ori reveals that over 95% of hairstyles exhibit a cosine similarity greater than 0.9, indicating a strong tendency for neighboring strands to align in similar directions.  (2) Strong Correlation between Curvature and Curliness: The distribution of C_mean demonstrates a clear positive correlation with the perceived curliness of the hairstyle.  Hairstyles with higher average curvatures tend to appear curlier.  This analysis supports the introduction of orientation consistency and curvature regularization losses in the proposed StrandHead model to ensure the generation of realistic and plausible 3D hairstyles from textual descriptions.  Examples of hairstyles with varying CS_ori and C_mean values are also included to further illustrate these observations. ", "section": "Method"}, {"figure_path": "https://arxiv.org/html/2412.11586/x6.png", "caption": "Figure 5: Examples of high-fidelity and diverse 3D heads and strand-accurate haircuts generated by our method.\nThe upper visualization includes rendered color and normal maps of the head and hair prism meshes.\nThe lower visualization shows the physics-based rendering result using Blender\u00a0[10].\nPlease zoom in for detailed views, and refer to the Supp. Mat. for video demonstrations.", "description": "Figure 5 showcases the results of StrandHead, demonstrating its capability to generate high-fidelity and diverse 3D heads with strand-accurate haircuts from text prompts. The upper section of the figure displays the rendered color and normal maps of the generated heads, including the generated prismatic hair meshes.  The lower section presents the same heads rendered with physics-based simulation in Blender, showcasing the practical application of the generated hair in realistic scenarios.  Additional details and video demonstrations are available in the supplementary materials.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11586/x7.png", "caption": "Figure 6: Qualitative comparisons with the SOTA methods. Since TECA\u00a0[89] uses the vanilla NeRF to represent hair, rendering normals is not supported. HAAR\u00a0[67] generates only the geometry of hair strands, so we first convert the strands into prismatic meshes using differentiable prismatization and then utilize TEXTure\u00a0[56] to generate texture for visualization and comparison.", "description": "Qualitative comparisons of StrandHead's results with the state-of-the-art (SOTA) methods for head avatar and haircut generation are presented. TECA's rendering lacks normals due to its use of vanilla NeRF for hair representation.  HAAR only generates hair strand geometry; for comparison, these strands were converted into prismatic meshes and textured using differentiable prismatization and TEXTure.", "section": "4.2. Comparisons of Head Generation"}, {"figure_path": "https://arxiv.org/html/2412.11586/x8.png", "caption": "Figure 7: Qualitative comparison with HAAR\u00a0[67]. For better visual comparison, we interpolate the hairstyles to approximately 10,000 strands and apply a consistent appearance. Since HAAR does not model heads, its generated results frequently display hair-head collisions, highlighted within the black box.", "description": "Qualitative comparison of StrandHead with HAAR for hair generation with two prompts: \"A short wavy brown bob\", and \"Shoulder-length straight red hair\". The generated hair from HAAR sometimes collides with the head as HAAR does not explicitly model heads, which is highlighted with a black box.  StrandHead generates more realistic hair without collision.", "section": "4.3. Comparisons of Hair Generation"}, {"figure_path": "https://arxiv.org/html/2412.11586/x9.png", "caption": "Figure 8: Ablation study on (a) strand-level optimization, (b) orientation consistency loss, (c) curvature regularization loss, (d) differentiable prismatization, and (e) strand-aware texture field.", "description": "This figure presents an ablation study showcasing the impact of various components of StrandHead on 3D hair generation. (a) demonstrates the effectiveness of strand-level optimization under the dual constraints of SDS loss and prior-driven losses, resulting in improved text alignment and integration with the head model. (b) and (c) illustrate the impact of orientation consistency loss and curvature regularization loss, respectively, in ensuring realistic hair orientation and curl. (d) compares the proposed differentiable prismatization algorithm against the quad mesh approach of NeuralHaircut, highlighting its superior gradient backpropagation and robustness against abnormal normals. Finally, (e) showcases the improved realism and high-frequency detail modeling achieved by the strand-aware texture field by switching coordinate spaces and incorporating strand orientations.", "section": "4.4. Ablation Study"}]