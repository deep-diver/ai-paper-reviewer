<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations &#183; HF Daily Paper Reviews by AI"><meta name=description content="Physics-Informed Gaussians (PIGs) revolutionize PDE solving by using adaptive, learnable Gaussian functions for superior accuracy and efficiency."><meta name=keywords content="Machine Learning,Deep Learning,üè¢ Department of Artificial Intelligence,Sungkyunkwan University,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations"><meta property="og:description" content="Physics-Informed Gaussians (PIGs) revolutionize PDE solving by using adaptive, learnable Gaussian functions for superior accuracy and efficiency."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-12-08T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-08T00:00:00+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="üè¢ Department of Artificial Intelligence, Sungkyunkwan University"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/cover.png"><meta name=twitter:title content="PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations"><meta name=twitter:description content="Physics-Informed Gaussians (PIGs) revolutionize PDE solving by using adaptive, learnable Gaussian functions for superior accuracy and efficiency."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations","headline":"PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations","abstract":"Physics-Informed Gaussians (PIGs) revolutionize PDE solving by using adaptive, learnable Gaussian functions for superior accuracy and efficiency.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2412.05994\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2024","dateCreated":"2024-12-08T00:00:00\u002b00:00","datePublished":"2024-12-08T00:00:00\u002b00:00","dateModified":"2024-12-08T00:00:00\u002b00:00","keywords":["Machine Learning","Deep Learning","üè¢ Department of Artificial Intelligence, Sungkyunkwan University"],"mainEntityOfPage":"true","wordCount":"5378"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-02-17/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-17</p></a><a href=/ai-paper-reviewer/2025-02-18/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-18</p></a><a href=/ai-paper-reviewer/2025-02-19/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-19</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-17/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-17</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-18/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-18</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-19/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-19</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2412.05994/cover_hu167661649410966757.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2412.05994/>PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-12-08T00:00:00+00:00>8 December 2024</time><span class="px-2 text-primary-500">&#183;</span><span>5378 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">26 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2412.05994/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2412.05994/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/machine-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Machine Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/deep-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Deep Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-department-of-artificial-intelligence-sungkyunkwan-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Department of Artificial Intelligence, Sungkyunkwan University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#physics-informed-gaussian>Physics-Informed Gaussian</a></li><li><a href=#adaptive-meshing>Adaptive Meshing</a></li><li><a href=#uat-for-pigs>UAT for PIGs</a></li><li><a href=#empirical-validation>Empirical Validation</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#physics-informed-gaussian>Physics-Informed Gaussian</a></li><li><a href=#adaptive-meshing>Adaptive Meshing</a></li><li><a href=#uat-for-pigs>UAT for PIGs</a></li><li><a href=#empirical-validation>Empirical Validation</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2412.05994</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Namgyu Kang et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-12-13</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2412.05994 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2412.05994 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/pig-physics-informed-gaussians-as-adaptive target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2412.05994/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Many machine learning methods for solving partial differential equations (PDEs) struggle with accuracy, especially when dealing with high-frequency or non-linear components of the solution. These methods often rely on fixed grid representations or neural networks with inherent limitations. The challenge lies in efficiently allocating computational resources to capture complex features of the solution without overfitting. Existing techniques frequently require very high-resolution grids or a large number of collocation points which are computationally expensive and may lead to overfitting.</p><p>Physics-Informed Gaussians (PIGs) offer a novel approach. Instead of fixed grid points, PIGs use trainable Gaussian functions. <strong>The mean and variance of each Gaussian are learned during training</strong>, allowing the model to dynamically adjust the location and shape of these functions to focus on areas with high variations in the solution. This adaptive mesh representation effectively addresses the limitations of existing methods, resulting in improved accuracy and faster convergence. <strong>Experimental results demonstrate PIGs&rsquo; competitive performance and efficiency across diverse PDEs.</strong></p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-301cd7b1ddc4336e840e100f4bf8430e></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-301cd7b1ddc4336e840e100f4bf8430e",{strings:[" PIGs use dynamically adjusted Gaussian functions to overcome limitations of traditional neural network approaches to solving PDEs. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-a3d4a78d2bd5c0438fc4b13794d03855></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-a3d4a78d2bd5c0438fc4b13794d03855",{strings:[" The adaptive mesh representation of PIGs leads to competitive performance with fewer parameters and faster convergence compared to existing methods. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-38d18b1d405e95d5b6a9d563dac12fa9></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-38d18b1d405e95d5b6a9d563dac12fa9",{strings:[" Experimental results demonstrate PIGs' effectiveness in solving various complex PDEs, showcasing their potential as a robust tool. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial for researchers working on solving partial differential equations (PDEs) using machine learning. <strong>It introduces a novel method that significantly improves accuracy and efficiency compared to existing techniques.</strong> The adaptive nature of the approach, using learnable Gaussian functions, allows for better approximation of complex PDEs, especially those with high-frequency components and singularities. This work also opens new avenues for research in adaptive mesh refinement and the integration of machine learning techniques with numerical methods for PDEs, making it highly relevant to current trends.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/AC_iteration.jpg alt></figure></p><blockquote><p>üîº Figure 1 visualizes the training process of a Physics-Informed Gaussian (PIG) model solving the Allen-Cahn equation. The figure displays snapshots at 200, 600, 1000, and 2000 training iterations. Each ellipsoid represents a Gaussian function within the PIG model, and their size, shape, and position dynamically adapt during training based on their learned mean and covariance parameters. The color within each ellipsoid indicates the weight of the Gaussian at that position. The use of a causal loss function ensures the solution is progressively learned from time t=0 to t=1. Noticeably, the Gaussian functions tend to cluster and become more numerous in areas where the solution changes rapidly, demonstrating the adaptive nature of the PIG model.</p><details><summary>read the caption</summary>Figure 1: Training visualization of the Allen-Cahn equation (200, 600, 1000, 2000 training iterations): Each Gaussian is displayed as the ellipsoids, exhibiting different positions and shapes according to the Gaussian parameters, mean and covariance. Since we adopt a causal loss (Wang et¬†al., 2024c), the solution is gradually approximated from t=0ùë°0t=0italic_t = 0 to t=1ùë°1t=1italic_t = 1. Note that the Gaussians are densely aligned in the locations where the solution changes abruptly.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Methods</th><th>Allen-Cahn</th><th>Helmholtz</th><th>Nonlinear Diffusion</th><th>Flow Mixing</th><th>Klein Gordon</th></tr></thead><tbody><tr><td>PINN</td><td>-</td><td>4.02e-1</td><td>9.50e-3</td><td>-</td><td>3.43e-2</td></tr><tr><td>LRA</td><td>-</td><td>3.69e-3</td><td>-</td><td>-</td><td>-</td></tr><tr><td>PIXEL</td><td>8.86e-3</td><td>8.63e-4</td><td>-</td><td>-</td><td>-</td></tr><tr><td>SPINN</td><td>-</td><td>-</td><td>4.47e-2</td><td>2.90e-3</td><td>1.93e-2</td></tr><tr><td>JAX-PI</td><td>5.37e-5</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>PirateNet</td><td>2.24e-5</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>PIG (Ours)</td><td>1.04e-4</td><td>4.13e-5</td><td>2.69e-3</td><td>4.51e-4</td><td>2.76e-3</td></tr><tr><td>¬± 1std</td><td>¬± 4.12e-5</td><td>¬± 2.59e-05</td><td>¬± 6.55e-4</td><td>¬± 1.74e-4</td><td>¬± 4.27e-4</td></tr><tr><td>best</td><td>5.93e-5</td><td>2.22e-5</td><td>1.44e-3</td><td>2.67e-4</td><td>2.36e-3</td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares the performance of various methods for approximating solutions to partial differential equations (PDEs) by showing their relative L2 errors. The comparison includes several state-of-the-art methods like PINN, Learning Rate Annealing (LRA), PIXEL, SPINN, JAX-PI, and Pirate-Net. The results are averaged over three separate experiments with different random seeds (100, 200, 300) to assess the robustness of the methods. Mean and standard deviation of L2 errors are presented for a comprehensive evaluation. Note that for fair comparisons, only results reported in the original papers for each method are included.</p><details><summary>read the caption</summary>Table 1: Comparison of relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT errors across different methods. Three experiments were conducted using seeds 100, 200, and 300, with the mean and standard deviation presented in the table. The methods compared include PINN¬†(Raissi et¬†al., 2019), Learning Rate Annealing (LRA)¬†(Wang et¬†al., 2021), PIXEL¬†(Kang et¬†al., 2023), SPINN¬†(Cho et¬†al., 2024), JAX-PI¬†(Wang et¬†al., 2023), and Pirate-Net¬†(Wang et¬†al., 2024b). For fair comparisons, we included the reported values from the respective references and omitted results that were not provided in the original papers.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Physics-Informed Gaussian<div id=physics-informed-gaussian class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#physics-informed-gaussian aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Physics-Informed Gaussians&rdquo; presents a novel approach to solving partial differential equations (PDEs) by combining the strengths of Gaussian processes and physics-informed neural networks (PINNs). The core idea involves using <strong>trainable Gaussian functions</strong> as basis functions to represent the solution space. Instead of fixed grid points like in traditional finite element methods or even parametric grid methods, the Gaussians&rsquo; means and covariances are learned during training, allowing for <strong>adaptive mesh refinement</strong>. This adaptability is crucial, as it enables the model to focus computational resources on areas where the solution is most complex or changes rapidly, leading to <strong>improved efficiency and accuracy</strong>. The integration with PINNs maintains the straightforward optimization framework, leveraging gradient-based methods for training. The use of Gaussians, with their smooth, infinitely differentiable nature, offers benefits in gradient computation for PDE residuals. By dynamically adjusting positions and shapes of the Gaussians, the method aims to overcome spectral bias issues commonly seen in standard neural networks applied to PDEs. Overall, <strong>Physics-Informed Gaussians</strong> offer a promising alternative that blends the advantages of mesh-free learning with adaptive mesh capabilities for superior performance in solving complex PDEs.</p><h4 class="relative group">Adaptive Meshing<div id=adaptive-meshing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adaptive-meshing aria-label=Anchor>#</a></span></h4><p>Adaptive meshing, in the context of solving partial differential equations (PDEs), is a crucial technique for optimizing computational efficiency and solution accuracy. <strong>Traditional methods often employ uniform grids</strong>, which can be computationally expensive and inefficient, especially when dealing with complex geometries or solutions exhibiting high gradients in localized areas. <strong>Adaptive meshing dynamically refines the mesh resolution in regions requiring higher accuracy</strong>, such as near boundaries or discontinuities, while coarsening the mesh in areas with smoother solutions. This approach ensures that computational resources are concentrated where they are most needed, leading to <strong>significant reductions in computational cost without sacrificing accuracy</strong>. Several strategies exist for implementing adaptive meshing, including error-based refinement, where the mesh is refined based on estimated errors in the solution, and feature-based refinement, which focuses on resolving features of interest. <strong>The choice of adaptive meshing strategy depends on the specific problem, the available computational resources, and the desired level of accuracy.</strong> For PDEs solved by neural networks, adaptive meshing is a particularly valuable tool for handling complex solutions efficiently. The optimal mesh density is not known in advance, and it evolves throughout training. This necessitates adaptive mechanisms that dynamically allocate computational resources throughout training.</p><h4 class="relative group">UAT for PIGs<div id=uat-for-pigs class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#uat-for-pigs aria-label=Anchor>#</a></span></h4><p>The Universal Approximation Theorem (UAT) for Physics-Informed Gaussians (PIGs) is a crucial aspect of the research paper. A rigorous proof of the UAT for PIGs would formally establish the capability of the model to approximate any continuous function, a fundamental property for a successful PDE solver. <strong>The proof likely focuses on the expressive power of the Gaussian feature embedding and lightweight neural network components of the PIG architecture</strong>. It would address how the combination of trainable Gaussian parameters (means and covariances) and the neural network enables the representation of complex functions. <strong>The interplay between the localized nature of Gaussian functions and the global approximation capacity of the neural network is a key element of this analysis.</strong> It is important to understand how the model&rsquo;s adaptability, through the dynamic adjustment of Gaussian positions, interacts with the theoretical guarantees of approximation provided by the UAT. The UAT for PIGs, thus, connects the model&rsquo;s architecture with its functional capabilities, supporting the claim of robustness and efficiency across a range of PDEs.</p><h4 class="relative group">Empirical Validation<div id=empirical-validation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#empirical-validation aria-label=Anchor>#</a></span></h4><p>An &lsquo;Empirical Validation&rsquo; section in a PDF research paper is crucial for demonstrating the practical effectiveness of the proposed methods. It should present <strong>rigorous experiments</strong> on diverse and challenging datasets, carefully designed to test the model&rsquo;s capabilities and limitations. The section needs to detail the experimental setup, including dataset characteristics, evaluation metrics, and parameter choices. <strong>Comparative analysis</strong> against existing state-of-the-art approaches is vital to establish the novelty and superiority of the proposed method. Results should be clearly presented through tables, figures, and statistical analysis, highlighting both the strengths and weaknesses of the method. <strong>Error analysis</strong>, including different types of errors, and an investigation into factors impacting performance, such as hyperparameter tuning, should also be included. A thoughtful discussion of the results, relating them back to the theoretical foundations of the paper, is necessary to provide a comprehensive and insightful validation of the research claims. Ultimately, a strong &lsquo;Empirical Validation&rsquo; section builds confidence in the scientific rigor and practical impact of the research.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>Future research directions stemming from this PDF could involve exploring <strong>more sophisticated adaptive mechanisms</strong> for the Gaussian parameters. The current approach dynamically adjusts parameters, but more intelligent strategies, potentially incorporating reinforcement learning or advanced optimization techniques, could yield substantial improvements in accuracy and efficiency. Another avenue would be to <strong>investigate alternative basis functions</strong> beyond Gaussians, perhaps exploring combinations of different functions to better capture diverse solution behaviors. The current framework uses a relatively simple neural network; incorporating more complex architectures, such as convolutional or recurrent networks, might further enhance the model&rsquo;s ability to approximate complex PDEs. Finally, a crucial area for future work is <strong>rigorous theoretical analysis</strong>. Establishing convergence guarantees and a deeper understanding of the model&rsquo;s limitations could greatly improve its practical usability and lead to the development of more robust and reliable PDE solvers. The application to higher-dimensional problems could also benefit from <strong>exploring advanced numerical techniques</strong> to manage computational costs.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/main_fig.jpg alt></figure></p><blockquote><p>üîº Figure 2 illustrates the architectures of three different PDE solving methods: (a) PINN, (b) Parametric Grid, and (c) PIG (Physics-Informed Gaussian). In (a), a PINN directly uses input coordinates as input and generates output values through a neural network. (b) shows a parametric grid method where input coordinates are mapped to feature vectors. The vertices of this grid contain learnable parameters, which are interpolated to produce the final output. Finally, (c) displays the proposed PIG approach. Multiple Gaussian functions, each with learnable parameters (mean, covariance, and feature embedding), dynamically adapt their position and shape during training. The final feature vector for a given coordinate is a weighted sum of these Gaussian functions, with the weights determined by proximity to the input coordinate. This dynamic adjustment allows PIG to efficiently focus its computational resources on areas where the solution changes significantly.</p><details><summary>read the caption</summary>Figure 2: (a) PINN directly takes input coordinates (four collocation points) as inputs and produces outputs. (b) Parametric grids first map input coordinates to output feature vectors. Each vertex in the grids holds learnable parameters, and output features are extracted through interpolation schemes. (c) The proposed PIG consists of numerous Gaussians moving around within the input domain, and their shapes change dynamically during training. Each Gaussian has learnable parameters, and a feature vector for an input coordinate is the weighted sum of the learnable parameters based on the distance to the Gaussians.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/pig_nn2.jpg alt></figure></p><blockquote><p>üîº This figure illustrates the architecture of the Physics-Informed Gaussian (PIG) model as a neural network. The input is a coordinate, which is passed through a layer of radial basis functions (RBFs), one for each Gaussian in the model. Each RBF produces a weighted contribution based on the distance from the coordinate to the Gaussian&rsquo;s center. These weighted contributions are then combined to form a feature vector. This feature vector is fed into a multilayer perceptron (MLP), which refines the features and produces the final output, which is the solution to the PDE. The weights of the Gaussian feature embeddings are learnable, as are the weights of the MLP.</p><details><summary>read the caption</summary>Figure 3: PIG as a neural network.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/ac_2.jpg alt></figure></p><blockquote><p>üîº Figure 4 presents a comparison of the Allen-Cahn equation&rsquo;s solution and error maps generated by PIG and JAX-PI. The left panels show the reference solution and the absolute error maps for both methods. The x-axis represents the spatial dimension (x), and the y-axis represents the time dimension (t). The right panel displays the L2 error curves during training for both methods, illustrating convergence over training iterations. The best relative L2 error achieved by PIG is 5.93 x 10^-5.</p><details><summary>read the caption</summary>Figure 4: Allen-Cahn Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (JAX-PI) to Allen-Cahn Equation (x-axis: tùë°titalic_t, y-axis: xùë•xitalic_x). The rightmost depicts a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process (x-axis: iterations, y-axis: L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error). The experiment was conducted with three different seeds, and the best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 5.93√ó10‚àí55.93superscript1055.93\times 10^{-5}5.93 √ó 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/hh_iclr_2.jpg alt></figure></p><blockquote><p>üîº Figure 5 presents a comparison of the proposed Physics-Informed Gaussian (PIG) model and the PIXEL method for solving the 2D Helmholtz equation. It showcases the reference solution alongside absolute error maps generated by both PIG and PIXEL. This visual comparison highlights the accuracy of each method in approximating the solution. The graph on the right displays the relative L2 error over the training iterations, demonstrating PIG&rsquo;s superior performance with a best relative L2 error of 2.22 x 10^-5.</p><details><summary>read the caption</summary>Figure 5: 2D Helmholtz Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (PIXEL) to 2D Helmholtz Equation. The rightmost depicts a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process and the best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.22√ó10‚àí52.22superscript1052.22\times 10^{-5}2.22 √ó 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/kg_4.jpg alt></figure></p><blockquote><p>üîº Figure 6 presents a comparison of the performance of the Physics-Informed Gaussian (PIG) model and the state-of-the-art SPINN model on the Klein-Gordon equation. The figure displays three subplots. The left subplot shows the reference solution, the center shows the absolute error for the PIG model, and the subplot on the right displays the absolute error of SPINN. The rightmost subplot is a graph showing the relative L2 error over the course of training for both models, illustrating that the PIG model achieves a lower relative L2 error (2.36e-3) than SPINN.</p><details><summary>read the caption</summary>Figure 6: Klein-Gordon Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (SPINN) to Klein-Gordon Equation. The rightmost depicts a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process and the best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.36√ó10‚àí32.36superscript1032.36\times 10^{-3}2.36 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/Flow_mixing_abolute_error_3.jpg alt></figure></p><blockquote><p>üîº Figure 7 presents a comparison of the Flow Mixing problem results obtained using Physics-Informed Gaussian (PIG) and state-of-the-art SPINN methods. The visualizations show the reference solution, the PIG&rsquo;s prediction, and the absolute error. PIG demonstrates significantly improved accuracy, achieving a best relative L2 error of 2.67 x 10‚Åª‚Å¥ and a maximum absolute error of 5.03 x 10‚Åª¬≥. This is a substantial improvement over SPINN, which achieved a relative L2 error of 1.93 x 10‚Åª¬≤ and a maximum absolute error of 2.63 x 10‚Åª¬π.</p><details><summary>read the caption</summary>Figure 7: Flow mixing problem. The best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.67√ó10‚àí42.67superscript1042.67\times 10^{-4}2.67 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT, while its maximum absolute error is 5.03√ó10‚àí35.03superscript1035.03\times 10^{-3}5.03 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT. In comparison, one of the state-of-the-art methods, SPINN achieved ¬†1.93√ó10‚àí21.93superscript1021.93\times 10^{-2}1.93 √ó 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error and showed a maximum absolute error of 2.63√ó10‚àí12.63superscript1012.63\times 10^{-1}2.63 √ó 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/spig_kg.jpg alt></figure></p><blockquote><p>üîº Figure 8 displays the results of applying the Separable Physics-Informed Gaussian (SPIG) method to the (2+1)D Klein-Gordon equation. The figure visually compares the reference solution (exact solution) against the solution predicted by the SPIG model, showing the absolute error. The relative L2 error achieved by the SPIG method for this problem is 3.68 x 10^-4, which indicates a high level of accuracy in approximating the solution.</p><details><summary>read the caption</summary>Figure 8: Klein-Gordon equationA.2.3. The relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of SPIG is 3.68√ó10‚àí43.68superscript1043.68\times 10^{-4}3.68 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/spig_hh3d.jpg alt></figure></p><blockquote><p>üîº Figure 9 presents the results of applying the Separable Physics-Informed Gaussian (SPIG) method to solve a 3D Helmholtz equation. The figure shows that SPIG achieves a relative L2 error of 1.50 x 10^-3. This demonstrates the accuracy of SPIG in handling high-dimensional problems, especially when compared to the results obtained using other methods described in the paper.</p><details><summary>read the caption</summary>Figure 9: 3D Helmholtz equation 9. The relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of SPIG is 1.50√ó10‚àí31.50superscript1031.50\times 10^{-3}1.50 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/Allen_Cahn_Inverse_upload.png alt></figure></p><blockquote><p>üîº Figure 10 presents a comparison of the performance of Physics-Informed Gaussians (PIG) and Physics-Informed Neural Networks (PINN) on an inverse problem for the Allen-Cahn equation. The Allen-Cahn equation is a partial differential equation modeling phase separation processes. In an inverse problem, the goal is to determine unknown parameters of the equation, such as a coefficient, based on observed data. The figure shows the estimated values of the unknown parameter (lambda) over training iterations for both methods. The experiment was repeated five times using different random seeds (100, 200, 300, 400, and 500) to assess the robustness and stability of the algorithms. PIG demonstrates faster convergence and achieves a more accurate estimate of the parameter than PINN. This highlights the effectiveness of PIGs in solving inverse problems.</p><details><summary>read the caption</summary>Figure 10: Allen-Cahn Inverse problem. The experiment was conducted on five different seeds (100, 200, 300, 400, 500). PIG showed better performance than PINN.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/100_dim_ac_poi.png alt></figure></p><blockquote><p>üîº This figure displays the relative L2 error curves for 100-dimensional Allen-Cahn and Poisson equations, demonstrating the performance of Physics-Informed Gaussians (PIGs) in high-dimensional settings. The left panel shows the error curve for the Allen-Cahn equation, while the right panel displays the error curve for the Poisson equation. PIGs achieved a relative L2 error of 8.88 x 10^-3 for the Allen-Cahn equation and 8.42 x 10^-3 for the Poisson equation. These results showcase PIG&rsquo;s ability to handle high-dimensional partial differential equations effectively.</p><details><summary>read the caption</summary>Figure 11: Relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curves for two high dimensional PDEs. Left: 100D Allen-Cahn equation. Right: 100D Poisson equation. PIGs achieved 8.88√ó10‚àí38.88superscript1038.88\times 10^{-3}8.88 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, and 8.42√ó10‚àí38.42superscript1038.42\times 10^{-3}8.42 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, respectively.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/LDC_Eq_upload.png alt></figure></p><blockquote><p>üîº Figure 12 presents a comparison of the results obtained using Physics-Informed Gaussians (PIG) and Parametric Grids with Convolutional Neural Networks (PG-CNN) for simulating a 2D Lid-driven cavity flow. The visualization showcases the reference solution alongside predictions generated by both methods. The absolute errors for each method are also displayed, highlighting the superior accuracy of PIG. PIG demonstrates a significantly lower relative L2 error (4.04 x 10^-4) compared to PGCAN (1.22 x 10^-3), indicating its improved accuracy in approximating complex flow patterns within the cavity.</p><details><summary>read the caption</summary>Figure 12: Lid-driven cavity flow problem. PIG achieved 4.04√ó10‚àí44.04superscript1044.04\times 10^{-4}4.04 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error whereas the baseline parametric grid method PGCAN resulted in 1.22√ó10‚àí31.22superscript1031.22\times 10^{-3}1.22 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/LDC_error_upload.png alt></figure></p><blockquote><p>üîº Figure 13 displays the relative L2 error over training iterations for the lid-driven cavity problem. The plot compares the performance of Physics-Informed Gaussians (PIG) against Physics-Guided Cell Networks (PGCAN), a method that utilizes parametric grids. The results demonstrate that PIG achieves significantly lower relative L2 error (4.04 x 10‚Åª‚Å¥) than PGCAN (1.22 x 10‚Åª¬≥), showcasing PIG&rsquo;s superior performance and efficiency in solving this specific problem.</p><details><summary>read the caption</summary>Figure 13: Relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve of the lid-driven cavity problem. PIG achieved 4.04√ó10‚àí44.04superscript1044.04\times 10^{-4}4.04 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT and PGCAN which used the parametric grid method achieved 1.22√ó10‚àí31.22superscript1031.22\times 10^{-3}1.22 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/hh_high_freq.jpg alt></figure></p><blockquote><p>üîº This figure demonstrates the ability of Physics-Informed Gaussians (PIG) to effectively approximate solutions to partial differential equations (PDEs), specifically a 2D Helmholtz equation with high-frequency components (wavenumbers a1=10 and a2=10). PIG achieves a significantly lower relative L2 error (7.09e-3) compared to the Parametric Fixed Grid method PIXEL (7.47e-2), highlighting PIG&rsquo;s superior performance in handling high-frequency details. The figure visually showcases the inability of traditional Physics-Informed Neural Networks (PINNs) to converge on this challenging problem.</p><details><summary>read the caption</summary>Figure 14: 2D Helmholtz equation with a high wavenumber (a1,a2)=(10,10)subscriptùëé1subscriptùëé21010(a_{1},a_{2})=(10,10)( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = ( 10 , 10 ). PIG achieved a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.09√ó10‚àí37.09superscript1037.09\times 10^{-3}7.09 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, while the parametric fixed grid method PIXEL reached a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.47√ó10‚àí27.47superscript1027.47\times 10^{-2}7.47 √ó 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT. PINN failed to converge.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/Histogram.jpg alt></figure></p><blockquote><p>üîº Figure 15 presents histograms visualizing the distribution of Gaussian parameters used in the Physics-Informed Gaussian (PIG) model for two distinct partial differential equations (PDEs): the flow-mixing equation and the Klein-Gordon equation. The top row displays histograms representing the minimum distances between the centers of adjacent Gaussian functions for each PDE. A distance greater than zero signifies that no two Gaussians occupy the same location; in other words, there is no mode collapse. The bottom row shows histograms of the variances (a measure of the spread) of the Gaussian functions. The non-zero variance values indicate that each Gaussian function has a unique and non-degenerate representation, thus preventing them from collapsing into a single point.</p><details><summary>read the caption</summary>Figure 15: Histograms of the Gaussian parameters for the flow-mixing equation and the Klein-Gordon equation. The upper panels display histograms of the minimum distances between the Gaussian centers, where distances >0absent0>0> 0 indicate the absence of mode collapse. The lower panels show histograms of the Gaussian variances, highlighting the non-degeneracy of the Gaussians.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/bg_1.png alt></figure></p><blockquote><p>üîº Figure 16 presents a comparison of the Physics-Informed Gaussian (PIG) model and the Physics-Informed Gaussian Splatting (PI-GS) model for approximating solutions of the (2+1)D Burgers&rsquo; equation. The left panels show the reference solution at time t=0 and t=1, respectively. The middle panels illustrate the solution predicted by the PIG model at the same time points, and the right panels show the absolute error between the PIG prediction and the reference solution. The results demonstrate that PIG achieves significantly higher accuracy than PI-GS (a relative L2 error of 7.68e-04 versus 1.62e-01) while also being more computationally efficient (0.28 seconds per iteration versus 1.5 seconds per iteration). This highlights PIG&rsquo;s superior performance in approximating solutions to complex PDEs.</p><details><summary>read the caption</summary>Figure 16: Prediction results of PIG for the first example of the (2+1)D Burgers‚Äô equation. PIG achieved a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.68√ó10‚àí47.68superscript1047.68\times 10^{-4}7.68 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT, with a computation time of 0.28 seconds per iteration. In contrast, PI-GS attained a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 1.62√ó10‚àí11.62superscript1011.62\times 10^{-1}1.62 √ó 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, requiring 1.50 seconds per iteration.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/bg_2.png alt></figure></p><blockquote><p>üîº Figure 17 presents a comparison of the performance of Physics-Informed Gaussians (PIG) and Physics-Informed Gaussian Splats (PI-GS) in approximating the solution of the (2+1)D Burgers‚Äô equation. The initial condition for this example is a probability density function (PDF) representing a mixture of two Gaussian distributions. The figure showcases the reference solution at time t=0 and t=1, alongside the corresponding predictions generated by PIG and PI-GS. The results highlight PIG&rsquo;s superior accuracy, achieving a relative L2 error of 1.08 x 10^-3 in only 0.29 seconds per iteration, compared to PI-GS&rsquo;s relative L2 error of 2.61 x 10^-1, requiring significantly more computation time (1.68 seconds per iteration).</p><details><summary>read the caption</summary>Figure 17: Prediction results of PIG for the second example of the (2+1)D Burgers‚Äô equation. PIG achieved a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 1.08√ó10‚àí31.08superscript1031.08\times 10^{-3}1.08 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, with a computation time of 0.29 seconds per iteration. In comparison, PI-GS attained a relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 2.61√ó10‚àí12.61superscript1012.61\times 10^{-1}2.61 √ó 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, requiring 1.68 seconds per iteration.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/Nonlinear_diffusion.jpg alt></figure></p><blockquote><p>üîº Figure 18 presents the results of applying the Physics-Informed Gaussian (PIG) model to solve the 2D nonlinear diffusion equation (detailed in Section 4.2.4 of the paper). The figure visually compares the reference solution (the known, correct solution) with the solution predicted by the PIG model. It demonstrates the accuracy of the PIG model by showing how closely the predicted solution matches the reference solution. Three separate trials were conducted, using different random seeds (100, 200, and 300) to assess the model&rsquo;s robustness and consistency. The caption indicates that the lowest relative L2 error achieved across these three trials was 1.44 x 10‚Åª¬≥. This signifies a relatively small discrepancy between the model&rsquo;s prediction and the actual solution.</p><details><summary>read the caption</summary>Figure 18: Non-linear diffusion equation 4.2.4. The experiment was conducted on three different seeds (100, 200, 300). The best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error is 1.44√ó10‚àí31.44superscript1031.44\times 10^{-3}1.44 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.05994/extracted/6053963/figs/Flow_mixing.jpg alt></figure></p><blockquote><p>üîº Figure 19 presents the results of the flow mixing simulation at different time points (t=0, t=2, t=4). The simulation was run three times using different random seeds (100, 200, 300) to evaluate the reproducibility and stability of the model. The figure compares the exact analytical solution of the flow mixing equation with the solution predicted by the Physics-Informed Gaussian (PIG) model. The best relative L2 error achieved across these three runs was 2.67 x 10^-4. This demonstrates the accuracy of the PIG model in approximating the complex, time-dependent behavior of the flow mixing system.</p><details><summary>read the caption</summary>Figure 19: Flow mixing equation 4.2.5. The experiment was conducted on three different seeds (100, 200, 300). The best relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error is 2.67√ó10‚àí42.67superscript1042.67\times 10^{-4}2.67 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th># Gaussians</th><th>Flow-Mixing</th><th>Nonliner-Diffusion</th><th>Allen-cahn</th></tr></thead><tbody><tr><td>200</td><td>6.07e-03</td><td>2.33e-03</td><td>1.83e-02</td></tr><tr><td>400</td><td>3.13e-03</td><td>2.22e-03</td><td>2.93e-03</td></tr><tr><td>600</td><td>1.50e-03</td><td>2.23e-03</td><td>2.75e-03</td></tr><tr><td>800</td><td>1.44e-03</td><td>1.95e-03</td><td>1.22e-03</td></tr><tr><td>1000</td><td>1.31e-03</td><td>7.33e-03</td><td>4.81e-04</td></tr><tr><td>1200</td><td>1.03e-03</td><td>3.96e-03</td><td>3.98e-04</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the impact of varying the number of Gaussian functions on the accuracy of the Physics-Informed Gaussian (PIG) model in approximating solutions for three different partial differential equations (PDEs): Flow-Mixing, Nonlinear Diffusion, and Allen-Cahn. The relative L2 error, a common metric for assessing the accuracy of PDE solution approximations, is reported for each PDE and for different counts of Gaussian functions used in the PIG model. The results illustrate the general trend that increasing the number of Gaussian functions generally leads to a reduction in the relative L2 error, suggesting improved approximation accuracy with more complex models. This demonstrates the model&rsquo;s ability to converge to the true solution with improved resolution.</p><details><summary>read the caption</summary>Table 2: The number of Gaussians and approximation accuracy (Flow-Mixing, Nonlinear Diffusion, and Allen-Cahn). The results indicate that increasing the number of Gaussians typically leads to a decrease in relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>(MLP, <math alttext="\mu" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">\mu</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">ùúá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\mu</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">italic_Œº</annotation></semantics></math>)</th><th>Allen-Cahn</th><th>Helmholtz</th><th>Nonlinear Diffusion</th><th>Flow-Mixing</th><th>Klein-Gordon</th></tr></thead><tbody><tr><td>(X, Fixed)</td><td>4.72e-03</td><td>3.97e-04</td><td>6.32e-03</td><td>4.33e-03</td><td>6.44e-02</td></tr><tr><td>(O, Fixed)</td><td>1.82e-03</td><td>2.12e-04</td><td>2.10e-03</td><td>1.09e-03</td><td>2.69e-02</td></tr><tr><td>(X, Learn)</td><td>7.29e-05</td><td>1.86e-04</td><td>5.26e-03</td><td>7.93e-04</td><td>8.51e-03</td></tr><tr><td>(O, Learn)</td><td>7.27e-05</td><td>2.22e-05</td><td>1.44e-03</td><td>4.51e-04</td><td>2.76e-03</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of an ablation study conducted to analyze the impact of two key components of the Physics-Informed Gaussian (PIG) model: the Multilayer Perceptron (MLP) and the Gaussian mean (Œº). The study was performed across various Partial Differential Equations (PDEs). It shows the effect of using either a fixed or learnable MLP, and whether the Gaussian means are fixed or dynamically adjusted during training. The results are presented as relative L2 errors, showcasing how these design choices influence the model&rsquo;s overall performance in solving different PDEs.</p><details><summary>read the caption</summary>Table 3: Ablation study results on MLP and Œºùúá\muitalic_Œº across various equations.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th># Hidden units</th><th>MLP input dim (=k)</th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>4</td><td>7.77e-03</td><td>9.60e-03</td><td>7.68e-03</td><td>9.60e-03</td></tr><tr><td>8</td><td>8.55e-03</td><td>6.44e-03</td><td>1.06e-02</td><td>8.54e-03</td></tr><tr><td>16</td><td>8.24e-03</td><td>1.06e-02</td><td>1.21e-02</td><td>6.90e-03</td></tr><tr><td>32</td><td>7.14e-03</td><td>8.06e-03</td><td>1.22e-02</td><td>6.87e-03</td></tr><tr><td>64</td><td>6.33e-03</td><td>7.50e-03</td><td>1.09e-02</td><td>9.48e-03</td></tr><tr><td>128</td><td>6.38e-03</td><td>6.88e-03</td><td>8.48e-03</td><td>7.47e-03</td></tr><tr><td>256</td><td>5.21e-03</td><td>6.60e-03</td><td>5.22e-03</td><td>5.40e-03</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of an ablation study conducted to evaluate the impact of different Multi-Layer Perceptron (MLP) configurations on the accuracy of solving the Helmholtz equation using Physics-Informed Gaussians (PIGs). The study varied two key aspects of the MLP: the number of hidden units (8, 16, 32, 64, 128, 256) and the input dimension (1, 2, 3, 4). The table shows the relative L2 error achieved at iteration 1000 for each configuration. The results demonstrate that the PIG model is robust to changes in the MLP architecture, showing minimal variation in accuracy across different numbers of hidden units and input dimensions.</p><details><summary>read the caption</summary>Table 4: The performance of different MLP configurations for the Helmholtz equation, displaying L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT relative errors at iteration 1,000 across various configurations of hidden units and MLP input dimensions. Overall, the results highlight the robustness to the size of MLP, showing minimal variation in errors across different settings.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th style=text-align:left></th><th style=text-align:center>Helmholtz</th><th style=text-align:center>Klein-Gordon</th><th style=text-align:center>Flow-Mixing</th><th style=text-align:center>Nonlinear Diffusion</th></tr></thead><tbody><tr><td style=text-align:left>Dense</td><td style=text-align:center>5.17e-05</td><td style=text-align:center>1.81e-03</td><td style=text-align:center>3.48e-04</td><td style=text-align:center>3.86e-03</td></tr><tr><td style=text-align:left>Diagonal</td><td style=text-align:center>2.22e-05</td><td style=text-align:center>2.76e-03</td><td style=text-align:center>4.51e-04</td><td style=text-align:center>1.44e-03</td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares the performance of Physics-Informed Gaussians (PIGs) using two different types of covariance matrices: diagonal and dense. For the dense matrix experiments, the PIG model was initially trained with a diagonal covariance matrix. The weights obtained from this initial training were then used to initialize the parameters for a dense covariance matrix, which was then further fine-tuned. The results show the relative L2 errors achieved by both approaches on various partial differential equations.</p><details><summary>read the caption</summary>Table 5: Comparison of error levels between dense and diagonal covariance matrices in PIGs. For dense covariance matrix experiments, we first trained PIG using a diagonal covariance matrix and then fine-tuned full covariance matrix parameters initialized from the trained diagonal elements.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th></th><th>Equation 23</th><th>Equation 24</th></tr></thead><tbody><tr><td>PIRBNs</td><td>6.87e-03 ¬± 3.70e-04</td><td>1.47e-02 ¬± 9.16e-03</td></tr><tr><td>PIGs</td><td>1.79e-05 ¬± 3.80e-06</td><td>1.14e-04 ¬± 1.19e-05</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparison of the performance of Physics-Informed Gaussians (PIGs) and Physics-Informed Radial Basis Networks (PIRBNs) on two different equations (Equations 23 and 24, as described in the paper&rsquo;s Appendix A.3). The results demonstrate that PIGs achieve significantly lower errors compared to PIRBNs, showcasing the superior performance of PIGs in approximating solutions for both equations.</p><details><summary>read the caption</summary>Table 6: Results of the comparison study between PIGs and PIRBNs for Equations 23 and 24. PIGs achieve lower errors than PIRBNs, highlighting their superior performance in both equations.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><p>| FE
+NN</p><table><thead><tr><th>Œ∏</th><th>Helmholtz</th><th>Flow-Mixing</th><th>Klein-Gordon</th></tr></thead><tbody><tr><td>SIREN + Id</td><td>1.68e-03 ¬± 2.02e-03</td><td>1.22e-02 ¬± 4.17e-03</td><td>1.18e-01 ¬± 4.88e-02</td></tr><tr><td>SIREN + tanh</td><td>1.31e-03 ¬± 8.26e-04</td><td>2.80e-02 ¬± 2.50e-02</td><td>1.04e-01 ¬± 8.61e-02</td></tr><tr><td>PIG + SIREN</td><td><strong>1.37e-05</strong> ¬± 1.64e-06</td><td>1.28e-03 ¬± 1.09e-04</td><td>2.37e-02 ¬± 4.62e-03</td></tr><tr><td>PIG + tanh</td><td>4.13e-05 ¬± 2.59e-05</td><td><strong>4.51e-04</strong> ¬± 1.74e-04</td><td><strong>2.76e-03</strong> ¬± 4.27e-04</td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares the performance of PIG (Physics-Informed Gaussians), using different neural network architectures, against SIREN (Implicit Neural Representations with Periodic Activation Functions). The comparison is made across multiple partial differential equations (PDEs): Allen-Cahn, Helmholtz, Flow Mixing, and Klein-Gordon. Results show that PIG with a tanh activation function generally outperforms SIREN across these PDEs, except for the Helmholtz equation. The better performance of PIG + SIREN on the Helmholtz equation is hypothesized to be due to the specific form of the Helmholtz equation&rsquo;s exact solution being better suited to SIREN&rsquo;s architecture.</p><details><summary>read the caption</summary>Table 7: Comparison of PIG and SIREN performance. For all cases except the Helmholtz equation, the original PIG + tanh\tanhroman_tanh formulation outperformed other methods. The improved performance of PIG + SIREN on the Helmholtz equation may be attributed to the functional form of its exact solution.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th style=text-align:left></th><th style=text-align:center>Burgers‚Äô equation (1)</th><th style=text-align:center>Burgers‚Äô equation (2)</th></tr></thead><tbody><tr><td style=text-align:left>PIG</td><td style=text-align:center>7.68 √ó 10‚Åª‚Å¥ (0.28s/it)</td><td style=text-align:center>1.08 √ó 10‚Åª¬≥ (0.29s/it)</td></tr><tr><td style=text-align:left>PI-GS</td><td style=text-align:center>1.62 √ó 10‚Åª¬π (1.5s/it)</td><td style=text-align:center>2.61 √ó 10‚Åª¬π (1.68s/it)</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparison of the performance of Physics-Informed Gaussians (PIG) and Physics-Informed Gaussian Splatting (PI-GS) across three benchmark problems: two variations of the (2+1)D Burgers&rsquo; equation and another unnamed problem. For each problem, the table shows the relative L2 error achieved by each method and the computation time per iteration in seconds (s/it). This comparison highlights the relative efficiency and accuracy of the two approaches in solving these benchmark partial differential equations (PDEs).</p><details><summary>read the caption</summary>Table 8: Performance comparison of PIG and PI-GS across 3 benchmark problems. Results include relative L2superscriptùêø2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT errors and computation times per iteration (s/it). Benchmarks are conducted on two variations of the (2+1)D Burgers equation.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-86872530142c0c0b6b701bbd4695e200 class=gallery><img src=https://ai-paper-reviewer.com/2412.05994/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2412.05994/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/&amp;title=PIG:%20Physics-Informed%20Gaussians%20as%20Adaptive%20Parametric%20Mesh%20Representations" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/&amp;text=PIG:%20Physics-Informed%20Gaussians%20as%20Adaptive%20Parametric%20Mesh%20Representations" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/&amp;subject=PIG:%20Physics-Informed%20Gaussians%20as%20Adaptive%20Parametric%20Mesh%20Representations" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2412.05994/index.md",oid_likes="likes_paper-reviews/2412.05994/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2412.05552/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-07T00:00:00+00:00>7 December 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2412.06845/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Fully Open Source Moxin-7B Technical Report</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-08T00:00:00+00:00>8 December 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>