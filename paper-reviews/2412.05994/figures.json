[{"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/AC_iteration.jpg", "caption": "Figure 1: Training visualization of the Allen-Cahn equation (200, 600, 1000, 2000 training iterations): Each Gaussian is displayed as the ellipsoids, exhibiting different positions and shapes according to the Gaussian parameters, mean and covariance. Since we adopt a causal loss (Wang et\u00a0al., 2024c), the solution is gradually approximated from t=0\ud835\udc610t=0italic_t = 0 to t=1\ud835\udc611t=1italic_t = 1. Note that the Gaussians are densely aligned in the locations where the solution changes abruptly.", "description": "Figure 1 visualizes the training process of a Physics-Informed Gaussian (PIG) model solving the Allen-Cahn equation.  The figure displays snapshots at 200, 600, 1000, and 2000 training iterations. Each ellipsoid represents a Gaussian function within the PIG model, and their size, shape, and position dynamically adapt during training based on their learned mean and covariance parameters. The color within each ellipsoid indicates the weight of the Gaussian at that position.  The use of a causal loss function ensures the solution is progressively learned from time t=0 to t=1.  Noticeably, the Gaussian functions tend to cluster and become more numerous in areas where the solution changes rapidly, demonstrating the adaptive nature of the PIG model.", "section": "3.2 Physics-Informed Gaussians"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/main_fig.jpg", "caption": "Figure 2: (a) PINN directly takes input coordinates (four collocation points) as inputs and produces outputs. (b) Parametric grids first map input coordinates to output feature vectors. Each vertex in the grids holds learnable parameters, and output features are extracted through interpolation schemes. (c) The proposed PIG consists of numerous Gaussians moving around within the input domain, and their shapes change dynamically during training. Each Gaussian has learnable parameters, and a feature vector for an input coordinate is the weighted sum of the learnable parameters based on the distance to the Gaussians.", "description": "Figure 2 illustrates the architectures of three different PDE solving methods: (a) PINN, (b) Parametric Grid, and (c) PIG (Physics-Informed Gaussian).  In (a), a PINN directly uses input coordinates as input and generates output values through a neural network. (b) shows a parametric grid method where input coordinates are mapped to feature vectors. The vertices of this grid contain learnable parameters, which are interpolated to produce the final output.  Finally, (c) displays the proposed PIG approach. Multiple Gaussian functions, each with learnable parameters (mean, covariance, and feature embedding), dynamically adapt their position and shape during training.  The final feature vector for a given coordinate is a weighted sum of these Gaussian functions, with the weights determined by proximity to the input coordinate.  This dynamic adjustment allows PIG to efficiently focus its computational resources on areas where the solution changes significantly.", "section": "3.2 Physics-Informed Gaussians"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/pig_nn2.jpg", "caption": "Figure 3: PIG as a neural network.", "description": "This figure illustrates the architecture of the Physics-Informed Gaussian (PIG) model as a neural network.  The input is a coordinate, which is passed through a layer of radial basis functions (RBFs), one for each Gaussian in the model. Each RBF produces a weighted contribution based on the distance from the coordinate to the Gaussian's center. These weighted contributions are then combined to form a feature vector. This feature vector is fed into a multilayer perceptron (MLP), which refines the features and produces the final output, which is the solution to the PDE. The weights of the Gaussian feature embeddings are learnable, as are the weights of the MLP.", "section": "3.2 Physics-Informed Gaussians"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/ac_2.jpg", "caption": "Figure 4: Allen-Cahn Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (JAX-PI) to Allen-Cahn Equation (x-axis: t\ud835\udc61titalic_t, y-axis: x\ud835\udc65xitalic_x). The rightmost depicts a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process (x-axis: iterations, y-axis: L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error). The experiment was conducted with three different seeds, and the best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 5.93\u00d710\u221255.93superscript1055.93\\times 10^{-5}5.93 \u00d7 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT.", "description": "Figure 4 presents a comparison of the Allen-Cahn equation's solution and error maps generated by PIG and JAX-PI.  The left panels show the reference solution and the absolute error maps for both methods. The x-axis represents the spatial dimension (x), and the y-axis represents the time dimension (t). The right panel displays the L2 error curves during training for both methods, illustrating convergence over training iterations. The best relative L2 error achieved by PIG is 5.93 x 10^-5.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/hh_iclr_2.jpg", "caption": "Figure 5: 2D Helmholtz Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (PIXEL) to 2D Helmholtz Equation. The rightmost depicts a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process and the best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.22\u00d710\u221252.22superscript1052.22\\times 10^{-5}2.22 \u00d7 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT.", "description": "Figure 5 presents a comparison of the proposed Physics-Informed Gaussian (PIG) model and the PIXEL method for solving the 2D Helmholtz equation.  It showcases the reference solution alongside absolute error maps generated by both PIG and PIXEL. This visual comparison highlights the accuracy of each method in approximating the solution. The graph on the right displays the relative L2 error over the training iterations, demonstrating PIG's superior performance with a best relative L2 error of 2.22 x 10^-5.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/kg_4.jpg", "caption": "Figure 6: Klein-Gordon Equation. Reference solution and absolute error maps of PIG and one of the state-of-the-art methods (SPINN) to Klein-Gordon Equation. The rightmost depicts a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve during the training process and the best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.36\u00d710\u221232.36superscript1032.36\\times 10^{-3}2.36 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.", "description": "Figure 6 presents a comparison of the performance of the Physics-Informed Gaussian (PIG) model and the state-of-the-art SPINN model on the Klein-Gordon equation.  The figure displays three subplots. The left subplot shows the reference solution, the center shows the absolute error for the PIG model, and the subplot on the right displays the absolute error of SPINN.  The rightmost subplot is a graph showing the relative L2 error over the course of training for both models, illustrating that the PIG model achieves a lower relative L2 error (2.36e-3) than SPINN.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/Flow_mixing_abolute_error_3.jpg", "caption": "Figure 7: Flow mixing problem. The best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of PIG is 2.67\u00d710\u221242.67superscript1042.67\\times 10^{-4}2.67 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT, while its maximum absolute error is 5.03\u00d710\u221235.03superscript1035.03\\times 10^{-3}5.03 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT. In comparison, one of the state-of-the-art methods, SPINN achieved \u00a01.93\u00d710\u221221.93superscript1021.93\\times 10^{-2}1.93 \u00d7 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error and showed a maximum absolute error of 2.63\u00d710\u221212.63superscript1012.63\\times 10^{-1}2.63 \u00d7 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.", "description": "Figure 7 presents a comparison of the Flow Mixing problem results obtained using Physics-Informed Gaussian (PIG) and state-of-the-art SPINN methods.  The visualizations show the reference solution, the PIG's prediction, and the absolute error. PIG demonstrates significantly improved accuracy, achieving a best relative L2 error of 2.67 x 10\u207b\u2074 and a maximum absolute error of 5.03 x 10\u207b\u00b3.  This is a substantial improvement over SPINN, which achieved a relative L2 error of 1.93 x 10\u207b\u00b2 and a maximum absolute error of 2.63 x 10\u207b\u00b9.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/spig_kg.jpg", "caption": "Figure 8: Klein-Gordon equationA.2.3. The relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of SPIG is 3.68\u00d710\u221243.68superscript1043.68\\times 10^{-4}3.68 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT.", "description": "Figure 8 displays the results of applying the Separable Physics-Informed Gaussian (SPIG) method to the (2+1)D Klein-Gordon equation.  The figure visually compares the reference solution (exact solution) against the solution predicted by the SPIG model, showing the absolute error. The relative L2 error achieved by the SPIG method for this problem is 3.68 x 10^-4, which indicates a high level of accuracy in approximating the solution.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/spig_hh3d.jpg", "caption": "Figure 9: 3D Helmholtz equation 9. The relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of SPIG is 1.50\u00d710\u221231.50superscript1031.50\\times 10^{-3}1.50 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.", "description": "Figure 9 presents the results of applying the Separable Physics-Informed Gaussian (SPIG) method to solve a 3D Helmholtz equation. The figure shows that SPIG achieves a relative L2 error of 1.50 x 10^-3.  This demonstrates the accuracy of SPIG in handling high-dimensional problems, especially when compared to the results obtained using other methods described in the paper.", "section": "A.4 Separable PIGs"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/Allen_Cahn_Inverse_upload.png", "caption": "Figure 10: Allen-Cahn Inverse problem. The experiment was conducted on five different seeds (100, 200, 300, 400, 500). PIG showed better performance than PINN.", "description": "Figure 10 presents a comparison of the performance of Physics-Informed Gaussians (PIG) and Physics-Informed Neural Networks (PINN) on an inverse problem for the Allen-Cahn equation.  The Allen-Cahn equation is a partial differential equation modeling phase separation processes.  In an inverse problem, the goal is to determine unknown parameters of the equation, such as a coefficient, based on observed data. The figure shows the estimated values of the unknown parameter (lambda) over training iterations for both methods. The experiment was repeated five times using different random seeds (100, 200, 300, 400, and 500) to assess the robustness and stability of the algorithms. PIG demonstrates faster convergence and achieves a more accurate estimate of the parameter than PINN. This highlights the effectiveness of PIGs in solving inverse problems.", "section": "4.2.1 (1+1)D Allen-Cahn Equation"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/100_dim_ac_poi.png", "caption": "Figure 11: Relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curves for two high dimensional PDEs. Left: 100D Allen-Cahn equation. Right: 100D Poisson equation. PIGs achieved 8.88\u00d710\u221238.88superscript1038.88\\times 10^{-3}8.88 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, and 8.42\u00d710\u221238.42superscript1038.42\\times 10^{-3}8.42 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, respectively.", "description": "This figure displays the relative L2 error curves for 100-dimensional Allen-Cahn and Poisson equations, demonstrating the performance of Physics-Informed Gaussians (PIGs) in high-dimensional settings. The left panel shows the error curve for the Allen-Cahn equation, while the right panel displays the error curve for the Poisson equation. PIGs achieved a relative L2 error of 8.88 x 10^-3 for the Allen-Cahn equation and 8.42 x 10^-3 for the Poisson equation.  These results showcase PIG's ability to handle high-dimensional partial differential equations effectively.", "section": "A.6 HIGH-DIMENSIONAL EQUATIONS"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/LDC_Eq_upload.png", "caption": "Figure 12: Lid-driven cavity flow problem. PIG achieved 4.04\u00d710\u221244.04superscript1044.04\\times 10^{-4}4.04 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error whereas the baseline parametric grid method PGCAN resulted in 1.22\u00d710\u221231.22superscript1031.22\\times 10^{-3}1.22 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.", "description": "Figure 12 presents a comparison of the results obtained using Physics-Informed Gaussians (PIG) and Parametric Grids with Convolutional Neural Networks (PG-CNN) for simulating a 2D Lid-driven cavity flow. The visualization showcases the reference solution alongside predictions generated by both methods.  The absolute errors for each method are also displayed, highlighting the superior accuracy of PIG.  PIG demonstrates a significantly lower relative L2 error (4.04 x 10^-4) compared to PGCAN (1.22 x 10^-3), indicating its improved accuracy in approximating complex flow patterns within the cavity.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/LDC_error_upload.png", "caption": "Figure 13: Relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error curve of the lid-driven cavity problem. PIG achieved 4.04\u00d710\u221244.04superscript1044.04\\times 10^{-4}4.04 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT and PGCAN which used the parametric grid method achieved 1.22\u00d710\u221231.22superscript1031.22\\times 10^{-3}1.22 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.", "description": "Figure 13 displays the relative L2 error over training iterations for the lid-driven cavity problem.  The plot compares the performance of Physics-Informed Gaussians (PIG) against Physics-Guided Cell Networks (PGCAN), a method that utilizes parametric grids.  The results demonstrate that PIG achieves significantly lower relative L2 error (4.04 x 10\u207b\u2074) than PGCAN (1.22 x 10\u207b\u00b3), showcasing PIG's superior performance and efficiency in solving this specific problem.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/hh_high_freq.jpg", "caption": "Figure 14: 2D Helmholtz equation with a high wavenumber (a1,a2)=(10,10)subscript\ud835\udc4e1subscript\ud835\udc4e21010(a_{1},a_{2})=(10,10)( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = ( 10 , 10 ). PIG achieved a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.09\u00d710\u221237.09superscript1037.09\\times 10^{-3}7.09 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, while the parametric fixed grid method PIXEL reached a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.47\u00d710\u221227.47superscript1027.47\\times 10^{-2}7.47 \u00d7 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT. PINN failed to converge.", "description": "This figure demonstrates the ability of Physics-Informed Gaussians (PIG) to effectively approximate solutions to partial differential equations (PDEs), specifically a 2D Helmholtz equation with high-frequency components (wavenumbers a1=10 and a2=10). PIG achieves a significantly lower relative L2 error (7.09e-3) compared to the Parametric Fixed Grid method PIXEL (7.47e-2), highlighting PIG's superior performance in handling high-frequency details. The figure visually showcases the inability of traditional Physics-Informed Neural Networks (PINNs) to converge on this challenging problem.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/Histogram.jpg", "caption": "Figure 15: Histograms of the Gaussian parameters for the flow-mixing equation and the Klein-Gordon equation. The upper panels display histograms of the minimum distances between the Gaussian centers, where distances >0absent0>0> 0 indicate the absence of mode collapse. The lower panels show histograms of the Gaussian variances, highlighting the non-degeneracy of the Gaussians.", "description": "Figure 15 presents histograms visualizing the distribution of Gaussian parameters used in the Physics-Informed Gaussian (PIG) model for two distinct partial differential equations (PDEs): the flow-mixing equation and the Klein-Gordon equation. The top row displays histograms representing the minimum distances between the centers of adjacent Gaussian functions for each PDE.  A distance greater than zero signifies that no two Gaussians occupy the same location; in other words, there is no mode collapse. The bottom row shows histograms of the variances (a measure of the spread) of the Gaussian functions.  The non-zero variance values indicate that each Gaussian function has a unique and non-degenerate representation, thus preventing them from collapsing into a single point.", "section": "4.3 Hyperparameter Analysis and Ablation Study"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/bg_1.png", "caption": "Figure 16: Prediction results of PIG for the first example of the (2+1)D Burgers\u2019 equation. PIG achieved a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 7.68\u00d710\u221247.68superscript1047.68\\times 10^{-4}7.68 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT, with a computation time of 0.28 seconds per iteration. In contrast, PI-GS attained a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 1.62\u00d710\u221211.62superscript1011.62\\times 10^{-1}1.62 \u00d7 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, requiring 1.50 seconds per iteration.", "description": "Figure 16 presents a comparison of the Physics-Informed Gaussian (PIG) model and the Physics-Informed Gaussian Splatting (PI-GS) model for approximating solutions of the (2+1)D Burgers' equation.  The left panels show the reference solution at time t=0 and t=1, respectively. The middle panels illustrate the solution predicted by the PIG model at the same time points, and the right panels show the absolute error between the PIG prediction and the reference solution. The results demonstrate that PIG achieves significantly higher accuracy than PI-GS (a relative L2 error of 7.68e-04 versus 1.62e-01) while also being more computationally efficient (0.28 seconds per iteration versus 1.5 seconds per iteration). This highlights PIG's superior performance in approximating solutions to complex PDEs.", "section": "A.12 Additional Figures"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/bg_2.png", "caption": "Figure 17: Prediction results of PIG for the second example of the (2+1)D Burgers\u2019 equation. PIG achieved a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 1.08\u00d710\u221231.08superscript1031.08\\times 10^{-3}1.08 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, with a computation time of 0.29 seconds per iteration. In comparison, PI-GS attained a relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error of 2.61\u00d710\u221212.61superscript1012.61\\times 10^{-1}2.61 \u00d7 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, requiring 1.68 seconds per iteration.", "description": "Figure 17 presents a comparison of the performance of Physics-Informed Gaussians (PIG) and Physics-Informed Gaussian Splats (PI-GS) in approximating the solution of the (2+1)D Burgers\u2019 equation.  The initial condition for this example is a probability density function (PDF) representing a mixture of two Gaussian distributions.  The figure showcases the reference solution at time t=0 and t=1, alongside the corresponding predictions generated by PIG and PI-GS.  The results highlight PIG's superior accuracy, achieving a relative L2 error of 1.08 x 10^-3 in only 0.29 seconds per iteration, compared to PI-GS's relative L2 error of 2.61 x 10^-1, requiring significantly more computation time (1.68 seconds per iteration).", "section": "A.12 Additional Figures"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/Nonlinear_diffusion.jpg", "caption": "Figure 18: Non-linear diffusion equation 4.2.4. The experiment was conducted on three different seeds (100, 200, 300). The best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error is 1.44\u00d710\u221231.44superscript1031.44\\times 10^{-3}1.44 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.", "description": "Figure 18 presents the results of applying the Physics-Informed Gaussian (PIG) model to solve the 2D nonlinear diffusion equation (detailed in Section 4.2.4 of the paper).  The figure visually compares the reference solution (the known, correct solution) with the solution predicted by the PIG model. It demonstrates the accuracy of the PIG model by showing how closely the predicted solution matches the reference solution. Three separate trials were conducted, using different random seeds (100, 200, and 300) to assess the model's robustness and consistency. The caption indicates that the lowest relative L2 error achieved across these three trials was 1.44 x 10\u207b\u00b3. This signifies a relatively small discrepancy between the model's prediction and the actual solution.", "section": "4.2 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2412.05994/extracted/6053963/figs/Flow_mixing.jpg", "caption": "Figure 19: Flow mixing equation 4.2.5. The experiment was conducted on three different seeds (100, 200, 300). The best relative L2superscript\ud835\udc3f2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error is 2.67\u00d710\u221242.67superscript1042.67\\times 10^{-4}2.67 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT.", "description": "Figure 19 presents the results of the flow mixing simulation at different time points (t=0, t=2, t=4).  The simulation was run three times using different random seeds (100, 200, 300) to evaluate the reproducibility and stability of the model. The figure compares the exact analytical solution of the flow mixing equation with the solution predicted by the Physics-Informed Gaussian (PIG) model.  The best relative L2 error achieved across these three runs was 2.67 x 10^-4. This demonstrates the accuracy of the PIG model in approximating the complex, time-dependent behavior of the flow mixing system.", "section": "4.2 Experimental Results"}]