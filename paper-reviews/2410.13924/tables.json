[{"figure_path": "2410.13924/tables/table_1_0.html", "caption": "Table 1. The size of dataset that is used for training and evaluation in this work. We provide by far the largest real-world labeled training dataset compared to existing real-world datasets. We provide automatically generated dense semantic annotations for 4471 training trajectories and 548 validation trajectories.", "description": "This table presents the number of training, validation, and test data points for several datasets used in the paper, highlighting the significantly larger size of the ARKit LabelMaker dataset.", "section": "4.2. Datasets and Metrics for Evaluation"}, {"figure_path": "2410.13924/tables/table_5_0.html", "caption": "Table 1. The size of dataset that is used for training and evaluation in this work. We provide by far the largest real-world labeled training dataset compared to existing real-world datasets. We provide automatically generated dense semantic annotations for 4471 training trajectories and 548 validation trajectories.", "description": "Table 1 presents the number of training, validation, and test samples for various 3D semantic segmentation datasets, including the ARKit LabelMaker dataset, highlighting its significantly larger size compared to existing real-world datasets.", "section": "4.2. Datasets and Metrics for Evaluation"}, {"figure_path": "2410.13924/tables/table_6_0.html", "caption": "Table 2. Semantic Segmentation Scores on ScanNet20. We compare different training strategies for two top-performing models (PointTransformerv3 [36] and MinkowskiNet [7]) on the Scan-Net20 dataset. We can show for both models adding ALS200 through pre-training and co-training improves the performance for both models. With PonderV2 [42] and Mix3D [20], we compare large-scale pretraining to two other training strategies. We can show that large-scale pre-training is superior to both, extensive data augmentation (Mix3D) and self-supervised pre-training (PonderV2).", "description": "Table 2 presents a comparison of different training strategies for PointTransformerv3 and MinkowskiNet models on the ScanNet20 dataset, highlighting the performance improvements achieved through large-scale pre-training with ALS200.", "section": "4. Results"}, {"figure_path": "2410.13924/tables/table_6_1.html", "caption": "Table 3. Semantic Segmentation Scores on ScanNet200 [29].", "description": "The table compares different training strategies for two top-performing models (PointTransformerv3 [36] and MinkowskiNet [7]) on the ScanNet200 dataset, showing the impact of adding ALS200 through pre-training and co-training.", "section": "4. Results"}, {"figure_path": "2410.13924/tables/table_6_2.html", "caption": "Table 4. Semantic Segmentation Scores on ScanNet++ [39]. We evaluated the efficacy of our ALC dataset on the ScanNet++ benchmark using both pre-training and joint training methods. \u2020: this number comes from Wu et al.", "description": "The table presents the results of semantic segmentation on the ScanNet++ benchmark, comparing different training strategies (pre-training and joint training) using ALC and other datasets.", "section": "4. Results"}, {"figure_path": "2410.13924/tables/table_8_0.html", "caption": "Table B1. ScanNet200 validation and test mIoU for head, common and tail classes. For MinkowskiNet, ARKit LabelMaker pre-trained network shows significant improvement on head and common classes. For PTv3, we see improvements across all three splits.", "description": "Table B1 presents the mean Intersection over Union (mIoU) scores for head, common, and tail classes on the ScanNet200 benchmark, comparing the performance of different training methods for MinkowskiNet and Point Transformer V3 models.", "section": "B. Head, common and tail split mIoU scores for ScanNet200"}, {"figure_path": "2410.13924/tables/table_9_0.html", "caption": "Table 1. The size of dataset that is used for training and evaluation in this work. We provide by far the largest real-world labeled training dataset compared to existing real-world datasets. We provide automatically generated dense semantic annotations for 4471 training trajectories and 548 validation trajectories.", "description": "This table presents the number of training, validation, and test samples for several 3D semantic segmentation datasets, including the newly generated ARKit LabelMaker dataset, highlighting its significantly larger size compared to existing datasets.", "section": "4.2. Datasets and Metrics for Evaluation"}]