[{"figure_path": "2410.17637/figures/figures_2_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on single-image and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_4_0.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations: sequence confusion and element interference, illustrating how attention values reveal the model's focus and contribute to incorrect responses.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_5_0.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, detailing the process of extending single-image data to multi-image data, using attention-based filtering to remove hallucinations, and applying the DPO algorithm.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_6_0.png", "caption": "Figure 4: Multi-Images DPO Data Format. To address multi-image hallucinations mentioned in Fig. 2, we construct our multi-image prompts in three formats: (a) Sequence. (b) Grid Collage. (c) Pic-in-Pic.", "description": "The figure shows three different ways to format data for multi-image prompts in MIA-DPO: sequence, grid collage, and pic-in-pic.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_6_2.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations: sequence confusion and element interference, illustrating how attention values reveal the model's focus and contribute to hallucination responses.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_6_3.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, showing how single-image data is augmented with unrelated images, attention is used to filter out hallucinations, and DPO is applied to create a stronger model.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_10_0.png", "caption": "Figure 6: Attention Difference Before and After DPO. We present the attention distribution in the intermediate layers for the original LLaVA-v1.5 (top row), MIA-DPO + LLaVA-v1.5 (second row), and the difference value (bottom row), respectively.", "description": "The figure visualizes the attention distribution changes in LLaVA-v1.5 before and after applying MIA-DPO, highlighting how MIA-DPO refines the model's focus on relevant image regions.", "section": "4.5 VISUALIZATION OBSERVATIONS"}, {"figure_path": "2410.17637/figures/figures_21_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "This figure shows an overview of the MIA-DPO framework and its performance improvements on multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_23_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on single and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on multiple single and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_1.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations (sequence confusion and element interference) and uses attention values to illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_24_2.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, showing how single-image data is extended to multi-image data, attention is used to filter out hallucination responses, and DPO is applied to improve the model's understanding of multi-image contexts.", "section": "3.3 MIA-DPO FRAMEWORK"}]