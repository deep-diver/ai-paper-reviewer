[{"figure_path": "2410.17637/figures/figures_2_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance improvements on various single and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_4_0.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model\u2019s focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations, sequence confusion and element interference, and illustrates how attention values reveal the model's focus across different images.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_5_0.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, detailing how single-image data is augmented with irrelevant images, attention values are used to filter out hallucinated responses, and the DPO algorithm is applied to create chosen/rejected pairs for model training.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_6_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure illustrates the MIA-DPO framework and its performance on multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_6_2.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations: sequence confusion and element interference, illustrating how the model's attention is incorrectly focused on irrelevant images.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_6_3.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, which extends single-image data to multi-image data by adding irrelevant images and uses attention values to filter out hallucination responses for DPO.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_10_0.png", "caption": "Figure 6: Attention Difference Before and After DPO. We present the attention distribution in the intermediate layers for the original LLaVA-v1.5 (top row), MIA-DPO + LLaVA-v1.5 (second row), and the difference value (bottom row), respectively.", "description": "The figure visualizes the attention distribution across different layers of the LLaVA model before and after applying MIA-DPO, highlighting changes in focus on specific image regions.", "section": "4.5 VISUALIZATION OBSERVATIONS"}, {"figure_path": "2410.17637/figures/figures_21_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_23_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on various single-image and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on multi-image and single-image benchmark tasks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_1.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations in Large Vision-Language Models (LVLMs): sequence confusion and element interference, illustrating how attention values reveal the model's mistaken focus.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_24_2.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, showing how single-image data is augmented with extra images, attention is used to filter out hallucinations, and chosen/rejected pairs are used for DPO.", "section": "3.3 MIA-DPO FRAMEWORK"}]