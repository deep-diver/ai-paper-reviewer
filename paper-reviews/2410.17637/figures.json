[{"figure_path": "2410.17637/figures/figures_2_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on single-image and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_4_0.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "This figure shows examples of two types of multi-image hallucinations: sequence confusion and element interference, illustrating how attention values reveal the model's focus and contribute to these errors.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_5_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_6_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on several multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_6_1.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, which extends single-image datasets to multi-image datasets and uses attention values to filter out hallucination responses.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_6_2.png", "caption": "Figure 2: Examples of Multi-Image Hallucinations. Top: Sequence Confusion that the model is confused about the order in which the images should be referenced. Bottom: Element Interference. The model incorrectly identified the attributes due to visual element interference across different images. Attention values illustrate how the model's focus was dispersed across different images, resulting in the hallucination response.", "description": "The figure shows two examples of multi-image hallucinations: sequence confusion and element interference, illustrating how the model's attention is dispersed across different images, resulting in incorrect responses.", "section": "3.2 ANALYSIS ON MULTI-IMAGE HALLUCINATIONS"}, {"figure_path": "2410.17637/figures/figures_6_3.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, showing how single-image data is augmented with irrelevant images, attention values are used to filter out hallucinations, and chosen/rejected pairs are created for DPO optimization.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_10_0.png", "caption": "Figure 6: Attention Difference Before and After DPO. We present the attention distribution in the intermediate layers for the original LLaVa-v1.5 (top row), MIA-DPO + LLaVa-v1.5 (second row), and the difference value (bottom row), respectively.", "description": "The figure visualizes the attention distribution changes in LLaVa-v1.5 before and after applying MIA-DPO on three multi-image examples.", "section": "4.5 VISUALIZATION OBSERVATIONS"}, {"figure_path": "2410.17637/figures/figures_21_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "This figure shows an overview of the MIA-DPO framework and its performance on various multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_23_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its performance on single and multi-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_0.png", "caption": "Figure 1: (a) Overview of MIA-DPO. We transform single-image data (e.g., LLaVA 665k) into multi-image data by adding noisy or unrelated images and using language descriptions to specify the target image. Attention values are then used to detect hallucinations in multi-image contexts, filtering out rejected data for DPO optimization. (b) Benchmark Results. MIA-DPO excels across five multi-image benchmarks while maintaining competitive performance on seven single-image benchmarks, demonstrating its robustness in both single and multi-image tasks.", "description": "The figure shows an overview of the MIA-DPO framework and its superior performance on multi-image and single-image benchmarks.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17637/figures/figures_24_1.png", "caption": "Figure 4: Multi-Images DPO Data Format. To address multi-image hallucinations mentioned in Fig. 2, we construct our multi-image prompts in three formats: (a) Sequence. (b) Grid Collage. (c) Pic-in-Pic.", "description": "The figure shows three different ways of creating multi-image prompts from single-image data to address hallucination issues in large vision language models.", "section": "3.3 MIA-DPO FRAMEWORK"}, {"figure_path": "2410.17637/figures/figures_24_2.png", "caption": "Figure 3: MIA-DPO Framework. We extend the single-image dataset to multi-image datasets by inserting irrelevant images and using attention values to filter out the hallucination responses for rejected samples of the DPO algorithm.", "description": "The figure illustrates the MIA-DPO framework, showing how single-image data is augmented with irrelevant images to create multi-image data, and attention mechanisms are used to filter out hallucinated responses for constructing chosen/rejected pairs in the DPO algorithm.", "section": "3.3 MIA-DPO FRAMEWORK"}]