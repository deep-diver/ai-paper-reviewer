{"references": [{"fullname_first_author": "Michael S Albergo", "paper_title": "Stochastic interpolants: A unifying framework for flows and diffusions", "publication_date": "2023-03-08", "reason": "This paper provides a foundational framework for understanding and unifying various flow and diffusion models, which are crucial for the image-to-video generation techniques discussed in the main paper."}, {"fullname_first_author": "Jie An", "paper_title": "Latent-shift: Latent diffusion with temporal shift for efficient text-to-video generation", "publication_date": "2023-04-08", "reason": "This work introduces an efficient method for text-to-video generation using latent diffusion models, offering a relevant comparison and advancement to the techniques employed in the main paper."}, {"fullname_first_author": "Omri Avrahami", "paper_title": "Spatext: Spatio-textual representation for controllable image generation", "publication_date": "2023-00-00", "reason": "This paper explores spatio-textual representations for image generation which is highly relevant to the main paper's focus on integrating textual and visual information for video generation."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-00-00", "reason": "This work addresses the scaling of latent video diffusion models, providing crucial context for understanding the challenges and advancements in video generation addressed in the main paper."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "publication_date": "2023-00-00", "reason": "This paper focuses on high-resolution video synthesis using latent diffusion models, offering a direct comparison and contrast to the approach and results presented in the main paper."}]}