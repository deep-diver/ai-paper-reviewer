{"references": [{" publication_date": "2023", "fullname_first_author": "Alyaa Aloraibi", "paper_title": "Image morphing techniques: A review", "reason": "This paper provides a comprehensive overview of image morphing techniques, a relevant area for frame interpolation, and its review of existing methods helps to establish the context and challenges in this field, justifying Framer's innovative approach.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Fitsum A. Reda", "paper_title": "FILM: frame interpolation for large motion", "reason": "FILM is a state-of-the-art frame interpolation method known for handling large motions. Comparing Framer against FILM helps highlight its improvements in handling such challenging scenarios.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Jinbo Xing", "paper_title": "Tooncrafter: Generative cartoon interpolation", "reason": "Tooncrafter focuses on cartoon interpolation, a specific application area also tackled by Framer.  This reference allows for a comparison of approaches and highlighting the versatility of Framer.", "section_number": 1}, {" publication_date": "2018", "fullname_first_author": "Huaizu Jiang", "paper_title": "Super slomo: High quality estimation of multiple intermediate frames for video interpolation", "reason": "This is a seminal paper in video interpolation, demonstrating early advancements in this field and establishes a baseline for comparison with more recent methods like Framer.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Yihao Liu", "paper_title": "Enhanced quadratic video interpolation", "reason": "This paper represents another important contribution to traditional video frame interpolation, focusing on quadratic methods. Comparing it to Framer emphasizes the shift from traditional methods to generative and interactive approaches.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Simon Niklaus", "paper_title": "Softmax splatting for video frame interpolation", "reason": "This work demonstrates a different approach to video interpolation using softmax splatting. This reference helps to further contextualize Framer's approach within the broader landscape of video interpolation techniques.", "section_number": 2}, {" publication_date": "2023a", "fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "reason": "This is a foundational paper in video diffusion models that Framer builds upon.  Understanding the strengths and limitations of this model is crucial for interpreting Framer's advancements.", "section_number": 2}, {" publication_date": "2023b", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This paper showcases another important application of video diffusion models.  Including this highlights the broader relevance of video diffusion models and Framer's contribution to the field.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "reason": "This work is relevant due to its focus on incorporating control into diffusion models, providing valuable context for Framer's interactive control mechanism.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xingang Pan", "paper_title": "Drag your GAN: interactive point-based manipulation on the generative image manifold", "reason": "This paper introduces interactive point-based manipulation in generative models, directly influencing the design and functionality of Framer's interactive mode.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jiong Dong", "paper_title": "Video frame interpolation: A comprehensive survey", "reason": "This survey provides a comprehensive overview of the video frame interpolation field, which helps to better understand the limitations of past approaches and appreciate the novelty of Framer.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kepan Nan", "paper_title": "Openvid-1m: A large-scale high-quality dataset for text-to-video generation", "reason": "The OpenVidHD-0.4M dataset is used for training and testing Framer.  This reference is crucial to understanding the experimental setup and its impact on the performance.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "Ilya Loshchilov", "paper_title": "Decoupled weight decay regularization", "reason": "AdamW, an optimizer based on decoupled weight decay, is used in training Framer.  This reference helps to clarify and justify the optimization techniques used in the training process.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Zeyue Xue", "paper_title": "RAPHAEL: text-to-image generation via large mixture of diffusion paths", "reason": "This paper explores text-to-image generation using a mixture of diffusion paths.  Mentioning this demonstrates Framer's position relative to related generative models.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Simon Niklaus", "paper_title": "Context-aware synthesis for video frame interpolation", "reason": "This work explores context-aware video frame interpolation, demonstrating the importance of context in generating smooth, natural-looking video frames.  This is directly related to the overall goal of Framer.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xiaojuan Wang", "paper_title": "Motionctrl: A unified and flexible motion controller for video generation", "reason": "This paper addresses motion control in video generation.  Its inclusion highlights the advancements in interactive control methods relevant to Framer.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Nikita Karaev", "paper_title": "Cotracker: It is better to track together", "reason": "Co-Tracker is used for point trajectory estimation in Framer's \"autopilot\" mode.   The importance of this reference is in understanding the details of the point tracking algorithm used in Framer.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jiong Dong", "paper_title": "Video frame interpolation: A comprehensive survey", "reason": "This survey is fundamental in understanding the existing landscape of video frame interpolation techniques.  It establishes the context for Framer's innovative approach.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xiaojuan Wang", "paper_title": "Videocomposer: Compositional video synthesis with motion controllability", "reason": "This paper explores compositional video synthesis, a related area to Framer's capability.  It highlights the broader impact of generative models and user control on video generation.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Jinbo Xing", "paper_title": "Dynamicrafter: Animating open-domain images with video diffusion priors", "reason": "DynamicCrafter is used as a baseline method for comparing performance. Including this provides more detail on the state-of-the-art, and thus context for Framer\u2019s performance.", "section_number": 4}]}