{"references": [{" publication_date": "2023", "fullname_first_author": "Alyaa Aloraibi", "paper_title": "Image morphing techniques: A review", "reason": "This paper provides a comprehensive overview of image morphing techniques, a core application area for Framer.  Understanding the existing methods and their limitations is crucial for evaluating Framer's contribution and establishing its novelty in addressing those limitations.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Fitsum A. Reda", "paper_title": "FILM: frame interpolation for large motion", "reason": "FILM is a state-of-the-art video frame interpolation method that focuses on handling large motions, a challenge that Framer directly addresses. Comparing Framer's performance against FILM helps highlight its improvements in handling complex motion scenarios.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Zhewei Huang", "paper_title": "RIFE: real-time intermediate flow estimation for video frame interpolation", "reason": "RIFE is a well-known real-time video frame interpolation method, making it a strong baseline for comparison.  The comparison highlights Framer's advancements in quality and handling complex motions compared to existing real-time methods.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "reason": "This paper introduces Stable Video Diffusion, a foundational model for Framer.  Understanding its properties and limitations is key to understanding Framer's design choices and evaluating its effectiveness in leveraging the Stable Video Diffusion model for video frame interpolation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jinbo Xing", "paper_title": "Dynamicrafter: Animating open-domain images with video diffusion priors", "reason": "DynamicCrafter is a related method using video diffusion models for image animation.  Comparing it with Framer clarifies their differences, emphasizing Framer's interactive controllability.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xiaojuan Wang", "paper_title": "Motionctrl: A unified and flexible motion controller for video generation", "reason": "This paper explores motion control in video generation, directly relating to the core functionality of Framer. Comparing these methods highlights Framer's unique approach to user-guided interactive motion control.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This paper explores high-resolution video synthesis using latent diffusion models. Understanding this advanced technique is essential for assessing the technical novelty and sophistication of Framer's approach.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "reason": "This paper provides insights into the capabilities of advanced video generation models, setting the context for evaluating Framer's performance relative to these powerful and versatile generative models.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "reason": "This paper focuses on adding control to diffusion models.  It's important to show Framer's relevance to the existing research landscape by connecting it to the broader field of controllable image and video generation using diffusion models.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xingang Pan", "paper_title": "Drag your GAN: interactive point-based manipulation on the generative image manifold", "reason": "This paper introduces an interactive method for manipulating images using points, making it highly relevant to Framer's point-based interaction method. Comparing the two methods clarifies their approaches and similarities.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jiong Dong", "paper_title": "Video frame interpolation: A comprehensive survey", "reason": "This survey paper provides a comprehensive overview of traditional video frame interpolation methods, setting the stage for a better understanding of Framer's novelty and advancements compared to existing techniques.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Siddhant Jain", "paper_title": "Video interpolation with diffusion models", "reason": "This paper explores the use of diffusion models for video interpolation, directly relevant to Framer's approach.  Comparing Framer's methodology against VIDIM showcases the differences and potential improvements Framer offers.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Haiwen Feng", "paper_title": "Explorative inbetweening of time and space", "reason": "This paper explores methods for inbetweening images in both time and space, relating directly to the core task of video frame interpolation.  Comparing this to Framer emphasizes the unique aspects of Framer's approach.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xiaojuan Wang", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "reason": "Videocrafter1 is a significant model in video generation using diffusion models.  Understanding this model's advancements provides context for assessing Framer's innovation and capabilities.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter2: Overcoming data limitations for high-quality video diffusion models", "reason": "Videocrafter2 addresses challenges related to data limitations in video diffusion models.  Understanding these limitations and how Framer tackles them is crucial for assessing its strengths and limitations.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Yihao Liu", "paper_title": "Enhanced quadratic video interpolation", "reason": "This method is a relatively straightforward method for video frame interpolation that can serve as a comparison point to illustrate the improvements made by Framer in handling more complex scenarios.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Liying Lu", "paper_title": "Video frame interpolation with transformer", "reason": "This paper explores transformer-based approaches for video frame interpolation, a method that is different from the diffusion model approach used in Framer. It is important to show that Framer is using a completely different technique.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Huaizu Jiang", "paper_title": "Super slomo: High quality estimation of multiple intermediate frames for video interpolation", "reason": "Super Slomo is a classic and highly influential method in video frame interpolation. Including it in the most important papers allows for demonstrating how Framer improves on the quality of generated frames while incorporating interactivity.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Tarun Kalluri", "paper_title": "FLAVR: flow-agnostic video representations for fast frame interpolation", "reason": "This paper presents a flow-agnostic approach for fast frame interpolation, a contrasting technique compared to Framer.  By comparing these two different approaches, we can highlight the advantages of the diffusion model-based methodology used in Framer.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Duolikun Danier", "paper_title": "LDMVFI: video frame interpolation with latent diffusion models", "reason": "This is another recent paper that uses a diffusion model to perform video frame interpolation. Comparing Framer's results with LDMVFI's results demonstrates its superiority.", "section_number": 2}]}