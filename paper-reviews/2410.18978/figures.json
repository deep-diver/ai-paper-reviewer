[{"figure_path": "2410.18978/figures/figures_1_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 shows examples of interactive frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_4_0.png", "caption": "Figure 2: Framer supports (a) a user-interactive mode for customized point trajectories and (b) an \"autopilot\" mode for video frame interpolation without trajectory inputs. During training, (d) we fine-tune the 3D-UNet of a pre-trained video diffusion model for video frame interpolation. Afterward, (c) we introduce point trajectory control by freezing the 3D-UNet and fine-tuning the controlling branch.", "description": "Figure 2 illustrates the architecture of Framer, showing its interactive mode, autopilot mode, trajectory controlling branch, and video frame interpolation fine-tuning process.", "section": "3 METHOD"}, {"figure_path": "2410.18978/figures/figures_5_0.png", "caption": "Figure 3: Point trajectory estimation. The point trajectory is initialized by interpolating the coordinates of matched keypoints. In each de-noising step, we perform point tracking by finding the nearest neighbor of keypoints in the start and end frames, respectively. Lastly, We check the bi-directional tracking consistency before updating the point coordinate.", "description": "Figure 3 illustrates the bi-directional point tracking method used in Framer's \"autopilot\" mode for estimating point trajectories.", "section": "3 METHOD"}, {"figure_path": "2410.18978/figures/figures_6_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the middle frame of seven interpolated frames generated by different methods, including the ground truth.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_6_1.png", "caption": "Figure 5: Reults on human preference.", "description": "The figure is a pie chart showing the results of a human preference test comparing Framer with several other video interpolation methods, indicating that Framer is overwhelmingly preferred.", "section": "4.2 COMPARISON"}, {"figure_path": "2410.18978/figures/figures_7_0.png", "caption": "Figure 6: Results on user interaction. The first row is generated without drag input, while the other two are generated with different drag controls. Customized trajectories are overlaid on frames.", "description": "The figure shows three sets of video frame interpolation results, each generated with different drag controls, demonstrating the fine-grained customization offered by the Framer model.", "section": "4.3 APPLICATIONS"}, {"figure_path": "2410.18978/figures/figures_7_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "The figure showcases various frame interpolation results generated by the Framer model, highlighting its ability to handle fine-grained customization and challenging scenarios.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_8_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging interpolation scenarios.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_8_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging cases.", "section": "Abstract"}, {"figure_path": "2410.18978/figures/figures_9_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases the results of Framer, demonstrating its ability to customize local motions and generate varying interpolation results from the same input frames, including handling challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_9_1.png", "caption": "Figure 12: Ablations on each component. \"w/o trajectory\" denotes inference without guidance from point trajectory, \"w/o traj. update\" indicates inference without trajectory updates, and \"w/o bi\" suggests trajectory updating without bi-directional consistency verification.", "description": "The figure shows ablation studies on each component of the Framer model, demonstrating the impact of trajectory guidance, trajectory updates, and bi-directional consistency verification on the final video interpolation results.", "section": "4.4 ABLATIONS STUDIES"}, {"figure_path": "2410.18978/figures/figures_17_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u201d strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 presents a qualitative comparison of the proposed Framer model with other state-of-the-art video frame interpolation methods, showing the middle frame of seven generated frames for each method.", "section": "4.2 COMPARISON"}, {"figure_path": "2410.18978/figures/figures_18_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u201d strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the proposed Framer method against several state-of-the-art video frame interpolation methods, showcasing the superior visual quality of Framer's results.", "section": "4.2 COMPARISON"}, {"figure_path": "2410.18978/figures/figures_19_0.png", "caption": "Figure 4: Qualitative comparison. \u201cGT\u201d strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 showcases a qualitative comparison of the proposed Framer model with existing methods for video frame interpolation on various sequences, highlighting the superior visual quality and detail preservation of Framer.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_20_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the proposed Framer model against several state-of-the-art video frame interpolation methods on various application scenarios.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_21_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results produced by the Framer model, highlighting its ability to handle various levels of motion complexity and user customization.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_21_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "The figure showcases the results of interactive frame interpolation using Framer, demonstrating fine-grained control over local motions and smooth transitions between frames, even in challenging scenarios.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_22_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_22_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases the interactive frame interpolation results produced by Framer, demonstrating its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_22_2.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}]