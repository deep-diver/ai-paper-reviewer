[{"figure_path": "2410.18978/figures/figures_1_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of interactive frame interpolation results generated by Framer, highlighting its ability to handle various levels of motion and image changes.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_4_0.png", "caption": "Figure 2: Framer supports (a) a user-interactive mode for customized point trajectories and (b) an \"autopilot\" mode for video frame interpolation without trajectory inputs. During training, (d) we fine-tune the 3D-UNet of a pre-trained video diffusion model for video frame interpolation. Afterward, (c) we introduce point trajectory control by freezing the 3D-UNet and fine-tuning the controlling branch.", "description": "Figure 2 illustrates the overall architecture of Framer, detailing its interactive mode, autopilot mode, trajectory controlling branch, and video frame interpolation fine-tuning process.", "section": "3 METHOD"}, {"figure_path": "2410.18978/figures/figures_5_0.png", "caption": "Figure 3: Point trajectory estimation. The point trajectory is initialized by interpolating the coordinates of matched keypoints. In each de-noising step, we perform point tracking by finding the nearest neighbor of keypoints in the start and end frames, respectively. Lastly, We check the bi-directional tracking consistency before updating the point coordinate.", "description": "Figure 3 illustrates the bi-directional point tracking method used in Framer's \"autopilot\" mode to estimate point trajectories for video frame interpolation.", "section": "3 METHOD"}, {"figure_path": "2410.18978/figures/figures_6_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the proposed Framer method with other state-of-the-art video frame interpolation methods on various video clips.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_6_1.png", "caption": "Figure 5: Reults on human preference.", "description": "The figure is a pie chart showing the percentage of human preference for Framer compared to other video interpolation methods.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_7_0.png", "caption": "Figure 6: Results on user interaction. The first row is generated without drag input, while the other two are generated with different drag controls. Customized trajectories are overlaid on frames.", "description": "The figure showcases the results of user interaction in the Framer model, demonstrating how different drag controls affect the generated frames and their trajectories.", "section": "3.2 INTERACTIVE FRAME INTERPOLATION"}, {"figure_path": "2410.18978/figures/figures_7_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "The figure showcases examples of frame interpolation results generated by the proposed Framer model, highlighting its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_8_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 shows example results of the Framer model performing interactive frame interpolation, demonstrating fine-grained control over local motions and the ability to handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_8_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 shows example results generated by the Framer model, highlighting its ability to customize local motions and produce smooth interpolation results even in challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_9_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "The figure showcases examples of frame interpolation results generated by the Framer model, demonstrating its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_9_1.png", "caption": "Figure 12: Ablations on each component. \"w/o trajectory\" denotes inference without guidance from point trajectory, \"w/o traj. update\" indicates inference without trajectory updates, and \"w/o bi\" suggests trajectory updating without bi-directional consistency verification.", "description": "The figure shows ablation studies on the individual components of Framer to validate their effectiveness.", "section": "4.4 ABLATIONS STUDIES"}, {"figure_path": "2410.18978/figures/figures_17_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the middle frame of 7 interpolated frames generated by different video frame interpolation methods, including the ground truth.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_18_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the proposed Framer model with other state-of-the-art video frame interpolation methods, illustrating the superior performance of Framer in generating visually appealing and temporally coherent frames.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_19_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 presents a qualitative comparison of the proposed Framer model against several state-of-the-art video interpolation methods, showcasing the middle frame of seven interpolated frames for each approach.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_20_0.png", "caption": "Figure 4: Qualitative comparison. 'GT\u2019 strands for ground truth. For each method, we only present the middle frame of 7 interpolated frames. The full results can be seen in Fig. S4 and Fig. S5 in the Appendix.", "description": "Figure 4 shows a qualitative comparison of the proposed Framer model with other state-of-the-art video frame interpolation methods on various video sequences.", "section": "4.2 Comparison"}, {"figure_path": "2410.18978/figures/figures_21_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "The figure showcases the results of the Framer model for interactive frame interpolation, demonstrating its ability to customize local motions and handle challenging cases.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_21_1.png", "caption": "Figure S10: More results on (a) cartoon and (b) sketch interpolation.", "description": "Figure S10 presents more examples of cartoon and sketch interpolation results generated using the proposed Framer method.", "section": "More Qualitative Results"}, {"figure_path": "2410.18978/figures/figures_22_0.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of interactive frame interpolation results generated by the proposed Framer model, highlighting its ability to handle various scenarios and user inputs.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_22_1.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases the results of interactive frame interpolation using Framer, demonstrating fine-grained control over local motions and the handling of challenging interpolation scenarios.", "section": "ABSTRACT"}, {"figure_path": "2410.18978/figures/figures_22_2.png", "caption": "Figure 1: Showcases produced by our Framer. It facilitates fine-grained customization of local motions and generates varying interpolation results given the same input start and end frame pair (first 3 rows). Moreover, Framer handles challenging cases and can realize smooth image morphing (last 2 rows). The input trajectories are overlayed on the frames.", "description": "Figure 1 showcases examples of frame interpolation results generated by the Framer model, highlighting its ability to customize local motions and handle challenging cases with smooth transitions.", "section": "ABSTRACT"}]