{"references": [{" publication_date": "2020", "fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is foundational to the field of large language models (LLMs), demonstrating their ability to perform well on various tasks with limited training data.  This is highly relevant to AutoKaggle, which leverages LLMs as core components in its multi-agent system for data science tasks.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ryan Holbrook", "paper_title": "Spaceship titanic", "reason": "This Kaggle competition, referenced in the paper's experiments, provided a real-world data science challenge to evaluate AutoKaggle's performance. Its inclusion is crucial for demonstrating the framework's effectiveness in realistic scenarios.", "section_number": 4}, {" publication_date": "2016", "fullname_first_author": "DataCanary", "paper_title": "House prices advanced regression techniques", "reason": "This paper describes a Kaggle competition used to evaluate AutoKaggle. Its inclusion helps demonstrate the framework's ability to solve realistic and diverse data science problems, showcasing its scalability and robustness.", "section_number": 4}, {" publication_date": "2012", "fullname_first_author": "Will", "paper_title": "Titanic - machine learning from disaster", "reason": "As one of the datasets used for testing AutoKaggle, this Kaggle competition provided a benchmark to evaluate the framework's performance on a well-known and established data science problem.  Its inclusion helps to validate the framework's capabilities.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Md Mahadi", "paper_title": "Chatgpt as your personal data scientist", "reason": "This paper explores the potential of LLMs in solving data science problems, which aligns with AutoKaggle's core functionality.  The comparison is important for showcasing AutoKaggle's advanced features and superior performance in handling complex data science tasks.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Zhiheng Xi", "paper_title": "The rise and potential of large language model based agents: A survey", "reason": "This survey paper provides a comprehensive overview of the current state-of-the-art in LLM-based agents. Its inclusion is vital as it contextualizes AutoKaggle's contribution to the field, highlighting its novel approach and unique features compared to existing methods.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jun Shern Chan", "paper_title": "Mle-bench: Evaluating machine learning agents on machine learning engineering", "reason": "This paper introduces a benchmark (MLE-Bench) for evaluating machine learning agents, which helps in understanding the context and performance of AutoKaggle. The comparison highlights AutoKaggle's strengths and limitations.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yizhou Chi", "paper_title": "Sela: Tree-search enhanced Ilm agents for automated machine learning", "reason": "This paper describes a method for improving the performance of LLM agents in automated machine learning.  The comparison to AutoKaggle is important because it highlights the different approaches to improving the performance and efficiency of LLM-based systems in the field of data science.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Siyuan Guo", "paper_title": "Ds-agent: Automated data science by empowering large language models with case-based reasoning", "reason": "This paper is highly relevant because it addresses similar challenges in automated data science. The comparison to AutoKaggle helps to distinguish the approach and performance differences between the two frameworks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xueyu Hu", "paper_title": "Infiagent-dabench: Evaluating agents on data analysis tasks", "reason": "This paper presents a benchmark for evaluating agents on data analysis tasks.  The comparison is valuable because it helps in understanding how AutoKaggle performs against other state-of-the-art systems for data analysis tasks.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Mike Lewis", "paper_title": "Deal or no deal? end-to-end learning for negotiation dialogues", "reason": "This paper explores multi-agent systems in the context of negotiation dialogues.  The inclusion is relevant because it highlights the benefits of multi-agent systems in problem-solving scenarios, aligning with AutoKaggle's collaborative multi-agent system.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Killian Lucas", "paper_title": "GitHub - KillianLucas/open-interpreter: A natural language interface for computers", "reason": "This project provides a natural language interface for computers, which is highly relevant to AutoKaggle's use of LLMs and natural language processing to automate data science tasks.  The comparison highlights the importance of efficient and user-friendly interfaces.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Aman Madaan", "paper_title": "Self-refine: Iterative refinement with self-feedback", "reason": "This paper describes a method for iteratively refining LLM outputs through self-feedback.  This is relevant to AutoKaggle's iterative debugging and testing process, highlighting the shared goal of enhancing the accuracy and reliability of LLM-generated code.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "OpenAI", "paper_title": "Chatgpt: Optimizing language models for dialogue", "reason": "This paper introduces ChatGPT, a powerful LLM that forms the basis of many LLM-based agents. This is essential because AutoKaggle's success hinges on the capabilities of its underlying LLMs.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "OpenAI", "paper_title": "Gpt-4 technical report", "reason": "This paper provides detailed information on GPT-4, a powerful LLM used in AutoKaggle's implementation.  Understanding GPT-4's capabilities is crucial for analyzing AutoKaggle's performance and potential limitations.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Noah Shinn", "paper_title": "Reflexion: Language agents with verbal reinforcement learning", "reason": "This paper explores language agents with verbal reinforcement learning, which is highly relevant to AutoKaggle's design.  The inclusion helps to highlight the unique aspects of AutoKaggle's approach and its potential advantages.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yashar Talebirad", "paper_title": "Multi-agent collaboration: Harnessing the power of intelligent Ilm agents", "reason": "This paper explores the potential of multi-agent collaboration with LLMs, aligning closely with AutoKaggle's design.  The comparison showcases AutoKaggle's specific contributions and unique characteristics.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xiangru Tang", "paper_title": "Ml-bench: Evaluating large language models and agents for machine learning tasks on repository-level code", "reason": "This paper provides another benchmark for evaluating large language models and agents for machine learning tasks.  The comparison helps to contextualize AutoKaggle's performance within the broader field of LLM-based agents for data science.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Gladys Tyen", "paper_title": "Llms cannot find reasoning errors, but can correct them given the error location", "reason": "This paper investigates the limitations of LLMs in detecting reasoning errors, which is directly relevant to AutoKaggle's iterative debugging and testing methodology.  The insights help in understanding the challenges and limitations of relying solely on LLMs for automated data science tasks.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Dominik Schmidt", "paper_title": "Introducing Weco AIDE", "reason": "This paper introduces AIDE, a baseline system used for comparison in the paper's experiments.  AIDE's inclusion is crucial for establishing a benchmark against which AutoKaggle's performance is evaluated, providing a clear demonstration of AutoKaggle's improved capabilities.", "section_number": 4}]}