{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is foundational to the Motion-Condition-Motion paradigm proposed, drawing inspiration from the next-token prediction paradigm that revolutionized NLP."}, {"fullname_first_author": "Nikos Athanasiou", "paper_title": "MotionFix: Text-Driven 3D Human Motion Editing", "publication_date": "2024-08-00", "reason": "This paper is highly relevant as it introduces text-based motion editing, a task that MotionLab aims to unify and improve upon."}, {"fullname_first_author": "Wenxun Dai", "paper_title": "MotionLCM: Real-time controllable motion generation via latent consistency model", "publication_date": "2025-00-00", "reason": "This paper is a key comparative model, representing state-of-the-art in trajectory-based motion generation, which MotionLab aims to enhance."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-00-00", "reason": "This paper's advancements in diffusion models are foundational to the methods used in MotionLab for motion generation and editing."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "This work is highly relevant as MotionLab builds upon rectified flows, a key component of its MotionFlow Transformer."}]}