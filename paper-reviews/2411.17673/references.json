{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2024-12-31", "reason": "This paper introduces Flamingo, a visual language model that is leveraged by SketchAgent for its sequential nature and rich prior knowledge."}, {"fullname_first_author": "Anthropic", "paper_title": "Claude", "publication_date": "2023-12-31", "reason": "SketchAgent uses Claude, a multimodal LLM from Anthropic, as its backbone model for sketch generation."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-12-31", "reason": "CLIP, a vision-language model introduced in this paper, is used in SketchAgent for qualitative and quantitative evaluations of sketch generation."}, {"fullname_first_author": "David Ha", "paper_title": "A neural representation of sketch drawings", "publication_date": "2017-12-31", "reason": "This paper introduces SketchRNN, a pioneering work in sequential sketch generation that serves as a baseline for SketchAgent's performance."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-12-31", "reason": "SketchAgent's approach is compared to methods using pretrained text-to-image diffusion models, such as those introduced in this paper."}]}