{"references": [{" publication_date": "2022", "fullname_first_author": "Kevin Meng", "paper_title": "Locating and editing factual associations in GPT", "reason": "This paper is foundational for the field of model editing, introducing a novel method (ROME) and providing a comprehensive framework for evaluating editing methods along the crucial dimensions of reliability, generalization, and locality.  Its impact on subsequent work is substantial, forming a basis for much of the current research on this topic.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Eric Mitchell", "paper_title": "Memory-based model editing at scale", "reason": "This paper significantly advances model editing by introducing the concept of memory-based editing and scaling it to a much larger scale than previously possible, pushing the boundaries of efficient knowledge update in LLMs. It provides a robust methodology that has been influential in subsequent research.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Eric Mitchell", "paper_title": "Fast model editing at scale", "reason": "This work is a significant early contribution to the field of model editing. It presents a novel method with high efficiency and precision for updating facts in large language models. This was groundbreaking and is cited frequently in the subsequent literature.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "Llama 2 is a significant improvement over previous LLMs, particularly in terms of size and quality, thereby offering a powerful tool for model editing experiments.  The availability of the model and its documentation contributes substantially to the reproducibility and advancement of research in this area.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "reason": "The release of the Llama language model provided a powerful and accessible open-source foundation for many subsequent research efforts in the field, including research on model editing.  Its influence on the reproducibility and broad adoption of this research is significant.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Kevin Meng", "paper_title": "Mass-editing memory in a transformer", "reason": "This paper directly addresses the scalability of model editing, a critical issue that limits the practical application of many existing methods.  It introduces novel techniques that make large-scale edits feasible, paving the way for more substantial knowledge updates in LLMs.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Longteng Zhang", "paper_title": "Dissecting the runtime performance of the training, fine-tuning, and inference of large language models", "reason": "This paper provides crucial insights into the computational challenges associated with training, fine-tuning, and inference of LLMs, directly impacting the design and implementation of efficient model editing methods. This informs the understanding of resource constraints often cited as limitations in fine-tuning-based approaches.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Zhenheng Tang", "paper_title": "FusionAI: Decentralized training and deploying LLMs with massive consumer-level GPUs", "reason": "This paper proposes a scalable and cost-effective training framework for LLMs, which is highly relevant to model editing.  Model editing often requires extensive computational resources, and this framework provides a potential solution to reduce these requirements, making large-scale editing more practical.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Song Wang", "paper_title": "Knowledge editing for large language models: A survey", "reason": "This survey paper provides a broad overview of model editing techniques, their strengths and weaknesses.  The paper covers the scope of the existing work, and identifies open research questions that helps contextualize the current study's contributions and direction.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Vittorio Mazzia", "paper_title": "A survey on knowledge editing of neural networks", "reason": "This survey offers a broader context for the research by situating model editing within the larger field of neural network knowledge editing. It helps to establish the significance of model editing in LLMs, relative to other applications of similar techniques.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Ningyu Zhang", "paper_title": "A comprehensive study of knowledge editing for large language models", "reason": "This work provides a broad and thorough analysis of various model editing methods, offering a comparative perspective and identifying commonalities and differences in their efficacy, helping to place this research in the broader context of existing model editing literature.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yunzhi Yao", "paper_title": "Editing large language models: Problems, methods, and opportunities", "reason": "This paper offers a comprehensive overview of the challenges and opportunities in model editing, thereby clarifying and framing the current state of the art in this domain. This helps contextualize the contributions and limitations of the present work.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Roi Cohen", "paper_title": "Evaluating the ripple effects of knowledge editing in language models", "reason": "This paper is crucial in highlighting the broader implications and potential negative side effects of model editing. It emphasizes the cascading effects of edits, which can impact not only the target knowledge but also other aspects of the model's performance.  This helps underscore the importance of the comprehensive evaluation performed in the current research.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Zexuan Zhong", "paper_title": "MQUAKE: Assessing knowledge editing in language models via multi-hop questions", "reason": "This paper focuses on evaluating the efficacy of model editing on multi-hop reasoning tasks. While the current research focuses on the broad impact, this paper helps to frame the discussion around specific reasoning capabilities, providing a critical comparative evaluation point.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Zhoubo Li", "paper_title": "Unveiling the pitfalls of knowledge editing for large language models", "reason": "This work is highly relevant to the current research due to its identification of crucial pitfalls in existing model editing methods, such as knowledge distortion and conflict. It provides a clear understanding of the inherent challenges in model editing, directly impacting the evaluation design and interpretation of results presented in this study.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Qi Li", "paper_title": "Can we continually edit language models? On the knowledge attenuation in sequential model editing", "reason": "This paper directly addresses the topic of continual editing, highlighting a crucial concern related to the stability and performance degradation when many sequential edits are performed.  It helps the current research by directly relating it to the limitations of sequential model editing, and forms a critical discussion point.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "reason": "MMLU is a widely used and respected benchmark for evaluating the overall capabilities of LLMs, thus its use is crucial for providing a standardized and widely recognized method for performance comparisons in the current study.  The comprehensive nature of the benchmark ensures that a diverse range of abilities is examined in the context of model editing.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Stella Biderman", "paper_title": "Pythia: A suite for analyzing large language models across training and scaling", "reason": "The Pythia model family provides a set of models with varying parameter sizes, enabling a systematic investigation of the impact of model scale on editing outcomes.  This is crucial to understanding the generalizability of findings across various model architectures and scales.", "section_number": 3}, {" publication_date": "2017", "fullname_first_author": "Omer Levy", "paper_title": "Zero-shot relation extraction via reading comprehension", "reason": "This dataset is highly influential in evaluating the ability of LLMs to handle tasks involving relational knowledge and reasoning; its use in conjunction with other benchmarks allows for a robust and multifaceted evaluation of the edited language models, going beyond simple factual recall.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Alon Talmor", "paper_title": "CommonsenseQA: A question answering challenge targeting commonsense knowledge", "reason": "CommonsenseQA is a widely used benchmark for evaluating common-sense reasoning capabilities in LLMs. Including this benchmark in the study's evaluation framework ensures a thorough assessment of the impact of model editing on a variety of cognitive abilities, not just factual knowledge recall.", "section_number": 3}]}