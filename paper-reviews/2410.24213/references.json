{"references": [{"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces VideoMAE, a masked autoencoder model that is used as the primary model for pre-training in the research."}, {"fullname_first_author": "Zhan Tong", "paper_title": "VideoMAE: Masked autoencoders are data-efficient learners for self-supervised video pre-training", "publication_date": "2022-00-00", "reason": "This paper introduces VideoMAE, which is the foundation of the self-supervised learning approach used in this research."}, {"fullname_first_author": "Manel Baradad", "paper_title": "Learning to see by looking at noise", "publication_date": "2021-00-00", "reason": "This paper explores the use of synthetic images for pre-training image models, providing a basis for the approach used in this work for video."}, {"fullname_first_author": "Manel Baradad", "paper_title": "Procedural image programs for representation learning", "publication_date": "2022-00-00", "reason": "This paper expands on the previous work by exploring more advanced synthetic image generation methods, which are relevant to the video synthesis approach in this paper."}, {"fullname_first_author": "Karen Simonyan", "paper_title": "Two-stream convolutional networks for action recognition in videos", "publication_date": "2014-00-00", "reason": "This paper is a foundational work in video action recognition, providing a baseline for comparison with the methods developed in this research."}]}