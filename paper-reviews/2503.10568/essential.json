{"importance": "This paper introduces a **novel AR framework for image generation**, offering a pathway to improve model efficiency and quality while simultaneously reducing memory consumption. This research aligns with the **growing interest in efficient and scalable autoregressive models**.", "summary": "ARPG: Randomly generate high-quality images by parallel decoding, outperforming existing methods in efficiency, memory, and quality.", "takeaways": ["ARPG enables parallel image generation with random token order using decoupled positional guidance.", "The method achieves state-of-the-art results in controllable image generation conditioned on edges and depth maps.", "ARPG sets a new benchmark for high-performance and high-efficiency autoregressive image generation."], "tldr": "Autoregressive (AR) models have excelled, especially in language modeling. However, applying next-token prediction to image generation presents challenges since images are structured in a 2D space. Standard AR models struggle with tasks like inpainting and outpainting because generation follows a specific token order, especially in high-resolution. Furthermore, using bidirectional attention, as in MaskGIT, prevents the use of the KV cache, increasing overhead. Thus, there is a need for a framework to support flexible generation orders and maintain efficiency.\n\nThis paper introduces a visual Autoregressive model, **ARPG, enabling Randomized Parallel Generation**. It uses a novel 'guided decoding' that decouples positional guidance from content representation. This enables random-order training and generation without needing bidirectional attention. **ARPG supports parallel inference** by concurrently processing multiple queries using a shared KV cache. It achieves state-of-the-art results in image generation, improving throughput and reducing memory usage compared to existing autoregressive models.", "affiliation": "Westlake University", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.10568/podcast.wav"}