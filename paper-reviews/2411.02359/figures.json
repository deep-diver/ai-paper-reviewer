[{"figure_path": "https://arxiv.org/html/2411.02359/x1.png", "caption": "Figure 1: \nLeft: Dynamic inference of DeeR. For inference, we adaptively activate an appropriate size of MLLM based on an exit criterion c\ud835\udc50citalic_c, which accounts for the current situation (including task instruction l\ud835\udc59litalic_l and observation otsubscript\ud835\udc5c\ud835\udc61o_{t}italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) and predefined computational and GPU memory budgets.\nThe language instruction and gripper camera image, not shown in this figure, are also inputs to the MLLM.\nAn action is then obtained using the intermediate feature x~tc\u2062(t)subscriptsuperscript~\ud835\udc65\ud835\udc50\ud835\udc61\ud835\udc61\\tilde{x}^{c(t)}_{t}over~ start_ARG italic_x end_ARG start_POSTSUPERSCRIPT italic_c ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and historical information.\nRight: Training of DeeR.We randomly sample features from all exits during training. This strategy helps minimize the discrepancy between training and dynamic inference. Moreover, we employ several auxiliary action heads (AuxH) to better optimize the MLLM.", "description": "This figure illustrates the dynamic inference and training process of the DeeR model. The left panel shows how DeeR dynamically adjusts the size of the activated MLLM based on the current situation (task instruction and observation) and resource constraints.  The right panel details the training process, which employs a random sampling strategy to minimize the discrepancy between training and inference and uses multiple auxiliary action heads to optimize the MLLM.", "section": "Dynamic Early-Exit for Robotic MLLM"}, {"figure_path": "https://arxiv.org/html/2411.02359/x2.png", "caption": "Figure 2: Multi-exit MLLM architecture for robot.", "description": "This figure illustrates the multi-exit architecture of the Multimodal Large Language Model (MLLM) used in DeeR for robot control.  It shows how the model is designed with multiple intermediate exits, allowing the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation. The diagram details the components including a vision encoder (processing visual observations), a language input module, multiple layers of the MLLM with intermediate outputs at multiple exits, and an action prediction head that takes the output from an appropriate exit point to generate robotic actions.", "section": "3.1 Multi-exit Architecture for Robot"}, {"figure_path": "https://arxiv.org/html/2411.02359/x5.png", "caption": "Figure 3: \nResults atop OpenFlamingo 3B.\nUpper: Avg. successful len v.s. avg. LLM GFLOPs. Bottom: Peak GLOPs and GPU memory for LLM.\nDifferent colors indicate different peak FLOPs and GPU memory budgets, denoted as DeeR-S and DeeR-B (they share a fixed model).\nDeeR preserve all the architecture and hyperparameters from RoboFlamingo++ for fair comparisons, except for our dynamic early-exit paradigm.", "description": "Figure 3 presents the results of experiments using the OpenFlamingo 3B model. The upper part shows a comparison of the average successful task completion length against the average LLM GFLOPs (floating point operations per second) consumed. The lower part shows the peak GFLOPs and GPU memory usage during inference.  Two versions of the DeeR model (DeeR-S and DeeR-B) are compared, which differ in their resource constraints; however, they both use the same underlying model architecture.  For fair comparison, DeeR retains the architecture and hyperparameters of RoboFlamingo++, except for the dynamic early-exit mechanism.", "section": "4.1 Main Results"}, {"figure_path": "https://arxiv.org/html/2411.02359/x6.png", "caption": "Figure 4: \nResults on the top of OpenFlamingo 9B.\nLeft: Avg. successful len v.s. average LLM GFLOPs. Right: Maxinum GLOPs and GPU memory budget for DeeR-S and DeeR-B.\nThe activated LLM in DeeR-S and DeeR-B consumes 12GB memory, whereas RoboFlamingo 9B requires 32GB.", "description": "Figure 4 presents a comparison of the performance and resource usage of DeeR and RoboFlamingo++ using the OpenFlamingo 9B model.  The left panel shows that DeeR achieves a similar average task success length as RoboFlamingo++ while using significantly fewer average LLM GFLOPs. The right panel highlights the memory efficiency of DeeR.  Both DeeR-S and DeeR-B configurations operate with a maximum of 12 GB of GPU memory for the activated LLM, a substantial reduction compared to the 32 GB required by RoboFlamingo++ 9B.", "section": "4.2 Ablation Study"}, {"figure_path": "https://arxiv.org/html/2411.02359/x7.png", "caption": "Figure 5: Visualization of DeeR rollouts in the CALVIN environment. Please zoom in to view details. The numbers indicate the termination exit index. Situations with a lower exit index are recognized as \u2018easier\u2019 ones.", "description": "This figure visualizes the dynamic inference process of DeeR across various tasks in the CALVIN environment. Each row represents a distinct task, showing a sequence of images from the robot's camera. The numbers overlaid on the images indicate the termination exit index chosen by DeeR, signifying the model size dynamically selected based on task complexity. A lower exit index signifies a simpler situation requiring a smaller model, while a higher index denotes a more challenging situation demanding a larger model. This illustrates DeeR's adaptive inference capability, adapting computational resources according to the situation's complexity.", "section": "3 Dynamic Early-Exit for Robotic MLLM"}]