[{"content": "|---|---|---|---|\n| ![x1](https://arxiv.org/html/2410.23825/x1.png) | **Corpus** | `v. 1.0` | [hf.co/datasets/cis-lmu/GlotCC-v1](https://huggingface.co/datasets/cis-lmu/GlotCC-v1) |\n| ![x2](https://arxiv.org/html/2410.23825/x2.png) | **Pipeline** | `v. 3.0` | [github.com/cisnlp/GlotCC](https://github.com/cisnlp/GlotCC) |", "caption": "Table 1: GlotLID v3.0 training hyperparameters", "description": "This table lists the hyperparameters used during the training of the GlotLID v3.0 language identification model.  It details the settings for various parameters that influence the model's training process, including the minimum number of word and label occurrences required, the range of character n-grams considered, the loss function employed, the dimensionality of word embeddings, and the learning rate used.  Understanding these hyperparameters is crucial for reproducibility and for comprehending the model's behavior and performance.", "section": "2 GlotLID"}, {"content": "| Argument | Description | Value |\n|---|---|---|\n| -minCount | Minimal number of word occurrences | 1000 |\n| -minCountLabel | Minimal number of label occurrences | 0 |\n| -wordNgrams | Max length of word ngram | 1 |\n| -bucket | Number of buckets | 10<sup>6</sup> |\n| -minn | Min length of char ngram | 2 |\n| -maxn | Max length of char ngram | 5 |\n| -loss | Loss function | softmax |\n| -dim | Size of word vectors | 256 |\n| -epoch | Number of epochs | 1 |\n| -lr | Learning rate | .8 |", "caption": "Table 2: Performance of GlotLID v3.0", "description": "This table presents the performance of the GlotLID v3.0 language identification model on three benchmark datasets: GlotTest, UDHR, and FLORES-200.  For each dataset, it shows the number of labels used, the F1 score (a measure of accuracy), and the false positive rate (FPR, the rate of incorrectly identifying a language). The F1 score and FPR are important metrics for evaluating the performance of language identification models, indicating the balance between correctly identifying languages and avoiding false positives.  A high F1 score and a low FPR are desirable.", "section": "2.2 Evaluation results"}, {"content": "| Benchmark | # Labels | F1 \u2191 | FPR \u2193 |\n|---|---|---|---| \n| GlotTest | 2102 | 0.991 | 0.000003 |\n| UDHR | 371 | 0.882 | 0.000298 |\n| FLORES-200 | 199 | 0.967 | 0.000161 |", "caption": "Table 3: Geographic distribution of languages in GlotCC.", "description": "This table shows the geographic distribution of the 1275 languages included in the GlotCC corpus.  It breaks down the number of languages represented by Glottolog macroarea (e.g., Eurasia, Papunesia, Africa, etc.). This provides a geographical overview of the linguistic diversity covered within the corpus.", "section": "3 GlotCC v1.0"}, {"content": "| Macroarea | # Labels |\n|---|---| \n| Eurasia | 395 |\n| Papunesia | 380 |\n| Africa | 252 |\n| North America | 123 |\n| South America | 97 |\n| Australia | 16 |\n| Constructed | 12 |", "caption": "Table 4:  Partition statistics for\nOSCAR 23.01 and GlotCC-v1.0.\nEach partition is defined as:\n10J># documents per language\u226510Isuperscript10\ud835\udc3d# documents per languagesuperscript10\ud835\udc3c10^{J}>\\text{\\# documents per language}\\geq 10^{I}10 start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT > # documents per language \u2265 10 start_POSTSUPERSCRIPT italic_I end_POSTSUPERSCRIPT\nwhere\n0\u2264I\u226470\ud835\udc3c70\\leq I\\leq 70 \u2264 italic_I \u2264 7,\n1\u2264J\u226491\ud835\udc3d91\\leq J\\leq 91 \u2264 italic_J \u2264 9.", "description": "Table 4 presents a comparative analysis of the language distribution within the OSCAR 23.01 and GlotCC v1.0 corpora.  It categorizes languages based on the number of documents associated with each language, grouping languages into partitions where the number of documents falls within a specific range (10<sup>I</sup> to 10<sup>J</sup>, where I and J represent integers from 0 to 7 and 1 to 9 respectively). This allows for a visualization of how many languages have a small number of documents versus a large number of documents and helps to highlight differences in corpus coverage between OSCAR and GlotCC. The table shows the total number of languages, lines, words, and religious and Wikipedia document counts for each partition across both datasets.", "section": "3 GlotCC v1.0"}, {"content": "| {I, J} | Corpus Version | # Languages | # Documents (Total) | # Documents (Median) | # Lines (Total) | # Lines (Median) | # Words (Total) | # Words (Median) | # Religious (Total pct.) | # Wikipedia (Total pct.) | \n|---|---|---|---|---|---|---|---|---|---|---|---|\n| {7, 9} | OSCAR 23.01 | 24 | 2.7B | 34.4M | - | - | 1.0T | 12.6B | - | - |\n| {7, 9} | GlotCC-v1.0 | 12 | 579.5M | 22.7M | 15.1B | 780.8M | 436.4B | 17.0B | 0.0001 | 0.0009 |\n| {6, 7} | OSCAR 23.01 | 23 | 80.0M | 2.4M | - | - | 27.6B | 738.8M | - | - |\n| {6, 7} | GlotCC-v1.0 | 22 | 92.2M | 3.8M | 3.0B | 122.1M | 67.8B | 2.4B | 0.0001 | 0.0044 |\n| {5, 6} | OSCAR 23.01 | 25 | 9.3M | 262.7K | - | - | 3.2B | 82.4M | - | - |\n| {5, 6} | GlotCC-v1.0 | 29 | 10.7M | 334.8K | 305.4M | 9.1M | 6.9B | 195.7M | 0.0001 | 0.0219 |\n| {4, 5} | OSCAR 23.01 | 26 | 919.7K | 25.2K | - | - | 212.0M | 5.4M | - | - |\n| {4, 5} | GlotCC-v1.0 | 52 | 1.9M | 29.6K | 55.1M | 714.4K | 1.3B | 17.9M | 0.0005 | 0.0922 |\n| {3, 4} | OSCAR 23.01 | 14 | 60.1K | 3.6K | - | - | 10.1M | 315.7K | - | - |\n| {3, 4} | GlotCC-v1.0 | 89 | 338.7K | 2.7K | 8.2M | 52.2K | 223.9M | 1.4M | 0.0029 | 0.2658 |\n| {2, 3} | OSCAR 23.01 | 20 | 8.6K | 400 | - | - | 772.3K | 13.4K | - | - |\n| {2, 3} | GlotCC-v1.0 | 145 | 53.9K | 326 | 1.4M | 6.5K | 39.3M | 192.6K | 0.0606 | 0.2940 |\n| {1, 2} | OSCAR 23.01 | 10 | 368 | 36 | - | - | 13.6K | 431 | - | - |\n| {1, 2} | GlotCC-v1.0 | 360 | 11.5K | 24 | 245.0K | 460 | 11.3M | 20.5K | 0.4441 | 0.1044 |\n| {0, 1} | OSCAR 23.01 | 10 | 44 | 4 | - | - | 21.5K | 67 | - | - |\n| {0, 1} | GlotCC-v1.0 | 566 | 1.7K | 2 | 41.5K | 26 | 1.7M | 1.2K | 0.4285 | 0.0285 |\n| {0, 9} | OSCAR 23.01 | 152 | 2.8B | 69.7K | - | - | 1.1T | 14.5M | - | - |\n| {0, 9} | GlotCC-v1.0 | 1275 | 684.7M | 14 | 18.5B | 254 | 512.6B | 11.6K | 0.000001 | 0.00000007 |", "caption": "Table 5: Comparison of GlotLID and NLLB on a random\nsubset of 20 pages from minority languages", "description": "This table compares the performance of the GlotLID and NLLB language identification models on a random sample of 20 pages containing minority languages.  It shows the number of times each model correctly identified the language, made an incorrect classification, or failed to make a prediction (labeled as 'miss'). This comparison highlights the relative strengths and weaknesses of each model in handling minority languages, providing insights into their accuracy and the frequency of prediction failures.", "section": "Evaluation results"}]