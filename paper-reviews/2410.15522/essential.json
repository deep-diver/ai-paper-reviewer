{"importance": "This paper is crucial for researchers working on reward models and large language models (LLMs), especially those focused on multilingual applications.  It introduces a new benchmark, M-REWARDBENCH, filling a critical gap in multilingual RM evaluation. The findings challenge assumptions about RM performance across languages and highlight the need for improved methods. This opens avenues for developing more robust and equitable multilingual LLMs.", "summary": "M-REWARDBENCH: A new multilingual benchmark reveals significant performance gaps in reward models across languages, highlighting the need for improved multilingual LLM development.", "takeaways": ["M-REWARDBENCH, a new multilingual benchmark for reward models (RMs) is introduced, evaluating RMs across 23 languages and 6 tasks.", "Significant performance differences exist between English and non-English languages in RMs, with translation quality positively impacting performance.", "Generative RMs demonstrate more robustness and better performance in multilingual settings compared to classifier and implicit RMs."], "tldr": "This research tackles the under-studied area of multilingual reward model (RM) performance in large language models (LLMs).  The core contribution is the creation of M-REWARDBENCH, a comprehensive benchmark dataset containing 2870 preference instances across 23 diverse languages. This dataset tests RMs on chat, safety, reasoning, and translation tasks.  The study rigorously evaluates a wide range of RMs on this benchmark, revealing a considerable performance gap between English and non-English languages.  The results highlight that the quality of the translations used significantly impacts the RM's performance.  Models generally performed better on high-resource languages.  The paper concludes by releasing the M-REWARDBENCH dataset and codebase to foster future research in multilingual RM evaluation and LLM development. This is vital for creating more inclusive and equitable LLMs that can effectively serve a diverse global population."}