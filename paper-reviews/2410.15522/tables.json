[{"figure_path": "2410.15522/tables/table_2_0.html", "caption": "Table 1: Dataset statistics for M-REWARDBENCH. Number of languages excludes English. For Translation, the languages are Chinese (zh) and German (de).", "description": "Table 1 presents the dataset statistics for the M-REWARDBENCH benchmark, showing the number of instances and languages for each task category.", "section": "3 M-REWARDBENCH: A Multilingual Benchmark for Evaluating RMs"}, {"figure_path": "2410.15522/tables/table_3_0.html", "caption": "Table 2: Top ten reward models on M-REWARDBENCH. We evaluate several reward model types: Classifier RMs (), Generative RMs (), and Implicit RMs trained using DPO (). Full results can be found in Table 9.", "description": "Table 2 presents the top ten performing reward models on the M-REWARDBENCH benchmark, categorized by model type and showing average performance across 23 languages.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_4_0.html", "caption": "Table 3: Performance drop from RewardBench (English) to M-REWARDBENCH across all categories for the top ten models in M-REWARDBENCH. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 3 shows the performance drop of the top ten reward models from the English-centric RewardBench to the multilingual M-REWARDBENCH across Chat, Chat-Hard, Safety, and Reasoning categories.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_6_0.html", "caption": "Table 4: Top ten reward models based on their performance in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 4 shows the performance of the top ten reward models on the translation task, categorized into EASY and HARD subsets, with different model types indicated.", "section": "5.2 Translation Task"}, {"figure_path": "2410.15522/tables/table_13_0.html", "caption": "Table 5: State-of-the-art models evaluated for M-REWARDBENCH.", "description": "Table 5 lists the proprietary and open-source reward models that were evaluated in the M-REWARDBENCH benchmark, including their providers, sizes, and references.", "section": "4 Experiment Details"}, {"figure_path": "2410.15522/tables/table_13_1.html", "caption": "Table 6: The 23 languages in M-REWARDBENCH and their linguistic information. Script, language family, and resource availability are based on Aryabumi et al. (2024). Resource classes are from Joshi et al. (2020).", "description": "Table 6 provides linguistic details for the 23 languages included in the M-REWARDBENCH benchmark, including script, family, resource availability, and resource class.", "section": "6.2 Language-specific analysis of RM performances"}, {"figure_path": "2410.15522/tables/table_15_0.html", "caption": "Table 8: Examples where a reward model (RM) disagrees with a native human speaker.", "description": "This table shows examples where reward model preferences disagree with those of native human speakers for Indonesian.", "section": "5. Results"}, {"figure_path": "2410.15522/tables/table_16_0.html", "caption": "Table 10: Performance of all reward models in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 10 presents the performance of various reward models on the translation task, categorized into easy and hard subsets, showing average scores and scores for different translation directions.", "section": "5.2 Translation Task"}]