[{"figure_path": "2410.15522/tables/table_2_0.html", "caption": "Table 1: Dataset statistics for M-REWARDBENCH. Number of languages excludes English. For Translation, the languages are Chinese (zh) and German (de).", "description": "Table 1 presents the dataset statistics for M-REWARDBENCH, showing the number of instances and languages for each task category.", "section": "3 M-REWARDBENCH: A Multilingual Benchmark for Evaluating RMs"}, {"figure_path": "2410.15522/tables/table_4_0.html", "caption": "Table 3: Performance drop from RewardBench (English) to M-REWARDBENCH across all categories for the top ten models in M-REWARDBENCH. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 3 shows the performance drop of the top ten reward models from English-centric RewardBench to the multilingual M-REWARDBENCH across different categories.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_6_0.html", "caption": "Table 4: Top ten reward models based on their performance in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 4 presents the top ten reward models' performance on the translation task, categorized into easy and hard subsets, with model types indicated.", "section": "5.2 Translation Task"}, {"figure_path": "2410.15522/tables/table_13_0.html", "caption": "Table 5: State-of-the-art models evaluated for M-REWARDBENCH.", "description": "Table 5 lists the proprietary and open-source reward models that were evaluated in the M-REWARDBENCH benchmark, including their provider, size, and reference.", "section": "4 Experiment Details"}, {"figure_path": "2410.15522/tables/table_13_1.html", "caption": "Table 6: The 23 languages in M-REWARDBENCH and their linguistic information. Script, language family, and resource availability are based on Aryabumi et al. (2024). Resource classes are from Joshi et al. (2020).", "description": "Table 6 presents linguistic features of the 23 languages included in the M-REWARDBENCH benchmark, including script, family, resource availability, and resource class.", "section": "6.2 Language-specific analysis of RM performances"}, {"figure_path": "2410.15522/tables/table_14_0.html", "caption": "Table 2: Top ten reward models on M-REWARDBENCH. We evaluate several reward model types: Classifier RMs (), Generative RMs (), and Implicit RMs trained using DPO (). Full results can be found in Table 9.", "description": "Table 2 presents the top ten performing reward models on the M-REWARDBENCH benchmark, categorized by model type and showing average performance across 23 languages.", "section": "5 Results"}, {"figure_path": "2410.15522/tables/table_15_0.html", "caption": "Table 8: Examples where a reward model (RM) disagrees with a native human speaker.", "description": "Table 8 shows examples where reward model preferences differ from those of native human speakers for Indonesian.", "section": "5. Results"}, {"figure_path": "2410.15522/tables/table_16_0.html", "caption": "Table 10: Performance of all reward models in the translation task. We source the translation evaluation set from MAPLE (Zhu et al., 2024), where we created EASY and HARD subsets. Icons represent different model types: Classifier-based RMs (), Generative RMs (), and Implicit RMs trained using DPO ().", "description": "Table 10 presents the performance of various reward models on the translation task, categorized by model type and difficulty level (easy/hard), across different language pairs.", "section": "5.2 Translation Task"}]