{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduced the Transformer model, which is the foundational architecture for WHISPER-GPT and many other large language models."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-05-28", "reason": "This work highlighted the few-shot learning capabilities of large language models, demonstrating their potential for various tasks with limited data."}, {"fullname_first_author": "Aaron van den Oord", "paper_title": "Neural Discrete Representation Learning", "publication_date": "2017-11-06", "reason": "This paper introduced Vector Quantized Variational Autoencoders (VQ-VAE), a key technique for learning discrete representations from continuous data, crucial for handling audio in WHISPER-GPT."}, {"fullname_first_author": "Alec Radford", "paper_title": "Robust Speech Recognition via Large-Scale Weak Supervision", "publication_date": "2023-01-01", "reason": "This paper introduced Whisper, a sequence-to-sequence model for automatic speech recognition that serves as a key inspiration for the hybrid architecture of WHISPER-GPT."}, {"fullname_first_author": "Chengyi Wang", "paper_title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers", "publication_date": "2023-01-06", "reason": "This paper presents VALL-E, a neural codec language model for text-to-speech synthesis, which directly influenced the design and evaluation of WHISPER-GPT, particularly its use of discrete acoustic tokens and focus on coarse token prediction."}]}