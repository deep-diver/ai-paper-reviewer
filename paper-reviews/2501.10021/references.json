{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces Stable Video Diffusion, a key foundation for the proposed X-Dyna model, providing significant advancements in latent video diffusion models and scaling them to larger datasets, improving upon the state-of-the-art in human video animation."}, {"fullname_first_author": "Di Chang", "paper_title": "MagicPose: Realistic human poses and facial expressions retargeting with identity-aware diffusion", "publication_date": "2023-00-00", "reason": "This paper introduces MagicPose, a state-of-the-art method in human pose and expression retargeting that directly informs and is compared against X-Dyna in the paper."}, {"fullname_first_author": "Li Hu", "paper_title": "Animate anyone: Consistent and controllable image-to-video synthesis for character animation", "publication_date": "2024-00-00", "reason": "Animate Anyone is a highly relevant prior work that X-Dyna builds upon, offering a direct comparison and highlighting areas of improvement by the proposed method."}, {"fullname_first_author": "Michael Dorkenwald", "paper_title": "Stochastic image-to-video synthesis using cinns", "publication_date": "2021-00-00", "reason": "This paper presents a significant prior work in stochastic image-to-video synthesis that is directly relevant to the X-Dyna model, providing insights into related methods and technologies."}, {"fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2023-07-04", "reason": "This paper introduces AnimateDiff, a crucial component in temporal module design for video generation, forming a foundational element upon which X-Dyna builds, offering improvements in dynamic detail and motion consistency."}]}