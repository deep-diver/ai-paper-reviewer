{"references": [{"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2022-09-14", "reason": "This paper is foundational to the current work, introducing a novel method for text-to-3D generation using 2D diffusion models, which is directly built upon in this paper."}, {"fullname_first_author": "Zhengyi Wang", "paper_title": "Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation", "publication_date": "2023-05-16", "reason": "This paper proposes a method that addresses limitations of previous approaches by incorporating variational score distillation for higher fidelity and diversity in generated 3D content."}, {"fullname_first_author": "Yichun Shi", "paper_title": "Mvdream: Multi-view diffusion for 3d generation", "publication_date": "2023-08-16", "reason": "This paper introduces a multi-view diffusion approach for improved 3D generation, which is compared against in this work, highlighting the advancements in multi-view techniques."}, {"fullname_first_author": "Junliang Ye", "paper_title": "Dreamreward: Text-to-3d generation with human preference", "publication_date": "2025-01-01", "reason": "This paper directly addresses human preference integration into the 3D generation process, which is a core aspect of the proposed method and provides an important comparison point."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces a technique for high-resolution image synthesis that is leveraged in the current work's text-to-image component, showcasing the importance of high-resolution generation for improved results."}]}