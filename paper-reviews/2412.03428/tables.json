[{"content": "| Method | Acc. \u2193 | Comp. \u2193 | Prec. \u2191 | Recall \u2191 | F-score \u2191 | Acc. \u2193 | Comp. \u2193 | Prec. \u2191 | Recall \u2191 | F-score \u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|\n| NeuS [4] | 0.105 | 0.124 | 0.448 | 0.378 | 0.409 | 0.160 | 0.224 | 0.294 | 0.221 | 0.251 |\n| Neuralangelo [34] | 0.185 | 0.223 | 0.252 | 0.260 | 0.255 | 0.363 | 0.264 | 0.172 | 0.120 | 0.141 |\n| 3DGS [9] | 0.338 | 0.406 | 0.129 | 0.067 | 0.085 | 0.144 | 0.990 | 0.322 | 0.066 | 0.104 |\n| SuGaR [51] | 0.167 | 0.148 | 0.361 | 0.373 | 0.366 | 0.158 | 0.178 | 0.383 | 0.349 | 0.361 |\n| 2DGS [10] | 0.157 | 0.151 | 0.336 | 0.347 | 0.341 | 0.359 | 0.228 | 0.230 | 0.160 | 0.183 |\n| PGSR [52] | 0.125 | 0.117 | 0.420 | 0.433 | 0.426 | 0.204 | 0.202 | 0.353 | 0.217 | 0.249 |\n| RaDe-GS [53] | 0.167 | 0.205 | 0.309 | 0.307 | 0.306 | 0.284 | 0.252 | 0.171 | 0.179 | 0.166 |\n| **2DGS-Room (Ours)** | 0.055 | 0.092 | 0.648 | 0.518 | 0.575 | 0.262 | 0.112 | 0.450 | 0.498 | 0.464 |", "caption": "Table 1: Quantitative reconstruction comparison on ScanNet and ScanNet++ dataset. Averaged results are reported over 8 scenes and 4 scenes, respectively. 2DGS-Room achieves the best F-score.", "description": "This table presents a quantitative comparison of the proposed 2DGS-Room method against several state-of-the-art techniques for 3D indoor scene reconstruction.  The comparison uses five standard metrics: Accuracy, Completion, Precision, Recall, and F-score.  These metrics assess the geometric accuracy and completeness of the reconstructed 3D models. Results are averaged across eight scenes from the ScanNet dataset and four scenes from the ScanNet++ dataset.  The table highlights that 2DGS-Room achieves the best F-score among all compared methods, indicating superior performance in balancing precision and recall in the 3D reconstruction task.  The metrics provide a comprehensive evaluation of the reconstruction quality, considering both geometric accuracy and completeness.", "section": "5. Results"}, {"content": "| Method | Acc.\u2193 | Comp.\u2193 | Prec.\u2191 | Recall\u2191 | F-score\u2191 |\n|---|---|---|---|---|---| \n| w/o Seed | 0.128 | 0.152 | 0.336 | 0.284 | 0.307 |\n| w/o Depth | 0.084 | 0.139 | 0.510 | 0.386 | 0.438 |\n| w/o Normal | 0.066 | 0.102 | 0.596 | 0.463 | 0.520 |\n| w/o MV | 0.055 | 0.092 | 0.644 | 0.508 | 0.566 |\n| Full model | **0.055** | **0.092** | **0.648** | **0.518** | **0.575** |", "caption": "Table 2: Results of the ablation study on ScanNet dataset. The best results are marked in bold.", "description": "This table presents the results of an ablation study conducted on the ScanNet dataset to evaluate the individual contributions of different components in the proposed 2DGS-Room model.  It shows the performance metrics (Accuracy, Completion, Precision, Recall, and F-score) achieved by the full model and variations of the model where specific components (seed points, depth supervision, normal supervision, and multi-view consistency constraints) were removed.  The best performing model variation for each metric is highlighted in bold, illustrating the relative importance of each component in achieving high reconstruction quality.", "section": "5.3. Ablation Studies"}, {"content": "| Metric | Definition |\n|---|---| \n| Acc. | \\mbox{mean}_{c\\in C}(\\min_{c^{*}\\in C^{*}}||c-c^{*}||) |\n| Comp. | \\mbox{mean}_{c^{*}\\in C^{*}}(\\min_{c\\in C}||c-c^{*}||) |\n| Prec. | \\mbox{mean}_{c\\in C}(\\min_{c^{*}\\in C^{*}}||c-c^{*}||<.05) |\n| Recall | \\mbox{mean}_{c^{*}\\in C^{*}}(\\min_{c\\in C}||c-c^{*}||<.05) |\n| zoF-score | \\frac{2\\times\\text{Prec}\\times\\text{Recall}}{\\text{Prec}+\\text{Recall}} |", "caption": "Table 3: Definitions of 3D metrics. c\ud835\udc50citalic_c and c\u2217superscript\ud835\udc50c^{*}italic_c start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT are the predicted and ground truth point clouds.", "description": "This table defines the five 3D geometry metrics used to evaluate the quality of the reconstructed point clouds.  These metrics assess the geometric fidelity by comparing the predicted point cloud (c) to the ground truth point cloud (c*). Specifically, Accuracy measures the average distance between corresponding points; Completion assesses how well the reconstruction covers the ground truth; Precision and Recall measure the proportion of points within a certain threshold; and F-score provides a balanced measure combining Precision and Recall. Lower values for Accuracy and Completion are better, while higher values for Precision, Recall, and F-score indicate better performance.", "section": "A. Definitions of Evaluation Metrics"}]