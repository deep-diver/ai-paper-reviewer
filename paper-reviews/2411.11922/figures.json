[{"figure_path": "https://arxiv.org/html/2411.11922/x1.png", "caption": "Figure 1: Illustration of two common failure cases in visual object tracking using SAM 2: (1) In a crowded scene with similar appearances between target and background objects, SAM 2 tends to ignore the motion cue and predict where the mask has the higher IoU score. (2) The original memory bank simply chooses and stores the previous n\ud835\udc5bnitalic_n frames into the memory bank, resulting in introducing some bad features during occlusion.", "description": "Figure 1 illustrates two common scenarios where the Segment Anything Model 2 (SAM 2) fails during visual object tracking. The first case shows that in crowded scenes with similar-looking objects, SAM 2 prioritizes the mask with the highest Intersection over Union (IoU) score, neglecting crucial motion cues, which often leads to inaccurate tracking of the target object.  The second case demonstrates how the fixed-window memory mechanism of SAM 2 indiscriminately stores the previous frames, without assessing the quality of the memories. This results in irrelevant or low-quality memory features being stored, especially during object occlusions, further compromising the tracking accuracy.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.11922/extracted/6006494/sec/figure/figure_2_pipeline_v2.png", "caption": "Figure 2: The overview of our SAMURAI visual object tracker.", "description": "This figure provides a detailed overview of the SAMURAI visual object tracking system.  It illustrates the flow of data through the various components:  the image encoder processes the input video frames; a motion modeling module refines the positional information; the sparse prompt tokens guide the initial mask selection; the memory attention layer incorporates historical context from the motion-aware memory selection mechanism, which only selects relevant frames based on both mask affinity and motion cues; a mask decoder outputs a set of predicted masks and related scores; finally, the multi-mask selection component chooses the most accurate mask.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2411.11922/x2.png", "caption": "Figure 3: SUC and Pnormnorm{}_{\\text{norm}}start_FLOATSUBSCRIPT norm end_FLOATSUBSCRIPT plots of LaSOT and LaSOTextext{}_{\\text{ext}}start_FLOATSUBSCRIPT ext end_FLOATSUBSCRIPT.", "description": "Figure 3 presents the success plots (SUC) and normalized precision plots (Pnorm) for the LaSOT and LaSOText datasets.  These plots illustrate the performance of the SAMURAI tracker and other trackers (both supervised and zero-shot) across different overlap thresholds (for SUC) and location error thresholds (for Pnorm). The SUC plot shows the percentage of frames where the tracker successfully keeps track of the object, while the Pnorm plot shows the precision of the tracker's bounding box predictions, normalized by the object's size.  The plots allow for a visual comparison of the relative performance of SAMURAI and competing trackers across varying tracking difficulty levels.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.11922/x3.png", "caption": "Figure 4: Visualization of tracking results comparing SAMURAIwith existing methods. (Top) Conventional VOT methods often struggle in crowded scenarios where the target object is surrounded by objects with similar appearances. (Bottom) The baseline SAM-based method suffers from fixed-window memory composition, leading to error propagation and reduced overall tracking accuracy due to ID switches.", "description": "This figure compares the visual object tracking performance of SAMURAI against other state-of-the-art methods.  The top row shows how traditional VOT (Visual Object Tracking) methods often fail in crowded scenes with similar-looking objects, frequently losing track of the target. The bottom row demonstrates that even the SAM (Segment Anything Model)-based baseline tracker struggles because of its fixed-window memory approach. This fixed memory results in accumulated errors and incorrect object identification (ID switches) over time. In contrast, SAMURAI's improved motion modeling and memory selection strategies mitigate these issues, enabling more accurate and stable tracking.", "section": "5.4. Qualitative Results"}]