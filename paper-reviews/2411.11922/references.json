{"references": [{"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-10-26", "reason": "This paper introduces the foundational Segment Anything Model (SAM), which SAMURAI builds upon and adapts for visual object tracking."}, {"fullname_first_author": "Nikhila Ravi", "paper_title": "SAM 2: Segment Anything in images and videos", "publication_date": "2024-08-01", "reason": "SAMURAI directly adapts SAM 2, which introduces streaming memory architecture for video processing, addressing the limitations of the original SAM."}, {"fullname_first_author": "Matthias Muller", "paper_title": "TrackingNet: A large-scale dataset and benchmark for object tracking in the wild", "publication_date": "2018-09-01", "reason": "TrackingNet is a crucial benchmark dataset for evaluating the performance of visual object trackers, and SAMURAI's performance is compared against state-of-the-art trackers on this dataset."}, {"fullname_first_author": "Heng Fan", "paper_title": "LaSOT: A high-quality benchmark for large-scale single object tracking", "publication_date": "2019-06-01", "reason": "LaSOT is another important benchmark dataset used for evaluation, and SAMURAI's performance is extensively analyzed on LaSOT."}, {"fullname_first_author": "Lianghua Huang", "paper_title": "GOT-10k: A large high-diversity benchmark for generic object tracking in the wild", "publication_date": "2019-01-01", "reason": "GOT-10k provides a challenging and diverse benchmark for visual object tracking, used to evaluate the robustness and generalization capability of SAMURAI."}]}