{"importance": "This paper is important for researchers in image generation because it **tackles the under-explored issue of preference divergence in diffusion models**. By introducing Adaptive-DPO, the research **offers a robust method to handle subjective annotations**, paving the way for more reliable and human-aligned image generation. It also opens new avenues for exploring preference learning.", "summary": "Adaptive Diffusion Models with Minority-Aware Adaptive DPO", "takeaways": ["Minority samples in preference datasets can negatively impact the performance of diffusion models.", "Adaptive-DPO effectively handles both synthetic minority data and real-world preference data.", "A novel minority-instance-aware metric that incorporates intra-annotator confidence and inter-annotator stability."], "tldr": "In the field of image generation, fine-tuning methods align models with human preferences. However, the subjective nature of preferences and minority samples in datasets pose challenges. Current methods assume uniform preference labels, neglecting the diversity of opinions. The impact of this dichotomy on diffusion models has not been explored, so this paper investigates the effect. The existence of minority samples can lead to performance decline, equivalent to 52% loss in performance gains.\n\nTo address these issues, **Adaptive-DPO is proposed, autonomously identifying and suppressing problematic minority samples.** It leverages a metric modeling intra-annotator confidence and inter-annotator stability, distinguishing between majority and minority samples. An adaptive loss improves model learning while mitigating negative impacts. Experiments demonstrate that the method handles synthetic and real-world data, enabling effective training in image generation.", "affiliation": "Fudan University", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.16921/podcast.wav"}