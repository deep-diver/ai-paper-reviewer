[{"figure_path": "https://arxiv.org/html/2410.23218/x1.png", "caption": "Figure 1: (Left) The OS-Atlas model operates in three distinct modes to cater to various research needs. In Grounding mode, OS-Atlas predicts element coordinates based on user instructions and can be integrated with a planner module to create a complete agent. In Action mode, OS-Atlas functions independently to solve step-level agent tasks universally across different platforms and applications, even in zero-shot OOD scenarios. In Agent mode, OS-Atlas undergoes further supervised fine-tuning to address specific agent tasks.\n(Right) Overall performance comparisons between OS-Atlas and other state-of-the-art models.", "description": "This figure illustrates the OS-Atlas model's functionality and performance. The left panel shows the three operational modes of OS-Atlas: Grounding Mode (predicting coordinates from instructions, potentially using a planner), Action Mode (independently solving step-level tasks across platforms, including zero-shot out-of-distribution scenarios), and Agent Mode (fine-tuned for specific tasks). The right panel provides a visual comparison of OS-Atlas's performance against other state-of-the-art models, highlighting its superior capabilities.", "section": "3 OS-ATLAS"}, {"figure_path": "https://arxiv.org/html/2410.23218/x2.png", "caption": "Figure 2: Overall training pipeline of OS-Atlas. We first perform large-scale pre-training using 13 million GUI grounding data collected to build OS-Atlas-Base. Next, we conduct multitask fine-tuning on agent data, resulting in OS-Atlas.", "description": "The figure illustrates the two-stage training process of the OS-Atlas model.  The first stage involves large-scale pre-training on a dataset of 13 million GUI grounding data points to create the OS-Atlas-Base model. This pre-training equips the model with a strong understanding of GUI screenshots and their constituent elements. The second stage consists of multitask fine-tuning using agent data. This fine-tuning adapts the pre-trained model to solve various agent tasks, ultimately resulting in the final OS-Atlas model, which excels at GUI grounding and out-of-distribution agentic tasks. The diagram visually depicts the flow of data and the transformation of the model through these two stages.", "section": "3 OS-ATLAS"}, {"figure_path": "https://arxiv.org/html/2410.23218/x3.png", "caption": "Figure 3: The effect of grounding data scaling on two metrics. The performances on three different domains are reported.", "description": "This figure shows the relationship between the amount of grounding data used to train the OS-Atlas-Base model and its performance on three different GUI domains (web, desktop, and mobile).  Two performance metrics are tracked: grounding accuracy (percentage of correctly located GUI elements) and Intersection over Union (IoU, a measure of the overlap between the predicted and ground truth bounding boxes). The graph illustrates that increased training data correlates with improved performance, especially for IoU. The web domain, with nearly 10 million elements, shows the strongest correlation, highlighting the potential of larger datasets.", "section": "4.2 RESULTS AND ANALYSIS"}, {"figure_path": "https://arxiv.org/html/2410.23218/x4.png", "caption": "Figure 4: Ablation studies and performance on ScreenSpot. IG/Mobile/Desktop refers to instruction grounding, mobile, and desktop grounding data, respectively.", "description": "This figure presents ablation study results and performance comparisons on the ScreenSpot benchmark for GUI grounding.  It shows the impact of different data sources on the model's performance. Specifically, it compares results when instruction grounding data (IG), mobile GUI data, and desktop GUI data are included or excluded from training, showcasing the effect of various data modalities on the model's ability to perform GUI grounding tasks accurately across different platforms (web, desktop, and mobile).  The charts illustrate the impact of each data source on both text-based and icon/widget-based instructions.", "section": "4.2 RESULTS AND ANALYSIS"}, {"figure_path": "https://arxiv.org/html/2410.23218/x5.png", "caption": "Figure 5: Ablation studies on the zero-shot OOD setting. The results are reported respectively across three platforms.", "description": "Figure 5 shows the results of ablation studies conducted on the zero-shot out-of-distribution (OOD) setting of the OS-Atlas model.  The ablation studies were performed to investigate the impact of two key components of the model: grounding pre-training and the unified action space.  The figure presents step-wise success rate and grounding accuracy for each ablation experiment.  The results are shown separately for three different platforms: web, desktop, and mobile, demonstrating the effect of the ablations across various GUI types.", "section": "5 EXPERIMENTS: AGENT TASKS"}, {"figure_path": "https://arxiv.org/html/2410.23218/x6.png", "caption": "Figure 6: OS-Atlas-Pro evaluation results.", "description": "Figure 6 shows the performance improvement achieved by OS-Atlas-Pro. OS-Atlas-Pro is a version of OS-Atlas that leverages a larger dataset for multitask fine-tuning, leading to enhanced performance across three domains: Web, Mobile, and Desktop.  The chart visually compares the average performance of OS-Atlas (both 4B and 7B versions) with that of OS-Atlas-Pro across these domains. The results demonstrate the positive impact of more extensive fine-tuning on model performance.", "section": "5.4 OS-ATLAS-PRO"}, {"figure_path": "https://arxiv.org/html/2410.23218/x7.png", "caption": "Figure 7: A case study from OS-World. OS-Atlas-Base works in the grounding mode, integrating GPT-4o as a task planner to create an agent. For each Click step, OS-Atlas-Base outputs the coordinates based on the provided step-level instructions.", "description": "Figure 7 presents a case study demonstrating OS-Atlas-Base's functionality within the OS-World environment.  OS-Atlas-Base operates in grounding mode, collaborating with GPT-40 (acting as a task planner). The process involves GPT-40 generating a sequence of steps to accomplish a task (hiding '.pycache__' folders in VS Code's explorer). For each 'Click' action within these steps, OS-Atlas-Base accurately predicts the necessary coordinates, highlighting its ability to translate high-level instructions into precise, executable actions.", "section": "5. Application: Grounding Mode"}]