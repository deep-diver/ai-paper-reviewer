{"references": [{"fullname_first_author": "Ouyang, L.", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-31", "reason": "This paper is foundational to the field of instruction tuning, a core concept that the current paper builds upon and challenges."}, {"fullname_first_author": "Wang, Y.", "paper_title": "Self-Instruct: Aligning language models with self-generated instructions", "publication_date": "2023-12-31", "reason": "This work introduces a method for creating large instruction-following datasets, a key resource for training language models, that is directly relevant to and compared against in the current work."}, {"fullname_first_author": "Yue, X.", "paper_title": "MAMmoth2: Scaling instructions from the web", "publication_date": "2024-12-31", "reason": "This paper provides a large-scale dataset used in the current paper, offering a benchmark for comparing the proposed approach against other state-of-the-art methods."}, {"fullname_first_author": "Yang, A.", "paper_title": "Qwen2.5 technical report", "publication_date": "2024-12-31", "reason": "This paper describes the language model used as the base model in several experiments; its performance is central to the evaluation of the proposed technique."}, {"fullname_first_author": "Yu, L.", "paper_title": "MetaMath: Bootstrap your own mathematical questions for large language models", "publication_date": "2024-12-31", "reason": "This paper introduces a dataset used in the current paper, providing additional evidence for the generalization of the proposed approach across different datasets."}]}