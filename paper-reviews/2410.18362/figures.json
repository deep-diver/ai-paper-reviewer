[{"figure_path": "2410.18362/figures/figures_1_0.png", "caption": "Figure 1: Removing the children of the element <div id=\"left-column\"> highlighted in yellow does not affect the structure of the visual layout of itself or its sibling element <div id=\"right-column\">.", "description": "This figure demonstrates the robustness of HTML structures.  Panel (a) shows the HTML and CSS code for a webpage, while (b) shows the rendered webpage based on this code.  Panel (c) displays the rendered webpage after removing a portion of the code (highlighted in yellow in panel (a)). The visual layout of the webpage in panel (c) remains largely unchanged despite this modification, illustrating that removing the children elements from the '<div id=\"left-column\">' element does not alter the structure of the '<div id=\"left-column\">' or its sibling element '<div id=\"right-column\">'.", "section": "1 Introduction"}, {"figure_path": "2410.18362/figures/figures_3_0.png", "caption": "Overview of WAFFLE, including training data mutation, structure-aware attention, and contrastive learning.", "description": "This figure illustrates the WAFFLE architecture.  It begins with a WebSight-v0.1 training sample, which includes an image (x) and its corresponding HTML code (y).  The image undergoes a mutation process to create variations. These images and the original image are then processed by a vision model (\u03b8v), generating image embeddings.  Simultaneously, the HTML code is processed by a text model (\u03b8t) that incorporates a structure-aware attention mechanism.  The resulting text embeddings, along with the image embeddings, are fed into a contrastive learning and language modeling objective function to optimize the model for generating accurate HTML code from UI images. A similarity matrix shows the relationships between the image and text embeddings.", "section": "Approach"}, {"figure_path": "2410.18362/figures/figures_4_0.png", "caption": "Example of structure-aware attention.", "description": "This figure illustrates the structure-aware attention mechanism used in WAFFLE.  Panel (a) shows example HTML code, (b) depicts its corresponding Document Object Model (DOM) tree, highlighting the parent-child and sibling relationships between elements. Panel (c) visualizes the structure-aware attention mechanism, demonstrating how attention is selectively applied to parent elements (green), sibling elements (yellow), and self (purple) in the language model decoder. This mechanism enables the model to better understand the hierarchical structure of HTML code during the generation process.", "section": "2.2 Structure-Aware Attention"}, {"figure_path": "2410.18362/figures/figures_12_0.png", "caption": "Figure 5: Example test instance from WebSight-Test dataset, with the generated images by GPT-40, Standard FT, and WAFFLE.", "description": "This figure presents a case study comparing the performance of different models on a single webpage generation task from the WebSight-Test dataset.  It shows four images: (a) the ground truth webpage; (b) the webpage generated by GPT-40, showing multiple errors (incorrect font style, size, color; incorrect block height and color; incorrect footer height); (c) the webpage generated by the standard fine-tuning (FT) method, which still has several errors (incorrect font style, size, color; incorrect block height and color; incorrect footer height), albeit fewer than GPT-40; and (d) the webpage generated by WAFFLE, which closely matches the ground truth with minimal to no errors, demonstrating its superior performance in generating accurate HTML code from UI images.  The CW-SSIM scores for each method are shown below each corresponding image, quantifying the visual similarity to the ground truth.", "section": "4.2 Ablation Studies"}, {"figure_path": "2410.18362/figures/figures_12_1.png", "caption": "Figure 6: Illustration of the tuning process of the parameter that controls the effect of structure-aware attention. In (b), the green line almost overlaps with the blue line.", "description": "This figure contains two sub-figures. Sub-figure (a) shows a line graph illustrating the validation LLEM (Low-Level Element Matching) score against different portions of structure-aware attention heads used in the model.  It shows that using 3/8 or 2/8 of the heads yielded the highest scores and lowest losses. Sub-figure (b) displays training loss curves for different portions of structure-aware attention heads.  The curves indicate that using 2/8, 3/8, or all attention heads leads to similar loss with 3/8 exhibiting less overall loss.", "section": "2 Approach"}]