{"reason": "The paper introduces WAFFLE, a novel fine-tuning strategy that significantly improves the accuracy of Multi-Modal Large Language Models (MLLMs) in generating HTML code from UI designs.  This addresses the challenges of representing HTML's hierarchical structure and bridging the visual-textual gap in UI-to-code generation.", "summary": "WAFFLE: A new fine-tuning strategy boosts AI's ability to turn UI designs into HTML code, achieving significant accuracy improvements.", "takeaways": ["WAFFLE uses a structure-aware attention mechanism to improve LLMs' understanding of HTML's hierarchical structure.", "WAFFLE employs contrastive fine-tuning to align LLMs' understanding of UI images and HTML code.", "WAFFLE outperforms existing methods on HTML match, CW-SSIM, CLIP, and LLEM metrics, demonstrating its effectiveness."], "tldr": "This paper tackles the challenge of automatically generating HTML code from UI designs using Large Language Models (LLMs).  Current LLMs struggle with the hierarchical nature of HTML and the visual-to-text translation. WAFFLE, a new fine-tuning approach, is introduced to address these limitations. It utilizes a 'structure-aware attention mechanism' to help the LLM better understand HTML structure and a 'contrastive fine-tuning' approach to improve the alignment between visual UI representations and the textual HTML code.  Experiments on a new benchmark, WebSight-Test, and Design2Code show that WAFFLE significantly improves HTML code generation accuracy.  The improvements are substantial across various evaluation metrics demonstrating the effectiveness of the proposed strategy."}