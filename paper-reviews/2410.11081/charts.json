[{"figure_path": "2410.11081/charts/charts_1_0.png", "caption": "Figure 1: Sample quality vs. effective sampling compute (billion parameters \u00d7 number of function evaluations during sampling). We compare the sample quality of different models on ImageNet 512\u00d7512, measured by FID (\u2193). Our 2-step sCM achieves sample quality comparable to the best previous generative models while using less than 10% of the effective sampling compute.", "description": "The chart compares the sample quality (measured by FID) of various generative models against their effective sampling compute (billion parameters times the number of function evaluations during sampling).", "section": "1 INTRODUCTION"}, {"figure_path": "2410.11081/charts/charts_6_0.png", "caption": "Figure 4: Stability of different formulations. We show the norms of both terms in \u2202\u209cf\u03b8 and \u2207\u2093f\u03b8\u22c5dx/dt for diffusion models trained with the EDM (Cnoise(t) = log(\u03c3atan(t))) and TrigFlow (Cnoise(t) = t) formulations using different time embeddings. We observe that large Fourier scales in Fourier embeddings cause instabilities. In addition, the EDM formulation suffers from numerical issues when t\u2192\u03c0/2, while TrigFlow (using positional embeddings) has stable partial derivatives for both xt and t.", "description": "The chart compares the stability of different formulations for diffusion models, showing that TrigFlow with positional embeddings offers more stable partial derivatives compared to EDM, especially near t=\u03c0/2.", "section": "4 STABILIZING CONTINUOUS-TIME CONSISTENCY MODELS"}, {"figure_path": "2410.11081/charts/charts_6_1.png", "caption": "Figure 4: Stability of different formulations. We show the norms of both terms in  \u2202\u209cf\u2080\u207b  and  \u2207\u2093f\u2080\u207b \u22c5 dx/dt  for diffusion models trained with the EDM (Cnoise(t) = log(\u03c3\u2090 tan(t))) and TrigFlow (Cnoise(t) = t) formulations using different time embeddings. We observe that large Fourier scales in Fourier embeddings cause instabilities. In addition, the EDM formulation suffers from numerical issues when t\u2192\u03c0/2, while TrigFlow (using positional embeddings) has stable partial derivatives for both x\u209c and t.", "description": "Figure 4 compares the stability of different formulations for calculating partial derivatives of diffusion models, showing TrigFlow with positional embeddings is more stable than EDM.", "section": "4 STABILIZING CONTINUOUS-TIME CONSISTENCY MODELS"}, {"figure_path": "2410.11081/charts/charts_6_2.png", "caption": "Figure 4: Stability of different formulations. We show the norms of both terms in dfo/dt = \u2207xf \u00b7 dx/dt + \u2202xf/\u2202t for diffusion models trained with the EDM (Cnoise(t) = log(\u03c3atan(t))) and TrigFlow (Cnoise(t) = t) formulations using different time embeddings. We observe that large Fourier scales in Fourier embeddings cause instabilities. In addition, the EDM formulation suffers from numerical issues when t\u2192\u03c0/2, while TrigFlow (using positional embeddings) has stable partial derivatives for both xt and t.", "description": "The chart compares the stability of different formulations of diffusion models, showing that TrigFlow with positional embeddings is more stable than EDM, especially when t approaches \u03c0/2.", "section": "4 STABILIZING CONTINUOUS-TIME CONSISTENCY MODELS"}, {"figure_path": "2410.11081/charts/charts_6_3.png", "caption": "Figure 5: Comparing different training objectives for consistency distillation. The diffusion models are EDM2 (Karras et al., 2024) pretrained on ImageNet 512\u00d7512. (a) 1-step and 2-step sampling of continuous-time CMs trained by using raw tangents for, clipped tangents clip(-, -1, 1) and normalized tangents /(|| + 0.1). (b) Quality of 1-step and 2-step samples from continuous-time CMs trained w/ and w/o adaptive weighting, both are w/ tangent normalization. (c) Quality of 1-step samples from continuous-time CMs vs. discrete-time CMs using varying number of time steps (N), trained using all techniques in Sec. 4.", "description": "The chart compares different training objectives for consistency distillation, showing the FID scores for 1-step and 2-step sampling of continuous-time CMs trained with various techniques, and compares continuous-time and discrete-time CM training.", "section": "4 STABILIZING CONTINUOUS-TIME CONSISTENCY MODELS"}, {"figure_path": "2410.11081/charts/charts_8_0.png", "caption": "Figure 1: Sample quality vs. effective sampling compute (billion parameters \u00d7 number of function evaluations during sampling). We compare the sample quality of different models on ImageNet 512\u00d7512, measured by FID (\u2193). Our 2-step sCM achieves sample quality comparable to the best previous generative models while using less than 10% of the effective sampling compute.", "description": "The chart compares the sample quality of different generative models on ImageNet 512x512 based on their effective sampling compute, showing that the proposed 2-step sCM achieves comparable quality with significantly less compute.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.11081/charts/charts_8_1.png", "caption": "Figure 7: sCD has higher diversity compared to VSD: Sample quality comparison of the EDM2 (Karras et al., 2024) diffusion model, VSD (Wang et al., 2024; Yin et al., 2024b), sCD, and the combination of VSD and SCD, across varying guidance scales. All models are of EDM2-M size and trained on ImageNet 512x512.", "description": "The chart compares the sample quality (precision, recall, and FID) of different models (EDM2, VSD, sCD, and combinations) across varying guidance scales on ImageNet 512x512.", "section": "5 Experiments"}]