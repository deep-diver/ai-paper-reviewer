[{"figure_path": "2410.15316/figures/figures_3_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "The figure illustrates Ichigo's architecture, showing how it processes both speech and text as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_6_0.png", "caption": "Figure 2. Data Processing Pipeline for Speech Instruction Dataset Generation. This chart illustrates the multi-stage filtering and conversion process, starting from 6M samples of multiple open-source instruction text datasets. The data undergoes filtering process results in 2.2M samples. Finally, these samples are converted to speech instruction data using WhisperSpeech (TTS) and WhisperVQ (speech to semantic tokens), creating the 1.3M pairs of Speech instruction and Text answer.", "description": "The figure shows the data processing pipeline used to create a speech instruction dataset, starting from open-source text datasets and involving multiple filtering and conversion steps.", "section": "3.2 Post-training Dataset"}, {"figure_path": "2410.15316/figures/figures_9_0.png", "caption": "Figure 3. a. Distribution of data types in the Instruction Fine-tuning dataset. The goal of this specific distribution was to enhance speech comprehension while maintaining robust general language abilities. b. Distribution of data samples used in the enhancement fine-tuning stage. This specific distribution improves Ichigo robustness in handling multi-turn conversations and inaudible inputs.", "description": "The figure shows the data distribution used in the Instruction Fine-tuning and Enhancement Fine-tuning stages, highlighting the balance between different data types to improve model performance.", "section": "4.2 Post-training Refinements"}, {"figure_path": "2410.15316/figures/figures_12_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Ichigo processes both speech and text modalities as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_13_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Ichigo processes speech and text modalities as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_13_1.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "The figure illustrates Ichigo's architecture, showing how both speech and text are converted into discrete tokens and processed using a unified transformer.", "section": "2 Model Architecture"}]