[{"figure_path": "2410.15316/figures/figures_3_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Figure 1 is an illustration of Ichigo's architecture, showing how it processes both speech and text modalities as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_6_0.png", "caption": "Figure 2. Data Processing Pipeline for Speech Instruction Dataset Generation. This chart illustrates the multi-stage filtering and conversion process, starting from 6M samples of multiple open-source instruction text datasets. The data undergoes filtering process results in 2.2M samples. Finally, these samples are converted to speech instruction data using WhisperSpeech (TTS) and WhisperVQ (speech to semantic tokens), creating the 1.3M pairs of Speech instruction and Text answer.", "description": "The figure shows the data processing pipeline for generating a speech instruction dataset, starting from open-source text datasets and using WhisperSpeech and WhisperVQ.", "section": "3.2 Post-training Dataset"}, {"figure_path": "2410.15316/figures/figures_9_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "The figure illustrates Ichigo's architecture, showing how it quantizes both speech and text into discrete tokens before processing them with a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_12_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Ichigo processes both speech and text modalities as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_13_0.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Ichigo uses WhisperVQ to convert speech into discrete tokens, enabling a unified transformer architecture for both speech and text processing.", "section": "2 Model Architecture"}, {"figure_path": "2410.15316/figures/figures_13_1.png", "caption": "Figure 1. Ichigo represents speech and text modalities as discrete tokens and uses a uniform transformer-based architecture. It uses WhisperVQ to quantize speech into discrete tokens in the same manner with original text modality.", "description": "Ichigo processes both speech and text modalities as discrete tokens using a uniform transformer-based architecture.", "section": "2 Model Architecture"}]