{"references": [{" publication_date": "2020", "fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is foundational in establishing the capabilities of large language models (LLMs) as few-shot learners, setting the stage for the development of models like Ichigo which leverage pre-trained LLMs for efficient development and integration with audio data.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This seminal work demonstrates the multi-task learning capabilities of LLMs, highlighting their ability to learn from diverse datasets and perform various tasks without explicit instruction.  This concept is directly relevant to Ichigo which extends the capabilities of a pre-trained LLM to speech processing.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "reason": "This paper describes the Llama-3 series of models, specifically mentioning Llama-3.1-8B-Instruct which is used as the backbone of Ichigo.  Understanding this base model is essential for grasping the design and performance of Ichigo.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yunfei Chu", "paper_title": "Qwen2-audio technical report", "reason": "This paper provides detailed information on Qwen2-Audio, a speech language model compared to Ichigo in Section 5 of the paper. This comparison allows for assessment of Ichigo's performance against existing state-of-the-art models in the field.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Chameleon Team", "paper_title": "Chameleon: Mixed-modal early-fusion foundation models", "reason": "This paper introduces a related tokenized early fusion model that handles images and text.  This allows for a comparison and contrasts with Ichigo which handles speech and text using the same technique. This comparison strengthens the argument for the novelty and efficiency of Ichigo.", "section_number": 6}, {" publication_date": "2023", "fullname_first_author": "Yu Shu", "paper_title": "LLASM: Large language and speech model", "reason": "This paper presents a noteworthy speech language model, LLaSM, which is compared with Ichigo's performance in the results section. This comparison helps establish Ichigo's competitive position within the existing audio-language modeling landscape.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Qingkai Fang", "paper_title": "Llama-omni: Seamless speech interaction with large language models", "reason": "This work proposes another approach to integrating speech and language capabilities into LLMs, allowing for direct comparison and contrast with Ichigo's method.  Understanding the different techniques is key to highlighting Ichigo's novel approach.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Alexandre D\u00e9fossez", "paper_title": "Moshi: a speech-text foundation model for real-time dialogue", "reason": "This paper introduces Moshi, a real-time native multimodal foundation model that addresses similar challenges to Ichigo. Comparing Moshi's approach with that of Ichigo helps highlight the unique aspects of Ichigo's design and implementation.", "section_number": 6}, {" publication_date": "2023", "fullname_first_author": "Kushal Lakhotia", "paper_title": "On generative spoken language modeling from raw audio", "reason": "This work is relevant because it focuses on audio-only language modeling. Understanding the progress made in this area is crucial for evaluating the significance of Ichigo's advancements in mixed-modal modeling.", "section_number": 6}, {" publication_date": "2021", "fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with clip latents", "reason": "While focused on image generation, this paper demonstrates the potential of hierarchical models in handling complex data structures.  Its relevance lies in the fact that a similar concept of interleaving information is used in Ichigo for speech and text.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Zhangchen Xu", "paper_title": "Magpie: Alignment data synthesis from scratch by prompting aligned llms with nothing", "reason": "This paper describes a dataset, Magpie, that is used in the creation of Ichigo's Instruction Speech Dataset. Understanding the data used to train the model is essential for evaluating its performance and limitations.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Vineel Pratap", "paper_title": "MLS: A large-scale multilingual dataset for speech research", "reason": "This paper describes the MLS dataset that contributes to Ichigo's Pre-training Dataset.  This dataset is crucial for the model's ability to understand various languages, making understanding its characteristics important for evaluating Ichigo's robustness.", "section_number": 3}, {" publication_date": "2015", "fullname_first_author": "Vassil Panayotov", "paper_title": "Librispeech: an asr corpus based on public domain audio books", "reason": "This paper describes the Librispeech dataset which contributes to Ichigo's pre-training data.  Understanding the composition and characteristics of Librispeech is critical for evaluating Ichigo's pre-training process and overall performance.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Leo Gao", "paper_title": "A framework for few-shot language model evaluation", "reason": "This paper provides a framework for evaluating language models, which is directly applied to Ichigo's evaluation in section 5.  Understanding the evaluation methodology helps in the interpretation of Ichigo's performance across different metrics.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Bin Wang", "paper_title": "Audiobench: A universal benchmark for audio large language models", "reason": "This paper describes the AudioBench benchmark, which forms a cornerstone of Ichigo's evaluation. Understanding the structure and design of this benchmark is essential for interpreting the significance of Ichigo's results.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "John Hewitt", "paper_title": "Initializing new word embeddings for pretrained language models", "reason": "This paper is relevant to Ichigo's method for initializing new embeddings for sound tokens. The approach described here is crucial for the success of Ichigo's architecture, especially in achieving smooth convergence during training.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "reason": "This paper is foundational for understanding the use of text-to-text transformers, a key concept behind Ichigo's architecture. The unified approach of this paper is similar to Ichigo's handling of speech and text tokens.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Soham Deshmukh", "paper_title": "Pengi: An audio language model for audio tasks", "reason": "This paper is cited because it presents another audio language model that is compared to Ichigo in the results section. This allows for an evaluation of Ichigo's performance compared to related models using similar methods.", "section_number": 6}, {" publication_date": "2023", "fullname_first_author": "Zal\u00e1n Borsos", "paper_title": "AudioLM: a language modeling approach to audio generation", "reason": "This paper focuses on audio-only language modeling and is relevant because it helps understand the evolution of models capable of generating audio outputs. This understanding is crucial for contextualizing Ichigo's mixed-modal achievements.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Shakti N Wadekar", "paper_title": "The evolution of multimodal model architectures", "reason": "This paper provides a review of different multimodal architectures and is especially useful in understanding the tradeoffs between tokenized and non-tokenized early fusion methods. This allows us to assess the significance and innovation of Ichigo's chosen tokenized early fusion approach.", "section_number": 6}]}