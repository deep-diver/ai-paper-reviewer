{"reason": "Ichigo is a novel mixed-modal voice assistant that processes interleaved speech and text using a unified transformer architecture, achieving state-of-the-art performance with low latency.", "summary": "Ichigo: a real-time voice assistant fusing speech & text via a unified transformer, achieving state-of-the-art performance with 111ms latency!", "takeaways": ["Ichigo uses a tokenized early-fusion approach, processing both speech and text modalities within a unified transformer architecture.", "It achieves state-of-the-art performance on speech question answering benchmarks, outperforming existing open-source models.", "It boasts a remarkably low latency of only 111ms to first token generation."], "tldr": "Ichigo is a new real-time voice assistant that tackles the challenge of integrating audio and text in speech-based tasks.  Unlike traditional systems that process speech and text separately (ASR->NLU->NLG->TTS), Ichigo uses a 'tokenized early fusion' approach. This means it converts both speech and text into discrete tokens that are processed together by a single transformer-based model. This method enables joint reasoning and generation across modalities, reducing the delay inherent in traditional cascaded models. The model was pre-trained on a massive multilingual speech recognition dataset and further fine-tuned on a new instruction-following dataset.  Experiments show Ichigo achieves state-of-the-art performance on benchmark tasks, significantly outperforming other open-source models and even matching or exceeding the results of more complex cascaded systems.  Importantly, Ichigo has a very low latency (111ms to first token generation), making it suitable for real-time applications."}