[{"figure_path": "2410.15316/tables/table_8_0.html", "caption": "Table 1. Training Hyper-parameters for Ichigo's three-stage process.", "description": "The table presents the hyperparameters and configurations used in Ichigo's three-stage training process: pre-training, instruction fine-tuning, and enhancement fine-tuning.", "section": "4 Training"}, {"figure_path": "2410.15316/tables/table_10_0.html", "caption": "Table 2. A comparative results of Ichigo against three representative Speech Language Models and a cascade system.", "description": "Table 2 presents a comparison of Ichigo's performance on two speech question answering benchmarks against three other speech language models and a cascaded system.", "section": "5.1 SpeechBench Evaluation"}, {"figure_path": "2410.15316/tables/table_11_0.html", "caption": "Table 3. The comparative results of latency to first token and VRAM usage across different models and systems", "description": "Table 3 compares the latency to the first token and VRAM usage of Ichigo against other speech models and a cascaded system.", "section": "5.2 Latency to first token"}, {"figure_path": "2410.15316/tables/table_12_0.html", "caption": "Table 4. Results of Ichigo across different versions and the original Llama3 8B Instruct model.", "description": "Table 4 compares the performance of different versions of the Ichigo model against the original Llama3 8B Instruct model across three benchmarks: MMLU, GPQA, and GSM-8K.", "section": "5 Results"}, {"figure_path": "2410.15316/tables/table_21_0.html", "caption": "Table 6. Ablations on training model with/without introducing new transcribe token", "description": "The table summarizes the results of ablation studies conducted to investigate the impact of different training configurations on the model's performance, focusing on the presence or absence of a transcription token and its effect on various metrics.", "section": "A.2 Ablation Studies"}]