[{"content": "| Models | Inputs | Quality Score (SROCC) | Quality Score (PLCC) | Importance Score (SROCC) | Importance Score (PLCC) | Distortion Severity Degree (Precision (%)) | Distortion Severity Degree (Recall (%)) | Distortion Severity Degree (F1 Score (%)) | Distortion Type Labels (Precision (%)) | Distortion Type Labels (Recall (%)) | Distortion Type Labels (F1 Score (%)) |\n|---|---|---|---|---|---|---|---|---|---|---|---| \n| HyperIQA |  | 0.7120 | 0.7162 | 0.6645 | 0.6636 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 |\n| DBCNN |  | 0.6836 | 0.6721 | 0.3832 | 0.3551 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 |\n| QualiCLIP |  | 0.6166 | 0.6090 | 0.4902 | 0.4915 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 |\n| PromptIQA* | Crop-based ROI | 0.7377 | 0.7112 | 0.6028 | 0.5991 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 | \u2014 |\n| Yi-VL (6B)* |  | 0.5315 | 0.5427 | 0.6697 | 0.6926 | 21.07% | 21.07% | 21.07% | 23.44% | 23.44% | 23.44% |\n| mPLUG-Owl2 (7B)* |  | 0.6281 | 0.6321 | 0.7176 | 0.7173 | 28.35% | 27.00% | 26.69% | 57.52% | 56.37% | 53.86% |\n| Qwen2-VL (7B)* |  | 0.6539 | 0.6533 | 0.7153 | 0.7161 | 27.41% | 24.50% | 25.02% | 51.15% | 45.03% | 45.83% |\n| LLaVA-1.5 (7B)* |  | 0.5693 | 0.5774 | 0.7338 | 0.7377 | 25.10% | 25.19% | 24.14% | 59.33% | 57.55% | 54.95% |\n| mPLUG-Owl2 (Q-Align)* |  | 0.6562 | 0.6622 | 0.5339 | 0.5127 | 15.60% | 12.20% | 13.02% | 52.44% | 39.77% | 42.19% |\n| mPLUG-Owl2 (Q-Instruct)* |  | 0.6644 | 0.6559 | 0.5172 | 0.5037 | 16.96% | 25.25% | 19.00% | 40.80% | 64.04% | 46.75% |\n| LLaVA-1.5 (Q-Instruct)* | BBox-based ROI & Full Image & Text | 0.6606 | 0.6623 | 0.7667 | 0.7605 | 27.69% | 26.52% | 26.02% | 57.87% | 56.77% | 53.96% |\n| Osprey (7B)*\u2020 | Mask-based ROI | 0.7176 | 0.7173 | 0.8811 | 0.8756 | 27.17% | 29.55% | 26.72% | 58.17% | 62.52% | 56.25% |\n| Seagull (7B)*\u2020 | & Full Image & Text | 0.7452 | 0.7465 | 0.8603 | 0.8468 | 29.50% | 32.51% | 29.03% | 59.90% | 66.87% | 59.08% |", "caption": "Table 1: ROI-based assessment comparison on four sub-tasks on the test set of Seagull-3k in terms of SROCC, PLCC, Sample-Average Precision, Sample-Average Recall and Sample-Average F1 Score. Best and second-best scores are marked in bold and underline, respectively. * denotes all-in-one models. \u2020\u2020\\dagger\u2020 denotes pre-training on Seagull-100w.", "description": "Table 1 presents a comprehensive comparison of various models' performance on four ROI-based image quality assessment sub-tasks using the Seagull-3k test dataset.  The evaluation metrics include SROCC, PLCC, Sample-Average Precision, Sample-Average Recall, and Sample-Average F1 Score.  The table highlights the best and second-best performing models for each sub-task.  It also indicates whether models are 'all-in-one' (performing all sub-tasks with a single model) and if they underwent pre-training on the Seagull-100w dataset.", "section": "5.2. Compared with State-of-the-art Models"}, {"content": "| Models | ROI Type | Blur | Colorfulness | Noise | Compression | Contrast | Exposure | Clean | Average |\n|---|---|---|---|---|---|---|---|---|---| \n| Qwen2-VL |  | 67.14% | 14.93% | 37.30% | 0.00% | 17.24% | 38.16% | **53.33%** | 32.58% |\n| LLaVA-1.5 |  | 79.09% | 33.63% | 39.59% | 23.53% | 23.91% | 51.34% | 49.56% | 42.95% |\n| mPLUG-Owl2 |  | 79.41% | 22.70% | 42.38% | 9.52% | 20.93% | 47.88% | 44.71% | 38.22% |\n| mPLUG-Owl2 (Q-Align) |  | 69.38% | 15.69% | 24.03% | 0.00% | 18.39% | 30.00% | 37.78% | 27.89% |\n| mPLUG-Owl2 (Q-Instruct) | BBox-based ROI &amp; Full Image &amp; Text | 78.70% | 33.02% | 38.58% | 5.26% | 10.81% | 47.45% | 1.58% | 30.77% |\n| Osprey\u2020 | Mask-based ROI | 81.05% | 38.91% | 46.43% | 20.83% | **28.57%** | 50.10% | 45.83% | 44.53% |\n| Seagull\u2020 | &amp; Full Image &amp; Text | **83.33%** | **39.48%** | **52.20%** | **25.00%** | 24.00% | **51.94%** | 52.58% | **46.93%** |", "caption": "Table 2: Distortion types identification accuracy comparison on the test set of Seagull-3k in terms of F1 Score. Best and second-best scores are highlighted in bold and underline, respectively. \u2020\u2020\\dagger\u2020 denotes pre-training on Seagull-100w.", "description": "This table presents a comparison of the accuracy of different models in identifying various distortion types within images, specifically focusing on the regions of interest (ROIs).  The accuracy is measured using the F1 score, a metric that considers both precision and recall. The table includes results from vision-based methods and vision-language models (VLMs), highlighting the impact of different ROI indication methods (crop-based, bounding box, and mask-based) and pre-training strategies.  The best and second-best F1 scores for each distortion type are emphasized to easily compare model performances.  The models that underwent pre-training on the SEAGULL-100w dataset are denoted by the symbol \u2020.", "section": "5.2. Compared with State-of-the-art Models"}, {"content": "| Scale | Quality Score |  | Importance Score |  | Distortion Degree |  | Distortion Type |  |\n|---|---|---|---|---|---|---|---|---|---| \n| 0% | 0.6236 | 0.6238 | 0.7512 | 0.7628 | 28.09% | 25.49% | 55.94% | 50.18% |\n| 25% | 0.6892 | 0.6866 | 0.7760 | 0.7776 | 28.10% | 25.64% | 61.64% | 56.12% |\n| 50% | 0.7441 | 0.7389 | 0.7878 | 0.7926 | 30.34% | 28.20% | 64.79% | 58.11% |\n| 100% | **0.7452** | **0.7465** | **0.8603** | **0.8468** | **32.51%** | **29.03%** | **66.87%** | **59.08%** |", "caption": "Table 3: The impact of pre-training scales on Seagull-100w in terms of SROCC, PLCC, Sample-Average Recall and Sample-Average F1 Score. Best scores are highlighted in bold.", "description": "This table presents the results of an experiment evaluating the effect of varying the size of the pre-training dataset (SEAGULL-100w) on the performance of the SEAGULL model.  The model was pre-trained using different percentages of the SEAGULL-100w dataset (0%, 25%, 50%, and 100%) before being fine-tuned on the SEAGULL-3k dataset.  The table displays the model's performance metrics on four sub-tasks of ROI quality assessment: Quality Score prediction (SROCC and PLCC), Importance Score prediction (SROCC and PLCC), Distortion Severity Degree prediction (Recall and F1 Score), and Distortion Type identification (Recall and F1 Score).  The best performance for each metric, indicating the optimal pre-training dataset size, is highlighted in bold.", "section": "5.3. More Discussion"}, {"content": "| Variants | Quality Score |  | Importance Score |  | Severity Degree |  | Distortion Degree |  |\n|---|---|---|---|---|---|---|---|---|\n|  | SROCC | PLCC | SROCC | PLCC | Recall | F1 Score | Recall | F1 Score |\n|---|---|---|---|---|---|---|---|---|\n| w/o Pre-train | 0.6236 | 0.6238 | 0.7512 | 0.7628 | 28.09% | 25.49% | 55.94% | 50.18% |\n| w/o JIR | 0.6954 | 0.7022 | 0.8020 | 0.7874 | 31.37% | 28.91% | 63.59% | 58.12% |\n| w/o Local | 0.7211 | 0.7331 | 0.8538 | 0.8409 | 31.49% | 28.72% | 65.44% | 58.16% |\n| w/o Global | 0.5671 | 0.5761 | 0.2475 | 0.2503 | 27.04% | 24.37% | 62.14% | 54.82% |\n| Full | **0.7452** | **0.7465** | **0.8603** | **0.8468** | **32.51%** | **29.03%** | **66.87%** | **59.08%** |", "caption": "Table 4: Ablation studies on critical components of the Seagull in terms of SROCC, PLCC, Sample-Average Recall and Sample-Average F1 Score. Best scores are highlighted in bold.", "description": "This table presents the results of ablation studies conducted on the SEAGULL model.  It evaluates the impact of removing or altering key components of the model on its performance across four metrics:  Spearman's Rank Order Correlation Coefficient (SROCC), Pearson's Linear Correlation Coefficient (PLCC), Sample-Average Recall, and Sample-Average F1-Score. The metrics assess the model's accuracy in predicting ROI Quality Scores, Importance Scores, Distortion Severity Degrees, and Distortion Types.  The different model variants compared include a version without pre-training, a version without judgment instruction-responses, a version without local view tokens extracted from the mask-based feature extractor, and a version without global view tokens. The table helps to demonstrate the contribution of each component to the overall performance of SEAGULL.", "section": "5. Experiment"}]