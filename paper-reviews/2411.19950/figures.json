[{"figure_path": "https://arxiv.org/html/2411.19950/x1.png", "caption": "Figure 1: Illustration of tablet properties and rendering.\nNormal and up vector determines the rotation of a tablet in 3D space, while every tablet maintains a distance ratio between the coordinates of the 3D field and 2D-pixel space.", "description": "Figure 1 illustrates the properties of an AlphaTablet and its rendering process.  An AlphaTablet represents a 3D plane as a rectangular primitive with associated properties: a normal vector and an up vector determine its 3D orientation, while a distance ratio maintains a consistent scale relationship between its 3D coordinates and its 2D projection in pixel space. This ensures accurate and consistent representation of the tablet across different viewpoints.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2411.19950/x2.png", "caption": "Figure 2: Pipeline of our proposed 3D planar reconstruction. Given a monocular video as input, we first initialize AlphaTablets using off-the-shelf superpixel, depth, and normal estimation models. The 3D AlphaTablets are then optimized through photometric guidance, followed by the merging scheme. This iterative process of optimization and merging refines the 3D AlphaTablets, resulting in accurate and complete 3D planar reconstruction.", "description": "This figure illustrates the pipeline for 3D planar reconstruction using AlphaTablets.  Starting with a monocular video, the process begins by initializing AlphaTablets using pre-trained models for superpixel segmentation, depth estimation, and surface normal estimation. These initial AlphaTablets are then iteratively refined. First, an optimization step adjusts their geometry and texture using photometric guidance (comparing rendered images to actual video frames). Second, a merging scheme combines neighboring AlphaTablets to create larger, more coherent planar structures. This iterative optimization and merging process continues until accurate and complete 3D planar reconstructions are achieved.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2411.19950/x3.png", "caption": "Figure 3: Qualitative results on ScanNet. Error maps are included. Better viewed when zoomed in.", "description": "This figure displays a qualitative comparison of 3D plane reconstruction results on the ScanNet dataset.  Several methods are shown: Metric3D + Seq-RANSAC, SuGaR + Seq-RANSAC, PlanarRecon, and the proposed 'Ours' method. For each method, the reconstructed 3D planes are visualized alongside an error map to highlight discrepancies from the ground truth.  The 'high' and 'low' labels refer to the error level, indicating the accuracy of the reconstruction.  The image is best viewed at a zoomed-in scale to better appreciate the details of the reconstruction and error maps.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19950/x4.png", "caption": "Figure 4: Qualitative results on TUM-RGBD and Replica datasets.", "description": "This figure shows qualitative results comparing the proposed AlphaTablets method to other state-of-the-art methods on two benchmark datasets: TUM-RGBD and Replica.  The visualizations showcase the reconstructed 3D planar surfaces.  This allows for a visual comparison of accuracy and completeness of plane reconstruction in different scene types and complexities. The results demonstrate the generalization capability of AlphaTablets across various datasets.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19950/x5.png", "caption": "Figure 5: 3D scene editing examples of our method.", "description": "This figure shows examples of 3D scene editing using the AlphaTablets method.  The original scene is shown, followed by the results of editing using AlphaTablets. The editing examples include changing textures, colors, and applying various visual effects. This demonstrates the flexibility and precision of the AlphaTablets method for manipulating 3D scenes.", "section": "4.3 Example Application: 3D Plane-based Scene Editing"}, {"figure_path": "https://arxiv.org/html/2411.19950/x6.png", "caption": "Figure 6: Qualitative Comparison of Initialization Methods for SuGaR.", "description": "This figure shows a qualitative comparison of two different initialization methods for the SuGaR (Surface-Aligned Gaussian Splatting) algorithm used in 3D plane reconstruction.  It visually compares the results obtained using COLMAP initialization versus Metric3D initialization. The comparison highlights the impact of the chosen initialization method on the final quality and accuracy of the 3D plane reconstruction generated by the SuGaR method.", "section": "4.1 Evaluation on 3D Plane Detection and Reconstruction"}, {"figure_path": "https://arxiv.org/html/2411.19950/x7.png", "caption": "Figure 7: Demonstration of Insufficient Coverage of 3D Ground-Truth Labels: The 3D ground truth labels only partially cover the range within the camera\u2019s view. Most of the red regions in the figure highlight this issue. While these uncovered areas reduce accuracy, they should not be considered a negative outcome.", "description": "Figure 7 demonstrates a crucial limitation in the ScanNet dataset's ground truth data for evaluating 3D planar reconstruction. The ground truth labels only cover a limited portion of the scene within the camera's view, neglecting significant portions of the scene.  The red regions in the figure highlight these areas not included in the ground truth data but present in the scene, showcasing the dataset's insufficient coverage of 3D planes.  These discrepancies reduce the accuracy of the quantitative evaluation metrics, but do not reflect a shortcoming of the 3D plane reconstruction itself, as the model is still accurately reconstructing areas outside the ground truth scope.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19950/extracted/6031766/figures/images/wildmore.png", "caption": "Figure 8: Visualization of Tablet Count Evolution.", "description": "This figure shows a graph illustrating the evolution of the number of AlphaTablets during the training process. It starts with a large number of tablets in the initialization stage, which gradually decreases as the tablets merge during optimization.  The x-axis represents the training stage, and the y-axis represents the number of tablets on a logarithmic scale. The graph shows how the number of tablets decreases over several training stages, finally converging to a smaller number of larger, more coherent tablets representing the final 3D planar reconstruction.", "section": "3.3 A Bottom-up Planar Reconstruction Pipeline with AlphaTablets"}]