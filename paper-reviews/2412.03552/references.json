{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen Video: High definition video generation with diffusion models", "publication_date": "2022-10-02", "reason": "This paper introduces a foundational video diffusion model that significantly advances the field of high-definition video generation, impacting the proposed Imagine360's architecture."}, {"fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2023-07-04", "reason": "This paper's AnimateDiff model, with its space-time disentangled design and resource-friendly training strategy, serves as a critical building block for Imagine360's architecture."}, {"fullname_first_author": "Qihua Chen", "paper_title": "Follow-Your-Canvas: Higher-resolution video outpainting with extensive content generation", "publication_date": "2024-09-01", "reason": "This paper directly addresses the related task of video outpainting and offers valuable insights into handling perspective video inputs and generating dynamic and diverse motions, informing Imagine360's approach."}, {"fullname_first_author": "Fanda Fan", "paper_title": "Hierarchical masked 3D diffusion model for video outpainting", "publication_date": "2023-00-00", "reason": "This paper's M3DDM addresses the challenging task of video outpainting, providing solutions for artifact accumulation in long videos and offering a frame-guided approach that is relevant to Imagine360's design."}, {"fullname_first_author": "Cheng Zhang", "paper_title": "Taming stable diffusion for text to 360 panorama image generation", "publication_date": "2024-00-00", "reason": "This paper's dual-branch design and strategies for generating high-quality panorama images with limited data directly inform Imagine360's design, particularly the dual-branch approach for 360 video generation."}]}