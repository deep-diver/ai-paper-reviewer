[{"content": "| Models | Subject |  |  |  |  |  |  |  |\n|---|---|---|---|---|---|---|---|---|\n| Consistency | Background |  |  |  |  |  |  |  |\n| Consistency | Temporal |  |  |  |  |  |  |  |\n| Flickering | Motion |  |  |  |  |  |  |  |\n| Smoothness | Dynamic |  |  |  |  |  |  |  |\n| Degree | Aesthetic |  |  |  |  |  |  |  |\n| Quality | Imaging |  |  |  |  |  |  |  |\n| Quality | Object |  |  |  |  |  |  |  |\n| Class |  |  |  |  |  |  |  |  |\n| Generative Camera Dolly [82] | 83.02% | 80.42% | 74.64% | 82.33% | **51.24%** | 38.67% | 58.62% | 76.46% |\n| Ours | **88.53**% | **92.02**% | **91.12**% | **98.24**% | 49.03% | **57.35**% | 64.75% | **82.07**% |", "caption": "Table 1: Quantitative comparisons with Generative Camera Dolly on VBench.", "description": "This table presents a quantitative comparison of the proposed ReCapture method and the Generative Camera Dolly method on the VBench benchmark.  It evaluates several aspects of video generation quality including subject and background consistency, the presence of flickering or motion smoothness issues, the dynamic range of the generated videos, the aesthetic quality, image quality, and object class consistency.  The results are presented as percentages, allowing for a direct comparison of the two methods across these key dimensions.", "section": "4. Experiments"}, {"content": "| Method | PSNR (all) \u2191 | SSIM (all) \u2191 | LPIPS (all) \u2193 | PSNR (occ.) \u2191 | SSIM (occ.) \u2191 |\n|---|---|---|---|---|---| \n| HexPlane [12] | 15.38 | 0.428 | 0.568 | 14.71 | 0.428 |\n| 4D-GS [93] | 14.92 | 0.388 | 0.584 | 14.55 | 0.392 |\n| DynIBaR [48] | 12.86 | 0.356 | 0.646 | 12.78 | 0.358 |\n| Vanilla SVD [8] | 13.85 | 0.312 | 0.556 | 13.66 | 0.326 |\n| ZeroNVS [74] | 15.68 | 0.396 | 0.508 | 14.18 | 0.368 |\n| Generative Camera Dolly [82] | 20.30 | 0.587 | 0.408 | 18.60 | 0.527 |\n| Ours | **20.92** | **0.596** | 0.402 | **18.92** | **0.541** |", "caption": "Table 2: \nComparison results on Kubric-4D. We evaluate gradual dynamic view synthesis models following\u00a0[82] to use video with resolution 384\u00d7256384256384\\times 256384 \u00d7 256. Our method achieves superior performance compared to other reconstruction and generative methods.", "description": "Table 2 presents a quantitative comparison of different methods for gradual dynamic view synthesis on the Kubric-4D dataset.  The evaluation uses videos downsampled to a resolution of 384x256 pixels.  The table compares the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) metrics.  The results show that the proposed method outperforms existing reconstruction and generative methods in terms of these metrics, demonstrating its superior performance in generating high-quality videos with novel viewpoints.", "section": "4.1 Quantitative Evaluation"}, {"content": "| Models | Subject |  |  |  |  |  |  |  |\n|---|---|---|---|---|---|---|---|---|\n| Consistency | Background |  |  |  |  |  |  |  |\n| Consistency | Temporal |  |  |  |  |  |  |  |\n| Flickering | Motion |  |  |  |  |  |  |  |\n| Smoothness | Dynamic |  |  |  |  |  |  |  |\n| Degree | Aesthetic |  |  |  |  |  |  |  |\n| Quality | Imaging |  |  |  |  |  |  |  |\n| Quality | Object |  |  |  |  |  |  |  |\n| Class |  |  |  |  |  |  |  |  |\n| Anchor Video | 82.41% | 77.45% | 64.50% | 74.27% | 49.72% | 34.94% | 55.90% | 79.82% |\n| + Temporal LoRAs w/ Masks ) | 85.24% | 90.88% | 89.60% | 97.32% | 49.64% | 40.41% | 62.34% | 80.02% |\n| ++ Spatial LoRAs) | 86.02% | 91.24% | 90.02% | 97.32% | 49.64% | 49.18% | 63.03% | 80.02% |\n| +++ SD-Edit | **88.53**% | **92.02**% | **91.12**% | **98.24**% | 49.03% | **57.35**% | **64.75**% | **82.07**% |", "caption": "Table 3: Ablation studies for each component of mask video diffusion finetuning: \u2019+ Temporal LoRAs\u2019 applies temporal LoRAs solely for masked video finetuning. \u2019++ Spatial LoRAs\u2019 introduces additional context-aware LoRAs, using both spatial and temporal LoRAs for finetuning. \u2019+++ SD-Edit\u2019 involves applying SD-editing after completing training with both LoRAs for eliminating blurriness.", "description": "This table presents the results of ablation studies evaluating the impact of different components in the masked video fine-tuning stage of the ReCapture model.  Three variations are compared: using only temporal LoRAs, adding spatial LoRAs to the temporal ones, and finally, applying SD-Edit post-processing to further reduce blurriness. The quantitative results are presented for various aspects of video quality, showing the cumulative improvement brought by each added component.", "section": "4.3 Ablation Studies"}]