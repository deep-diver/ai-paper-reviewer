[{"figure_path": "2410.14470/charts/charts_5_0.png", "caption": "Figure 2: Adversarial training increases the average criticality proportional to the training attack budget \u03b5. We ablate l\u221e from l2-norm training but do not observe any significant differences in their trends. The marker size in the plot indicates the validation accuracy on ImageNet-1k (larger is better).", "description": "The chart shows that adversarial training increases the average criticality of layers in a neural network proportionally to the attack budget, with minimal difference observed between l2 and l\u221e norm attacks.", "section": "3 Results"}, {"figure_path": "2410.14470/charts/charts_6_0.png", "caption": "Figure 3: Correlation between average network criticality and performance on ImageNet-1k.", "description": "The chart displays the correlation between average network criticality and ImageNet-1k validation accuracy across different training methods.", "section": "3 Results"}, {"figure_path": "2410.14470/charts/charts_11_0.png", "caption": "Figure 1: Training methods determine what layers become critical. We measure the criticality of fifty different ResNet-50-based models that all utilize the same exact network architecture and training data (ImageNet-1k) but differ in their training methods. Darker spots denote layers that are critical, i.e., in significantly different predictions and decreased performance after reset. Brighter spots are auxiliary, i.e., resetting these layers does not significantly affect the model. We denote the average (mean\u00b1std) layer criticality for both, a model across layers on the right, for a layer across model on the bottom.", "description": "The chart visualizes how different training methods influence the criticality of various layers in ResNet-50 models trained on ImageNet-1k.", "section": "3 Results"}, {"figure_path": "2410.14470/charts/charts_12_0.png", "caption": "Figure 1: Training methods determine what layers become critical. We measure the criticality of fifty different ResNet-50-based models that all utilize the same exact network architecture and training data (ImageNet-1k) but differ in their training methods. Darker spots denote layers that are critical, i.e., in significantly different predictions and decreased performance after reset. Brighter spots are auxiliary, i.e., resetting these layers does not significantly affect the model. We denote the average (mean\u00b1std) layer criticality for both, a model across layers on the right, for a layer across model on the bottom.", "description": "The chart visualizes how different training methods influence the criticality of various layers in ResNet-50 models trained on ImageNet-1k.", "section": "3 Results"}]