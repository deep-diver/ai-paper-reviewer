{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-XX-XX", "reason": "This paper introduces the Stable Diffusion model, which is the foundation model used and extended in the current work."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-XX-XX", "reason": "This paper introduces the DreamBooth method, which is a key technique used for adapting text-to-image models to specific subjects, a core component of the proposed method."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-XX-XX", "reason": "This paper introduces ControlNet, a crucial method that enables controlling the generation process by adding extra condition information, a concept leveraged and improved upon in the current work."}, {"fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2024-XX-XX", "reason": "This paper introduces Animatediff, a method for generating videos from images using diffusion models, which is integrated into the proposed framework to enhance video generation capabilities."}, {"fullname_first_author": "Yue Ma", "paper_title": "Follow-your-emoji: Fine-controllable and expressive freestyle portrait animation", "publication_date": "2024-XX-XX", "reason": "This paper introduces a method for high-fidelity portrait animation which the current paper builds upon to improve the quality of the generated videos."}]}