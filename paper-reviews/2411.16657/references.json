{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "This paper introduces CLIP, a crucial model for evaluating the alignment between generated videos and their text descriptions, significantly impacting the evaluation metrics in this work."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2021-MM-DD", "reason": "This paper introduces LoRA, a parameter-efficient fine-tuning method adopted for learning motion and subject priors, contributing to DREAMRUNNER's efficiency and performance improvements."}, {"fullname_first_author": "Zhuoyi Yang", "paper_title": "Cogvideox: Text-to-video diffusion models with an expert transformer", "publication_date": "2024-MM-DD", "reason": "This paper introduces CogVideoX-2B, the foundation model used for video generation, representing a critical architectural component of the proposed DREAMRUNNER framework."}, {"fullname_first_author": "Omer Bar-Tal", "paper_title": "Lumiere: A space-time diffusion model for video generation", "publication_date": "2024-MM-DD", "reason": "This paper introduces Lumiere, a relevant baseline model in storytelling video generation that is compared against DREAMRUNNER, providing a context for evaluating the advancements achieved."}, {"fullname_first_author": "Han Lin", "paper_title": "VideodirectorGPT: Consistent multi-scene video generation via LLM-guided planning", "publication_date": "2023-MM-DD", "reason": "This paper introduces VideoDirectorGPT, a key comparative model in storytelling video generation, highlighting DREAMRUNNER's improvements in character consistency, text alignment, and smooth transitions."}]}