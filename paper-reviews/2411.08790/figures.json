[{"figure_path": "https://arxiv.org/html/2411.08790/x2.png", "caption": "Figure 1: Steering vectors are out-of-distribution for SAEs. The L2subscript\ud835\udc3f2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-norm of the corrigibility steering vector is outside the distribution of L2subscript\ud835\udc3f2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-norms of layer 14 model activations, causing the encoder bias to skew the SAE decomposition. Model activations are taken over sequences from\nThe Pile [6], totalling 200,000 tokens.", "description": "This figure illustrates that steering vectors, specifically the one for 'corrigibility', have significantly smaller L2 norms compared to the typical model activations. This difference in magnitude is substantial. The distribution of L2 norms for layer 14 model activations is shown as a histogram, clearly demonstrating that the L2 norm of the corrigibility steering vector falls far outside this distribution.  The consequence of this is that, when a sparse autoencoder (SAE) attempts to decompose this steering vector, the encoder's bias term significantly influences the result, skewing the decomposition and leading to unreliable interpretations.", "section": "3.1 Steering vectors are out-of-distribution"}, {"figure_path": "https://arxiv.org/html/2411.08790/x3.png", "caption": "Figure 2: The five highest activating SAE features for the corrigibility steering vector and zero vector. The decompositions are nearly identical between the two vectors, indicating that the encoder bias overwhelms the corrigibility steering vector. This shows that SAE decomposition only reflects the encoder bias.", "description": "This figure shows the top five SAE features with the highest activations for both the corrigibility steering vector and a zero vector.  The near-identical activation patterns demonstrate that the SAE's encoder bias, rather than the steering vector itself, heavily influences the decomposition. This highlights a key limitation of directly applying SAEs to steering vectors: the encoder bias masks any meaningful signal from the steering vector, leading to misleading interpretations.", "section": "3.1 Steering vectors are out-of-distribution"}, {"figure_path": "https://arxiv.org/html/2411.08790/x4.png", "caption": "Figure 3: Scaled steering vectors remain out-of-distribution in certain directions. Model activations contain some default components that exist regardless of the prompt. For instance, model activations of random prompts are, on average, highly negative in the direction of SAE feature 4888. The SAE offsets this default component with a positive encoder bias term (86.20), resulting in SAE activations around zero (right-hand axis). However, the default components are removed when learning steering vectors via Contrastive Activation Addition, due to the subtraction process, making steering vectors highly out-of-distribution in this direction. Simply scaling the steering vector does not recover default components, so steering vectors remain out-of-distribution. SV: Corrigibility steering vector. Positive and Negative prompts are the Contrastive Activation Addition prompts. Random prompts are from the Pile [6].", "description": "This figure illustrates why simply scaling steering vectors doesn't solve the out-of-distribution problem for sparse autoencoders (SAEs).  Model activations naturally include \"default components,\" present regardless of the input.  Random prompts show these components are highly negative in the direction of SAE feature 4888.  SAEs compensate for this negativity with a large positive bias (86.20), bringing activations closer to zero.  However, the Contrastive Activation Addition method used to create steering vectors removes these default components during the subtraction process. Thus, even after scaling, steering vectors remain out-of-distribution because they lack these default components, differing significantly from the typical SAE input distribution.", "section": "3.1 Steering vectors are out-of-distribution"}, {"figure_path": "https://arxiv.org/html/2411.08790/x5.png", "caption": "Figure 4: Negative projections can cause misleading positive activations in SAE decompositions. Left: Feature 14004 activates more strongly on negative corrigibility prompts than positive ones, indicating its relevance to the steering vector. However, while the steering vector has a strong negative projection in this direction, SAEs are not designed to accommodate negative coefficients, resulting in an activation of 0.000.000.000.00. Right: Feature 3517 rarely activates for either prompt type. However, since it has negative cosine similarity with feature 14004 (-0.82), the steering vector shows a strong positive projection in this direction, causing feature 3517 to spuriously activate. All prompt activations are taken at the answer token position.", "description": "This figure illustrates how negative projections in Sparse Autoencoders (SAEs) can lead to misleading positive activations.  The left panel shows feature 14004, which activates more strongly for negative corrigibility prompts than positive ones.  This indicates its relevance to the steering vector. However, because SAEs cannot handle negative coefficients, its activation is reported as 0.0, masking its true importance. The right panel depicts feature 3517, which rarely activates for either prompt type.  But due to its negative cosine similarity (-0.82) with feature 14004, the steering vector shows a strong positive projection onto feature 3517, causing it to spuriously activate. This demonstrates how the limitations of SAEs can distort the interpretation of steering vector components.", "section": "3.2 SAEs do not allow negative reconstruction coefficients"}, {"figure_path": "https://arxiv.org/html/2411.08790/x6.png", "caption": "Figure 5: The corrigibility steering vector extracted at layer 14 has the highest steerability. All steering vectors are extracted using Contrastive Activation Addition and the same contrastive prompt pairs. Steerability is defined as in [18].", "description": "This figure displays the steerability of corrigibility steering vectors extracted from different layers of a language model. Steerability, a metric defined in reference [18], measures how effectively a steering vector alters the model's behavior.  The plot shows that layer 14 exhibits the highest steerability, indicating it is the optimal layer for extracting steering vectors related to corrigibility. All vectors were obtained using the Contrastive Activation Addition method with identical prompt pairs.", "section": "B Comparing the corrigibility steering vectors at different layers"}]