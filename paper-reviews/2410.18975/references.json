{"references": [{" publication_date": "1986", "fullname_first_author": "James P. Carse", "paper_title": "Finite and Infinite Games: A Vision of Life as Play and Possibility", "reason": "This book introduces the fundamental concept of finite and infinite games, a core idea that shapes the philosophy and design of UNBOUNDED.  The distinction between finite (win-lose) and infinite (play-for-play's sake) games provides a theoretical framework for understanding UNBOUNDED's unique characteristics as a generative, open-ended game that transcends the limitations of traditional finite video game designs.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper introduces the concept of few-shot learning in large language models (LLMs), a key technique that underpins UNBOUNDED's ability to generate diverse and coherent game content and interactions with limited fine-tuning data.  The authors' demonstration of the ability of LLMs to generalize to novel tasks with minimal training is crucial to the success of UNBOUNDED's real-time content generation.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "reason": "This work is foundational to the development of the image generation model used in UNBOUNDED.  The findings on self-supervised vision transformers, particularly concerning the emergence of properties and the effectiveness of self-supervised learning, are directly applied in UNBOUNDED's visual generation component, contributing to the efficiency and quality of image production in real-time.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "reason": "This paper introduces a technique of 'textual inversion' for customizing text-to-image generation, which is relevant to UNBOUNDED's approach to character personalization.  Textual inversion allows for fine-grained control over visual outputs based on textual descriptions, a crucial aspect for UNBOUNDED's ability to create consistent character appearances and interactions.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Stephanie Fu", "paper_title": "Dreamsim: Learning new dimensions of human visual similarity using synthetic data", "reason": "The concept and methodology of 'Dreamsim' for improving visual similarity is directly relevant to UNBOUNDED\u2019s need for generating visually consistent environments and characters.  The paper's work on learning visual similarity using synthetic data informs UNBOUNDED's approach to generating consistent character appearances in various environments.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "LoRA is a crucial technique used in UNBOUNDED to enhance the efficiency and performance of large language models. The paper's introduction of low-rank adaptation provides a method for fine-tuning LLMs while substantially reducing computational costs, enabling the real-time generation of game content and interactions.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Simian Luo", "paper_title": "Latent consistency models: Synthesizing high-resolution images with few-step inference", "reason": "Latent Consistency Models (LCMs) are at the core of UNBOUNDED's real-time image generation capability.  This paper introduces LCMs, demonstrating their ability to generate high-resolution images with significantly reduced inference time compared to traditional diffusion models, making real-time interactive gameplay possible in UNBOUNDED.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP's ability to measure the similarity between images and textual descriptions is directly relevant to UNBOUNDED\u2019s evaluation strategy.  The paper's introduction of CLIP, and its demonstration of transferable visual models from natural language supervision, allows for the quantitative evaluation of visual consistency in UNBOUNDED's image generations across various environments and character interactions.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "reason": "The study of self-supervised vision transformers from this paper directly informs UNBOUNDED's image generation model.  The findings on the emergence of properties and effectiveness of self-supervised learning are central to UNBOUNDED's ability to generate consistent and high-quality images of characters and environments in real-time.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Nataniel Ruiz", "paper_title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation", "reason": "Dreambooth is a key technique used in UNBOUNDED for character personalization. This paper\u2019s introduction of Dreambooth provides a method for fine-tuning text-to-image diffusion models to generate images of specific subjects, allowing UNBOUNDED to generate images of custom characters with consistent appearances across different game environments.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Hu Ye", "paper_title": "Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models", "reason": "This paper introduces the original concept of the Image Prompt Adapter (IP-Adapter), which is a crucial component of UNBOUNDED's visual generation system. While UNBOUNDED improves upon this initial concept, understanding the original IP-Adapter is essential to comprehending the advancements in UNBOUNDED's regional IP-Adapter.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Lai Zeqiang", "paper_title": "Mini-dalle3: Interactive text to image by prompting large language models", "reason": "This paper explores interactive text-to-image generation using large language models (LLMs), an approach that's relevant to UNBOUNDED's design philosophy. Although UNBOUNDED differs in its architecture and uses a specialized distilled LLM, understanding the interactive text-to-image generation approach informed the design of UNBOUNDED's open-ended interaction system.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Chunting Zhou", "paper_title": "Transfusion: Predict the next token and diffuse images with one multi-modal model", "reason": "The multi-modal approach demonstrated in this work is relevant to UNBOUNDED's architecture, which integrates an LLM with a visual generation model. While not directly implemented in the same manner, this work provides insights on effectively combining language and image models in a unified system.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Dustin Podell", "paper_title": "Sdxl: Improving latent diffusion models for high-resolution image synthesis", "reason": "SDXL is the foundation upon which UNBOUNDED's image generation model is built. This paper's introduction of SDXL's improvements in latent diffusion models is crucial for achieving the high-resolution, consistent image generations in UNBOUNDED, especially considering the real-time constraints of the application.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP is used extensively in UNBOUNDED for evaluating image generation quality and semantic alignment. Understanding the strengths and capabilities of CLIP as introduced in this paper is essential to interpreting the quantitative results presented in the evaluation.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Shilong Liu", "paper_title": "Grounding dino: Marrying dino with grounded pre-training for open-set object detection", "reason": "Grounding-DINO is a crucial tool in UNBOUNDED's evaluation of image generation, particularly concerning the presence of the character in the generated images. This paper introduces Grounding-DINO, and its use in object detection helps ensure the generated images align with the prompt and the character remains consistently visible.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Nataniel Ruiz", "paper_title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation", "reason": "Dreambooth is crucial to UNBOUNDED\u2019s character personalization. This paper is foundational in demonstrating how to effectively fine-tune text-to-image diffusion models to generate high-quality, consistent images of specified subjects, which is fundamental to generating the unique characters in UNBOUNDED.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Chameleon Team", "paper_title": "Chameleon: Mixed-modal early-fusion foundation models", "reason": "The concept of mixed-modal foundation models used in Chameleon is conceptually relevant to UNBOUNDED's integrated approach. While not directly applied in the same manner, this paper provides insights on designing unified systems that effectively combine different modalities (text and images) for complex tasks like game generation.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Gemma Team", "paper_title": "Gemma: Open models based on gemini research and technology", "reason": "Gemma-2B, the base LLM for UNBOUNDED's game engine, is directly inspired by the research presented in this paper.  This work is fundamental to UNBOUNDED's ability to generate dynamic game mechanics and narratives in real-time, owing to the underlying foundation models' architecture and training methodology.", "section_number": 3}]}