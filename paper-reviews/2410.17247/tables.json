[{"figure_path": "2410.17247/tables/table_7_0.html", "caption": "Table 1: LVLM w and w/o our method on 6 benchmarks. Benchmark names are abbreviated due to space limits. MMB: MMBenchmark (Liu et al., 2023); MMBCN: MMBench-Chinese (Liu et al., 2023); SEED\u00b9: SEED-Bench (Image) (Li et al., 2023b). We denote PyramidDrop as PDrop.", "description": "Table 1 shows the performance of LLaVA and LLaVA-NeXT with and without PyramidDrop on six benchmarks, including training and inference time, FLOPs, and scores on different tasks.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_7_1.html", "caption": "Table 2: LLaVA -NeXT-7B on other 8 benchmarks. We report more benchmarks which contain lots of fine-grained content to examine the performance.", "description": "Table 2 presents the performance comparison of the LLaVA-NeXT-7B model with and without PyramidDrop across eight benchmarks, focusing on benchmarks with fine-grained visual content.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_8_0.html", "caption": "Table 3: Performance gain with models trained with PyramidDrop. Directly applying efficient inference strategies like FastV to models trained with PyramidDrop yields substantial improvement.", "description": "The table compares the performance of models trained with and without PyramidDrop, showing performance gains with the application of FastV inference strategy.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_8_1.html", "caption": "Table 4: Ablation studies results. We adjust \u03bb form 0.4 to 0.6 for investigating the influence on performance and training time.", "description": "Table 4 shows the ablation study results of adjusting the hyperparameter \u03bb (drop ratio) from 0.4 to 0.6, demonstrating its impact on performance and training time across different benchmarks for both LLaVA-NeXT-7B and LLaVA-1.5-7B models.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_9_0.html", "caption": "Table 5: Inference acceleration performance. We compare PDrop, FastV and vanilla model, and find PDrop outperforms FastV on almost all benchmarks. PDrop here is as an inference-only strategy.", "description": "Table 5 compares the inference acceleration performance of PyramidDrop against FastV and a vanilla model across various benchmarks, showing PyramidDrop's superior performance as an inference-only strategy.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN INFERENCE"}]