[{"figure_path": "2410.17247/tables/table_7_0.html", "caption": "Table 1: LVLM w and w/o our method on 6 benchmarks. Benchmark names are abbreviated due to space limits. MMB: MMBenchmark (Liu et al., 2023); MMBCN: MMBench-Chinese (Liu et al., 2023); SEED\u00b9: SEED-Bench (Image) (Li et al., 2023b). We denote PyramidDrop as PDrop.", "description": "Table 1 presents the performance comparison of vanilla LVLMs and LVLMs using PyramidDrop on six benchmarks, showing training and inference efficiency improvements.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_7_1.html", "caption": "Table 2: LLaVA -NeXT-7B on other 8 benchmarks. We report more benchmarks which contain lots of fine-grained content to examine the performance.", "description": "Table 2 presents the performance comparison of the LLaVA-NeXT-7B model with and without PyramidDrop across eight benchmarks, showcasing the model's performance on benchmarks containing detailed information.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_8_0.html", "caption": "Table 3: Performance gain with models trained with PyramidDrop. Directly applying efficient inference strategies like FastV to models trained with PyramidDrop yields substantial improvement.", "description": "Table 3 shows the performance improvement achieved by applying FastV inference strategy to models trained with PyramidDrop, demonstrating the substantial performance gains obtained.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_8_1.html", "caption": "Table 4: Ablation studies results. We adjust \u03bb form 0.4 to 0.6 for investigating the influence on performance and training time.", "description": "Table 4 presents the ablation study results of varying the hyperparameter \u03bb (drop ratio) from 0.4 to 0.6, showing its impact on model performance and training time for two different LVLMs.", "section": "4.2 EFFICIENT OF PYRAMID DROP IN TRAINING"}, {"figure_path": "2410.17247/tables/table_9_0.html", "caption": "Table 5: Inference acceleration performance. We compare PDrop, FastV and vanilla model, and find PDrop outperforms FastV on almost all benchmarks. PDrop here is as an inference-only strategy.", "description": "Table 5 compares the inference acceleration performance of PyramidDrop, FastV, and a vanilla model across various benchmarks, showing PyramidDrop's superior performance when used as an inference-only strategy.", "section": "4.3 EFFICIENT OF PYRAMIDDROP IN INFERENCE"}]