[{"content": "| Method | Reference-based | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| MC-v2 [46] | | 0.8632 | 48.37 | 13.50 | 0.6987 | 4.753 | 0.8833 | 33.14 | 17.20 | 0.8396 | 4.845 |\n| ACDO [2] | | 0.8687 | 39.38 | 15.75 | 0.7672 | 4.540 | 0.8970 | 28.12 | 21.77 | 0.9516 | 4.686 |\n| EBMC [28] | \u2713 | 0.8542 | 38.77 | 15.21 | 0.7592 | 4.605 | 0.8859 | 19.48 | 20.80 | 0.9474 | 4.702 |\n| ScreenVAE [71] | \u2713 | 0.7328 | 98.52 | 9.12 | 0.5373 | 4.160 | - | - | - | - | |\n| Ours | \u2713 | **0.9419** | **13.37** | **25.88** | **0.9541** | **4.924** | **0.9433** | **12.17** | **26.01** | **0.9579** | **5.011** |\n\nNote: The first row specifies metrics names for Screenstyle and Grayscale Image, each having the same set of metrics.\n", "caption": "Table 1: \nQuantitative comparisons with state-of-the-art models for Reference Image-based Colorization. We compare two models without reference image input Manga Colorization V2 (MC-v2)\u00a0[45] and AnimeColorDeOldify (ACDO)\u00a0[16], and two reference image-based colorization models, Example Based Manga Colorization (EBMC)\u00a0[28] and ScreenVAE\u00a0[71]. Best results are in bold.", "description": "This table presents a quantitative comparison of various image colorization models, both with and without reference images, using metrics such as CLIP Image Similarity (CLIP-IS), Fr\u00e9chet Inception Distance (FID), Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Aesthetic Score (AS) on a dataset called ColorFlow-Bench.  The models evaluated include Manga Colorization V2 (MC-v2), AnimeColorDeOldify (ACDO), Example Based Manga Colorization (EBMC), and ScreenVAE.  The goal is to demonstrate the effectiveness of the proposed method, ColorFlow, compared to existing state-of-the-art techniques for reference-based image colorization.", "section": "4.4. Quantitative Comparisons"}, {"content": "| Training | Inference | Inference | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 |\n|---|---|---|---|---|---|---|---| \n| RAP | RAP | GSRP |  |  |  |  |  |\n|  | \u2713 | \u2713 | 0.9326 | 15.98 | 24.48 | 0.9448 | 4.921 |\n|  |  | \u2713 | 0.9233 | 18.32 | 24.16 | 0.9410 | 4.907 |\n| \u2713 |  | \u2713 | 0.9266 | 17.07 | 24.64 | 0.9464 | 4.914 |\n| \u2713 | \u2713 |  | 0.9322 | 17.85 | 20.12 | 0.8077 | 4.898 |\n| \u2713 | \u2713 | \u2713 | **0.9419** | **13.37** | **25.88** | **0.9541** | **4.924** |", "caption": "Table 2: \nAblation Study on the Influence of Retrieval-Augmentated Pipeline (RAP) and Guided Super-Resolution Pipeline (GSRP).", "description": "This table presents an ablation study on the impact of two key components of the ColorFlow framework: the Retrieval-Augmented Pipeline (RAP) and the Guided Super-Resolution Pipeline (GSRP).  The study investigates the influence of these components both during the training and inference stages. The provided metrics measure colorization quality, color fidelity to the original image, and perceptual quality in order to assess the performance of ColorFlow.", "section": "4.6. Ablation Study"}, {"content": "| Width \\* Height (Pixel) | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 |\n|---|---|---|---|---|---| \n| 512 \\* 800 | 0.9372 | 14.91 | 23.51 | 0.9414 | 4.868 |\n| 1024 \\* 1600 | **0.9419** | **13.37** | 25.88 | 0.9541 | 4.924 |\n| 1280 \\* 2000 | 0.9398 | 13.42 | **26.02** | **0.9580** | **4.929** |", "caption": "Table 3: \nAblation of Inference Resolution.", "description": "This table presents the ablation study on inference resolution. It shows how the model generalizes across different resolutions despite being trained only on a resolution of 512x800.", "section": "4.6. Abaltion Study"}, {"content": "| Rank | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 |\n|---|---|---|---|---|---| \n| 32 | 0.940 | 13.46 | 25.46 | 0.9521 | 4.920 |\n| 64 | **0.9419** | **13.37** | **25.88** | **0.9541** | 4.924 |\n| 128 | 0.9376 | 14.31 | 24.79 | 0.9461 | **4.930** |\n| 192 | 0.9370 | 14.46 | 24.59 | 0.9440 | 4.914 |", "caption": "Table 4: \nAblation of LoRA Rank.", "description": "This table presents the ablation study results for different Low-Rank Adaptation (LoRA) ranks. The table shows how the performance of ColorFlow varies with the change in LoRA rank. It uses five metrics: CLIP Image Similarity (CLIP-IS), Fr\u00e9chet Inception Distance (FID), Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Aesthetic Score (AS). The results demonstrate that using a LoRA rank of 64 leads to the best overall performance across these five metrics, outperforming other LoRA ranks.", "section": "4.6. Ablation Study"}, {"content": "| \u03bc | CLIP-IS\u2191 | FID\u2193 | PSNR\u2191 | SSIM\u2191 | AS\u2191 |\n|---|---|---|---|---|---| \n| 0 | 0.9351 | 14.18 | 25.12 | 0.9501 | **4.927** |\n| 1.5 | **0.9419** | **13.37** | **25.88** | **0.9541** | 4.924 |\n| 3 | 0.9395 | 13.51 | 25.42 | 0.9509 | 4.917 |", "caption": "Table 5: \nAblation of Timesteps Sampling.", "description": "This table presents an ablation study on the impact of adjusting the timestep sampling during image colorization using the proposed ColorFlow method. It explores the effects of varying the sampling emphasis at higher timesteps (represented by the factor '\u00b5') on the performance of the model, using metrics such as CLIP-IS, FID, PSNR, SSIM, and AS.", "section": "4.6. Abaltion Study"}, {"content": "|                               | Ours | EBMC | MC-v2 | ACDO | ScreenVAE |\n|--------------------------------|------|------|-------|------|----------|\n| Aesthetic Quality \u2191            | **4.577** | 3.141 | 2.891 | 2.844 | 1.547    |\n| Similarity to Original \u2191       | **4.673** | 3.316 | 2.984 | 2.642 | 1.385    |\n| Consistency in Sequences \u2191 | **4.538** | 3.399 | 3.215 | 2.540 | 1.308    |", "caption": "Table 6: \nResults of the User Study. The table presents the average Score for different models based on aesthetic quality, similarity to the original image, and consistency in sequences", "description": "This table presents the average user ratings for different image colorization models across three criteria: aesthetic quality, similarity to the original image, and color consistency across image sequences. Users ranked their preference among five sample groups, assigning scores from 1 (least preferred) to 5 (most preferred). The table then presents the average score each model received for each evaluation metric.", "section": "4.7. User Study"}]