[{"content": "| Symbol | Description |\n|---|---| \n| <math alttext=\"D\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.1.1.1.m1.1\"><semantics id=\"S5.T1.1.1.1.m1.1a\"><mi id=\"S5.T1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.m1.1.1.cmml\">D</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.m1.1b\"><ci id=\"S5.T1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\">\ud835\udc37</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.m1.1c\">D</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.1.1.1.m1.1d\">italic_D</annotation></semantics></math> | Amount of finetuning data |\n| <math alttext=\"L(\n\ntext{M})\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.2.2.1.m1.1\"><semantics id=\"S5.T1.2.2.1.m1.1a\"><mrow id=\"S5.T1.2.2.1.m1.1.2\" xref=\"S5.T1.2.2.1.m1.1.2.cmml\"><mi id=\"S5.T1.2.2.1.m1.1.2.2\" xref=\"S5.T1.2.2.1.m1.1.2.2.cmml\">L</mi><mo id=\"S5.T1.2.2.1.m1.1.2.1\" xref=\"S5.T1.2.2.1.m1.1.2.1.cmml\">\u2062</mo><mrow id=\"S5.T1.2.2.1.m1.1.2.3.2\" xref=\"S5.T1.2.2.1.m1.1.1a.cmml\"><mo id=\"S5.T1.2.2.1.m1.1.2.3.2.1\" stretchy=\"false\" xref=\"S5.T1.2.2.1.m1.1.1a.cmml\">(</mo><mtext id=\"S5.T1.2.2.1.m1.1.1\" xref=\"S5.T1.2.2.1.m1.1.1.cmml\">M</mtext><mo id=\"S5.T1.2.2.1.m1.1.2.3.2.2\" stretchy=\"false\" xref=\"S5.T1.2.2.1.m1.1.1a.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.1.m1.1b\"><apply id=\"S5.T1.2.2.1.m1.1.2.cmml\" xref=\"S5.T1.2.2.1.m1.1.2\"><times id=\"S5.T1.2.2.1.m1.1.2.1.cmml\" xref=\"S5.T1.2.2.1.m1.1.2.1\"></times><ci id=\"S5.T1.2.2.1.m1.1.2.2.cmml\" xref=\"S5.T1.2.2.1.m1.1.2.2\">\ud835\udc3f</ci><ci id=\"S5.T1.2.2.1.m1.1.1a.cmml\" xref=\"S5.T1.2.2.1.m1.1.2.3.2\"><mtext id=\"S5.T1.2.2.1.m1.1.1.cmml\" xref=\"S5.T1.2.2.1.m1.1.1\">M</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.1.m1.1c\">L(\n\ntext{M})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.2.2.1.m1.1d\">italic_L ( M )</annotation></semantics></math> | Pretraining loss of model <span class=\"ltx_text ltx_align_left ltx_markedasmath\" id=\"S5.T1.3.3.2.1.1.1\">M</span> |\n| <span class=\"ltx_text ltx_markedasmath\" id=\"S5.T1.4.4.1.1\">Perf</span> | Downstream performance |\n| <math alttext=\"A,B,E\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.5.5.1.m1.3\"><semantics id=\"S5.T1.5.5.1.m1.3a\"><mrow id=\"S5.T1.5.5.1.m1.3.4.2\" xref=\"S5.T1.5.5.1.m1.3.4.1.cmml\"><mi id=\"S5.T1.5.5.1.m1.1.1\" xref=\"S5.T1.5.5.1.m1.1.1.cmml\">A</mi><mo id=\"S5.T1.5.5.1.m1.3.4.2.1\" xref=\"S5.T1.5.5.1.m1.3.4.1.cmml\">,</mo><mi id=\"S5.T1.5.5.1.m1.2.2\" xref=\"S5.T1.5.5.1.m1.2.2.cmml\">B</mi><mo id=\"S5.T1.5.5.1.m1.3.4.2.2\" xref=\"S5.T1.5.5.1.m1.3.4.1.cmml\">,</mo><mi id=\"S5.T1.5.5.1.m1.3.3\" xref=\"S5.T1.5.5.1.m1.3.3.cmml\">E</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.5.5.1.m1.3b\"><list id=\"S5.T1.5.5.1.m1.3.4.1.cmml\" xref=\"S5.T1.5.5.1.m1.3.4.2\"><ci id=\"S5.T1.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.5.5.1.m1.1.1\">\ud835\udc34</ci><ci id=\"S5.T1.5.5.1.m1.2.2.cmml\" xref=\"S5.T1.5.5.1.m1.2.2\">\ud835\udc35</ci><ci id=\"S5.T1.5.5.1.m1.3.3.cmml\" xref=\"S5.T1.5.5.1.m1.3.3\">\ud835\udc38</ci></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.5.5.1.m1.3c\">A,B,E</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.5.5.1.m1.3d\">italic_A , italic_B , italic_E</annotation></semantics></math> | ReLU parameters |\n| <math alttext=\"E_{\n\n\n\ntheta}(D)\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.6.6.1.m1.1\"><semantics id=\"S5.T1.6.6.1.m1.1a\"><mrow id=\"S5.T1.6.6.1.m1.1.2\" xref=\"S5.T1.6.6.1.m1.1.2.cmml\"><msub id=\"S5.T1.6.6.1.m1.1.2.2\" xref=\"S5.T1.6.6.1.m1.1.2.2.cmml\"><mi id=\"S5.T1.6.6.1.m1.1.2.2.2\" xref=\"S5.T1.6.6.1.m1.1.2.2.2.cmml\">E</mi><mi id=\"S5.T1.6.6.1.m1.1.2.2.3\" xref=\"S5.T1.6.6.1.m1.1.2.2.3.cmml\">\u03b8</mi></msub><mo id=\"S5.T1.6.6.1.m1.1.2.1\" xref=\"S5.T1.6.6.1.m1.1.2.1.cmml\">\u2062</mo><mrow id=\"S5.T1.6.6.1.m1.1.2.3.2\" xref=\"S5.T1.6.6.1.m1.1.2.cmml\"><mo id=\"S5.T1.6.6.1.m1.1.2.3.2.1\" stretchy=\"false\" xref=\"S5.T1.6.6.1.m1.1.2.cmml\">(</mo><mi id=\"S5.T1.6.6.1.m1.1.1\" xref=\"S5.T1.6.6.1.m1.1.1.cmml\">D</mi><mo id=\"S5.T1.6.6.1.m1.1.2.3.2.2\" stretchy=\"false\" xref=\"S5.T1.6.6.1.m1.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.6.6.1.m1.1b\"><apply id=\"S5.T1.6.6.1.m1.1.2.cmml\" xref=\"S5.T1.6.6.1.m1.1.2\"><times id=\"S5.T1.6.6.1.m1.1.2.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.2.1\"></times><apply id=\"S5.T1.6.6.1.m1.1.2.2.cmml\" xref=\"S5.T1.6.6.1.m1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S5.T1.6.6.1.m1.1.2.2.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.2.2\">subscript</csymbol><ci id=\"S5.T1.6.6.1.m1.1.2.2.2.cmml\" xref=\"S5.T1.6.6.1.m1.1.2.2.2\">\ud835\udc38</ci><ci id=\"S5.T1.6.6.1.m1.1.2.2.3.cmml\" xref=\"S5.T1.6.6.1.m1.1.2.2.3\">\ud835\udf03</ci></apply><ci id=\"S5.T1.6.6.1.m1.1.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.1\">\ud835\udc37</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.6.6.1.m1.1c\">E_{\n\n\n\ntheta}(D)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.6.6.1.m1.1d\">italic_E start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_D )</annotation></semantics></math> | Emergence law; models emergence shift |\n| <math alttext=\"k,\n\n\n\n\nalpha,C\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.7.7.1.m1.3\"><semantics id=\"S5.T1.7.7.1.m1.3a\"><mrow id=\"S5.T1.7.7.1.m1.3.4.2\" xref=\"S5.T1.7.7.1.m1.3.4.1.cmml\"><mi id=\"S5.T1.7.7.1.m1.1.1\" xref=\"S5.T1.7.7.1.m1.1.1.cmml\">k</mi><mo id=\"S5.T1.7.7.1.m1.3.4.2.1\" xref=\"S5.T1.7.7.1.m1.3.4.1.cmml\">,</mo><mi id=\"S5.T1.7.7.1.m1.2.2\" xref=\"S5.T1.7.7.1.m1.2.2.cmml\">\u03b1</mi><mo id=\"S5.T1.7.7.1.m1.3.4.2.2\" xref=\"S5.T1.7.7.1.m1.3.4.1.cmml\">,</mo><mi id=\"S5.T1.7.7.1.m1.3.3\" xref=\"S5.T1.7.7.1.m1.3.3.cmml\">C</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.7.7.1.m1.3b\"><list id=\"S5.T1.7.7.1.m1.3.4.1.cmml\" xref=\"S5.T1.7.7.1.m1.3.4.2\"><ci id=\"S5.T1.7.7.1.m1.1.1.cmml\" xref=\"S5.T1.7.7.1.m1.1.1\">\ud835\udc58</ci><ci id=\"S5.T1.7.7.1.m1.2.2.cmml\" xref=\"S5.T1.7.7.1.m1.2.2\">\ud835\udefc</ci><ci id=\"S5.T1.7.7.1.m1.3.3.cmml\" xref=\"S5.T1.7.7.1.m1.3.3\">\ud835\udc36</ci></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.7.7.1.m1.3c\">k,\n\n\n\n\nalpha,C</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.7.7.1.m1.3d\">italic_k , italic_\u03b1 , italic_C</annotation></semantics></math> | Emergence law parameters |\n| <math alttext=\"D_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.8.8.1.m1.1\"><semantics id=\"S5.T1.8.8.1.m1.1a\"><msub id=\"S5.T1.8.8.1.m1.1.1\" xref=\"S5.T1.8.8.1.m1.1.1.cmml\"><mi id=\"S5.T1.8.8.1.m1.1.1.2\" xref=\"S5.T1.8.8.1.m1.1.1.2.cmml\">D</mi><mn id=\"S5.T1.8.8.1.m1.1.1.3\" xref=\"S5.T1.8.8.1.m1.1.1.3.cmml\">0</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.8.8.1.m1.1b\"><apply id=\"S5.T1.8.8.1.m1.1.1.cmml\" xref=\"S5.T1.8.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T1.8.8.1.m1.1.1.1.cmml\" xref=\"S5.T1.8.8.1.m1.1.1\">subscript</csymbol><ci id=\"S5.T1.8.8.1.m1.1.1.2.cmml\" xref=\"S5.T1.8.8.1.m1.1.1.2\">\ud835\udc37</ci><cn id=\"S5.T1.8.8.1.m1.1.1.3.cmml\" type=\"integer\" xref=\"S5.T1.8.8.1.m1.1.1.3\">0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.8.8.1.m1.1c\">D_{0}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.8.8.1.m1.1d\">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> | Low data extrapolation limit |\n| <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T1.9.9.1.m1.1\"><semantics id=\"S5.T1.9.9.1.m1.1a\"><mi id=\"S5.T1.9.9.1.m1.1.1\" mathvariant=\"normal\" xref=\"S5.T1.9.9.1.m1.1.1.cmml\">\u0394</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.9.9.1.m1.1b\"><ci id=\"S5.T1.9.9.1.m1.1.1.cmml\" xref=\"S5.T1.9.9.1.m1.1.1\">\u0394</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.9.9.1.m1.1c\">\\Delta</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T1.9.9.1.m1.1d\">roman_\u0394</annotation></semantics></math> | Optional parameter; shifts ReLU base |", "caption": "Table 1: Symbols used in Section\u00a05.", "description": "This table lists the symbols used in Section 5 of the paper and their corresponding descriptions.  It provides a key for understanding the mathematical notation and variables used in the emergence law model presented in that section.  The symbols include those representing the amount of finetuning data, the model's pretraining loss, downstream performance, and the parameters used in the emergence law itself.", "section": "5 Scaling Laws for Emergence Prediction"}, {"content": "| Ablation Setting | GSM8K | MMLU | CSQA | CoLA |\n|---|---|---|---|---|\n| Full Data | 0.022 [0.004, 0.170] | 0.041 [0.011, 0.055] | 0.003 [0.001, 0.045] | 0.064 [0.030, 0.121] |\n| -1 Smallest Subset | 0.014 [0.002, 0.051] | 0.022 [0.010, 0.031] | 0.051 [0.037, 0.084] | 0.071 [0.024, 0.097] |\n| -2 Smallest Subset | 0.047 [0.018, 0.063] | 0.025 [0.003, 0.032] | 0.087 [0.063, 0.129] | 0.634 [0.577, 0.711] |\n| -3 Smallest Subset | 0.005 [0.002, 0.050] | 0.001 [0.002, 0.025] | 0.988 [0.913, 1.099] | 1.513 [1.291, 1.698] |\n| -1 Largest Subset | 0.022 [0.002, 0.032] | 0.034 [0.024, 0.034] | 0.045 [0.003, 0.096] | 0.036 [0.007, 0.090] |\n| -2 Largest Subset | 0.005 [0.002, 0.054] | 1.017 [1.482, 1.985] | 0.057 [0.056, 0.059] | 0.004 [0.002, 0.058] |\n| -3 Largest Subset | 0.016 [0.002, 0.083] | 0.332 [1.371, 4.200] | 0.089 [0.077, 0.098] | 0.044 [0.019, 0.143] |\n| Only Subset Sample 1 | 0.006 [0.001, 0.031] | 0.244 [0.223, 0.489] | 1.557 [1.616, 2.573] | 0.179 [0.125, 0.269] |\n| Only Subset Sample 2 | 0.026 [0.002, 0.067] | 0.073 [0.059, 0.077] | 0.035 [0.004, 0.102] | 0.034 [0.022, 0.047] |\n| Last 6 Checkpoints | 0.010 [0.003, 0.113] | 0.041 [0.007, 0.049] | 0.075 [0.063, 0.301] | 0.118 [0.087, 0.167] |\n| Last 5 Checkpoints | 0.047 [0.048, 0.176] | 0.032 [0.020, 0.038] | 1.165 [1.070, 1.728] | 0.130 [0.099, 0.170] |\n| Last 4 Checkpoints | 0.080 [0.072, 4.925] | 0.030 [0.001, 0.042] | 1.734 [1.555, 2.308] | 0.076 [0.052, 0.111] |\n| Last 3 Checkpoints | 0.159 [0.124, 0.703] | 0.013 [0.002, 0.059] | 0.986 [0.802, 1.249] | 0.039 [0.004, 0.077] |\n| Last 6 Checkpoints, Every Other Even | 0.019 [0.003, 0.162] | 0.070 [0.059, 0.075] | 1.663 [1.667, 1.781] | 0.033 [0.007, 0.050] |\n| Last 6 Checkpoints, Every Other Odd | 0.044 [0.041, 0.126] | 0.040 [0.024, 0.045] | 0.037 [0.031, 0.191] | 0.224 [0.190, 0.287] |\n| -1 Last Checkpoints | 0.069 [0.003, 0.149] | 0.043 [0.023, 0.055] | 0.985 [0.858, 1.800] | 0.026 [0.004, 0.079] |\n| -2 Last Checkpoints | 0.087 [0.003, 0.176] | 0.076 [0.046, 0.089] | 0.102 [0.098, 0.104] | 0.165 [0.098, 0.242] |\n| -3 Last Checkpoints | 0.110 [0.010, 0.468] | 0.664 [0.500, 0.959] | 0.616 [0.510, 0.822] | 2.217 [2.031, 2.407] |\n| -4 Last Checkpoints | 0.044 [0.005, 0.089] | 2.308 [2.347, 57.068] | 0.581 [0.546, 1.169] | 1.039 [0.905, 1.298] |", "caption": "Table 2: Ablating the effect of holding out different finetuning subsets and model checkpoints when fitting the emergence law. We present the absolute error between the maximum likelihood predicted point of emergence and the ground-truth. In brackets we include the 5th and 95th percentile of prediction errors produced by our MCMC posterior sampling. We consider fits where the maximum likelihood prediction is greater than 0.1 nats from the ground-truth to be failures and highlight these cases in red; otherwise we highlight in green. In the top row we present results for the fit obtained using all finetuning data amounts and model checkpoints. In the middle rows (e.g., \u201c-1 Smallest Subset\u201d to \u201cOnly Subset Sample 2\u201d), we present ablations in which we hold out various finetuning data subsets, so as to understand the effect of our data subset selection methodology on our predictions. Finally, in the bottom rows, we present ablations in which we hold out various model checkpoints, so as to understand how many checkpoints are needed to obtain good predictions (e.g., \u201cLast 6 Checkpoints\u201d to \u201c-4 Last Checkpoint\u201d). We describe each ablation in more detail in Appendix\u00a0A.6.", "description": "This table presents the results of ablations conducted on the emergence prediction method.  The main goal is to assess the impact of using different subsets of finetuning data and varying numbers of model checkpoints when fitting the emergence law. The table shows the absolute error between the predicted and actual emergence points, along with 5th and 95th percentile errors from MCMC sampling.  Errors larger than 0.1 nats are marked in red (indicating failure). The top row shows the baseline using all data, the middle rows show results with various amounts of held-out finetuning data to analyze data selection's impact, and the bottom rows vary the number of model checkpoints used for fitting to determine the minimum number needed for accurate predictions. More details on the ablations are in Appendix A.6.", "section": "5 Scaling Laws for Emergence Prediction"}, {"content": "| Task | Method | 5% | 10% | 25% | 50% | 75% | 90% | 95% | MLE | GT |\n|---|---|---|---|---|---|---|---|---|---|---|\n| GSM8K | MCMC | 1.813 | 1.852 | 1.900 | 1.937 | 1.970 | 1.992 | 2.003 | 2.006 | 1.984 |\n|  | Bootstrap | 1.978 | 1.984 | 1.995 | 2.007 | 2.021 | 2.031 | 2.036 |  |  |\n| MMLU | MCMC | 1.825 | 1.828 | 1.837 | 1.847 | 1.858 | 1.866 | 1.869 | 1.855 | 1.814 |\n|  | Bootstrap | 1.818 | 1.825 | 1.836 | 1.848 | 1.859 | 1.867 | 1.871 |  |  |\n| CSQA | MCMC | 1.781 | 1.810 | 1.821 | 1.829 | 1.835 | 1.840 | 1.843 | 1.830 | 1.827 |\n|  | Bootstrap | 1.723 | 1.736 | 1.815 | 1.835 | 1.846 | 1.857 | 1.863 |  |  |\n| CoLA | MCMC | 1.712 | 1.724 | 1.742 | 1.761 | 1.779 | 1.795 | 1.804 | 1.769 | 1.833 |\n|  | Bootstrap | 1.738 | 1.746 | 1.758 | 1.770 | 1.782 | 1.791 | 1.798 |  |  |\n| MMLU C4 V1 | MCMC | 2.207 | 2.221 | 2.241 | 2.246 | 2.255 | 2.259 | 2.261 | 2.254 | 2.226 |\n|  | Bootstrap | 2.183 | 2.200 | 2.216 | 2.228 | 2.238 | 2.246 | 2.250 |  |  |\n| MMLU C4 V2 | MCMC | 2.264 | 2.275 | 2.289 | 2.306 | 2.310 | 2.316 | 2.320 | 2.311 | 2.318 |\n|  | Bootstrap | 2.249 | 2.257 | 2.272 | 2.284 | 2.296 | 2.305 | 2.311 |  |  |\n| APPS | MCMC | 1.324 | 1.332 | 1.344 | 1.357 | 1.370 | 1.380 | 1.386 | 1.361 | \u2014 |\n|  | Bootstrap | 1.285 | 1.304 | 1.330 | 1.352 | 1.370 | 1.385 | 1.393 |  |  |", "caption": "Table 3: Comparing emergence prediction uncertainty estimates obtained via MCMC and bootstrapping. On each task, we present seven a range of percentiles for the point of emergence in terms of pretraining loss for each distribution. We also present the maximum likelihood prediction (\u201cMLE\u201d), and the ground-truth (\u201cGT\u201d) point of emergence. We see that both methods generally produce similar distributions. In the top section we present the uncertainties for each task used in Section\u00a06.2. In the middle we include uncertainties for the data quality experiments in Section\u00a07.1. \u201cMMLU C4 V1\u201d refers to the OpenLLaMA V1 fit and \u201cMMLU C4 V2\u201d refers to the V2 fit. At the bottom, we include uncertainties for the APPS experiment in Section\u00a07.2.", "description": "This table compares two methods for estimating the uncertainty of emergence predictions: Markov Chain Monte Carlo (MCMC) and bootstrapping.  For each task (MMLU, GSM8K, CSQA, CoLA, and APPS), it shows the 5th, 10th, 25th, 50th, 75th, 90th, and 95th percentiles of the emergence point's pretraining loss, as determined by each method. The maximum likelihood estimate (MLE) and the ground truth are also provided for comparison. The results demonstrate that both methods generally produce similar uncertainty estimates. The table is organized into three sections: the first shows results for the tasks in Section 6.2, the second shows results for the data quality experiments in Section 7.1, and the third presents the results for the APPS experiment in Section 7.2.  The 'MMLU C4 V1' and 'MMLU C4 V2' rows refer to the OpenLLaMA model versions used.", "section": "6 Evaluating the Emergence Law"}]