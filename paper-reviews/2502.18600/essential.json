{"importance": "This paper introduces a new prompting strategy that **reduces computational costs and latency without sacrificing accuracy**, thus offering practical benefits for real-world LLM applications. CoD offers a middle ground between CoT and standard prompting, allowing for **more efficient resource utilization and faster response times**. It aligns LLMs with human-like reasoning, paving the way for future research in minimalist reasoning strategies.", "summary": "CoD: LLMs think faster by writing less! A novel prompting strategy cuts costs and latency while maintaining reasoning accuracy.", "takeaways": ["Chain of Draft (CoD) is a novel prompting strategy that aligns more closely with human reasoning by prioritizing efficiency and minimalism.", "CoD maintains or improves accuracy compared with Chain of Thought, while significantly reducing token usage and latency.", "CoD can achieve significantly reduced latency and cost without sacrificing accuracy."], "tldr": "**LLMs like Chain-of-Thought (CoT) improve reasoning**, but demand more computational resources and verbose outputs. This contrasts with human problem-solving, which captures essential insights with concise drafts. The discrepancy motivates this paper to pursue a more efficient strategy to align with human reasoning.\n\nThis paper introduces **Chain of Draft (CoD), a novel strategy** that mimics human thought processes by generating concise intermediate reasoning outputs. Results show CoD matching/surpassing CoT in accuracy, cutting token use to 7.6%, reducing cost/latency across tasks.", "affiliation": "Zoom Communications", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2502.18600/podcast.wav"}