[{"heading_title": "Skill Stitching", "details": {"summary": "**Skill stitching** is crucial for humanoid robots to perform complex tasks. The paper highlights the challenges in smoothly transitioning between skills like navigation and manipulation, **requiring precise pose adjustments** to avoid failures. A vision-language model, or a similar connector, is proposed to bridge the gap between high-level plans and low-level skill execution. The connector enhances decision-making and coordination to improve task success and efficiency. This integration facilitates **real-time adaptation**, better task sequencing, and improved robustness in dynamic environments. Skill coordination leads to successful completion of complicated tasks in real-world scenarios."}}, {"heading_title": "VLM Connector", "details": {"summary": "The VLM Connector serves as a crucial bridge, **translating FM plans into actionable skills**. By grounding abstract language plans in real-time visual input, it enhances the robot's adaptability and robustness. **Key functions include grounding FM plans, closed-loop navigation**, and improving transitions between navigation and manipulation. It leverages visual understanding and object detection to inform skill selection. The VLM's rapid inference capabilities and pose adjustment improve the initialization states for subsequent manipulations, **reducing compounding errors** and enhancing overall task success with greater navigation efficiency. This approach allows the robot to perceive surroundings, adapt to unexpected obstacles, and coordinate locomotion and manipulation to tackle complex, long-horizon tasks in dynamic environments."}}, {"heading_title": "Active Vision", "details": {"summary": "The research paper highlights the significant role of **active vision** in enhancing a humanoid robot's capabilities. Traditional fixed camera setups impose limitations on both navigation and manipulation tasks. By contrast, **Being-0, equips the humanoid with an actuated neck and binocular RGB cameras**, enabling it to dynamically adapt its field of view. This dynamic adjustment is crucial for tasks requiring both broad environmental awareness during navigation and precise object localization for manipulation. The system leverages VLM to estimate the relative position and trigger locomotion skills, allowing robot can search the target in 3D space.  The **integration of an active camera** consistently achieves high success rates, showcasing superior performance in tasks where visual adaptability is essential. This approach, therefore, significantly contributes to the robot's dexterity and robustness in complex, real-world environments."}}, {"heading_title": "FM + Skills", "details": {"summary": "Combining Foundation Models (**FMs**) with robotic skills holds immense potential but faces challenges. **FMs** excel at high-level planning but can lack real-time responsiveness needed for complex robotic tasks. The efficiency and precision of **FMs** directly control robots are often compromised. Directly connecting FMs with skills often leads to issues, particularly for humanoid robots due to their unstable locomotion. Humanoid robots' unpredictable movements necessitate continuous adjustments, exceeding the processing capabilities of existing **FMs** and compounding errors. The inherent instability of humanoid robots requires **FM** to continuously react and adjust, adding an additional layer of complexity. "}}, {"heading_title": "Limited FM", "details": {"summary": "**Limited FMs in Robotics**: The paper highlights challenges when directly using large, general-purpose Foundation Models (FMs) like GPT-40 for humanoid robots. **Instability and poor 3D understanding** lead to inefficiency. High inference times make real-time adaptation difficult. This motivates exploring smaller, specialized models, like the VLM-based Connector, which can perform grounded planning. It also calls for finding a lightweight design in model architecture to optimize resource allocation."}}]