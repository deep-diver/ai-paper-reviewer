{"references": [{" publication_date": "2021", "fullname_first_author": "Anurag Arnab", "paper_title": "ViViT: A video vision transformer", "reason": "This paper introduces ViViT, a video vision transformer, a crucial component in the MuVi architecture.  Its ability to efficiently process video data and extract relevant temporal and semantic information is vital for the model's performance.  The authors' choice to use ViViT as the backbone highlights its leading-edge capabilities in video understanding.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This paper describes the latent diffusion model, which is fundamental to MuVi's audio generation component. The authors' adaptation of this model to music generation highlights the state-of-the-art capabilities in high-fidelity audio generation, ensuring high quality in the model's output.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "reason": "This paper introduces classifier-free diffusion guidance which is crucial for MuVi's generation.  The approach enhances the generation process by improving the model's ability to generate high-quality music while maintaining the balance between diversity and fidelity.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA: Open and efficient foundation language models", "reason": "This paper introduces LLaMA, a crucial component in MuVi's music generation component.  Its efficiency and open nature enable the model to generate high-quality music while maintaining efficiency.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP, introduced in this paper, is a fundamental component of MuVi's visual processing.  Its ability to generate image features rich in semantic space is crucial for aligning the generated music with the video's visual content.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jade Copet", "paper_title": "Simple and controllable music generation", "reason": "This paper introduces MusicGen, a key component in MuVi's music generation.  Its ability to generate high-quality music with control over style and genre ensures flexibility and high-fidelity in the generated audio.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Yaron Lipman", "paper_title": "Flow matching for generative modeling", "reason": "This paper proposes a novel approach to generative modeling based on flow matching.  The authors' adoption of this model to music generation enhances the quality and efficiency of the generated audio, making MuVi more efficient and high-performing.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "This paper presents a scalable diffusion model with transformers, which is crucial for MuVi's music generation. Its scalability is important for efficient processing and generation of high-quality music.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Chuang Gan", "paper_title": "Foley Music: Learning to generate music from videos", "reason": "This is a seminal work in video-to-music generation which is relevant to MuVi's approach to generate music from videos, as it highlights one of the pioneering techniques in the field.  MuVi improves upon the approach by addressing rhythmic synchronization and dynamic content changes.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Kun Su", "paper_title": "V2Meow: Meowing to the visual beat via video-to-music generation", "reason": "This paper is highly relevant to MuVi because it presents a state-of-the-art approach to V2M generation, which is built upon by MuVi.  MuVi's contributions are mainly in improving rhythmic synchronization and handling dynamic content changes, which are key limitations addressed in this paper.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Zejiang Hou", "paper_title": "MILAN: Masked Image Pretraining on Language Assisted Representation", "reason": "This paper introduces a masked image pre-training method that utilizes textual information to generate image representations, an approach that can be adopted for visual processing in MuVi. Its ability to generate semantically rich features is crucial for semantic alignment in the model.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Ye Zhu", "paper_title": "Quantized GAN for complex music generation from dance videos", "reason": "This work is relevant to MuVi due to its focus on music generation from videos, although limited to dance videos.  MuVi extends this by addressing the broader challenge of generating music for general video content, improving upon this work by handling more complex video semantics and dynamic changes.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Dosovitskiy Alexey", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This paper introduces the Vision Transformer (ViT), which is a foundational model used in MuVi. Its contribution to visual processing in MuVi is essential, enabling the model to effectively extract and process visual features from the input video frames.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Dmitry Bogdanov", "paper_title": "The MTG-Jamendo dataset for automatic music tagging", "reason": "This paper describes the MTG-Jamendo dataset, a crucial component in MuVi's experimental setup. The dataset is used for training and evaluating the music generation component, providing a large amount of data for model learning and assessment.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Andrea Agostinelli", "paper_title": "MusicLM: Generating music from text", "reason": "MusicLM, introduced in this paper, is relevant to MuVi because it shows the state-of-the-art in text-to-music generation.  This is important for the in-context learning in MuVi, which leverages this work to improve its ability to generate music in response to specific input.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Zhan Tong", "paper_title": "VideoMAE: Masked autoencoders are data-efficient learners for self-supervised video pre-training", "reason": "VideoMAE, introduced in this paper, is the backbone of MuVi's visual processing component. Its effectiveness in processing and extracting relevant features from videos makes it a crucial component in the overall system, improving upon previous methods by enhancing the accuracy and efficiency of visual feature extraction.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Simian Luo", "paper_title": "Diff-foley: Synchronized video-to-audio synthesis with diffusion models", "reason": "This paper is closely related to MuVi because it explores video-to-audio synthesis, which is very similar to video-to-music generation.  Although focusing on audio and using a different architecture, the core ideas of contrastive learning and diffusion models are directly applicable to MuVi's approach to generate music.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Kinyugo Maina", "paper_title": "MSANII: High fidelity music synthesis on a shoestring budget", "reason": "This paper provides a highly efficient method for music synthesis, which is directly relevant to MuVi's design choice of using a flow-matching-based music generator.  The efficiency of this method reduces the computational cost and improves the overall performance of MuVi.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Benjamin Elizalde", "paper_title": "CLAP: Learning audio concepts from natural language supervision", "reason": "This work focuses on the use of contrastive learning for learning audio concepts from natural language, which is highly relevant to MuVi.  MuVi adapts the contrastive learning approach to incorporate both visual and audio data for better synchronization and alignment, resulting in superior performance.", "section_number": 4}, {" publication_date": "2017", "fullname_first_author": "A Vaswani", "paper_title": "Attention is all you need", "reason": "This paper introduces the Transformer architecture, which is the core of MuVi's DiT.  Its effectiveness in handling sequential data is essential for the model's ability to generate music that accurately aligns with the video content, surpassing previous approaches that lack the capacity to handle the complexity and length of musical sequences effectively.", "section_number": 3}]}