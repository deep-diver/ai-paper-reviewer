[{"figure_path": "2410.12957/tables/table_8_0.html", "caption": "Table 1: Results of different visual encoders and adaptors. The bold numbers represent the best result of that column, and the underlined numbers represent the second best. \"Softmax\" and \"Sigmoid\" represent the Softmax and Sigmoid aggregation strategies, \u201cAttention\u201d means the attention pooling strategy, and \"Average\" and \u201cCLS\" indicate average pooling and pooling with the CLS token.", "description": "The table presents the performance comparison of different visual encoders and visual adaptor strategies on various metrics including FAD, KL, IS, FD, BCS, BHS, SIM, MOS-Q and MOS-A.", "section": "4.2 RESULTS OF VIDEO-TO-MUSIC GENERATION"}, {"figure_path": "2410.12957/tables/table_9_0.html", "caption": "Table 2: Results of several V2M systems.", "description": "Table 2 presents a comparison of several video-to-music generation systems, evaluating their performance using various metrics including FAD, KL, IS, FD, BCS, BHS, SIM, MOS-Q, and MOS-A.", "section": "4.2 RESULTS OF VIDEO-TO-MUSIC GENERATION"}, {"figure_path": "2410.12957/tables/table_9_1.html", "caption": "Table 3: Results of in-context learning (ICL).", "description": "Table 3 presents a comparison of the performance metrics for MuVi with and without in-context learning, showing the impact of incorporating a music prompt on the generated music's quality and alignment with the video.", "section": "4.2 RESULTS OF VIDEO-TO-MUSIC GENERATION"}, {"figure_path": "2410.12957/tables/table_10_0.html", "caption": "Table 4: Results of different settings of pre-training. PT(DiT) indicates whether the DiT is pre-trained unconditionally with music; CL stands for basic contrastive learning; TS and RR stand for the involvement of negative samples constructed from temporal shift and random replacement, respectively.", "description": "Table 4 presents the ablation study results showing the impact of different pre-training settings on the performance of the MuVi model.", "section": "4.4 ABLATION STUDY"}, {"figure_path": "2410.12957/tables/table_10_1.html", "caption": "Table 5: Results of different model sizes.", "description": "Table 5 presents the results of using different model sizes (small, base, and large) for video-to-music generation, evaluating performance metrics such as FAD, KL, IS, FD, BCS, BHS, SIM, MOS-Q, and MOS-A.", "section": "4.2 RESULTS OF VIDEO-TO-MUSIC GENERATION"}, {"figure_path": "2410.12957/tables/table_16_0.html", "caption": "Table 6: Model configurations of the DiT with different sizes.", "description": "Table 6 shows the hyperparameters of the diffusion transformer (DiT) model with different sizes (small, base, and large), including hidden dimension, number of layers, attention heads, and total number of parameters.", "section": "A ARCHITECTURE AND IMPLEMENTATION DETAILS"}, {"figure_path": "2410.12957/tables/table_18_0.html", "caption": "Table 7: Results of different video frame rates.", "description": "Table 7 presents the effects of different video frame rates on the performance of MuVi, comparing metrics such as FAD, KL, IS, FD, BCS, BHS, SIM, MOS-Q, and MOS-A.", "section": "4.2 RESULTS OF VIDEO-TO-MUSIC GENERATION"}]