[{"content": "| Dataset | Transparency |  |  | Versatility |  |  | Scale (TB) |\n|---|---|---|---|---|---|---|---|---|\n|  | Open Access | Open Code | Raw Data | Composite | Multilingual |  |  |\n| Refined Web [44] | \u2714(subset) | \u2717 | \u2717 | \u2717 | \u2717 |  | 2.8 |\n| FineWeb [43] | \u2714 | \u2714 | \u2717 | \u2717 | \u2717 |  | 93.4 |\n| FineWeb-EDU [43] | \u2714 | \u2714 | \u2717 | \u2717 | \u2717 |  | 8.8 |\n| C4 [46] | \u2714 | \u2714 | \u2717 | \u2717 | \u2717 |  | 0.3 |\n| mC4 [63] | \u2714 | \u2714 | \u2717 | \u2717 | \u2714 |  | 9.7 |\n| DCLM baseline [30] | \u2714 | \u2714 | \u2717 | \u2717 | \u2717 |  | 10.0 |\n| DCLM-Pool [30] | \u2714 | \u2714 | \u2714 | \u2717 | \u2714 |  | 340.0 |\n| Dolma v1.7 [52] | \u2714 | \u2714 | \u2717 | \u2714 | \u2717 |  | 4.5 |\n| Pile [17] | \u2714 | \u2714 | \u2717 | \u2714 | \u2717 |  | 0.8 |\n| SlimPajama [51] | \u2714 | \u2714 | \u2717 | \u2714 | \u2717 |  | 0.9 |\n| ROOTS [26, 27] | \u2714 | \u2714 | \u2717 | \u2714 | \u2714 |  | 1.6 |\n| RedPajama-V1 | \u2714 | \u2714 | \u2717 | \u2714 | \u2717 |  | 3.0 |\n| RedPajama-V2 | \u2714 | \u2714 | \u2714 | \u2717 | \u2714 |  | 270.0 |", "caption": "Table 1: Comparison of open pretraining Datasets along the dimensions of transparency, versatility, and scale.", "description": "This table compares several open-source large language model (LLM) pretraining datasets across three key aspects: transparency (whether the dataset's creation process and composition are openly documented and accessible), versatility (the range of sources and domains included in the dataset), and scale (the total size of the dataset in terabytes).  It provides a valuable overview of the characteristics of different publicly available datasets, aiding researchers in selecting appropriate datasets for their own work. Each dataset is assessed based on whether it has open access, open source code, and whether it contains raw data or only a composite, as well as if it is multilingual.", "section": "2 Related Work"}, {"content": "| Dataset Slice | Token Count |\n|---|---| \n| CommonCrawl | 878B |\n| C4 | 175B |\n| GitHub | 59B |\n| Books | 26B |\n| ArXiv | 28B |\n| Wikipedia | 24B |\n| StackExchange | 20B |\n| Total | 1.2T |", "caption": "Table 2: Token counts for the RedPajama-V1 dataset.", "description": "This table presents the token counts for each data source used in creating the RedPajama-V1 dataset, which is a reproduction of the LLaMA training dataset.  The total number of tokens across all sources is shown, along with the breakdown for each individual component: Common Crawl, C4, GitHub, Books, Wikipedia, Stack Exchange, and ArXiv. This provides a quantitative overview of the dataset's composition.", "section": "3 RedPajama-V1: An open Reproduction of the LLaMA Training Data"}, {"content": "|                     | All                     |                     `tail`                     |                      `head+middle`                     |       `head+middle` (dedupe)       |\n| :------------------ | :----------------------- | :---------------------------------- | :------------------------------------- | :----------------------------- |\n|                     | docs (B) | tokens (T) | docs (B) | tokens (T) | docs (B) | tokens (T) | docs (B) | tokens (T) |\n| English             | 87.5                   | 90.5                   | 63.0                   | 53.6                   | 24.5                   | 37.0                   | 14.5                   | 20.5                   |\n| German              | 8.6                    | 10.3                   | 5.9                    | 6.2                    | 2.7                    | 4.1                    | 1.9                    | 3.0                    |\n| French              | 6.7                    | 8.5                    | 4.5                    | 4.8                    | 2.2                    | 3.7                    | 1.6                    | 2.7                    |\n| Spanish             | 6.9                    | 9.5                    | 4.7                    | 5.6                    | 2.3                    | 3.9                    | 1.8                    | 2.8                    |\n| Italian             | 3.5                    | 4.7                    | 2.4                    | 2.7                    | 1.2                    | 1.9                    | 0.9                    | 1.5                    |\n| Total               | 113.3                  | 123.7                  | 80.5                   | 73.0                   | 32.8                   | 50.7                   | 20.8                   | 30.4                   |", "caption": "Table 3: Document and token counts for each partition and language of the RPv2 dataset.", "description": "This table presents a detailed breakdown of the RedPajama-V2 (RPv2) dataset, categorized by language and data partition.  It shows the number of documents (in billions) and tokens (in trillions) within each partition (head, middle, tail, and the combined head+middle). The head+middle partition also includes a deduplicated count, representing the number of unique documents after removing duplicates.  This allows for a comprehensive understanding of the dataset's size and composition across different languages and quality levels.", "section": "4 RedPajama-V2"}, {"content": "| Task | Type | Random | Metric | Agg. BM-Eval |\n|---|---|---|---|---|\n| ANLI [40] | Natural language inference | 25.0 | `acc` |  |\n| ARC-c [13] | Natural language inference | 25.0 | `acc_norm` |  |\n| ARC-e [13] | Natural language inference | 25.0 | `acc_norm` | \u2714 |\n| Winogrande [48] | Coreference resolution | 50.0 | `acc` | \u2714 |\n| Hellaswag [64] | Sentence completion | 25.0 | `acc_norm` | \u2714 |\n| LAMBADA [42] | Sentence completion | 0.0 | `acc` | \u2714 |\n| CoQA [47] | Conversational QA | 0.0 | `F1` | \u2714 |\n| MMLU [20] | Multiple-choice QA | 25.0 | `acc` | \u2714 |\n| OpenbookQA [38] | Multiple-choice QA | 25.0 | `acc_norm` | \u2714 |\n| PIQA [5] | Multiple-choice QA | 50.0 | `acc_norm` | \u2714 |\n| PubMedQA [23] | Multiple-choice QA | 33.3 | `acc` | \u2714 |\n| SciQ [60] | Multiple-choice QA | 25.0 | `acc_norm` | \u2714 |\n| SocialIQA [50] | Multiple-choice QA | 25.0 | `acc` |  |\n| TruthfulQA [33] | Multiple-choice QA | 25.0 | `acc` |  |", "caption": "Table 4: Benchmarks used in our ablations. The column \u201cAgg. BM-Eval\u201d indicates whether the score is used in the aggregate scores reported in Tables\u00a05 and\u00a06.", "description": "This table lists the benchmarks used to evaluate the performance of language models trained on different subsets of the RedPajama-V2 dataset.  The benchmarks cover a range of natural language processing tasks, including natural language inference, coreference resolution, sentence completion, and question answering.  The \"Agg. BM-Eval\" column indicates which benchmark scores were included in the aggregated scores reported in Tables 5 and 6, which summarizes the overall performance across multiple benchmarks. This helps readers understand which tasks were considered most important in the overall evaluation.", "section": "4 RedPajama-V2"}, {"content": "| Dataset | Deduplication |  | Rule-based |  | ML Heuristics |  |  | Agg. BM-Eval (\u2191) |  | Val-Perplexity (\u2193) |  | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | Exact | Fuzzy | C4 | Gopher | Classif. | DSIR | PPL | Avg. | Norm. Avg. | Rank-Score | Pile | Paloma |\n| C4 |  |  |  |  |  |  |  | 35.8 | 0.140 | 0.472 | 29.5 | 39.5 |\n| Dolma-v1.7 CC |  |  |  |  |  |  |  | 36.0 | 0.140 | 0.511 | 21.4 | 38.3 |\n| FineWeb |  |  |  |  |  |  |  | 36.5 | 0.146 | 0.644 | 26.8 | 33.6 |\n| RefinedWeb |  |  |  |  |  |  |  | 37.9 | 0.165 | 0.650 | 19.1 | 32.8 |\n| RPv1-CC | \u2714(sharded) |  |  |  | \u2714 (Wiki-Ref.) |  |  | 35.6 | 0.127 | 0.461 | 18.7 | 31.5 |\n| RPv2 (2023-14) |  |  |  |  |  |  |  | 36.4 | 0.141 | 0.594 | 19.7 | 31.1 |\n| RPv2 (2023-14) | \u2714 |  |  |  |  |  |  | 36.2 | 0.138 | 0.472 | 19.5 | 39.9 |\n| RPv2 (2023-14) |  | \u2714 |  |  | \u2714 (full) |  |  | 37.6 | 0.160 | 0.700 | 24.9 | 34.5 |\n| RPv2 (2023-14) |  |  |  | \u2714 |  |  |  | 36.8 | 0.150 | 0.622 | 36.3 | 56.9 |\n| RPv2 (2023-14) |  | \u2714 |  |  | \u2714 (natlang) |  |  | 37.2 | 0.154 | 0.639 | 23.6 | 38.2 |\n| RPv2 (2023-14) |  | \u2714 |  |  | \u2714 (Rep.) |  |  | 37.5 | 0.158 | 0.633 | 20.4 | 36.0 |\n| RPv2 (9 Dumps) |  | \u2714 |  | \u2714 |  |  |  | 35.3 | 0.128 | 0.517 | 35.0 | 54.2 |\n| RPv2 (9 Dumps) |  | \u2714 |  | \u2714 | \u2714 (full) |  |  | 36.7 | 0.149 | 0.556 | 43.8 | 63.9 |\n| RPv2 (9 Dumps) |  | \u2714 |  | \u2714 | \u2714 (Rep.) | \u2714 (Palm-mix) |  | 35.9 | 0.138 | 0.439 | 44.3 | 89.9 |\n| RPv2 (9 Dumps) |  | \u2714 |  | \u2714 | \u2714 (Rep.) | \u2714 (Palm-mix) |  | 35.9 | 0.139 | 0.483 | 43.8 | 67.1 |\n| RPv2 (9 Dumps) |  | \u2714 |  | \u2714 | \u2714 (natlang) | \u2714 (Palm-mix) |  | 36.7 | 0.152 | 0.550 | 41.8 | 67.9 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 (line-filter) | \u2714 (natlang) | \u2714 (Palm-mix) |  |  | 36.4 | 0.144 | 0.539 | 32.4 | 52.9 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules |  | \u2714 (Wiki-Ref.) |  | Pwiki>30 | 35.8 | 0.130 | 0.467 | 18.5 | 39.7 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules + Gopher-Rep. |  | \u2714 (Wiki-Ref.) |  | Pwiki>30 | 35.9 | 0.133 | 0.500 | 19.8 | 45.8 |", "caption": "Table 5: \nEvaluations for the 468M parameter LM for different dataset filters and other SOTA web datasets. The Benchmark scores are aggregated from the benchmarks outlined in Table\u00a03, using (1) the average accuracy, (2) the Rank-Score, and (3) the normalized average score. The best score is indicated in bold underlined font, the second-best is bolded, and the third is in italics underlined.", "description": "This table presents a performance comparison of a 468M parameter language model trained on various datasets.  The datasets include different versions of the RedPajama dataset filtered using various techniques, alongside other state-of-the-art open web datasets.  The model's performance is evaluated across several NLP benchmarks. The results are summarized using three metrics: average accuracy, Rank-Score, and a normalized average score.  The best, second-best, and third-best performing datasets for each metric are highlighted to facilitate comparison.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Fuzzy Deduplication | Rule-based C4 | Rule-based Gopher | Rule-based Palm Classif. | Rule-based Wiki-Ref Classif. | Rule-based Avg. | Rule-based Norm. Avg. | ML Heuristics Rank-Score | ML Heuristics Pile | ML Heuristics Paloma | Agg. BM-Eval (\u2191) | Val-Perplexity (\u2193) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| RefinedWeb |  |  |  |  |  |  |  | 52.0 | 34.0 | 0.139 | 10.7 | 17.7 |\n| RPv2 (full) | \u2714 |  | \u2714 |  | \u2714 |  |  | 50.0 | 31.1 | 0.106 | 13.6 | 20.8 |\n| RPv2 (full) | \u2714 | \u2714 | \u2714(natlang) | \u2714 | \u2714 |  |  | 47.9 | 29.4 | 0.089 | 22.2 | 30.7 |", "caption": "Table 6: \nAggregated evaluations for the 1.6B parameter LM for different datasets. The Benchmark scores are aggregated from the benchmarks outlined in Table\u00a04, using (1) the average accuracy, (2) the Rank-Score, and (3) the normalized average score.", "description": "Table 6 presents a performance comparison of a 1.6B parameter Language Model (LM) trained on various datasets.  The table shows aggregated benchmark scores, calculated using three metrics derived from the benchmarks listed in Table 4. These metrics are the average accuracy across benchmarks, the Rank-Score (a measure of ranking performance), and a normalized average score. The datasets used are compared in terms of their performance using these three metrics. The table is useful for understanding how data filtering techniques and dataset composition affect the overall performance of the LM. ", "section": "4 RedPajama-V2"}, {"content": "| Model | Lambada (acc) | Hellaswag (acc_norm) | Winogrande (acc) | Piqa (acc) | Avg. | HELM avg. |\n|---|---|---|---|---|---|---|\n| GPT-Neo | 0.6223 | 0.5579 | 0.5769 | 0.7219 | 0.6197 | 0.3570 |\n| Pythia-2.8B | 0.6466 | 0.5933 | 0.6006 | 0.7399 | 0.6451 | 0.3770 |\n| Pythia-2.8B-dedup | **0.6524** | 0.5941 | 0.5848 | 0.7404 | 0.6429 | - |\n| RedPajama-INCITE-Base-3B-v1 | 0.6541 | **0.6317** | **0.6322** | **0.7470** | **0.6662** | **0.4060** |", "caption": "Table 7: Results for RedPajama-INCITE-Base-3B-v1 on a subset of lm-evaluation-harness (Zero-Shot) and HELM, compared to models with similar parameter counts. The top-scoring model for each benchmark is highlighted in bold font.", "description": "This table presents a comparative analysis of the RedPajama-INCITE-Base-3B-v1 language model's performance against other models with similar parameter counts across various benchmarks, including both zero-shot and few-shot evaluations from the lm-evaluation-harness and HELM.  The results showcase RedPajama-INCITE-Base-3B-v1's strengths and weaknesses relative to other open-source models. The top performing model for each benchmark is clearly highlighted.", "section": "3.2 The RedPajama-INCITE family of LLMs"}, {"content": "| Model | RedPajama 7B (Instruct) | Llama 7B | MPT 7B | Falcon 7B (Base) | GPT J | Falcon 7B (Instruct) | Pythia 7B | Dolly v2 | MPT 7B (Instruct) | Stablelm Alpha 7B |\n|---|---|---|---|---|---|---|---|---|---|---|\n| HELM-AVG | **0.492** | 0.472 | 0.444 | 0.441 | 0.431 | 0.417 | 0.407 | 0.400 | 0.396 | 0.393 | 0.288 |\n| MMLU - EM | **0.366** | 0.345 | 0.294 | 0.285 | 0.323 | 0.249 | 0.271 | 0.266 | 0.238 | 0.349 | 0.293 |\n| BoolQ - EM | 0.697 | 0.751 | 0.731 | **0.770** | 0.694 | 0.649 | 0.708 | 0.656 | 0.602 | 0.442 | 0.537 |\n| NarrativeQA - F1 | **0.623** | 0.524 | 0.541 | 0.549 | 0.512 | 0.545 | 0.381 | 0.427 | 0.441 | 0.220 | 0.218 |\n| NaturalQuestions (closed-book) - F1 | 0.229 | **0.297** | 0.284 | 0.289 | 0.258 | 0.156 | 0.192 | 0.141 | 0.133 | 0.247 | 0.077 |\n| NaturalQuestions (open-book) - F1 | **0.654** | 0.580 | 0.603 | 0.574 | 0.600 | 0.559 | 0.453 | 0.549 | 0.535 | 0.627 | 0.317 |\n| QuAC - F1 | 0.252 | 0.332 | 0.343 | 0.322 | 0.323 | 0.330 | 0.300 | 0.306 | 0.299 | **0.352** | 0.218 |\n| HellaSwag - EM | 0.698 | 0.747 | 0.754 | 0.732 | 0.702 | 0.663 | 0.690 | 0.653 | 0.692 | **0.763** | 0.421 |\n| OpenbookQA - EM | 0.488 | 0.574 | 0.540 | **0.546** | 0.504 | 0.514 | 0.498 | 0.496 | 0.516 | 0.532 | 0.394 |\n| TruthfulQA - EM | 0.226 | 0.297 | 0.186 | 0.206 | 0.205 | 0.199 | 0.203 | 0.225 | **0.250** | 0.188 | 0.209 |\n| MS MARCO (regular) - RR@10 | **0.391** | 0.252 | 0.161 | 0.169 | 0.135 | 0.152 | 0.225 | 0.159 | 0.160 | 0.161 | 0.110 |\n| MS MARCO (TREC) - NDCG@10 | **0.709** | 0.482 | 0.369 | 0.362 | 0.322 | 0.345 | 0.481 | 0.342 | 0.359 | 0.387 | 0.253 |\n| CNN/DailyMail - ROUGE-2 | 0.143 | **0.149** | 0.137 | 0.147 | 0.137 | 0.131 | 0.114 | 0.101 | 0.140 | 0.148 | 0.045 |\n| XSUM - ROUGE-2 | 0.101 | **0.127** | 0.107 | 0.116 | 0.114 | 0.096 | 0.071 | 0.079 | 0.074 | 0.101 | 0.037 |\n| IMDB - EM | 0.941 | 0.933 | 0.903 | 0.893 | 0.916 | **0.939** | 0.906 | 0.930 | 0.907 | 0.891 | 0.627 |\n| CivilComments - EM | **0.667** | 0.578 | 0.525 | 0.511 | 0.536 | 0.520 | 0.516 | 0.527 | 0.520 | 0.270 | 0.490 |\n| RAFT - EM | 0.682 | 0.583 | 0.618 | 0.586 | 0.611 | **0.619** | 0.498 | 0.542 | 0.466 | 0.616 | 0.368 |", "caption": "Table 8: HELM Benchmark results for RedPajama-INCITE-Base-7B-v1 and instruction tuned. The top-scoring model for each benchmark is highlighted in bold font.", "description": "This table presents the HELM benchmark results for two language models: the RedPajama-INCITE-Base-7B-v1 (a base, pretrained model) and its instruction-tuned counterpart.  For various NLP tasks, the table compares their performance to other leading open-source LLMs of similar size. The top-performing model for each benchmark is highlighted in bold font, allowing for a direct comparison of performance across different models on a range of evaluation metrics. ", "section": "3.2 The RedPajama-INCITE family of LLMs"}, {"content": "| Model | LM-eval-harness-AVG | arc_challenge (acc_norm) | arc_easy (acc) | boolq (acc) | copa (acc) | hellaswag (acc_norm) | lambada_openai (acc) | piqa (acc_norm) | winogrande (acc) |\n|---|---|---|---|---|---|---|---|---|---| \n| MPT 7B (Instruct) | **0.7195** | **0.4462** | **0.7218** | 0.7425 | **0.9000** | **0.7717** | 0.6918 | 0.8041 | 0.6780 |\n| Falcon 7B | 0.7161 | 0.4326 | 0.7096 | 0.7361 | 0.8600 | 0.7634 | **0.7467** | **0.8069** | 0.6732 |\n| MPT 7B | 0.7100 | 0.4215 | 0.7008 | **0.7486** | 0.8500 | 0.7626 | 0.7056 | 0.8052 | **0.6859** |\n| RedPajama 7B (Base) | 0.6882 | 0.3925 | 0.6923 | 0.707 | 0.880 | 0.7037 | 0.7143 | 0.7737 | 0.6417 |\n| Llama 7B | 0.6881 | 0.4147 | 0.5253 | 0.7315 | 0.8500 | 0.7620 | 0.7360 | 0.7810 | 0.7040 |\n| RedPajama 7B (Instruct) | 0.6858 | 0.4078 | 0.7159 | 0.6865 | 0.850 | 0.7103 | 0.6895 | 0.7699 | 0.6567 |\n| Falcon 7B (Instruct) | 0.6813 | 0.4283 | 0.6789 | 0.7089 | 0.8400 | 0.6978 | 0.6831 | 0.7856 | 0.6669 |\n| Dolly v2 | 0.6557 | 0.4027 | 0.6423 | 0.6502 | 0.8600 | 0.6896 | 0.6893 | 0.7486 | 0.6140 |\n| GPT-J | 0.6526 | 0.3660 | 0.6225 | 0.6544 | 0.8300 | 0.6625 | 0.6831 | 0.7617 | 0.6409 |\n| Pythia 7B | 0.6392 | 0.3532 | 0.6338 | 0.6446 | 0.7400 | 0.6588 | 0.6441 | 0.7671 | 0.6267 |\n| StableLM Alpha 7B | 0.5260 | 0.2705 | 0.4487 | 0.6006 | 0.7500 | 0.4122 | 0.6379 | 0.6736 | 0.5012 |", "caption": "Table 9: LM eval harness results for RedPajama-INCITE-Base-7B-v1 and instruction tuned model. The top-scoring model for each benchmark is highlighted in bold font.", "description": "Table 9 presents the results of evaluating the RedPajama-INCITE-Base-7B-v1 and its instruction-tuned counterpart on a range of benchmarks commonly used for language model evaluation.  The table compares the performance of these models against other prominent open-source language models, such as Llama-7B, Falcon-7B, and MPT-7B, highlighting their strengths and weaknesses across various tasks. The top-performing model for each benchmark is clearly indicated in bold.", "section": "3.2 The RedPajama-INCITE family of LLMs"}, {"content": "| Subset | Uncertainty | Decision |\n|---|---|---|\n| CommonCrawl | Which snapshots were used? | We use the first snapshot from 2019 to 2023. |\n|  | What classifier was used, and how was it constructed? | We use a fasttext classifier with unigram features and use 300k training samples. |\n|  | What threshold was used to classify a sample as high quality? | We set the threshold to match the token count reported in LLama. |\n| GitHub | Quality filtering heuristics | We remove any file<br>\u2022 with a maximum line length of more than 1000 characters.<br>\u2022 with an average line length of more than 100 characters.<br>\u2022 with a proportion of alphanumeric characters of less than 0.25.<br>\u2022 with a ratio between the number of alphabetical characters and the number of tokens of less than 1.5.<br>whose extension is not in the following set of whitelisted extensions: .asm, .bat, .cmd, .c, .h, .cs, .cpp, .hpp, .c++, .h++, .cc, .hh, .C, .H, .cmake, .css, .dockerfile, .f90, .f, .f03, .f08, .f77, .f95, .for, .fpp, .go, .hs, .html, .java, .js, .jl, .lua, .md, .markdown, .php, .php3, .php4, .php5, .phps, .phpt, .pl, .pm, .pod, .perl, .ps1, .psd1, .psm1, .py, .rb, .rs, .sql, .scala, .sh, .bash, .command, .zsh, .ts, .tsx, .tex, .vb, Dockerfile, Makefile, .xml, .rst, .m, .smali | \n| Wikipedia | Which Wikipedia dump was used? | We used the most recent at the time of data curation (2023-03-20). |\n| Books | How were the books deduplicated? | We use SimHash to perform near deduplication. |", "caption": "Table 10: Overview over the different uncertainties and decisions made during the construction of the RedPajama-V1 dataset.", "description": "This table details the ambiguities encountered during the recreation of the original LLaMA training dataset for the RedPajama-V1 project and the decisions made to address them.  It covers data sources like Common Crawl, GitHub, and Wikipedia, highlighting uncertainties in the original LLaMA dataset description regarding data selection criteria, processing techniques, and quality filtering methods. For each source, the table lists the uncertainties and the choices made by the RedPajama-V1 team to resolve those issues.", "section": "3 RedPajama-V1: An open Reproduction of the LLaMA Training Data"}, {"content": "| Annotation Tag | Description |\n|---|---| \n| ccnet_bucket | head, middle or tail bucket of the perplexity score |\n| ccnet_language_score | score of the language identification model |\n| ccnet_length | number of characters |\n| ccnet_nlines | number of lines |\n| ccnet_original_length | number of characters before line-level deduplication |\n| ccnet_original_nlines | number of lines before line-level deduplication |\n| ccnet_perplexity | perplexity of an LM trained on Wikipedia |", "caption": "Table 11: Quality signals originating from the CCNet pipeline\u00a0[61].", "description": "This table lists quality signals derived from the CCNet pipeline, a data processing framework used in creating the RedPajama-V2 dataset.  Each signal provides metadata about the text documents, such as the document's length, language, and perplexity score, helping to assess the quality of the web data.", "section": "4.1 Data Processing Steps"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1\">\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A4.T12.1.1.2.1\">Annotation Tag</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A4.T12.1.1.2.2\">Description</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A4.T12.1.1.2.3\">Reference(s)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.3.1\">rps_doc_curly_bracket</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.3.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.3.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.3.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.3.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.3.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.3.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio between the number of</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.3.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.3.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">occurrences of \u2019{\u2019 or \u2019}\u2019 and the</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.3.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.3.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">number of characters in the raw text.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.3.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.3.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.4.1\">rps_doc_frac_all_caps_words</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.4.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.4.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.4.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.4.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.4.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.4.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The fraction of words in the content that</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.4.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.4.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">only consist of uppercase letters. This is</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.4.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.4.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">based on the raw content.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.4.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.4.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib34\" title=\"\">34</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.5.1\">rps_doc_frac_lines_end_with_ellipsis</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.5.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.5.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.5.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.5.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.5.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.5.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The fraction of lines that end with an ellipsis,</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.5.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.5.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">where an ellipsis is defined as either</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.5.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.5.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">\"\u2026\" or \"U+2026\".</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.5.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.5.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.6.1\">rps_doc_frac_no_alph_words</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.6.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.6.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.6.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.6.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.6.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.6.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The fraction of words that contain</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.6.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.6.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">no alphabetical character.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.6.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.6.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.7.1\">rps_doc_lorem_ipsum</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.7.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.7.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.7.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.7.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.7.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.7.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio between the number of occurrences of</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.7.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.7.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">\u2019lorem ipsum\u2019 and the number of characters in the</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.7.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.7.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">content after normalisation.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.7.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.7.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.8.1\">rps_doc_mean_word_length</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.8.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.8.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.8.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.8.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.8.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.8.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The mean length of words in the content</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.8.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.8.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">after normalisation.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.8.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.8.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.9.1\">rps_doc_stop_word_fraction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.9.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.9.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.9.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.9.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.9.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.9.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio between the number of stop words</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.9.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.9.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">and the number of words in the document.</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.9.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.9.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Stop words are obtained from <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/6/stopwords-json\" title=\"\">https://github.com/6/stopwords-json</a>.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.9.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.9.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.10.1\">rps_doc_symbol_to_word_ratio</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.10.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.10.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.10.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.10.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.10.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.10.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio of symbols to words in the content. Symbols</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.10.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.10.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">are defined as U+0023 (#), \"\u2026\", and U+2026.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.10.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.10.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.11.1\">rps_doc_frac_unique_words</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.11.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.11.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.11.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.11.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.11.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.11.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The fraction of unique words in the content.</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.11.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.11.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">This is also known as the degeneracy of a</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.11.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.11.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">text sample. Calculated based on the</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.11.2.2.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.11.2.2.1.4.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">normalised content.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.11.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.11.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib34\" title=\"\">34</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.1.2\">rps_doc_unigram_entropy</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.1.1\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.1.1.2\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.1.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.1.1.1.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.1.1.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.1.1.1.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The entropy of the unigram distribution of the content.</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.1.1.1.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.1.1.1.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">This measures the diversity of the content and is computed using</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.1.1.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.1.1.1.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><math alttext=\"\\sum_{x}-\\frac{x}{n}\\cdot\\log(\\frac{1}{n})\" class=\"ltx_Math\" display=\"inline\" id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2\"><semantics id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2a\"><mrow id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.cmml\"><msub id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.cmml\"><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2.cmml\">\u2211</mo><mi id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3.cmml\">x</mi></msub><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1\" lspace=\"0em\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1.cmml\">\u2212</mo><mrow id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.cmml\"><mfrac id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.cmml\"><mi id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2.cmml\">x</mi><mi id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3.cmml\">n</mi></mfrac><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1\" lspace=\"0.222em\" rspace=\"0.222em\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1.cmml\">\u22c5</mo><mrow id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\"><mi id=\"A4.T12.1.1.1.1.1.1.1.1.m1.1.1\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.1.1.cmml\">log</mi><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2a\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\">\u2061</mo><mrow id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\"><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1.1\" stretchy=\"false\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\">(</mo><mfrac id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.cmml\"><mn id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2.cmml\">1</mn><mi id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3.cmml\">n</mi></mfrac><mo id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1.2\" stretchy=\"false\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2b\"><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3\"><minus id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1\"></minus><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2\"><csymbol cd=\"ambiguous\" id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2\">subscript</csymbol><sum id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2\"></sum><ci id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3\">\ud835\udc65</ci></apply><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3\"><ci id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1\">\u22c5</ci><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2\"><divide id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2\"></divide><ci id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2\">\ud835\udc65</ci><ci id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3\">\ud835\udc5b</ci></apply><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2\"><log id=\"A4.T12.1.1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.1.1\"></log><apply id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2\"><divide id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.1.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2\"></divide><cn id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2.cmml\" type=\"integer\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2\">1</cn><ci id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3.cmml\" xref=\"A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3\">\ud835\udc5b</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2c\">\\sum_{x}-\\frac{x}{n}\\cdot\\log(\\frac{1}{n})</annotation><annotation encoding=\"application/x-llamapun\" id=\"A4.T12.1.1.1.1.1.1.1.1.m1.2d\">\u2211 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT - divide start_ARG italic_x end_ARG start_ARG italic_n end_ARG \u22c5 roman_log ( divide start_ARG 1 end_ARG start_ARG italic_n end_ARG )</annotation></semantics></math>where the sum is taken over counts of</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.1.1.1.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.1.1.1.1.4.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">unique words in the normalised content.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.1.1.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.1.3\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.12.1\">rps_doc_word_count</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.12.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.12.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.12.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.12.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.12.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.12.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The number of words in the content after normalisation.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.12.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.12.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.13.1\">rps_lines_ending_with_terminal_punctution_mark</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.13.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.13.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.13.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.13.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.13.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.13.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Indicates whether a line ends with a terminal punctuation</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.13.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.13.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">mark. A terminal punctuation mark is defined as one of: \".\", \"!\", \"?\", \"\u201d\".</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.13.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.13.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.14.1\">rps_lines_javascript_counts</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.14.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.14.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.14.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.14.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.14.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.14.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The number of occurrences of the word \"javascript\" in each line.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.14.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.14.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.15.1\">rps_lines_num_words</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.15.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.15.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.15.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.15.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.15.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.15.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The number of words in each line. This is computed based on the</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.15.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.15.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">normalised text.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.15.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.15.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.16.1\">rps_lines_numerical_chars_fraction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.16.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.16.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.16.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.16.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.16.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.16.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio between the number of numerical</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.16.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.16.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">characters and total number of characters</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.16.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.16.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">in each line. This is based on the</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.16.2.2.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.16.2.2.1.4.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">normalised content.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.16.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.16.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.17.1\">rps_lines_start_with_bulletpoint</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.17.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.17.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.17.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.17.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Whether the lines that start with a bullet point symbol. The</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">following set of unicodes are considered a bullet point:</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+2022 (bullet point),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.4.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+2023 (triangular bullet point),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.5\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.5.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25B6 (black right pointing triangle),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.6\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.6.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25C0 (black left pointing triangle),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.7\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.7.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25E6 (white bullet point),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.8\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.8.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+2013 (en dash)</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.9\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.9.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25A0 (black square),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.10\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.10.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25A1 (white square),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.11\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.11.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25AA (black small square),</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.17.2.2.1.12\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.17.2.2.1.12.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">U+25AB (white small square).</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.17.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.17.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib43\" title=\"\">43</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib45\" title=\"\">45</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.18.1\">rps_lines_uppercase_letter_fraction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.18.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.18.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.18.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.18.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.18.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.18.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The ratio between the number of uppercase letters</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.18.2.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.18.2.2.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">and total number of characters in each line.</span></span>\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.18.2.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.18.2.2.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">This is based on the raw text.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.18.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T12.1.1.18.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib44\" title=\"\">44</a>]</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T12.1.1.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"A4.T12.1.1.19.1\">rps_doc_num_sentences</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"A4.T12.1.1.19.2\">\n<span class=\"ltx_text\" id=\"A4.T12.1.1.19.2.1\"></span><span class=\"ltx_text\" id=\"A4.T12.1.1.19.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A4.T12.1.1.19.2.2.1\">\n<span class=\"ltx_tr\" id=\"A4.T12.1.1.19.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A4.T12.1.1.19.2.2.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">The number of sentences in the content.</span></span>\n</span></span><span class=\"ltx_text\" id=\"A4.T12.1.1.19.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"A4.T12.1.1.19.3\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2411.12372v1#bib.bib46\" title=\"\">46</a>]</cite></td>\n</tr>\n</table>", "caption": "Table 12: Summary of quality signals which measure how much a document corresponds to natural language.", "description": "This table lists quality signals used to assess the natural language quality of text documents.  Each signal is described, indicating how it measures the extent to which text resembles human-written language rather than machine-generated or non-language content.  References to prior works which introduced each signal are included for further study.", "section": "4.1.2 Quality Signals"}, {"content": "| Annotation Tag | Description | Reference(s) |\n|---|---|---|\n| rps_doc_books_importance | Given a bag of 1,2-wordgram model trained on Books $p$, and a model trained on the source domain $q$, This is the logarithm of the ratio $p/q$. | [62] |\n| rps_doc_openwebtext_importance | Given a bag of 1,2-wordgram model trained on OpenWebText $p$, and a model trained on the source domain $q$, this is the logarithm of the ratio $p/q$. | [62] |\n| rps_doc_wikipedia_importance | Given a bag of 1,2-wordgram model trained on Wikipedia articles $p$, and a model trained on the source domain $q$, this is the logarithm of the ratio $p/q$. | [62] |\n| rps_doc_ml_wikiref_score | Fasttext classifier prediction for the document being a Wikipedia reference. This is the same fasttext model used in the RedPajama-1T dataset. Only applies to English data. | [57] |\n| rps_doc_ml_palm_score | Fasttext classifier prediction for the document being a Wikipedia article, OpenWebText sample or a RedPajama-V1 book. Only for English data. | [12], [16] |\n| rps_doc_ml_wikipedia_score | Fasttext classifier prediction for the document being a Wikipedia article. This is used for non-English data | - |", "caption": "Table 13: Quality signals based on ML heuristics.", "description": "This table lists quality signals derived from machine learning (ML) heuristics.  These signals are used to assess the quality of text documents by comparing them to reference datasets. Specifically, they measure how similar a document's textual characteristics are to those found in high-quality datasets such as Books, OpenWebText, and Wikipedia.", "section": "4.1.2 Quality Signals"}, {"content": "| Annotation Tag | Description | Reference(s) |\n|---|---|---|\n| rps_doc_frac_chars_dupe_10grams | The fraction of characters in duplicate word 10grams. | [43, 45] |\n| rps_doc_frac_chars_dupe_5grams | The fraction of characters in duplicate word 5grams. | [43, 45] |\n| rps_doc_frac_chars_dupe_6grams | The fraction of characters in duplicate word 6grams. | [43, 45] |\n| rps_doc_frac_chars_dupe_7grams | The fraction of characters in duplicate word 7grams. | [43, 45] |\n| rps_doc_frac_chars_dupe_8grams | The fraction of characters in duplicate word 8grams. | [43, 45] |\n| rps_doc_frac_chars_dupe_9grams | The fraction of characters in duplicate word 9grams. | [43, 45] |\n| rps_doc_frac_chars_top_2gram | The fraction of characters in the top word 2gram. | [43, 45] |\n| rps_doc_frac_chars_top_3gram | The fraction of characters in the top word 3gram. | [43, 45] |\n| rps_doc_frac_chars_top_4gram | The fraction of characters in the top word 4gram. | [43, 45] |", "caption": "Table 14: Summary of Quality signals which measure how repetitive text is.", "description": "This table lists quality signals that assess the repetitiveness of text.  It provides a comprehensive overview of various metrics used to quantify text repetition within the RedPajama-V2 dataset. Each row represents a specific signal, offering its name, a description explaining how the signal measures repetitiveness (e.g., the fraction of characters within duplicate n-grams), and its reference to the source where it was initially described.", "section": "4.1 Data Processing Steps"}, {"content": "| Annotation Tag | Description | Reference(s) |\n|---|---|---|\n| rps_doc_ldnoobw_words | The number of sequences of words that are contained in the List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words blocklist. The blocklist is obtained from https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words. | [46] |\n| rps_doc_ut1_blacklist | A categorical id corresponding to the list of categories of the domain of the document. Categories are obtained from https://dsi.ut-capitole.fr/blacklists/ | [44] |", "caption": "Table 15: Summary of Quality signals which are based on the content of the text, measuring toxicity.", "description": "This table lists quality signals in the RedPajama-V2 dataset that assess the toxicity of text documents.  It details the specific annotation tags used, a description of what each tag measures (e.g., presence of offensive words), and the sources or methods used to calculate these metrics.", "section": "4.1.2 Quality Signals"}, {"content": "| Cluster Topics | Document |\n|---|---| \n| (broad - medium - specific) |  | \n| Election - Health (2) - COVID Testing | immediately moving to the Purple Tier. This is the most restrictive level in the State\u2019s effort to control the spread of COVID-19. Businesses and residents must comply with the Purple Tier restrictions by Tuesday, Nov. 17. To determine restrictions by industry, business and activity, visit: https://covid19.ca.gov/safer-economy/ Read the full news release here: www.gov.ca.gov/2020/11/16/governor-newsom-announces-new-immediate-actions-to-curb-covid-19-transmission/ Watch the Governor\u2019s press conference during which he made the announcement today here: www.facebook.com/CAgovernor/videos/376746553637721 According to County of Orange officials, schools that have not already opened must continue with remote classes and cannot reopen in-person. Read the County\u2019s release here: https://cms.ocgov.com/civicax/filebank/blobdload.aspx?BlobID=118441 The California Department of Public Health has also issued a travel advisory encouraging Californians to stay home or in their region and avoid non-esse | \n| Religion/Spirituality - Gaming - Gaming (3) | Top 100 Employers, and one of Canada\u2019s Top Employers for Young People multiple years running! At Ubisoft Toronto, we look for people who are excited to create the future of games in one of the most diverse cities in the world. We believe that embracing our differences helps us build stronger creative teams and develop better games for all players. We are an equal-opportunity employer and welcome applications from all interested candidates. We strongly encourage applications from Indigenous people, racialized people, neurodivergent people, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities. We are committed to providing reasonable accommodation for people with disability upon request. If this sounds like your kind of studio, what are you waiting for? Apply to join us now! We thank you for your interest, however, only those candidates selected for an interview will be contacted. No agencies please. Senior Game Design | \n| Education - Golf - Rotary Meetings | what\u2019s happening. Conversely, some people rely on the newsletter. Thus, the more avenues to inform people, the better. attendance at many social functions is poor, possibly due to the limited advertising reach. In practical terms, it means that social functions may be advertised in the OOC newsletter (current practice) the schedule, as is done for outdoor activities such as hikes the OOC\u2019s Facebook group As when social functions are advertised in the newsletter, the person organizing the social function can choose how much location information to provide, especially if it is to be held at someone\u2019s residence. OOC bylaw Article 3, Section 9 (f) states (highlighting added) (f) Social Coordinator: Shall be responsible for coordinating all social events for Club members only, and for preparing a schedule of these outings, not to be advertised to non-members. The executive voted to amend this statement by removing the limitation per Paragraph 3 of \"Article 5 - Amending Formula\" of the Const | ", "caption": "Table 16: Examples of documents and corresponding cluster topics from Nomic Atlas\u00a0[41].", "description": "This table presents examples of documents from the RedPajama-V2 dataset and their corresponding cluster topics as determined by Nomic Atlas.  It showcases the diversity of topics covered in the dataset and how Nomic Atlas groups similar documents together based on semantic meaning.", "section": "4.3 Dataset Ablations"}, {"content": "| Cluster Topics | Document |\n|---|---| \n| (broad - medium - specific) |  |\n| Online Privacy - Privacy Policy - Contracts | shall be governed by the laws of the Federal Republic of Germany under exclusion of the UN Convention on the International Sale of Goods (CISG), without prejudice to any mandatory conflict of laws and consumer protection provisions. 11.2 If the Customer is an entrepreneur according to Sec. 14 German Civil Code (\u201cBGB\u201d), a legal person under public law or a special fund under public law the courts at the place of business of the vendor shall have exclusive jurisdiction in respect of all disputes arising out of or in connection with the relevant contract. 11.3 In the event that one or more provisions of the contract should be or become invalid or unenforceable, the validity of the remaining provisions shall not be affected thereby. The invalid or unenforceable provision shall be deemed to be replaced - as existent - with statutory provisions. In case of an unacceptable rigor to one of the parties, the contract shall be deemed invalid as a whole. 11.4 In case of deviations of these General | \n| Religion/Spirituality - Film/Movie - Movie | Movie of Nelson Mandela\u2019s life premieres in South Africa Nov. 04 - Stars Idris Elba and Naomie Harris attend the premiere of \"Mandela: Long Walk to Freedom,\" based on the autobiography of anti-apartheid icon Nelson Mandela. Matthew Stock reports. | \n| Election - Election (2) - Healthcare (4) | McAuliffe revived that language as an amendment to the budget. He also called on the General Assembly to immediately convene a special joint committee that had been created to assess the impact that repealing the ACA would have had on Virginia. The legislature will gather April 5 to consider the governor\u2019s amendments and vetoes, but leaders said Monday that McAuliffe\u2019s new budget language stands no better chance this time. In a joint statement, the Republican leadership of the House of Delegates said expanding Medicaid would lead to increased costs and eventually blow a hole in the state budget. \u201cThe lack of action in Washington has not changed that and in fact, the uncertainty of federal health policy underscores the need to be cautious over the long term,\u201d the leaders, including House Speaker William J. Howell (R-Stafford) and the man selected to replace him as speaker when he retires next year, Del. Kirk Cox (R-Colonial Heights), said via email. \u201cVirginians can barely afford our cu |", "caption": "Table 17: Examples of documents and corresponding cluster topics from Nomic Atlas\u00a0[41].", "description": "This table presents example documents from the RedPajama-V2 dataset and their corresponding cluster topics as determined by Nomic Atlas, a tool for topic modeling and clustering.  It shows how Nomic Atlas groups similar documents based on semantic meaning, illustrating the diversity of topics within the RedPajama-V2 dataset.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Deduplication | Deduplication | Rule-based | Rule-based | ML Heuristics | ML Heuristics | ML Heuristics | Natural Language Inference | Natural Language Inference | Natural Language Inference | Coref. Res. | Sentence Completion | Sentence Completion |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | Exact | Fuzzy | C4 | Gopher | Classif. | DSIR | PPL | ANLI | ARC-c | ARC-e | Winogrande | Hellaswag | LAMBADA |\n| C4 |  |  |  |  |  |  |  | 33.8 | 22.0 | 37.0 | 51.9 | **32.9** | 15.5 |\n| Dolma-v1.7 CC |  |  |  |  |  |  |  | 33.5 | **24.0** | 38.3 | 49.6 | 32.3 | 17.3 |\n| FineWeb |  |  |  |  |  |  |  | 34.0 | 23.4 | 37.7 | 51.8 | **32.8** | 18.1 |\n| RefinedWeb |  |  |  |  |  |  |  | 32.8 | 22.6 | 38.3 | 51.9 | 31.6 | 17.8 |\n| RPv1-CC |  |  |  |  | \u2713 (Wiki-Ref.) |  |  | 33.9 | 22.4 | 37.5 | **52.6** | 29.7 | *19.0* |\n| RPv2 (2023-14) |  |  |  |  |  |  |  | 33.3 | 22.2 | 38.5 | 52.4 | 31.5 | 18.2 |\n| RPv2 (2023-14) | \u2713 |  |  |  |  |  |  | 33.9 | 22.1 | 38.1 | 50.6 | 31.3 | 18.0 |\n| RPv2 (2023-14) |  | \u2713 |  |  |  |  |  | 34.1 | 22.3 | 38.3 | 52.2 | 32.1 | 18.7 |\n| RPv2 (2023-14) |  | \u2713 | \u2713 |  |  |  |  | 33.4 | 22.7 | 38.9 | 51.1 | 32.4 | 17.5 |\n| RPv2 (2023-14) |  | \u2713 |  | \u2713 (natlang) |  |  | Wiki-middle | 33.4 | **24.2** | 37.7 | 49.8 | 33.1 | **19.2** |\n| RPv2 (2023-14) |  | \u2713 |  | \u2713 (Rep.) |  |  | Wiki-middle | 34.2 | 23.1 | 37.4 | 50.8 | 32.5 | 18.5 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 |  |  |  |  | *34.3* | 23.5 | *38.6* | 51.5 | 32.0 | 17.2 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 | \u2713 (full) |  |  |  | 33.5 | 23.3 | 38.4 | 50.2 | **32.8** | 16.8 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 | \u2713 (Rep.) |  | \u2713 (Palm-mix) |  | 33.8 | 21.9 | 38.0 | *52.5* | 32.0 | 17.3 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 | \u2713 (Rep.) | \u2713 (Palm-mix) |  |  | **34.6** | 23.3 | *38.6* | 52.2 | *32.7* | 16.4 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 | \u2713 (natlang) | \u2713 (Palm-mix) |  |  | **34.8** | 23.0 | **39.2** | **53.0** | 32.3 | 16.9 |\n| RPv2 (9 Dumps) |  | \u2713 | \u2713 (line-filter) | \u2713 (natlang) | \u2713 (Palm-mix) |  |  | 33.7 | 22.9 | 38.5 | 50.9 | 32.3 | **19.9** |\n| RPv2 (9 Dumps) |  | \u2713 | custom-rules |  | \u2713 (Wiki-Ref.) |  | P<sub>wiki</sub>>30 | 33.2 | 23.0 | 37.9 | 49.6 | 30.1 | 18.7 |\n| RPv2 (9 Dumps) |  | \u2713 | custom-rules + Gopher-Rep |  | \u2713 (Wiki-Ref.) |  | P<sub>wiki</sub>>30 | 33.0 | *23.8* | **38.9** | 50.5 | 30.0 | 18.9 |", "caption": "Table 18: \nEvaluations for the 468M parameter LM for different dataset filters and other strong web datasets. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.", "description": "This table presents the performance of a 468M parameter language model trained on various datasets.  The datasets include different versions of the RedPajama dataset filtered using various rules (exact deduplication, fuzzy deduplication, rule-based filtering, Gopher filtering, classification-based filtering, ML heuristic filtering, and DSIR filtering), along with other established web datasets such as C4, Dolma-v1.7 CC, FineWeb, and RefinedWeb. The model's performance is evaluated on a selection of downstream tasks (Natural Language Inference, Coreference Resolution, Sentence Completion), with the top-performing dataset for each metric highlighted.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Deduplication |  | Rule-based |  | ML Heuristics |  |  | MMLU | Stem | Humanities | Other | Social Sciences |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| C4 |  |  |  |  |  |  |  | 24.9 | 26.4 | 24.1 | 25.8 | 23.4 |\n| Dolma-v1.7 CC |  |  |  |  |  |  |  | 26.0 | 27.8 | 24.5 | 26.2 | 26.1 |\n| FineWeb |  |  |  |  |  |  |  | 26.2 | 25.4 | 25.1 | 25.8 | 29.3 |\n| RefinedWeb |  |  |  |  |  |  |  | 24.8 | 23.9 | 23.7 | 26.5 | 25.6 |\n| RPv1-CC |  |  |  |  | \u2714 (Wiki-Ref.) |  |  | 25.1 | 25.1 | 23.7 | 24.0 | 28.5 |\n| RPv2 (2023-14) |  |  |  |  |  |  |  | 26.3 | 26.7 | 25.3 | 24.1 | 29.6 |\n| RPv2 (2023-14) | \u2714 |  |  |  |  |  |  | 26.4 | 26.8 | 25.3 | 25.2 | 28.8 |\n| RPv2 (2023-14) |  | \u2714 |  | \u2714 (full) |  |  |  | 27.0 | 28.8 | 24.8 | 25.6 | 30.0 |\n| RPv2 (2023-14) |  | \u2714 | \u2714 |  |  |  |  | 25.4 | 27.8 | 24.1 | 26.1 | 24.1 |\n| RPv2 (2023-14) |  | \u2714 |  | \u2714 (natlang) |  |  | Wiki-middle | 26.1 | 27.4 | 25.2 | 24.6 | 27.7 |\n| RPv2 (2023-14) |  | \u2714 |  | \u2714 (Rep.) |  |  | Wiki-middle | 25.5 | 24.3 | 25.2 | 27.8 | 24.8 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  |  |  |  | 26.3 | 28.3 | 25.3 | 25.8 | 26.6 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 | \u2714 (full) |  |  |  | 25.6 | 28.0 | 25.1 | 24.9 | 24.4 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 | \u2714 (Rep.) |  | \u2714 (Palm-mix) |  | 24.4 | 26.9 | 23.7 | 24.8 | 22.7 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 | \u2714 (Rep.) | \u2714 (Palm-mix) |  |  | 24.9 | 26.1 | 24.0 | 26.3 | 23.8 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 | \u2714 (natlang) | \u2714 (Palm-mix) |  |  | 25.3 | 27.8 | 24.2 | 25.4 | 24.5 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 (line-filter) | \u2714 (natlang) | \u2714 (Palm-mix) |  |  | 25.1 | 27.5 | 24.0 | 25.0 | 24.4 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules |  | \u2714 (Wiki-Ref.) |  |  $P_{wiki} > 30$ | 27.0 | 27.9 | 25.1 | 26.0 | 30.0 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules + Gopher-Rep |  | \u2714 (Wiki-Ref.) |  |  $P_{wiki} > 30$ | 25.9 | 25.8 | 24.3 | 27.1 | 27.2 |", "caption": "Table 19: \nEvaluations in the 5-shot setting on MMLU and subtasks for the 468M parameter LM. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.", "description": "This table presents the results of a 5-shot evaluation on the Massive Multitask Language Understanding (MMLU) benchmark and its subtasks.  The evaluation uses a language model with 468 million parameters.  Multiple datasets were used to train the model, and the table shows the performance achieved on each dataset.  The top-performing dataset for each metric is highlighted.  The highlighting differentiates between the top performer, the second-best, and the third-best datasets.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Deduplication |  | Rule-based |  | ML Heuristics |  |  | CoQA | OpenbookQA | PIQA | PubMedQA | SciQ | SocialIQA | TruthfulQA |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | Exact | Fuzzy | C4 | Gopher | Classif. | DSIR | PPL |  |  |  |  |  |  |  |\n| C4 |  |  |  |  |  |  |  | 3.8 | **30.2** | *64.4* | 46.0 | 51.7 | *33.4* | 33.3 |\n| Dolma-v1.7 CC |  |  |  |  |  |  |  | 5.2 | 28.2 | **65.3** | 42.6 | 55.2 | 31.6 | 33.2 |\n| FineWeb |  |  |  |  |  |  |  | 9.0 | **29.4** | **64.5** | 41.4 | 54.3 | 32.4 | 33.5 |\n| RefinedWeb |  |  |  |  |  |  |  | **13.2** | 28.6 | *64.4* | *52.2* | **56.4** | 32.8 | 33.3 |\n| RPv1-CC |  |  |  |  |  | \u2714 (Wiki-Ref.) |  | 11.6 | 25.4 | 57.3 | 40.6 | **56.7** | 33.1 | **33.9** |\n| RPv2 (2023-14) |  |  |  |  |  |  |  | **12.5** | *29.2* | 61.6 | 40.8 | 53.0 | 32.9 | 31.4 |\n| RPv2 (2023-14) | \u2714 |  |  |  |  |  |  | 11.8 | 27.6 | 61.1 | 43.6 | 53.7 | 32.5 | 33.4 |\n| RPv2 (2023-14) |  | \u2714 |  |  |  |  |  | 11.3 | 28.8 | 62.8 | 51.0 | 53.9 | 32.6 | 32.6 |\n| RPv2 (2023-14) |  | \u2714 | \u2714 |  |  |  |  | 5.8 | 28.8 | 63.4 | 49.6 | 54.7 | 36.6 | *33.8* |\n| RPv2 (2023-14) |  | \u2714 |  |  |  |  | Wiki-middle | 11.3 | 28.4 | 63.5 | 49.6 | 53.6 | 32.8 | 33.4 |\n| RPv2 (2023-14) |  | \u2714 |  |  |  |  | Wiki-middle | *11.9* | **29.4** | 63.1 | **52.6** | 53.4 | 32.5 | 31.6 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  |  |  |  | 6.6 | 29.0 | 62.0 | 36.2 | 53.7 | 33.2 | **34.3** |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  |  |  |  | 5.8 | 28.6 | 62.8 | *51.2* | 54.8 | **34.4** | 31.2 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  |  |  |  | 6.0 | **29.4** | 61.6 | 45.4 | 52.2 | *33.4* | 33.1 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  | \u2714 (Palm-mix) |  |  | 5.4 | **29.4** | 62.5 | 45.0 | 51.7 | **34.0** | 33.7 |\n| RPv2 (9 Dumps) |  | \u2714 | \u2714 |  | \u2714 (Palm-mix) |  |  | 4.9 | 28.0 | 62.9 | **52.8** | 52.0 | 33.0 | 33.6 |\n| RPv2 (9 Dumps) |  | \u2714 | *\u2714 (line-filter)* | *\u2714 (natlang)* | \u2714 (Palm-mix) |  |  | 6.4 | 27.0 | 63.2 | 47.8 | 52.9 | 32.8 | 32.0 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules |  | \u2714 (Wiki-Ref.) |  | P<sub>wiki</sub>>30 | 10.0 | 27.8 | 59.6 | 41.2 | *55.8* | 33.3 | 32.0 |\n| RPv2 (9 Dumps) |  | \u2714 | custom-rules + Gopher-Rep |  | \u2714 (Wiki-Ref.) |  | P<sub>wiki</sub>>30 | 9.3 | 28.0 | 59.2 | 43.4 | 54.9 | 33.0 | 33.3 |", "caption": "Table 20: \nEvaluations on multiple choice tasks for the 468M parameter LM. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.", "description": "This table presents the results of an evaluation of various datasets used to train a 468M parameter language model on multiple-choice question answering tasks.  The evaluation metrics include accuracy scores across several different benchmarks.  The table highlights the top-performing datasets for each metric, indicating the top dataset with bolded underlined text, the second-best with bolded text, and the third-best with italicized underlined text.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Fuzzy Deduplication | Rule-based C4 | Rule-based Gopher | ANLI | ARC-c | ARC-e | Winogrande | Hellaswag | LAMBADA | Coref. Res. | Sentence Completion | \n|---|---|---|---|---|---|---|---|---|---|---|---| \n| RefinedWeb |  |  |  |  |  | 33.6 | 26.9 | 51.7 | 54.4 | 55.8 | 47.9 | \n| RPv2 (full) | \u2714 |  | \u2714 | WikiRef |  | 32.4 | 27.9 | 51.3 | 56.4 | 47.4 | 47.4 | \n| RPv2 (full) | \u2714 | \u2714 | \u2714(natlang) | Palm-Mix |  | 33.6 | 28.7 | 52.4 | 54.5 | 53.1 | 42.9 | ", "caption": "Table 21: Downstream task accuracy for a 1.6B LM trained on different datasets over 350B tokens.", "description": "This table presents the results of downstream task accuracy achieved by a 1.6 billion parameter language model (LM) trained on various datasets.  Each dataset was used to train the LM using 350 billion tokens. The table displays the accuracy scores across several downstream tasks, including various Natural Language Inference (NLI) tasks, Coreference Resolution, and Sentence Completion tasks.  The results offer a comparison of how different datasets impact the performance of the LM on various tasks.", "section": "D.5 Evaluations for the 1.6B Parameter Models"}, {"content": "| Dataset | Fuzzy Deduplication | Rule-based C4 | Rule-based Gopher | Rule-based MMLU | ML Heuristics | MMLU MMLU | MMLU Stem | MMLU Humanities | MMLU Other | MMLU Social Sciences |\n|---|---|---|---|---|---|---|---|---|---|---|\n| RefinedWeb |  |  |  |  | 25.3 | 24.9 | 24.9 | 27.0 | 24.7 |\n| RPv2 (full) | \u2714 |  | \u2714 | WikiRef | 25.2 | 26.0 | 26.7 | 23.9 | 23.3 |\n| RPv2 (full) | \u2714 | \u2714 | \u2714 (natlang) | Palm-Mix | 24.7 | 25.7 | 25.4 | 23.8 | 23.4 |", "caption": "Table 22: Evaluations in the 5-shot setting on MMLU and subtasks for the 1.6B parameter LM.", "description": "This table presents the results of a 5-shot evaluation of a 1.6B parameter language model on the Massive Multitask Language Understanding (MMLU) benchmark and its subtasks.  The evaluation measures the model's performance across various subdomains of MMLU, providing insights into its capabilities in different areas of knowledge and reasoning.  The table likely compares the model's performance across different dataset variations, allowing for analysis of how data composition influences model capabilities.", "section": "4.3 Dataset Ablations"}, {"content": "| Dataset | Fuzzy Deduplication | Rule-based C4 | Rule-based Gopher | ML Heuristics WikiRef | CoQA | OpenbookQA | PIQA | PubMedQA | SciQ | SocialIQA | TruthfulQA |\n|---|---|---|---|---|---|---|---|---|---|---|---| \n| RefinedWeb |  |  |  |  | 47.4 | 31.6 | 73.8 | 57.0 | 75.3 | 41.0 | 36.6 |\n| RPv2 (full) | \u2714 |  | \u2714 |  | 43.7 | 32.6 | 67.4 | 55.6 | 72.7 | 40.4 | 36.9 |\n| RPv2 (full) | \u2714 | \u2714 | \u2714(natlang) | Palm-Mix | 22.1 | 32.2 | 71.3 | 55.2 | 71.0 | 42.2 | 35.7 |", "caption": "Table 23: \nEvaluations on multiple choice tasks for the 1.6B parameter LM.", "description": "This table presents the performance of a 1.6B parameter language model on various multiple-choice question answering benchmarks.  The model was trained on the RedPajama-V2 dataset, with different filtering techniques applied to the data. The results show how different data filtering methods affect the model's performance across a variety of tasks and datasets.  The table includes a variety of metrics to evaluate performance, such as accuracy and F1-score, allowing for a comprehensive assessment of the model's capabilities under diverse conditions.", "section": "4.3 Dataset Ablations"}]