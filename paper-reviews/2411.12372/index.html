<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>RedPajama: an Open Dataset for Training Large Language Models &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="RedPajama: an Open Dataset for Training Large Language Models &#183; HF Daily Paper Reviews by AI"><meta name=description content="RedPajama, two massive open-source datasets, are released for training LLMs, improving transparency and facilitating the development of high-performing open-source models."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ Stanford University,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="RedPajama: an Open Dataset for Training Large Language Models"><meta property="og:description" content="RedPajama, two massive open-source datasets, are released for training LLMs, improving transparency and facilitating the development of high-performing open-source models."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-11-19T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-19T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ Stanford University"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/cover.png"><meta name=twitter:title content="RedPajama: an Open Dataset for Training Large Language Models"><meta name=twitter:description content="RedPajama, two massive open-source datasets, are released for training LLMs, improving transparency and facilitating the development of high-performing open-source models."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"RedPajama: an Open Dataset for Training Large Language Models","headline":"RedPajama: an Open Dataset for Training Large Language Models","abstract":"RedPajama, two massive open-source datasets, are released for training LLMs, improving transparency and facilitating the development of high-performing open-source models.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2411.12372\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2024","dateCreated":"2024-11-19T00:00:00\u002b00:00","datePublished":"2024-11-19T00:00:00\u002b00:00","dateModified":"2024-11-19T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ Stanford University"],"mainEntityOfPage":"true","wordCount":"7625"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About This Project">About</p></a><a href=/ai-paper-reviewer/2025-02-11/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-11s>2025-02-11</p></a><a href=/ai-paper-reviewer/2025-02-12/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-12s>2025-02-12</p></a><a href=/ai-paper-reviewer/2025-02-13/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-13s>2025-02-13</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Paper Reviews by AI">Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About This Project">About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-11/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-11s>2025-02-11</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-12/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-12s>2025-02-12</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-13/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-13s>2025-02-13</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Paper Reviews by AI">Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2411.12372/cover_hu_cf2df924842ac23c.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2411.12372/>RedPajama: an Open Dataset for Training Large Language Models</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">RedPajama: an Open Dataset for Training Large Language Models</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-19T00:00:00+00:00>19 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span>7625 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">36 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2411.12372/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2411.12372/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-stanford-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Stanford University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu_97e7d424fadd1c26.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#open-llm-datasets>Open LLM Datasets</a></li><li><a href=#redpajama-v1v2>RedPajama-V1/V2</a></li><li><a href=#ablation-studies>Ablation Studies</a></li><li><a href=#data-quality-signals>Data Quality Signals</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#open-llm-datasets>Open LLM Datasets</a></li><li><a href=#redpajama-v1v2>RedPajama-V1/V2</a></li><li><a href=#ablation-studies>Ablation Studies</a></li><li><a href=#data-quality-signals>Data Quality Signals</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2411.12372</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Maurice Weber et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-11-20</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2411.12372 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2411.12372 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/redpajama-an-open-dataset-for-training-large target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2411.12372/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large language models (LLMs) are rapidly advancing but suffer from a lack of transparency in data sources and model development processes. Existing high-performing models often lack publicly available datasets, hindering open-source development. This paper aims to address this issue by providing extensive data and insights into building better LLMs.</p><p>The researchers introduce RedPajama, comprising two datasets: RedPajama-V1, which replicates the LLaMA training dataset, and RedPajama-V2, a massive web-only dataset augmented with quality metadata. They conduct various experiments using these datasets to evaluate the relationship between data quality and LLM performance, showcasing how RedPajama can advance the development of <strong>transparent and high-performing</strong> LLMs. The availability of these datasets and accompanying analysis encourages broader participation in developing better LLMs.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-a7c9e613680bd057fd34071e232ef831></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-a7c9e613680bd057fd34071e232ef831",{strings:[" RedPajama-V1 and RedPajama-V2, two large-scale datasets, are released to promote transparency and accelerate open-source LLM development. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-066c702b7efb4af04820165e76c942f4></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-066c702b7efb4af04820165e76c942f4",{strings:[" RedPajama-V2 features web data with quality signals, enabling researchers to curate better datasets. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-46fa41527f42b78151929e3e01c88e02></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-46fa41527f42b78151929e3e01c88e02",{strings:[" Analyses and ablation studies demonstrate how quality signals can be used effectively to improve model performance. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is important because it addresses the lack of transparency and data availability in large language model (LLM) development. By releasing two massive, open datasets ‚Äì RedPajama-V1 (a reproduction of the LLaMA dataset) and RedPajama-V2 (a web-only dataset with quality signals) ‚Äì and providing detailed analysis and ablation studies, it empowers researchers to develop more transparent and performant open-source LLMs. It also facilitates further research into optimal data composition and filtering techniques for LLMs, setting a new standard for future high-quality web datasets. This significantly impacts the LLM field by fostering collaboration, accelerating open-source model development and promoting the understanding of the relationship between training data and model performance.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/rp-ecosystem-v2.2.png alt></figure></p><blockquote><p>üîº This figure illustrates the various open-source large language models (LLMs) that have been trained using the RedPajama datasets. RedPajama-V1 and RedPajama-V2 are shown as the foundational datasets. Several downstream LLMs, such as OpenELM, OLMo, Snowflake&rsquo;s Arctic, and the RedPajama-INCITE models, are depicted as having been trained with data from these datasets, highlighting the contribution of RedPajama to the open-source LLM ecosystem. The figure also shows SlimPajama, a cleaned and deduplicated version of RedPajama-V1.</p><details><summary>read the caption</summary>Figure 1: The ecosystem around the RedPajama datasets. RedPajama has provided pretraining data for multiple open-source LLMs, including OpenELM¬†[36], OLMo¬†[19], Snowflake‚Äôs Arctic¬†[54] and RedPajama-INCITE. SlimPajama is a cleaned and deduplicated version of RedPajama-V1.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Transparency</th><th></th><th></th><th>Versatility</th><th></th><th></th><th>Scale (TB)</th><th></th></tr></thead><tbody><tr><td></td><td>Open Access</td><td>Open Code</td><td>Raw Data</td><td>Composite</td><td>Multilingual</td><td></td><td></td><td></td></tr><tr><td>Refined Web [44]</td><td>‚úî(subset)</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td></td><td>2.8</td><td></td></tr><tr><td>FineWeb [43]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td></td><td>93.4</td><td></td></tr><tr><td>FineWeb-EDU [43]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td></td><td>8.8</td><td></td></tr><tr><td>C4 [46]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td></td><td>0.3</td><td></td></tr><tr><td>mC4 [63]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úó</td><td>‚úî</td><td></td><td>9.7</td><td></td></tr><tr><td>DCLM baseline [30]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td></td><td>10.0</td><td></td></tr><tr><td>DCLM-Pool [30]</td><td>‚úî</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td></td><td>340.0</td><td></td></tr><tr><td>Dolma v1.7 [52]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td>‚úó</td><td></td><td>4.5</td><td></td></tr><tr><td>Pile [17]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td>‚úó</td><td></td><td>0.8</td><td></td></tr><tr><td>SlimPajama [51]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td>‚úó</td><td></td><td>0.9</td><td></td></tr><tr><td>ROOTS [26, 27]</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td>‚úî</td><td></td><td>1.6</td><td></td></tr><tr><td>RedPajama-V1</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td>‚úó</td><td></td><td>3.0</td><td></td></tr><tr><td>RedPajama-V2</td><td>‚úî</td><td>‚úî</td><td>‚úî</td><td>‚úó</td><td>‚úî</td><td></td><td>270.0</td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares several open-source large language model (LLM) pretraining datasets across three key aspects: transparency (whether the dataset&rsquo;s creation process and composition are openly documented and accessible), versatility (the range of sources and domains included in the dataset), and scale (the total size of the dataset in terabytes). It provides a valuable overview of the characteristics of different publicly available datasets, aiding researchers in selecting appropriate datasets for their own work. Each dataset is assessed based on whether it has open access, open source code, and whether it contains raw data or only a composite, as well as if it is multilingual.</p><details><summary>read the caption</summary>Table 1: Comparison of open pretraining Datasets along the dimensions of transparency, versatility, and scale.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Open LLM Datasets<div id=open-llm-datasets class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#open-llm-datasets aria-label=Anchor>#</a></span></h4><p>The landscape of open large language model (LLM) datasets is complex and dynamic. <strong>Accessibility</strong> is a major hurdle; while some datasets are publicly available, many remain proprietary, hindering open research and development. <strong>Transparency</strong> is another key issue; the composition and curation methods of many datasets are opaque, making it difficult to evaluate their impact and potential biases. <strong>Scale</strong> presents a third challenge, as high-performance LLMs require massive datasets, demanding significant computational resources and expertise to curate. Therefore, initiatives like the RedPajama project are critical for fostering progress in open LLMs by addressing these challenges; providing large, openly licensed datasets with associated metadata and quality signals is crucial. This enhances <strong>reproducibility</strong>, <strong>comparability</strong>, and allows researchers to effectively curate subsets better suited to specific tasks and avoiding potential biases. The long-term goal is a collaborative ecosystem where open datasets drive innovation and democratize access to this transformative technology.</p><h4 class="relative group">RedPajama-V1/V2<div id=redpajama-v1v2 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#redpajama-v1v2 aria-label=Anchor>#</a></span></h4><p>The RedPajama project introduces two significant open-source datasets for large language model (LLM) training: RedPajama-V1 and RedPajama-V2. <strong>RedPajama-V1 serves as a meticulously recreated replication of the LLaMA training dataset</strong>, offering transparency and accessibility to researchers. However, <strong>RedPajama-V2 represents a substantial departure, focusing exclusively on a massive web-only dataset</strong>. Unlike V1, it prioritizes scale and versatility, providing raw, unfiltered web data exceeding 100 trillion tokens along with comprehensive quality signals. These signals empower researchers to curate high-quality subsets, facilitating the development and evaluation of novel data filtering techniques. The difference in approach between the two highlights a shift from precise replication to a broader, more flexible resource for LLM development.</p><h4 class="relative group">Ablation Studies<div id=ablation-studies class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ablation-studies aria-label=Anchor>#</a></span></h4><p>Ablation studies, in the context of large language model (LLM) research, are crucial for understanding the contribution of different dataset components or model features to overall performance. They involve systematically removing or altering specific aspects of the system and observing the impact on downstream tasks. In the RedPajama paper, ablation studies likely investigated the effects of various data filtering techniques on model quality. <strong>The results would highlight the importance of specific data characteristics</strong> and the effectiveness of different data cleaning strategies. By removing certain data subsets (e.g., low-quality web data or duplicated content), researchers could assess the impact on benchmark scores, perplexity, and other relevant metrics. Such analyses would reveal which data sources and filtering methods are most vital for training high-performing and robust LLMs. This is particularly important because <strong>open-source LLMs often face challenges in data quality</strong>. The ablation studies&rsquo; findings could guide future dataset creation and curation efforts for open-source LLM projects, providing valuable insights into how data composition and quality control significantly influence model performance and generalization.</p><h4 class="relative group">Data Quality Signals<div id=data-quality-signals class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#data-quality-signals aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;Data Quality Signals&rsquo; is crucial for training robust large language models (LLMs). The paper highlights the importance of <strong>not just quantity but also quality</strong> of data. Instead of filtering out noisy web data, the authors propose enriching the dataset with various quality signals. These signals provide crucial metadata, allowing for more nuanced curation. This approach prioritizes <strong>versatility</strong>, enabling users to build datasets tailored to specific needs, rather than prescribing a single &lsquo;perfect&rsquo; dataset. <strong>Transparency</strong> is also key; making quality signals openly available fosters research into better data filtering methods. The use of multiple signals covering natural language, repetitiveness, content quality, and ML-based heuristics, ensures a multifaceted understanding of data quality. <strong>This strategy facilitates iterative dataset improvement</strong>, promoting the development of higher-performing and more reliable LLMs.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>Future research directions stemming from the RedPajama project are plentiful. <strong>Improving data filtering techniques</strong> is crucial, exploring more sophisticated methods beyond simple heuristics. This involves investigating advanced <strong>machine learning models for quality assessment</strong>, possibly incorporating multi-modal analysis to enhance filtering precision. <strong>Addressing biases and ethical concerns</strong> inherent in large language models trained on web data is also paramount; research on bias detection and mitigation strategies would significantly contribute to responsible development. Furthermore, the scalability of data processing and model training is a major challenge. Future work could focus on <strong>developing more efficient and sustainable data curation and training processes</strong>, particularly for handling datasets of this magnitude. Finally, investigation into the relationship between dataset diversity, quality signals, and downstream model performance warrants further study, ultimately guiding best practices for creating optimal LLMs.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/rp_incite.png alt></figure></p><blockquote><p>üîº Figure 2 presents a comparison of the RedPajama-INCITE-Base 3B model&rsquo;s performance against other open-source language models, namely Pythia and GPT-J, across a subset of tasks from the lm-evaluation-harness benchmark. The selected tasks were chosen to align with the evaluation performed in the original Pythia and GPT-J papers. This allows for a direct comparison of the RedPajama model to these established benchmarks. The figure provides a visual representation of the performance differences on each task, highlighting the relative strengths and weaknesses of the RedPajama model.</p><details><summary>read the caption</summary>Figure 2: RedPajama-INCITE-Base 3B results on a subset of lm-evaluation-harness. The tasks were selected according to the selection made to evaluate Pythia¬†[4] and GPT-J¬†[59]</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/document_counts.png alt></figure></p><blockquote><p>üîº This figure shows the chronological count of documents from the Common Crawl dataset for each snapshot, both before and after deduplication. The deduplication process starts with the most recent snapshot and proceeds sequentially to the oldest. The graph visually demonstrates how the number of documents changes over time as the deduplication process removes redundant entries. The x-axis represents the Common Crawl snapshots in chronological order, and the y-axis represents the number of documents.</p><details><summary>read the caption</summary>Figure 3: Chronological count of documents for each CommonCrawl snapshot before and after deduplication. Deduplication is performed sequentially, starting from the most recent snapshot and iterating until the oldest snapshot.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/quality_signals/ccnet_language_score.png alt></figure></p><blockquote><p>üîº This figure displays histograms visualizing the distributions of six quality metrics generated by the CCNet pipeline. These metrics offer insights into the characteristics of text data used to train large language models. The metrics shown represent various aspects of text quality, such as language identification score, text length (in characters and lines), and perplexity scores from a language model trained on Wikipedia. Understanding these distributions helps in assessing the quality and diversity of the training data and potentially informs data filtering strategies for improved model performance.</p><details><summary>read the caption</summary>Figure 4: Histograms for the quality signals computed by the CCNet¬†[61] pipeline.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/quality_signals/ccnet_length.png alt></figure></p><blockquote><p>üîº This figure displays histograms visualizing the distributions of several Machine Learning (ML)-based quality signals. These signals are used to evaluate the quality of text data within the RedPajama-V2 dataset. Each histogram represents a different quality metric, providing a visual representation of its frequency distribution. This allows for the assessment of the dataset&rsquo;s quality and facilitates informed decisions regarding data filtering and selection for downstream tasks. The specific metrics shown are detailed in Section 4.1.2 of the paper.</p><details><summary>read the caption</summary>Figure 5: Histograms for ML-based quality signals.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/quality_signals/ccnet_nlines.png alt></figure></p><blockquote><p>üîº This figure presents histograms visualizing the distributions of various natural language-based quality signals extracted from the RedPajama-V2 dataset. These signals help assess the quality and characteristics of text documents, such as the proportion of uppercase words, the frequency of unique words, and the presence of certain punctuation marks. The distributions provide insights into the nature and variability of the web data included in the dataset, highlighting potential issues such as the prevalence of non-natural language content or repetitive text.</p><details><summary>read the caption</summary>Figure 6: Histograms for Natural language based quality signals.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/quality_signals/ccnet_original_length.png alt></figure></p><blockquote><p>üîº This figure displays histograms visualizing the distribution of several quality metrics related to text repetitiveness within the RedPajama-V2 dataset. These metrics help assess the quality of the text data by quantifying the amount of repeated content. The histograms show how frequently different levels of repetitiveness occur across the dataset, offering valuable insights into the dataset&rsquo;s composition and potential biases arising from redundant information.</p><details><summary>read the caption</summary>Figure 7: Histograms for quality signals measuring the repetitiveness of text.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.12372/extracted/6009674/figures/quality_signals/ccnet_original_nlines.png alt></figure></p><blockquote><p>üîº This figure visualizes the topical clusters within the RedPajama-V2 dataset, specifically focusing on the 2021-04 snapshot&rsquo;s 2 million unfiltered documents. Nomic Atlas, a topic modeling tool, was used to analyze the data using gte-large-en-v1.5 embeddings. The visualization helps understand the thematic distribution and relationships within the vast dataset.</p><details><summary>read the caption</summary>Figure 8: Visualization of topical clusters appearing in the RedPajama-V2 dataset. The clusters are computed in Nomic Atlas¬†[41] based on gte-large-en-v1.5 embeddings for 2M documents of the unfiltered 2021-04 snapshot.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset Slice</th><th>Token Count</th></tr></thead><tbody><tr><td>CommonCrawl</td><td>878B</td></tr><tr><td>C4</td><td>175B</td></tr><tr><td>GitHub</td><td>59B</td></tr><tr><td>Books</td><td>26B</td></tr><tr><td>ArXiv</td><td>28B</td></tr><tr><td>Wikipedia</td><td>24B</td></tr><tr><td>StackExchange</td><td>20B</td></tr><tr><td>Total</td><td>1.2T</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the token counts for each data source used in creating the RedPajama-V1 dataset, which is a reproduction of the LLaMA training dataset. The total number of tokens across all sources is shown, along with the breakdown for each individual component: Common Crawl, C4, GitHub, Books, Wikipedia, Stack Exchange, and ArXiv. This provides a quantitative overview of the dataset&rsquo;s composition.</p><details><summary>read the caption</summary>Table 2: Token counts for the RedPajama-V1 dataset.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th style=text-align:left></th><th style=text-align:left>All</th><th style=text-align:left><code>tail</code></th><th style=text-align:left><code>head+middle</code></th><th style=text-align:left><code>head+middle</code> (dedupe)</th></tr></thead><tbody><tr><td style=text-align:left></td><td style=text-align:left>docs (B)</td><td style=text-align:left>tokens (T)</td><td style=text-align:left>docs (B)</td><td style=text-align:left>tokens (T)</td></tr><tr><td style=text-align:left>English</td><td style=text-align:left>87.5</td><td style=text-align:left>90.5</td><td style=text-align:left>63.0</td><td style=text-align:left>53.6</td></tr><tr><td style=text-align:left>German</td><td style=text-align:left>8.6</td><td style=text-align:left>10.3</td><td style=text-align:left>5.9</td><td style=text-align:left>6.2</td></tr><tr><td style=text-align:left>French</td><td style=text-align:left>6.7</td><td style=text-align:left>8.5</td><td style=text-align:left>4.5</td><td style=text-align:left>4.8</td></tr><tr><td style=text-align:left>Spanish</td><td style=text-align:left>6.9</td><td style=text-align:left>9.5</td><td style=text-align:left>4.7</td><td style=text-align:left>5.6</td></tr><tr><td style=text-align:left>Italian</td><td style=text-align:left>3.5</td><td style=text-align:left>4.7</td><td style=text-align:left>2.4</td><td style=text-align:left>2.7</td></tr><tr><td style=text-align:left>Total</td><td style=text-align:left>113.3</td><td style=text-align:left>123.7</td><td style=text-align:left>80.5</td><td style=text-align:left>73.0</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a detailed breakdown of the RedPajama-V2 (RPv2) dataset, categorized by language and data partition. It shows the number of documents (in billions) and tokens (in trillions) within each partition (head, middle, tail, and the combined head+middle). The head+middle partition also includes a deduplicated count, representing the number of unique documents after removing duplicates. This allows for a comprehensive understanding of the dataset&rsquo;s size and composition across different languages and quality levels.</p><details><summary>read the caption</summary>Table 3: Document and token counts for each partition and language of the RPv2 dataset.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Task</th><th>Type</th><th>Random</th><th>Metric</th><th>Agg. BM-Eval</th></tr></thead><tbody><tr><td>ANLI [40]</td><td>Natural language inference</td><td>25.0</td><td><code>acc</code></td><td></td></tr><tr><td>ARC-c [13]</td><td>Natural language inference</td><td>25.0</td><td><code>acc_norm</code></td><td></td></tr><tr><td>ARC-e [13]</td><td>Natural language inference</td><td>25.0</td><td><code>acc_norm</code></td><td>‚úî</td></tr><tr><td>Winogrande [48]</td><td>Coreference resolution</td><td>50.0</td><td><code>acc</code></td><td>‚úî</td></tr><tr><td>Hellaswag [64]</td><td>Sentence completion</td><td>25.0</td><td><code>acc_norm</code></td><td>‚úî</td></tr><tr><td>LAMBADA [42]</td><td>Sentence completion</td><td>0.0</td><td><code>acc</code></td><td>‚úî</td></tr><tr><td>CoQA [47]</td><td>Conversational QA</td><td>0.0</td><td><code>F1</code></td><td>‚úî</td></tr><tr><td>MMLU [20]</td><td>Multiple-choice QA</td><td>25.0</td><td><code>acc</code></td><td>‚úî</td></tr><tr><td>OpenbookQA [38]</td><td>Multiple-choice QA</td><td>25.0</td><td><code>acc_norm</code></td><td>‚úî</td></tr><tr><td>PIQA [5]</td><td>Multiple-choice QA</td><td>50.0</td><td><code>acc_norm</code></td><td>‚úî</td></tr><tr><td>PubMedQA [23]</td><td>Multiple-choice QA</td><td>33.3</td><td><code>acc</code></td><td>‚úî</td></tr><tr><td>SciQ [60]</td><td>Multiple-choice QA</td><td>25.0</td><td><code>acc_norm</code></td><td>‚úî</td></tr><tr><td>SocialIQA [50]</td><td>Multiple-choice QA</td><td>25.0</td><td><code>acc</code></td><td></td></tr><tr><td>TruthfulQA [33]</td><td>Multiple-choice QA</td><td>25.0</td><td><code>acc</code></td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the benchmarks used to evaluate the performance of language models trained on different subsets of the RedPajama-V2 dataset. The benchmarks cover a range of natural language processing tasks, including natural language inference, coreference resolution, sentence completion, and question answering. The &lsquo;Agg. BM-Eval&rsquo; column indicates which benchmark scores were included in the aggregated scores reported in Tables 5 and 6, which summarizes the overall performance across multiple benchmarks. This helps readers understand which tasks were considered most important in the overall evaluation.</p><details><summary>read the caption</summary>Table 4: Benchmarks used in our ablations. The column ‚ÄúAgg. BM-Eval‚Äù indicates whether the score is used in the aggregate scores reported in Tables¬†5 and¬†6.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Deduplication</th><th></th><th>Rule-based</th><th></th><th>ML Heuristics</th><th></th><th></th><th>Agg. BM-Eval (‚Üë)</th><th></th><th>Val-Perplexity (‚Üì)</th><th></th><th></th></tr></thead><tbody><tr><td></td><td>Exact</td><td>Fuzzy</td><td>C4</td><td>Gopher</td><td>Classif.</td><td>DSIR</td><td>PPL</td><td>Avg.</td><td>Norm. Avg.</td><td>Rank-Score</td><td>Pile</td><td>Paloma</td></tr><tr><td>C4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>35.8</td><td>0.140</td><td>0.472</td><td>29.5</td><td>39.5</td></tr><tr><td>Dolma-v1.7 CC</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>36.0</td><td>0.140</td><td>0.511</td><td>21.4</td><td>38.3</td></tr><tr><td>FineWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>36.5</td><td>0.146</td><td>0.644</td><td>26.8</td><td>33.6</td></tr><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>37.9</td><td>0.165</td><td>0.650</td><td>19.1</td><td>32.8</td></tr><tr><td>RPv1-CC</td><td>‚úî(sharded)</td><td></td><td></td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td></td><td>35.6</td><td>0.127</td><td>0.461</td><td>18.7</td><td>31.5</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>36.4</td><td>0.141</td><td>0.594</td><td>19.7</td><td>31.1</td></tr><tr><td>RPv2 (2023-14)</td><td>‚úî</td><td></td><td></td><td></td><td></td><td></td><td></td><td>36.2</td><td>0.138</td><td>0.472</td><td>19.5</td><td>39.9</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td>‚úî (full)</td><td></td><td></td><td>37.6</td><td>0.160</td><td>0.700</td><td>24.9</td><td>34.5</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td></td><td></td><td>‚úî</td><td></td><td></td><td></td><td>36.8</td><td>0.150</td><td>0.622</td><td>36.3</td><td>56.9</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td>‚úî (natlang)</td><td></td><td></td><td>37.2</td><td>0.154</td><td>0.639</td><td>23.6</td><td>38.2</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td>‚úî (Rep.)</td><td></td><td></td><td>37.5</td><td>0.158</td><td>0.633</td><td>20.4</td><td>36.0</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td></td><td></td><td></td><td>35.3</td><td>0.128</td><td>0.517</td><td>35.0</td><td>54.2</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td>‚úî (full)</td><td></td><td></td><td>36.7</td><td>0.149</td><td>0.556</td><td>43.8</td><td>63.9</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td>‚úî (Rep.)</td><td>‚úî (Palm-mix)</td><td></td><td>35.9</td><td>0.138</td><td>0.439</td><td>44.3</td><td>89.9</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td>‚úî (Rep.)</td><td>‚úî (Palm-mix)</td><td></td><td>35.9</td><td>0.139</td><td>0.483</td><td>43.8</td><td>67.1</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td>‚úî (natlang)</td><td>‚úî (Palm-mix)</td><td></td><td>36.7</td><td>0.152</td><td>0.550</td><td>41.8</td><td>67.9</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî (line-filter)</td><td>‚úî (natlang)</td><td>‚úî (Palm-mix)</td><td></td><td></td><td>36.4</td><td>0.144</td><td>0.539</td><td>32.4</td><td>52.9</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>Pwiki>30</td><td>35.8</td><td>0.130</td><td>0.467</td><td>18.5</td><td>39.7</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules + Gopher-Rep.</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>Pwiki>30</td><td>35.9</td><td>0.133</td><td>0.500</td><td>19.8</td><td>45.8</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a performance comparison of a 468M parameter language model trained on various datasets. The datasets include different versions of the RedPajama dataset filtered using various techniques, alongside other state-of-the-art open web datasets. The model&rsquo;s performance is evaluated across several NLP benchmarks. The results are summarized using three metrics: average accuracy, Rank-Score, and a normalized average score. The best, second-best, and third-best performing datasets for each metric are highlighted to facilitate comparison.</p><details><summary>read the caption</summary>Table 5: Evaluations for the 468M parameter LM for different dataset filters and other SOTA web datasets. The Benchmark scores are aggregated from the benchmarks outlined in Table¬†3, using (1) the average accuracy, (2) the Rank-Score, and (3) the normalized average score. The best score is indicated in bold underlined font, the second-best is bolded, and the third is in italics underlined.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Fuzzy Deduplication</th><th>Rule-based C4</th><th>Rule-based Gopher</th><th>Rule-based Palm Classif.</th><th>Rule-based Wiki-Ref Classif.</th><th>Rule-based Avg.</th><th>Rule-based Norm. Avg.</th><th>ML Heuristics Rank-Score</th><th>ML Heuristics Pile</th><th>ML Heuristics Paloma</th><th>Agg. BM-Eval (‚Üë)</th><th>Val-Perplexity (‚Üì)</th></tr></thead><tbody><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>52.0</td><td>34.0</td><td>0.139</td><td>10.7</td><td>17.7</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td></td><td>‚úî</td><td></td><td>‚úî</td><td></td><td></td><td>50.0</td><td>31.1</td><td>0.106</td><td>13.6</td><td>20.8</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td>‚úî</td><td>‚úî(natlang)</td><td>‚úî</td><td>‚úî</td><td></td><td></td><td>47.9</td><td>29.4</td><td>0.089</td><td>22.2</td><td>30.7</td></tr></tbody></table></table></figure><blockquote><p>üîº Table 6 presents a performance comparison of a 1.6B parameter Language Model (LM) trained on various datasets. The table shows aggregated benchmark scores, calculated using three metrics derived from the benchmarks listed in Table 4. These metrics are the average accuracy across benchmarks, the Rank-Score (a measure of ranking performance), and a normalized average score. The datasets used are compared in terms of their performance using these three metrics. The table is useful for understanding how data filtering techniques and dataset composition affect the overall performance of the LM.</p><details><summary>read the caption</summary>Table 6: Aggregated evaluations for the 1.6B parameter LM for different datasets. The Benchmark scores are aggregated from the benchmarks outlined in Table¬†4, using (1) the average accuracy, (2) the Rank-Score, and (3) the normalized average score.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Lambada (acc)</th><th>Hellaswag (acc_norm)</th><th>Winogrande (acc)</th><th>Piqa (acc)</th><th>Avg.</th><th>HELM avg.</th></tr></thead><tbody><tr><td>GPT-Neo</td><td>0.6223</td><td>0.5579</td><td>0.5769</td><td>0.7219</td><td>0.6197</td><td>0.3570</td></tr><tr><td>Pythia-2.8B</td><td>0.6466</td><td>0.5933</td><td>0.6006</td><td>0.7399</td><td>0.6451</td><td>0.3770</td></tr><tr><td>Pythia-2.8B-dedup</td><td><strong>0.6524</strong></td><td>0.5941</td><td>0.5848</td><td>0.7404</td><td>0.6429</td><td>-</td></tr><tr><td>RedPajama-INCITE-Base-3B-v1</td><td>0.6541</td><td><strong>0.6317</strong></td><td><strong>0.6322</strong></td><td><strong>0.7470</strong></td><td><strong>0.6662</strong></td><td><strong>0.4060</strong></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparative analysis of the RedPajama-INCITE-Base-3B-v1 language model&rsquo;s performance against other models with similar parameter counts across various benchmarks, including both zero-shot and few-shot evaluations from the lm-evaluation-harness and HELM. The results showcase RedPajama-INCITE-Base-3B-v1&rsquo;s strengths and weaknesses relative to other open-source models. The top performing model for each benchmark is clearly highlighted.</p><details><summary>read the caption</summary>Table 7: Results for RedPajama-INCITE-Base-3B-v1 on a subset of lm-evaluation-harness (Zero-Shot) and HELM, compared to models with similar parameter counts. The top-scoring model for each benchmark is highlighted in bold font.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>RedPajama 7B (Instruct)</th><th>Llama 7B</th><th>MPT 7B</th><th>Falcon 7B (Base)</th><th>GPT J</th><th>Falcon 7B (Instruct)</th><th>Pythia 7B</th><th>Dolly v2</th><th>MPT 7B (Instruct)</th><th>Stablelm Alpha 7B</th></tr></thead><tbody><tr><td>HELM-AVG</td><td><strong>0.492</strong></td><td>0.472</td><td>0.444</td><td>0.441</td><td>0.431</td><td>0.417</td><td>0.407</td><td>0.400</td><td>0.396</td><td>0.393</td></tr><tr><td>MMLU - EM</td><td><strong>0.366</strong></td><td>0.345</td><td>0.294</td><td>0.285</td><td>0.323</td><td>0.249</td><td>0.271</td><td>0.266</td><td>0.238</td><td>0.349</td></tr><tr><td>BoolQ - EM</td><td>0.697</td><td>0.751</td><td>0.731</td><td><strong>0.770</strong></td><td>0.694</td><td>0.649</td><td>0.708</td><td>0.656</td><td>0.602</td><td>0.442</td></tr><tr><td>NarrativeQA - F1</td><td><strong>0.623</strong></td><td>0.524</td><td>0.541</td><td>0.549</td><td>0.512</td><td>0.545</td><td>0.381</td><td>0.427</td><td>0.441</td><td>0.220</td></tr><tr><td>NaturalQuestions (closed-book) - F1</td><td>0.229</td><td><strong>0.297</strong></td><td>0.284</td><td>0.289</td><td>0.258</td><td>0.156</td><td>0.192</td><td>0.141</td><td>0.133</td><td>0.247</td></tr><tr><td>NaturalQuestions (open-book) - F1</td><td><strong>0.654</strong></td><td>0.580</td><td>0.603</td><td>0.574</td><td>0.600</td><td>0.559</td><td>0.453</td><td>0.549</td><td>0.535</td><td>0.627</td></tr><tr><td>QuAC - F1</td><td>0.252</td><td>0.332</td><td>0.343</td><td>0.322</td><td>0.323</td><td>0.330</td><td>0.300</td><td>0.306</td><td>0.299</td><td><strong>0.352</strong></td></tr><tr><td>HellaSwag - EM</td><td>0.698</td><td>0.747</td><td>0.754</td><td>0.732</td><td>0.702</td><td>0.663</td><td>0.690</td><td>0.653</td><td>0.692</td><td><strong>0.763</strong></td></tr><tr><td>OpenbookQA - EM</td><td>0.488</td><td>0.574</td><td>0.540</td><td><strong>0.546</strong></td><td>0.504</td><td>0.514</td><td>0.498</td><td>0.496</td><td>0.516</td><td>0.532</td></tr><tr><td>TruthfulQA - EM</td><td>0.226</td><td>0.297</td><td>0.186</td><td>0.206</td><td>0.205</td><td>0.199</td><td>0.203</td><td>0.225</td><td><strong>0.250</strong></td><td>0.188</td></tr><tr><td>MS MARCO (regular) - RR@10</td><td><strong>0.391</strong></td><td>0.252</td><td>0.161</td><td>0.169</td><td>0.135</td><td>0.152</td><td>0.225</td><td>0.159</td><td>0.160</td><td>0.161</td></tr><tr><td>MS MARCO (TREC) - NDCG@10</td><td><strong>0.709</strong></td><td>0.482</td><td>0.369</td><td>0.362</td><td>0.322</td><td>0.345</td><td>0.481</td><td>0.342</td><td>0.359</td><td>0.387</td></tr><tr><td>CNN/DailyMail - ROUGE-2</td><td>0.143</td><td><strong>0.149</strong></td><td>0.137</td><td>0.147</td><td>0.137</td><td>0.131</td><td>0.114</td><td>0.101</td><td>0.140</td><td>0.148</td></tr><tr><td>XSUM - ROUGE-2</td><td>0.101</td><td><strong>0.127</strong></td><td>0.107</td><td>0.116</td><td>0.114</td><td>0.096</td><td>0.071</td><td>0.079</td><td>0.074</td><td>0.101</td></tr><tr><td>IMDB - EM</td><td>0.941</td><td>0.933</td><td>0.903</td><td>0.893</td><td>0.916</td><td><strong>0.939</strong></td><td>0.906</td><td>0.930</td><td>0.907</td><td>0.891</td></tr><tr><td>CivilComments - EM</td><td><strong>0.667</strong></td><td>0.578</td><td>0.525</td><td>0.511</td><td>0.536</td><td>0.520</td><td>0.516</td><td>0.527</td><td>0.520</td><td>0.270</td></tr><tr><td>RAFT - EM</td><td>0.682</td><td>0.583</td><td>0.618</td><td>0.586</td><td>0.611</td><td><strong>0.619</strong></td><td>0.498</td><td>0.542</td><td>0.466</td><td>0.616</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the HELM benchmark results for two language models: the RedPajama-INCITE-Base-7B-v1 (a base, pretrained model) and its instruction-tuned counterpart. For various NLP tasks, the table compares their performance to other leading open-source LLMs of similar size. The top-performing model for each benchmark is highlighted in bold font, allowing for a direct comparison of performance across different models on a range of evaluation metrics.</p><details><summary>read the caption</summary>Table 8: HELM Benchmark results for RedPajama-INCITE-Base-7B-v1 and instruction tuned. The top-scoring model for each benchmark is highlighted in bold font.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>LM-eval-harness-AVG</th><th>arc_challenge (acc_norm)</th><th>arc_easy (acc)</th><th>boolq (acc)</th><th>copa (acc)</th><th>hellaswag (acc_norm)</th><th>lambada_openai (acc)</th><th>piqa (acc_norm)</th><th>winogrande (acc)</th></tr></thead><tbody><tr><td>MPT 7B (Instruct)</td><td><strong>0.7195</strong></td><td><strong>0.4462</strong></td><td><strong>0.7218</strong></td><td>0.7425</td><td><strong>0.9000</strong></td><td><strong>0.7717</strong></td><td>0.6918</td><td>0.8041</td><td>0.6780</td></tr><tr><td>Falcon 7B</td><td>0.7161</td><td>0.4326</td><td>0.7096</td><td>0.7361</td><td>0.8600</td><td>0.7634</td><td><strong>0.7467</strong></td><td><strong>0.8069</strong></td><td>0.6732</td></tr><tr><td>MPT 7B</td><td>0.7100</td><td>0.4215</td><td>0.7008</td><td><strong>0.7486</strong></td><td>0.8500</td><td>0.7626</td><td>0.7056</td><td>0.8052</td><td><strong>0.6859</strong></td></tr><tr><td>RedPajama 7B (Base)</td><td>0.6882</td><td>0.3925</td><td>0.6923</td><td>0.707</td><td>0.880</td><td>0.7037</td><td>0.7143</td><td>0.7737</td><td>0.6417</td></tr><tr><td>Llama 7B</td><td>0.6881</td><td>0.4147</td><td>0.5253</td><td>0.7315</td><td>0.8500</td><td>0.7620</td><td>0.7360</td><td>0.7810</td><td>0.7040</td></tr><tr><td>RedPajama 7B (Instruct)</td><td>0.6858</td><td>0.4078</td><td>0.7159</td><td>0.6865</td><td>0.850</td><td>0.7103</td><td>0.6895</td><td>0.7699</td><td>0.6567</td></tr><tr><td>Falcon 7B (Instruct)</td><td>0.6813</td><td>0.4283</td><td>0.6789</td><td>0.7089</td><td>0.8400</td><td>0.6978</td><td>0.6831</td><td>0.7856</td><td>0.6669</td></tr><tr><td>Dolly v2</td><td>0.6557</td><td>0.4027</td><td>0.6423</td><td>0.6502</td><td>0.8600</td><td>0.6896</td><td>0.6893</td><td>0.7486</td><td>0.6140</td></tr><tr><td>GPT-J</td><td>0.6526</td><td>0.3660</td><td>0.6225</td><td>0.6544</td><td>0.8300</td><td>0.6625</td><td>0.6831</td><td>0.7617</td><td>0.6409</td></tr><tr><td>Pythia 7B</td><td>0.6392</td><td>0.3532</td><td>0.6338</td><td>0.6446</td><td>0.7400</td><td>0.6588</td><td>0.6441</td><td>0.7671</td><td>0.6267</td></tr><tr><td>StableLM Alpha 7B</td><td>0.5260</td><td>0.2705</td><td>0.4487</td><td>0.6006</td><td>0.7500</td><td>0.4122</td><td>0.6379</td><td>0.6736</td><td>0.5012</td></tr></tbody></table></table></figure><blockquote><p>üîº Table 9 presents the results of evaluating the RedPajama-INCITE-Base-7B-v1 and its instruction-tuned counterpart on a range of benchmarks commonly used for language model evaluation. The table compares the performance of these models against other prominent open-source language models, such as Llama-7B, Falcon-7B, and MPT-7B, highlighting their strengths and weaknesses across various tasks. The top-performing model for each benchmark is clearly indicated in bold.</p><details><summary>read the caption</summary>Table 9: LM eval harness results for RedPajama-INCITE-Base-7B-v1 and instruction tuned model. The top-scoring model for each benchmark is highlighted in bold font.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Subset</th><th>Uncertainty</th><th>Decision</th></tr></thead><tbody><tr><td>CommonCrawl</td><td>Which snapshots were used?</td><td>We use the first snapshot from 2019 to 2023.</td></tr><tr><td></td><td>What classifier was used, and how was it constructed?</td><td>We use a fasttext classifier with unigram features and use 300k training samples.</td></tr><tr><td></td><td>What threshold was used to classify a sample as high quality?</td><td>We set the threshold to match the token count reported in LLama.</td></tr><tr><td>GitHub</td><td>Quality filtering heuristics</td><td>We remove any file<br>‚Ä¢ with a maximum line length of more than 1000 characters.<br>‚Ä¢ with an average line length of more than 100 characters.<br>‚Ä¢ with a proportion of alphanumeric characters of less than 0.25.<br>‚Ä¢ with a ratio between the number of alphabetical characters and the number of tokens of less than 1.5.<br>whose extension is not in the following set of whitelisted extensions: .asm, .bat, .cmd, .c, .h, .cs, .cpp, .hpp, .c++, .h++, .cc, .hh, .C, .H, .cmake, .css, .dockerfile, .f90, .f, .f03, .f08, .f77, .f95, .for, .fpp, .go, .hs, .html, .java, .js, .jl, .lua, .md, .markdown, .php, .php3, .php4, .php5, .phps, .phpt, .pl, .pm, .pod, .perl, .ps1, .psd1, .psm1, .py, .rb, .rs, .sql, .scala, .sh, .bash, .command, .zsh, .ts, .tsx, .tex, .vb, Dockerfile, Makefile, .xml, .rst, .m, .smali</td></tr><tr><td>Wikipedia</td><td>Which Wikipedia dump was used?</td><td>We used the most recent at the time of data curation (2023-03-20).</td></tr><tr><td>Books</td><td>How were the books deduplicated?</td><td>We use SimHash to perform near deduplication.</td></tr></tbody></table></table></figure><blockquote><p>üîº This table details the ambiguities encountered during the recreation of the original LLaMA training dataset for the RedPajama-V1 project and the decisions made to address them. It covers data sources like Common Crawl, GitHub, and Wikipedia, highlighting uncertainties in the original LLaMA dataset description regarding data selection criteria, processing techniques, and quality filtering methods. For each source, the table lists the uncertainties and the choices made by the RedPajama-V1 team to resolve those issues.</p><details><summary>read the caption</summary>Table 10: Overview over the different uncertainties and decisions made during the construction of the RedPajama-V1 dataset.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Annotation Tag</th><th>Description</th></tr></thead><tbody><tr><td>ccnet_bucket</td><td>head, middle or tail bucket of the perplexity score</td></tr><tr><td>ccnet_language_score</td><td>score of the language identification model</td></tr><tr><td>ccnet_length</td><td>number of characters</td></tr><tr><td>ccnet_nlines</td><td>number of lines</td></tr><tr><td>ccnet_original_length</td><td>number of characters before line-level deduplication</td></tr><tr><td>ccnet_original_nlines</td><td>number of lines before line-level deduplication</td></tr><tr><td>ccnet_perplexity</td><td>perplexity of an LM trained on Wikipedia</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists quality signals derived from the CCNet pipeline, a data processing framework used in creating the RedPajama-V2 dataset. Each signal provides metadata about the text documents, such as the document&rsquo;s length, language, and perplexity score, helping to assess the quality of the web data.</p><details><summary>read the caption</summary>Table 11: Quality signals originating from the CCNet pipeline¬†[61].</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_align_middle" id=A4.T12.1.1><tr class=ltx_tr id=A4.T12.1.1.2><td class="ltx_td ltx_align_left ltx_border_tt" id=A4.T12.1.1.2.1>Annotation Tag</td><td class="ltx_td ltx_align_left ltx_border_tt" id=A4.T12.1.1.2.2>Description</td><td class="ltx_td ltx_align_left ltx_border_tt" id=A4.T12.1.1.2.3>Reference(s)</td></tr><tr class=ltx_tr id=A4.T12.1.1.3><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.3.1>rps_doc_curly_bracket</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.3.2><span class=ltx_text id=A4.T12.1.1.3.2.1></span><span class=ltx_text id=A4.T12.1.1.3.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.3.2.2.1><span class=ltx_tr id=A4.T12.1.1.3.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.3.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio between the number of</span></span>
<span class=ltx_tr id=A4.T12.1.1.3.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.3.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>occurrences of ‚Äô{‚Äô or ‚Äô}‚Äô and the</span></span>
<span class=ltx_tr id=A4.T12.1.1.3.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.3.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>number of characters in the raw text.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.3.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.3.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.4><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.4.1>rps_doc_frac_all_caps_words</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.4.2><span class=ltx_text id=A4.T12.1.1.4.2.1></span><span class=ltx_text id=A4.T12.1.1.4.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.4.2.2.1><span class=ltx_tr id=A4.T12.1.1.4.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.4.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The fraction of words in the content that</span></span>
<span class=ltx_tr id=A4.T12.1.1.4.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.4.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>only consist of uppercase letters. This is</span></span>
<span class=ltx_tr id=A4.T12.1.1.4.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.4.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>based on the raw content.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.4.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.4.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib34 title>34</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.5><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.5.1>rps_doc_frac_lines_end_with_ellipsis</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.5.2><span class=ltx_text id=A4.T12.1.1.5.2.1></span><span class=ltx_text id=A4.T12.1.1.5.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.5.2.2.1><span class=ltx_tr id=A4.T12.1.1.5.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.5.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The fraction of lines that end with an ellipsis,</span></span>
<span class=ltx_tr id=A4.T12.1.1.5.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.5.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>where an ellipsis is defined as either</span></span>
<span class=ltx_tr id=A4.T12.1.1.5.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.5.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>"‚Ä¶" or "U+2026".</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.5.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.5.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.6><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.6.1>rps_doc_frac_no_alph_words</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.6.2><span class=ltx_text id=A4.T12.1.1.6.2.1></span><span class=ltx_text id=A4.T12.1.1.6.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.6.2.2.1><span class=ltx_tr id=A4.T12.1.1.6.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.6.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The fraction of words that contain</span></span>
<span class=ltx_tr id=A4.T12.1.1.6.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.6.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>no alphabetical character.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.6.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.6.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.7><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.7.1>rps_doc_lorem_ipsum</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.7.2><span class=ltx_text id=A4.T12.1.1.7.2.1></span><span class=ltx_text id=A4.T12.1.1.7.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.7.2.2.1><span class=ltx_tr id=A4.T12.1.1.7.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.7.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio between the number of occurrences of</span></span>
<span class=ltx_tr id=A4.T12.1.1.7.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.7.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>‚Äôlorem ipsum‚Äô and the number of characters in the</span></span>
<span class=ltx_tr id=A4.T12.1.1.7.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.7.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>content after normalisation.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.7.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.7.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.8><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.8.1>rps_doc_mean_word_length</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.8.2><span class=ltx_text id=A4.T12.1.1.8.2.1></span><span class=ltx_text id=A4.T12.1.1.8.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.8.2.2.1><span class=ltx_tr id=A4.T12.1.1.8.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.8.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The mean length of words in the content</span></span>
<span class=ltx_tr id=A4.T12.1.1.8.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.8.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>after normalisation.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.8.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.8.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.9><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.9.1>rps_doc_stop_word_fraction</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.9.2><span class=ltx_text id=A4.T12.1.1.9.2.1></span><span class=ltx_text id=A4.T12.1.1.9.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.9.2.2.1><span class=ltx_tr id=A4.T12.1.1.9.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.9.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio between the number of stop words</span></span>
<span class=ltx_tr id=A4.T12.1.1.9.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.9.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>and the number of words in the document.</span></span>
<span class=ltx_tr id=A4.T12.1.1.9.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.9.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>Stop words are obtained from <a class="ltx_ref ltx_url ltx_font_typewriter" href=https://github.com/6/stopwords-json title>https://github.com/6/stopwords-json</a>.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.9.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.9.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.10><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.10.1>rps_doc_symbol_to_word_ratio</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.10.2><span class=ltx_text id=A4.T12.1.1.10.2.1></span><span class=ltx_text id=A4.T12.1.1.10.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.10.2.2.1><span class=ltx_tr id=A4.T12.1.1.10.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.10.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio of symbols to words in the content. Symbols</span></span>
<span class=ltx_tr id=A4.T12.1.1.10.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.10.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>are defined as U+0023 (#), "‚Ä¶", and U+2026.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.10.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.10.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.11><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.11.1>rps_doc_frac_unique_words</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.11.2><span class=ltx_text id=A4.T12.1.1.11.2.1></span><span class=ltx_text id=A4.T12.1.1.11.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.11.2.2.1><span class=ltx_tr id=A4.T12.1.1.11.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.11.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The fraction of unique words in the content.</span></span>
<span class=ltx_tr id=A4.T12.1.1.11.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.11.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>This is also known as the degeneracy of a</span></span>
<span class=ltx_tr id=A4.T12.1.1.11.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.11.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>text sample. Calculated based on the</span></span>
<span class=ltx_tr id=A4.T12.1.1.11.2.2.1.4><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.11.2.2.1.4.1 style=padding-top:1.5pt;padding-bottom:1.5pt>normalised content.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.11.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.11.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib34 title>34</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.1><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.1.2>rps_doc_unigram_entropy</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.1.1><span class=ltx_text id=A4.T12.1.1.1.1.2></span><span class=ltx_text id=A4.T12.1.1.1.1.1>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.1.1.1.1><span class=ltx_tr id=A4.T12.1.1.1.1.1.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.1.1.1.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The entropy of the unigram distribution of the content.</span></span>
<span class=ltx_tr id=A4.T12.1.1.1.1.1.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.1.1.1.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>This measures the diversity of the content and is computed using</span></span>
<span class=ltx_tr id=A4.T12.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.1.1.1.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt><math alttext="\sum_{x}-\frac{x}{n}\cdot\log(\frac{1}{n})" class="ltx_Math" display="inline" id="A4.T12.1.1.1.1.1.1.1.1.m1.2"><semantics id="A4.T12.1.1.1.1.1.1.1.1.m1.2a"><mrow id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.cmml"><msub id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.cmml"><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2.cmml">‚àë</mo><mi id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3.cmml">x</mi></msub><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1" lspace="0em" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1.cmml">‚àí</mo><mrow id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.cmml"><mfrac id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.cmml"><mi id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2.cmml">x</mi><mi id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3.cmml">n</mi></mfrac><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1.cmml">‚ãÖ</mo><mrow id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml"><mi id="A4.T12.1.1.1.1.1.1.1.1.m1.1.1" xref="A4.T12.1.1.1.1.1.1.1.1.m1.1.1.cmml">log</mi><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2a" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml">‚Å°</mo><mrow id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml"><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1.1" stretchy="false" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml">(</mo><mfrac id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.cmml"><mn id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2.cmml">1</mn><mi id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3.cmml">n</mi></mfrac><mo id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2.1.2" stretchy="false" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.T12.1.1.1.1.1.1.1.1.m1.2b"><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3"><minus id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.1"></minus><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2"><csymbol cd="ambiguous" id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2">subscript</csymbol><sum id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.2"></sum><ci id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.2.3">ùë•</ci></apply><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3"><ci id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.1">‚ãÖ</ci><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2"><divide id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2"></divide><ci id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.2">ùë•</ci><ci id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.2.3">ùëõ</ci></apply><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.3.3.3.2"><log id="A4.T12.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.1.1"></log><apply id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2"><divide id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.1.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2"></divide><cn id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2.cmml" type="integer" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.2">1</cn><ci id="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3.cmml" xref="A4.T12.1.1.1.1.1.1.1.1.m1.2.2.3">ùëõ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T12.1.1.1.1.1.1.1.1.m1.2c">\sum_{x}-\frac{x}{n}\cdot\log(\frac{1}{n})</annotation><annotation encoding="application/x-llamapun" id="A4.T12.1.1.1.1.1.1.1.1.m1.2d">‚àë start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT - divide start_ARG italic_x end_ARG start_ARG italic_n end_ARG ‚ãÖ roman_log ( divide start_ARG 1 end_ARG start_ARG italic_n end_ARG )</annotation></semantics></math>where the sum is taken over counts of</span></span>
<span class=ltx_tr id=A4.T12.1.1.1.1.1.1.4><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.1.1.1.1.4.1 style=padding-top:1.5pt;padding-bottom:1.5pt>unique words in the normalised content.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.1.1.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.1.3>-</td></tr><tr class=ltx_tr id=A4.T12.1.1.12><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.12.1>rps_doc_word_count</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.12.2><span class=ltx_text id=A4.T12.1.1.12.2.1></span><span class=ltx_text id=A4.T12.1.1.12.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.12.2.2.1><span class=ltx_tr id=A4.T12.1.1.12.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.12.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The number of words in the content after normalisation.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.12.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.12.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.13><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.13.1>rps_lines_ending_with_terminal_punctution_mark</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.13.2><span class=ltx_text id=A4.T12.1.1.13.2.1></span><span class=ltx_text id=A4.T12.1.1.13.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.13.2.2.1><span class=ltx_tr id=A4.T12.1.1.13.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.13.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>Indicates whether a line ends with a terminal punctuation</span></span>
<span class=ltx_tr id=A4.T12.1.1.13.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.13.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>mark. A terminal punctuation mark is defined as one of: ".", "!", "?", "‚Äù".</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.13.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.13.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.14><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.14.1>rps_lines_javascript_counts</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.14.2><span class=ltx_text id=A4.T12.1.1.14.2.1></span><span class=ltx_text id=A4.T12.1.1.14.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.14.2.2.1><span class=ltx_tr id=A4.T12.1.1.14.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.14.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The number of occurrences of the word "javascript" in each line.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.14.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.14.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.15><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.15.1>rps_lines_num_words</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.15.2><span class=ltx_text id=A4.T12.1.1.15.2.1></span><span class=ltx_text id=A4.T12.1.1.15.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.15.2.2.1><span class=ltx_tr id=A4.T12.1.1.15.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.15.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The number of words in each line. This is computed based on the</span></span>
<span class=ltx_tr id=A4.T12.1.1.15.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.15.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>normalised text.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.15.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.15.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.16><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.16.1>rps_lines_numerical_chars_fraction</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.16.2><span class=ltx_text id=A4.T12.1.1.16.2.1></span><span class=ltx_text id=A4.T12.1.1.16.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.16.2.2.1><span class=ltx_tr id=A4.T12.1.1.16.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.16.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio between the number of numerical</span></span>
<span class=ltx_tr id=A4.T12.1.1.16.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.16.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>characters and total number of characters</span></span>
<span class=ltx_tr id=A4.T12.1.1.16.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.16.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>in each line. This is based on the</span></span>
<span class=ltx_tr id=A4.T12.1.1.16.2.2.1.4><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.16.2.2.1.4.1 style=padding-top:1.5pt;padding-bottom:1.5pt>normalised content.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.16.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.16.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.17><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.17.1>rps_lines_start_with_bulletpoint</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.17.2><span class=ltx_text id=A4.T12.1.1.17.2.1></span><span class=ltx_text id=A4.T12.1.1.17.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.17.2.2.1><span class=ltx_tr id=A4.T12.1.1.17.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>Whether the lines that start with a bullet point symbol. The</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>following set of unicodes are considered a bullet point:</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+2022 (bullet point),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.4><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.4.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+2023 (triangular bullet point),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.5><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.5.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25B6 (black right pointing triangle),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.6><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.6.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25C0 (black left pointing triangle),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.7><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.7.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25E6 (white bullet point),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.8><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.8.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+2013 (en dash)</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.9><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.9.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25A0 (black square),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.10><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.10.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25A1 (white square),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.11><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.11.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25AA (black small square),</span></span>
<span class=ltx_tr id=A4.T12.1.1.17.2.2.1.12><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.17.2.2.1.12.1 style=padding-top:1.5pt;padding-bottom:1.5pt>U+25AB (white small square).</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.17.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.17.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib43 title>43</a>, <a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib45 title>45</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.18><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.18.1>rps_lines_uppercase_letter_fraction</td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.18.2><span class=ltx_text id=A4.T12.1.1.18.2.1></span><span class=ltx_text id=A4.T12.1.1.18.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.18.2.2.1><span class=ltx_tr id=A4.T12.1.1.18.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.18.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The ratio between the number of uppercase letters</span></span>
<span class=ltx_tr id=A4.T12.1.1.18.2.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.18.2.2.1.2.1 style=padding-top:1.5pt;padding-bottom:1.5pt>and total number of characters in each line.</span></span>
<span class=ltx_tr id=A4.T12.1.1.18.2.2.1.3><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.18.2.2.1.3.1 style=padding-top:1.5pt;padding-bottom:1.5pt>This is based on the raw text.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.18.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T12.1.1.18.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib44 title>44</a>]</cite></td></tr><tr class=ltx_tr id=A4.T12.1.1.19><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=A4.T12.1.1.19.1>rps_doc_num_sentences</td><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=A4.T12.1.1.19.2><span class=ltx_text id=A4.T12.1.1.19.2.1></span><span class=ltx_text id=A4.T12.1.1.19.2.2>
<span class="ltx_tabular ltx_align_middle" id=A4.T12.1.1.19.2.2.1><span class=ltx_tr id=A4.T12.1.1.19.2.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_left" id=A4.T12.1.1.19.2.2.1.1.1 style=padding-top:1.5pt;padding-bottom:1.5pt>The number of sentences in the content.</span></span>
</span></span><span class=ltx_text id=A4.T12.1.1.19.2.3></span></td><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=A4.T12.1.1.19.3><cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2411.12372v1#bib.bib46 title>46</a>]</cite></td></tr></table></table></figure><blockquote><p>üîº This table lists quality signals used to assess the natural language quality of text documents. Each signal is described, indicating how it measures the extent to which text resembles human-written language rather than machine-generated or non-language content. References to prior works which introduced each signal are included for further study.</p><details><summary>read the caption</summary>Table 12: Summary of quality signals which measure how much a document corresponds to natural language.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Annotation Tag</th><th>Description</th><th>Reference(s)</th></tr></thead><tbody><tr><td>rps_doc_books_importance</td><td>Given a bag of 1,2-wordgram model trained on Books $p$, and a model trained on the source domain $q$, This is the logarithm of the ratio $p/q$.</td><td>[62]</td></tr><tr><td>rps_doc_openwebtext_importance</td><td>Given a bag of 1,2-wordgram model trained on OpenWebText $p$, and a model trained on the source domain $q$, this is the logarithm of the ratio $p/q$.</td><td>[62]</td></tr><tr><td>rps_doc_wikipedia_importance</td><td>Given a bag of 1,2-wordgram model trained on Wikipedia articles $p$, and a model trained on the source domain $q$, this is the logarithm of the ratio $p/q$.</td><td>[62]</td></tr><tr><td>rps_doc_ml_wikiref_score</td><td>Fasttext classifier prediction for the document being a Wikipedia reference. This is the same fasttext model used in the RedPajama-1T dataset. Only applies to English data.</td><td>[57]</td></tr><tr><td>rps_doc_ml_palm_score</td><td>Fasttext classifier prediction for the document being a Wikipedia article, OpenWebText sample or a RedPajama-V1 book. Only for English data.</td><td>[12], [16]</td></tr><tr><td>rps_doc_ml_wikipedia_score</td><td>Fasttext classifier prediction for the document being a Wikipedia article. This is used for non-English data</td><td>-</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists quality signals derived from machine learning (ML) heuristics. These signals are used to assess the quality of text documents by comparing them to reference datasets. Specifically, they measure how similar a document&rsquo;s textual characteristics are to those found in high-quality datasets such as Books, OpenWebText, and Wikipedia.</p><details><summary>read the caption</summary>Table 13: Quality signals based on ML heuristics.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Annotation Tag</th><th>Description</th><th>Reference(s)</th></tr></thead><tbody><tr><td>rps_doc_frac_chars_dupe_10grams</td><td>The fraction of characters in duplicate word 10grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_dupe_5grams</td><td>The fraction of characters in duplicate word 5grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_dupe_6grams</td><td>The fraction of characters in duplicate word 6grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_dupe_7grams</td><td>The fraction of characters in duplicate word 7grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_dupe_8grams</td><td>The fraction of characters in duplicate word 8grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_dupe_9grams</td><td>The fraction of characters in duplicate word 9grams.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_top_2gram</td><td>The fraction of characters in the top word 2gram.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_top_3gram</td><td>The fraction of characters in the top word 3gram.</td><td>[43, 45]</td></tr><tr><td>rps_doc_frac_chars_top_4gram</td><td>The fraction of characters in the top word 4gram.</td><td>[43, 45]</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists quality signals that assess the repetitiveness of text. It provides a comprehensive overview of various metrics used to quantify text repetition within the RedPajama-V2 dataset. Each row represents a specific signal, offering its name, a description explaining how the signal measures repetitiveness (e.g., the fraction of characters within duplicate n-grams), and its reference to the source where it was initially described.</p><details><summary>read the caption</summary>Table 14: Summary of Quality signals which measure how repetitive text is.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Annotation Tag</th><th>Description</th><th>Reference(s)</th></tr></thead><tbody><tr><td>rps_doc_ldnoobw_words</td><td>The number of sequences of words that are contained in the List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words blocklist. The blocklist is obtained from <a href=https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words target=_blank>https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words</a>.</td><td>[46]</td></tr><tr><td>rps_doc_ut1_blacklist</td><td>A categorical id corresponding to the list of categories of the domain of the document. Categories are obtained from <a href=https://dsi.ut-capitole.fr/blacklists/ target=_blank>https://dsi.ut-capitole.fr/blacklists/</a></td><td>[44]</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists quality signals in the RedPajama-V2 dataset that assess the toxicity of text documents. It details the specific annotation tags used, a description of what each tag measures (e.g., presence of offensive words), and the sources or methods used to calculate these metrics.</p><details><summary>read the caption</summary>Table 15: Summary of Quality signals which are based on the content of the text, measuring toxicity.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Cluster Topics</th><th>Document</th></tr></thead><tbody><tr><td>(broad - medium - specific)</td><td></td></tr><tr><td>Election - Health (2) - COVID Testing</td><td>immediately moving to the Purple Tier. This is the most restrictive level in the State‚Äôs effort to control the spread of COVID-19. Businesses and residents must comply with the Purple Tier restrictions by Tuesday, Nov. 17. To determine restrictions by industry, business and activity, visit: <a href=https://covid19.ca.gov/safer-economy/ target=_blank>https://covid19.ca.gov/safer-economy/</a> Read the full news release here: <a href=https://www.gov.ca.gov/2020/11/16/governor-newsom-announces-new-immediate-actions-to-curb-covid-19-transmission/ target=_blank>www.gov.ca.gov/2020/11/16/governor-newsom-announces-new-immediate-actions-to-curb-covid-19-transmission/</a> Watch the Governor‚Äôs press conference during which he made the announcement today here: <a href=https://www.facebook.com/CAgovernor/videos/376746553637721 target=_blank>www.facebook.com/CAgovernor/videos/376746553637721</a> According to County of Orange officials, schools that have not already opened must continue with remote classes and cannot reopen in-person. Read the County‚Äôs release here: <a href="https://cms.ocgov.com/civicax/filebank/blobdload.aspx?BlobID=118441" target=_blank>https://cms.ocgov.com/civicax/filebank/blobdload.aspx?BlobID=118441</a> The California Department of Public Health has also issued a travel advisory encouraging Californians to stay home or in their region and avoid non-esse</td></tr><tr><td>Religion/Spirituality - Gaming - Gaming (3)</td><td>Top 100 Employers, and one of Canada‚Äôs Top Employers for Young People multiple years running! At Ubisoft Toronto, we look for people who are excited to create the future of games in one of the most diverse cities in the world. We believe that embracing our differences helps us build stronger creative teams and develop better games for all players. We are an equal-opportunity employer and welcome applications from all interested candidates. We strongly encourage applications from Indigenous people, racialized people, neurodivergent people, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities. We are committed to providing reasonable accommodation for people with disability upon request. If this sounds like your kind of studio, what are you waiting for? Apply to join us now! We thank you for your interest, however, only those candidates selected for an interview will be contacted. No agencies please. Senior Game Design</td></tr><tr><td>Education - Golf - Rotary Meetings</td><td>what‚Äôs happening. Conversely, some people rely on the newsletter. Thus, the more avenues to inform people, the better. attendance at many social functions is poor, possibly due to the limited advertising reach. In practical terms, it means that social functions may be advertised in the OOC newsletter (current practice) the schedule, as is done for outdoor activities such as hikes the OOC‚Äôs Facebook group As when social functions are advertised in the newsletter, the person organizing the social function can choose how much location information to provide, especially if it is to be held at someone‚Äôs residence. OOC bylaw Article 3, Section 9 (f) states (highlighting added) (f) Social Coordinator: Shall be responsible for coordinating all social events for Club members only, and for preparing a schedule of these outings, not to be advertised to non-members. The executive voted to amend this statement by removing the limitation per Paragraph 3 of &ldquo;Article 5 - Amending Formula&rdquo; of the Const</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents examples of documents from the RedPajama-V2 dataset and their corresponding cluster topics as determined by Nomic Atlas. It showcases the diversity of topics covered in the dataset and how Nomic Atlas groups similar documents together based on semantic meaning.</p><details><summary>read the caption</summary>Table 16: Examples of documents and corresponding cluster topics from Nomic Atlas¬†[41].</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Cluster Topics</th><th>Document</th></tr></thead><tbody><tr><td>(broad - medium - specific)</td><td></td></tr><tr><td>Online Privacy - Privacy Policy - Contracts</td><td>shall be governed by the laws of the Federal Republic of Germany under exclusion of the UN Convention on the International Sale of Goods (CISG), without prejudice to any mandatory conflict of laws and consumer protection provisions. 11.2 If the Customer is an entrepreneur according to Sec. 14 German Civil Code (‚ÄúBGB‚Äù), a legal person under public law or a special fund under public law the courts at the place of business of the vendor shall have exclusive jurisdiction in respect of all disputes arising out of or in connection with the relevant contract. 11.3 In the event that one or more provisions of the contract should be or become invalid or unenforceable, the validity of the remaining provisions shall not be affected thereby. The invalid or unenforceable provision shall be deemed to be replaced - as existent - with statutory provisions. In case of an unacceptable rigor to one of the parties, the contract shall be deemed invalid as a whole. 11.4 In case of deviations of these General</td></tr><tr><td>Religion/Spirituality - Film/Movie - Movie</td><td>Movie of Nelson Mandela‚Äôs life premieres in South Africa Nov. 04 - Stars Idris Elba and Naomie Harris attend the premiere of &ldquo;Mandela: Long Walk to Freedom,&rdquo; based on the autobiography of anti-apartheid icon Nelson Mandela. Matthew Stock reports.</td></tr><tr><td>Election - Election (2) - Healthcare (4)</td><td>McAuliffe revived that language as an amendment to the budget. He also called on the General Assembly to immediately convene a special joint committee that had been created to assess the impact that repealing the ACA would have had on Virginia. The legislature will gather April 5 to consider the governor‚Äôs amendments and vetoes, but leaders said Monday that McAuliffe‚Äôs new budget language stands no better chance this time. In a joint statement, the Republican leadership of the House of Delegates said expanding Medicaid would lead to increased costs and eventually blow a hole in the state budget. ‚ÄúThe lack of action in Washington has not changed that and in fact, the uncertainty of federal health policy underscores the need to be cautious over the long term,‚Äù the leaders, including House Speaker William J. Howell (R-Stafford) and the man selected to replace him as speaker when he retires next year, Del. Kirk Cox (R-Colonial Heights), said via email. ‚ÄúVirginians can barely afford our cu</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents example documents from the RedPajama-V2 dataset and their corresponding cluster topics as determined by Nomic Atlas, a tool for topic modeling and clustering. It shows how Nomic Atlas groups similar documents based on semantic meaning, illustrating the diversity of topics within the RedPajama-V2 dataset.</p><details><summary>read the caption</summary>Table 17: Examples of documents and corresponding cluster topics from Nomic Atlas¬†[41].</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Deduplication</th><th>Deduplication</th><th>Rule-based</th><th>Rule-based</th><th>ML Heuristics</th><th>ML Heuristics</th><th>ML Heuristics</th><th>Natural Language Inference</th><th>Natural Language Inference</th><th>Natural Language Inference</th><th>Coref. Res.</th><th>Sentence Completion</th><th>Sentence Completion</th></tr></thead><tbody><tr><td></td><td>Exact</td><td>Fuzzy</td><td>C4</td><td>Gopher</td><td>Classif.</td><td>DSIR</td><td>PPL</td><td>ANLI</td><td>ARC-c</td><td>ARC-e</td><td>Winogrande</td><td>Hellaswag</td><td>LAMBADA</td></tr><tr><td>C4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>33.8</td><td>22.0</td><td>37.0</td><td>51.9</td><td><strong>32.9</strong></td><td>15.5</td></tr><tr><td>Dolma-v1.7 CC</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>33.5</td><td><strong>24.0</strong></td><td>38.3</td><td>49.6</td><td>32.3</td><td>17.3</td></tr><tr><td>FineWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>34.0</td><td>23.4</td><td>37.7</td><td>51.8</td><td><strong>32.8</strong></td><td>18.1</td></tr><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>32.8</td><td>22.6</td><td>38.3</td><td>51.9</td><td>31.6</td><td>17.8</td></tr><tr><td>RPv1-CC</td><td></td><td></td><td></td><td></td><td>‚úì (Wiki-Ref.)</td><td></td><td></td><td>33.9</td><td>22.4</td><td>37.5</td><td><strong>52.6</strong></td><td>29.7</td><td><em>19.0</em></td></tr><tr><td>RPv2 (2023-14)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>33.3</td><td>22.2</td><td>38.5</td><td>52.4</td><td>31.5</td><td>18.2</td></tr><tr><td>RPv2 (2023-14)</td><td>‚úì</td><td></td><td></td><td></td><td></td><td></td><td></td><td>33.9</td><td>22.1</td><td>38.1</td><td>50.6</td><td>31.3</td><td>18.0</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úì</td><td></td><td></td><td></td><td></td><td></td><td>34.1</td><td>22.3</td><td>38.3</td><td>52.2</td><td>32.1</td><td>18.7</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úì</td><td>‚úì</td><td></td><td></td><td></td><td></td><td>33.4</td><td>22.7</td><td>38.9</td><td>51.1</td><td>32.4</td><td>17.5</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úì</td><td></td><td>‚úì (natlang)</td><td></td><td></td><td>Wiki-middle</td><td>33.4</td><td><strong>24.2</strong></td><td>37.7</td><td>49.8</td><td>33.1</td><td><strong>19.2</strong></td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úì</td><td></td><td>‚úì (Rep.)</td><td></td><td></td><td>Wiki-middle</td><td>34.2</td><td>23.1</td><td>37.4</td><td>50.8</td><td>32.5</td><td>18.5</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì</td><td></td><td></td><td></td><td></td><td><em>34.3</em></td><td>23.5</td><td><em>38.6</em></td><td>51.5</td><td>32.0</td><td>17.2</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì</td><td>‚úì (full)</td><td></td><td></td><td></td><td>33.5</td><td>23.3</td><td>38.4</td><td>50.2</td><td><strong>32.8</strong></td><td>16.8</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì</td><td>‚úì (Rep.)</td><td></td><td>‚úì (Palm-mix)</td><td></td><td>33.8</td><td>21.9</td><td>38.0</td><td><em>52.5</em></td><td>32.0</td><td>17.3</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì</td><td>‚úì (Rep.)</td><td>‚úì (Palm-mix)</td><td></td><td></td><td><strong>34.6</strong></td><td>23.3</td><td><em>38.6</em></td><td>52.2</td><td><em>32.7</em></td><td>16.4</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì</td><td>‚úì (natlang)</td><td>‚úì (Palm-mix)</td><td></td><td></td><td><strong>34.8</strong></td><td>23.0</td><td><strong>39.2</strong></td><td><strong>53.0</strong></td><td>32.3</td><td>16.9</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>‚úì (line-filter)</td><td>‚úì (natlang)</td><td>‚úì (Palm-mix)</td><td></td><td></td><td>33.7</td><td>22.9</td><td>38.5</td><td>50.9</td><td>32.3</td><td><strong>19.9</strong></td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>custom-rules</td><td></td><td>‚úì (Wiki-Ref.)</td><td></td><td>P<sub>wiki</sub>>30</td><td>33.2</td><td>23.0</td><td>37.9</td><td>49.6</td><td>30.1</td><td>18.7</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úì</td><td>custom-rules + Gopher-Rep</td><td></td><td>‚úì (Wiki-Ref.)</td><td></td><td>P<sub>wiki</sub>>30</td><td>33.0</td><td><em>23.8</em></td><td><strong>38.9</strong></td><td>50.5</td><td>30.0</td><td>18.9</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of a 468M parameter language model trained on various datasets. The datasets include different versions of the RedPajama dataset filtered using various rules (exact deduplication, fuzzy deduplication, rule-based filtering, Gopher filtering, classification-based filtering, ML heuristic filtering, and DSIR filtering), along with other established web datasets such as C4, Dolma-v1.7 CC, FineWeb, and RefinedWeb. The model&rsquo;s performance is evaluated on a selection of downstream tasks (Natural Language Inference, Coreference Resolution, Sentence Completion), with the top-performing dataset for each metric highlighted.</p><details><summary>read the caption</summary>Table 18: Evaluations for the 468M parameter LM for different dataset filters and other strong web datasets. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Deduplication</th><th></th><th>Rule-based</th><th></th><th>ML Heuristics</th><th></th><th></th><th>MMLU</th><th>Stem</th><th>Humanities</th><th>Other</th><th>Social Sciences</th></tr></thead><tbody><tr><td>C4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>24.9</td><td>26.4</td><td>24.1</td><td>25.8</td><td>23.4</td></tr><tr><td>Dolma-v1.7 CC</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>26.0</td><td>27.8</td><td>24.5</td><td>26.2</td><td>26.1</td></tr><tr><td>FineWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>26.2</td><td>25.4</td><td>25.1</td><td>25.8</td><td>29.3</td></tr><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>24.8</td><td>23.9</td><td>23.7</td><td>26.5</td><td>25.6</td></tr><tr><td>RPv1-CC</td><td></td><td></td><td></td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td></td><td>25.1</td><td>25.1</td><td>23.7</td><td>24.0</td><td>28.5</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>26.3</td><td>26.7</td><td>25.3</td><td>24.1</td><td>29.6</td></tr><tr><td>RPv2 (2023-14)</td><td>‚úî</td><td></td><td></td><td></td><td></td><td></td><td></td><td>26.4</td><td>26.8</td><td>25.3</td><td>25.2</td><td>28.8</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td>‚úî (full)</td><td></td><td></td><td></td><td>27.0</td><td>28.8</td><td>24.8</td><td>25.6</td><td>30.0</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>25.4</td><td>27.8</td><td>24.1</td><td>26.1</td><td>24.1</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td>‚úî (natlang)</td><td></td><td></td><td>Wiki-middle</td><td>26.1</td><td>27.4</td><td>25.2</td><td>24.6</td><td>27.7</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td>‚úî (Rep.)</td><td></td><td></td><td>Wiki-middle</td><td>25.5</td><td>24.3</td><td>25.2</td><td>27.8</td><td>24.8</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>26.3</td><td>28.3</td><td>25.3</td><td>25.8</td><td>26.6</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td>‚úî (full)</td><td></td><td></td><td></td><td>25.6</td><td>28.0</td><td>25.1</td><td>24.9</td><td>24.4</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td>‚úî (Rep.)</td><td></td><td>‚úî (Palm-mix)</td><td></td><td>24.4</td><td>26.9</td><td>23.7</td><td>24.8</td><td>22.7</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td>‚úî (Rep.)</td><td>‚úî (Palm-mix)</td><td></td><td></td><td>24.9</td><td>26.1</td><td>24.0</td><td>26.3</td><td>23.8</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td>‚úî (natlang)</td><td>‚úî (Palm-mix)</td><td></td><td></td><td>25.3</td><td>27.8</td><td>24.2</td><td>25.4</td><td>24.5</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî (line-filter)</td><td>‚úî (natlang)</td><td>‚úî (Palm-mix)</td><td></td><td></td><td>25.1</td><td>27.5</td><td>24.0</td><td>25.0</td><td>24.4</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>$P_{wiki} > 30$</td><td>27.0</td><td>27.9</td><td>25.1</td><td>26.0</td><td>30.0</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules + Gopher-Rep</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>$P_{wiki} > 30$</td><td>25.9</td><td>25.8</td><td>24.3</td><td>27.1</td><td>27.2</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of a 5-shot evaluation on the Massive Multitask Language Understanding (MMLU) benchmark and its subtasks. The evaluation uses a language model with 468 million parameters. Multiple datasets were used to train the model, and the table shows the performance achieved on each dataset. The top-performing dataset for each metric is highlighted. The highlighting differentiates between the top performer, the second-best, and the third-best datasets.</p><details><summary>read the caption</summary>Table 19: Evaluations in the 5-shot setting on MMLU and subtasks for the 468M parameter LM. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Deduplication</th><th></th><th>Rule-based</th><th></th><th>ML Heuristics</th><th></th><th></th><th>CoQA</th><th>OpenbookQA</th><th>PIQA</th><th>PubMedQA</th><th>SciQ</th><th>SocialIQA</th><th>TruthfulQA</th></tr></thead><tbody><tr><td></td><td>Exact</td><td>Fuzzy</td><td>C4</td><td>Gopher</td><td>Classif.</td><td>DSIR</td><td>PPL</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>C4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>3.8</td><td><strong>30.2</strong></td><td><em>64.4</em></td><td>46.0</td><td>51.7</td><td><em>33.4</em></td><td>33.3</td></tr><tr><td>Dolma-v1.7 CC</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>5.2</td><td>28.2</td><td><strong>65.3</strong></td><td>42.6</td><td>55.2</td><td>31.6</td><td>33.2</td></tr><tr><td>FineWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>9.0</td><td><strong>29.4</strong></td><td><strong>64.5</strong></td><td>41.4</td><td>54.3</td><td>32.4</td><td>33.5</td></tr><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td><strong>13.2</strong></td><td>28.6</td><td><em>64.4</em></td><td><em>52.2</em></td><td><strong>56.4</strong></td><td>32.8</td><td>33.3</td></tr><tr><td>RPv1-CC</td><td></td><td></td><td></td><td></td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>11.6</td><td>25.4</td><td>57.3</td><td>40.6</td><td><strong>56.7</strong></td><td>33.1</td><td><strong>33.9</strong></td></tr><tr><td>RPv2 (2023-14)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td><strong>12.5</strong></td><td><em>29.2</em></td><td>61.6</td><td>40.8</td><td>53.0</td><td>32.9</td><td>31.4</td></tr><tr><td>RPv2 (2023-14)</td><td>‚úî</td><td></td><td></td><td></td><td></td><td></td><td></td><td>11.8</td><td>27.6</td><td>61.1</td><td>43.6</td><td>53.7</td><td>32.5</td><td>33.4</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td></td><td></td><td></td><td>11.3</td><td>28.8</td><td>62.8</td><td>51.0</td><td>53.9</td><td>32.6</td><td>32.6</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>5.8</td><td>28.8</td><td>63.4</td><td>49.6</td><td>54.7</td><td>36.6</td><td><em>33.8</em></td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td></td><td></td><td>Wiki-middle</td><td>11.3</td><td>28.4</td><td>63.5</td><td>49.6</td><td>53.6</td><td>32.8</td><td>33.4</td></tr><tr><td>RPv2 (2023-14)</td><td></td><td>‚úî</td><td></td><td></td><td></td><td></td><td>Wiki-middle</td><td><em>11.9</em></td><td><strong>29.4</strong></td><td>63.1</td><td><strong>52.6</strong></td><td>53.4</td><td>32.5</td><td>31.6</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>6.6</td><td>29.0</td><td>62.0</td><td>36.2</td><td>53.7</td><td>33.2</td><td><strong>34.3</strong></td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>5.8</td><td>28.6</td><td>62.8</td><td><em>51.2</em></td><td>54.8</td><td><strong>34.4</strong></td><td>31.2</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td></td><td></td><td></td><td>6.0</td><td><strong>29.4</strong></td><td>61.6</td><td>45.4</td><td>52.2</td><td><em>33.4</em></td><td>33.1</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td>‚úî (Palm-mix)</td><td></td><td></td><td>5.4</td><td><strong>29.4</strong></td><td>62.5</td><td>45.0</td><td>51.7</td><td><strong>34.0</strong></td><td>33.7</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>‚úî</td><td></td><td>‚úî (Palm-mix)</td><td></td><td></td><td>4.9</td><td>28.0</td><td>62.9</td><td><strong>52.8</strong></td><td>52.0</td><td>33.0</td><td>33.6</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td><em>‚úî (line-filter)</em></td><td><em>‚úî (natlang)</em></td><td>‚úî (Palm-mix)</td><td></td><td></td><td>6.4</td><td>27.0</td><td>63.2</td><td>47.8</td><td>52.9</td><td>32.8</td><td>32.0</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>P<sub>wiki</sub>>30</td><td>10.0</td><td>27.8</td><td>59.6</td><td>41.2</td><td><em>55.8</em></td><td>33.3</td><td>32.0</td></tr><tr><td>RPv2 (9 Dumps)</td><td></td><td>‚úî</td><td>custom-rules + Gopher-Rep</td><td></td><td>‚úî (Wiki-Ref.)</td><td></td><td>P<sub>wiki</sub>>30</td><td>9.3</td><td>28.0</td><td>59.2</td><td>43.4</td><td>54.9</td><td>33.0</td><td>33.3</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of an evaluation of various datasets used to train a 468M parameter language model on multiple-choice question answering tasks. The evaluation metrics include accuracy scores across several different benchmarks. The table highlights the top-performing datasets for each metric, indicating the top dataset with bolded underlined text, the second-best with bolded text, and the third-best with italicized underlined text.</p><details><summary>read the caption</summary>Table 20: Evaluations on multiple choice tasks for the 468M parameter LM. The top-scoring dataset for each metric is indicated in bolded underlined, the top-2 is bolded, and the third-scoring dataset is in italics underlined.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Fuzzy Deduplication</th><th>Rule-based C4</th><th>Rule-based Gopher</th><th>ANLI</th><th>ARC-c</th><th>ARC-e</th><th>Winogrande</th><th>Hellaswag</th><th>LAMBADA</th><th>Coref. Res.</th><th>Sentence Completion</th></tr></thead><tbody><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td></td><td>33.6</td><td>26.9</td><td>51.7</td><td>54.4</td><td>55.8</td><td>47.9</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td></td><td>‚úî</td><td>WikiRef</td><td></td><td>32.4</td><td>27.9</td><td>51.3</td><td>56.4</td><td>47.4</td><td>47.4</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td>‚úî</td><td>‚úî(natlang)</td><td>Palm-Mix</td><td></td><td>33.6</td><td>28.7</td><td>52.4</td><td>54.5</td><td>53.1</td><td>42.9</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of downstream task accuracy achieved by a 1.6 billion parameter language model (LM) trained on various datasets. Each dataset was used to train the LM using 350 billion tokens. The table displays the accuracy scores across several downstream tasks, including various Natural Language Inference (NLI) tasks, Coreference Resolution, and Sentence Completion tasks. The results offer a comparison of how different datasets impact the performance of the LM on various tasks.</p><details><summary>read the caption</summary>Table 21: Downstream task accuracy for a 1.6B LM trained on different datasets over 350B tokens.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Fuzzy Deduplication</th><th>Rule-based C4</th><th>Rule-based Gopher</th><th>Rule-based MMLU</th><th>ML Heuristics</th><th>MMLU MMLU</th><th>MMLU Stem</th><th>MMLU Humanities</th><th>MMLU Other</th><th>MMLU Social Sciences</th></tr></thead><tbody><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td>25.3</td><td>24.9</td><td>24.9</td><td>27.0</td><td>24.7</td><td></td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td></td><td>‚úî</td><td>WikiRef</td><td>25.2</td><td>26.0</td><td>26.7</td><td>23.9</td><td>23.3</td><td></td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td>‚úî</td><td>‚úî (natlang)</td><td>Palm-Mix</td><td>24.7</td><td>25.7</td><td>25.4</td><td>23.8</td><td>23.4</td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of a 5-shot evaluation of a 1.6B parameter language model on the Massive Multitask Language Understanding (MMLU) benchmark and its subtasks. The evaluation measures the model&rsquo;s performance across various subdomains of MMLU, providing insights into its capabilities in different areas of knowledge and reasoning. The table likely compares the model&rsquo;s performance across different dataset variations, allowing for analysis of how data composition influences model capabilities.</p><details><summary>read the caption</summary>Table 22: Evaluations in the 5-shot setting on MMLU and subtasks for the 1.6B parameter LM.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Dataset</th><th>Fuzzy Deduplication</th><th>Rule-based C4</th><th>Rule-based Gopher</th><th>ML Heuristics WikiRef</th><th>CoQA</th><th>OpenbookQA</th><th>PIQA</th><th>PubMedQA</th><th>SciQ</th><th>SocialIQA</th><th>TruthfulQA</th></tr></thead><tbody><tr><td>RefinedWeb</td><td></td><td></td><td></td><td></td><td>47.4</td><td>31.6</td><td>73.8</td><td>57.0</td><td>75.3</td><td>41.0</td><td>36.6</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td></td><td>‚úî</td><td></td><td>43.7</td><td>32.6</td><td>67.4</td><td>55.6</td><td>72.7</td><td>40.4</td><td>36.9</td></tr><tr><td>RPv2 (full)</td><td>‚úî</td><td>‚úî</td><td>‚úî(natlang)</td><td>Palm-Mix</td><td>22.1</td><td>32.2</td><td>71.3</td><td>55.2</td><td>71.0</td><td>42.2</td><td>35.7</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of a 1.6B parameter language model on various multiple-choice question answering benchmarks. The model was trained on the RedPajama-V2 dataset, with different filtering techniques applied to the data. The results show how different data filtering methods affect the model&rsquo;s performance across a variety of tasks and datasets. The table includes a variety of metrics to evaluate performance, such as accuracy and F1-score, allowing for a comprehensive assessment of the model&rsquo;s capabilities under diverse conditions.</p><details><summary>read the caption</summary>Table 23: Evaluations on multiple choice tasks for the 1.6B parameter LM.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-2965abec82621776781f674aaebfeaa4 class=gallery><img src=https://ai-paper-reviewer.com/2411.12372/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.12372/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/&amp;title=RedPajama:%20an%20Open%20Dataset%20for%20Training%20Large%20Language%20Models" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/&amp;text=RedPajama:%20an%20Open%20Dataset%20for%20Training%20Large%20Language%20Models" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/&amp;subject=RedPajama:%20an%20Open%20Dataset%20for%20Training%20Large%20Language%20Models" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2411.12372/index.md",oid_likes="likes_paper-reviews/2411.12372/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2411.12734/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Soft Robotic Dynamic In-Hand Pen Spinning</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-19T00:00:00+00:00>19 November 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2411.12240/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Evaluating Tokenizer Performance of Large Language Models Across Official Indian Languages</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-19T00:00:00+00:00>19 November 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title=Tags>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>