[{"figure_path": "https://arxiv.org/html/2412.09013/x2.png", "caption": "Figure 1: \nQualitative comparisons of our proposed method to recent state-of-the-art diffusion-based approaches on two real-world examples, where the number of sampling steps is annotated in the format \u201cMethod name-Steps\u201d. We provide the runtime (in milliseconds) highlighted by red in the sub-caption of the first example , which is tested on \u00d7\\times\u00d74 (128\u2192512\u2192128512128\\rightarrow 512128 \u2192 512) SR task on an A100 GPU. Our method offers an efficient and flexible sampling mechanism, allowing users to freely adjust the number of sampling steps based on the degradation type or their specific requirements. In the first example, mainly degraded by blurriness, multi-step sampling is preferable to single-step sampling as it progressively recovers finer details. Conversely, in the second example with severe noise, a single sampling step is sufficient to achieve satisfactory results, whereas additional steps may amplify the noise and introduce unwanted artifacts. (Zoom-in for best view)", "description": "This figure showcases a comparison between the proposed image super-resolution (SR) method and other state-of-the-art diffusion-based SR methods. Two real-world examples are used for the comparison. The number of sampling steps used for each method is indicated.  The first example demonstrates that for blurry images, multiple sampling steps progressively improve the result with finer details.  The second example, however, shows that a single sampling step is preferable for images with noise as additional steps may exacerbate it.  Runtimes for the various methods on an A100 GPU are shown for the first example's x4 (128 to 512 pixels) super-resolution task. The proposed method is highlighted as offering a flexible and efficient sampling process that can be adjusted according to the image's degradation.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.09013/x3.png", "caption": "Figure 2: Inference flow of our proposed method, wherein {\u03c4i}i=1Ssuperscriptsubscriptsubscript\ud835\udf0f\ud835\udc56\ud835\udc561\ud835\udc46\\{\\tau_{i}\\}_{i=1}^{S}{ italic_\u03c4 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT denotes the inversion timesteps. Note that the predicted noise map \ud835\udc9b\u03c4Ssubscript\ud835\udc9bsubscript\ud835\udf0f\ud835\udc46\\bm{z}_{\\tau_{S}}bold_italic_z start_POSTSUBSCRIPT italic_\u03c4 start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_POSTSUBSCRIPT exhibits an obvious correlation with the LR image, indicating the non-zero mean property of its statistical distribution.", "description": "Figure 2 illustrates the inference process of the proposed image super-resolution method.  The input is a low-resolution (LR) image. A noise predictor network (fw) estimates the initial noise map (z\u03c4S) needed to start the reverse diffusion process.  This initial noise map is added to a scaled version of the LR image, creating the starting point for the sampling process. The reverse diffusion process, using a pre-trained diffusion model, then iteratively refines this initial estimate to generate the final high-resolution (HR) image. The figure highlights that the predicted initial noise map (z\u03c4S) shows a strong correlation with the input LR image, exhibiting a non-zero mean in its statistical distribution, which is unusual for typical diffusion processes.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.09013/x4.png", "caption": "Figure 3: From left to right: (a) zoomed LR image, (b) predicted noise map by our method for the initial timestep, (c) super-resolved results by our method with a single sampling step.", "description": "This figure visually demonstrates the core concept of the proposed method.  It shows three images: (a) a zoomed-in view of a low-resolution (LR) image used as input; (b) the noise map predicted by the model's noise predictor network for the initial step of the diffusion process; and (c) the final super-resolved high-resolution (HR) image produced by the method using only a single sampling step of the reverse diffusion process.  The predicted noise map highlights the model's ability to estimate the optimal noise needed to initiate the upscaling process within the diffusion model, leading directly to a high-resolution result in a single step. This illustrates the efficiency and efficacy of the proposed Partial Noise Prediction (PnP) strategy.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.09013/x5.png", "caption": "Figure 4: Visual results of different methods on two typical real-world examples from RealSet80 dataset. For clear comparisons, the number of sampling steps is annotated in the format \u201cMethod name-Steps\u201d for diffusion-based approaches. (Zoom-in for best view)", "description": "Figure 4 presents a visual comparison of different image super-resolution (SR) methods applied to two real-world examples from the RealSet80 dataset.  The images showcase the performance of various techniques, including both diffusion-based and non-diffusion-based approaches. For the diffusion-based SR methods, the number of sampling steps used during the process is clearly indicated within the image caption, following the format \"Method Name-Steps.\"  This allows for an easy and direct comparison of performance at varying numbers of steps. The images are intended to be viewed at a zoomed-in level to fully appreciate the fine-grained details of the results.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09013/x6.png", "caption": "Figure 5: A typical visual comparison of the proposed InvSR based on different diffusion models: SD-2.0 and SD-Turbo. Note that these results are achieved with five sampling steps.", "description": "This figure compares the performance of the proposed InvSR method using two different pre-trained diffusion models as its base: Stable Diffusion 2.0 (SD-2.0) and Stable Diffusion Turbo (SD-Turbo).  Both versions of InvSR utilize five sampling steps in the image generation process. The visual comparison allows for a qualitative assessment of the image quality and the differences in the generated results when using different base diffusion models. This helps to demonstrate the impact of the choice of base diffusion model on the final image quality produced by InvSR.", "section": "B.1 Base Diffusion Model"}, {"figure_path": "https://arxiv.org/html/2412.09013/x7.png", "caption": "Figure 6: Qualitative comparisons of the proposed InvSR with different sampling steps, where the number of sampling steps is annotated in the format \u201cInvSR-Steps\u201d. In the first example, mainly degraded by blurriness, multi-step sampling is preferable to single-step sampling as it progressively recovers finer details. Conversely, in the second example with severe noise, a single sampling step is sufficient to achieve satisfactory results, whereas additional steps may amplify the noise and introduce unwanted artifacts. (Zoom-in for best view)", "description": "Figure 6 presents a qualitative comparison of the InvSR model's performance using different numbers of sampling steps. The number of steps used is indicated as \"InvSR-Steps\".  The top row shows an image primarily affected by blur. Here, multiple sampling steps are superior to a single step because they progressively reveal finer details, enhancing the image quality.  In contrast, the bottom row illustrates an image with significant noise. In this case, a single sampling step is ideal; additional steps would intensify the noise and introduce undesirable artifacts. The \"Zoom-in for best view\" note suggests the details are best observed at a higher magnification.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09013/x8.png", "caption": "Figure 7: Visual comparisons of the proposed method with various loss configurations. (a) Zoomed LR image, (b) Baseline1 with \u03bbl=0subscript\ud835\udf06\ud835\udc590\\lambda_{l}=0italic_\u03bb start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = 0 and \u03bbg=0subscript\ud835\udf06\ud835\udc540\\lambda_{g}=0italic_\u03bb start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT = 0, (c) Baseline2 with \u03bbl=2.0subscript\ud835\udf06\ud835\udc592.0\\lambda_{l}=2.0italic_\u03bb start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = 2.0 and \u03bbg=0subscript\ud835\udf06\ud835\udc540\\lambda_{g}=0italic_\u03bb start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT = 0, (d) Baseline3 with \u03bbl=0subscript\ud835\udf06\ud835\udc590\\lambda_{l}=0italic_\u03bb start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = 0 and \u03bbg=0.1subscript\ud835\udf06\ud835\udc540.1\\lambda_{g}=0.1italic_\u03bb start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT = 0.1, (e) recommended settings of \u03bbl=2.0subscript\ud835\udf06\ud835\udc592.0\\lambda_{l}=2.0italic_\u03bb start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = 2.0 and \u03bbg=0.1subscript\ud835\udf06\ud835\udc540.1\\lambda_{g}=0.1italic_\u03bb start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT = 0.1. (Zoom-in for best view)", "description": "This figure shows the impact of different loss function configurations on the performance of the proposed image super-resolution method.  It compares the results of using only the L2 loss (Baseline1), adding the LPIPS loss (Baseline2), adding the GAN loss (Baseline3), and finally using the recommended combination of L2, LPIPS, and GAN losses (InvSR-1). The zoomed LR image is also provided for comparison. The goal is to illustrate how the different loss functions affect the visual quality of the super-resolved image.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.09013/x9.png", "caption": "Figure 8: Visual comparisons of various methods on three typical examples from ImageNet-Test. For diffusion-based methods, the number of sampling steps is annotated in the format of \u201cMethod name-Steps\u201d. (Zoom-in for best view)", "description": "Figure 8 presents a qualitative comparison of different image super-resolution (SR) methods on three diverse examples sourced from the ImageNet-Test dataset.  The figure showcases the results of various techniques, including both GAN-based and diffusion-based approaches. For the diffusion-based SR models, the number of sampling steps used during the SR process is explicitly indicated in the format of 'Method Name-Steps'. This visual comparison allows for a direct assessment of the relative strengths and weaknesses of each method in terms of detail preservation, artifact reduction, and overall image quality.  The caption suggests zooming in for a more detailed examination of the results.", "section": "Experiments"}]