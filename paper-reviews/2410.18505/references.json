{"references": [{" publication_date": "2020", "fullname_first_author": "Leo Gao", "paper_title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", "reason": "This paper is foundational to the field of large language models, introducing the Pile dataset which has significantly impacted the advancement of LLMs, serving as a primary benchmark and resource for many subsequent research efforts.  The Pile's significance is further enhanced by the fact that the present work explicitly addresses the limitations of the dataset's scale and quality regarding its treatment of Chinese language data.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 Herd of Models", "reason": "This paper introduces a significant advancement in the development of LLMs. The scale and performance of the models described within the paper are directly relevant to the present work as it establishes a new benchmark which the study tries to improve upon by producing high quality Chinese datasets. The Llama 3 models have had a substantial impact on the field.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "An Yang", "paper_title": "Qwen2 Technical Report", "reason": "This report details the architecture and training of a very large language model, Qwen2, and is extremely relevant to the current study because it provides a high-quality model which is used for creating a high-quality dataset that is compared with other datasets. The methodologies employed for creating Qwen2 provides context for the current work.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Leo Gao", "paper_title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", "reason": "This paper introduces the Pile dataset, a foundational resource for LLM training. Its impact is explicitly acknowledged in the introduction, highlighting the need for similar high-quality resources in Chinese, which is the main focus of the current work.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Together Computer", "paper_title": "RedPajama: An Open Source Recipe to Reproduce Llama Training Dataset", "reason": "This paper provides a detailed methodology and the resources for reproducing a large language model training dataset, which is relevant to the current study because it helps highlight the technical aspects of creating such a high quality dataset. This paper is also crucial because it shows how open sourcing the dataset is important to development.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Sha Yuan", "paper_title": "Wudaocorpora: A Super Large-Scale Chinese Corpora for Pre-Training Language Models", "reason": "This paper presents WuDaoCorpora, a large-scale Chinese dataset relevant to the present work due to its size and focus on Chinese language modeling.  The study specifically addresses the limitations of this and other similar datasets, such as scale and quality, which are the primary motivations behind this study.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Tianwen Wei", "paper_title": "Skywork: A More Open Bilingual Foundation Model", "reason": "This study focuses on improving bilingual models and provides insights into the creation and use of large language models.  The present work references this study as it provides a good comparison point to the data quality and methodology used within the current study.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Conghui He", "paper_title": "Wanjuan: A Comprehensive Multimodal Dataset for Advancing English and Chinese Large Models", "reason": "This paper introduces Wanjuan, a multimodal dataset focusing on both English and Chinese which provides another comparison point to the present work.  The limitations and challenges encountered in this paper provide a strong argument for the current study.", "section_number": 2}, {" publication_date": "1997", "fullname_first_author": "A. Broder", "paper_title": "On the Resemblance and Containment of Documents", "reason": "This foundational paper on MinHash is crucial to the data processing pipeline in the current work, as MinHash is used for efficient document-level deduplication.  Understanding the underlying theory and effectiveness of MinHash is vital for comprehending the data preprocessing techniques employed in this paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jianghao Chen", "paper_title": "ChineseWebText: Large-Scale High-Quality Chinese Web Text Extracted with Effective Evaluation Model", "reason": "This study describes ChineseWebText, a dataset used in the current work as a baseline for quality assessment. It's critical for understanding the starting point of the data quality and the rationale for using a more sophisticated approach in the current study.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Woosuk Kwon", "paper_title": "Efficient Memory Management for Large Language Model Serving with PagedAttention", "reason": "This paper is highly relevant to the resource requirements and efficiency considerations of training and deploying large language models. The current work utilizes similar infrastructure and techniques, therefore this paper is highly relevant to the methodological discussion on efficient processing in the current work.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jianlv Chen", "paper_title": "BGE-M3-Embedding: Multi-lingual, Multi-functionality, Multi-granularity Text Embeddings Through Self-Knowledge Distillation", "reason": "This paper describes BGE-M3, a model used as the base for the quality classifier in the current study's pipeline. Understanding the model's architecture and capabilities is crucial for evaluating the effectiveness of the approach used in this study.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Raymond Li", "paper_title": "StarCoder: May the Source Be With You!", "reason": "This paper introduces StarCoder, a code dataset used in the mixed-dataset experiment of the present work.  Understanding the properties and quality of this dataset is crucial for interpreting the results of the mixed-dataset experiment.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Cl\u00e9mentine Fourrier", "paper_title": "Lighteval: A Lightweight Framework for LLM Evaluation", "reason": "This paper presents Lighteval, a crucial tool used for evaluating the performance of LLMs in this study.  Understanding its capabilities and limitations is necessary for interpreting the results and comparing the performance of different models on various datasets.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Yuzhen Huang", "paper_title": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models", "reason": "This study introduces C-Eval, a benchmark specifically designed for evaluating Chinese language models, and it's directly used in the experiments to assess the performance of models trained on the CCI3.0-HQ dataset, making this paper highly relevant to the assessment.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Haonan Li", "paper_title": "CMMLU: Measuring Massive Multitask Language Understanding in Chinese", "reason": "This paper introduces the CMMLU benchmark, another crucial tool for evaluating the performance of LLMs in Chinese. This is directly used in the experiments to assess the performance of models trained on the CCI3.0-HQ dataset, making this paper essential to understanding the methodology and results.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Peter Clark", "paper_title": "Think You Have Solved Question Answering? Try ARC, The AI2 Reasoning Challenge", "reason": "This study introduces the ARC benchmark, relevant to the experiments in assessing the reasoning abilities of LLMs. This work is referenced in the experimental setup and results section, which is highly relevant to the present work\u2019s methodology.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Rowan Zellers", "paper_title": "HellaSwag: Can a Machine Really Finish Your Sentence?", "reason": "This study introduces the HellaSwag benchmark for evaluating common-sense reasoning in LLMs. Its inclusion in the current study's experimental evaluation demonstrates the comprehensive approach taken in measuring the performance across various benchmark tasks.", "section_number": 3}, {" publication_date": "2012", "fullname_first_author": "Hector J. Levesque", "paper_title": "The Winograd Schema Challenge", "reason": "This paper introduces the Winograd Schema Challenge, a widely used benchmark in the field, which is used in this study to assess the model's performance in understanding nuanced language and resolving ambiguities. This benchmark is directly used in the paper.", "section_number": 3}]}