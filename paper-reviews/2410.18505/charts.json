[{"figure_path": "2410.18505/charts/charts_4_0.png", "caption": "Figure 2: Effects of Backbone Freezing and Learning Rate Adjustments on Classifier Tuning Performance", "description": "The chart displays the effects of backbone freezing and different learning rates on the performance of a classifier during tuning.  It shows two lines, one representing the F1 score when the backbone model is \"Locked\" (parameters frozen) and another when it's \"Unlocked\" (parameters unfrozen).  The x-axis represents the training step, while the y-axis shows the F1 score. The \"Locked\" line initially shows a slower increase in F1 score than the \"Unlocked\" line, but eventually surpasses it, suggesting that locking the backbone leads to a more efficient and robust classifier. The chart includes a second subplot showing the influence of various learning rates on the classifier's performance.", "section": "3.1 Experimental Setting"}, {"figure_path": "2410.18505/charts/charts_4_1.png", "caption": "Figure 2: Effects of Backbone Freezing and Learning Rate Adjustments on Classifier Tuning Performance", "description": "The chart displays the effects of backbone freezing and different learning rates on the F1 score during classifier tuning.  It presents learning curves for four different learning rates (lr3e-4, lr6e-4, lr1e-5, and lr1e-4), showing the F1 score plotted against the training step.  The curves show how the F1 score changes for each learning rate over the training process, allowing for a comparison of their impact on the performance of the classifier.  The use of a locked vs. unlocked backbone is also investigated, as shown in the subplot (a), which shows the effect of backbone freezing on the model performance. ", "section": "3.1 Experimental Setting"}, {"figure_path": "2410.18505/charts/charts_10_0.png", "caption": "Figure 5: Mixed Dataset Experiment", "description": "The chart visualizes the performance of various datasets across different training token amounts during a mixed dataset experiment.  Two sub-charts are presented; the left sub-chart displays the 'Average' performance across all metrics, while the right one shows the 'Average Chinese' performance, which indicates the performance on Chinese-specific metrics.  Both charts plot the performance of five datasets: Wanjuan-v1, CCI3.0, CCI3.0-HQ, SkyPile, and CCI3.0.  Each dataset's performance is represented by a different colored line, showing the change in average score as the number of training tokens increases from 0 to 100 billion.  The x-axis represents the training tokens (in billions), while the y-axis represents the average score for each dataset.  The chart indicates CCI3.0-HQ generally outperforms other datasets across both average and Chinese-specific metrics.", "section": "5.1 Evaluation of Training Dynamics"}]