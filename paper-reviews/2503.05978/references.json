{"references": [{"fullname_first_author": "Vaswani, A.", "paper_title": "Attention is all you need", "publication_date": "2017", "reason": "This paper introduced the Transformer architecture, which is a fundamental building block of many modern deep learning models, including the diffusion transformer used in MagicInfinite."}, {"fullname_first_author": "Goodfellow, Ian", "paper_title": "Generative adversarial networks", "publication_date": "2020-11-01", "reason": "This paper introduced Generative Adversarial Networks (GANs) which serve as one of the most influential deep learning frameworks which MagicInfinite compares its performance against."}, {"fullname_first_author": "Kingma, Diederik P", "paper_title": "Auto-encoding variational bayes", "publication_date": "2013", "reason": "Auto-Encoding Variational Bayes (VAEs) forms the basis of the causal 3D VAE component used within the MagicInfinite architecture to compresses pixel-space videos and images into a compact latent space, reducing the token count for the subsequent diffusion transformer model."}, {"fullname_first_author": "Ho, Jonathan", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2022", "reason": "Classifier-free guidance is a key technique used in diffusion models, which MagicInfinite incorporates to improve the quality and controllability of the generated videos."}, {"fullname_first_author": "Rombach, Robin", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022", "reason": "This paper introduced Latent Diffusion Models (LDMs) which MagicInfinite builds upon and applies T2V diffusion to portrait animation with better diversity and coherence."}]}