[{"figure_path": "2410.11331/tables/table_1_0.html", "caption": "Table 1: Specifications of Shakti-LLM", "description": "Table 1 presents the specifications of the Shakti-LLM, including model parameters, dimensions, and hyperparameters.", "section": "4 Continued Pretraining (CPT)"}, {"figure_path": "2410.11331/tables/table_4_0.html", "caption": "Table 1: Specifications of Shakti-LLM", "description": "Table 1 provides a detailed specification of the Shakti-LLM model, outlining its key architectural features and resource requirements.", "section": "4 Shakti-LLM Specification"}, {"figure_path": "2410.11331/tables/table_6_0.html", "caption": "Table 2: Benchmark Comparison of Various Models. Bolded values indicate the highest scores, and underlined values indicate the second highest.", "description": "Table 2 summarizes the performance of Shakti-LLM compared to other models across key NLP benchmarks.", "section": "5.1 Popular Benchmarks and Results"}, {"figure_path": "2410.11331/tables/table_7_0.html", "caption": "Table 3: Performance comparison of different quantized language models across various hardware platforms. The table shows model names, quantization types, model sizes, and inference speeds (in tokens per second) on GPU, CPU, and Mac systems", "description": "Table 3 compares the performance of different quantized language models across various hardware platforms, showing inference speeds in tokens per second for GPU, CPU, and Mac systems.", "section": "5.5 Model Inference and Performance Efficiency"}, {"figure_path": "2410.11331/tables/table_8_0.html", "caption": "Table 3: Performance comparison of different quantized language models across various hardware platforms. The table shows model names, quantization types, model sizes, and inference speeds (in tokens per second) on GPU, CPU, and Mac systems", "description": "Table 3 presents a performance comparison of different quantized language models across various hardware platforms, showing model names, quantization types, sizes, and inference speeds.", "section": "5.5 Model Inference and Performance Efficiency"}, {"figure_path": "2410.11331/tables/table_10_0.html", "caption": "Table 3: Performance comparison of different quantized language models across various hardware platforms. The table shows model names, quantization types, model sizes, and inference speeds (in tokens per second) on GPU, CPU, and Mac systems", "description": "Table 3 compares the performance of different quantized language models across various hardware platforms, showing their inference speeds in tokens per second.", "section": "5.5 Model Inference and Performance Efficiency"}]