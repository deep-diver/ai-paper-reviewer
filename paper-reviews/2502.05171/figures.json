[{"figure_path": "https://arxiv.org/html/2502.05171/x1.png", "caption": "Figure 1: We train a 3.5B parameter language model with depth recurrence. At test time, the model can iterate longer to use more compute and improve its performance. Instead of scaling test-time reasoning by \u201cverbalizing\u201d in long Chains-of-Thought, the model improves entirely by reasoning in latent space. Tasks that require less reasoning like OpenBookQA converge quicker than tasks like GSM8k, which effectively make use of more compute.", "description": "This figure demonstrates the performance of a 3.5 billion parameter language model that utilizes depth recurrence.  Depth recurrence allows the model to iteratively process information in latent space during inference, increasing computation time and improving accuracy.  Unlike methods that rely on chain-of-thought prompting to extend reasoning, this model implicitly reasons in its latent space. The graph shows accuracy improvements across three reasoning benchmarks (ARC challenge, GSM8K Chain-of-Thought, and OpenBookQA) as a function of increasing test-time compute (controlled by the number of recurrent iterations).  OpenBookQA, a task requiring less complex reasoning, shows faster convergence to a peak accuracy than GSM8K, which benefits significantly from increased compute. This highlights the model's ability to leverage additional computation time for improved performance on more demanding reasoning tasks.", "section": "Scaling up Test-Time Compute with Recurrent Depth"}, {"figure_path": "https://arxiv.org/html/2502.05171/x2.png", "caption": "Figure 2: A visualization of the Architecture, as described in Section\u00a03. Each block consists of a number of sub-layers. The blue prelude block embeds the inputs into latent space, where the green shared recurrent block is a block of layers that is repeated to compute the final latent state, which is decoded by the layers of the red coda block.", "description": "The figure illustrates the model's architecture, which is composed of three main blocks: a prelude, a recurrent block, and a coda.  The prelude block processes the input sequence and embeds it into a latent space.  The recurrent block is the core of the model, iterating multiple times (unrolling at test time) to perform latent reasoning. The number of iterations in the recurrent block is sampled during training and determines the test-time compute budget. Finally, the coda block decodes the final latent state generated by the recurrent block to produce the output sequence. Each block is further comprised of multiple sub-layers, typically transformer layers.  The figure highlights the flow of information through these blocks using color-coding to distinguish them visually. The recurrence allows for scaling test-time compute by increasing the number of iterations in the recurrent block, allowing the model to perform more reasoning steps.", "section": "A scalable recurrent architecture"}, {"figure_path": "https://arxiv.org/html/2502.05171/x3.png", "caption": "Figure 3: We use a log-normal Poisson Distribution to sample the number of recurrent iterations for each training step.", "description": "The figure shows the distribution of the number of recurrent iterations randomly sampled for each training step.  Instead of using a fixed number of iterations, the model is trained with a variable number of iterations drawn from a log-normal Poisson distribution. This approach helps the model learn to handle different computational loads at test time, by ensuring it can scale up the computation if needed without the need for specialized training data. The distribution's properties help balance between shorter and longer computation chains, promoting better generalization.", "section": "3. A scalable recurrent architecture"}, {"figure_path": "https://arxiv.org/html/2502.05171/x4.png", "caption": "Figure 4: Distribution of data sources that are included during training. The majority of our data is comprised of generic web-text, scientific writing and code.", "description": "This figure shows a pie chart that breaks down the composition of the training dataset used for the language model.  The dataset is comprised of several different sources of text and code.  The largest portions of the data are generic web text (28.71%), code (25.36%), and scientific text (18.73%). Smaller portions are made up of synthetic text (8.14%), long-form text (7.5%), math (6.14%), generic instructions (2.09%), Q&A text (1.58%), math instructions (1.51%), writing instructions (0.12%), and miscellaneous reasoning data (0.11%).  This illustrates the diverse range of data types used to train the model, which is likely to contribute to its improved reasoning capabilities.", "section": "4. Training a large-scale recurrent-depth Language Model"}, {"figure_path": "https://arxiv.org/html/2502.05171/x5.png", "caption": "Figure 5: Plots of the initial 10000 steps for the first two failed attempts and the final, successful run (\u201cMain\u201d). Note the hidden state collapse (middle) and collapse of the recurrence (right) in the first two failed runs, underlining the importance of our architecture and initialization in inducing a recurrent model and explain the underperformance of these runs in terms of pretraining loss (left).", "description": "This figure displays training curves for three attempts to train the model. The left plot shows the pretraining loss, the middle plot shows the correlation between hidden states, and the right plot shows validation perplexity. The first two attempts failed, exhibiting hidden state collapse (where the model predicts the same hidden state for every token) and recurrence collapse (where the model's performance plateaus despite additional compute).  The final attempt successfully trained a recurrent model, highlighting the importance of the architecture and initialization in enabling successful recurrent training and preventing collapse. The differences in the curves highlight the significance of architectural design and initialization in achieving successful recurrent model training.", "section": "3. A scalable recurrent architecture"}, {"figure_path": "https://arxiv.org/html/2502.05171/x8.png", "caption": "Figure 6: Left: Plot of pretrain loss over the 800B tokens on the main run. Right: Plot of val ppl at recurrent depths 1, 4, 8, 16, 32, 64. During training, the model improves in perplexity on all levels of recurrence.", "description": "This figure displays the training progress of a large language model.  The left panel shows the training loss, a measure of how well the model is learning during training.  The loss decreases gradually over 800 billion tokens processed. The right panel shows the validation perplexity (val ppl) for different model depths (1, 4, 8, 16, 32, 64).  Validation perplexity is a measure of how well the model performs on unseen data, similar to test data, so it assesses generalization ability.  Importantly, at all tested depths, the validation perplexity decreases as the model trains, indicating improvement in generalization performance across model depths.", "section": "Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x12.png", "caption": "Table 2: Benchmarks of mathematical reasoning and understanding. We report flexible and strict extract for GSM8K and GSM8K CoT, extract match for Minerva Math, and acc norm. for MathQA.", "description": "This table presents the results of several mathematical reasoning and understanding benchmarks.  The benchmarks used are GSM8K (both standard and Chain-of-Thought versions), Minerva Math, and MathQA.  For GSM8K and GSM8K CoT, the metrics reported are \"flexible extract\" and \"strict extract\" accuracy.  For Minerva Math, the metric is \"extract match\" accuracy, and for MathQA, the metric is \"normalized accuracy\". The table allows for a comparison of the performance of different language models on these challenging tasks. Each row represents a different language model, and the columns show its performance on each benchmark.", "section": "5. Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x13.png", "caption": "Table 3: Evaluation on code benchmarks, MBPP and HumanEval. We report pass@1 for both datasets.", "description": "This table presents the results of evaluating the performance of different language models on two prominent code-related benchmarks: MBPP (Massive Benchmarks for Program Synthesis) and HumanEval (a benchmark focusing on evaluating the code generation capabilities of large language models).  The \"pass@1\" metric indicates the percentage of times the model successfully generated correct code on the first attempt.  The table allows for a comparison of various models, showing their relative strengths and weaknesses in terms of code generation accuracy.", "section": "5. Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/extracted/6187079/figures/convergence_chart_range_I_74_103.png", "caption": "Figure 7: Performance on GSM8K CoT (strict match and flexible match), HellaSwag (acc norm.), and HumanEval (pass@1). As we increase compute, the performance on these benchmarks increases. HellaSwag only needs 8888 recurrences to achieve near peak performance while other benchmarks make use of more compute.", "description": "Figure 7 presents a graph illustrating the performance of a recurrent language model on three distinct benchmarks: GSM8K CoT (both strict and flexible match conditions), HellaSwag (accuracy normalized), and HumanEval (pass@1).  The x-axis represents the number of recurrences (test-time compute) used by the model, while the y-axis shows the corresponding performance.  The graph demonstrates that increasing the test-time computation, by allowing more recurrences, generally leads to improved performance across all three benchmarks. Notably, the HellaSwag benchmark shows near peak performance with a relatively small number of recurrences (around 8), suggesting it doesn't require extensive reasoning. In contrast, the GSM8K CoT and HumanEval benchmarks exhibit performance gains even at higher recurrence levels, indicating their need for greater computational resources to solve the problems accurately.  This highlights the varying computational demands of different reasoning tasks.", "section": "5. Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x17.png", "caption": "Figure 8: GSM8K CoT, HellaSwag, and HumanEval performance over the training tokens with different recurrences at test-time. We evaluate GSM8K CoT with chat template and 8-way few shot as multiturn. HellaSwag and HumanEval are zero-shot with no chat template. Model performance on harder tasks grows almost linearly with the training budget, if provided sufficient\ntest-time compute.", "description": "This figure displays the performance of a recurrent depth language model on three different tasks (GSM8K CoT, HellaSwag, and HumanEval) across various numbers of training tokens and recurrence levels at test time.  The GSM8K CoT results incorporate a chat template and 8-way few-shot learning in a multi-turn setting, while HellaSwag and HumanEval results are generated zero-shot, without a chat template. The graph highlights that the model's performance, particularly on more challenging tasks, shows an almost linear improvement as the training budget (tokens) increases, provided sufficient test-time compute (recurrence steps) is used.", "section": "Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x22.png", "caption": "Figure 9: The saturation point in un-normalized accuracy via test-time recurrence on the ARC challenge set is correlated with the number of few-shot examples. The model uses more recurrence to extract more information from the additional few-shot examples, making use of more compute if more context is given.", "description": "This figure displays the relationship between test-time compute (measured by the number of recurrences), the number of few-shot examples provided as context, and the model's accuracy on the ARC challenge set.  The x-axis represents the number of recurrences, which corresponds to the computational resources used at test time. The y-axis represents the model's accuracy. Different lines show the accuracy achieved when varying numbers of few-shot examples (additional context) are provided. The plot illustrates that when more context is provided, the model's accuracy increases with higher test-time compute (more recurrences) and requires more iterations to reach saturation. This shows that the model effectively uses additional computational time to process the extra information present in the few-shot examples to boost its performance. In other words, the model does not have a fixed limit on its computational budget but dynamically adapts its resource consumption based on the complexity of the task, represented here by the amount of context available.", "section": "Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x23.png", "caption": "Figure 10: Histograms of zero-shot, per-token adaptive exits based on KL difference between steps for questions from MMLU categories, with and without zero-shot continuous CoT. The mean of each distribution is given in the legends. The exit threshold is fixed to 5\u00d710\u221245E-45\\text{\\times}{10}^{-4}start_ARG 5 end_ARG start_ARG times end_ARG start_ARG power start_ARG 10 end_ARG start_ARG - 4 end_ARG end_ARG. We see that the model converges quicker on high school mathematics than tasks such as logical fallacies or moral scenarios. On some tasks, such as philosophy, the model is able to effectively re-use states in its latent CoT and converge quickly on a subset of tokens, leading to fewer steps required overall.", "description": "Figure 10 presents histograms illustrating the number of steps required for a language model to reach a convergence threshold during zero-shot per-token adaptive computation.  The model's task is answering questions from different categories within the MMLU benchmark.  Two scenarios are compared: with and without zero-shot continuous Chain-of-Thought (CoT).  The Kullback-Leibler (KL) divergence between successive steps serves as the convergence metric; convergence is declared when the KL divergence falls below 5e-4.  The histograms show the distribution of the number of steps until convergence for each question category.  Analysis reveals variations in convergence speed across different question categories, with faster convergence observed for questions related to high school mathematics compared to those concerning logical fallacies or moral scenarios.  Interestingly, the model demonstrates the ability to reuse latent states within its continuous CoT, particularly evident in philosophy questions, resulting in fewer steps to convergence for certain tokens within those specific questions.", "section": "6. Zero-Shot Adaptive Compute at Test-Time"}, {"figure_path": "https://arxiv.org/html/2502.05171/x24.png", "caption": "Figure 11: Convergence of latent states for every token in a sequence (going top to bottom) and latent iterations (going left to right), plotting the distance a final iterate s\u2217superscript\ud835\udc60s^{*}italic_s start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT, which we set with r=128\ud835\udc5f128r=128italic_r = 128. Shown is an unsafe question posed to the model. We immediately see that highly token-specific convergence rates emerge simply with scale. This is interesting, as the model is only trained with r\ud835\udc5fritalic_r fixed for whole sequences seen during training. We see that convergence is especially slow on the key part of the question, really wrong-ed.We further see that the model also learns different behaviors, we see an oscillating pattern in latent space, here most notably for the school token.", "description": "Figure 11 visualizes the convergence of latent states within a recurrent language model.  The figure displays the distance of each latent state (at each time step of the recurrence) from a final converged state, calculated using 128 iterations.  Each row represents a token in a sentence (ordered from top to bottom). Each column shows a different iteration step of the model's recurrence (ordered from left to right). The input sentence is a question considered unsafe by human standards. The visualization reveals token-specific convergence rates, some converging much faster than others. This is notable because the model was trained with a fixed number of iterations for each entire sequence, not individual tokens.  The figure also shows that the model exhibits varied behaviors in latent space during inference, including oscillating patterns, especially evident for the word \"school\". The visualization demonstrates that even though the model was trained with a fixed recurrence depth, its latent representations can have varied convergence properties, highlighting the dynamic nature of its test-time computation.", "section": "7. What Mechanisms Emerge at Scale in Recurrent-Depth Models"}, {"figure_path": "https://arxiv.org/html/2502.05171/extracted/6187079/figures/convergence_chart_range_W_182_241.png", "caption": "Figure 12: Latent Space trajectories for select tokens. We show a small part of these high-dimensional trajectories by visualizing the first 6 PCA directions, computing the PCA over all latent state trajectories of all tokens in a sequence. The color gradient going from dark to bright represents steps in the trajectory. The center of mass is marked in red. While on many tokens, the state simply converges (top row), the model also learns to use orbits (middle row), and \u201csliders\u201d (bottom row, middle) to represent and handle more advanced concepts, such as arithmetic or complicated deliberation.", "description": "This figure visualizes the latent space trajectories of selected tokens within a sequence.  The first six principal components (PCs) of the high-dimensional latent space are projected into 2D plots (three pairs of PCs). Each point in a trajectory represents the latent state of a given token at a particular time step during the recurrent process. A color gradient maps the progression of steps within the trajectory, with dark colors indicating early steps and bright colors indicating later steps. The centroid of each trajectory is marked in red.  The top row illustrates simple convergence behavior, where the latent state steadily approaches a fixed point. The middle row showcases the emergence of cyclic or orbital patterns in the latent space, suggesting a more complex, iterative reasoning process. The bottom row exemplifies a 'sliding' behavior along a specific direction in the latent space. These different behaviors demonstrate how the model uses latent space to represent and process various kinds of information, including arithmetic operations and complex deliberation.", "section": "7. What Mechanisms Emerge at Scale in Recurrent-Depth Models"}, {"figure_path": "https://arxiv.org/html/2502.05171/extracted/6187079/figures/convergence_chart_range_C_19_40.png", "caption": "Figure 13: Additional categories for Figure\u00a010 in the main body.", "description": "This figure expands on Figure 10 by displaying histograms of the number of steps required to reach a KL-based convergence threshold for various MMLU question categories.  Both zero-shot and continuous chain-of-thought (CoT) results are included for each category, enabling a comparison of convergence speeds under different conditions. The histograms show the distribution of steps needed, revealing differences in convergence behavior across different types of questions.  Faster convergence might indicate easier tasks for the model.", "section": "Zero-Shot Adaptive Compute at Test-Time"}, {"figure_path": "https://arxiv.org/html/2502.05171/extracted/6187079/figures/convergence_chart_range_I_74_103.png", "caption": "Figure 14: Multi-Operand Arithmetic. Following a precedent of training recurrent architectures for algorithmic and arithmetic tasks (Schwarzschild et\u00a0al., 2021b; Bansal et\u00a0al., 2022; Schwarzschild et\u00a0al., 2023; McLeish et\u00a0al., 2024), we explore whether our model can leverage increased test-time compute via recurrence to solve verbalized addition problems of increased difficulty. For these problems we use the following system prompt \u2018\u2018You are a helpful assistant that is capable of helping users with mathematical reasoning.\u2019\u2019 embedded in a conversational chat template, and we present each problem by opening the first user turn of the conversation like so: f\"What is the result of \u2019 + \u2019.join(map(str, digits))?\" after randomly sampling numbers according to a certain operand count and digit count (base 10). We score correct answers by checking whether the correct sum appears as as string anywhere in the model\u2019s output, and for each measurement, we average over 50 trials. \n\nIn the heatmap (top left), we evaluate the model at 32 recurrences to get a upper estimate of its addition performance at various difficulties. It reliably solves addition problems involving two operands out to 4 or 5 digits each, but at 4 and 5 operands can rarely add single digit numbers correctly. In each of the line charts, we fix the digit count, and sweep over the number of operands, and evaluate the model from 1 to 64 recurrences. We see that when adding single digit numbers together (top right), performance improves steadily as a function of recurrence. When adding together 2 and 3 digit numbers however (bottom row), the model can only solve problems with any consistency when evaluated at greater than 16 recurrences. Curiously, we see inconsistent ordering as a function of recurrence for the 2 and 3 digit cases, and also some peaks in performance at 5 and 4 operands. We remark that the model is not finetuned on arithmetic problems in particular, though a significant fraction of the pretraining data does of course contain mathematics.", "description": "This figure displays the results of an experiment testing the model's ability to perform multi-operand addition with varying difficulty levels. The experiment involved presenting the model with addition problems of different operand counts and digit counts, using a system prompt and conversational chat template. The results are presented in a heatmap (top left) showing the model's accuracy at 32 recurrences and line charts showing accuracy with varying numbers of recurrences for problems with 1, 2 and 3 digits.  The results suggest that the model's performance improves with increased test-time compute (recurrence) especially for more difficult problems.", "section": "5. Benchmark Results"}, {"figure_path": "https://arxiv.org/html/2502.05171/x28.png", "caption": "Figure 15: Main directions in latent space, for a) a math question, 2) a trivia question and 3) an unsafe question, which will be described in more detail below. Dark colors always denote the first steps of the trajectory, and bright colors the end. Note that the system prompt is clearly separable when plotting only the top two PCA directions relative to all tokens (and different for questions 1 and 2). Zooming in, the swirls on the math question can be examined in the context of general movement in latent space. More detailed visualizations follow on later pages.", "description": "This figure visualizes the latent space trajectories of tokens in three different types of questions: a mathematical question, a trivia question, and an unsafe question.  The top two principal components (PCs) of the latent space are plotted against the token's position in the sequence. Darker colors represent the initial steps of the trajectory while lighter colors indicate later steps. The system prompt is clearly distinct when considering only the first two PCs. Detailed analysis of latent space trajectories, including those for individual tokens, can be found in later sections of the paper.", "section": "7. What Mechanisms Emerge at Scale in Recurrent-Depth Models"}, {"figure_path": "https://arxiv.org/html/2502.05171/x29.png", "caption": "Figure 16: Latent Space trajectories for a math question. The model is rotating the number three, on which the problem hinges. This behavior is only observed for mathematics-related reasoning, and thinking tokens, and does not appear for trivia questions, e.g. as above. The question is Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks? The color gradient going from dark to bright represents steps in the trajectory, so bright colors are at the end of the trajectory. The center of mass is marked in red.", "description": "This figure visualizes the latent space trajectories of tokens within a language model processing a math word problem.  The model's internal reasoning is represented by the movement of token vectors through latent space.  The plot shows the trajectory of tokens over several iterations.  It's particularly noteworthy that the model's representation of the number '3' (central to the problem) follows a circular path, suggesting the model performs a form of rotation or cyclical computation to arrive at the solution. This 'rotation' pattern was only observed in mathematical problems; similar plots for other tasks (such as general knowledge questions) showed different, typically linear, trajectories.  The color intensity of the path indicates the progression of the computation, with lighter colors representing earlier steps and darker colors representing later steps.  The center of mass is shown in red.", "section": "7. What Mechanisms Emerge at Scale in Recurrent-Depth Models"}, {"figure_path": "https://arxiv.org/html/2502.05171/x30.png", "caption": "Figure 17: Latent Space trajectories for a standard trivia question, What do you think of Goethe\u2019s Faust?. Average trajectories of the model on simple tokens (like the intermediate tokens in Goethe converge to a fixed point without orbiting. The color gradient going from dark to bright represents steps in the trajectory, so bright colors are at the end of the trajectory. The center of mass is marked in red.", "description": "This figure visualizes the latent space trajectories of tokens in a model's response to a standard trivia question.  The analysis focuses on the movement of token representations within the high-dimensional latent space as the model processes the question. Specifically, it examines how simple tokens (like the intermediate tokens in the word \"Goethe\") converge towards a fixed point in the latent space, indicating a stable and predictable representation. The color gradient in the trajectory lines maps the progression of iterations, with dark colors representing early steps and bright colors indicating the end of the iterative process. The center of mass for each trajectory is marked in red.  This visualization offers insights into the model's internal reasoning process, demonstrating a characteristic behavior of convergence without complex patterns such as orbiting or cyclical movement.", "section": "7. What Mechanisms Emerge at Scale in Recurrent-Depth Models"}]