{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024", "reason": "This paper introduces the visual instruction tuning method, which is the foundation of the BlueLM-V-3B model's architecture and significantly impacts its performance."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2024", "reason": "This paper proposes InternVL, a strong multimodal large language model that heavily influences BlueLM-V-3B's design and serves as a key comparative model."}, {"fullname_first_author": "Haotian Liu", "paper_title": "LLaVA-NeXT: Improved reasoning, OCR, and world knowledge", "publication_date": "2024", "reason": "This paper introduces LLaVA-NeXT, a significant advancement in multimodal large language models, directly impacting BlueLM-V-3B's dynamic resolution scheme."}, {"fullname_first_author": "Marah Abdin", "paper_title": "Phi-3 technical report: A highly capable language model locally on your phone", "publication_date": "2024-04-14", "reason": "This paper introduces Phi-3, a highly capable language model designed for mobile devices, offering a key comparison point for BlueLM-V-3B's performance and efficiency on mobile platforms."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023", "reason": "This paper introduces Llama, an influential open-source language model that forms the base language model of BlueLM-V-3B, making it a crucial reference for understanding the model's linguistic capabilities."}]}