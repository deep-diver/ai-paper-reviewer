{"references": [{"fullname_first_author": "Yash Goyal", "paper_title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering", "publication_date": "2017-01-01", "reason": "This paper emphasizes the importance of image understanding in Visual Question Answering (VQA), which is a core theme in the study of how VLMs handle visual information."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper is one of the seminal works on visual instruction tuning, a common methodology in current VLMs."}, {"fullname_first_author": "Minesh Mathew", "paper_title": "Docvqa: A dataset for vqa on document images", "publication_date": "2021-01-01", "reason": "This paper introduces the DocVQA dataset, which is utilized in this study to evaluate VLMs' performance in document understanding."}, {"fullname_first_author": "Freda Shi", "paper_title": "Large language models can be easily distracted by irrelevant context", "publication_date": "2023-01-01", "reason": "This paper investigates how large language models are influenced by irrelevant context, which is relevant to the analysis of text bias in this submission."}, {"fullname_first_author": "Pan Lu", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts", "publication_date": "2024-01-01", "reason": "This paper introduces the MathVista dataset, which is utilized in this study to evaluate VLMs' performance in mathematical reasoning."}]}