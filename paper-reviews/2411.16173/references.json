{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for large language models (LLMs) and is the basis of many subsequent advancements in the field."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a significant early multimodal LLM that combines visual and language understanding."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, presented in this paper, is a highly influential model that connects images and text, enabling various multimodal applications."}, {"fullname_first_author": "Christoph Feichtenhofer", "paper_title": "Slowfast networks for video recognition", "publication_date": "2019-10-01", "reason": "This paper introduces SlowFast networks, a highly influential architecture for video analysis that is adapted in the current work."}, {"fullname_first_author": "Bo Li", "paper_title": "LLaVA-onevision: Easy visual task transfer", "publication_date": "2024-08-01", "reason": "LLaVA, presented in this paper, is a state-of-the-art model that directly inspired the current work, offering a strong baseline for comparison."}]}