[{"content": "MJHQ | sDCI\n---|---|---|---|---|---|---|---|---|---|---\nBackbone | Model | Precision | Method | Quality (FID \u2193) | Similarity (IR \u2191) | Quality (LPIPS \u2193) | Similarity (PSNR \u2191) | Quality (FID \u2193) | Similarity (IR \u2191) | Quality (LPIPS \u2193) | Similarity (PSNR \u2191)\n---|---|---|---|---|---|---|---|---|---|---\n |  FLUX.1-dev (50 Steps) | BF16 | \u2013 | 20.3 | 0.953 | \u2013 | \u2013 | 24.8 | 1.02 | \u2013 | \u2013\n | INT W8A8 | Ours | 20.4 | 0.948 | 0.089 | 27.0 | 24.7 | 1.02 | 0.106 | 24.9\n | W4A16 | NF4 | 20.6 | 0.910 | 0.272 | 19.5 | 24.9 | 0.986 | 0.292 | 18.2\n | INT W4A4 | Ours | **19.9** | 0.932 | 0.254 | 20.1 | **24.7** | 0.992 | 0.273 | **18.8**\n | FP W4A4 | Ours | 21.0 | **0.933** | **0.247** | **20.2** | 25.7 | **0.995** | **0.267** | 18.7\n |  FLUX.1-schnell (4 Steps) | BF16 | \u2013 | 19.2 | 0.938 | \u2013 | \u2013 | 20.8 | 0.932 | \u2013 | \u2013\n | INT W8A8 | Ours | 19.2 | 0.966 | 0.120 | 22.9 | 20.7 | 0.975 | 0.133 | 21.3\nDiT | W4A16 | NF4 | 18.9 | 0.943 | **0.257** | **18.2** | 20.7 | 0.953 | **0.263** | **17.1**\n | INT W4A4 | Ours | **18.4** | **0.969** | 0.292 | 17.5 | **20.1** | **0.988** | 0.299 | 16.3\n | FP W4A4 | Ours | 19.9 | 0.956 | 0.279 | 17.5 | 21.5 | 0.967 | 0.278 | 16.6\n | PixArt-\u03a3 (20 Steps) | FP16 | \u2013 | 16.6 | 0.944 | \u2013 | \u2013 | 24.8 | 0.966 |  | \n | INT W8A8 | ViDiT-Q | **15.7** | 0.944 | 0.137 | 22.5 | **23.5** | **0.974** | 0.163 | 20.4\n | INT W8A8 | Ours | 16.3 | **0.955** | **0.109** | **23.7** | 24.2 | 0.969 | **0.129** | **21.8**\n | INT W4A8 | ViDiT-Q | 37.3 | 0.573 | 0.611 | 12.0 | 40.6 | 0.600 | 0.629 | 11.2\n | INT W4A4 | ViDiT-Q | 412 | -2.27 | 0.854 | 6.44 | 425 | -2.28 | 0.838 | 6.70\n | INT W4A4 | Ours | 20.1 | 0.898 | 0.394 | 16.2 | 25.1 | 0.922 | 0.434 | 14.9\n | FP W4A4 | Ours | 18.3 | **0.946** | **0.326** | **17.4** | 23.7 | **0.978** | **0.357** | **16.1**\nUNet |  SDXL-Turbo (4 Steps) | FP16 | \u2013 | 24.3 | 0.845 | \u2013 | \u2013 | 24.7 | 0.705 | \u2013 | \u2013\n | INT W8A8 | MixDQ | **24.1** | 0.834 | 0.147 | 21.7 | 25.0 | 0.690 | 0.157 | 21.6\n | INT W8A8 | Ours | 24.3 | **0.845** | **0.100** | **24.0** | **24.8** | **0.701** | **0.110** | **23.7**\n | INT W4A8 | MixDQ | 27.7 | 0.708 | 0.402 | 15.7 | 25.9 | 0.610 | 0.415 | 15.7\n | INT W4A4 | MixDQ | 353 | -2.26 | 0.685 | 11.0 | 373 | -2.28 | 0.686 | 11.3\n | INT W4A4 | Ours | 24.5 | 0.816 | 0.265 | 17.9 | 25.7 | 0.667 | 0.278 | 17.8\n | FP W4A4 | Ours | **24.1** | **0.822** | **0.250** | **18.5** | **24.7** | **0.699** | **0.261** | **18.4**\n |  SDXL (30 Steps) | FP16 | \u2013 | 16.6 | 0.729 | \u2013 | \u2013 | 22.5 | 0.573 | \u2013 | \u2013\n | INT W8A8 | TensorRT | 20.2 | 0.591 | 0.247 | 22.0 | 25.4 | 0.453 | 0.265 | 21.7\n | INT W8A8 | Ours | **16.6** | **0.718** | **0.119** | **26.4** | **22.4** | **0.574** | **0.129** | **25.9**\n | INT W4A4 | Ours | 20.7 | 0.609 | 0.298 | 20.6 | 26.3 | 0.494 | 0.314 | 20.4\n | FP W4A4 | Ours | **19.0** | **0.607** | **0.294** | **21.0** | **25.4** | **0.480** | **0.312** | **20.7**", "caption": "Table 1: \nQuantitative quality comparisons across different models. IR means ImageReward. Our 8-bit results closely match the quality of the 16-bit models. Moreover, our 4-bit results outperform other 4-bit baselines, effectively preserving the visual quality of 16-bit models.", "description": "This table presents a quantitative comparison of image quality across various diffusion models and different bit-depths (8-bit and 4-bit) of weight and activation quantization.  It uses several metrics, including FID (Fr\u00e9chet Inception Distance), IR (ImageReward), LPIPS (Learned Perceptual Image Patch Similarity), and PSNR (Peak Signal-to-Noise Ratio), to assess the visual quality of the generated images. The results demonstrate that the 8-bit quantized models achieve similar image quality to the original 16-bit models.  Furthermore, the 4-bit quantized models using the proposed SVDQuant method significantly outperform other existing 4-bit quantization baselines, indicating that SVDQuant effectively preserves image quality even at a very aggressive quantization level.", "section": "5 Experiments"}, {"content": "| Backbone | Model | Precision | Method | MJHQ Quality | MJHQ Similarity | sDCI Quality | sDCI Similarity |\n|---|---|---|---|---|---|---|---| \n|  |  |  |  | C.IQA (\u2191) | C.SCR (\u2191) | C.IQA (\u2191) | C.SCR (\u2191) |\n|  | FLUX.1-dev (50 Steps) | BF16 | \u2013 | 0.952 | 26.0 | 0.955 | 25.4 |\n|  | INT W8A8 Ours |  | 0.953 | 26.0 | 0.748 | 0.955 | 25.4 | 0.697 |\n|  | W4A16 NF4 |  | 0.947 | 25.8 | 0.748 | 0.951 | 25.4 | 0.697 |\n|  | INT W4A4 Ours |  | 0.950 | 25.8 | 0.773 | 0.953 | 25.3 | 0.721 |\n|  | FP W4A4 Ours |  | 0.950 | 25.8 | 0.780 | 0.952 | 25.3 | 0.727 |\n|  | FLUX.1-schnell (4 Steps) | BF16 | \u2013 | 0.938 | 26.6 | 0.932 | 26.2 |\n|  | INT W8A8 Ours |  | 0.938 | 26.6 | 0.844 | 0.932 | 26.2 | 0.811 |\n| DiT | W4A16 NF4 |  | 0.941 | 26.6 | 0.713 | 0.933 | 26.2 | 0.674 |\n|  | INT W4A4 Ours |  | 0.939 | 26.5 | 0.693 | 0.932 | 26.2 | 0.647 |\n|  | FP W4A4 Ours |  | 0.938 | 26.5 | 0.703 | 0.933 | 26.2 | 0.667 |\n|  | PixArt-\u03a3 (20 Steps) | FP16 | \u2013 | 0.944 | 26.8 | 0.966 | 26.1 |\n|  | INT W8A8 ViDiT-Q |  | 0.948 | 26.7 | 0.815 | 0.966 | 26.1 | 0.756 |\n|  | INT W8A8 Ours |  | 0.947 | 26.8 | 0.849 | 0.967 | 26.0 | 0.800 |\n|  | INT W4A8 ViDiT-Q |  | 0.912 | 25.7 | 0.356 | 0.917 | 25.4 | 0.295 |\n|  | INT W4A4 ViDiT-Q |  | 0.185 | 13.3 | 0.077 | 0.176 | 13.3 | 0.080 |\n|  | INT W4A4 Ours |  | 0.927 | 26.6 | 0.602 | 0.952 | 26.1 | 0.519 |\n|  | FP W4A4 Ours |  | 0.935 | 26.7 | 0.652 | 0.957 | 26.1 | 0.574 |\n| UNet | SDXL-Turbo (4 Steps) | FP16 | \u2013 | 0.926 | 26.5 | 0.913 | 26.5 |\n|  | INT W8A8 MixDQ |  | 0.922 | 26.5 | 0.763 | 0.907 | 26.5 | 0.750 |\n|  | INT W8A8 Ours |  | 0.925 | 26.5 | 0.821 | 0.912 | 26.5 | 0.808 |\n|  | INT W4A8 MixDQ |  | 0.893 | 25.9 | 0.512 | 0.895 | 26.1 | 0.493 |\n|  | INT W4A4 MixDQ |  | 0.556 | 13.1 | 0.289 | 0.548 | 11.9 | 0.296 |\n|  | INT W4A4 Ours |  | 0.916 | 26.5 | 0.630 | 0.894 | 26.8 | 0.610 |\n|  | FP W4A4 Ours |  | 0.919 | 26.4 | 0.640 | 0.901 | 26.7 | 0.620 |\n|  | SDXL (30 Steps) | FP16 | \u2013 | 0.907 | 27.2 | 0.911 | 26.5 |\n|  | INT W8A8 TensorRT |  | 0.905 | 26.7 | 0.733 | 0.901 | 26.1 | 0.697 |\n|  | INT W8A8 Ours |  | 0.912 | 27.0 | 0.843 | 0.910 | 26.3 | 0.814 |\n|  | INT W4A4 Ours |  | 0.916 | 26.5 | 0.630 | 0.894 | 26.8 | 0.610 |\n|  | FP W4A4 Ours |  | 0.919 | 26.4 | 0.640 | 0.901 | 26.7 | 0.620 |", "caption": "Table 2: \nAdditional quantitative quality comparisons across different models. C.IQA means CLIP IQA, and C.SCR means CLIP Score.", "description": "This table presents a detailed quantitative comparison of image quality across various diffusion models and quantization methods.  It includes metrics such as Fr\u00e9chet Inception Distance (FID), ImageReward (IR), Learned Perceptual Image Patch Similarity (LPIPS), Peak Signal-to-Noise Ratio (PSNR), CLIP Image Quality Assessment (C.IQA), CLIP Score (C.SCR), and Structural Similarity Index (SSIM).  The models are evaluated at different precision levels (e.g., 16-bit, 8-bit, 4-bit) using various quantization techniques, including SVDQuant (the method proposed in the paper).  This allows for a comprehensive analysis of how different quantization strategies impact image quality and similarity to the original high-precision models.", "section": "5.2 RESULTS"}]