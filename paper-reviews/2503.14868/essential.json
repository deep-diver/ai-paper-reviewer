{"importance": "This paper introduces **a novel method, ZOODiP, for personalizing diffusion models on resource-constrained devices**, like mobile phones, using forward passes only. This work is important as it **makes personalized AI more accessible** and paves the way for future research in memory-efficient on-device training.  It challenges the traditional reliance on backpropagation and quantized models, **offering a new direction for AI personalization**.", "summary": "Personalize diffusion models efficiently on devices without backpropagation.", "takeaways": ["Textual Inversion tokens primarily optimize within a low-dimensional subspace.", "Partial timesteps are sufficient for effective training.", "Zeroth-order optimization achieves comparable performance with significantly lower memory requirements."], "tldr": "Diffusion models excel in image synthesis but demand significant resources, posing challenges for personalization on devices with limited memory. Existing methods still require significant memory for storing activations and gradients. This paper addresses the challenge by **quantizing a diffusion model and leveraging zeroth-order optimization** on personalization tokens. It allows personalization without backpropagation that requires considerable memory.\n\nTo improve noisy gradient estimation, the method projects it onto a subspace constructed with the past history of tokens, called Subspace Gradient. In addition, the study investigates the influence of text embedding in image generation, leading to Partial Uniform Timestep Sampling for sampling with effective diffusion timesteps. The method achieves **comparable performance in image and text alignment scores while reducing training memory demand up to 8.2x**.", "affiliation": "Seoul National University", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.14868/podcast.wav"}