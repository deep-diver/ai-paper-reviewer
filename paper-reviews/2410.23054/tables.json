[{"content": "Method|Transport|Parameters|Support|\u03d5\n---|---|---|---|---\nDet<SUB>zero</SUB> [Suau et al., 2022]|\u03c9a+\u03b2|\u03c9=0, \u03b2=m<SUB>b</SUB>|Any layer, {a\u2223AP(A,B)>\u03b5}|max\nActAdd [Turner et al., 2023]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2=a<SUP>+</SUP>-a<SUP>-</SUP>|Layer search|last\nCAA [Rimsky et al., 2023]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2=m<SUB>b</SUB>-m<SUB>a</SUB>|Layer search|last\nRePE [Zou et al., 2023]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2=a<SUP>+</SUP>(**x**)-a<SUP>-</SUP>(**x**)|Layer search|last\nAurA [Suau et al., 2024]|\u03c9a+\u03b2|\u03c9=1-Gini(A,B), \u03b2=0|Any layer, {a\u2223AUROC(A,B)>0.5}|max\nEAST [Rahn et al., 2024]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2\u2248m<SUB>b</SUB>|Layer search|last\nITI-m [Li et al., 2024]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2=m<SUB>b</SUB>-m<SUB>a</SUB>|Attention head search|last\nITI-c [Li et al., 2024]|\u03c9a+\u03bb\u03b2|\u03c9=1, \u03b2=f<SUB>CLS</SUB>(A,B)|Attention head search|last\nMean-AcT, Section 3.1|(1-\u03bb)a+\u03bb(\u03c9a+\u03b2)|\u03c9=1, \u03b2=m<SUB>b</SUB>-m<SUB>a</SUB>|Any layer, a\u2208Q<SUB>o</SUB> or Q<SUB>\u221e</SUB>|mean\nLinear-AcT, Definition 3.1|(1-\u03bb)a+\u03bb(\u03c9a+\u03b2)|\u03c9,\u03b2=argmin<SUB>\u03c9,\u03b2</SUB>\u2211<SUB>i</SUB>(b<SUP>(i)</SUP>-(\u03c9a<SUP>(i)</SUP>+\u03b2))<SUP>2</SUP>|Any layer, a\u2208Q<SUB>o</SUB> or Q<SUB>\u221e</SUB>|mean", "caption": "Table 1: Comparison of different inference-time interventions in the literature. All methods listed can be expressed as a specific form of a linear map. With AcT, the conditioning strength \u03bb\ud835\udf06\\lambdaitalic_\u03bb interpolated between the activation a\ud835\udc4eaitalic_a and its transformed version (following Equation\u00a01), while existing methods use \u03bb\ud835\udf06\\lambdaitalic_\u03bb as a bias multiplier, thus becoming less interpretable and less robust to model/layer changes. As a result, many methods require a grid-search to find the best layer to intervene upon.", "description": "Table 1 compares several methods for controlling the behavior of large language models (LLMs) at inference time, without retraining.  Most methods involve adding a bias vector to the model's activations.  This bias is often scaled by a parameter (lambda). However, this approach can make the effect of the parameter difficult to interpret, making model control less precise and more sensitive to the choice of layer and model architecture.  AcT (Activation Transport), in contrast, uses optimal transport theory to create an interpolation map between the original and modified activation distributions, offering more fine-grained and interpretable control.", "section": "Related Work"}, {"content": "|   | Causal | Layer | Best \u03bb | PPL Wikipedia \u2193 | PPL Mistral-7B \u2193 | CLS Toxicity (%) \u2193 | 0-shot Toxicity (%) \u2193 |\n|---|---|---|---|---|---|---|---| \n| Original | - | - | - | 13.98 | 6.62 | 4.08 \u00b1 0.36 | 13.25 \u00b1 0.88 |\n| Mean-AcT |  | Attention | 1.0 | 13.90 | 7.23 (+0.61) | 1.12 \u00b1 0.35 | 5.60 \u00b1 1.01 |\n| Mean-AcT | \u2713 | Attention | 1.0 | 14.08 (+0.11) | 7.23 (+0.61) | 1.06 \u00b1 0.17 | 5.14 \u00b1 0.50 |\n| Linear-AcT |  | Attention | 1.0 | 14.04 (+0.06) | 7.26 (+0.64) | 0.97 \u00b1 0.39 | 5.75 \u00b1 0.90 |\n| Linear-AcT | \u2713 | Attention | 1.0 | 14.21 (+0.23) | 7.24 (+0.62) | 0.90 \u00b1 0.33 | 5.06 \u00b1 0.63 |\n| Mean-AcT |  | Post-LN | 1.0 | 14.11 (+0.13) | 7.71 (+1.09) | 0.62 \u00b1 0.05 | 4.47 \u00b1 0.65 |\n| Mean-AcT | \u2713 | Post-LN | 1.0 | 14.21 (+0.23) | 7.59 (+0.97) | 0.54 \u00b1 0.44 | 4.10 \u00b1 0.41 |\n| Linear-AcT |  | Post-LN | 0.9 | 14.54 (+0.57) | 7.87 (+1.25) | 0.65 \u00b1 0.17 | 4.40 \u00b1 0.39 |\n| Linear-AcT | \u2713 | Post-LN | 1.0 | 14.79 (+0.81) | 7.99 (+1.37) | 0.56 \u00b1 0.21 | 4.14 \u00b1 0.55 |", "caption": "Table 2: Toxicity mitigation for Gemma2-2B and Llama3-8B, results over 5 runs. We intervene upon different layer types (layer column) and show the best layer per method. ITI-c, ActAdd and AcT have a strength parameter \u03bb\ud835\udf06\\lambdaitalic_\u03bb which we sweep. For each method, we report results for the \u03bb\ud835\udf06\\lambdaitalic_\u03bb that attained the best CLS toxicity that incurs less than +11+1+ 1 increase in PPL Wikipedia. AcT methods and provide best results for \u03bb=1\ud835\udf061\\lambda=1italic_\u03bb = 1, achieving up to 7.5\u00d77.5\\times7.5 \u00d7 (Gemma2-2B) and 4.3\u00d74.3\\times4.3 \u00d7 (Llama3-8B) CLS toxicity mitigation with Linear-AcT. ITI-c is very sensitive to \u03bb\ud835\udf06\\lambdaitalic_\u03bb as well as layer choice (see full results in Appendix\u00a0G), and AurA reaches up to 3.1\u00d73.1\\times3.1 \u00d7 reduction.", "description": "Table 2 presents the results of toxicity mitigation experiments conducted on two large language models, Gemma2-2B and Llama3-8B.  The experiments involved applying several methods (ACT, ITI-C, AURA, ACTADD) to reduce toxicity in model outputs.  For each model, different layers within the model's architecture were targeted for intervention. A parameter \u03bb (lambda) controls the strength of the intervention. The table shows the best results achieved for each method, focusing on the reduction in toxicity (measured by CLS toxicity) while ensuring that the increase in perplexity (PPL) on a Wikipedia text dataset remained below 1.  The ACT methods consistently yielded the best results, significantly reducing toxicity with minimal impact on perplexity.  In contrast, ITI-C's performance was highly sensitive to the choice of lambda and layer, and AURA's impact was less substantial.", "section": "4 Experiments on LLMs"}, {"content": "|   | Causal   | Layer   | Best \u03bb   | PPL Wikipedia \u2193   | PPL Mistral-7B \u2193   | CLS Toxicity (%) \u2193   | 0-shot Toxicity (%) \u2193   |\n|---|---|---|---|---|---|---|---| \n| Original | - | - | - | 9.06  | 5.68  | 5.80  | 15.00  |\n| Mean-AcT |  | Attention | 1.0 | 9.35 (+0.28) | 6.33 (+0.65) | 1.40 \u00b1 0.29 | 6.73 \u00b1 1.13 |\n| Mean-AcT | \u2713 | Attention | 1.0 | 9.56 (+0.49) | 6.36 (+0.68) | 1.38 \u00b1 0.17 | 5.60 \u00b1 0.34 |\n| Linear-AcT |  | Attention | 1.0 | 9.38 (+0.32) | 6.27 (+0.58) | 1.38 \u00b1 0.24 | 6.55 \u00b1 0.75 |\n| Linear-AcT | \u2713 | Attention | 1.0 | 9.56 (+0.49) | 6.28 (+0.60) | 1.35 \u00b1 0.39 | 6.68 \u00b1 0.81 |", "caption": "Table 3: TruthfulQA results for Gemma2-2B and Llama3-8B, results over 5 runs. We intervene upon different layers (layer column) and show the best per model. ITI-c, ActAdd and AcT have a strength parameter \u03bb\ud835\udf06\\lambdaitalic_\u03bb which we sweep, reporting the best \u03bb\ud835\udf06\\lambdaitalic_\u03bb result per model (MC1 Accuracy so that MMLU is within the best AcT MMLU \u00b1\u20040.1plus-or-minus0.1\\pm\\;0.1\u00b1 0.1).", "description": "This table presents the results of experiments evaluating the performance of different methods on the TruthfulQA benchmark.  The experiments involved modifying the activations of pre-trained large language models (LLMs) Gemma2-2B and Llama3-8B. Multiple methods were tested, including ACT, ITI-C, and ACTADD, each with a tunable parameter \u03bb (lambda).  The models' performance was measured using three metrics: MC1 Accuracy, MC2 Accuracy, and MMLU Accuracy.  The table shows the best performance obtained for each method by sweeping through different values of \u03bb, while ensuring that the obtained MMLU accuracy for each method was comparable (\u00b10.1) to the best MMLU accuracy achieved by the ACT methods. The best performing layer for each method is also identified.", "section": "4 Experiments on LLMs"}, {"content": "| Layer | Best \u03bb | PPL Wikipedia \u2193 | PPL Mistral-7B \u2193 | MMLU \u2191 | CLS Toxicity (%) \u2193 | 0-shot Toxicity (%) \u2193 |\n|---|---|---|---|---|---|---|\n| Original | - | - | 13.98 | 6.68 | 53.1 | 4.17 \u00b1 0.32 | 13.42 \u00b1 1.08 |\n| ActAdd | Atention | 0.5 | 13.99 (+0.02) | 6.58 | 53.2 (+0.2) | 4.17 \u00b1 0.15 | 13.25 \u00b1 1.63 |\n| ITI-c | Atention | 8.0 | 14.90 (+0.92) | 7.44 (+0.76) | 52.6 (-0.5) | **0.74** \u00b1 0.18 | 5.36 \u00b1 0.91 |\n| Mean-AcT | Atention | 1.0 | 14.08 (+0.11) | 7.23 (+0.55) | 52.5 (-0.6) | 1.06 \u00b1 0.17 | **5.14** \u00b1 0.50 |\n| Linear-AcT | Atention | 1.0 | 14.21 (+0.23) | 7.24 (+0.56) | 52.2 (-0.9) | **0.90** \u00b1 0.33 | **5.06** \u00b1 0.63 |\n| ActAdd | Post-LN | 0.1 | 14.04 (+0.06) | 6.61 | 53.2 (+0.2) | 4.08 \u00b1 0.43 | 13.50 |\n| ITI-c | Post-LN | 13.0 | 14.89 (+0.92) | 7.34 (+0.66) | 52.8 (-0.3) | 3.08 \u00b1 0.61 | 12.24 \u00b1 0.69 |\n| Mean-AcT | Post-LN | 1.0 | 14.21 (+0.23) | 7.59 (+0.90) | 51.6 (-1.5) | **0.54** \u00b1 0.44 | **4.10** \u00b1 0.41 |\n| Linear-AcT | Post-LN | 1.0 | 14.79 (+0.81) | 7.99 (+1.31) | 51.3 (-1.8) | **0.56** \u00b1 0.21 | **4.14** \u00b1 0.55 |\n| AurA | MLP | - | 14.18 (+0.21) | 7.04 (+0.36) | 53.0 (-0.1) | 2.12 \u00b1 0.27 | 9.04 \u00b1 0.66 |\n| ActAdd | MLP | 0.5 | 14.69 (+0.72) | 6.67 (+0.05) | 53.0 (-0.1) | 3.96 \u00b1 0.24 | 13.43 \u00b1 1.42 |\n| ITI-c | MLP | 1.0 | 13.99 (+0.01) | 6.77 (+0.08) | 52.8 (-0.3) | 4.50 \u00b1 0.32 | 15.06 \u00b1 0.76 |\n| Mean-AcT | MLP | 1.0 | 14.33 (+0.35) | 7.02 (+0.34) | 52.4 (-0.7) | **1.30** \u00b1 0.37 | **7.28** \u00b1 0.88 |\n| Linear-AcT | MLP | 1.0 | 14.89 (+0.92) | 7.53 (+0.85) | 51.9 (-1.2) | **1.30** \u00b1 0.39 | **7.15** \u00b1 0.98 |", "caption": "Table 4: Causal (gray background) vs.\u00a0simultaneous estimation of AcT on Gemma2-2B in a toxicity mitigation setting (explained in Section\u00a04.1). Causal estimation provides better conditioning (lower toxicity).", "description": "This table compares the performance of causal and simultaneous estimation methods of Activation Transport (ACT) on the Gemma2-2B language model for toxicity mitigation.  Causal estimation involves sequentially applying transport maps layer by layer, respecting the causal flow of information within the model. Simultaneous estimation, on the other hand, applies transport maps to all layers at once. The table shows various metrics, including perplexity and toxicity scores, to evaluate the effectiveness of each method in reducing toxicity while maintaining the overall model's usability. The results demonstrate that the causal estimation of ACT achieves better results in toxicity reduction compared to simultaneous estimation.", "section": "4.1 Toxicity Mitigation in LLMs"}, {"content": "| Layer | Best \u03bb | PPL Wikipedia \u2193 | PPL Mistral-7B \u2193 | MMLU \u2191 | CLS Toxicity (%) \u2193 | 0-shot Toxicity (%) \u2193 |\n|---|---|---|---|---|---|---|\n| Original | - | - | 9.06 | 5.68 | 65.3 | 5.80 | 15.00 |\n| ActAdd | Atention | 0.3 | 9.71 (+0.65) | 5.85 (+0.16) | 65.5 (+0.2) | 5.57 \u00b1 0.45 | 15.73 \u00b1 0.21 |\n| ITI-c | Atention | 3.0 | 9.48 (+0.42) | 6.17 (+0.49) | 64.7 (-0.6) | 1.60 \u00b1 0.22 | 6.53 \u00b1 0.66 |\n| Mean-AcT | Atention | 1.0 | 9.56 (+0.49) | 6.36 (+0.68) | 64.7 (-0.7) | 1.38 \u00b1 0.17 | 5.60 \u00b1 0.34 |\n| Linear-AcT | Atention | 1.0 | 9.56 (+0.49) | 6.28 (+0.60) | 64.5 (-0.8) | 1.35 \u00b1 0.39 | 6.68 \u00b1 0.81 |\n| AurA | MLP | - | 9.52 (+0.45) | 6.05 (+0.37) | 65.5 (+0.2) | 1.90 \u00b1 0.61 | 8.12 \u00b1 0.85 |\n| ActAdd | MLP | - | - | - | - | - | - |\n| ITI-c | MLP | 1.0 | 9.09 (+0.03) | 5.79 (+0.11) | 63.5 (-1.9) | 5.62 \u00b1 0.96 | 15.48 \u00b1 1.16 |\n| Mean-AcT | MLP | 0.9 | 9.90 (+0.84) | 6.24 (+0.55) | 60.7 (-4.6) | 2.10 \u00b1 0.48 | 10.65 \u00b1 1.02 |\n| Linear-AcT | MLP | 0.8 | 10.06 (+0.99) | 5.98 (+0.29) | 61.9 (-3.4) | 2.23 \u00b1 0.53 | 10.27 \u00b1 0.97 |", "caption": "Table 5: Causal (gray background) vs.\u00a0simultaneous estimation of AcT on Llama3-8B in a toxicity mitigation setting (see Section\u00a04.1). Causal estimation provides better conditioning (lower toxicity).", "description": "This table compares the results of causal and simultaneous estimation methods for the Activation Transport (ACT) model on the Llama3-8B large language model.  The goal is toxicity mitigation, as described in section 4.1.  The table shows the performance metrics for both estimation methods across different layers in the model, illustrating that the causal approach leads to better control over toxicity (lower toxicity scores) while maintaining reasonable performance on other metrics. The gray background highlights the causal estimation results.", "section": "4.1 TOXICITY MITIGATION IN LLMS"}, {"content": "Layer|Best \u03bb|MC1 Accuracy (%) \u2191|MC2 Accuracy (%) \u2191|MMLU Accuracy (%) \u2191\n---|---|---|---|---\nOriginal|-|-|21.05|32.80|53.10\nAurA|MLP|-|21.20 \u00b1 0.10|32.88 \u00b1 0.22|52.73 \u00b1 0.07\nActAdd|Attention|3.0|22.64 \u00b1 0.00|34.64 \u00b1 0.00|53.02 \u00b1 0.00\nITI-c|Attention|5.0|23.18 \u00b1 0.28|36.16 \u00b1 0.34|52.10 \u00b1 0.44\nMean-AcT|Attention|1.0|21.62 \u00b1 0.07|34.08 \u00b1 0.19|52.83 \u00b1 0.09\nLinear-AcT|Attention|1.0|21.71 \u00b1 0.14|34.47 \u00b1 0.22|52.86 \u00b1 0.08\nActAdd|All-LN|1.0|21.42 \u00b1 0.00|32.93 \u00b1 0.00|51.65 \u00b1 0.00\nITI-c|All-LN|4.0|23.94 \u00b1 0.96|36.62 \u00b1 0.86|51.37 \u00b1 0.41\nMean-AcT|All-LN|1.0|25.07 \u00b1 0.20|38.68 \u00b1 0.30|51.81 \u00b1 0.12\nLinear-AcT|All-LN|1.0|26.00 \u00b1 0.32|40.17 \u00b1 0.24|51.47 \u00b1 0.27\nActAdd|Post-LN|0.8|22.40 \u00b1 0.00|34.27 \u00b1 0.00|53.11 \u00b1 0.00\nITI-c|Post-LN|8.0|23.16 \u00b1 0.40|35.94 \u00b1 0.55|51.39 \u00b1 0.45\nMean-AcT|Post-LN|1.0|21.93 \u00b1 0.20|34.98 \u00b1 0.25|52.77 \u00b1 0.10\nLinear-AcT|Post-LN|1.0|22.45 \u00b1 0.22|35.94 \u00b1 0.36|52.43 \u00b1 0.20\nActAdd|MLP|3.0|23.01 \u00b1 0.00|34.76 \u00b1 0.00|52.83 \u00b1 0.00\nITI-c|MLP|2.0|24.53 \u00b1 0.11|37.06 \u00b1 0.38|51.39 \u00b1 0.41\nMean-AcT|MLP|1.0|21.98 \u00b1 0.19|35.18 \u00b1 0.31|52.84 \u00b1 0.04\nLinear-AcT|MLP|1.0|21.93 \u00b1 0.20|35.47 \u00b1 0.25|52.73 \u00b1 0.19", "caption": "Table 6: Toxicity mitigation for Gemma2-2B, results over 5 runs. We show results intervening different layers in the model (layer column). ITI-c, ActAdd and AcT have a strength parameter \u03bb\ud835\udf06\\lambdaitalic_\u03bb which we sweep, reporting for each method the best result (best \u03bb\ud835\udf06\\lambdaitalic_\u03bb) in CLS toxicity that incurs less than +11+1+ 1 increase in PPL Wikipedia. AcT methods are robust to the choice of layer and provide best results for \u03bb=1\ud835\udf061\\lambda=1italic_\u03bb = 1, achieving up to 7.5\u00d77.5\\times7.5 \u00d7 toxicity mitigation with Linear-AcT. ITI-c is very sensitive to \u03bb\ud835\udf06\\lambdaitalic_\u03bb as well as layer choice, and AurA does not provide a strength control.", "description": "This table presents the results of an experiment evaluating the effectiveness of different methods for mitigating toxicity in the Gemma2-2B language model.  The experiment was run five times for each method and layer, and each method's performance was measured based on two metrics: the Classification Loss (CLS) of toxicity and the Perplexity (PPL) on Wikipedia text.  The best result for each method was selected as the one that achieved the lowest CLS toxicity while keeping the increase in PPL to less than 1.  The table shows that the Activation Transport (ACT) methods are robust to the choice of model layers and perform best at lambda = 1, greatly reducing toxicity. In contrast, the Inference-Time Intervention-Contrastive (ITI-C) method is shown to be very sensitive to the choice of model layer and lambda parameter.  The AURA method is also included for comparison, but lacks a controllable strength parameter.", "section": "4.1 Toxicity Mitigation in LLMs"}, {"content": "Layer|Best \u03bb|MC1 Accuracy (%) \u2191|MC2 Accuracy (%) \u2191|MMLU Accuracy\n---|---|---|---|---\n-|-|-|-|-\nOriginal|-|-|25.46|40.27|65.35\nAurA|MLP|-|25.34 \u00b1 0.15|40.47 \u00b1 0.20|65.37 \u00b1 0.06\nActAdd|Attention|0.7|26.19 \u00b1 0.00|40.88 \u00b1 0.00|65.42 \u00b1 0.00\nITI-c|Attention|1.0|27.42 \u00b1 0.30|42.01 \u00b1 0.42|65.26 \u00b1 0.11\nMean-AcT|Attention|1.0|26.73 \u00b1 0.19|42.20 \u00b1 0.24|65.37 \u00b1 0.06\nLinear-AcT|Attention|1.0|27.17 \u00b1 0.23|42.15 \u00b1 0.31|65.33 \u00b1 0.11\nActAdd|All-LN|1.0|25.58 \u00b1 0.00|41.00 \u00b1 0.00|64.88 \u00b1 0.00\nITI-c|All-LN|3.0|29.65 \u00b1 0.71|44.43 \u00b1 0.56|64.71 \u00b1 0.22\nMean-AcT|All-LN|1.0|32.88 \u00b1 0.54|48.23 \u00b1 0.64|64.83 \u00b1 0.14\nLinear-AcT|All-LN|1.0|33.22 \u00b1 0.22|48.69 \u00b1 0.34|64.78 \u00b1 0.15\nActAdd|MLP|0.5|25.46 \u00b1 0.00|40.64 \u00b1 0.00|65.34 \u00b1 0.00\nITI-c|MLP|2.0|30.11 \u00b1 0.60|45.41 \u00b1 0.24|64.71 \u00b1 0.14\nMean-AcT|MLP|1.0|26.17 \u00b1 0.24|41.27 \u00b1 0.34|65.01 \u00b1 0.20\nLinear-AcT|MLP|1.0|26.41 \u00b1 0.52|39.34 \u00b1 0.54|60.98 \u00b1 3.14", "caption": "Table 7: Toxicity mitigation for Llama3-8B, results over 5 runs. Similar conclusions as in Table\u00a06 are extracted.", "description": "This table presents the results of toxicity mitigation experiments conducted on the Llama3-8B language model.  Five runs were performed for each method and layer, and the results show the reduction in toxicity levels while keeping the performance of the model mostly unchanged. The table compares different methods (Linear-ACT, Mean-ACT, ITI-C, ACTADD, AURA), layers in the model (Attention, Post-LN, MLP), and the impact on various metrics such as toxicity (CLS and 0-shot), perplexity, and MMLU accuracy.", "section": "4 EXPERIMENTS ON LLMS"}, {"content": "| Anime | anime style, large expressive eyes, stylized hair, bold outlines, simplified colors, dynamic perspective, exaggerated features, angular shapes, chibis, manga inspired, emotive facial expressions, action sequences, speed lines, cell shading, graphic backgrounds, vibrant palettes |\n| Art nouveau | Art Nouveau, Alphonse Mucha, Gustav Klimt, flowing lines, organic shapes, floral motifs, geometric patterns, ornamental designs, Jugendstil, Secessionism, symbolism, female figures, gold leaf, intricate details, turn of the century art, early 20th century |\n| Impressionism | impressionism, Claude Monet, brush strokes, light, color, outdoor scenes, water lilies, haystacks, Rouen Cathedral, reflections, nature, atmospheric, vibrant colors, visible textures, 19th century art, French impressionism |\n| Cyberpunk | cyberpunk, neon lights, urban jungles, high-tech architecture, augmented reality, AI technology, biopunk, futuristic cities, post-apocalyptic scenes, digital hacking, megacorporations, androids, dystopian societies, cybernetic enhancements, chromed details, glowing neon signs, rain-soaked streets |\n| Photorealism | photorealism, hyperrealism, optical precision, photographic quality, fine detail, lifelike textures, realistic lighting, accurate perspective, human figures, still life, cityscapes, landscapes, skin tones, reflections and shadows, everyday objects, documentary style art, contemporary realism |\n| Sketch | sketches, pencil drawing, charcoal sketches, ink illustrations, gestural lines, quick studies, figure drawing, perspective sketching, urban sketching, landscape sketches, still life drawings, sketchbook art, doodles, minimalist lines, expressive mark-making, observational drawing |\n| Watercolor | watercolor style, transparent media, wet-on-wet application, dry brush strokes, soft blending, delicate touches, gentle shading, luminous hues, atmospheric lighting, ethereal quality, subtle textures, color gradients, painterly aesthetics, fluid paint behavior, watercolor paper texture |", "caption": "Table 8: \nGenerations at different \u03bb\ud835\udf06\\lambdaitalic_\u03bb inducing concept Football.", "description": "This table presents text samples generated by the model, illustrating how different strengths of the Linear-ACT and ITI-C methods influence the generation of text related to the concept of \"football.\" Each row shows the generated text for a specific method and strength parameter (\u03bb).  The purpose is to demonstrate how these methods can be tuned to control the degree to which the generated text is about football.", "section": "4.2 INDUCING CONCEPTS IN LLMS WITH ACT"}, {"content": "| Pink elephant | a pink elephant. containing a pink elephant. with a pink elephant in plain view. and a pink elephant. it displays a pink elephant. featuring a pink elephant. in addition to a pink elephant. and also a pink elephant. and a pink elephant as well. the pink elephant can be clearly seen. |\n| Gorilla | a gorilla. containing a gorilla. with a gorilla in plain view. and a gorilla. it displays a gorilla. featuring a gorilla. in addition to a gorilla. and also a gorilla. and a gorilla as well. the gorilla can be clearly seen. |\n| White bear | a white bear. containing a white bear. with a white bear in plain view. and a white bear. it displays a white bear. featuring a white bear. in addition to a white bear. and also a white bear. and a white bear as well. the white bear can be clearly seen. |\n| No pink elephant | without a pink elephant. not containing a pink elephant. without a pink elephant in plain view. and a pink elephant that cannot be seen. it does not display a pink elephant. not featuring a pink elephant. lacking a pink elephant. and not a pink elephant. and a pink elephant is missing. the pink elephant cannot be seen. |\n| No gorilla | without a gorilla. not containing a gorilla. without a gorilla in plain view. and a gorilla that cannot be seen. it does not display a gorilla. not featuring a gorilla. lacking a gorilla. and not a gorilla. and a gorilla is missing. the gorilla cannot be seen. |\n| No white bear | without a white bear. not containing a white bear. without a white bear in plain view. and a white bear that cannot be seen. it does not display a white bear. not featuring a white bear. lacking a white bear. and not a white bear. and a white bear is missing. the white bear cannot be seen. |", "caption": "Table 9: \nGenerations at different \u03bb\ud835\udf06\\lambdaitalic_\u03bb inducing concept Flower.", "description": "This table presents several text generations from the Gemma2-2B large language model (LLM) using the Activation Transport (ACT) method.  Each row shows a generation with varying strength (\u03bb) of concept induction for the concept \"Flower\".  The baseline generation (\u03bb = 0) shows a typical story, whereas increasing \u03bb values gradually introduce the \"Flower\" concept into the narrative, culminating in a story heavily focused on flowers (\u03bb = 1.0).  The table illustrates the method's ability to precisely control the strength of concept insertion into the generated text.", "section": "4.2 INDUCING CONCEPTS IN LLMS WITH ACT"}]