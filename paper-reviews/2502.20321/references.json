{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP is used as a baseline and for contrastive loss, and is thus fundamentally important for setting the context."}, {"fullname_first_author": "Van Den Oord", "paper_title": "Neural discrete representation learning", "publication_date": "2017-01-01", "reason": "VQVAE is central to the model's architecture, providing the foundation for discrete visual tokenization."}, {"fullname_first_author": "Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "Attention mechanism are adapted and modified for factorization, thus central for token representation."}, {"fullname_first_author": "Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-01-01", "reason": "VQGAN is used for improving reconstruction quality, and its performance is compared against UniTok."}, {"fullname_first_author": "Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-01-01", "reason": "LLAMA 2 is used to construct unified multimodal model (MLLM) , thus central for integration with text."}]}