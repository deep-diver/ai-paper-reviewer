[{"figure_path": "https://arxiv.org/html/2411.00871/x1.png", "caption": "Figure 1: Overall framework of LLaMo.\nLLaMo consists of a graph neural network, a multi-level graph projector, and a large language model. It first encodes an input 2D molecular graph with the graph neural network and then converts the encoded graph into molecular graph tokens with the multi-level graph projector. Finally, the large language model generates the instruction-following response given the input SMILES, graph tokens, and the instruction.", "description": "LLaMo is composed of three main parts: a graph neural network (GNN) to encode a 2D molecular graph, a multi-level graph projector to transform the encoded graph into tokens usable by the language model, and a large language model (LLM) to generate the final response.  The process begins with inputting a 2D molecular graph and its SMILES representation. The GNN processes the graph. The multi-level graph projector converts the GNN's output into a format the LLM understands, combining information from multiple layers of the GNN. Finally, the LLM generates a response based on the processed graph tokens, SMILES, and instructions.", "section": "3 LLaMo: Large Language Model-based Molecular Graph Assistant"}, {"figure_path": "https://arxiv.org/html/2411.00871/x2.png", "caption": "Figure 2: Node representations of graph encoder with 1,2,4,5 layers. As the number of layers increases, node representations collapse.", "description": "This figure visualizes the node representations learned by a graph neural network (GNN) at different layers (1, 2, 4, and 5). Each subfigure represents the node embeddings for a specific layer. As the number of layers in the GNN increases, the node representations tend to converge towards similar values, which is known as the 'over-smoothing' problem.  This phenomenon reduces the GNN's capability to distinguish between different nodes and limits its ability to capture the nuanced characteristics within the molecular graph.", "section": "3.1 Model Architecture"}, {"figure_path": "https://arxiv.org/html/2411.00871/x3.png", "caption": "(a) Stage 1: graph-language alignment", "description": "This figure illustrates the first stage of a two-stage training pipeline for the LLaMo model.  Stage 1 focuses on aligning the molecular graph encoder and the large language model.  The graph encoder processes a 2D molecular graph, and a multi-level graph projector transforms the resulting node representations into molecular graph tokens, enabling alignment with the large language model.  The language model is frozen during this stage; only the graph encoder and projector are trained. The training objective is to learn effective graph-to-text mappings, improving the model's overall understanding of molecular structures and their language descriptions.", "section": "3 LLaMo: Large Language Model-based Molecular Graph Assistant"}, {"figure_path": "https://arxiv.org/html/2411.00871/x4.png", "caption": "(b) Stage 2: instruction-tuning", "description": "In the second stage of the two-stage training pipeline, the large language model (LLM) is fine-tuned using LoRA (Low-Rank Adaptation).  The multi-level graph projector continues to be trained concurrently.  This stage focuses on improving the model's instruction-following capabilities and enhancing its understanding of molecular graphs. The instruction-following response generation is used as the training objective.", "section": "3.2 Training LLaMo"}, {"figure_path": "https://arxiv.org/html/2411.00871/x5.png", "caption": "Figure 3: \n\nTwo-stage training pipeline.\nStage 1 involves training the graph encoder, and stage 2 entails fine-tuning the LLM using LoRA. In both stages, the multi-level graph projector is continuously trained. All training processes are performed by generating the instruction-following response.", "description": "LLaMo's training is divided into two stages. Stage 1 pre-trains the graph encoder and multi-level graph projector to align graph and language representations. Stage 2 fine-tunes the large language model (LLM) using Low-Rank Adaptation (LoRA), while continuing to train the projector.  Both stages use instruction-following response generation for training.", "section": "3 LLaMo: Large Language Model-based Molecular Graph Assistant"}, {"figure_path": "https://arxiv.org/html/2411.00871/x6.png", "caption": "Figure 4: \nVisualization of attention maps for samples with coarse-grained caption\u00a0(left) and fine-grained caption\u00a0(right).\nThe attention scores of high-level features are relatively high when generating coarse-grained captions, whereas those of low-level features are high for fine-grained captions.", "description": "Figure 4 visualizes attention mechanisms within the LLaMo model for generating captions of varying detail levels.  The left panel shows attention weights when producing a coarse-grained caption (high-level overview), and the right panel shows attention weights when generating a fine-grained caption (detailed description). The visualization demonstrates that the model focuses more on high-level features (e.g., overall molecular structure) for coarse captions, and shifts to low-level features (e.g., specific atom and bond details) when generating fine-grained descriptions.", "section": "5.3 Analysis"}, {"figure_path": "https://arxiv.org/html/2411.00871/x7.png", "caption": "Figure 5: An example of molecular description generation results of LLaMo\u00a0w/o graph and LLaMo\u00a0w/ graph given the molecule\u00a0(\u201cC(CCC/C=C\\\\\\backslash\\C/C=C\\\\\\backslash\\CCCCCO)CCCC(=O)[O-1]\u201d).\nIn the top box, the molecular graphs of IUPAC and functional groups in the descriptions are depicted.", "description": "Figure 5 presents a comparison of molecular description generation results between two versions of the LLaMo model: one trained without molecular graph data (LLaMo w/o graph) and another trained with it (LLaMo w/ graph).  The input molecule is represented using the SMILES string \u201cC(CCC/C=C\\\\C/C=C\\\\CCCCCO)CCCC(=O)[O-1]\u201d. The figure highlights the difference in the generated descriptions.  The top section of the figure visually depicts the molecular graph, the IUPAC name, and the key functional groups used in the generated descriptions for both model versions, aiding in understanding how the presence of molecular graph information impacts the LLaMo model's descriptive capabilities.", "section": "3 LLaMo: Large Language Model-based Molecular Graph Assistant"}, {"figure_path": "https://arxiv.org/html/2411.00871/x11.png", "caption": "Figure 6: An example of molecular description generation results of LLaMo w/o MGProj and LLaMo w/ MGProj given the molecule\n(\u201cC[C@@H1]1CN(C(=O)C2=C(C(=CC=C2)NC(=O)C3=NC=CN= C3)O[C@@H1]1CNC)[C@H1](C)CO\u201d).\nIn the top box, the molecular graphs of IUPAC and functional groups in the descriptions are depicted.", "description": "This figure compares the molecular description generation results between two versions of the LLaMo model: one without the multi-level graph projector (LLaMo w/o MGProj) and one with it (LLaMo w/ MGProj).  The input molecule, represented by its SMILES string \"C[C@@H1]1CN(C(=O)C2=C(C(=CC=C2)NC(=O)C3=NC=CN=C3)O[C@@H1]1CNC)[C@H1](C)CO\", is processed by both models. The top section of the figure shows the input molecule's structure visualized as a graph, along with highlighted functional groups relevant to the descriptions generated by the models. This visualization helps to understand how the models interpret and represent the molecule. The generated descriptions from both models are then presented, illustrating the influence of the multi-level graph projector on the quality and detail of the generated descriptions. The comparison showcases how integrating a multi-level graph projector allows the model to provide richer, more accurate, and chemically meaningful descriptions.", "section": "3. LLaMo: Large Language Model-based Molecular Graph Assistant"}, {"figure_path": "https://arxiv.org/html/2411.00871/x12.png", "caption": "Figure 7: Node representations of graph encoder with 1,2,4,5 layers. As the number of layers increases, node representations collapse.", "description": "This figure visualizes the node representations learned by a graph neural network (GNN) at different layers (1, 2, 4, and 5).  Each sub-figure shows the node representations as points in a multi-dimensional space. The main observation is that as the number of layers in the GNN increases, the node representations tend to converge or 'collapse' towards a central point, losing their individual distinctiveness and potentially hindering the network's ability to discriminate between different nodes or structural features within the graph.", "section": "3.1 Model Architecture"}, {"figure_path": "https://arxiv.org/html/2411.00871/x13.png", "caption": "Figure 8: An example of molecular description generation results of LLaMo\u00a0w/o graph and LLaMo\u00a0w/ graph given the molecule \u201cCCCCC[C@@H1](CC[C@H1]1[C@@H1](C[C@@H1]([C@@H1]\n1C/C=C\\\\\\backslash\\CCCC(=O)[O-1])O)O)O)\u201d.", "description": "Figure 8 presents a comparison of molecular description generation results between two models: LLaMo with graph and LLaMo without graph.  The input molecule, represented by its SMILES string \"CCCCC[C@@H1](CC[C@H1]1[C@@H1](C[C@@H1]([C@@H1]1C/C=C\\\\CCCC(=O)[O-1])O)O)O)\", is identical for both models.  The figure showcases how the inclusion of the molecular graph in LLaMo significantly improves the accuracy and detail of the generated description. The descriptions generated by both models are presented alongside the input molecule's structure, allowing for visual inspection and comparison. The results highlight the importance of incorporating molecular graph information into large language models for more effective and accurate understanding and generation of molecule descriptions.", "section": "Experimental Results"}]