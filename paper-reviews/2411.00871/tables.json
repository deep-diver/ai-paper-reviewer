[{"content": "| Context type 1: SMILES representation |  | \n|---|---| \n| CCCCC(C)/C=C(\\C)/C=C/C(=O)NC1=C[C@]([C@@H](CC1=O)O)(/C=C/C=C/C=C/C(=O)NC2 |  | \n| =C(CCC2=O)O)O |  | \n| Context type 2: Description |  | \n|---|---| \n| The molecule is a polyene antibiotic that is TMC-1A in which the 2,4-dimethyloct-2-enoyl group has been replaced by an (E,E)-4,6-dimethyldeca-2,4-dienoyl group. TMC-1C is an antitumour antibiotic isolated from Streptomyces sp. A-230\u2026<omitted> |  | \n| **Context type 3: IUPAC name** |  | \n|---|---| \n| (2E,4E)-N-[(3S,4R)-3,4-dihydroxy-3-[(1E,3E,5E)-7-[(2-hydroxy-5-oxocyclopenten-1-yl)amino]-7-oxohepta-1,3,5-trienyl]-6-oxocyclohexen-1-yl]-4,6-dimethyldeca-2,4-dienamide |  | \n| **Response: Multi-turn conversation** |  | \n|---|---| \n| Question: |  | \n| What is the IUPAC name of the molecule you are analyzing? |  | \n| === |  | \n| Answer: |  | \n| The IUPAC name of the molecule is (2E,4E)-N-[(3S,4R)-3,4-dihydroxy-3-[(1E,3E,5E)-7-[(2-hydroxy-5-oxocyclopenten-1-yl)amino]-7-oxohepta-1,3,5-trienyl]-6-oxocyclohexen-1-yl]-4,6-dimethyldeca-2,4-dienamide. |  | \n| === |  | \n| Question: |  | \n| Can you identify the type of acid or base this molecule can act as in a reaction? |  | \n| === |  | \n| Answer: |  | \n| This molecule can act as a weak acid due to the presence of the carboxylic acid group. |  |", "caption": "Table 1: One example to illustrate the instruction-following data. The top block shows the contexts such as SMILES, description, and IUPAC name used to prompt GPT, and the bottom block shows the response of GPT-4.", "description": "This table showcases an example of the instruction-following data used to train the LLaMo model.  The top section presents the input context provided to GPT-4, including the SMILES notation for a molecule, its description, and its IUPAC name. The bottom section displays the GPT-4's response, illustrating the model's ability to engage in a multi-turn conversation and answer questions related to the provided molecule information.", "section": "4 GPT-assisted Molecular Graph Instruction Data Generation"}, {"content": "| Projector | Molecule description BLEU (<img src=\"https://arxiv.org/html/2411.00871/uparrow.png\">) | Molecule description METEOR (<img src=\"https://arxiv.org/html/2411.00871/uparrow.png\">) | IUPAC prediction BLEU (<img src=\"https://arxiv.org/html/2411.00871/uparrow.png\">) | IUPAC prediction METEOR (<img src=\"https://arxiv.org/html/2411.00871/uparrow.png\">) | Property QA MAE (<img src=\"https://arxiv.org/html/2411.00871/downarrow.png\">) | \n|---|---|---|---|---|---| \n| w/o Graph | 26.1 | 56.6 | 36.3 | 62.2 | 0.013 | \n| MLP (w/ low-level) | 32.4 | 62.1 | 42.2 | 68.4 | 0.009 | \n| MLP (w/ high-level) | 33.8 | 63.4 | 45.5 | 67.4 | 0.008 | \n| MLP (w/ concat) | 34.8 | 64.1 | 47.1 | 70.2 | **0.007** | \n| Resampler | 34.4 | 62.8 | 43.4 | 65.2 | 0.009 | \n| MGProj (w/o motif) | 36.1 | 65.3 | 48.8 | 69.8 | 0.008 | \n| **MGProj (Ours)** | **37.8** | **66.1** | **49.6** | **70.9** | **0.007** | ", "caption": "Table 2: Performance (%) of generalist models on three tasks: molecule description generation, IUPAC prediction, and property prediction.\nMol. Inst. tuned denotes the molecular instruction-tuned model.\n\u2217*\u2217 The result is not available since LLaMA2 fails generating numerical outputs.\n\u2020\u2020\\dagger\u2020 denotes the experimental results drawn from Mol-Instruction\u00a0[48].", "description": "This table presents the performance comparison of various generalist models on three molecular tasks: molecule description generation, IUPAC name prediction, and property prediction.  The performance is measured using metrics appropriate for each task (BLEU, METEOR, MAE).  The models are categorized and compared, showing the impact of instruction tuning, and highlighting a model's ability to handle all three tasks simultaneously versus specializing in one.  Specific model variations are noted, along with sources for experimental results where applicable.", "section": "5 Experiments"}, {"content": "| Model | Exact\u2191 | BLEU\u2191 | Levenshtein\u2193 | RDK FTS\u2191 | MACCS FTS\u2191 | Morgan FTS\u2191 | Validity\u2191 |\n|---|---|---|---|---|---|---|---| \n| Alpaca\u2020 [14] | 0.000 | 0.065 | 41.989 | 0.004 | 0.024 | 0.008 | 0.138 |\n| Baize\u2020 [51] | 0.000 | 0.044 | 41.500 | 0.004 | 0.025 | 0.009 | 0.097 |\n| ChatGLM\u2020 [52] | 0.000 | 0.183 | 40.008 | 0.050 | 0.100 | 0.044 | 0.108 |\n| LLaMA\u2020 [53] | 0.000 | 0.020 | 42.002 | 0.001 | 0.002 | 0.001 | 0.039 |\n| Vicuna\u2020 [37] | 0.000 | 0.057 | 41.690 | 0.007 | 0.016 | 0.006 | 0.059 |\n| LLaMA\u2217 [53] | 0.012 | 0.804 | 29.947 | 0.499 | 0.649 | 0.407 | **1.000** |\n| Mol-Instruction [48] | 0.045 | 0.654 | 27.262 | 0.313 | 0.509 | 0.262 | **1.000** |\n| InstructMol-G [54] | 0.153 | 0.906 | 20.155 | 0.519 | 0.717 | 0.457 | **1.000** |\n| InstructMol-GS [54] | 0.536 | **0.967** | 10.851 | 0.776 | 0.878 | 0.741 | **1.000** |\n| **LLaMo (Ours)** | **0.584** | 0.894 | **6.162** | **0.857** | **0.918** | **0.841** | 0.938 |\n| Alpaca\u2020 [14] | 0.000 | 0.063 | 46.915 | 0.005 | 0.023 | 0.007 | 0.160 |\n| Baize\u2020 [51] | 0.000 | 0.095 | 44.714 | 0.025 | 0.050 | 0.023 | 0.112 |\n| ChatGLM\u2020 [52] | 0.000 | 0.117 | 48.365 | 0.056 | 0.075 | 0.043 | 0.046 |\n| LLaMA\u2020 [53] | 0.000 | 0.036 | 46.844 | 0.018 | 0.029 | 0.017 | 0.010 |\n| Vicuna\u2020 [37] | 0.000 | 0.057 | 46.877 | 0.025 | 0.030 | 0.021 | 0.017 |\n| LLaMA\u2217 [53] | 0.000 | 0.283 | 53.510 | 0.136 | 0.294 | 0.106 | **1.000** |\n| Mol-Instruction [48] | 0.009 | 0.705 | 31.227 | 0.283 | 0.487 | 0.230 | **1.000** |\n| InstructMol-G [54] | 0.114 | 0.586 | 21.271 | 0.422 | 0.523 | 0.285 | **1.000** |\n| InstructMol-GS [54] | **0.407** | **0.941** | 13.967 | 0.753 | 0.852 | 0.714 | **1.000** |\n| **LLaMo (Ours)** | 0.341 | 0.830 | **12.263** | **0.793** | **0.868** | **0.750** | 0.954 |", "caption": "Table 3: Performance (%) of specialist models on molecule captioning with the PubChem324k and ChEBI-20 datasets and IUPAC name prediction. Full ft denotes full parameter fine-tuning.", "description": "This table presents the performance comparison of various specialist models on two tasks: molecule captioning and IUPAC name prediction.  The models are evaluated using the PubChem324k and ChEBI-20 datasets for molecule captioning, and a separate dataset for IUPAC name prediction.  Performance is measured using BLEU and METEOR scores. The 'Full ft' column indicates whether the model used full parameter fine-tuning or a more efficient method.", "section": "5.2 Experimental Results"}, {"content": "| Molecule SMILES | The molecule's IUPAC name |\n|---|---| \n| COc1cc([C@H]2COc3cc(O)ccc3C2)ccc1O | (3S)-3-(4-hydroxy-3-methoxyphenyl)-3,4-dihydro-2H-chromen-7-ol |\n| COc1c([C@@H]2COc3cc(O)ccc3C2)ccc2c1C=CC(C)(C)O2 | (3R)-3-(5-methoxy-2,2-dimethylchromen-6-yl)-3,4-dihydro-2H-chromen-7-ol |\n| COC1=CC(=O)C(C2COc3cc(O)ccc3C2)=CC1=O |  |", "caption": "Table 4: Performance comparison according to the projector type.", "description": "This table presents a comparison of the performance of different types of graph projectors used in the LLaMo model.  It shows the results for three tasks: molecule description generation, IUPAC prediction, and property prediction (using MAE). The table compares the performance of models with no graph projector, MLP-based projectors (with low-level, high-level, and concatenated inputs), a resampler projector, and the proposed multi-level graph projector (MGProj) with and without motif information.", "section": "5.3 Analysis"}, {"content": "| Molecule SMILES | Output Value |\n|---|---| \n| COCC12OC3CC1C32 | 0.2967 |\n| OCCC12CC3C(O1)C32 | 0.305 |\n| CCC1C2OC3C1C23C |  |", "caption": "Table 5: Ablation studies on training stage and GPT-generated instruction tuning data.", "description": "This table presents the results of ablation studies conducted to analyze the impact of different training stages and the use of GPT-generated instruction tuning data on the performance of the LLaMo model.  It shows how each training stage (Stage 1 and Stage 2) and the inclusion or exclusion of GPT-generated data affects the model's performance on three tasks: molecule description generation, IUPAC prediction, and property prediction (measured using BLEU, METEOR, and MAE, respectively). This allows researchers to understand the contribution of each component to the model's overall effectiveness.", "section": "3.2 Training LLaMo"}, {"content": "| Instructions | Details |\n|---|---| \n| You are an AI chemical assistant, and you are seeing a single molecule. What you see is provided with SMILES representation of the molecule and sentences describing the same molecule you are analyzing. Answer all questions as you are seeing the molecule. |  |\n| Ask diverse questions and give corresponding answers. |  |\n| Include questions asking about the detailed information of the molecule, including the class, conjugate acid/base, functional groups, chemical role, etc. |  |\n| Do not ask any question that cannot be answered confidently. |  |\n| Molecule SMILES: {SMILES} |  |\n| Caption: {CAPTION} |  |\n| Conversation: |  |", "caption": "Table 6: Performance comparison according to the training type.", "description": "This table compares the performance of models trained using different methods: without instruction tuning (only Stage 1 pre-training), multi-task learning, and the proposed instruction tuning approach (ours). The performance is evaluated across three tasks: molecule description generation, IUPAC prediction, and property prediction (using Mean Absolute Error).  This allows for a direct comparison of the effectiveness of different training strategies on various downstream tasks.", "section": "3.2 Training LLaMo"}, {"content": "| Instruction | Detail |\n|---|---| \n| You are an AI chemical assistant, and you are seeing a single molecule. What you see is provided with SMILES representation of the molecule and sentences describing the same molecule you are analyzing. In addition, the IUPAC name of the molecule is given. Answer all questions as you are seeing the molecule. |  |\n| Ask diverse questions and give corresponding answers. |  |\n| Include questions asking about the detailed information of the molecule, including the class, conjugate acid/base, functional groups, chemical role, etc. |  |\n| Do not ask any questions that cannot be answered confidently. |  |\n| Molecule SMILES: {SMILES} |  |\n| Caption: {CAPTION} |  |\n| IUPAC: {IUPAC} |  |\n| Conversation: |  |", "caption": "Table 7: Performance on chemical reaction tasks, including forward reaction prediction and retrosynthesis. \u2217*\u2217 denotes the model fine-tuned with task-specific instruction data.", "description": "Table 7 presents the performance comparison of various models on two chemical reaction prediction tasks: forward reaction prediction and retrosynthesis.  The table shows the performance metrics (Exact, BLEU, Levenshtein, RDK FTS, MACCS FTS, Morgan FTS, and Validity) for different models on these tasks. The models include various baselines (Alpaca, Baize, ChatGLM+, LLaMA+, Vicuna) and instruction-tuned models (LLaMA*, Mol-Instruction, InstructMol-G, InstructMol-GS).  The asterisk (*) indicates that the model was fine-tuned using task-specific instruction data. This allows for a direct comparison of models trained with and without task-specific instruction tuning, showcasing the effects of this training method on performance.", "section": "5 Experiments"}]