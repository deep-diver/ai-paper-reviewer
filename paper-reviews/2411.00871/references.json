{"references": [{"fullname_first_author": "Ross Taylor", "paper_title": "Galactica: A large language model for science", "publication_date": "2022-11-09", "reason": "This paper introduces Galactica, a large language model specifically trained for scientific tasks, which is directly relevant to the LLaMo model's approach and capabilities."}, {"fullname_first_author": "Zhiyuan Liu", "paper_title": "Molca: Molecular graph-language modeling with cross-modal projector and uni-modal adapter", "publication_date": "2023-XX-XX", "reason": "This paper introduces MolCA, a model which directly addresses the challenge of bridging language and graph modalities for molecular data, a key aspect of LLaMo's design."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-XX", "reason": "This paper introduces Llama 2, the large language model that serves as the foundation for LLaMo, providing the core language capabilities."}, {"fullname_first_author": "Yizhong Wang", "paper_title": "Self-instruct: Aligning language models with self-generated instructions", "publication_date": "2023-XX-XX", "reason": "This paper details the self-instruct method for aligning language models using self-generated instructions, a crucial technique used to enhance LLaMo's instruction-following abilities."}, {"fullname_first_author": "Yin Fang", "paper_title": "Mol-Instructions: A large-scale biomolecular instruction dataset for large language models", "publication_date": "2024-XX-XX", "reason": "This paper presents Mol-Instructions, a dataset that plays a key role in training and evaluating LLaMo, providing instruction-following data for molecular tasks."}]}