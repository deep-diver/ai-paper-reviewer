{"references": [{"fullname_first_author": "Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-06-04", "reason": "This paper introduces the foundational denoising diffusion probabilistic models, which are used by all the methods discussed in this study."}, {"fullname_first_author": "Chen", "paper_title": "Videocrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-06-17", "reason": "This paper provides an empirical and comparative analysis between ARVDMs with different network structures to take more past frames as input and is one of the methods to mitigate the memory bottleneck this study suggests."}, {"fullname_first_author": "Kim", "paper_title": "FIFO-Diffusion: Generating infinite videos from text without training", "publication_date": "2024-05-17", "reason": "This paper provides a comparison between methods of auto-regressive video diffusion models, specifically the effect of having two different stages of video generation, which is used in this study."}, {"fullname_first_author": "Chen", "paper_title": "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions", "publication_date": "2022-09-22", "reason": "This paper provides an analysis of diffusion models from the lens of score functions and is used to analyze the performance of the ARVDMs."}, {"fullname_first_author": "Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-12-01", "reason": "This paper provides a specific architectural option to better enhance memory by using more advanced transformers."}]}