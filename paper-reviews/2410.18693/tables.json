[{"figure_path": "2410.18693/tables/table_6_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing various models' performance using different data synthesis methods and highlighting the best scores for each model.", "section": "3.2 MAIN RESULTS"}, {"figure_path": "2410.18693/tables/table_9_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing different models' performance using various data synthesis methods and highlighting the best scores for each model.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_9_1.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of various models, including those using different data synthesis methods.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_10_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks comparing different models' performance, highlighting the best-performing model within each base model category.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_11_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of different models using various data synthesis methods.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_16_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of different models trained using various data synthesis methods, including ScaleQuest.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_19_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the performance of various models on four mathematical reasoning benchmarks, comparing different data synthesis methods and highlighting the impact of ScaleQuest.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_19_1.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing various models' performance using different data synthesis methods.", "section": "3.2 Main Results"}]