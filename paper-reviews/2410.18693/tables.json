[{"figure_path": "2410.18693/tables/table_6_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing different models' performance with various data synthesis methods.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_9_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of various models using different data synthesis methods.", "section": "3.2 MAIN RESULTS"}, {"figure_path": "2410.18693/tables/table_9_1.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of different models using various data synthesis methods.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_10_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing different models' performance using various data synthesis methods and highlighting the best performance achieved within each base model.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_11_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks comparing different models and data synthesis methods, showing ScaleQuest's significant outperformance.", "section": "3.2 MAIN RESULTS"}, {"figure_path": "2410.18693/tables/table_16_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing the performance of different models using various data synthesis methods.", "section": "3.2 Main Results"}, {"figure_path": "2410.18693/tables/table_19_0.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks comparing different models' performance with various data synthesis methods.", "section": "3.2 MAIN RESULTS"}, {"figure_path": "2410.18693/tables/table_19_1.html", "caption": "Table 1: Main results on four mathematical reasoning benchmarks. Bold means the best score within the respective base model. The baselines use different synthesis models, such as GPT-4, GPT-4-Turbo, GPT-40, DeepSeekMath, and Qwen2-Math. If multiple models are used, only the latest released one is marked. More details concerning these datasets are shown in Figure 5.", "description": "Table 1 presents the main results of four mathematical reasoning benchmarks, comparing various models' performance using different data synthesis methods.", "section": "3.2 Main Results"}]