[{"figure_path": "2410.18693/figures/figures_3_0.png", "caption": "Figure 2: Overview of our ScaleQuest method.", "description": "This figure illustrates the overall process of ScaleQuest, including question generation, data construction, and filtering.", "section": "2 SCALEQUEST: SCALING QUESTION SYNTHESIS FROM SCRATCH"}, {"figure_path": "2410.18693/figures/figures_15_0.png", "caption": "Figure 2: Overview of our ScaleQuest method.", "description": "This figure shows the overview of the ScaleQuest method, illustrating the question generation process from scratch, question generation, and final data construction.", "section": "2 SCALEQUEST: SCALING QUESTION SYNTHESIS FROM SCRATCH"}, {"figure_path": "2410.18693/figures/figures_18_0.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The figure shows the performance of different language models on the MATH benchmark, comparing the results obtained using different data synthesis methods, including ScaleQuest, and highlighting the improvements achieved by ScaleQuest.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18693/figures/figures_20_0.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The figure shows the performance comparison of different LLMs on MATH benchmark and the improvement achieved by fine-tuning Llama3-8B using different publicly available datasets.", "section": "1 INTRODUCTION"}]