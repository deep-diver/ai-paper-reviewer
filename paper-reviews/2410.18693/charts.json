[{"figure_path": "2410.18693/charts/charts_1_0.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The chart displays the performance of various language models on the MATH benchmark, comparing the impact of different data synthesis methods, particularly highlighting the improvement achieved using the ScaleQuest method.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18693/charts/charts_1_1.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The chart displays the performance of various models on the MATH benchmark, comparing the performance gains achieved using different data synthesis methods, notably highlighting the performance boost from the ScaleQuest method.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18693/charts/charts_1_2.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The chart displays the performance of various models on the MATH benchmark and Llama3-8B fine-tuned on different datasets, highlighting the impact of ScaleQuest.", "section": "INTRODUCTION"}, {"figure_path": "2410.18693/charts/charts_3_0.png", "caption": "Figure 3: The difficulty distribution of two real-world datasets and two synthetic datasets. The difficulty score is calculated based solely on the problem part.", "description": "The chart displays the distribution of difficulty scores for two real-world datasets (GSM8K and MATH) and two synthetic datasets generated using a question fine-tuning method.", "section": "2.2 QUESTION FINE-TUNING (QFT)"}, {"figure_path": "2410.18693/charts/charts_4_0.png", "caption": "Figure 4: The solvability and difficulty of the raw questions generated by the QFT model and the optimized ones.", "description": "The chart displays the solvability and difficulty ratios of questions before and after optimization using two different optimization models.", "section": "2.3 QUESTION PREFERENCE OPTIMIZATION (QPO)"}, {"figure_path": "2410.18693/charts/charts_8_0.png", "caption": "Figure 5: A comparison of the synthetic dataset generated by the raw instruct model, the model after QFT, the model after QPO, and the final dataset after applying reward filtering. The evaluation covers question solvability, difficulty, and instruction tuning effectiveness on Llama3-8B.", "description": "The chart compares the solvability, difficulty, and accuracy of a synthetic dataset generated using different stages of a question generation method, showing improvements at each stage.", "section": "3.3 ABLATION STUDY"}, {"figure_path": "2410.18693/charts/charts_15_0.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The chart displays a comparison of various LLMs' performance on the MATH benchmark, showcasing the improvement achieved using the ScaleQuest dataset.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18693/charts/charts_15_1.png", "caption": "Figure 1: Left: Results of different models on MATH, where -ScaleQuest denotes ours. Right: Results of Llama3-8B fine-tuned on publicly available datasets constructed by different methods.", "description": "The chart displays the performance of various models on the MATH benchmark, comparing the impact of different data synthesis methods, including ScaleQuest, on model accuracy.", "section": "1 INTRODUCTION"}]