[{"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/main_figure_2.jpg", "caption": "Figure 1: Qualitative comparison (Top): guidance sampling methods (CFG[18], PAG[1], SEG[20])\n(Mid): guidance-distilled models (DMD2[61], SDXL-Lightning\u00a0[31], Hyper-SDXL[42]) (Bottom): Other backbone such as Stable Diffusion 1.5\u00a0[44] and SANA\u00a0[59] with our proposed method, PLADIS(Ours). PLADIS is compatible with all guidance techniques and also supports guidance-distilled models including various backbone. It provides the generation of plausible and improved text alignment without any training or extra inference.", "description": "Figure 1 displays a qualitative comparison of various text-to-image generation methods.  The top row shows results from three guidance sampling methods: Classifier-Free Guidance (CFG), Perturbed Attention Guidance (PAG), and Smooth Energy Guidance (SEG). The middle row showcases results using three guidance-distilled models: DMD2, SDXL-Lightning, and Hyper-SDXL. The bottom row presents results obtained by applying the authors' proposed method, PLADIS, to several different base diffusion models, including Stable Diffusion 1.5 and SANA. This figure highlights PLADIS's versatility and compatibility with various existing techniques, showing improved text alignment and more plausible image generations without requiring any additional training or inference steps.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/compare_self-cross.jpg", "caption": "Figure 2: Conceptual comparison between other guidance methods\u00a0[18, 1, 20] and PLADIS: Existing guidance methods require extra inference steps due to undesired paths, such as null conditions or perturbing self-attention with an identity matrix or blurred attention weights. In contrast, PLADIS avoids additional inference paths by computing both sparse and dense attentions within all cross-attention modules using a scaling factor, \u03bb\ud835\udf06\\lambdaitalic_\u03bb. Moreover, PLADIS can be easily integrated with existing guidance approaches by simply replacing the cross-attention module.", "description": "Figure 2 illustrates the core difference between PLADIS and other guidance methods.  Existing methods like CFG, PAG, and SEG, while effective, introduce extra computational steps during inference because they either handle null conditions (CFG) or modify the behavior of self-attention (PAG and SEG). These modifications, such as replacing self-attention weights with an identity matrix (PAG) or blurring attention weights (SEG), introduce indirect paths that add to inference time. PLADIS, however, directly incorporates both sparse and dense cross-attention computations within the cross-attention module. A scaling factor (\u03bb) controls the balance between these two attention types. This streamlined approach eliminates the need for additional inference steps and facilitates easy integration into existing guidance techniques simply by replacing the cross-attention module. This is in contrast to the other methods which often require adjusting parameters for specific layers or modules.", "section": "3. Main Contribution : PLADIS"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_ablation_alpha.jpg", "caption": "Figure 3: Qualitative comparison between baseline and variants that substitute self-attention and cross-attention mechanisms with sparse attention methods.", "description": "Figure 3 presents a qualitative comparison of image generation results using different attention mechanisms in diffusion models.  The \"Baseline\" uses standard dense self-attention and cross-attention. The \"Replace Self-Attention\" variant substitutes sparse attention for the self-attention mechanism, while the \"Replace Cross-Attention\" variant replaces the cross-attention with sparse attention.  The figure displays generated images to illustrate the impact of each approach on image quality and text alignment.  It aims to show that replacing cross-attention with its sparse counterpart yields more favorable results but that replacing self-attention negatively impacts image generation.", "section": "3. Sparse Attention for T2I Generation"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_lambda.jpg", "caption": "Figure 4: Comparison of \u03b1\ud835\udefc\\alphaitalic_\u03b1 values in \u03b1\u2062-Entmax\ud835\udefc-Entmax\\alpha\\texttt{-Entmax}italic_\u03b1 -Entmax on the MS-COCO dataset with CFG and PAG guidance.", "description": "This figure displays the results of an experiment evaluating the impact of different sparsity levels (controlled by the \u03b1\u03b1\nparameter in \u03b1\u2062-Entmax\u03b1-Entmax\n) on the quality of images generated by a diffusion model. The experiment used the MS-COCO dataset and two guidance methods: Classifier-Free Guidance (CFG) and Perturbed Attention Guidance (PAG).  The figure likely shows metrics like FID (Fr\u00e9chet Inception Distance), CLIPScore, and possibly others, across varying \u03b1\u03b1\nvalues.  It demonstrates how the sparsity level affects the quality of generated images and potentially other aspects of image generation, as measured by these metrics, when using either CFG or PAG.", "section": "3. Effect of Sparsity in Cross-Attention Module"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/userstudy.jpg", "caption": "Figure 5: Qualitative comparison by varying the scale \u03bb\ud835\udf06\\lambdaitalic_\u03bb.\nAs the scale \u03bb\ud835\udf06\\lambdaitalic_\u03bb increases, images represent improved plausibility and enhanced text alignment. But too high a value leads to smoother textures and potential artifacts, similar to those seen in CFG. When \u03bb\ud835\udf06\\lambdaitalic_\u03bb is greater than 0, our PLADIS method is applied. In our configuration, \u03bb\ud835\udf06\\lambdaitalic_\u03bb is set to 2.0.", "description": "This figure displays a qualitative comparison of image generation results using the PLADIS method with different scaling factors (\u03bb).  The top row shows images generated with a baseline method, while subsequent rows demonstrate results with increasing \u03bb values (1.0, 1.5, 2.0, 3.0, 4.0). The images illustrate how increasing \u03bb enhances both the plausibility of the generated images and their alignment with the given text prompts.  However, excessively large \u03bb values (e.g., 4.0) can lead to overly smoothed textures and potential artifacts, mirroring the behavior observed with classifier-free guidance (CFG). The optimal \u03bb value selected for the PLADIS method in this paper is 2.0.", "section": "3. Main Contribution : PLADIS"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_ablation.jpg", "caption": "Figure 6: User Preference Study for PLADIS.", "description": "This figure presents the results of a user preference study comparing image generation results with and without the proposed PLADIS method.  The study used various guidance sampling methods (CFG, PAG, SEG) and guidance-distilled models.  Two questions were asked of participants:  'Which image is of higher quality and visually more pleasing?' and 'Which image looks more representative of the given prompt?'. The bar graphs show the percentage of times each method was preferred for image quality and prompt alignment.", "section": "User Preference Study"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/userstudy_supple.jpg", "caption": "Figure 7: Ablation study on the scale, \u03bb\ud835\udf06\\lambdaitalic_\u03bb, for PLADIS.", "description": "This ablation study analyzes how changing the scaling factor \u03bb in the PLADIS method affects the model's performance.  The scaling factor \u03bb controls the influence of sparse attention compared to dense attention.  The plots show how FID, CLIPScore, and PickScore change as \u03bb varies from 1.0 to 3.0.  This helps determine the optimal value of \u03bb for balancing the benefits of sparse attention with the performance of the base model.  The results illustrate the impact of different levels of sparsity on image generation quality and text alignment.", "section": "6. Ablation Study and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_ablation_tmper.jpg", "caption": "Figure 8: User preference study for PLADIS in the context of guidance-distilled models.\nWe evaluate the two aspects of model output with and without PLADIS such as image quality and prompt alignment.", "description": "This figure presents the results of a user preference study comparing image generation with and without the PLADIS method applied to guidance-distilled models.  Users were asked to evaluate two aspects of the generated images: image quality and prompt alignment. The bar charts show the percentage of users who preferred the images generated with PLADIS for each aspect and each model.  The results demonstrate that PLADIS consistently improves both image quality and prompt alignment across different guidance-distilled models, highlighting its effectiveness.", "section": "User Preference Study"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_cross.jpg", "caption": "Table 7: Application on other BackBone Model on MS COCO validation set. SD1.5 and SANA indicate that Stable Diffusion version 1.5 and SANA 1.6 B model, respectively.", "description": "This table presents a quantitative comparison of the performance of the proposed PLADIS method on different backbones: Stable Diffusion v1.5 (SD1.5) and SANA 1.6B.  It evaluates the FID (Fr\u00e9chet Inception Distance), CLIPScore, and ImageReward metrics to assess the image quality, text-image alignment, and overall user preference.  The results demonstrate the effectiveness and generalizability of the PLADIS method across various diffusion models.", "section": "E. Application on Other Backbone"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_sd15.jpg", "caption": "Table 8: Ablation study on layer group which is replaced with PLADIS on MS COCO validation dataset.", "description": "This ablation study investigates the impact of applying PLADIS to different layer groups within the UNet architecture of Stable Diffusion XL.  The MS-COCO validation dataset was used for evaluation. The table compares the performance (FID, CLIPScore, and ImageReward) of various configurations, including applying PLADIS to only the 'Up', 'Mid', or 'Down' layer groups, combinations of these groups, and finally applying it to all layers. This analysis aims to determine the optimal layer or group of layers for applying PLADIS to maximize its effectiveness in improving image generation quality and text alignment.", "section": "3. Main Contribution : PLADIS"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_sana.jpg", "caption": "Figure 9: Comparison results for various temperatures, with and without PLADIS, are presented, including the baseline (Softmax) and 1.5\u2212EntmaxEntmax-\\texttt{Entmax}- Entmax. While lower temperatures with the baseline offer benefits in both cases, our proposed method (\u03b1\ud835\udefc\\alphaitalic_\u03b1 = 1.5), with and without PLADIS, outperforms across all temperature settings.", "description": "Figure 9 displays the impact of temperature on the performance of different attention mechanisms, with and without the proposed PLADIS method.  The x-axis represents temperature, ranging from 0.1 to 1.0.  Four lines are plotted: Softmax (baseline), Softmax with PLADIS, 1.5-Entmax, and 1.5-Entmax with PLADIS. Each line shows the performance in terms of FID, CLIPScore, and ImageReward metrics. The results indicate that while lower temperatures generally improve the baseline method, the 1.5-Entmax approach (with or without PLADIS) consistently outperforms Softmax across all temperature settings.  This suggests that the sparsity introduced by 1.5-Entmax is beneficial, regardless of temperature.", "section": "Ablation Study and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_cfg.jpg", "caption": "Figure 10: Qualitative comparison of cross-attention average maps across all time steps. Top: Baseline. Middle: PLADIS (with \u03bb\ud835\udf06\\lambdaitalic_\u03bb = 1) represent only use \u03b1\u2062-Entmax\ud835\udefc-Entmax\\alpha\\texttt{-Entmax}italic_\u03b1 -Entmax transformation. Bottom: PLADIS (with \u03bb\ud835\udf06\\lambdaitalic_\u03bb = 2.0). Our PLADIS with \u03bb\ud835\udf06\\lambdaitalic_\u03bb = 2.0 provides a more sparse and sharp correlation with each text prompt, especially \u201drabbit\u201d and \u201ddog.\u201d Furthermore, other approaches yield incorrect attention maps that highlight the space between the dog prompt and rabbit space. However, our method provides an exact attention map.", "description": "Figure 10 visualizes cross-attention maps across different time steps to compare the baseline method with PLADIS, using \u03b1-Entmax with different sparsity levels (\u03bb=1 and \u03bb=2). The baseline shows diffuse attention, failing to clearly distinguish between objects in the prompt. PLADIS with \u03bb=1 shows improvement in focusing on relevant objects. PLADIS with \u03bb=2 yields the sharpest, most accurate attention map, correctly highlighting the \"rabbit\" and \"dog\" while avoiding the incorrect attention given to the space between them present in other methods.", "section": "3.1 Sparse Attention for T2I Generation"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_pag.jpg", "caption": "Figure 11: Qualitative evaluation of Stable Diffusion 1.5 using our PLADIS method: PLADIS significantly boosts generation quality, strengthens alignment with the given text prompt, and generates visually compelling images.", "description": "This figure showcases the improved image generation capabilities of Stable Diffusion 1.5 when enhanced with the PLADIS method.  The examples demonstrate that PLADIS not only improves the visual quality of the generated images but also significantly improves the alignment between the generated image and the given text prompt.  Each row presents a text prompt and the corresponding images generated by Stable Diffusion 1.5 both with and without PLADIS. The comparison highlights PLADIS's ability to create more realistic and visually appealing images that better match the user's intentions.", "section": "5. Results"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_seg.jpg", "caption": "Figure 12: Qualitative assessment of SANA\u00a0[59] with and without our PLADIS method: PLADIS notably improves generation quality, strengthens alignment with the provided text prompt, and produces visually striking images.", "description": "This figure presents a qualitative comparison of image generation results using the SANA model [59] with and without the application of the proposed PLADIS method.  Each row shows a text prompt, followed by two images: one generated using the original SANA model, and one generated using SANA enhanced with PLADIS.  The comparison highlights how PLADIS improves the generated images by enhancing their visual quality, ensuring that the generated image more accurately reflects the given text prompt, and overall resulting in more visually striking and compelling images.", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_1step.jpg", "caption": "Figure 13: Qualitative evaluation of the joint usage CFG\u00a0[18] with our method: CFG with PLADIS generates more plausible images with significantly improved text alignment based on the text prompt, without requiring additional inference.", "description": "Figure 13 showcases the combined effect of Classifier-Free Guidance (CFG) and the proposed PLADIS method on image generation.  It demonstrates that integrating PLADIS with CFG produces images that are more realistic and have better alignment with the text prompts.  Importantly, this improvement is achieved without any increase in the computational cost of inference, showing the efficiency of PLADIS.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_4step.jpg", "caption": "Figure 14: Qualitative evaluation of the joint usage PAG\u00a0[1] with our method: Integrating PAG with PLADIS produces highly credible images with markedly enhanced correspondence to the text prompt, all achieved without any further inference steps.", "description": "Figure 14 shows a qualitative comparison of image generation results using Perturbed Attention Guidance (PAG) with and without PLADIS.  The figure demonstrates that combining PAG with PLADIS significantly improves the quality and accuracy of generated images, especially in their alignment with the given text prompt.  Importantly, this improvement is achieved without the need for any additional inference steps or model retraining, highlighting the efficiency of the PLADIS method.", "section": "Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_ablation.jpg", "caption": "Figure 15: Qualitative evaluation of the joint usage SEG\u00a0[20] with our method: The combination of SEG and PLADIS yields highly convincing image generations with substantially improved alignment to the given text prompt, accomplished without the need for additional inference.", "description": "Figure 15 presents a qualitative comparison showcasing the results of using Smooth Energy Guidance (SEG) in conjunction with the proposed PLADIS method.  The images generated demonstrate that combining these techniques leads to highly realistic and convincing outputs, significantly improving the alignment between the generated images and their corresponding text prompts. Notably, these improvements are achieved without the need for any additional inference steps, highlighting the efficiency of the PLADIS approach.", "section": "Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.07677/extracted/6266216/fig/fig_supple_alpha.jpg", "caption": "Figure 16: Qualitative comparison of the guidance-distilled model with our PLADIS method for one-step sampling: Even with one-step sampling, our PLADIS enhances generation quality, improves coherence with the given text prompt, and produces visually plausible images.", "description": "Figure 16 presents a qualitative comparison of several guidance-distilled models (SDXL-Turbo, SDXL-Lightening, DMD2, and Hyper-SDXL) with and without the application of the proposed PLADIS method.  The comparison focuses specifically on one-step sampling.  The figure shows that even with just one sampling step, PLADIS significantly improves the quality of generated images, enhances the alignment between the generated images and the given text prompts, and produces images that are more visually realistic and plausible.", "section": "Results"}]