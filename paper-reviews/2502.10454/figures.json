[{"figure_path": "https://arxiv.org/html/2502.10454/x1.png", "caption": "Figure 1: Comparison between drill-based learning and example-based learning. The first two math LLMs fail when confronted with advanced mathematics, and \u201cProving by examples\u201d is a highly creative and concept-intensive mathematical skill.", "description": "This figure compares two learning paradigms in mathematical problem-solving: drill-based learning and example-based learning. Drill-based learning involves repetitive practice with similar problems, while example-based learning emphasizes understanding mathematical concepts through illustrative examples and counterexamples. The figure highlights that while the drill-based approach might be sufficient for simple problems, it falls short when dealing with complex, advanced mathematical concepts.  Example-based learning, including the use of counterexamples to disprove statements, is shown to be crucial for deeper mathematical understanding. The figure shows that even advanced LLMs often struggle with the types of complex mathematical reasoning required for this example-based approach.  The image illustrates that traditional methods of training LLMs, focused on repetition, are not sufficient for achieving true mathematical understanding and reasoning abilities.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.10454/x2.png", "caption": "Figure 2: Overview the construction process of CounterMATH. CounterMATH was first extracted from photocopied mathematical textbooks by crowd-sourced labelers with the OCR tool. For the next step, authors with bachelor degrees in applied mathematics as annotation experts would filter and correct improper statement-rationale pairs. Finally, GPT-4o was prompted to translate the validated data into English under experts\u2019 supervision.", "description": "The figure illustrates the creation of the CounterMATH dataset.  First, mathematical textbooks were scanned and processed using Optical Character Recognition (OCR). Crowd-sourced workers then extracted statement-rationale pairs. Applied mathematics experts reviewed this data, correcting errors and ensuring the quality of the statement-rationale pairs.  Finally, a large language model (GPT-4) translated the validated data into English under expert oversight.", "section": "3. COUNTERMATH"}, {"figure_path": "https://arxiv.org/html/2502.10454/x3.png", "caption": "(a) Different fields.", "description": "The figure shows a pie chart illustrating the distribution of data points across four different mathematical fields within the COUNTERMATH dataset.  The fields are: Algebra, Topology, Real Analysis, and Functional Analysis. The size of each slice is proportional to the number of statement-rationale pairs belonging to that field. This visualization helps understand the dataset's coverage across various mathematical subfields.", "section": "3. Data Analysis"}, {"figure_path": "https://arxiv.org/html/2502.10454/x4.png", "caption": "(b) Judgement types.", "description": "This figure shows the distribution of judgements (True/False) in the COUNTERMATH dataset.  The majority of statements are labeled as 'True', likely because the statements are from mathematical textbooks where accurate statements are the norm and to avoid confusing readers.", "section": "3.2. Data Analysis"}, {"figure_path": "https://arxiv.org/html/2502.10454/x5.png", "caption": "Figure 3: Data Distribution of CounterMATH.", "description": "This figure shows the distribution of the COUNTERMATH dataset across different fields of mathematics and the distribution of true and false statements within the dataset.  The left subplot (a) illustrates the proportion of data points originating from Algebra, Topology, Real Analysis, and Functional Analysis, highlighting the diverse mathematical areas covered in COUNTERMATH. The right subplot (b) visualizes the class imbalance in the dataset, indicating the overwhelming proportion of 'True' statements compared to 'False' statements. This imbalance is a characteristic feature of the dataset which is created from textbooks and is noteworthy when evaluating model performance.", "section": "3. COUNTERMATH"}, {"figure_path": "https://arxiv.org/html/2502.10454/x6.png", "caption": "Figure 4: The overview of our training data engineering framework.", "description": "This figure illustrates the process of creating training data for enhancing the model's counterexample-driven reasoning. It starts with available mathematical datasets and filters data containing counterexamples or counterexample-based proofs.  The filtered data is then refined to align with the benchmark's characteristics, focusing on explicitly showing examples in the reasoning process. The final output is a refined training dataset ready for model fine-tuning.", "section": "5.1. Training Data Engineering Framework"}, {"figure_path": "https://arxiv.org/html/2502.10454/x7.png", "caption": "Figure 5: Fine-grained evaluation results of different fields in CounterMATH.", "description": "This figure presents a fine-grained analysis of the performance of various LLMs on the COUNTERMATH benchmark across four distinct mathematical fields: algebra, topology, real analysis, and functional analysis.  It shows the F1 score for each model within each field, providing a detailed view of model strengths and weaknesses across different mathematical domains. This allows for a deeper understanding of the nuances in LLM performance in higher-level mathematics.", "section": "6. Analysis and Discussions"}, {"figure_path": "https://arxiv.org/html/2502.10454/x8.png", "caption": "Figure 6: The relationship between Mean Token Ratios (%) and F1 (macro) scores for various models. The red dashed line represents the Ground Truth Token Ratio (100%), serving as an efficiency benchmark. Models closer to this line are more token-efficient, while those farther to the right consume significantly more tokens.", "description": "This figure displays the correlation between a model's performance (measured by the F1 macro score) and its token efficiency.  Token efficiency is calculated as the ratio of tokens used by the model to the tokens in the ground truth.  The graph shows that models closer to the 100% Ground Truth Token Ratio line are more efficient, using fewer tokens to achieve comparable accuracy.  Points far to the right indicate models that use significantly more tokens than necessary, suggesting inefficiency.", "section": "6. Analysis and Discussions"}]