{"importance": "**Data contamination** significantly impacts LLM evaluation. This work introduces a novel benchmark, which automatically **updates with real-world knowledge, ensuring contamination-free evaluation**. This automation enables easier adaptation to new LLMs and facilitates more reliable research progress by addressing a critical challenge in the field.", "summary": "Auto-built benchmark with up-to-date knowledge ensures contamination-free LLM evaluation.", "takeaways": ["AntiLeak-Bench guarantees contamination-free evaluation by using real-world knowledge updated after an LLM's training cutoff.", "It automates benchmark building, reducing maintenance costs and enabling adaptation to new LLMs.", "Experiments highlight data contamination issues in existing benchmarks and the efficacy of AntiLeak-Bench in addressing them."], "tldr": "Static benchmarks for evaluating large language models (LLMs) suffer from data contamination, where test data leaks into training sets of newer models. Current dynamic benchmarks update with new data, but they may still contain pre-existing knowledge and rely heavily on human labor, hindering their reliability and maintenance.  Existing benchmarks update with new data, but without verifying its novelty, leading to potential contamination. Furthermore, they rely heavily on manual updates, hindering their frequent maintenance and scalability with the rise of new LLMs. AntiLeak-Bench addresses these issues by using only verifiably new knowledge absent from training sets to construct contamination-free samples. It also employs a fully automated workflow for building and updating the benchmark, reducing human labor and enabling seamless adaptation to new emerging LLMs.", "affiliation": "Nanyang Technological University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2412.13670/podcast.wav"}