<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning &#183; HF Daily Paper Reviews by AI"><meta name=description content="Boosting language model reasoning:  A novel hybrid approach using latent tokens drastically shortens reasoning traces, improving model performance and efficiency."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ Meta AI,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning"><meta property="og:description" content="Boosting language model reasoning:  A novel hybrid approach using latent tokens drastically shortens reasoning traces, improving model performance and efficiency."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-02-05T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-05T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ Meta AI"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/cover.png"><meta name=twitter:title content="Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning"><meta name=twitter:description content="Boosting language model reasoning:  A novel hybrid approach using latent tokens drastically shortens reasoning traces, improving model performance and efficiency."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning","headline":"Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning","abstract":"Boosting language model reasoning:  A novel hybrid approach using latent tokens drastically shortens reasoning traces, improving model performance and efficiency.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2502.03275\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-02-05T00:00:00\u002b00:00","datePublished":"2025-02-05T00:00:00\u002b00:00","dateModified":"2025-02-05T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ Meta AI"],"mainEntityOfPage":"true","wordCount":"3144"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-03-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-24</p></a><a href=/ai-paper-reviewer/2025-03-25/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-25</p></a><a href=/ai-paper-reviewer/2025-03-26/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-26</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-24</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-25/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-25</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-26/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-26</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2502.03275/cover_hu2839535969123088943.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2502.03275/>Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-02-05T00:00:00+00:00>5 February 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3144 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">15 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2502.03275/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2502.03275/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-meta-ai/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Meta AI</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#latent-reasoning>Latent Reasoning</a></li><li><a href=#vq-vae-encoding>VQ-VAE Encoding</a></li><li><a href=#hybrid-training>Hybrid Training</a></li><li><a href=#benchmark-results>Benchmark Results</a></li><li><a href=#token-efficiency>Token Efficiency</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#latent-reasoning>Latent Reasoning</a></li><li><a href=#vq-vae-encoding>VQ-VAE Encoding</a></li><li><a href=#hybrid-training>Hybrid Training</a></li><li><a href=#benchmark-results>Benchmark Results</a></li><li><a href=#token-efficiency>Token Efficiency</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2502.03275</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>DiJia Su et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-02-06</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2502.03275 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2502.03275 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2502.03275/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Current large language models (LLMs) excel at reasoning when provided with step-by-step explanations (chain-of-thought prompting). However, this method leads to lengthy inputs, increasing computational costs. This paper tackles this issue by focusing on the efficiency problem of chain-of-thought prompting. The core problem is that using many words for explanation consumes lots of computational resources and increases response time.</p><p>This research introduces a hybrid approach that uses latent discrete tokens (generated by VQ-VAE) to partially represent the initial reasoning steps. This significantly reduces the input length. The researchers trained the model using a random mixing strategy of latent and text tokens, adapting quickly to new tokens and achieving significant performance gains in various benchmarks (Math, GSM8K, and a fresh Gaokao Math dataset). The experiments show that the proposed method not only improved performance but also significantly reduced reasoning trace length (on average, 17%).</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-d500c4bf30b3874b169c77a0cfd9cf9b></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-d500c4bf30b3874b169c77a0cfd9cf9b",{strings:[" A hybrid representation of reasoning processes using latent tokens significantly reduces reasoning trace length, thus improving computational efficiency. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-09bb46f4f4226a25004d8d281a20d2ea></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-09bb46f4f4226a25004d8d281a20d2ea",{strings:[" The proposed training procedure, which mixes latent and text tokens, facilitates effective learning with unseen latent tokens. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-2da6ececfb2aae69945df5628cd5ce6a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-2da6ececfb2aae69945df5628cd5ce6a",{strings:[" Consistent performance improvements over baseline methods are demonstrated across various benchmarks, including mathematical and logical reasoning tasks. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial for researchers working on <strong>large language models (LLMs)</strong> and <strong>reasoning</strong>. It addresses the computational cost of chain-of-thought prompting by introducing a novel method to significantly shorten reasoning traces, thus enhancing LLM efficiency and performance. The proposed technique of using latent tokens opens <strong>new avenues for research on efficient and effective LLM training</strong> and offers a potential solution to improve the overall efficiency of using LLMs for various reasoning and planning tasks. This is highly relevant given the increasing emphasis on reducing the computational footprint of LLMs.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/x1.png alt></figure></p><blockquote><p>üîº This figure illustrates the method of compressing reasoning traces in the paper by replacing sequences of text tokens with latent tokens. Specifically, it shows an example where 32 consecutive chain-of-thought (CoT) tokens are replaced by two latent tokens. The replacement starts from the left and proceeds to the right up to a predefined point; after that point, the remaining CoT tokens retain their original form. This technique is used to shorten the length of reasoning traces and reduce computational costs while preserving the crucial reasoning information. The chunk size (L) is set to 16, and the compression rate (r) is also 16, indicating that each chunk of 16 tokens is replaced by one latent token.</p><details><summary>read the caption</summary>Figure 3.1: An example illustrating our replacement strategy. With chunk size L=16ùêø16L=16italic_L = 16 and compression rate r=16ùëü16r=16italic_r = 16, we encode 32 textual CoT tokens into 2 discrete latent tokens from left to right. The other CoT tokens will remain in their original forms.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S4.T1.3.3><thead class=ltx_thead><tr class=ltx_tr id=S4.T1.3.3.4.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S4.T1.3.3.4.1.1 rowspan=2><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.4.1.1.1>Model</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan=2 id=S4.T1.3.3.4.1.2><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.4.1.2.1>Keys-Finding Maze</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan=2 id=S4.T1.3.3.4.1.3><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.4.1.3.1>ProntoQA</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan=2 id=S4.T1.3.3.4.1.4><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.4.1.4.1>ProsQA</span></th></tr><tr class=ltx_tr id=S4.T1.3.3.5.2><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.1>1-Feasible-10 (%)</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.2>Num. Tokens</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.3>Accuracy</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.4>Num. Tokens</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.5>Accuracy</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id=S4.T1.3.3.5.2.6>Num. Tokens</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S4.T1.3.3.6.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S4.T1.3.3.6.1.1>Sol-Only</th><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.2>3</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.3>645</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.4>93.8</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.5>3.0</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.6>76.7</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.3.3.6.1.7>8.2</td></tr><tr class=ltx_tr id=S4.T1.3.3.7.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S4.T1.3.3.7.2.1>CoT</th><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.2><span class="ltx_text ltx_framed ltx_framed_underline" id=S4.T1.3.3.7.2.2.1>43</span></td><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.3>1312.0</td><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.4><span class="ltx_text ltx_framed ltx_framed_underline" id=S4.T1.3.3.7.2.4.1>98.8</span></td><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.5>92.5</td><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.6><span class="ltx_text ltx_framed ltx_framed_underline" id=S4.T1.3.3.7.2.6.1>77.5</span></td><td class="ltx_td ltx_align_center" id=S4.T1.3.3.7.2.7>49.4</td></tr><tr class=ltx_tr id=S4.T1.3.3.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S4.T1.3.3.3.4><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.3.4.1>Latent (ours)</span></th><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.1.1.1.1><span class="ltx_text ltx_font_bold" id=S4.T1.1.1.1.1.1>62.8 <span class=ltx_text id=S4.T1.1.1.1.1.1.1 style=color:green>(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.1.m1.1.1" mathcolor="#008000" stretchy="false" xref="S4.T1.1.1.1.1.1.1.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.1.1.m1.1d">‚Üë</annotation></semantics></math> +19.8)</span></span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.3.3.3.5>374.6</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.2.2.2><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.2.1>100 <span class=ltx_text id=S4.T1.2.2.2.2.1.1 style=color:green>(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.2.1.1.m1.1"><semantics id="S4.T1.2.2.2.2.1.1.m1.1a"><mo id="S4.T1.2.2.2.2.1.1.m1.1.1" mathcolor="#008000" stretchy="false" xref="S4.T1.2.2.2.2.1.1.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.1.1.m1.1b"><ci id="S4.T1.2.2.2.2.1.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.1.1.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.2.1.1.m1.1d">‚Üë</annotation></semantics></math> +1.2)</span></span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.3.3.3.6>7.7</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.3.3.3.3><span class="ltx_text ltx_font_bold" id=S4.T1.3.3.3.3.1>96.2 <span class=ltx_text id=S4.T1.3.3.3.3.1.1 style=color:green>(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.3.1.1.m1.1"><semantics id="S4.T1.3.3.3.3.1.1.m1.1a"><mo id="S4.T1.3.3.3.3.1.1.m1.1.1" mathcolor="#008000" stretchy="false" xref="S4.T1.3.3.3.3.1.1.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.1.1.m1.1b"><ci id="S4.T1.3.3.3.3.1.1.m1.1.1.cmml" xref="S4.T1.3.3.3.3.1.1.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.3.1.1.m1.1d">‚Üë</annotation></semantics></math> +18.7)</span></span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.3.3.3.7>10.9</td></tr></tbody></table></table></figure><blockquote><p>üîº Table 4.1 presents a comparison of different methods for solving three reasoning tasks: Keys-Finding Maze, ProntoQA, and ProsQA. The results demonstrate that the proposed &rsquo;latent approach&rsquo; significantly outperforms existing methods (Sol-Only, CoT, iCoT) in terms of accuracy across all three tasks. Importantly, the table also highlights the efficiency gains of the latent approach. It shows a substantial reduction in the number of tokens required for generating solutions compared to the chain-of-thought (CoT) baseline, while achieving accuracy comparable to or exceeding the Sol-Only approach which generates the shortest traces.</p><details><summary>read the caption</summary>Table 4.1: Our latent approach surpasses the other baselines on Keys-Finding Maze, ProntoQA and ProsQA with a large margin . We use top-kùëòkitalic_k (k=10ùëò10k=10italic_k = 10) decoding for Keys-Finding Maze and greedy decoding for ProntoQA and ProsQA. In terms of token efficiency, our latent approach also generates much shorter reasoning traces than the CoT baseline, closely tracking or even outperforming the Sol-Only approach. Bold: best results. Underline: second best results. (‚Üë‚Üë\uparrow‚Üë +Performance gain compared with the second best result.)</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Latent Reasoning<div id=latent-reasoning class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#latent-reasoning aria-label=Anchor>#</a></span></h4><p>Latent reasoning, in the context of large language models (LLMs), represents <strong>a significant advancement</strong> in improving reasoning capabilities. Instead of relying solely on explicit textual reasoning steps, which can be computationally expensive and lengthy, latent reasoning aims to <strong>implicitly capture the core essence of reasoning</strong> within a compact, compressed representation. This is often achieved through techniques like vector quantization (VQ-VAE), where intermediate reasoning steps are encoded into discrete latent tokens. <strong>The key advantage</strong> is that these latent representations dramatically reduce the length of reasoning traces processed by the LLM, leading to improved efficiency and potentially better performance on complex reasoning tasks. However, effective utilization of latent reasoning requires careful consideration of several factors. Successful implementation necessitates a robust encoding mechanism that can <strong>accurately capture the nuances of the reasoning process</strong> and a decoding method that allows the LLM to effectively utilize these latent tokens. Furthermore, training methods must be carefully designed to allow the model to adapt effectively to the presence of unseen latent tokens in the fine-tuning stage, and to balance the benefits of compressed representation against potential information loss.</p><h4 class="relative group">VQ-VAE Encoding<div id=vq-vae-encoding class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#vq-vae-encoding aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;VQ-VAE Encoding&rsquo; in the context of a research paper likely refers to the use of a Vector Quantized Variational Autoencoder (VQ-VAE) to generate a compressed, discrete latent representation of input data. <strong>This technique is particularly relevant for processing long sequences, such as those found in chain-of-thought (CoT) reasoning traces</strong> where many words contribute to textual coherence rather than core reasoning information. The VQ-VAE learns to map sequences of text tokens (the CoT trace) into a lower-dimensional space represented by a discrete set of &rsquo;latent tokens&rsquo;. <strong>This compression significantly reduces computational cost and memory usage.</strong> A crucial aspect is the use of a codebook, which acts as a lookup table, converting these latent vectors back to meaningful representations. The effectiveness of this approach depends on the VQ-VAE&rsquo;s ability to capture the essence of the reasoning steps without losing crucial information and the subsequent LLM&rsquo;s capacity to learn and effectively utilize this compressed representation during reasoning tasks. <strong>The success likely hinges on both the design and training of the VQ-VAE as well as the method used to integrate these latent tokens with the remaining parts of the CoT trace</strong> during the final model training phase. Therefore, a thorough discussion of architecture, training strategies, and quantitative results evaluating the trade-off between compression and reasoning performance would be expected in a detailed exploration of &lsquo;VQ-VAE Encoding&rsquo;.</p><h4 class="relative group">Hybrid Training<div id=hybrid-training class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hybrid-training aria-label=Anchor>#</a></span></h4><p>A hypothetical &ldquo;Hybrid Training&rdquo; section in a research paper on language models would likely explore methods combining different training paradigms to leverage their respective strengths. <strong>One approach could involve pretraining a model on a massive text corpus using standard techniques, followed by finetuning on a smaller, higher-quality dataset designed for specific reasoning tasks.</strong> This approach leverages the general knowledge and language proficiency from pretraining, enhancing the model&rsquo;s ability to reason effectively on more specific tasks during finetuning. <strong>Another strategy might involve integrating reinforcement learning (RL) with supervised learning.</strong> Initially, supervised learning would establish a baseline performance; RL would then refine the model‚Äôs reasoning skills by providing rewards for correct answers and penalties for incorrect ones. This could address the limitations of pure supervised learning by allowing the model to learn from experience and adapt to nuanced problem-solving scenarios. <strong>A particularly innovative approach could combine symbolic reasoning methods with neural networks.</strong> This could involve incorporating explicit rules and logical structures into the model&rsquo;s architecture, complementing the network&rsquo;s ability to learn complex patterns from data. The potential benefits of such an approach are considerable, offering improved robustness and explainability, while also potentially enabling the model to handle more complex and abstract reasoning problems. The challenges would focus on effective integration of these disparate methods and balancing the benefits of each approach. Careful evaluation would be needed to determine the efficacy and efficiency of hybrid approaches compared to traditional methods.</p><h4 class="relative group">Benchmark Results<div id=benchmark-results class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#benchmark-results aria-label=Anchor>#</a></span></h4><p>A dedicated &lsquo;Benchmark Results&rsquo; section in a research paper would ideally present a comprehensive evaluation of the proposed method against existing state-of-the-art techniques. This would involve selecting relevant and diverse benchmarks, clearly describing the evaluation metrics used, and presenting the results in a clear and easily interpretable format, such as tables and charts. <strong>Crucially, the analysis should go beyond simply reporting raw numbers.</strong> A robust analysis would delve into the strengths and weaknesses of the proposed method relative to the baselines, exploring possible reasons for superior or inferior performance on specific benchmarks. For instance, if the new method excels on certain tasks but underperforms on others, the reasons for these discrepancies would be investigated and discussed, possibly pointing to areas for future improvement. <strong>Statistical significance testing</strong> would provide strong evidence supporting the claims of improvement. Further, discussing limitations of the benchmarks themselves and potential biases inherent in the dataset is essential to promote a balanced and credible interpretation of the results. Finally, a detailed discussion of the efficiency and resource requirements of the new method, compared to existing methods, would provide a holistic perspective.</p><h4 class="relative group">Token Efficiency<div id=token-efficiency class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#token-efficiency aria-label=Anchor>#</a></span></h4><p>The concept of <strong>token efficiency</strong> in large language models (LLMs) is crucial for optimizing both computational resources and inference speed. The paper explores this by introducing a hybrid representation of reasoning processes, leveraging latent discrete tokens alongside traditional text tokens. This approach significantly reduces the length of reasoning traces, leading to improved <strong>token efficiency</strong>. The reduction in trace length is achieved by abstracting away initial reasoning steps using a vector-quantized variational autoencoder (VQ-VAE), thereby compressing the information into fewer tokens. The effectiveness of this method is demonstrated across various benchmarks, showing consistent improvements in reasoning tasks while using significantly shorter input sequences. The method also incorporates a randomized replacement strategy during training, enabling fast adaptation to new latent tokens, further enhancing <strong>token efficiency</strong> and overall performance. <strong>Reduced computational cost and faster inference</strong> are the direct benefits of this improved token efficiency, making the approach particularly valuable for resource-constrained environments and applications requiring real-time responses.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/x2.png alt></figure></p><blockquote><p>üîº The figure illustrates the Vector Quantized Variational Autoencoder (VQ-VAE) used to generate latent tokens for compressing reasoning traces. The VQ-VAE consists of an encoder (f_enc), a codebook, a quantizer (q), and a decoder (f_dec). The encoder maps sequences of text tokens representing reasoning steps into continuous embedding vectors. These vectors are then quantized to the nearest codebook entry using the quantizer, yielding a discrete latent token representing the original sequence. The decoder maps these latent tokens back to text tokens. This process converts the original sequence of text tokens into a compressed sequence of discrete latent tokens, which can be used to shorten reasoning traces and improve efficiency. The VQ-VAE is trained on the whole input sequence X to enhance the quality of latent abstractions, although it only operates on the reasoning steps during inference, effectively abstracting away the less informative initial steps of the reasoning process.</p><details><summary>read the caption</summary>Figure 3.2: A graphical illustration of our VQ-VAE. fencsubscriptùëìenc{f_{\text{enc}}}italic_f start_POSTSUBSCRIPT enc end_POSTSUBSCRIPT encodes the text tokens into latent embeddings, which are quantized by checking the nearest neighbors in the codebook. fdecsubscriptùëìdec{f_{\text{dec}}}italic_f start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT decodes those quantized embeddings back to text tokens. When applying the VQ-VAE to compress the text tokens, the discrete latent tokens ZùëçZitalic_Z are essentially the index of corresponding embeddings in the codebook.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/entry_1.png alt></figure></p><blockquote><p>üîº This figure shows a comparison of the average attention weights across input prompt tokens between the proposed latent model and the baseline CoT model for the question: What is the positive difference between 120% of 30 and 130% of 20?. The latent model demonstrates a stronger focus on numerical values and mathematical operation tokens, highlighting its improved ability to process mathematical problems.</p><details><summary>read the caption</summary>(a) Prompt: What is the positive difference between $120%$ of 30 and $130%$ of 20?</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/entry_7746.png alt></figure></p><blockquote><p>üîº This figure shows the attention weights visualization for the second question in the prompt: Mark has $50 in his bank account; he earns $10 per day at his work. If he wants to buy a bike that costs $300, how many days does Mark have to save his money?. The visualization compares the attention weights of the model using the proposed latent approach against the baseline CoT model. It demonstrates that the latent approach focuses more attention on the numbers (50, 10, 300) and words representing mathematical operations, indicating a better understanding of the problem&rsquo;s numerical aspects.</p><details><summary>read the caption</summary>(b) Prompt: Mark has $50 in his bank account. He earns $10 per day at his work. If he wants to buy a bike that costs $300, how many days does Mark have to save his money?</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/maze_env.png alt></figure></p><blockquote><p>üîº Figure 4.1 presents a comparison of attention weights between the proposed latent approach and the baseline chain-of-thought (CoT) method. The visualization shows the average attention weights assigned to input tokens during the generation of responses for two mathematical reasoning problems. The latent model is shown to have significantly higher attention weights on numbers and operation-related tokens compared to the CoT model, indicating a stronger focus on core numerical computation in the latent approach.</p><details><summary>read the caption</summary>Figure 4.1: Comparing with the CoT model, our latent approach have high attention weights on numbers and text tokens representing mathematical operations.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/maze_traj1.png alt></figure></p><blockquote><p>üîº This figure shows a visual representation of the Keys-Finding Maze environment used in the experiments. It&rsquo;s a grid-based maze where an agent needs to navigate to a target location by collecting keys to open color-coded doors. The maze is composed of multiple interconnected rooms, making it more complex than a simple path-finding problem.</p><details><summary>read the caption</summary>Figure A.1: An example of the keys-finding maze environment.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/maze_traj2.png alt></figure></p><blockquote><p>üîº This figure shows the first phase of a multi-step process in a Keys-Finding Maze environment. The agent (black circle) is in a maze and must navigate to a goal location (gold diamond). To get there, they must collect keys of different colors (red, green, blue) that correspond to similarly colored doors, one key at a time. This first phase depicts the agent&rsquo;s initial state and the location of the goal, keys and doors.</p><details><summary>read the caption</summary>(a) Phase 1</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/maze_traj3.png alt></figure></p><blockquote><p>üîº This phase of the Keys-Finding Maze shows the agent, after obtaining the blue key in Phase 1, proceeding to open the blue door to access the red key. The agent&rsquo;s next step will involve using the red key.</p><details><summary>read the caption</summary>(b) Phase 2</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03275/extracted/6181144/plots/maze_traj4.png alt></figure></p><blockquote><p>üîº This figure shows the third phase of an agent&rsquo;s optimal trajectory in a keys-finding maze. The agent has already acquired the blue key, opened the blue door, and obtained the red key. In this phase, the agent is moving towards the red door to use the red key to open it.</p><details><summary>read the caption</summary>(c) Phase 3</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A1.T1.2><thead class=ltx_thead><tr class=ltx_tr id=A1.T1.2.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A1.T1.2.1.1.1><span class="ltx_text ltx_font_bold" id=A1.T1.2.1.1.1.1>Parameter</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A1.T1.2.1.1.2><span class="ltx_text ltx_font_bold" id=A1.T1.2.1.1.2.1>Value</span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A1.T1.2.2.1><td class="ltx_td ltx_align_left ltx_border_t" id=A1.T1.2.2.1.1>Number of Layers (Transformer Blocks)</td><td class="ltx_td ltx_align_center ltx_border_t" id=A1.T1.2.2.1.2>12</td></tr><tr class=ltx_tr id=A1.T1.2.3.2><td class="ltx_td ltx_align_left" id=A1.T1.2.3.2.1>Hidden Size (Embedding Size)</td><td class="ltx_td ltx_align_center" id=A1.T1.2.3.2.2>768</td></tr><tr class=ltx_tr id=A1.T1.2.4.3><td class="ltx_td ltx_align_left" id=A1.T1.2.4.3.1>Number of Attention Heads</td><td class="ltx_td ltx_align_center" id=A1.T1.2.4.3.2>12</td></tr><tr class=ltx_tr id=A1.T1.2.5.4><td class="ltx_td ltx_align_left" id=A1.T1.2.5.4.1>Vocabulary Size</td><td class="ltx_td ltx_align_center" id=A1.T1.2.5.4.2>50,257</td></tr><tr class=ltx_tr id=A1.T1.2.6.5><td class="ltx_td ltx_align_left ltx_border_bb" id=A1.T1.2.6.5.1>Total Number of Parameters</td><td class="ltx_td ltx_align_center ltx_border_bb" id=A1.T1.2.6.5.2>117 million</td></tr></tbody></table></table></figure><blockquote><p>üîº Table 4.2 presents a comprehensive evaluation of the proposed &rsquo;latent approach&rsquo; on various mathematical reasoning benchmarks. Models were fine-tuned using the MetaMathQA dataset. The results are compared against several baselines: Sol-Only (trained only on solutions), CoT (trained with complete chain-of-thought), iCoT (iterative chain-of-thought elimination), and Pause Token (uses pause tokens). The table highlights performance gains of the latent approach compared to the second-best baseline for each benchmark, categorized by in-domain (Math and GSM8K, which were used to create the MetaMathQA training data) and out-of-domain datasets. Bold text indicates the best result, underlined text the second-best, and the arrows indicate the performance improvements.</p><details><summary>read the caption</summary>Table 4.2: Our latent approach outperforms the baselines on various types of mathematical reasoning benchmarks. The models are fine-tuned on the MetaMathQA¬†(Yu et¬†al., 2023) dataset. The Math and GSM8K are in-domain datasets since they are used to generate MetaMathQA, while the others are out-of-domain. Bold: best results. Underscore: second best results. ‚Üë‚Üë\uparrow‚Üë +: ‚ÄÖPerformance gain compared with the second best result.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A2.T1.45><tbody class=ltx_tbody><tr class=ltx_tr id=A2.T1.2.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id=A2.T1.1.1.1><math alttext="X=P\oplus C\oplus S" class="ltx_Math" display="inline" id="A2.T1.1.1.1.m1.1"><semantics id="A2.T1.1.1.1.m1.1a"><mrow id="A2.T1.1.1.1.m1.1.1" xref="A2.T1.1.1.1.m1.1.1.cmml"><mi id="A2.T1.1.1.1.m1.1.1.2" xref="A2.T1.1.1.1.m1.1.1.2.cmml">X</mi><mo id="A2.T1.1.1.1.m1.1.1.1" xref="A2.T1.1.1.1.m1.1.1.1.cmml">=</mo><mrow id="A2.T1.1.1.1.m1.1.1.3" xref="A2.T1.1.1.1.m1.1.1.3.cmml"><mi id="A2.T1.1.1.1.m1.1.1.3.2" xref="A2.T1.1.1.1.m1.1.1.3.2.cmml">P</mi><mo id="A2.T1.1.1.1.m1.1.1.3.1" xref="A2.T1.1.1.1.m1.1.1.3.1.cmml">‚äï</mo><mi id="A2.T1.1.1.1.m1.1.1.3.3" xref="A2.T1.1.1.1.m1.1.1.3.3.cmml">C</mi><mo id="A2.T1.1.1.1.m1.1.1.3.1a" xref="A2.T1.1.1.1.m1.1.1.3.1.cmml">‚äï</mo><mi id="A2.T1.1.1.1.m1.1.1.3.4" xref="A2.T1.1.1.1.m1.1.1.3.4.cmml">S</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.1.1.1.m1.1b"><apply id="A2.T1.1.1.1.m1.1.1.cmml" xref="A2.T1.1.1.1.m1.1.1"><eq id="A2.T1.1.1.1.m1.1.1.1.cmml" xref="A2.T1.1.1.1.m1.1.1.1"></eq><ci id="A2.T1.1.1.1.m1.1.1.2.cmml" xref="A2.T1.1.1.1.m1.1.1.2">ùëã</ci><apply id="A2.T1.1.1.1.m1.1.1.3.cmml" xref="A2.T1.1.1.1.m1.1.1.3"><csymbol cd="latexml" id="A2.T1.1.1.1.m1.1.1.3.1.cmml" xref="A2.T1.1.1.1.m1.1.1.3.1">direct-sum</csymbol><ci id="A2.T1.1.1.1.m1.1.1.3.2.cmml" xref="A2.T1.1.1.1.m1.1.1.3.2">ùëÉ</ci><ci id="A2.T1.1.1.1.m1.1.1.3.3.cmml" xref="A2.T1.1.1.1.m1.1.1.3.3">ùê∂</ci><ci id="A2.T1.1.1.1.m1.1.1.3.4.cmml" xref="A2.T1.1.1.1.m1.1.1.3.4">ùëÜ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.1.1.1.m1.1c">X=P\oplus C\oplus S</annotation><annotation encoding="application/x-llamapun" id="A2.T1.1.1.1.m1.1d">italic_X = italic_P ‚äï italic_C ‚äï italic_S</annotation></semantics></math></th><td class="ltx_td ltx_align_left ltx_border_tt" id=A2.T1.2.2.2>input text sample where <math alttext="\oplus" class="ltx_Math" display="inline" id="A2.T1.2.2.2.m1.1"><semantics id="A2.T1.2.2.2.m1.1a"><mo id="A2.T1.2.2.2.m1.1.1" xref="A2.T1.2.2.2.m1.1.1.cmml">‚äï</mo><annotation-xml encoding="MathML-Content" id="A2.T1.2.2.2.m1.1b"><csymbol cd="latexml" id="A2.T1.2.2.2.m1.1.1.cmml" xref="A2.T1.2.2.2.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.2.2.2.m1.1c">\oplus</annotation><annotation encoding="application/x-llamapun" id="A2.T1.2.2.2.m1.1d">‚äï</annotation></semantics></math> means concatenation</td></tr><tr class=ltx_tr id=A2.T1.4.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.3.3.1><math alttext="P" class="ltx_Math" display="inline" id="A2.T1.3.3.1.m1.1"><semantics id="A2.T1.3.3.1.m1.1a"><mi id="A2.T1.3.3.1.m1.1.1" xref="A2.T1.3.3.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="A2.T1.3.3.1.m1.1b"><ci id="A2.T1.3.3.1.m1.1.1.cmml" xref="A2.T1.3.3.1.m1.1.1">ùëÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.3.3.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="A2.T1.3.3.1.m1.1d">italic_P</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.4.4.2>prompt of length<math alttext="t_{p}" class="ltx_Math" display="inline" id="A2.T1.4.4.2.m1.1"><semantics id="A2.T1.4.4.2.m1.1a"><msub id="A2.T1.4.4.2.m1.1.1" xref="A2.T1.4.4.2.m1.1.1.cmml"><mi id="A2.T1.4.4.2.m1.1.1.2" xref="A2.T1.4.4.2.m1.1.1.2.cmml">t</mi><mi id="A2.T1.4.4.2.m1.1.1.3" xref="A2.T1.4.4.2.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.4.4.2.m1.1b"><apply id="A2.T1.4.4.2.m1.1.1.cmml" xref="A2.T1.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.4.4.2.m1.1.1.1.cmml" xref="A2.T1.4.4.2.m1.1.1">subscript</csymbol><ci id="A2.T1.4.4.2.m1.1.1.2.cmml" xref="A2.T1.4.4.2.m1.1.1.2">ùë°</ci><ci id="A2.T1.4.4.2.m1.1.1.3.cmml" xref="A2.T1.4.4.2.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.4.4.2.m1.1c">t_{p}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.4.4.2.m1.1d">italic_t start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.6.6><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.5.5.1><math alttext="p_{i}" class="ltx_Math" display="inline" id="A2.T1.5.5.1.m1.1"><semantics id="A2.T1.5.5.1.m1.1a"><msub id="A2.T1.5.5.1.m1.1.1" xref="A2.T1.5.5.1.m1.1.1.cmml"><mi id="A2.T1.5.5.1.m1.1.1.2" xref="A2.T1.5.5.1.m1.1.1.2.cmml">p</mi><mi id="A2.T1.5.5.1.m1.1.1.3" xref="A2.T1.5.5.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.5.5.1.m1.1b"><apply id="A2.T1.5.5.1.m1.1.1.cmml" xref="A2.T1.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.5.5.1.m1.1.1.1.cmml" xref="A2.T1.5.5.1.m1.1.1">subscript</csymbol><ci id="A2.T1.5.5.1.m1.1.1.2.cmml" xref="A2.T1.5.5.1.m1.1.1.2">ùëù</ci><ci id="A2.T1.5.5.1.m1.1.1.3.cmml" xref="A2.T1.5.5.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.5.5.1.m1.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.5.5.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.6.6.2>the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.6.6.2.m1.1"><semantics id="A2.T1.6.6.2.m1.1a"><mi id="A2.T1.6.6.2.m1.1.1" xref="A2.T1.6.6.2.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.6.6.2.m1.1b"><ci id="A2.T1.6.6.2.m1.1.1.cmml" xref="A2.T1.6.6.2.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.6.6.2.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.6.6.2.m1.1d">italic_i</annotation></semantics></math>-th token of prompt (in text)</td></tr><tr class=ltx_tr id=A2.T1.8.8><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.7.7.1><math alttext="C" class="ltx_Math" display="inline" id="A2.T1.7.7.1.m1.1"><semantics id="A2.T1.7.7.1.m1.1a"><mi id="A2.T1.7.7.1.m1.1.1" xref="A2.T1.7.7.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.T1.7.7.1.m1.1b"><ci id="A2.T1.7.7.1.m1.1.1.cmml" xref="A2.T1.7.7.1.m1.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.7.7.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="A2.T1.7.7.1.m1.1d">italic_C</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.8.8.2>reasoning trace of length<math alttext="t_{c}" class="ltx_Math" display="inline" id="A2.T1.8.8.2.m1.1"><semantics id="A2.T1.8.8.2.m1.1a"><msub id="A2.T1.8.8.2.m1.1.1" xref="A2.T1.8.8.2.m1.1.1.cmml"><mi id="A2.T1.8.8.2.m1.1.1.2" xref="A2.T1.8.8.2.m1.1.1.2.cmml">t</mi><mi id="A2.T1.8.8.2.m1.1.1.3" xref="A2.T1.8.8.2.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.8.8.2.m1.1b"><apply id="A2.T1.8.8.2.m1.1.1.cmml" xref="A2.T1.8.8.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.8.8.2.m1.1.1.1.cmml" xref="A2.T1.8.8.2.m1.1.1">subscript</csymbol><ci id="A2.T1.8.8.2.m1.1.1.2.cmml" xref="A2.T1.8.8.2.m1.1.1.2">ùë°</ci><ci id="A2.T1.8.8.2.m1.1.1.3.cmml" xref="A2.T1.8.8.2.m1.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.8.8.2.m1.1c">t_{c}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.8.8.2.m1.1d">italic_t start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.10.10><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.9.9.1><math alttext="c_{i}" class="ltx_Math" display="inline" id="A2.T1.9.9.1.m1.1"><semantics id="A2.T1.9.9.1.m1.1a"><msub id="A2.T1.9.9.1.m1.1.1" xref="A2.T1.9.9.1.m1.1.1.cmml"><mi id="A2.T1.9.9.1.m1.1.1.2" xref="A2.T1.9.9.1.m1.1.1.2.cmml">c</mi><mi id="A2.T1.9.9.1.m1.1.1.3" xref="A2.T1.9.9.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.9.9.1.m1.1b"><apply id="A2.T1.9.9.1.m1.1.1.cmml" xref="A2.T1.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.9.9.1.m1.1.1.1.cmml" xref="A2.T1.9.9.1.m1.1.1">subscript</csymbol><ci id="A2.T1.9.9.1.m1.1.1.2.cmml" xref="A2.T1.9.9.1.m1.1.1.2">ùëê</ci><ci id="A2.T1.9.9.1.m1.1.1.3.cmml" xref="A2.T1.9.9.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.9.9.1.m1.1c">c_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.9.9.1.m1.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.10.10.2>the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.10.10.2.m1.1"><semantics id="A2.T1.10.10.2.m1.1a"><mi id="A2.T1.10.10.2.m1.1.1" xref="A2.T1.10.10.2.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.10.10.2.m1.1b"><ci id="A2.T1.10.10.2.m1.1.1.cmml" xref="A2.T1.10.10.2.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.10.10.2.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.10.10.2.m1.1d">italic_i</annotation></semantics></math>-th token of trace (in text)</td></tr><tr class=ltx_tr id=A2.T1.12.12><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.11.11.1><math alttext="S" class="ltx_Math" display="inline" id="A2.T1.11.11.1.m1.1"><semantics id="A2.T1.11.11.1.m1.1a"><mi id="A2.T1.11.11.1.m1.1.1" xref="A2.T1.11.11.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A2.T1.11.11.1.m1.1b"><ci id="A2.T1.11.11.1.m1.1.1.cmml" xref="A2.T1.11.11.1.m1.1.1">ùëÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.11.11.1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="A2.T1.11.11.1.m1.1d">italic_S</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.12.12.2>solution of length<math alttext="t_{s}" class="ltx_Math" display="inline" id="A2.T1.12.12.2.m1.1"><semantics id="A2.T1.12.12.2.m1.1a"><msub id="A2.T1.12.12.2.m1.1.1" xref="A2.T1.12.12.2.m1.1.1.cmml"><mi id="A2.T1.12.12.2.m1.1.1.2" xref="A2.T1.12.12.2.m1.1.1.2.cmml">t</mi><mi id="A2.T1.12.12.2.m1.1.1.3" xref="A2.T1.12.12.2.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.12.12.2.m1.1b"><apply id="A2.T1.12.12.2.m1.1.1.cmml" xref="A2.T1.12.12.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.12.12.2.m1.1.1.1.cmml" xref="A2.T1.12.12.2.m1.1.1">subscript</csymbol><ci id="A2.T1.12.12.2.m1.1.1.2.cmml" xref="A2.T1.12.12.2.m1.1.1.2">ùë°</ci><ci id="A2.T1.12.12.2.m1.1.1.3.cmml" xref="A2.T1.12.12.2.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.12.12.2.m1.1c">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.12.12.2.m1.1d">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.14.14><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.13.13.1><math alttext="s_{i}" class="ltx_Math" display="inline" id="A2.T1.13.13.1.m1.1"><semantics id="A2.T1.13.13.1.m1.1a"><msub id="A2.T1.13.13.1.m1.1.1" xref="A2.T1.13.13.1.m1.1.1.cmml"><mi id="A2.T1.13.13.1.m1.1.1.2" xref="A2.T1.13.13.1.m1.1.1.2.cmml">s</mi><mi id="A2.T1.13.13.1.m1.1.1.3" xref="A2.T1.13.13.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.13.13.1.m1.1b"><apply id="A2.T1.13.13.1.m1.1.1.cmml" xref="A2.T1.13.13.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.13.13.1.m1.1.1.1.cmml" xref="A2.T1.13.13.1.m1.1.1">subscript</csymbol><ci id="A2.T1.13.13.1.m1.1.1.2.cmml" xref="A2.T1.13.13.1.m1.1.1.2">ùë†</ci><ci id="A2.T1.13.13.1.m1.1.1.3.cmml" xref="A2.T1.13.13.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.13.13.1.m1.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.13.13.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.14.14.2>the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.14.14.2.m1.1"><semantics id="A2.T1.14.14.2.m1.1a"><mi id="A2.T1.14.14.2.m1.1.1" xref="A2.T1.14.14.2.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.14.14.2.m1.1b"><ci id="A2.T1.14.14.2.m1.1.1.cmml" xref="A2.T1.14.14.2.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.14.14.2.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.14.14.2.m1.1d">italic_i</annotation></semantics></math>-th token of solution (in text)</td></tr><tr class=ltx_tr id=A2.T1.16.16><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.15.15.1><math alttext="Z" class="ltx_Math" display="inline" id="A2.T1.15.15.1.m1.1"><semantics id="A2.T1.15.15.1.m1.1a"><mi id="A2.T1.15.15.1.m1.1.1" xref="A2.T1.15.15.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="A2.T1.15.15.1.m1.1b"><ci id="A2.T1.15.15.1.m1.1.1.cmml" xref="A2.T1.15.15.1.m1.1.1">ùëç</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.15.15.1.m1.1c">Z</annotation><annotation encoding="application/x-llamapun" id="A2.T1.15.15.1.m1.1d">italic_Z</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.16.16.2>the complete latent reasoning traces of length<math alttext="t_{z}" class="ltx_Math" display="inline" id="A2.T1.16.16.2.m1.1"><semantics id="A2.T1.16.16.2.m1.1a"><msub id="A2.T1.16.16.2.m1.1.1" xref="A2.T1.16.16.2.m1.1.1.cmml"><mi id="A2.T1.16.16.2.m1.1.1.2" xref="A2.T1.16.16.2.m1.1.1.2.cmml">t</mi><mi id="A2.T1.16.16.2.m1.1.1.3" xref="A2.T1.16.16.2.m1.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.16.16.2.m1.1b"><apply id="A2.T1.16.16.2.m1.1.1.cmml" xref="A2.T1.16.16.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.16.16.2.m1.1.1.1.cmml" xref="A2.T1.16.16.2.m1.1.1">subscript</csymbol><ci id="A2.T1.16.16.2.m1.1.1.2.cmml" xref="A2.T1.16.16.2.m1.1.1.2">ùë°</ci><ci id="A2.T1.16.16.2.m1.1.1.3.cmml" xref="A2.T1.16.16.2.m1.1.1.3">ùëß</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.16.16.2.m1.1c">t_{z}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.16.16.2.m1.1d">italic_t start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.18.18><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.17.17.1><math alttext="z_{i}" class="ltx_Math" display="inline" id="A2.T1.17.17.1.m1.1"><semantics id="A2.T1.17.17.1.m1.1a"><msub id="A2.T1.17.17.1.m1.1.1" xref="A2.T1.17.17.1.m1.1.1.cmml"><mi id="A2.T1.17.17.1.m1.1.1.2" xref="A2.T1.17.17.1.m1.1.1.2.cmml">z</mi><mi id="A2.T1.17.17.1.m1.1.1.3" xref="A2.T1.17.17.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.17.17.1.m1.1b"><apply id="A2.T1.17.17.1.m1.1.1.cmml" xref="A2.T1.17.17.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.17.17.1.m1.1.1.1.cmml" xref="A2.T1.17.17.1.m1.1.1">subscript</csymbol><ci id="A2.T1.17.17.1.m1.1.1.2.cmml" xref="A2.T1.17.17.1.m1.1.1.2">ùëß</ci><ci id="A2.T1.17.17.1.m1.1.1.3.cmml" xref="A2.T1.17.17.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.17.17.1.m1.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.17.17.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.18.18.2>the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.18.18.2.m1.1"><semantics id="A2.T1.18.18.2.m1.1a"><mi id="A2.T1.18.18.2.m1.1.1" xref="A2.T1.18.18.2.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.18.18.2.m1.1b"><ci id="A2.T1.18.18.2.m1.1.1.cmml" xref="A2.T1.18.18.2.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.18.18.2.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.18.18.2.m1.1d">italic_i</annotation></semantics></math>-th token of latent trace</td></tr><tr class=ltx_tr id=A2.T1.19.19><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.19.19.1><math alttext="r=t_{c}/t_{z}" class="ltx_Math" display="inline" id="A2.T1.19.19.1.m1.1"><semantics id="A2.T1.19.19.1.m1.1a"><mrow id="A2.T1.19.19.1.m1.1.1" xref="A2.T1.19.19.1.m1.1.1.cmml"><mi id="A2.T1.19.19.1.m1.1.1.2" xref="A2.T1.19.19.1.m1.1.1.2.cmml">r</mi><mo id="A2.T1.19.19.1.m1.1.1.1" xref="A2.T1.19.19.1.m1.1.1.1.cmml">=</mo><mrow id="A2.T1.19.19.1.m1.1.1.3" xref="A2.T1.19.19.1.m1.1.1.3.cmml"><msub id="A2.T1.19.19.1.m1.1.1.3.2" xref="A2.T1.19.19.1.m1.1.1.3.2.cmml"><mi id="A2.T1.19.19.1.m1.1.1.3.2.2" xref="A2.T1.19.19.1.m1.1.1.3.2.2.cmml">t</mi><mi id="A2.T1.19.19.1.m1.1.1.3.2.3" xref="A2.T1.19.19.1.m1.1.1.3.2.3.cmml">c</mi></msub><mo id="A2.T1.19.19.1.m1.1.1.3.1" xref="A2.T1.19.19.1.m1.1.1.3.1.cmml">/</mo><msub id="A2.T1.19.19.1.m1.1.1.3.3" xref="A2.T1.19.19.1.m1.1.1.3.3.cmml"><mi id="A2.T1.19.19.1.m1.1.1.3.3.2" xref="A2.T1.19.19.1.m1.1.1.3.3.2.cmml">t</mi><mi id="A2.T1.19.19.1.m1.1.1.3.3.3" xref="A2.T1.19.19.1.m1.1.1.3.3.3.cmml">z</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.19.19.1.m1.1b"><apply id="A2.T1.19.19.1.m1.1.1.cmml" xref="A2.T1.19.19.1.m1.1.1"><eq id="A2.T1.19.19.1.m1.1.1.1.cmml" xref="A2.T1.19.19.1.m1.1.1.1"></eq><ci id="A2.T1.19.19.1.m1.1.1.2.cmml" xref="A2.T1.19.19.1.m1.1.1.2">ùëü</ci><apply id="A2.T1.19.19.1.m1.1.1.3.cmml" xref="A2.T1.19.19.1.m1.1.1.3"><divide id="A2.T1.19.19.1.m1.1.1.3.1.cmml" xref="A2.T1.19.19.1.m1.1.1.3.1"></divide><apply id="A2.T1.19.19.1.m1.1.1.3.2.cmml" xref="A2.T1.19.19.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="A2.T1.19.19.1.m1.1.1.3.2.1.cmml" xref="A2.T1.19.19.1.m1.1.1.3.2">subscript</csymbol><ci id="A2.T1.19.19.1.m1.1.1.3.2.2.cmml" xref="A2.T1.19.19.1.m1.1.1.3.2.2">ùë°</ci><ci id="A2.T1.19.19.1.m1.1.1.3.2.3.cmml" xref="A2.T1.19.19.1.m1.1.1.3.2.3">ùëê</ci></apply><apply id="A2.T1.19.19.1.m1.1.1.3.3.cmml" xref="A2.T1.19.19.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="A2.T1.19.19.1.m1.1.1.3.3.1.cmml" xref="A2.T1.19.19.1.m1.1.1.3.3">subscript</csymbol><ci id="A2.T1.19.19.1.m1.1.1.3.3.2.cmml" xref="A2.T1.19.19.1.m1.1.1.3.3.2">ùë°</ci><ci id="A2.T1.19.19.1.m1.1.1.3.3.3.cmml" xref="A2.T1.19.19.1.m1.1.1.3.3.3">ùëß</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.19.19.1.m1.1c">r=t_{c}/t_{z}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.19.19.1.m1.1d">italic_r = italic_t start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT / italic_t start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.19.19.2>compression rate</td></tr><tr class=ltx_tr id=A2.T1.20.20><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.20.20.1><math alttext="m" class="ltx_Math" display="inline" id="A2.T1.20.20.1.m1.1"><semantics id="A2.T1.20.20.1.m1.1a"><mi id="A2.T1.20.20.1.m1.1.1" xref="A2.T1.20.20.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.T1.20.20.1.m1.1b"><ci id="A2.T1.20.20.1.m1.1.1.cmml" xref="A2.T1.20.20.1.m1.1.1">ùëö</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.20.20.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.T1.20.20.1.m1.1d">italic_m</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.20.20.2>number of trace tokens to be replaced by latent tokens during training</td></tr><tr class=ltx_tr id=A2.T1.21.21><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.21.21.1><math alttext="{\widetilde{X}}" class="ltx_Math" display="inline" id="A2.T1.21.21.1.m1.1"><semantics id="A2.T1.21.21.1.m1.1a"><mover accent="true" id="A2.T1.21.21.1.m1.1.1" xref="A2.T1.21.21.1.m1.1.1.cmml"><mi id="A2.T1.21.21.1.m1.1.1.2" xref="A2.T1.21.21.1.m1.1.1.2.cmml">X</mi><mo id="A2.T1.21.21.1.m1.1.1.1" xref="A2.T1.21.21.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="A2.T1.21.21.1.m1.1b"><apply id="A2.T1.21.21.1.m1.1.1.cmml" xref="A2.T1.21.21.1.m1.1.1"><ci id="A2.T1.21.21.1.m1.1.1.1.cmml" xref="A2.T1.21.21.1.m1.1.1.1">~</ci><ci id="A2.T1.21.21.1.m1.1.1.2.cmml" xref="A2.T1.21.21.1.m1.1.1.2">ùëã</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.21.21.1.m1.1c">{\widetilde{X}}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.21.21.1.m1.1d">over~ start_ARG italic_X end_ARG</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.21.21.2>modified input with mixed text and latent tokens</td></tr><tr class=ltx_tr id=A2.T1.22.22><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=A2.T1.22.22.1><math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="A2.T1.22.22.1.m1.1"><semantics id="A2.T1.22.22.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A2.T1.22.22.1.m1.1.1" xref="A2.T1.22.22.1.m1.1.1.cmml">‚Ñ∞</mi><annotation-xml encoding="MathML-Content" id="A2.T1.22.22.1.m1.1b"><ci id="A2.T1.22.22.1.m1.1.1.cmml" xref="A2.T1.22.22.1.m1.1.1">‚Ñ∞</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.22.22.1.m1.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.22.22.1.m1.1d">caligraphic_E</annotation></semantics></math></th><td class="ltx_td ltx_align_left ltx_border_t" id=A2.T1.22.22.2>codebook of VQ-VAE</td></tr><tr class=ltx_tr id=A2.T1.25.25><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.23.23.1><math alttext="e_{i}" class="ltx_Math" display="inline" id="A2.T1.23.23.1.m1.1"><semantics id="A2.T1.23.23.1.m1.1a"><msub id="A2.T1.23.23.1.m1.1.1" xref="A2.T1.23.23.1.m1.1.1.cmml"><mi id="A2.T1.23.23.1.m1.1.1.2" xref="A2.T1.23.23.1.m1.1.1.2.cmml">e</mi><mi id="A2.T1.23.23.1.m1.1.1.3" xref="A2.T1.23.23.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.23.23.1.m1.1b"><apply id="A2.T1.23.23.1.m1.1.1.cmml" xref="A2.T1.23.23.1.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.23.23.1.m1.1.1.1.cmml" xref="A2.T1.23.23.1.m1.1.1">subscript</csymbol><ci id="A2.T1.23.23.1.m1.1.1.2.cmml" xref="A2.T1.23.23.1.m1.1.1.2">ùëí</ci><ci id="A2.T1.23.23.1.m1.1.1.3.cmml" xref="A2.T1.23.23.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.23.23.1.m1.1c">e_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.23.23.1.m1.1d">italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.25.25.3>the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.24.24.2.m1.1"><semantics id="A2.T1.24.24.2.m1.1a"><mi id="A2.T1.24.24.2.m1.1.1" xref="A2.T1.24.24.2.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.24.24.2.m1.1b"><ci id="A2.T1.24.24.2.m1.1.1.cmml" xref="A2.T1.24.24.2.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.24.24.2.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.24.24.2.m1.1d">italic_i</annotation></semantics></math>-th vector in the codebook, which corresponds to the <math alttext="i" class="ltx_Math" display="inline" id="A2.T1.25.25.3.m2.1"><semantics id="A2.T1.25.25.3.m2.1a"><mi id="A2.T1.25.25.3.m2.1.1" xref="A2.T1.25.25.3.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.T1.25.25.3.m2.1b"><ci id="A2.T1.25.25.3.m2.1.1.cmml" xref="A2.T1.25.25.3.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.25.25.3.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.T1.25.25.3.m2.1d">italic_i</annotation></semantics></math>-th latent token</td></tr><tr class=ltx_tr id=A2.T1.27.27><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.26.26.1><math alttext="d" class="ltx_Math" display="inline" id="A2.T1.26.26.1.m1.1"><semantics id="A2.T1.26.26.1.m1.1a"><mi id="A2.T1.26.26.1.m1.1.1" xref="A2.T1.26.26.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A2.T1.26.26.1.m1.1b"><ci id="A2.T1.26.26.1.m1.1.1.cmml" xref="A2.T1.26.26.1.m1.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.26.26.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="A2.T1.26.26.1.m1.1d">italic_d</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.27.27.2>dimension of <math alttext="e_{i}" class="ltx_Math" display="inline" id="A2.T1.27.27.2.m1.1"><semantics id="A2.T1.27.27.2.m1.1a"><msub id="A2.T1.27.27.2.m1.1.1" xref="A2.T1.27.27.2.m1.1.1.cmml"><mi id="A2.T1.27.27.2.m1.1.1.2" xref="A2.T1.27.27.2.m1.1.1.2.cmml">e</mi><mi id="A2.T1.27.27.2.m1.1.1.3" xref="A2.T1.27.27.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.T1.27.27.2.m1.1b"><apply id="A2.T1.27.27.2.m1.1.1.cmml" xref="A2.T1.27.27.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.27.27.2.m1.1.1.1.cmml" xref="A2.T1.27.27.2.m1.1.1">subscript</csymbol><ci id="A2.T1.27.27.2.m1.1.1.2.cmml" xref="A2.T1.27.27.2.m1.1.1.2">ùëí</ci><ci id="A2.T1.27.27.2.m1.1.1.3.cmml" xref="A2.T1.27.27.2.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.27.27.2.m1.1c">e_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.27.27.2.m1.1d">italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>s</td></tr><tr class=ltx_tr id=A2.T1.28.28><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.28.28.1><math alttext="{\mathcal{V}}" class="ltx_Math" display="inline" id="A2.T1.28.28.1.m1.1"><semantics id="A2.T1.28.28.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A2.T1.28.28.1.m1.1.1" xref="A2.T1.28.28.1.m1.1.1.cmml">ùí±</mi><annotation-xml encoding="MathML-Content" id="A2.T1.28.28.1.m1.1b"><ci id="A2.T1.28.28.1.m1.1.1.cmml" xref="A2.T1.28.28.1.m1.1.1">ùí±</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.28.28.1.m1.1c">{\mathcal{V}}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.28.28.1.m1.1d">caligraphic_V</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.28.28.2>vocabulary of text tokens</td></tr><tr class=ltx_tr id=A2.T1.29.29><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.29.29.1><math alttext="L" class="ltx_Math" display="inline" id="A2.T1.29.29.1.m1.1"><semantics id="A2.T1.29.29.1.m1.1a"><mi id="A2.T1.29.29.1.m1.1.1" xref="A2.T1.29.29.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A2.T1.29.29.1.m1.1b"><ci id="A2.T1.29.29.1.m1.1.1.cmml" xref="A2.T1.29.29.1.m1.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.29.29.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A2.T1.29.29.1.m1.1d">italic_L</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.29.29.2>chunk size</td></tr><tr class=ltx_tr id=A2.T1.32.32><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.30.30.1><math alttext="{f_{\text{enc}}}(\cdot)" class="ltx_Math" display="inline" id="A2.T1.30.30.1.m1.1"><semantics id="A2.T1.30.30.1.m1.1a"><mrow id="A2.T1.30.30.1.m1.1.2" xref="A2.T1.30.30.1.m1.1.2.cmml"><msub id="A2.T1.30.30.1.m1.1.2.2" xref="A2.T1.30.30.1.m1.1.2.2.cmml"><mi id="A2.T1.30.30.1.m1.1.2.2.2" xref="A2.T1.30.30.1.m1.1.2.2.2.cmml">f</mi><mtext id="A2.T1.30.30.1.m1.1.2.2.3" xref="A2.T1.30.30.1.m1.1.2.2.3a.cmml">enc</mtext></msub><mo id="A2.T1.30.30.1.m1.1.2.1" xref="A2.T1.30.30.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="A2.T1.30.30.1.m1.1.2.3.2" xref="A2.T1.30.30.1.m1.1.2.cmml"><mo id="A2.T1.30.30.1.m1.1.2.3.2.1" stretchy="false" xref="A2.T1.30.30.1.m1.1.2.cmml">(</mo><mo id="A2.T1.30.30.1.m1.1.1" lspace="0em" rspace="0em" xref="A2.T1.30.30.1.m1.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.30.30.1.m1.1.2.3.2.2" stretchy="false" xref="A2.T1.30.30.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.30.30.1.m1.1b"><apply id="A2.T1.30.30.1.m1.1.2.cmml" xref="A2.T1.30.30.1.m1.1.2"><times id="A2.T1.30.30.1.m1.1.2.1.cmml" xref="A2.T1.30.30.1.m1.1.2.1"></times><apply id="A2.T1.30.30.1.m1.1.2.2.cmml" xref="A2.T1.30.30.1.m1.1.2.2"><csymbol cd="ambiguous" id="A2.T1.30.30.1.m1.1.2.2.1.cmml" xref="A2.T1.30.30.1.m1.1.2.2">subscript</csymbol><ci id="A2.T1.30.30.1.m1.1.2.2.2.cmml" xref="A2.T1.30.30.1.m1.1.2.2.2">ùëì</ci><ci id="A2.T1.30.30.1.m1.1.2.2.3a.cmml" xref="A2.T1.30.30.1.m1.1.2.2.3"><mtext id="A2.T1.30.30.1.m1.1.2.2.3.cmml" mathsize="70%" xref="A2.T1.30.30.1.m1.1.2.2.3">enc</mtext></ci></apply><ci id="A2.T1.30.30.1.m1.1.1.cmml" xref="A2.T1.30.30.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.30.30.1.m1.1c">{f_{\text{enc}}}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.30.30.1.m1.1d">italic_f start_POSTSUBSCRIPT enc end_POSTSUBSCRIPT ( ‚ãÖ )</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.32.32.3>encodes a chunk of <math alttext="L" class="ltx_Math" display="inline" id="A2.T1.31.31.2.m1.1"><semantics id="A2.T1.31.31.2.m1.1a"><mi id="A2.T1.31.31.2.m1.1.1" xref="A2.T1.31.31.2.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A2.T1.31.31.2.m1.1b"><ci id="A2.T1.31.31.2.m1.1.1.cmml" xref="A2.T1.31.31.2.m1.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.31.31.2.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A2.T1.31.31.2.m1.1d">italic_L</annotation></semantics></math> text tokens to <math alttext="\frac{L}{r}" class="ltx_Math" display="inline" id="A2.T1.32.32.3.m2.1"><semantics id="A2.T1.32.32.3.m2.1a"><mfrac id="A2.T1.32.32.3.m2.1.1" xref="A2.T1.32.32.3.m2.1.1.cmml"><mi id="A2.T1.32.32.3.m2.1.1.2" xref="A2.T1.32.32.3.m2.1.1.2.cmml">L</mi><mi id="A2.T1.32.32.3.m2.1.1.3" xref="A2.T1.32.32.3.m2.1.1.3.cmml">r</mi></mfrac><annotation-xml encoding="MathML-Content" id="A2.T1.32.32.3.m2.1b"><apply id="A2.T1.32.32.3.m2.1.1.cmml" xref="A2.T1.32.32.3.m2.1.1"><divide id="A2.T1.32.32.3.m2.1.1.1.cmml" xref="A2.T1.32.32.3.m2.1.1"></divide><ci id="A2.T1.32.32.3.m2.1.1.2.cmml" xref="A2.T1.32.32.3.m2.1.1.2">ùêø</ci><ci id="A2.T1.32.32.3.m2.1.1.3.cmml" xref="A2.T1.32.32.3.m2.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.32.32.3.m2.1c">\frac{L}{r}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.32.32.3.m2.1d">divide start_ARG italic_L end_ARG start_ARG italic_r end_ARG</annotation></semantics></math> embedding vectors</td></tr><tr class=ltx_tr id=A2.T1.35.35><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.33.33.1><math alttext="\bar{X}=\bar{x}_{1},\ldots,\bar{x}_{\frac{L}{r}}" class="ltx_Math" display="inline" id="A2.T1.33.33.1.m1.3"><semantics id="A2.T1.33.33.1.m1.3a"><mrow id="A2.T1.33.33.1.m1.3.3" xref="A2.T1.33.33.1.m1.3.3.cmml"><mover accent="true" id="A2.T1.33.33.1.m1.3.3.4" xref="A2.T1.33.33.1.m1.3.3.4.cmml"><mi id="A2.T1.33.33.1.m1.3.3.4.2" xref="A2.T1.33.33.1.m1.3.3.4.2.cmml">X</mi><mo id="A2.T1.33.33.1.m1.3.3.4.1" xref="A2.T1.33.33.1.m1.3.3.4.1.cmml">¬Ø</mo></mover><mo id="A2.T1.33.33.1.m1.3.3.3" xref="A2.T1.33.33.1.m1.3.3.3.cmml">=</mo><mrow id="A2.T1.33.33.1.m1.3.3.2.2" xref="A2.T1.33.33.1.m1.3.3.2.3.cmml"><msub id="A2.T1.33.33.1.m1.2.2.1.1.1" xref="A2.T1.33.33.1.m1.2.2.1.1.1.cmml"><mover accent="true" id="A2.T1.33.33.1.m1.2.2.1.1.1.2" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2.cmml"><mi id="A2.T1.33.33.1.m1.2.2.1.1.1.2.2" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2.2.cmml">x</mi><mo id="A2.T1.33.33.1.m1.2.2.1.1.1.2.1" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2.1.cmml">¬Ø</mo></mover><mn id="A2.T1.33.33.1.m1.2.2.1.1.1.3" xref="A2.T1.33.33.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="A2.T1.33.33.1.m1.3.3.2.2.3" xref="A2.T1.33.33.1.m1.3.3.2.3.cmml">,</mo><mi id="A2.T1.33.33.1.m1.1.1" mathvariant="normal" xref="A2.T1.33.33.1.m1.1.1.cmml">‚Ä¶</mi><mo id="A2.T1.33.33.1.m1.3.3.2.2.4" xref="A2.T1.33.33.1.m1.3.3.2.3.cmml">,</mo><msub id="A2.T1.33.33.1.m1.3.3.2.2.2" xref="A2.T1.33.33.1.m1.3.3.2.2.2.cmml"><mover accent="true" id="A2.T1.33.33.1.m1.3.3.2.2.2.2" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2.cmml"><mi id="A2.T1.33.33.1.m1.3.3.2.2.2.2.2" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2.2.cmml">x</mi><mo id="A2.T1.33.33.1.m1.3.3.2.2.2.2.1" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2.1.cmml">¬Ø</mo></mover><mfrac id="A2.T1.33.33.1.m1.3.3.2.2.2.3" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3.cmml"><mi id="A2.T1.33.33.1.m1.3.3.2.2.2.3.2" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3.2.cmml">L</mi><mi id="A2.T1.33.33.1.m1.3.3.2.2.2.3.3" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3.3.cmml">r</mi></mfrac></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.33.33.1.m1.3b"><apply id="A2.T1.33.33.1.m1.3.3.cmml" xref="A2.T1.33.33.1.m1.3.3"><eq id="A2.T1.33.33.1.m1.3.3.3.cmml" xref="A2.T1.33.33.1.m1.3.3.3"></eq><apply id="A2.T1.33.33.1.m1.3.3.4.cmml" xref="A2.T1.33.33.1.m1.3.3.4"><ci id="A2.T1.33.33.1.m1.3.3.4.1.cmml" xref="A2.T1.33.33.1.m1.3.3.4.1">¬Ø</ci><ci id="A2.T1.33.33.1.m1.3.3.4.2.cmml" xref="A2.T1.33.33.1.m1.3.3.4.2">ùëã</ci></apply><list id="A2.T1.33.33.1.m1.3.3.2.3.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2"><apply id="A2.T1.33.33.1.m1.2.2.1.1.1.cmml" xref="A2.T1.33.33.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="A2.T1.33.33.1.m1.2.2.1.1.1.1.cmml" xref="A2.T1.33.33.1.m1.2.2.1.1.1">subscript</csymbol><apply id="A2.T1.33.33.1.m1.2.2.1.1.1.2.cmml" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2"><ci id="A2.T1.33.33.1.m1.2.2.1.1.1.2.1.cmml" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2.1">¬Ø</ci><ci id="A2.T1.33.33.1.m1.2.2.1.1.1.2.2.cmml" xref="A2.T1.33.33.1.m1.2.2.1.1.1.2.2">ùë•</ci></apply><cn id="A2.T1.33.33.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="A2.T1.33.33.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="A2.T1.33.33.1.m1.1.1.cmml" xref="A2.T1.33.33.1.m1.1.1">‚Ä¶</ci><apply id="A2.T1.33.33.1.m1.3.3.2.2.2.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="A2.T1.33.33.1.m1.3.3.2.2.2.1.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2">subscript</csymbol><apply id="A2.T1.33.33.1.m1.3.3.2.2.2.2.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2"><ci id="A2.T1.33.33.1.m1.3.3.2.2.2.2.1.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2.1">¬Ø</ci><ci id="A2.T1.33.33.1.m1.3.3.2.2.2.2.2.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.2.2">ùë•</ci></apply><apply id="A2.T1.33.33.1.m1.3.3.2.2.2.3.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3"><divide id="A2.T1.33.33.1.m1.3.3.2.2.2.3.1.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3"></divide><ci id="A2.T1.33.33.1.m1.3.3.2.2.2.3.2.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3.2">ùêø</ci><ci id="A2.T1.33.33.1.m1.3.3.2.2.2.3.3.cmml" xref="A2.T1.33.33.1.m1.3.3.2.2.2.3.3">ùëü</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.33.33.1.m1.3c">\bar{X}=\bar{x}_{1},\ldots,\bar{x}_{\frac{L}{r}}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.33.33.1.m1.3d">over¬Ø start_ARG italic_X end_ARG = over¬Ø start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ‚Ä¶ , over¬Ø start_ARG italic_x end_ARG start_POSTSUBSCRIPT divide start_ARG italic_L end_ARG start_ARG italic_r end_ARG end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.35.35.3>embedding vectors of <math alttext="X" class="ltx_Math" display="inline" id="A2.T1.34.34.2.m1.1"><semantics id="A2.T1.34.34.2.m1.1a"><mi id="A2.T1.34.34.2.m1.1.1" xref="A2.T1.34.34.2.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="A2.T1.34.34.2.m1.1b"><ci id="A2.T1.34.34.2.m1.1.1.cmml" xref="A2.T1.34.34.2.m1.1.1">ùëã</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.34.34.2.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="A2.T1.34.34.2.m1.1d">italic_X</annotation></semantics></math> outputted by<math alttext="{f_{\text{enc}}}(\cdot)" class="ltx_Math" display="inline" id="A2.T1.35.35.3.m2.1"><semantics id="A2.T1.35.35.3.m2.1a"><mrow id="A2.T1.35.35.3.m2.1.2" xref="A2.T1.35.35.3.m2.1.2.cmml"><msub id="A2.T1.35.35.3.m2.1.2.2" xref="A2.T1.35.35.3.m2.1.2.2.cmml"><mi id="A2.T1.35.35.3.m2.1.2.2.2" xref="A2.T1.35.35.3.m2.1.2.2.2.cmml">f</mi><mtext id="A2.T1.35.35.3.m2.1.2.2.3" xref="A2.T1.35.35.3.m2.1.2.2.3a.cmml">enc</mtext></msub><mo id="A2.T1.35.35.3.m2.1.2.1" xref="A2.T1.35.35.3.m2.1.2.1.cmml">‚Å¢</mo><mrow id="A2.T1.35.35.3.m2.1.2.3.2" xref="A2.T1.35.35.3.m2.1.2.cmml"><mo id="A2.T1.35.35.3.m2.1.2.3.2.1" stretchy="false" xref="A2.T1.35.35.3.m2.1.2.cmml">(</mo><mo id="A2.T1.35.35.3.m2.1.1" lspace="0em" rspace="0em" xref="A2.T1.35.35.3.m2.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.35.35.3.m2.1.2.3.2.2" stretchy="false" xref="A2.T1.35.35.3.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.35.35.3.m2.1b"><apply id="A2.T1.35.35.3.m2.1.2.cmml" xref="A2.T1.35.35.3.m2.1.2"><times id="A2.T1.35.35.3.m2.1.2.1.cmml" xref="A2.T1.35.35.3.m2.1.2.1"></times><apply id="A2.T1.35.35.3.m2.1.2.2.cmml" xref="A2.T1.35.35.3.m2.1.2.2"><csymbol cd="ambiguous" id="A2.T1.35.35.3.m2.1.2.2.1.cmml" xref="A2.T1.35.35.3.m2.1.2.2">subscript</csymbol><ci id="A2.T1.35.35.3.m2.1.2.2.2.cmml" xref="A2.T1.35.35.3.m2.1.2.2.2">ùëì</ci><ci id="A2.T1.35.35.3.m2.1.2.2.3a.cmml" xref="A2.T1.35.35.3.m2.1.2.2.3"><mtext id="A2.T1.35.35.3.m2.1.2.2.3.cmml" mathsize="70%" xref="A2.T1.35.35.3.m2.1.2.2.3">enc</mtext></ci></apply><ci id="A2.T1.35.35.3.m2.1.1.cmml" xref="A2.T1.35.35.3.m2.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.35.35.3.m2.1c">{f_{\text{enc}}}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.35.35.3.m2.1d">italic_f start_POSTSUBSCRIPT enc end_POSTSUBSCRIPT ( ‚ãÖ )</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.38.38><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.36.36.1><math alttext="q(\cdot)" class="ltx_Math" display="inline" id="A2.T1.36.36.1.m1.1"><semantics id="A2.T1.36.36.1.m1.1a"><mrow id="A2.T1.36.36.1.m1.1.2" xref="A2.T1.36.36.1.m1.1.2.cmml"><mi id="A2.T1.36.36.1.m1.1.2.2" xref="A2.T1.36.36.1.m1.1.2.2.cmml">q</mi><mo id="A2.T1.36.36.1.m1.1.2.1" xref="A2.T1.36.36.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="A2.T1.36.36.1.m1.1.2.3.2" xref="A2.T1.36.36.1.m1.1.2.cmml"><mo id="A2.T1.36.36.1.m1.1.2.3.2.1" stretchy="false" xref="A2.T1.36.36.1.m1.1.2.cmml">(</mo><mo id="A2.T1.36.36.1.m1.1.1" lspace="0em" rspace="0em" xref="A2.T1.36.36.1.m1.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.36.36.1.m1.1.2.3.2.2" stretchy="false" xref="A2.T1.36.36.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.36.36.1.m1.1b"><apply id="A2.T1.36.36.1.m1.1.2.cmml" xref="A2.T1.36.36.1.m1.1.2"><times id="A2.T1.36.36.1.m1.1.2.1.cmml" xref="A2.T1.36.36.1.m1.1.2.1"></times><ci id="A2.T1.36.36.1.m1.1.2.2.cmml" xref="A2.T1.36.36.1.m1.1.2.2">ùëû</ci><ci id="A2.T1.36.36.1.m1.1.1.cmml" xref="A2.T1.36.36.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.36.36.1.m1.1c">q(\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.36.36.1.m1.1d">italic_q ( ‚ãÖ )</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.38.38.3>quantization operator that replaces, e.g., <math alttext="\bar{x}_{1}" class="ltx_Math" display="inline" id="A2.T1.37.37.2.m1.1"><semantics id="A2.T1.37.37.2.m1.1a"><msub id="A2.T1.37.37.2.m1.1.1" xref="A2.T1.37.37.2.m1.1.1.cmml"><mover accent="true" id="A2.T1.37.37.2.m1.1.1.2" xref="A2.T1.37.37.2.m1.1.1.2.cmml"><mi id="A2.T1.37.37.2.m1.1.1.2.2" xref="A2.T1.37.37.2.m1.1.1.2.2.cmml">x</mi><mo id="A2.T1.37.37.2.m1.1.1.2.1" xref="A2.T1.37.37.2.m1.1.1.2.1.cmml">¬Ø</mo></mover><mn id="A2.T1.37.37.2.m1.1.1.3" xref="A2.T1.37.37.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.T1.37.37.2.m1.1b"><apply id="A2.T1.37.37.2.m1.1.1.cmml" xref="A2.T1.37.37.2.m1.1.1"><csymbol cd="ambiguous" id="A2.T1.37.37.2.m1.1.1.1.cmml" xref="A2.T1.37.37.2.m1.1.1">subscript</csymbol><apply id="A2.T1.37.37.2.m1.1.1.2.cmml" xref="A2.T1.37.37.2.m1.1.1.2"><ci id="A2.T1.37.37.2.m1.1.1.2.1.cmml" xref="A2.T1.37.37.2.m1.1.1.2.1">¬Ø</ci><ci id="A2.T1.37.37.2.m1.1.1.2.2.cmml" xref="A2.T1.37.37.2.m1.1.1.2.2">ùë•</ci></apply><cn id="A2.T1.37.37.2.m1.1.1.3.cmml" type="integer" xref="A2.T1.37.37.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.37.37.2.m1.1c">\bar{x}_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.37.37.2.m1.1d">over¬Ø start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> by its nearest neighbor in <math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="A2.T1.38.38.3.m2.1"><semantics id="A2.T1.38.38.3.m2.1a"><mi class="ltx_font_mathcaligraphic" id="A2.T1.38.38.3.m2.1.1" xref="A2.T1.38.38.3.m2.1.1.cmml">‚Ñ∞</mi><annotation-xml encoding="MathML-Content" id="A2.T1.38.38.3.m2.1b"><ci id="A2.T1.38.38.3.m2.1.1.cmml" xref="A2.T1.38.38.3.m2.1.1">‚Ñ∞</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.38.38.3.m2.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.38.38.3.m2.1d">caligraphic_E</annotation></semantics></math>:</td></tr><tr class=ltx_tr id=A2.T1.39.39><th class="ltx_td ltx_th ltx_th_row" id=A2.T1.39.39.2></th><td class="ltx_td ltx_align_left" id=A2.T1.39.39.1>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†<math alttext="g(\bar{x}_{1})=\operatorname*{argmin}_{e_{i}\in{\mathcal{E}}}\left\|e_{i}-\bar%
{x}_{1}\right\|^{2}" class="ltx_Math" display="inline" id="A2.T1.39.39.1.m1.2"><semantics id="A2.T1.39.39.1.m1.2a"><mrow id="A2.T1.39.39.1.m1.2.2" xref="A2.T1.39.39.1.m1.2.2.cmml"><mrow id="A2.T1.39.39.1.m1.1.1.1" xref="A2.T1.39.39.1.m1.1.1.1.cmml"><mi id="A2.T1.39.39.1.m1.1.1.1.3" xref="A2.T1.39.39.1.m1.1.1.1.3.cmml">g</mi><mo id="A2.T1.39.39.1.m1.1.1.1.2" xref="A2.T1.39.39.1.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="A2.T1.39.39.1.m1.1.1.1.1.1" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.cmml"><mo id="A2.T1.39.39.1.m1.1.1.1.1.1.2" stretchy="false" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="A2.T1.39.39.1.m1.1.1.1.1.1.1" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.cmml"><mover accent="true" id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.cmml"><mi id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.2" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mo id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.1" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.1.cmml">¬Ø</mo></mover><mn id="A2.T1.39.39.1.m1.1.1.1.1.1.1.3" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="A2.T1.39.39.1.m1.1.1.1.1.1.3" stretchy="false" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A2.T1.39.39.1.m1.2.2.3" rspace="0.1389em" xref="A2.T1.39.39.1.m1.2.2.3.cmml">=</mo><mrow id="A2.T1.39.39.1.m1.2.2.2" xref="A2.T1.39.39.1.m1.2.2.2.cmml"><msub id="A2.T1.39.39.1.m1.2.2.2.2" xref="A2.T1.39.39.1.m1.2.2.2.2.cmml"><mo id="A2.T1.39.39.1.m1.2.2.2.2.2" lspace="0.1389em" rspace="0em" xref="A2.T1.39.39.1.m1.2.2.2.2.2.cmml">argmin</mo><mrow id="A2.T1.39.39.1.m1.2.2.2.2.3" xref="A2.T1.39.39.1.m1.2.2.2.2.3.cmml"><msub id="A2.T1.39.39.1.m1.2.2.2.2.3.2" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2.cmml"><mi id="A2.T1.39.39.1.m1.2.2.2.2.3.2.2" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2.2.cmml">e</mi><mi id="A2.T1.39.39.1.m1.2.2.2.2.3.2.3" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2.3.cmml">i</mi></msub><mo id="A2.T1.39.39.1.m1.2.2.2.2.3.1" xref="A2.T1.39.39.1.m1.2.2.2.2.3.1.cmml">‚àà</mo><mi class="ltx_font_mathcaligraphic" id="A2.T1.39.39.1.m1.2.2.2.2.3.3" xref="A2.T1.39.39.1.m1.2.2.2.2.3.3.cmml">‚Ñ∞</mi></mrow></msub><msup id="A2.T1.39.39.1.m1.2.2.2.1" xref="A2.T1.39.39.1.m1.2.2.2.1.cmml"><mrow id="A2.T1.39.39.1.m1.2.2.2.1.1.1" xref="A2.T1.39.39.1.m1.2.2.2.1.1.2.cmml"><mo id="A2.T1.39.39.1.m1.2.2.2.1.1.1.2" xref="A2.T1.39.39.1.m1.2.2.2.1.1.2.1.cmml">‚Äñ</mo><mrow id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.cmml"><msub id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.cmml"><mi id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.2" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.2.cmml">e</mi><mi id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.3" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.3.cmml">i</mi></msub><mo id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.1" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.1.cmml">‚àí</mo><msub id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.cmml"><mover accent="true" id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.cmml"><mi id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.2" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.2.cmml">x</mi><mo id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.1" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.1.cmml">¬Ø</mo></mover><mn id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.3" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="A2.T1.39.39.1.m1.2.2.2.1.1.1.3" xref="A2.T1.39.39.1.m1.2.2.2.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="A2.T1.39.39.1.m1.2.2.2.1.3" xref="A2.T1.39.39.1.m1.2.2.2.1.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.39.39.1.m1.2b"><apply id="A2.T1.39.39.1.m1.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2"><eq id="A2.T1.39.39.1.m1.2.2.3.cmml" xref="A2.T1.39.39.1.m1.2.2.3"></eq><apply id="A2.T1.39.39.1.m1.1.1.1.cmml" xref="A2.T1.39.39.1.m1.1.1.1"><times id="A2.T1.39.39.1.m1.1.1.1.2.cmml" xref="A2.T1.39.39.1.m1.1.1.1.2"></times><ci id="A2.T1.39.39.1.m1.1.1.1.3.cmml" xref="A2.T1.39.39.1.m1.1.1.1.3">ùëî</ci><apply id="A2.T1.39.39.1.m1.1.1.1.1.1.1.cmml" xref="A2.T1.39.39.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.1.1.1.1.1.1.1.cmml" xref="A2.T1.39.39.1.m1.1.1.1.1.1">subscript</csymbol><apply id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.cmml" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2"><ci id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.1.cmml" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.1">¬Ø</ci><ci id="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.2.cmml" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.2.2">ùë•</ci></apply><cn id="A2.T1.39.39.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="A2.T1.39.39.1.m1.1.1.1.1.1.1.3">1</cn></apply></apply><apply id="A2.T1.39.39.1.m1.2.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2"><apply id="A2.T1.39.39.1.m1.2.2.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.2.2.2.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2">subscript</csymbol><ci id="A2.T1.39.39.1.m1.2.2.2.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.2">argmin</ci><apply id="A2.T1.39.39.1.m1.2.2.2.2.3.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3"><in id="A2.T1.39.39.1.m1.2.2.2.2.3.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.1"></in><apply id="A2.T1.39.39.1.m1.2.2.2.2.3.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.2.2.2.2.3.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2">subscript</csymbol><ci id="A2.T1.39.39.1.m1.2.2.2.2.3.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2.2">ùëí</ci><ci id="A2.T1.39.39.1.m1.2.2.2.2.3.2.3.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.2.3">ùëñ</ci></apply><ci id="A2.T1.39.39.1.m1.2.2.2.2.3.3.cmml" xref="A2.T1.39.39.1.m1.2.2.2.2.3.3">‚Ñ∞</ci></apply></apply><apply id="A2.T1.39.39.1.m1.2.2.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.2.2.2.1.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1">superscript</csymbol><apply id="A2.T1.39.39.1.m1.2.2.2.1.1.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="A2.T1.39.39.1.m1.2.2.2.1.1.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.2">norm</csymbol><apply id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1"><minus id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.1"></minus><apply id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.2">ùëí</ci><ci id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.3.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.2.3">ùëñ</ci></apply><apply id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2"><ci id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.1.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.1">¬Ø</ci><ci id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.2.cmml" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.2.2">ùë•</ci></apply><cn id="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.3.cmml" type="integer" xref="A2.T1.39.39.1.m1.2.2.2.1.1.1.1.3.3">1</cn></apply></apply></apply><cn id="A2.T1.39.39.1.m1.2.2.2.1.3.cmml" type="integer" xref="A2.T1.39.39.1.m1.2.2.2.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.39.39.1.m1.2c">g(\bar{x}_{1})=\operatorname*{argmin}_{e_{i}\in{\mathcal{E}}}\left\|e_{i}-\bar%
{x}_{1}\right\|^{2}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.39.39.1.m1.2d">italic_g ( over¬Ø start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = roman_argmin start_POSTSUBSCRIPT italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà caligraphic_E end_POSTSUBSCRIPT ‚à• italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over¬Ø start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ‚à• start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=A2.T1.41.41><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.40.40.1><math alttext="g(\cdot)" class="ltx_Math" display="inline" id="A2.T1.40.40.1.m1.1"><semantics id="A2.T1.40.40.1.m1.1a"><mrow id="A2.T1.40.40.1.m1.1.2" xref="A2.T1.40.40.1.m1.1.2.cmml"><mi id="A2.T1.40.40.1.m1.1.2.2" xref="A2.T1.40.40.1.m1.1.2.2.cmml">g</mi><mo id="A2.T1.40.40.1.m1.1.2.1" xref="A2.T1.40.40.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="A2.T1.40.40.1.m1.1.2.3.2" xref="A2.T1.40.40.1.m1.1.2.cmml"><mo id="A2.T1.40.40.1.m1.1.2.3.2.1" stretchy="false" xref="A2.T1.40.40.1.m1.1.2.cmml">(</mo><mo id="A2.T1.40.40.1.m1.1.1" lspace="0em" rspace="0em" xref="A2.T1.40.40.1.m1.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.40.40.1.m1.1.2.3.2.2" stretchy="false" xref="A2.T1.40.40.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.40.40.1.m1.1b"><apply id="A2.T1.40.40.1.m1.1.2.cmml" xref="A2.T1.40.40.1.m1.1.2"><times id="A2.T1.40.40.1.m1.1.2.1.cmml" xref="A2.T1.40.40.1.m1.1.2.1"></times><ci id="A2.T1.40.40.1.m1.1.2.2.cmml" xref="A2.T1.40.40.1.m1.1.2.2">ùëî</ci><ci id="A2.T1.40.40.1.m1.1.1.cmml" xref="A2.T1.40.40.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.40.40.1.m1.1c">g(\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.40.40.1.m1.1d">italic_g ( ‚ãÖ )</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.41.41.2>maps prompt to a <math alttext="d" class="ltx_Math" display="inline" id="A2.T1.41.41.2.m1.1"><semantics id="A2.T1.41.41.2.m1.1a"><mi id="A2.T1.41.41.2.m1.1.1" xref="A2.T1.41.41.2.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A2.T1.41.41.2.m1.1b"><ci id="A2.T1.41.41.2.m1.1.1.cmml" xref="A2.T1.41.41.2.m1.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.41.41.2.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="A2.T1.41.41.2.m1.1d">italic_d</annotation></semantics></math>-dimensional embedding vector</td></tr><tr class=ltx_tr id=A2.T1.44.44><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=A2.T1.42.42.1><math alttext="{f_{\text{dec}}}(\cdot,\cdot)" class="ltx_Math" display="inline" id="A2.T1.42.42.1.m1.2"><semantics id="A2.T1.42.42.1.m1.2a"><mrow id="A2.T1.42.42.1.m1.2.3" xref="A2.T1.42.42.1.m1.2.3.cmml"><msub id="A2.T1.42.42.1.m1.2.3.2" xref="A2.T1.42.42.1.m1.2.3.2.cmml"><mi id="A2.T1.42.42.1.m1.2.3.2.2" xref="A2.T1.42.42.1.m1.2.3.2.2.cmml">f</mi><mtext id="A2.T1.42.42.1.m1.2.3.2.3" xref="A2.T1.42.42.1.m1.2.3.2.3a.cmml">dec</mtext></msub><mo id="A2.T1.42.42.1.m1.2.3.1" xref="A2.T1.42.42.1.m1.2.3.1.cmml">‚Å¢</mo><mrow id="A2.T1.42.42.1.m1.2.3.3.2" xref="A2.T1.42.42.1.m1.2.3.3.1.cmml"><mo id="A2.T1.42.42.1.m1.2.3.3.2.1" stretchy="false" xref="A2.T1.42.42.1.m1.2.3.3.1.cmml">(</mo><mo id="A2.T1.42.42.1.m1.1.1" lspace="0em" rspace="0em" xref="A2.T1.42.42.1.m1.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.42.42.1.m1.2.3.3.2.2" rspace="0em" xref="A2.T1.42.42.1.m1.2.3.3.1.cmml">,</mo><mo id="A2.T1.42.42.1.m1.2.2" lspace="0em" rspace="0em" xref="A2.T1.42.42.1.m1.2.2.cmml">‚ãÖ</mo><mo id="A2.T1.42.42.1.m1.2.3.3.2.3" stretchy="false" xref="A2.T1.42.42.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.42.42.1.m1.2b"><apply id="A2.T1.42.42.1.m1.2.3.cmml" xref="A2.T1.42.42.1.m1.2.3"><times id="A2.T1.42.42.1.m1.2.3.1.cmml" xref="A2.T1.42.42.1.m1.2.3.1"></times><apply id="A2.T1.42.42.1.m1.2.3.2.cmml" xref="A2.T1.42.42.1.m1.2.3.2"><csymbol cd="ambiguous" id="A2.T1.42.42.1.m1.2.3.2.1.cmml" xref="A2.T1.42.42.1.m1.2.3.2">subscript</csymbol><ci id="A2.T1.42.42.1.m1.2.3.2.2.cmml" xref="A2.T1.42.42.1.m1.2.3.2.2">ùëì</ci><ci id="A2.T1.42.42.1.m1.2.3.2.3a.cmml" xref="A2.T1.42.42.1.m1.2.3.2.3"><mtext id="A2.T1.42.42.1.m1.2.3.2.3.cmml" mathsize="70%" xref="A2.T1.42.42.1.m1.2.3.2.3">dec</mtext></ci></apply><interval closure="open" id="A2.T1.42.42.1.m1.2.3.3.1.cmml" xref="A2.T1.42.42.1.m1.2.3.3.2"><ci id="A2.T1.42.42.1.m1.1.1.cmml" xref="A2.T1.42.42.1.m1.1.1">‚ãÖ</ci><ci id="A2.T1.42.42.1.m1.2.2.cmml" xref="A2.T1.42.42.1.m1.2.2">‚ãÖ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.42.42.1.m1.2c">{f_{\text{dec}}}(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.42.42.1.m1.2d">italic_f start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT ( ‚ãÖ , ‚ãÖ )</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=A2.T1.44.44.3>decodes <math alttext="L/r" class="ltx_Math" display="inline" id="A2.T1.43.43.2.m1.1"><semantics id="A2.T1.43.43.2.m1.1a"><mrow id="A2.T1.43.43.2.m1.1.1" xref="A2.T1.43.43.2.m1.1.1.cmml"><mi id="A2.T1.43.43.2.m1.1.1.2" xref="A2.T1.43.43.2.m1.1.1.2.cmml">L</mi><mo id="A2.T1.43.43.2.m1.1.1.1" xref="A2.T1.43.43.2.m1.1.1.1.cmml">/</mo><mi id="A2.T1.43.43.2.m1.1.1.3" xref="A2.T1.43.43.2.m1.1.1.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.43.43.2.m1.1b"><apply id="A2.T1.43.43.2.m1.1.1.cmml" xref="A2.T1.43.43.2.m1.1.1"><divide id="A2.T1.43.43.2.m1.1.1.1.cmml" xref="A2.T1.43.43.2.m1.1.1.1"></divide><ci id="A2.T1.43.43.2.m1.1.1.2.cmml" xref="A2.T1.43.43.2.m1.1.1.2">ùêø</ci><ci id="A2.T1.43.43.2.m1.1.1.3.cmml" xref="A2.T1.43.43.2.m1.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.43.43.2.m1.1c">L/r</annotation><annotation encoding="application/x-llamapun" id="A2.T1.43.43.2.m1.1d">italic_L / italic_r</annotation></semantics></math> quantized embedding vectors in <math alttext="{\mathcal{E}}" class="ltx_Math" display="inline" id="A2.T1.44.44.3.m2.1"><semantics id="A2.T1.44.44.3.m2.1a"><mi class="ltx_font_mathcaligraphic" id="A2.T1.44.44.3.m2.1.1" xref="A2.T1.44.44.3.m2.1.1.cmml">‚Ñ∞</mi><annotation-xml encoding="MathML-Content" id="A2.T1.44.44.3.m2.1b"><ci id="A2.T1.44.44.3.m2.1.1.cmml" xref="A2.T1.44.44.3.m2.1.1">‚Ñ∞</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.44.44.3.m2.1c">{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="A2.T1.44.44.3.m2.1d">caligraphic_E</annotation></semantics></math> back to text tokens,</td></tr><tr class=ltx_tr id=A2.T1.45.45><th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id=A2.T1.45.45.2></th><td class="ltx_td ltx_align_left ltx_border_bb" id=A2.T1.45.45.1>conditioning on prompt embedding generated by<math alttext="g(\cdot)" class="ltx_Math" display="inline" id="A2.T1.45.45.1.m1.1"><semantics id="A2.T1.45.45.1.m1.1a"><mrow id="A2.T1.45.45.1.m1.1.2" xref="A2.T1.45.45.1.m1.1.2.cmml"><mi id="A2.T1.45.45.1.m1.1.2.2" xref="A2.T1.45.45.1.m1.1.2.2.cmml">g</mi><mo id="A2.T1.45.45.1.m1.1.2.1" xref="A2.T1.45.45.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="A2.T1.45.45.1.m1.1.2.3.2" xref="A2.T1.45.45.1.m1.1.2.cmml"><mo id="A2.T1.45.45.1.m1.1.2.3.2.1" stretchy="false" xref="A2.T1.45.45.1.m1.1.2.cmml">(</mo><mo id="A2.T1.45.45.1.m1.1.1" lspace="0em" rspace="0em" xref="A2.T1.45.45.1.m1.1.1.cmml">‚ãÖ</mo><mo id="A2.T1.45.45.1.m1.1.2.3.2.2" stretchy="false" xref="A2.T1.45.45.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.T1.45.45.1.m1.1b"><apply id="A2.T1.45.45.1.m1.1.2.cmml" xref="A2.T1.45.45.1.m1.1.2"><times id="A2.T1.45.45.1.m1.1.2.1.cmml" xref="A2.T1.45.45.1.m1.1.2.1"></times><ci id="A2.T1.45.45.1.m1.1.2.2.cmml" xref="A2.T1.45.45.1.m1.1.2.2">ùëî</ci><ci id="A2.T1.45.45.1.m1.1.1.cmml" xref="A2.T1.45.45.1.m1.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T1.45.45.1.m1.1c">g(\cdot)</annotation><annotation encoding="application/x-llamapun" id="A2.T1.45.45.1.m1.1d">italic_g ( ‚ãÖ )</annotation></semantics></math></td></tr></tbody></table></table></figure><blockquote><p>üîº Table 4.3 presents a detailed comparison of the average number of tokens used in generated responses across different methods. It shows that the proposed &rsquo;latent&rsquo; approach significantly reduces the response length (by 17%) compared to the standard Chain-of-Thought (CoT) method, while simultaneously achieving superior performance (as shown in Table 4.2). The table also demonstrates that while the iCoT method generates even shorter responses, its overall accuracy is substantially lower than the latent approach. The percentage reduction in response length compared to CoT is also indicated for each method.</p><details><summary>read the caption</summary>Table 4.3: The average number of tokens in the generated responses. Compared with the CoT baseline, our latent approach achieves an 17%percent1717\%17 % reduction in response length on average, while surpassing it in final performance according to¬†Table¬†4.2. The iCoT method generates shorter responses than our approach, yet performs significantly worse, see¬†Table¬†4.2. ‚Üì‚Üì\downarrow‚Üì -:‚ÄÖTrace length reduction rate compared with CoT.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-2723ce9bb69552fb1f099f8b7dd2616b class=gallery><img src=https://ai-paper-reviewer.com/2502.03275/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03275/18.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/&amp;title=Token%20Assorted:%20Mixing%20Latent%20and%20Text%20Tokens%20for%20Improved%20Language%20Model%20Reasoning" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/&amp;text=Token%20Assorted:%20Mixing%20Latent%20and%20Text%20Tokens%20for%20Improved%20Language%20Model%20Reasoning" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03275/&amp;subject=Token%20Assorted:%20Mixing%20Latent%20and%20Text%20Tokens%20for%20Improved%20Language%20Model%20Reasoning" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2502.03275/index.md",oid_likes="likes_paper-reviews/2502.03275/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2502.03639/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-05T00:00:00+00:00>5 February 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2502.03628/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-05T00:00:00+00:00>5 February 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>