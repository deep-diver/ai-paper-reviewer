{"importance": "This paper is crucial because it **tackles the underexplored area of user action extraction from desktop recordings using Vision-Language Models (VLMs)**.  It introduces novel methods, benchmarks, and insights that can significantly advance the field of Robotic Process Automation (RPA), personalized user experience design, and automated tutorial generation. The findings also **open new avenues for future research** into VLM applications in complex dynamic environments like desktop interfaces.", "summary": "Sharingan extracts user action sequences from desktop recordings using novel VLM-based methods, achieving 70-80% accuracy and enabling RPA.", "takeaways": ["Two novel VLM-based methods for user action extraction from desktop recordings are proposed: Direct Frame-Based Approach and Differential Frame-Based Approach.", "The Direct Frame-Based Approach achieved 70-80% accuracy in identifying user actions, with extracted sequences being replayable via RPA.", "The study contributes new benchmarks and datasets for evaluating user action extraction methods."], "tldr": "Extracting user actions from desktop recordings is valuable for automating processes, creating personalized user experiences, and generating tutorials.  However, this area has been largely unexplored. Existing video analysis methods often struggle with the complexities of desktop interfaces and the rich temporal dynamics of user interactions.  This paper addresses this gap by proposing two methods to extract user action sequences from desktop recordings, using Vision-Language Models (VLMs). \nThe proposed methods are evaluated on two benchmark datasets, one self-curated and another adapted from prior work. The Direct Frame-Based Approach, which directly inputs video frames into VLMs, outperforms the Differential Frame-Based Approach, demonstrating the potential of VLMs for this task. The study also shows that the accuracy of user action extraction ranges from 70% to 80%, with the extracted action sequences being replayable through Robotic Process Automation (RPA). This work represents the first application of VLMs for extracting user action sequences from desktop recordings, paving the way for novel applications and research.", "affiliation": "Tsinghua University", "categories": {"main_category": "Computer Vision", "sub_category": "Video Understanding"}, "podcast_path": "2411.08768/podcast.wav"}