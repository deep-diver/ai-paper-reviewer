{"references": [{"fullname_first_author": "Florian Bordes", "paper_title": "An introduction to vision-language modeling", "publication_date": "2024-00-00", "reason": "This paper provides a foundational overview of vision-language modeling, which is the core methodology of the research."}, {"fullname_first_author": "Dongping Chen", "paper_title": "GUI-World: A dataset for GUI-oriented multimodal LLM-based agents", "publication_date": "2024-00-00", "reason": "This paper introduces a benchmark dataset (ACTREAL) crucial for evaluating the proposed methods and comparing them against existing approaches."}, {"fullname_first_author": "Hao Fei", "paper_title": "Video-of-Thought: Step-by-step video reasoning from perception to cognition", "publication_date": "2024-00-00", "reason": "This paper explores spatial-temporal understanding in videos, which is related to the paper's focus on understanding user actions from video sequences."}, {"fullname_first_author": "Google", "paper_title": "Gemini Models", "publication_date": "2024-00-00", "reason": "This paper introduces the Gemini models, which are used in the paper's experiments as the core Vision-Language Models (VLMs)."}, {"fullname_first_author": "OpenAI", "paper_title": "GPT-4", "publication_date": "2024-00-00", "reason": "This paper introduces the GPT-4 models, which are also used in the paper's experiments as the core VLMs."}]}