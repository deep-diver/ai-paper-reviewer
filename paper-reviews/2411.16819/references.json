{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-00", "reason": "This paper is foundational to the proposed method, introducing the use of  video diffusion models for high-quality temporal coherence in video generation, which is directly leveraged for image editing."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This work is highly influential in image generation and editing, introducing the fundamental concept of denoising diffusion models that the current method builds upon."}, {"fullname_first_author": "Bahjat Kawar", "paper_title": "Imagic: Text-based real image editing with diffusion models", "publication_date": "2023-00-00", "reason": "This paper introduces a competing method for text-based image editing that is compared against in the current work's experiments, providing a benchmark to evaluate the proposed approach."}, {"fullname_first_author": "Manuel Brack", "paper_title": "Ledits++: Limitless image editing using text-to-image models", "publication_date": "2023-00-00", "reason": "This paper introduces another competing method for image editing, offering a comparison point for evaluating the performance and improvements of the proposed method."}, {"fullname_first_author": "Zhuoyi Yang", "paper_title": "Cogvideox: Text-to-video diffusion models with an expert transformer", "publication_date": "2024-00-00", "reason": "This paper provides the generative video model used in the proposed method, forming a core component of the framework and directly impacting its functionality and performance."}]}