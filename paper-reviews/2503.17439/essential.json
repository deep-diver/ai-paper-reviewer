{"importance": "This paper is important because it addresses the **critical issue of error correction in LLMs**, a key area for improving their reliability. It aligns with the trend of **enhancing reasoning through learning from mistakes** and opens new avenues for researchers by demonstrating a structured approach to error analysis and correction, which can be **applied to other complex tasks**.", "summary": "LEMMA: LLMs learn math via mistake analysis and correction, boosting performance without external critics.", "takeaways": ["LEMMA enhances LLMs' reasoning by learning from error-corrective trajectories.", "Error-type grounded augmentation and smooth reflection improve self-correction.", "LEMMA achieves SOTA performance on math reasoning benchmarks."], "tldr": "Large Language Models (LLMs) are facing the challenge of solving mathematical problems. Current approaches focus on refining correct training data, overlooking the valuable insights within error data. This omission limits LLMs' reflective reasoning ability. Moreover, existing methods for leveraging error data often involve complex mechanisms like Monte Carlo Tree Search, adding to the computational overhead and complexity.\n\nTo solve the problems above, LEMMA is proposed, a novel method to systematically enhance LLMs' reasoning. It involves constructing and learning from error-corrective trajectories using two complementary mechanisms, Fix & Continue, and Fresh & Restart Trajectories. Experiments show LEMMA achieves state-of-the-art performance in benchmarks like GSM8K and MATH. LEMMA also reduces the occurrence of representative error types consistently.", "affiliation": "Tsinghua University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.17439/podcast.wav"}