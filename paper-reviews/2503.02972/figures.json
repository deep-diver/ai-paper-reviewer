[{"figure_path": "https://arxiv.org/html/2503.02972/x1.png", "caption": "Figure 1: LingOly-TOO benchmark overview. Framework for developing LingOly-TOO, starting from an original problem, annotating it and developing its orthographic template to generate several obfuscations.", "description": "The figure illustrates the framework for creating the LINGOLY-TOO benchmark.  It begins with an original linguistic reasoning problem from the UK Linguistics Olympiad. This problem undergoes annotation, where irrelevant metadata is removed while preserving the problem's solvability.  Then, an orthographic template is developed. This template defines rules for systematically altering the writing system of the original language (the Problemese) while maintaining the underlying linguistic structure and reasoning steps needed to solve the problem. Finally, multiple obfuscated versions of the problem are generated by applying different permutations based on the orthographic template. This process creates many variations of the same problem, reducing the likelihood that specific problem instances have been seen by language models during training.", "section": "2. The LINGOLY-TOO Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.02972/x2.png", "caption": "Figure 2: LingOly-TOO benchmark main results. (a) Mean exact match scores by model on LingOly-TOO Mo\u2062gsubscript\ud835\udc40\ud835\udc5c\ud835\udc54M_{og}italic_M start_POSTSUBSCRIPT italic_o italic_g end_POSTSUBSCRIPT is on nonobfuscated problems and Mo\u2062b\u2062fsubscript\ud835\udc40\ud835\udc5c\ud835\udc4f\ud835\udc53M_{obf}italic_M start_POSTSUBSCRIPT italic_o italic_b italic_f end_POSTSUBSCRIPT is on obfuscated problems. (b) \u0394o\u2062b\u2062fsubscript\u0394\ud835\udc5c\ud835\udc4f\ud835\udc53\\Delta_{obf}roman_\u0394 start_POSTSUBSCRIPT italic_o italic_b italic_f end_POSTSUBSCRIPT for the 6666 obfuscations of 57575757 problems (for brevity), showing performance changes by model. Red indicates a performance drop for that particular obfuscation, while blue indicates an improvement. Results for all problems are in Appendix H.", "description": "Figure 2 presents the key results from the LINGOLY-TOO benchmark.  Panel (a) shows the average performance of various large language models (LLMs) on the original LINGOLY problems (Mog) and their obfuscated versions (Mobf).  The original problems are those from the UK Linguistics Olympiad that were used to create the dataset.  The obfuscated versions have had the orthography modified, making them different from the training data and therefore relying more on true reasoning abilities. Panel (b) shows the difference in performance (\u0394obf) between the original and obfuscated problems for a subset of the problems to illustrate the variation in model performance across different obfuscations. Red indicates a drop in performance, and blue an increase; this highlights how sensitive LLM performance is, even with a small change. Appendix H provides the full results for all problems.", "section": "3. Results"}, {"figure_path": "https://arxiv.org/html/2503.02972/x3.png", "caption": "Figure 3: Performance by problem difficulty level for o1-preview. The relative difficulty level of problems is largely preserved by the obfuscation process. Categories as defined by UKLO.", "description": "This figure shows the performance of the o1-preview model on the LINGOLY-TOO benchmark, broken down by the difficulty level of the problems.  The x-axis represents the problem difficulty level, categorized as Breakthrough, Foundation, Intermediate, Advanced, and Round 2 by the UK Linguistics Olympiad (UKLO). The y-axis shows the exact match score, a measure of model accuracy. The bars show the average exact match score for problems at each difficulty level, comparing the model's performance on the original (unobfuscated) problems and their obfuscated versions.  The figure demonstrates that, despite the obfuscation, the relative difficulty of the problems is largely maintained.  Easier problems consistently yield higher scores than harder problems, irrespective of whether the problem is obfuscated or not.", "section": "3. Results"}, {"figure_path": "https://arxiv.org/html/2503.02972/x4.png", "caption": "Figure 4: The effect of obfuscation is larger for high-resource languages. Scores for each problem are averaged across all eight models in Figure\u00a02. Active speaker numbers serves as a proxy for language resourcedness. Speaker numbers are transformed by log\u2061(x+1)\ud835\udc651\\log(x+1)roman_log ( italic_x + 1 ) to emphasise differences between low-resource languages.", "description": "Figure 4 illustrates the impact of orthographic obfuscation on the performance of large language models (LLMs) across different language problems.  The x-axis represents the average score on non-obfuscated problems (Mog) across eight LLMs, while the y-axis represents the average score on obfuscated problems (Mobf) for the same models.  Each point represents a language problem, and the size of the point reflects the number of active speakers of the language (a proxy for resource abundance).  The logarithmic transformation of speaker numbers highlights the differences between low-resource and high-resource languages. The figure shows that the negative impact of obfuscation (difference between Mog and Mobf) is more pronounced for high-resource languages, suggesting that LLMs rely more on memorization for these languages than on actual reasoning capabilities. ", "section": "3. Results"}, {"figure_path": "https://arxiv.org/html/2503.02972/x6.png", "caption": "Figure 5: Score distribution across bootstrapped samples. Distribution of scores across 500 bootstrapped samples of our data by model. Each consists of 82 problems. Open source models are shown in orange while proprietary models are in blue.", "description": "This figure displays the distribution of scores obtained from 500 bootstrapped samples for each of the models evaluated in the paper. Each bootstrapped sample contains scores for 82 problems.  The distributions are shown as histograms. Open-source models are represented in orange, while proprietary models are in blue. The figure helps visualize the variability in model performance across different problem sets and highlights potential differences between open-source and proprietary models.", "section": "3. Results"}, {"figure_path": "https://arxiv.org/html/2503.02972/x9.png", "caption": "Figure 6: Performance by linguistic subdiscipline. Left: Averaged across all models. Models perform comparably across linguistic subdisciplines, with the exception of numbers problems. The effect of obfuscation is relatively even across subdisciplines. Right: Averaged across the four highest-scoring models (o1 Preview, Claude 3.5 Sonnet, GPT 4o, Gemini 1.5 Pro). Compounding problems are affected particularly severely by obfuscation.", "description": "This figure displays the performance of various large language models (LLMs) on linguistic reasoning problems categorized by linguistic subdiscipline.  The left panel shows the average performance across all evaluated LLMs, indicating comparable performance across most subdisciplines except for 'numbers' problems.  The obfuscation technique, aimed at reducing memorization, shows relatively consistent effects across different subdisciplines. The right panel focuses on the four top-performing LLMs, revealing a significant negative impact of obfuscation specifically on 'compounding' problems.", "section": "3. Results"}, {"figure_path": "https://arxiv.org/html/2503.02972/x10.png", "caption": "Figure 7: Problem-level comparison of exact match scores between standard and alternative tokenisation. The dashed line represents the threshold where the score remains unchanged after altering the tokenisation. Point above the dashed line indicate better performance with alternative tokenisation, while points below the line indicate worse performance. (a) The problems are unobfuscated and we compare scores of standard tokenisation against dash tokenisation. (b) The problems are obfuscated and we compare scores of standard tokenisation against dash tokenisation. (c) The problems are unobfuscated and we compare scores of standard tokenisation against character-level tokenisation. (d) The problems are obfuscated and we compare scores of standard tokenisation against character-level tokenisation.", "description": "This figure displays a comparison of exact match scores achieved using standard versus alternative tokenization methods. The x-axis represents scores from standard tokenization, and the y-axis represents scores from the alternative methods.  The dashed line indicates where the scores are equal. Points above the line show improved performance with the alternative method, and points below show worse performance. The figure is divided into four subplots: (a) unobfuscated problems with dash tokenization, (b) obfuscated problems with dash tokenization, (c) unobfuscated problems with character-level tokenization, and (d) obfuscated problems with character-level tokenization. This allows for a detailed analysis of how different tokenization approaches impact performance on both original and obfuscated linguistic problems.", "section": "Evaluation"}]