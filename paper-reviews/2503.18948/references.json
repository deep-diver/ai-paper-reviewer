{"references": [{"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces a foundational approach for high-resolution image synthesis by taming transformers, and is the base autoencoder used by the paper."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This is the basic diffusion model used by this paper, and it also introduces a tokenizer (which this paper improves) to compress the images before generation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper lays the groundwork for denoising diffusion probabilistic models (DDPMs), a core technology in modern generative image modeling."}, {"fullname_first_author": "Yaron Lipman", "paper_title": "Flow matching for generative modeling", "publication_date": "2023-01-01", "reason": "This paper presents Flow Matching, an algorithm for generative modeling and this work uses this method to accelerate training."}, {"fullname_first_author": "Tianhong Li", "paper_title": "Autoregressive image generation without vector quantization", "publication_date": "2024-01-01", "reason": "This paper introduces a different method for autoregressive image generation, and serves as the baseline this paper compares against."}]}