[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.2\"># Num task.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.3\">gFID</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.2.1.1\">AR-MAR-2D</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.2.1.2\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.2.1.3\">7.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.3.2.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.3.2.2\">16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.3.2.3\">5.57</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.3.1\">AR-MAR-2D</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.3.2\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.3.3\">92.46</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.5.4.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.5.4.2\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.5.4.3\">8.99</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: \nPerformance under Zero-shot Setting. # Num task. is used to denote the number of trained subtasks. The total number of subtasks is 16 for all methods.", "description": "This table presents the results of a zero-shot learning experiment.  Models were trained on a subset of 16 subtasks and then evaluated on all 16 subtasks. The table compares the performance of the proposed method against a baseline method, measuring performance using the gFID (Generative Fr\u00e9chet Inception Distance) metric.  The number of training subtasks (# Num task.) is shown for both methods, highlighting the zero-shot generalization capabilities of the proposed approach.", "section": "4.2. Deep Analysis on Equivariance"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.3.3.4\" style=\"padding:0.25pt 4.0pt;\">Method</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1\" style=\"padding:0.25pt 4.0pt;\">gFID<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.1.1.1.m1.1\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mo id=\"S4.T2.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.1.1.1.m1.1d\">\u2193</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.2.2.2\" style=\"padding:0.25pt 4.0pt;\">IS<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.2.2.2.m1.1\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><mo id=\"S4.T2.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><ci id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.2.2.2.m1.1d\">\u2191</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.3.3.5\" style=\"padding:0.25pt 4.0pt;\">#Para.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.3.3.6\" style=\"padding:0.25pt 4.0pt;\">#Len.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.3.3.3\" style=\"padding:0.25pt 4.0pt;\">GFLOPs<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.3.3.3.m1.1\"><semantics id=\"S4.T2.3.3.3.m1.1a\"><mo id=\"S4.T2.3.3.3.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.3.3.3.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.m1.1b\"><ci id=\"S4.T2.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.3.3.3.m1.1d\">\u2193</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.4.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"6\" id=\"S4.T2.3.4.1.1\" style=\"padding:0.25pt 4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T2.3.4.1.1.1\" style=\"color:#808080;\">Diffusion</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.5.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.1\" style=\"padding:0.25pt 4.0pt;\">DiT\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib26\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">26</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.2\" style=\"padding:0.25pt 4.0pt;\">2.27</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.3\" style=\"padding:0.25pt 4.0pt;\">278.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.4\" style=\"padding:0.25pt 4.0pt;\">675M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.5\" style=\"padding:0.25pt 4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.5.2.6\" style=\"padding:0.25pt 4.0pt;\">118.64</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.6.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"6\" id=\"S4.T2.3.6.3.1\" style=\"padding:0.25pt 4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T2.3.6.3.1.1\" style=\"color:#808080;\">MaskGIT</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.7.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.1\" style=\"padding:0.25pt 4.0pt;\">TiTok\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib46\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">46</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.2\" style=\"padding:0.25pt 4.0pt;\">1.97</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.3\" style=\"padding:0.25pt 4.0pt;\">281.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.4\" style=\"padding:0.25pt 4.0pt;\">287M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.5\" style=\"padding:0.25pt 4.0pt;\">128</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.7.4.6\" style=\"padding:0.25pt 4.0pt;\">37.35</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.8.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.1\" style=\"padding:0.25pt 4.0pt;\">MAR\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib18\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">18</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.2\" style=\"padding:0.25pt 4.0pt;\">1.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.3\" style=\"padding:0.25pt 4.0pt;\">296.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.4\" style=\"padding:0.25pt 4.0pt;\">479M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.5\" style=\"padding:0.25pt 4.0pt;\">64</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.5.6\" style=\"padding:0.25pt 4.0pt;\">70.13</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.9.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.1\" style=\"padding:0.25pt 4.0pt;\">FractalMAR\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib17\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">17</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.2\" style=\"padding:0.25pt 4.0pt;\">7.30</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.3\" style=\"padding:0.25pt 4.0pt;\">334.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.4\" style=\"padding:0.25pt 4.0pt;\">438M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.5\" style=\"padding:0.25pt 4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.6.6\" style=\"padding:0.25pt 4.0pt;\">238.58</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.10.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"6\" id=\"S4.T2.3.10.7.1\" style=\"padding:0.25pt 4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T2.3.10.7.1.1\" style=\"color:#808080;\">Autoregressive</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.11.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.1\" style=\"padding:0.25pt 4.0pt;\">VQGAN\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib7\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">7</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.2\" style=\"padding:0.25pt 4.0pt;\">15.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.3\" style=\"padding:0.25pt 4.0pt;\">74.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.4\" style=\"padding:0.25pt 4.0pt;\">1.4B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.5\" style=\"padding:0.25pt 4.0pt;\">256</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.11.8.6\" style=\"padding:0.25pt 4.0pt;\">246.67</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.12.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.1\" style=\"padding:0.25pt 4.0pt;\">VAR\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib40\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">40</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.2\" style=\"padding:0.25pt 4.0pt;\">3.30</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.3\" style=\"padding:0.25pt 4.0pt;\">274.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.4\" style=\"padding:0.25pt 4.0pt;\">310M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.5\" style=\"padding:0.25pt 4.0pt;\">680</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.12.9.6\" style=\"padding:0.25pt 4.0pt;\">105.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.13.10\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.1\" style=\"padding:0.25pt 4.0pt;\">MAR\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.18948v1#bib.bib18\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">18</span></a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.2\" style=\"padding:0.25pt 4.0pt;\">4.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.3\" style=\"padding:0.25pt 4.0pt;\">244.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.4\" style=\"padding:0.25pt 4.0pt;\">479M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.5\" style=\"padding:0.25pt 4.0pt;\">64</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.13.10.6\" style=\"padding:0.25pt 4.0pt;\">78.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.14.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.1\" style=\"padding:0.25pt 4.0pt;\">Ours-S</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.2\" style=\"padding:0.25pt 4.0pt;\">7.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.3\" style=\"padding:0.25pt 4.0pt;\">233.70</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.4\" style=\"padding:0.25pt 4.0pt;\">151M</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.5\" style=\"padding:0.25pt 4.0pt;\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.14.11.6\" style=\"padding:0.25pt 4.0pt;\">5.41</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.15.12\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.1\" style=\"padding:0.25pt 4.0pt;\">Ours-B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.2\" style=\"padding:0.25pt 4.0pt;\">5.57</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.3\" style=\"padding:0.25pt 4.0pt;\">260.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.4\" style=\"padding:0.25pt 4.0pt;\">294M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.5\" style=\"padding:0.25pt 4.0pt;\">16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.15.12.6\" style=\"padding:0.25pt 4.0pt;\">9.78</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.16.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.1\" style=\"padding:0.25pt 4.0pt;\">Ours-L</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.2\" style=\"padding:0.25pt 4.0pt;\">4.48</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.3\" style=\"padding:0.25pt 4.0pt;\">259.91</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.4\" style=\"padding:0.25pt 4.0pt;\">644M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.5\" style=\"padding:0.25pt 4.0pt;\">16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.16.13.6\" style=\"padding:0.25pt 4.0pt;\">19.66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.17.14\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.1\" style=\"padding:0.25pt 4.0pt;\">Ours-H</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.2\" style=\"padding:0.25pt 4.0pt;\">4.17</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.3\" style=\"padding:0.25pt 4.0pt;\">290.66</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.4\" style=\"padding:0.25pt 4.0pt;\">1.2B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.5\" style=\"padding:0.25pt 4.0pt;\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.17.14.6\" style=\"padding:0.25pt 4.0pt;\">34.91</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: \nClass-conditional Generation Results on ImageNet 256\u00d7256 Benchmark. #Para. denotes the number of parameters in each generator, while #Len. indicates the token sequence length that generators are required to model.", "description": "This table presents the results of class-conditional image generation experiments conducted on the ImageNet dataset at 256x256 resolution.  Several different generative models were compared, and the table shows key performance metrics including the Fr\u00e9chet Inception Distance (gFID), which measures the quality of the generated images, and the Inception Score (IS), which assesses the diversity and quality of the generated images.  The table also lists the number of parameters (#Para.) in each model, providing an indication of model complexity, and the token sequence length (#Len.) used by each model during the generation process. Lower gFID and higher IS values generally indicate better performance.", "section": "4.4. System Comparison with SOTA Methods"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.2.2.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.2.2.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Tokens Length</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">gFID<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.1.1.1.m1.1\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T3.1.1.1.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.2.2.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GFLOPs<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.2.2.2.m1.1\"><semantics id=\"S4.T3.2.2.2.m1.1a\"><mo id=\"S4.T3.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S4.T3.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.m1.1b\"><ci id=\"S4.T3.2.2.2.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T3.2.2.2.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.3.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T3.2.3.1.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">AR-MAR-2D-B</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T3.2.3.1.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">256</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.2.3.1.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">3.99</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.2.3.1.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">130.46</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.4.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.2.4.1.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">AR-MAR-2D-B</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.2.4.1.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">16</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.4.1.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">7.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.4.1.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">9.79</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.5.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.2.5.2.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">AR-MAR-2D-L</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.2.5.2.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.2.5.2.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">7.49</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.2.5.2.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">19.68</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.6.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.2.6.3.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Ours-B</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.2.6.3.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.2.6.3.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5.57</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.2.6.3.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">9.78</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.7.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.2.7.4.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Ours-L</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.2.7.4.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">16</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.2.7.4.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">4.48</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.2.7.4.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">19.66</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: Comparison on the performance and computational efficiency. Our methods achieves better trade-off between performance and computation cost.", "description": "This table compares the performance (in terms of gFID) and computational efficiency (GFLOPs) of different models for image generation.  It highlights the trade-off between these two aspects. The models compared include the baseline autoregressive models with different token lengths (256 and 16) and the proposed equivariant models with token lengths of 16. The results show that the proposed equivariant models achieve a better trade-off, offering comparable or better performance with significantly reduced computational cost.", "section": "4.4. System Comparison with SOTA Methods"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.2.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.2.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Equ.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.2.5\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">L-Ctx.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">gFID<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.1.1.1.m1.1\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><mo id=\"S4.T4.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><ci id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.1.1.1.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.2.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Attn FLOPs<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.2.2.2.m1.1\"><semantics id=\"S4.T4.2.2.2.m1.1a\"><mo id=\"S4.T4.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S4.T4.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.m1.1b\"><ci id=\"S4.T4.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.2.2.2.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.2.3.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Full Causal</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T4.2.3.1.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">7.35</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.5\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">4.2M</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.4.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.2.4.2.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Real Equ.</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.2.4.2.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\u2713</td>\n<td class=\"ltx_td\" id=\"S4.T4.2.4.2.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.2.4.2.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">8.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.2.4.2.5\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.4.2.5.1\">0.26M</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.5.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.5.3.1\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Window Causal</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.5.3.2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.5.3.3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.5.3.4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.5.3.4.1\">7.21</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.5.3.5\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">1.8M</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: Ablation Study of Windowed Causal Attention. \u201dReal Equ.\u201d indicates the strictly equivariant model variant as described in \u00a0Sec.\u00a03.2; \u201dEqu.\u201d refers to whether the model possesses equivariant properties; and \u201dL-Ctx.\u201d denotes whether long-range contexts are utilized.", "description": "This table presents an ablation study on the impact of windowed causal attention in an equivariant autoregressive image generation model. It compares four different model variations: a baseline model with full causal attention, a strictly equivariant model (Real Equ.) with a limited context window, a model using windowed causal attention, and a model with windowed causal attention and long-range context.  The table shows the gFID (lower is better), a measure of image generation quality, and the attention FLOPs (floating-point operations, lower is better), representing computational cost.  This allows for an analysis of the trade-off between model performance and computational efficiency when employing different attention mechanisms and degrees of equivariance.", "section": "4.5. Ablation Studies"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T5.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T5.2.2.3\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.2.2.4\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1\">rFID<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T5.1.1.1.m1.1\"><semantics id=\"S4.T5.1.1.1.m1.1a\"><mo id=\"S4.T5.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T5.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.m1.1b\"><ci id=\"S4.T5.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T5.1.1.1.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.2.2.2\">gFID <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T5.2.2.2.m1.1\"><semantics id=\"S4.T5.2.2.2.m1.1a\"><mo id=\"S4.T5.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S4.T5.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.2.2.2.m1.1b\"><ci id=\"S4.T5.2.2.2.m1.1.1.cmml\" xref=\"S4.T5.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.2.2.2.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T5.2.2.2.m1.1d\">\u2193</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T5.2.3.1.1\">1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.2.3.1.2\">baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.2.3.1.3\">1.11</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.2.3.1.4\">7.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.2.4.2.1\">2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.4.2.2\">+Stronger discriminator</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.4.2.3\">0.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.4.2.4\">6.29</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.2.5.3.1\">3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.5.3.2\">+ Decoder finetune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.5.3.3\">0.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.5.3.4\">6.25</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T5.2.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.2.6.4.1.1\">Ours</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.2.6.4.2\">+Semantic aligned loss</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.2.6.4.3\">0.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.2.6.4.4\">5.57</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 5: \nAblation on the Impact of Tokenizer Components. \u201dOurs\u201d denotes the final setting we adopted in all other experiments.", "description": "This table presents the results of ablation experiments performed to evaluate the impact of different components within the tokenizer on the overall model performance.  The baseline model is compared against variations that include a stronger discriminator, decoder fine-tuning, and the addition of a semantic alignment loss. The \"Ours\" row represents the final model configuration that incorporates all of these improvements, and was used in all other experiments in the paper. The table shows the resulting rFID and gFID scores for each variation, demonstrating how the incremental improvements affect the model's performance in reconstruction fidelity and sample quality.", "section": "4.4 System Comparison with SOTA Methods"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T6.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T6.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T6.2.1.1.1\">config</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T6.2.1.1.2\">value</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T6.2.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T6.2.2.1.1\">Base channels</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.2.2.1.2\">128</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.3.2.1\">Base channel multiplier per stage</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.3.2.2\">[1, 1, 2, 4, 4]</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.4.3.1\">Residual blocks per stage</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.4.3.2\">2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.5.4.1\">Attention resolutions</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.5.4.2\">16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.6.5.1\">Token channels</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.6.5.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.7.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T6.2.7.6.1\">Adversarial loss enabled at iteration</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.2.7.6.2\">5000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.8.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.8.7.1\">Discriminator loss weight</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.8.7.2\">0.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.9.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.9.8.1\">Discriminator loss</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.9.8.2\">hinge loss</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.10.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.10.9.1\">Perceptual loss weight</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.10.9.2\">1.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.11.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.11.10.1\">Semantic anlignment loss enabled at iteration</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.11.10.2\">20000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.12.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.12.11.1\">Semantic anlignment loss weight</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.12.11.2\">5.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.13.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.13.12.1\">KL divergence loss weight</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.13.12.2\">0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.14.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T6.2.14.13.1\">Gradient clipping by norm</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.2.14.13.2\">1.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.15.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.15.14.1\">Optimizer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.15.14.2\">Adam</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.16.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.16.15.1\">Beta1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.16.15.2\">0.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.17.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.17.16.1\">Beta2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.17.16.2\">0.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.18.17\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.18.17.1\">Base LR</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.18.17.2\">1.92e-4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.19.18\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.19.18.1\">LR warmup iterations</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.19.18.2\">5000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.20.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.20.19.1\">LR decay frequency</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.20.19.2\">30000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.21.20\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.21.20.1\">LR decay ratio</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.21.20.2\">0.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.22.21\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T6.2.22.21.1\">EMA decay</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.2.22.21.2\">0.9999</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.23.22\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T6.2.23.22.1\">Training epochs</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.2.23.22.2\">50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.24.23\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T6.2.24.23.1\">Total Batchsize</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.2.24.23.2\">192</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.2.25.24\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T6.2.25.24.1\">GPU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T6.2.25.24.2\">A100</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 6: Detailed hyper-parameters for our equivariant 1D tokenizer.", "description": "This table lists the hyperparameters used during training of the Equivariant 1D tokenizer, a key component in the proposed image generation framework.  It details settings for various aspects of the training process, including network architecture (base channels, residual blocks, attention resolutions), loss functions (adversarial, discriminator, perceptual, semantic alignment, KL divergence), optimization parameters (optimizer, learning rate, decay, warmup, and EMA), and training schedule (epochs, batch size). These values were carefully chosen to optimize the performance of the tokenizer in preparing the image data for the subsequent generative model.", "section": "B. Implementation Details"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T7.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T7.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"A2.T7.2.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T7.2.1.1.2\">#Para.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.2.1.1.3\">Layers</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.2.1.1.4\">Hidden dim</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.2.1.1.5\">Attn heads</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.2.1.1.6\">Diff. hidden dim</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.2.1.1.7\">Diff.layers</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T7.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T7.2.2.1.1\">Small</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A2.T7.2.2.1.2\">151M</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.1.3\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.1.4\">512</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.1.5\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.1.6\">960</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.1.7\">12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T7.2.3.2.1\">Base</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A2.T7.2.3.2.2\">294M</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.3.2.3\">24</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.3.2.4\">768</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.3.2.5\">12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.3.2.6\">1024</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.3.2.7\">12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T7.2.4.3.1\">Large</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A2.T7.2.4.3.2\">644M</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.4.3.3\">32</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.4.3.4\">1024</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.4.3.5\">16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.4.3.6\">1280</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.2.4.3.7\">12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T7.2.5.4.1\">Huge</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T7.2.5.4.2\">1.2B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.2.5.4.3\">40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.2.5.4.4\">1280</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.2.5.4.5\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.2.5.4.6\">1536</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.2.5.4.7\">12</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 7: The model configurations of our generators. #Para. denotes the number of parameters in the respective generators and Diff. presents the diffusion head. We also use \u201dS\u201d, \u201dB\u201d, and \u201dL\u201d and \u201dH\u201d as shorthand for different models in the manuscript.", "description": "This table details the architecture specifications for four different image generation models (Small, Base, Large, and Huge).  For each model, it lists the number of parameters (#Para.), the number of layers, the hidden dimension size, the number of attention heads, the diffusion hidden dimension size, and the number of diffusion layers.  The \"Diff.\" column refers to the diffusion head, a component of the model used for image generation. The table also notes that \"S\", \"B\", \"L\", and \"H\" are used in the paper as shorthand for Small, Base, Large, and Huge respectively.", "section": "4. Experiments"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T8.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T8.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T8.2.1.1.1\">config</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T8.2.1.1.2\">value</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T8.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.2.2.1.1\">Token length</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.2.1.2\">16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.3.2.1\">Token channels</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.3.2.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.2.4.3.1\">MLP ratio</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.4.3.2\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.5.4.1\">Norn layer in attention blocks</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.5.4.2\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T8.2.5.4.2.1\">nn.LayerNorm</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.6.5.1\">Class labels sequence length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.6.5.2\">16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.7.6.1\">Class labels dropout</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.7.6.2\">0.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.8.7.1\">Attention dropout</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.8.7.2\">0.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.9.8.1\">Projection layer dropout</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.9.8.2\">0.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.2.10.9.1\">Gradient clipping by norm</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.10.9.2\">3.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.11.10.1\">Optimizer</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.11.10.2\">Adam</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.12.11.1\">Beta1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.12.11.2\">0.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.13.12.1\">Beta2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.13.12.2\">0.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.14.13.1\">Base LR</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.14.13.2\">8.0e-4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.15.14.1\">LR scheduler</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.15.14.2\">constant</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.16.15.1\">LR warmup epochs</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.16.15.2\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.17.16.1\">Weight decay</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.17.16.2\">0.02</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.2.18.17.1\">EMA decay</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.18.17.2\">0.9999</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.2.19.18.1\">Training epochs</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.19.18.2\">1200</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.20.19.1\">Total Batchsize</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.20.19.2\">2048</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T8.2.21.20.1\">GPU</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T8.2.21.20.2\">A100</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 8: Detailed hyper-parameters for our equivariant generator.", "description": "This table details the hyperparameters used for training the equivariant generator model.  It lists the settings for various aspects of the training process, including tokenization parameters (token length and channels), network architecture choices (MLP ratio, normalization layers, dropout rates), optimization settings (optimizer, learning rate schedule, weight decay), and other regularization techniques.", "section": "4. Experiments"}]