[{"figure_path": "https://arxiv.org/html/2503.10772/x2.png", "caption": "Figure 1: \nText-to-Image Generation Results by FlowTok. FlowTok projects both text and images into a unified, compact 1D latent space, enabling direct flow matching between 1D tokens and facilitating the efficient generation of diverse, high-fidelity images.", "description": "FlowTok, a novel model, processes both text and images within a shared, compact one-dimensional (1D) latent space. This unified representation allows for direct flow matching between 1D tokens corresponding to text and images.  The result is the efficient generation of diverse and high-fidelity images directly from text prompts. The figure displays a selection of images generated by the FlowTok model, showcasing its ability to generate varied and realistic image content from textual descriptions.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2503.10772/x3.png", "caption": "Figure 2: \nText as Conditions vs. Direct Flow between Modalities.\nTop: Conventional text-to-image generation relies on the diffusion process, where text serves as a conditioning signal to guide the denoising process.\nBottom: The proposed FlowTok enables direct flow between text and image modalities by projecting both into a shared, compact 1D latent space, facilitating seamless generation of both.", "description": "This figure compares two approaches to text-to-image generation. The top panel illustrates the conventional method using a diffusion process, where text acts as a conditioning signal to guide the generation from noise to a final image.  The bottom panel shows the FlowTok approach.  Instead of using diffusion, FlowTok projects both text and images into a shared, low-dimensional (1D) latent space. This allows for direct transformation between the text and image representations, resulting in more efficient and seamless generation of images from text or vice versa.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10772/x4.png", "caption": "(a) FID vs. Training Costs.", "description": "The figure shows a comparison of the Fr\u00e9chet Inception Distance (FID) score, a metric for evaluating image quality, against the training cost (measured in 8-A100 GPU days) for various models.  It illustrates that FlowTok achieves comparable or better FID scores with significantly reduced training costs compared to other models, highlighting its efficiency.", "section": "3. COCO Results"}, {"figure_path": "https://arxiv.org/html/2503.10772/x5.png", "caption": "(b) FID vs. Inference Speed.", "description": "This figure shows a comparison of different models' performance on the COCO dataset, specifically focusing on the trade-off between image quality (measured by FID score) and inference speed (images per second).  The graph visualizes how various models balance these two factors. Lower FID indicates better image quality, while higher inference speed implies faster image generation.", "section": "COCO Results"}, {"figure_path": "https://arxiv.org/html/2503.10772/x6.png", "caption": "Figure 3: \nCOCO Results.\nFlowTok presents comparable performance to previous methods on COCO while significantly reducing training resource requirements (Fig.\u00a03(a)) and achieving much faster sampling speed (Fig.\u00a03(b)). This efficiency stems from its minimalist design centered around 1D tokens, which facilitates direct transformation between text and image modalities, leading to superior performance with enhanced computational efficiency.\nWe note that the compared CrossFlow\u00a0[53] uses high-quality proprietary data.", "description": "Figure 3 displays a comparison of FlowTok's performance against other state-of-the-art models on the COCO dataset.  Subfigure (a) shows that FlowTok achieves comparable FID scores (a measure of image quality) to other models, but requires significantly less training time (measured in 8-A100 GPU days). Subfigure (b) demonstrates that FlowTok's inference speed (images per second) is considerably faster than competing methods.  The superior efficiency of FlowTok results from its novel design using compact 1D tokens for representing both text and images, enabling direct transformation between the two modalities and improving computational efficiency. Note that a competitor model, CrossFlow, utilized high-quality proprietary data, which may influence the results.", "section": "3. COCO Results"}, {"figure_path": "https://arxiv.org/html/2503.10772/x7.png", "caption": "Figure 4: Overview of FlowTok.\nFlowTok is a minimal framework that facilitates seamless flow between 1D text tokens and image tokens for both text-to-image and image-to-text generation.\nTop: For text-to-image generation, the input text is encoded by the CLIP text encoder into \ud835\udc13init\u2208\u211dN\u00d7Csubscript\ud835\udc13initsuperscript\u211d\ud835\udc41\ud835\udc36\\mathbf{T}_{\\text{init}}\\in\\mathbb{R}^{N\\times C}bold_T start_POSTSUBSCRIPT init end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_N \u00d7 italic_C end_POSTSUPERSCRIPT, projected into a low-dimensional latent space as text tokens \ud835\udc19T\u2208\u211dN\u00d7Dsubscript\ud835\udc19Tsuperscript\u211d\ud835\udc41\ud835\udc37\\mathbf{Z}_{\\text{T}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_N \u00d7 italic_D end_POSTSUPERSCRIPT, then transformed into image tokens \ud835\udc19I\u2208\u211dN\u00d7Dsubscript\ud835\udc19Isuperscript\u211d\ud835\udc41\ud835\udc37\\mathbf{Z}_{\\text{I}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_N \u00d7 italic_D end_POSTSUPERSCRIPT of the same shape through flow matching and decoded by a 1D Image VAE Decoder to generate the final image.\nBottom: For image-to-text generation, an input image is encoded by a 1D Image VAE Encoder into \ud835\udc19Isubscript\ud835\udc19I\\mathbf{Z}_{\\text{I}}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT, mapped to \ud835\udc19Tsubscript\ud835\udc19T\\mathbf{Z}_{\\text{T}}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPT through flow matching and decoded into text via a text decoder. Unlike conventional approaches that rely on 2D noise and image latents (e.g., 32\u00d732\u00d743232432\\times 32\\times 432 \u00d7 32 \u00d7 4 for 256-resolution images) with text as conditions, our direct 1D transformation (i.e., 77\u00d716771677\\times 1677 \u00d7 16) achieves a 3.3\u00d7\\times\u00d7 compression rate, significantly reducing memory costs, accelerating training, and enabling faster inference.", "description": "Figure 4 provides a detailed overview of the FlowTok framework.  The top half illustrates the text-to-image generation process.  Input text is first encoded into a high-dimensional vector representation (Tinit) using a CLIP text encoder. This vector is then projected into a lower-dimensional latent space, creating text tokens (ZT).  These text tokens are transformed into image tokens (ZI) of the same dimensions via a flow matching process. Finally, a 1D Image VAE Decoder uses the image tokens to generate the final image. The bottom half demonstrates image-to-text generation.  An input image is encoded into image tokens (ZI) by a 1D Image VAE Encoder. Through flow matching, these tokens are mapped to text tokens (ZT) which are then decoded by a text decoder to produce the final text.  The figure highlights FlowTok's efficiency compared to traditional methods, achieving a 3.3x compression rate by using a direct 1D transformation of both text and images, leading to reduced memory usage, faster training, and quicker inference.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2503.10772/x8.png", "caption": "(a)", "description": "This figure shows the FID (Fr\u00e9chet Inception Distance) scores and inference speeds of different models on the COCO dataset.  Panel (a) compares the FID scores against the training costs (measured in 8-A100 GPU days), illustrating the efficiency of FlowTok which achieves comparable FID scores with significantly reduced training costs compared to other models like SD-2.1 and CrossFlow. Panel (b) presents the FID scores against the inference speed (images per second), highlighting FlowTok's superior inference efficiency with throughputs exceeding those of Show-o and CrossFlow.", "section": "3. COCO Results"}, {"figure_path": "https://arxiv.org/html/2503.10772/x9.png", "caption": "(b)", "description": "This figure shows the comparison of FID scores versus inference speed for various models.  FlowTok's superior efficiency is highlighted by its placement at the top-left.  Compared to other methods, FlowTok achieves comparable FID scores while showing significantly faster inference speeds, demonstrating a major improvement in efficiency.", "section": "COCO Results"}]