[{"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.2.1.1.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.2.1.1.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Type</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">CoT</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">RefCOCOg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">ReasonSeg</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.1.2.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Baseline</th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.1.2.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.2.1.2.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.1.2.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">70.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.1.2.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">47.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.1.3.2.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.1.3.2.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">SFT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.3.2.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u00d7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.3.2.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">70.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.3.2.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">44.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.1.4.3.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.1.4.3.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">RL</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.4.3.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u00d7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.4.3.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">73.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.1.4.3.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">51.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.2.1.5.4.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.2.1.5.4.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">RL</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.1.5.4.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.1.5.4.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.5.4.4.1\">73.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.1.5.4.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.5.4.5.1\">53.8</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: Segmentation task comparison. Model trained with RL + CoT thinking reward achieves best performance on in-domain and OOD data.", "description": "This table compares the performance of different training methods on a semantic segmentation task.  The methods compared include supervised fine-tuning (SFT) and reinforcement learning (RL), with and without chain-of-thought (CoT) prompting.  The results are shown for both in-domain (RefCOCOg) and out-of-domain (ReasonSeg) datasets. The table highlights that the model trained with RL and CoT achieves the best performance across both datasets, demonstrating the effectiveness of this approach for improving generalization capabilities in reasoning segmentation.", "section": "4. Experiment"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.2.1.1.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.2.1.1.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Bbox</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.2.1.1.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Points</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.2.1.1.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">RefCOCOg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.2.1.1.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">ReasonSeg</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.2.1.2.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Baseline</th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.2.1.2.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.2.1.2.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">70.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.2.1.2.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">47.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.3.2.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.2.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u00d7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.2.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.2.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">69.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.3.2.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">45.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.4.3.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.3.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.3.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u00d7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.3.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">72.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.1.4.3.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">53.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.2.1.5.4.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.2.1.5.4.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.2.1.5.4.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.2.1.5.4.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.5.4.4.1\">73.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.2.1.5.4.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.5.4.5.1\">53.8</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Ablation on the design of bbox and points prompt.", "description": "This table presents the results of ablation studies on the design of prompts used in the Seg-Zero model.  Specifically, it investigates the impact of using only bounding boxes, only points, or both bounding boxes and points as input prompts for the segmentation task. The performance is evaluated on the RefCOCOg and ReasonSeg datasets, using gIoU as the metric. This helps determine the optimal prompt design for achieving best segmentation accuracy.", "section": "3. Method"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.2.1.1.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.2.1.1.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Type</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.2.1.1.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">RefCOCOg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S4.T3.2.1.1.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">ReasonSeg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.2.1.1.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">sum</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.2.1.2.1.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.2.1.2.1.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Soft</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.1.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">70.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.2.1.2.1.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.2.1.2.1.4.1\">54.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.1.2.1.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">124.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.2.1.3.2.1\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.2.1.3.2.2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Hard</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.2.1.3.2.3\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.2.1.3.2.3.1\">73.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T3.2.1.3.2.4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">53.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.2.1.3.2.5\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.2.1.3.2.5.1\">127.4</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: Ablation on the accuracy reward type.", "description": "This table presents the results of an ablation study on the accuracy reward type used in the Seg-Zero model training.  It shows how different accuracy reward designs affect the model's performance on both in-domain (RefCOCOg) and out-of-domain (ReasonSeg) datasets.  The results demonstrate the impact of various accuracy reward types on the final segmentation results.", "section": "3.4 Training"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T4.2.1.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T4.2.1.1.1.2\">Type</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.1.1.1.3\">RefCOCOg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S4.T4.2.1.1.1.4\">ReasonSeg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.2.1.1.1.5\">sum</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.1.2.1.1\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.1.2.1.2\">Soft</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.1.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.1.2.1.3.1\">73.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.2.1.2.1.4\">53.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.1.2.1.5\">127.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T4.2.1.3.2.1\">Seg-Zero</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T4.2.1.3.2.2\">Strict</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.1.3.2.3\">73.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T4.2.1.3.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.1.3.2.4.1\">56.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.1.3.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.1.3.2.5.1\">129.1</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: Ablation on the format reward type. Strict format is better.", "description": "This table presents the ablation study on the format reward type used in the Seg-Zero model training.  It compares the performance of the model when using a 'soft' format reward (allowing some flexibility in the output format) versus a 'strict' format reward (requiring a precise output format). The results show that the 'strict' format reward leads to better overall performance, suggesting that enforcing a structured reasoning process is beneficial for the model's accuracy.", "section": "3. Method"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T5.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T5.2.1.1.1.1\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Reasoning Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.2.1.1.1.2\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">RefCOCOg</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.2.1.1.1.3\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">ReasonSeg</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T5.2.1.2.1.1\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Qwen2-VL-2B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.2.1.2.1.2\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">70.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.2.1.2.1.3\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">37.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.2.1.3.2.1\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Qwen2.5-VL-3B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.1.3.2.2\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">73.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.2.1.3.2.3\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">56.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T5.2.1.4.3.1\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Qwen2.5-VL-7B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.2.1.4.3.2\" style=\"padding-left:12.0pt;padding-right:12.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.2.1.4.3.2.1\">74.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.2.1.4.3.3\" style=\"padding-left:12.0pt;padding-right:12.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.2.1.4.3.3.1\">57.5</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 5: Ablation on reasoning model choice. Larger scale model achieves better performance.", "description": "This table presents the results of an ablation study investigating the impact of different reasoning model sizes on the performance of the Seg-Zero model.  The study compared three variants of the Qwen model (2B, 3B, and 7B parameters), evaluating their performance on the RefCOCOg and ReasonSeg datasets using the cIoU metric. The results demonstrate that using a larger-scale model consistently improves the overall performance, highlighting the importance of model scale in achieving better reasoning and segmentation capabilities.", "section": "4.3. Ablation Study"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T6.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T6.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.2.1.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T6.2.1.1.1.1\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\" id=\"S4.T6.2.1.1.2\">ReasonSeg</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T6.2.2.2.1\">val</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"S4.T6.2.2.2.2\">test</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.3.3.1\">gIoU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T6.2.3.3.2\">cIoU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.3.3.3\">gIoU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.3.3.4\">cIoU</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.2.4.4.1\">OVSeg</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.4.4.2\">28.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T6.2.4.4.3\">18.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.4.4.4\">26.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.4.4.5\">20.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.5.5.1\">ReLA</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.5.5.2\">22.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.5.5.3\">19.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.5.5.4\">21.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.5.5.5\">22.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.6.6.1\">Grounded-SAM</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.6.6.2\">26.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.6.6.3\">14.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.6.6.4\">21.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.6.6.5\">16.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.7.7.1\">LISA-7B-LLaVA1.5</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.7.7.2\">53.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.7.7.3\">52.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.7.7.4\">48.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.7.7.5\">48.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.8.8.1\">LISA-13B-LLaVA1.5</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.8.8.2\">57.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.8.8.3\">60.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.8.8.4\">53.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.8.8.5\">50.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.9.9.1\">SAM4MLLM</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.9.9.2\">46.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.9.9.3\">48.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.9.9.4\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.9.9.5\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.10.10.1\">Qwen2.5VL-3B+SAM2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.10.10.2\">53.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.10.10.3\">44.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.10.10.4\">47.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.10.10.5\">37.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.2.11.11.1\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.11.11.1.1\" style=\"background-color:#EFEFEF;\">Seg-Zero-3B (ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.11.11.2\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.11.11.2.1\" style=\"background-color:#EFEFEF;\">62.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T6.2.11.11.3\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.11.11.3.1\" style=\"background-color:#EFEFEF;\">58.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.11.11.4\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.11.11.4.1\" style=\"background-color:#EFEFEF;\">56.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.11.11.5\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.11.11.5.1\" style=\"background-color:#EFEFEF;\">48.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T6.2.12.12.1\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text\" id=\"S4.T6.2.12.12.1.1\" style=\"background-color:#EFEFEF;\">Seg-Zero-7B (ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T6.2.12.12.2\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.12.12.2.1\" style=\"background-color:#EFEFEF;\">62.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T6.2.12.12.3\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.12.12.3.1\" style=\"background-color:#EFEFEF;\">62.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T6.2.12.12.4\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.12.12.4.1\" style=\"background-color:#EFEFEF;\">57.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T6.2.12.12.5\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.12.12.5.1\" style=\"background-color:#EFEFEF;\">52.0</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 6: Zero-shot reasoning segmentation results.", "description": "This table presents a comparison of zero-shot reasoning segmentation results across various methods.  The metrics used are gIoU and cIoU (for both validation and test sets).  Methods compared include OVSeg, RELA, Grounded-SAM, LISA-7B-LLaVA1.5, LISA-13B-LLaVA1.5, SAM4MLLM, Qwen2.5VL-3B+SAM2 and the two versions of the authors' model Seg-Zero (using 3B and 7B parameter models). The table shows that Seg-Zero achieves state-of-the-art performance in zero-shot reasoning segmentation.", "section": "4. Comparison with Other Methods"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T7.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T7.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.2.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">refCOCO</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">refCOCO+</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">refCOCOg</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.2.2.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">testA</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.2.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">testA</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.2.2.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">test</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T7.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.2.3.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">LAVT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.2.3.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">75.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.2.3.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.2.3.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">62.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.2.4.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">ReLA</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.4.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">76.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.4.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.4.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">66.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.2.5.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">LISA-7B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.5.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">76.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.5.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">67.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.5.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.2.6.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">PixelLM-7B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.6.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">76.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.6.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.6.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.2.7.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">PerceptionGPT-7B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.7.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">78.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.7.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.7.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.2.8.6.1\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.8.6.1.1\" style=\"background-color:#EFEFEF;\">Seg-Zero-3B (ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.8.6.2\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.8.6.2.1\" style=\"background-color:#EFEFEF;\">79.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.8.6.3\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.8.6.3.1\" style=\"background-color:#EFEFEF;\">73.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.2.8.6.4\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.8.6.4.1\" style=\"background-color:#EFEFEF;\">71.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T7.2.9.7.1\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.9.7.1.1\" style=\"background-color:#EFEFEF;\">Seg-Zero-7B (ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.2.9.7.2\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.2.9.7.2.1\" style=\"background-color:#EFEFEF;\">80.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.2.9.7.3\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.2.9.7.3.1\" style=\"background-color:#EFEFEF;\">76.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.2.9.7.4\" style=\"background-color:#EFEFEF;padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.2.9.7.4.1\" style=\"background-color:#EFEFEF;\">72.6</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 7: Referring expression segmentation results. We compare the cIoU in this table.", "description": "This table presents a comparison of the performance of various referring expression segmentation models using the cIoU (complete Intersection over Union) metric.  The models compared include LAVT, RELA, LISA-7B, PixelLM-7B, PerceptionGPT-7B, and the Seg-Zero model (in both 3B and 7B variants). The comparison is done across three different datasets: refCOCO, refCOCO+, and refCOCOg, allowing for an evaluation of performance on various data splits and difficulty levels.", "section": "4. Experiment"}]