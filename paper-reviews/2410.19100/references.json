{"references": [{" publication_date": "2024", "fullname_first_author": "Rogerio Bonatti", "paper_title": "Windows agent arena: Evaluating multi-modal os agents at scale", "reason": "This paper introduces a benchmark for evaluating multimodal OS agents, which is highly relevant to the current work's focus on evaluating multimodal video agents.  The benchmark's focus on evaluating agents across diverse scenarios and operating systems provides a strong comparison point for VideoWebArena's evaluation of video-based agents.  The shared goal of pushing the boundaries of multimodal agent capabilities makes it highly relevant to the current research. ", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xiang Deng", "paper_title": "Mind2web: Towards a generalist agent for the web", "reason": "This paper presents Mind2web, a benchmark designed to evaluate the general capabilities of web agents. This work is highly relevant as it touches on several aspects that are critical to VideoWebArena: it tackles general web agent capabilities (which VideoWebArena focuses on within a specific video context), and it addresses the importance of multimodal understanding in navigating and completing complex web tasks.  These shared concerns make it a valuable comparison and related work for the proposed benchmark.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Alexandre Drouin", "paper_title": "WorkArena: How capable are web agents at solving common knowledge work tasks?", "reason": "This paper introduces WorkArena, a benchmark specifically designed for evaluating agents in a knowledge work setting using the ServiceNow platform.  This is highly relevant to VideoWebArena because it highlights the broader context of agent evaluation in professional settings.  The focus on complex tasks and real-world applications adds value to the discussion of VideoWebArena and its potential.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yunhao Fang", "paper_title": "VILA2: Vila augmented vila", "reason": "This paper builds upon prior research, and directly improves upon a model that is relevant to VideoWebArena. It demonstrates advancements in the Video-based Interaction Language Agent (VILA) model, which is directly relevant to the area VideoWebArena targets: creating comprehensive evaluations for models' long-context video understanding capabilities.  The direct connection to VILA establishes a clear lineage and contextual relevance to the advancement of multimodal understanding and agent capabilities.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yao Fu", "paper_title": "Autoguide: Automated generation and selection of state-aware guidelines for large language model agents", "reason": "This paper focuses on improving the performance of large language model agents through automated generation of guidelines tailored to specific tasks.  This is highly relevant to VideoWebArena because it addresses the challenge of improving agent abilities, particularly when dealing with complex video-based tasks.  The strategies for enhancing performance via intelligent guidance are directly applicable to the evaluation and improvement of agents in VideoWebArena.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Hiroki Furuta", "paper_title": "Multimodal web navigation with instruction-finetuned foundation models", "reason": "This paper explores multimodal web navigation using instruction-finetuned models, directly relevant to the core objective of VideoWebArena. The use of multimodal models and navigation tasks highlights the shared goal of creating robust and efficient agents capable of operating in complex environments. The focus on finetuning instruction models is especially valuable for creating effective and efficient agents within VideoWebArena's framework.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Google", "paper_title": "Gemini: A family of highly capable multimodal models", "reason": "This paper introduces the Gemini family of multimodal models, which are directly relevant to VideoWebArena's evaluation. Gemini is one of the most powerful models used in the baseline agents' evaluation, so any research on this powerful family of models is relevant to assessing the state-of-the-art in video understanding. Its comprehensive capabilities are compared to the performance of the VideoWebArena benchmark.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jing Yu Koh", "paper_title": "Visualwebarena: Evaluating multimodal agents on realistic visual web tasks", "reason": "This paper introduces VisualWebArena, a benchmark directly related to VideoWebArena. As a foundational benchmark, VisualWebArena directly informs the design and scope of VideoWebArena, serving as a basis for comparison and expansion into the realm of long-context video understanding.  The shared focus on evaluating agentic capabilities in visual web tasks creates a strong foundation for understanding the contributions of VideoWebArena.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Hanyu Lai", "paper_title": "Autowebglm: Bootstrap and reinforce a large language model-based web navigating agent", "reason": "This paper presents AutoWebGLM, a method for bootstrapping and reinforcing large language models (LLMs) as web navigating agents, a closely related area to VideoWebArena's focus on creating robust video-capable agents.  The method's focus on improving agent performance through reinforcement and iterative learning is highly relevant to the challenges in developing and evaluating effective agents for long-context video understanding, as highlighted by the benchmark in this work.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Jie Lei", "paper_title": "Tvqa: Localized, compositional video question answering", "reason": "This paper introduces TVQA, a benchmark for evaluating video question-answering capabilities. This is highly relevant to VideoWebArena because it addresses the challenge of evaluating video understanding performance within a task-oriented setting.  The focus on video understanding and question answering directly relates to the evaluation of factual retention in VideoWebArena, providing insights and context for the development of robust evaluation metrics.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kunchang Li", "paper_title": "Mvbench: A comprehensive multi-modal video understanding benchmark", "reason": "This work introduces MvBench, a comprehensive benchmark for multimodal video understanding.  The focus on multimodal understanding and video comprehension is highly relevant to VideoWebArena, as it provides context and comparison for evaluating long-context video understanding capabilities.  The insights gained from MvBench's thorough evaluation of various aspects of multimodal video understanding provide valuable context for interpreting the performance of agents within the VideoWebArena framework.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Karttikeya Mangalam", "paper_title": "Egoschema: A diagnostic benchmark for very long-form video language understanding", "reason": "This paper introduces EgoSchema, a benchmark focusing on long-form video language understanding.  The benchmark's focus on long-form video directly addresses the challenge of evaluating long-context video understanding, a core theme in VideoWebArena.  The shared focus on challenging the capabilities of models in processing extended video sequences establishes a clear connection and provides valuable context for evaluating the performance and capabilities of agents within the VideoWebArena framework.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Ajay Patel", "paper_title": "Large language models can self-improve at web agent tasks", "reason": "This paper explores the self-improvement capabilities of large language models (LLMs) in web agent tasks, a topic closely related to VideoWebArena's focus on improving agent performance. The methods of self-improvement and reinforcement learning are directly relevant to the challenges in developing and evaluating effective agents for long-context video understanding.  The insights into self-improvement strategies can provide valuable information for future development of VideoWebArena.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Viorica P\u0103tr\u0103ucean", "paper_title": "Perception test: A diagnostic benchmark for multimodal video models", "reason": "This paper introduces Perception Test, a benchmark for multimodal video models focusing on diagnostic capabilities, which is relevant to the work because it emphasizes the detailed analysis of model performance and identification of failure modes.  The shared focus on understanding model performance within a video-based task framework is highly relevant, and the approaches to diagnostic evaluation provide valuable context for evaluating the effectiveness of agents within VideoWebArena.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents", "reason": "This paper introduces AndroidWorld, a benchmark for evaluating autonomous agents in a mobile environment.  While the context differs from VideoWebArena (which focuses on web-based tasks), the core concept of evaluating agents across various environments and challenges is highly relevant.  The approaches to creating a dynamic and challenging evaluation environment offer insights and inspiration for improving the robustness and generality of VideoWebArena's benchmark.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Gabriel Sarch", "paper_title": "ICAL: Continual learning of multimodal agents by transforming trajectories into actionable insights", "reason": "This paper presents ICAL, a method for continual learning of multimodal agents that focuses on transforming trajectories into actionable insights.  This is directly relevant to VideoWebArena because it addresses the challenge of improving agent performance in dynamic and long-context scenarios.  The focus on continual learning and actionable insights offers valuable perspectives for designing and evaluating agents that operate effectively in complex video-based environments.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Zora Zhiruo Wang", "paper_title": "Agent workflow memory", "reason": "This paper explores agent workflow memory, a critical aspect of long-context video understanding.  VideoWebArena explicitly addresses long-context video tasks, and the study of workflow memory directly addresses challenges related to maintaining context and information over long sequences.  The insights into effective memory management are directly relevant for improving agent performance in VideoWebArena's challenging tasks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Haoning Wu", "paper_title": "Longvideobench: A benchmark for long-context interleaved video-language understanding", "reason": "This paper introduces LongVideoBench, a benchmark focused on long-context video-language understanding.  This benchmark directly relates to the core focus of VideoWebArena, specifically addressing the need for benchmarks that effectively evaluate the capabilities of models in handling long sequences of video data.  The shared interest in understanding long-context video understanding makes it a highly relevant related work for informing and evaluating the VideoWebArena benchmark.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Fuzhao Xue", "paper_title": "Longvila: Scaling long-context visual language models for long videos", "reason": "This paper introduces LongVILA, a model explicitly designed for long-context video understanding.  LongVILA directly addresses the challenge of processing and understanding long video sequences, a core problem that VideoWebArena aims to address through its benchmark. The use of this model in the evaluation highlights the importance of long-context video understanding and provides valuable context for evaluating the capabilities of agents within the VideoWebArena framework.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jianwei Yang", "paper_title": "Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v", "reason": "This paper focuses on improving visual grounding capabilities in large language models using a specific prompting technique.  The focus on improving visual grounding is directly relevant to VideoWebArena, as it addresses the challenge of effectively integrating visual information from video into the task completion process.  The insights into effective prompting techniques are also valuable for designing and evaluating agents in VideoWebArena.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Shunyu Yao", "paper_title": "Webshop: Towards scalable real-world web interaction with grounded language agents", "reason": "This paper introduces WebShop, a benchmark focusing on real-world web interaction with grounded language agents, which is related to VideoWebArena's evaluation of web-based video agents.  The focus on real-world interaction and grounded language understanding highlights the shared challenges and goals in creating robust and efficient multimodal agents.  The insights into real-world agent performance are highly relevant for understanding and improving VideoWebArena's evaluation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Ziniu Zhang", "paper_title": "Mmina: Benchmarking multihop multimodal internet agents", "reason": "This paper introduces MMInA, a benchmark for evaluating multihop multimodal internet agents, which is highly relevant to VideoWebArena's focus on creating benchmarks for multimodal video agents. The shared focus on evaluating agent capabilities in complex multimodal scenarios highlights the importance of comprehensive evaluation in understanding the performance of these agents. The insights into the challenges of evaluating multi-hop reasoning and complex interactions provide valuable context for designing effective evaluation metrics in VideoWebArena.", "section_number": 2}]}