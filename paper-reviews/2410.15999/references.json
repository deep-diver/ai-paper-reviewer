{"references": [{" publication_date": "2019", "fullname_first_author": "Fabio Petroni", "paper_title": "Language models as knowledge bases?", "reason": "This paper is foundational for the current work as it establishes the concept of LLMs as knowledge bases, a key aspect of the research. The authors demonstrate that LLMs can store and retrieve factual knowledge. This work is crucial because the current research explores how to address conflicts when this factual knowledge is inaccurate or incomplete.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is highly influential as it establishes the foundation for understanding the capabilities and limitations of large language models (LLMs). The authors show that LLMs can perform various tasks with minimal examples which shows how LLMs can be a useful tool for various tasks but may also suffer from inaccuracies and inconsistencies.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "This paper introduces Llama 2, one of the LLMs used in the current study, providing the experimental base. The authors present the architecture and performance of Llama 2, which is relevant because the current study evaluates the effectiveness of a new method on this specific LLM model.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Albert Q Jiang", "paper_title": "Mistral 7b", "reason": "This paper introduces another LLM model, Mistral 7B, used in the experiments. Providing another experimental base, this is significant because the current work assesses the robustness and generalizability of their method across different LLMs.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Rongwu Xu", "paper_title": "Knowledge conflicts for LLMs: A survey", "reason": "This paper provides a comprehensive overview of the challenges posed by knowledge conflicts in LLMs, a central theme of the current research. The authors identify various types of knowledge conflicts and discuss existing approaches to resolve them, which is useful for providing background and context for the current research.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Vladimir Karpukhin", "paper_title": "Dense passage retrieval for open-domain question answering", "reason": "This paper is important because it introduces retrieval-augmented generation, a technique that directly addresses the challenges of inaccurate or outdated knowledge in LLMs, and is very relevant to the current research since it examines a representation engineering approach to improve knowledge selection in LLMs.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Patrick Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks", "reason": "This paper is highly relevant as it explores the combination of retrieval and generation methods for knowledge-intensive tasks.  This approach is closely related to the current research's focus on improving knowledge selection and handling conflicts between context and internal knowledge in LLMs. This hybrid approach is relevant to the current work.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Shayne Longpre", "paper_title": "Entity-based knowledge conflicts in question answering", "reason": "This paper is crucial because it introduces the concept of entity-based knowledge conflicts in question answering tasks. This concept is central to the current work as the researchers focus on resolving context-memory knowledge conflicts in open-domain question-answering. This work is directly related to the current paper.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Nelson Elhage", "paper_title": "A mathematical framework for transformer circuits", "reason": "This paper is foundational for understanding the internal workings of transformer models. This is important because the current research leverages the internal activations of LLMs to detect and resolve knowledge conflicts, and the current work uses transformer LLMs.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Leo Gao", "paper_title": "Scaling and evaluating sparse autoencoders", "reason": "This paper is highly relevant because it provides a comprehensive evaluation of sparse autoencoders (SAEs), the key component of the proposed method. The authors present the results and limitations of SAEs.  Their research is directly related to the current work because SAEs are used to enhance the efficiency and interpretability of the knowledge selection process.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Trenton Bricken", "paper_title": "Towards monosemanticity: Decomposing language models with dictionary learning", "reason": "This is highly relevant to the current research because it focuses on decomposing language model representations into more interpretable components using techniques like dictionary learning, which is closely related to the use of Sparse Autoencoders (SAEs) in the proposed method.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Alexis Conneau", "paper_title": "What you can cram into a single vector: Probing sentence embeddings for linguistic properties", "reason": "This paper introduces the linear probing method, used in the current work for detecting knowledge conflicts.  The authors demonstrate its effectiveness in assessing linguistic properties using sentence embeddings. The current paper uses linear probing to detect signals indicating knowledge conflicts.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Zeyuan Allen-Zhu", "paper_title": "Physics of language models: Part 1, context-free grammar", "reason": "This paper provides a theoretical framework for understanding the behaviour of LLMs, which is relevant to the current work as it explains the internal mechanics of LLMs. Understanding the internal structure of LLMs is important because the current work aims to modify their internal representations to control knowledge selection.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Trenton Bricken", "paper_title": "Towards monosemanticity: Decomposing language models with dictionary learning", "reason": "This paper introduces the concept of monosemanticity and shows how to decompose language models using dictionary learning. This is highly relevant to the current research as it directly relates to the use of sparse autoencoders (SAEs) for interpreting LLM representations.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Leo Gao", "paper_title": "Scaling and evaluating sparse autoencoders", "reason": "This paper is highly relevant because it provides a detailed analysis of sparse autoencoders (SAEs) and their properties, which are crucial for understanding the proposed method. The evaluation provides benchmarks and insights into the performance of SAEs, helping to justify their use in the proposed method.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Roee Hendel", "paper_title": "In-context learning creates task vectors", "reason": "This paper is highly relevant as it introduces the concept of task vectors, which are closely related to the functional features identified in the current research. The authors show that in-context learning creates task vectors, and this is very relevant to the current research because it provides evidence for the hypothesis that certain activations can control knowledge selection.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Yung-Sung Chuang", "paper_title": "DoLa: Decoding by contrasting layers improves factuality in large language models", "reason": "This paper proposes contrastive decoding as a method for improving factuality in LLMs.  It is a relevant baseline for comparison in the experimental section of the current paper because contrastive decoding methods are often used to address knowledge conflicts. This provides another baseline to compare the performance of the method.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Weijia Shi", "paper_title": "Trusting your evidence: Hallucinate less with context-aware decoding", "reason": "This paper introduces another contrastive decoding method which is another relevant baseline for comparison in the experimental section of the current paper. The researchers focus on context-aware decoding and show its effect on hallucination which is another competing method.", "section_number": 5}, {" publication_date": "2020", "fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is important as a baseline for comparison in the experimental section of the current research because it establishes the capabilities and limitations of large language models in few-shot learning.  This paper demonstrates that LLMs can perform various tasks with minimal examples, which is a relevant baseline to compare the method against.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Timo Schick", "paper_title": "Toolformer: Language models can teach themselves to use tools", "reason": "This paper is highly relevant as it presents a method for enhancing LLMs with external tools. It serves as a relevant comparison for the current research because it demonstrates an approach to enhancing LLMs by providing them with external knowledge, which is closely related to the current research's representation engineering method.", "section_number": 5}]}