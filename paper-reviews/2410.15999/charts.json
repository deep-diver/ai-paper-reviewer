[{"figure_path": "2410.15999/charts/charts_3_0.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores for knowledge conflict detection across different layers and activation types in Llama2-7B and Gemma2-9B models.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_7_0.png", "caption": "Figure 4: Detailed evaluation results of controlling capability on NQSwap. We use different colours for different methods and use different shapes for different models. The upper-right area indicates a high performance for all figures. (a) presents the capability of changing the behaviour of LLMs, where x-axis and y-axis are EMC\u2192M and EMM\u2192C, measuring the capability of changing the answer from C to M and from M to C, respectively; (b) presents the capability of maintaining the behaviour when steering to the same behaviour as the original behaviour, where x-axis and y-axis are EMM\u2192M and EMC\u2192C, measuring the maintaining capability of generating M and C, respectively; (c) present the ablation analysis of SPARE, x-axis and y-axis are EMM and EMC.", "description": "Figure 4 shows a multi-faceted evaluation of SPARE and other methods' capabilities in controlling LLM behavior, focusing on changing and maintaining knowledge selection.", "section": "5.3 Multi-Perspective Controlling Analysis"}, {"figure_path": "2410.15999/charts/charts_8_0.png", "caption": "Figure 5: Effectiveness of SPARE on editing different layers individually.", "description": "The chart displays the effectiveness of SPARE in controlling the knowledge selection behavior of LLMs when editing different layers individually, showing performance variations across different layers.", "section": "6.1 Analysing the Layer Choice"}, {"figure_path": "2410.15999/charts/charts_8_1.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the knowledge conflict probing results for Llama2-7B and Gemma2-9B models on the NQSwap dataset, showing the accuracy of detecting knowledge conflicts across different layers and activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_8_2.png", "caption": "Figure 6: The residual stream changes after applying SPARE to Llama3-8B at the 15th layer.", "description": "The chart displays the AUROC and kurtosis of the residual stream for Llama3-8B on the NQSwap dataset with and without applying SPARE, showing how SPARE changes the representation to guide knowledge selection.", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_14_0.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores achieved by a linear probing method to classify knowledge conflicts in different layers of Llama2-7B and Gemma2-9B.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_14_1.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores for detecting knowledge conflicts in Llama2-7B and Gemma2-9B across different layers and activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_14_2.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores achieved when probing different layers of Llama2-7B and Gemma2-9B LLMs for the ability to detect knowledge conflicts.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_14_3.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the accuracy of detecting knowledge conflicts in LLMs across different layers and activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_14_4.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores for detecting knowledge conflicts in different layers of Llama2-7B and Gemma2-9B language models, broken down by activation type (hidden, MLP, and attention).", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_14_5.png", "caption": "Figure 8: Knowledge conflict probing results using Llama2-7B on NQSwap.", "description": "The chart displays the AUPRC scores for knowledge conflict probing across different layers and activation types (hidden, mlp, attn) in the Llama2-7B model on the NQSwap dataset.", "section": "A More Analysis of Knowledge Conflict Probing"}, {"figure_path": "2410.15999/charts/charts_16_0.png", "caption": "Figure 10: The impact of the number of the collected hidden states N on the controlling performance.", "description": "The chart displays the performance of the controlling capability of SPARE in relation to the number of hidden states used for calculating the functional activations.", "section": "C Implementation Details"}, {"figure_path": "2410.15999/charts/charts_19_0.png", "caption": "Figure 11: Proportion of accumulated mutual Information (K) on Gemma2-9B", "description": "The chart shows the relationship between the proportion of accumulated mutual information and the number of selected activations for different layers of the Gemma2-9B model.", "section": "E Distribution of Mutual Information"}, {"figure_path": "2410.15999/charts/charts_19_1.png", "caption": "Figure 11: Proportion of accumulated mutual Information (K) on Gemma2-9B", "description": "The chart displays the relationship between the proportion of accumulated mutual information and the number of selected activations for different layers (23, 24, and 25) in the Gemma2-9B model.", "section": "E Distribution of Mutual Information"}, {"figure_path": "2410.15999/charts/charts_19_2.png", "caption": "Figure 11: Proportion of accumulated mutual Information (K) on Gemma2-9B", "description": "The chart shows the relationship between the proportion of accumulated mutual information and the number of selected activations for Gemma2-9B across different layers.", "section": "E Distribution of Mutual Information"}, {"figure_path": "2410.15999/charts/charts_19_3.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the AUROC scores for knowledge conflict detection in different layers of Llama2-7B and Gemma2-9B models using various activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_19_4.png", "caption": "Figure 16: Skewness of the MLP activation of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of MLP activations for Llama2-7B on the NQSwap dataset, differentiating between instances where the model uses parametric knowledge (DM) and contextual knowledge (DC).", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_19_5.png", "caption": "Figure 19: L1 norm and L2 norm of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the L1 and L2 norm values of the hidden states of Llama2-7B model on the NQSwap dataset, categorized by whether the model uses contextual or parametric knowledge.", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_19_6.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the results of probing experiments to detect knowledge conflicts in LLMs, showing that the accuracy of detection increases in the middle layers of the model across different activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_19_7.png", "caption": "Figure 14: Skewness of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of hidden states across layers for Llama2-7B on the NQSwap dataset, differentiating between instances where the model uses parametric knowledge (DM) versus contextual knowledge (DC).", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_19_8.png", "caption": "Figure 14: Skewness of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of hidden states across different layers in Llama2-7B model for two groups of instances (DM and Dc) on NQSwap dataset.", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_20_0.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the results of probing experiments to detect knowledge conflicts in Llama2-7B and Gemma2-9B models across different layer types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_20_1.png", "caption": "Figure 14: Skewness of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of the hidden states of Llama2-7B model when generating answers using either parametric knowledge (DM) or contextual knowledge (DC) in the NQSwap dataset.", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_20_2.png", "caption": "Figure 19: L1 norm and L2 norm of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the L1 and L2 norms of the hidden states for Llama2-7B model on the NQSwap dataset, categorized by whether the model uses parametric knowledge (DM) or contextual knowledge (DC).", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_20_3.png", "caption": "Figure 2: The knowledge conflict probing results of Llama2-7B and Gemma2-9B on NQSwap (Longpre et al., 2021). The probing results on hidden states, MLP and Self-Attention activations are coloured differently.", "description": "The chart displays the results of probing experiments to detect knowledge conflicts in Llama2-7B and Gemma2-9B LLMs on the NQSwap dataset, showing the AUROC scores across different layers and activation types.", "section": "3 Detection of Knowledge Conflicts"}, {"figure_path": "2410.15999/charts/charts_20_4.png", "caption": "Figure 14: Skewness of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of hidden states for Llama2-7B model on the NQSwap dataset, differentiating between instances where the model uses parametric knowledge (DM) versus contextual knowledge (DC) to generate answers.", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_20_5.png", "caption": "Figure 14: Skewness of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the skewness of hidden states for Llama2-7B model on the NQSwap dataset, differentiating between instances where the model uses parametric knowledge (DM) versus contextual knowledge (Dc).", "section": "6.2 Analysing the Residual Stream"}, {"figure_path": "2410.15999/charts/charts_20_6.png", "caption": "Figure 19: L1 norm and L2 norm of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the L1 and L2 norms of the hidden states of the Llama2-7B model on the NQSwap dataset, categorized by whether the model used parametric knowledge (DM) or contextual knowledge (DC) to generate its answers.", "section": "5.3 Multi-Perspective Controlling Analysis"}, {"figure_path": "2410.15999/charts/charts_20_7.png", "caption": "Figure 19: L1 norm and L2 norm of the hidden states of Llama2-7B on NQSwap.", "description": "The chart displays the L1 and L2 norms of the hidden states for Llama2-7B model on the NQSwap dataset, differentiating between instances where the model selects parametric knowledge (DM) versus contextual knowledge (DC).", "section": "5.3 Multi-Perspective Controlling Analysis"}]