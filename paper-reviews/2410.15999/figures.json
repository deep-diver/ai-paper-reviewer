[{"figure_path": "2410.15999/figures/figures_1_0.png", "caption": "Figure 1: In the event of a knowledge conflict, the model can rely on the context or on the parametric knowledge. The figure presents the predictions of Llama2-7B steered by SPARE.", "description": "The figure shows two examples of how SPARE steers Llama2-7B to use either context or memory when there is a knowledge conflict.", "section": "Introduction"}, {"figure_path": "2410.15999/figures/figures_4_0.png", "caption": "Figure 3: The workflow of SPARE steers the knowledge selection behaviour. The figure presents an example of steering the model to use parametric knowledge. First, the SAE encoder fe encodes hidden state h into the SAE activation z. Then, it determines the values of SAE activations z\u00af and z+ for editing (Eq. (2) and Eq. (3)). Finally, we edit the hidden state using the features extracted from the SAE decoder go (Eq. (4)).", "description": "The figure illustrates the process of SPARE, showing how it uses sparse autoencoders to identify and edit activations to control knowledge selection behaviours in LLMs.", "section": "Resolving Knowledge Conflicts by Representation Engineering"}]