[{"figure_path": "2410.15999/figures/figures_1_0.png", "caption": "Figure 1: In the event of a knowledge conflict, the model can rely on the context or on the parametric knowledge. The figure presents the predictions of Llama2-7B steered by SPARE.", "description": "The figure shows two examples of how SPARE steers Llama2-7B to use either contextual or parametric knowledge when there is a knowledge conflict.", "section": "1 Introduction"}, {"figure_path": "2410.15999/figures/figures_4_0.png", "caption": "Figure 3: The workflow of SPARE steers the knowledge selection behaviour. The figure presents an example of steering the model to use parametric knowledge. First, the SAE encoder fe encodes hidden state h into the SAE activation z. Then, it determines the values of SAE activations z\u00af and z+ for editing (Eq. (2) and Eq. (3)). Finally, we edit the hidden state using the features extracted from the SAE decoder go (Eq. (4)).", "description": "The figure illustrates the workflow of the Sparse Auto-Encoder-based Representation Engineering (SPARE) method for steering knowledge selection behaviors in LLMs by editing the hidden states using features extracted from sparse auto-encoders.", "section": "Resolving Knowledge Conflicts by Representation Engineering"}]