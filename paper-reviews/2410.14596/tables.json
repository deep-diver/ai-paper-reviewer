[{"figure_path": "2410.14596/tables/table_6_0.html", "caption": "Table 1: Rate at which models adopt misinformation across different datasets (lower is better). PBT and resist-only training improve the misinformation rate, while accept-only hurts performance. Other models in Table 5.", "description": "Table 1 presents the rate at which different language models adopt misinformation across various datasets, comparing the performance of models trained with persuasion-balanced training (PBT), resist-only training, accept-only training, and no training.", "section": "4.1 RQ1: Resisting Negative Persuasion"}, {"figure_path": "2410.14596/tables/table_6_1.html", "caption": "Table 2: Flipflopping evaluation using Laban et al. (2023)'s \"Are you sure?\" prompt. PBT leads to less flipflopping. Full results in Appendix A.", "description": "Table 2 shows the accuracy of different models using the \u201cAre you sure?\u201d prompt from Laban et al. (2023), measuring the rate at which models flip their answers when challenged.", "section": "4.1 RQ1: Resisting Negative Persuasion"}, {"figure_path": "2410.14596/tables/table_6_2.html", "caption": "Table 3: Accuracy on balanced persuasion data, where half of the examples involve flipping a correct answer to an incorrect one (+ \u2192 -) and the other half involve flipping an incorrect answer to a correct one (- \u2192 +). Resist-only training leads to low accuracy on \u2192 +, while combined training leads to the best overall results.", "description": "Table 3 presents the accuracy of different models on a balanced dataset containing both positive and negative persuasion examples, showing the effect of different training methods on the model's ability to both resist and accept persuasion.", "section": "4.2 RQ2: Addressing Positive Persuasion"}, {"figure_path": "2410.14596/tables/table_8_0.html", "caption": "Table 1: Rate at which models adopt misinformation across different datasets (lower is better). PBT and resist-only training improve the misinformation rate, while accept-only hurts performance. Other models in Table 5.", "description": "Table 1 presents the rate at which different language models adopt misinformation across four datasets, comparing the performance of models trained with Persuasion-Balanced Training (PBT), resist-only training, accept-only training, and a baseline model.", "section": "4.1 RQ1: Resisting Negative Persuasion"}, {"figure_path": "2410.14596/tables/table_9_0.html", "caption": "Table 1: Rate at which models adopt misinformation across different datasets (lower is better). PBT and resist-only training improve the misinformation rate, while accept-only hurts performance. Other models in Table 5.", "description": "Table 1 presents the rate of misinformation adoption by different language models across various datasets, comparing the performance of models trained with PBT, resist-only, accept-only, and base training methods.", "section": "4.1 RQ1: Resisting Negative Persuasion"}, {"figure_path": "2410.14596/tables/table_12_0.html", "caption": "Table 1: Rate at which models adopt misinformation across different datasets (lower is better). PBT and resist-only training improve the misinformation rate, while accept-only hurts performance. Other models in Table 5.", "description": "Table 1 presents the rate at which different language models adopt misinformation across various datasets, comparing the performance of models trained with different methods (PBT, resist-only, accept-only).", "section": "4.1 RQ1: Resisting Negative Persuasion"}, {"figure_path": "2410.14596/tables/table_12_1.html", "caption": "Table 2: Flipflopping evaluation using Laban et al. (2023)'s \u201cAre you sure?\u201d prompt. PBT leads to less flipflopping. Full results in Appendix A.", "description": "Table 2 presents the accuracy of different models using Laban et al. (2023)'s \"Are you sure?\" prompt to measure the rate of flip-flopping, showing PBT leads to less flip-flopping.", "section": "4.1 RQ1: Resisting Negative Persuasion"}]