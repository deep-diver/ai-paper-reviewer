{"references": [{"fullname_first_author": "Stephen Bach", "paper_title": "PromptSource: An integrated development environment and repository for natural language prompts", "publication_date": "2022-00-00", "reason": "This paper introduces PromptSource, a crucial resource for managing and sharing prompts, directly relevant to the TIP-I2V dataset's focus on prompt analysis and generation in the visual domain."}, {"fullname_first_author": "Max Bain", "paper_title": "Frozen in time: A joint video and image encoder for end-to-end retrieval", "publication_date": "2021-00-00", "reason": "This paper presents a method for joint video and image encoding, relevant to the TIP-I2V dataset's task of utilizing image prompts for video generation."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper describes Stable Video Diffusion, one of the core models used to generate videos in the TIP-I2V dataset, directly impacting the dataset's composition and quality."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-10-19", "reason": "Videocrafter1, presented in this paper, is another key model for video generation in the TIP-I2V dataset, influencing the dataset's scope and capabilities."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-00-00", "reason": "This paper addresses the challenges and limitations in video diffusion model development, providing valuable context to the creation and limitations of the TIP-I2V dataset."}]}