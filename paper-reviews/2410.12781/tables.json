[{"figure_path": "2410.12781/tables/table_8_0.html", "caption": "Table 1: Quantitative comparison to 3D Gaussian splatting optimization. \u2018Feed-forward\u2019 column indicates whether the method performs zero-shot feed-forward prediction. \u2018Time\u2019 refers to the total inference/optimization time for all views in the test split for each scene. The image resolution is 960 \u00d7 540.", "description": "Table 1 quantitatively compares Long-LRM's performance against optimization-based 3D Gaussian splatting in terms of reconstruction quality (PSNR, SSIM, LPIPS), inference speed, and whether the approach is feed-forward.", "section": "4.3 RESULTS"}, {"figure_path": "2410.12781/tables/table_9_0.html", "caption": "Table 2: Ablation studies on model architecture. We study how the model architecture affects training time and memory efficiency as well as the reconstruction quality. All variants have 24 blocks in total. {7M1T} \u00d7 3 refers to our \"7 Mamba2 blocks + 1 Transformer block, repeating 3 times\" model architecture. @9 means the token merging happens at the beginning of the 9th block. Models are trained on DL3DV-10K and evaluated on DL3DV-140 Benchmark. *The 512-resolution models are finetuned from the checkpoints of their 256-resolution counterparts, and the 960-resolution from the 512-resolution checkpoints.", "description": "Table 2 shows the ablation study on model architecture variants, comparing training time, memory usage, and reconstruction quality across different configurations.", "section": "5.1 ABLATION STUDIES OF MODEL DESIGNS"}, {"figure_path": "2410.12781/tables/table_10_0.html", "caption": "Table 3: Ablation studies on training objectives. We study how the opacity loss and the depth supervision affect the reconstruction quality as well as the Gaussian usage.", "description": "Table 3 shows the ablation study of different loss functions on the reconstruction quality and Gaussian usage, demonstrating the impact of opacity loss and depth supervision.", "section": "5.2 ABLATION STUDIES OF TRAINING OBJECTIVES"}, {"figure_path": "2410.12781/tables/table_10_1.html", "caption": "Table 4: Gaussian usage impacted by opacity loss and input size. We observe the opacity loss can effectively reduce the number of visible Gaussians, and our model learns to adapt to a more compact set of Gaussians when the input views get denser.", "description": "Table 4 shows the impact of the opacity loss and input image size on the percentage of Gaussians with opacity greater than 0.001, demonstrating the effectiveness of the opacity loss in reducing the number of Gaussians while maintaining reconstruction quality and adapting to different input densities.", "section": "5.2 ABLATION STUDIES OF TRAINING OBJECTIVES"}]