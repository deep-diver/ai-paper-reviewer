[{"page_end_idx": 2, "page_start_idx": 1, "section_number": 1, "section_title": "Introduction", "details": {"details": "Autonomous planning has been a long-standing pursuit in artificial intelligence. Early planning agents, based on curated problem solvers, provided precise solutions for specific tasks but lacked generalization. The advent of Large Language Models (LLMs) and their powerful reasoning capabilities has renewed interest in autonomous planning due to the potential for automatically generating reasonable solutions for various tasks.  However, current research and experimental evidence indicate that language agents still fall short of human-level planning abilities.  Even state-of-the-art models like OpenAI's model achieve a low success rate (only 15.6% on a complex real-world benchmark) highlighting a critical need to understand the barriers preventing human-level planning performance by language agents. While some studies have pointed to weak agent planning, the underlying issues, mechanisms, and limitations of proposed strategies remain insufficiently understood. This paper aims to address this gap in understanding by investigating the key factors hindering planning performance.", "first_cons": "Current language agents demonstrate significantly weak performance in planning tasks, even failing to reach 20% success rate on a real-world benchmark, falling far short of human-level capabilities.", "first_pros": "The introduction clearly establishes the context and importance of autonomous planning research, highlighting the limitations of existing approaches and the potential of LLMs to revolutionize the field.", "keypoints": ["Autonomous planning is a long-standing AI pursuit.", "Early planning agents lacked generalization despite precise solutions for specific tasks.", "LLMs offer a new approach to autonomous planning, but current agents underperform.", "OpenAI's state-of-the-art model only achieves 15.6% success on a real-world benchmark.", "The underlying reasons for this underperformance and limitations of current strategies are poorly understood."], "second_cons": "While the introduction highlights the problem, it does not offer concrete solutions or propose a specific methodology for addressing the challenges.  It primarily sets the stage for the later investigation.", "second_pros": "The introduction effectively presents a compelling research question focusing on the gap between current language agent planning capabilities and human-level performance, setting a clear objective for the subsequent investigation.", "summary": "This paper introduces the long-standing challenge of autonomous planning in AI, highlighting the limitations of traditional methods and the potential, yet unrealized, of LLMs.  It emphasizes the significant performance gap between current language agents and human-level planning ability, even with state-of-the-art models achieving only 15.6% success rate on a benchmark task. This paper aims to investigate the root causes of this underperformance and the effectiveness of existing strategies to address these limitations."}}, {"page_end_idx": 3, "page_start_idx": 2, "section_number": 2, "section_title": "Related Work", "details": {"details": "This section, \"Related Work,\" provides background on language agents and planning in AI.  It begins by discussing the rise of language agents, which leverage large language models (LLMs) to interact with the world, including using tools, understanding environments, and controlling robots.  These agents are seen as an improvement over previous task-specific planning systems due to their flexibility and ability to generalize across different tasks. However,  despite LLMs' impressive capabilities in various areas, their application to planning remains suboptimal; even top models achieve less than 20% success on real-world planning benchmarks.  The section then delves into the specific role of language in planning, explaining how the ability to plan is crucial for an agent's overall intelligence and performance across multiple tasks.  It notes that while significant progress has been made in improving LLM-based planning, there is a still a substantial gap between what agents can achieve and human-level performance, particularly in dealing with complex scenarios and dynamic constraints. The section concludes by highlighting the challenges of interpreting and understanding LLMs' thinking processes, which are often opaque and require sophisticated techniques like attention visualization and feature attribution methods to be analyzed.", "first_cons": "The section primarily focuses on the limitations of language agents in planning without proposing concrete, novel solutions to address these challenges.", "first_pros": "The section accurately summarizes the state-of-the-art in language agents for planning, highlighting the gap between current capabilities and human-level performance.", "keypoints": ["Language agents, powered by LLMs, offer a more general approach to planning than previous task-specific systems.", "Despite advancements, language agents significantly underperform humans on complex planning benchmarks; even top models like OpenAI's achieve only around 15.6% accuracy on some real-world tasks.", "Three main approaches exist to improve language agent planning: episodic memory updating, parametric memory updating, and translating queries into formal planning languages for external solver resolution.", "The opacity of LLMs' reasoning processes presents a key challenge; techniques like feature attribution are crucial for understanding the factors hindering planning.", "Constraints and questions are fundamental components of planning, yet current agents demonstrate limited understanding and utilization of both."], "second_cons": "The discussion on interpretability methods is brief and lacks depth. While it mentions techniques like attention visualization and feature attribution, it does not provide detailed examples or analyses of their application in planning tasks.", "second_pros": "The categorization of planning strategies into episodic and parametric memory updating, and formal language translation, provides a clear structure for understanding existing approaches.", "summary": "This section reviews the current state of language agents in AI planning, highlighting the significant gap between their capabilities and human-level performance. It examines the role of language in planning, categorizes existing improvement strategies (episodic and parametric memory updates, and formal language translation), and underscores the challenge of interpreting LLMs' decision-making processes, particularly their limited understanding of constraints and the diminishing influence of questions as planning complexity increases.  It concludes by highlighting the need for more research into interpreting LLMs to unlock the full potential of language agents in planning."}}, {"page_end_idx": 4, "page_start_idx": 3, "section_number": 3, "section_title": "Background", "details": {"details": "This section lays the groundwork for the study by detailing the datasets used, explaining the Permutation Feature Importance method, and describing the experimental setup.  The datasets chosen are Blocks World, a classical planning benchmark with explicit constraints, and TravelPlanner, a more complex, real-world travel planning benchmark with dynamic, implicit constraints. The Permutation Feature Importance method is chosen as the analysis strategy for evaluating feature importance because it allows for direct testing of the impact of features on the final plan without assumptions. The experimental setup details the data splits for training and validation, how episodic and parametric memory updating strategies are implemented, and the computational resources used (including 8x A100 GPUs for some experiments). The setup also clarifies the use of both supervised fine-tuning (SFT) for parametric memory updating and human-written insights, including Behavioral Cloning and Oracle feedback, for episodic memory updating, emphasizing the approach to ensure consistency and control in the analysis.", "first_cons": "The description of the experimental setup, while detailed, could benefit from a clearer explanation of the differences in the implementation of episodic and parametric memory updating, especially concerning the treatment of the human-written reference insights.  The computational resource details (8x A100 GPUs) while useful lack a contextualization regarding accessibility for broader replication.", "first_pros": "The selection of two diverse benchmarks, Blocks World and TravelPlanner, is a significant strength. It provides a robust test of the capabilities of language agents in both simpler, rule-based planning and more complex, real-world scenarios. The use of the Permutation Feature Importance method allows for direct and unbiased evaluation of the impact of different features within the datasets.", "keypoints": ["Two diverse datasets are used: Blocks World (classical planning) and TravelPlanner (real-world planning).", "Permutation Feature Importance method is applied to quantify the contributions of constraints and questions.", "The experimental setup includes data splits (training and validation sets), and detailed descriptions of episodic and parametric memory updating strategies."], "second_cons": "The explanation of the Permutation Feature Importance method could be improved by illustrating the calculation with a simple numerical example. While the description mentions its unbiased nature, a visual example would strengthen this point and improve comprehension.", "second_pros": "The clear explanation of the experimental methodology, including the use of both classical (Blocks World) and real-world (TravelPlanner) datasets, allows for a thorough understanding of the study's design and ensures the reproducibility of the findings. The detailed description of the computational resources used, although lacking complete contextualization, allows readers to gauge the scale of the undertaken analysis.", "summary": "The Background section establishes the foundation of the research by introducing the datasets used (Blocks World and TravelPlanner), which provide a diverse range of planning challenges;  explaining the Permutation Feature Importance method utilized to analyze the effects of constraints and questions during planning; and, detailing the experimental setup, including the data splits, memory updating strategies (episodic and parametric), and computational resources employed (8x A100 GPUs for certain experiments)."}}, {"page_end_idx": 5, "page_start_idx": 4, "section_number": 4, "section_title": "Why Do Current Language Agents Struggle with Planning?", "details": {"details": "This section investigates why current language agents struggle with planning, focusing on the roles of constraints and questions in the planning process.  The authors utilize Permutation Feature Importance to analyze the contribution of constraints and questions to the final plans generated by various language models on two benchmarks: BlocksWorld (a classical planning task) and TravelPlanner (a more complex, real-world task).  The results reveal that language agents exhibit limited understanding of constraints, with attribution scores consistently below 25% in BlocksWorld, indicating that constraints play a less significant role than expected in their planning process. In TravelPlanner, the situation is even worse, with some models showing negative attribution scores for constraints, suggesting that constraints may even hinder the planning process for some agents.  Furthermore, the influence of questions diminishes as the planning horizon increases.  Episodic and parametric memory updating strategies improve performance, but they primarily focus on improving understanding rather than addressing the fundamental issues of limited constraint use and diminishing influence of questions, suggesting these strategies are more of a 'shortcut' rather than true problem solving.  The authors suggest that current approaches resemble 'shortcut learning', excelling in short-horizon and low-level planning, but falling short in scenarios requiring more complex reasoning and long-term planning.", "first_cons": "The analysis primarily focuses on two specific benchmarks (BlocksWorld and TravelPlanner), which may not fully represent the diversity of planning tasks and the generalizability of the findings.", "first_pros": "The use of Permutation Feature Importance offers a novel and effective way to analyze the inner workings of language agents during planning, providing valuable insights into the relative contributions of different input elements.", "keypoints": ["Language agents show limited understanding of constraints, with attribution scores consistently below 25% in BlocksWorld and even negative in some cases in TravelPlanner.", "The influence of questions in guiding plan generation diminishes as the planning horizon increases.", "Episodic and parametric memory updating strategies, while improving performance, do not fully address the underlying issues of limited constraint usage and diminishing question influence.", "Current strategies may resemble 'shortcut learning', excelling in short-horizon and low-level planning but failing in complex reasoning and long-term planning"], "second_cons": "The study doesn't delve deeper into the internal mechanisms of the language models, potentially missing crucial details of how these models process information during planning.", "second_pros": "The study identifies two key factors hindering language agents in planning: the limited role of constraints and the diminishing influence of questions, providing a valuable framework for future research and development.", "summary": "Current language agents struggle with planning due to their limited understanding of constraints and the diminishing influence of questions as the planning horizon increases. While memory updating strategies offer improvement, they primarily address surface-level issues and don't resolve the deeper problem of insufficient constraint usage and goal focus, thus resembling \"shortcut learning\" rather than true problem-solving abilities."}}, {"page_end_idx": 7, "page_start_idx": 5, "section_number": 5, "section_title": "What Happens in Memory Updating for Language Agents?", "details": {"details": "This section investigates the effects of episodic and parametric memory updating strategies on language agents' planning performance.  Episodic memory updating, which involves refining or reiterating existing insights, shows improvement, particularly when the refined information is explicit.  However, agents struggle to reference this refined information in a fine-grained manner, and gains remain relatively small.  Parametric memory updating, on the other hand, enhances the influence of the question on the final plan, as evidenced by increased question attribution scores.  Yet, both methods struggle when the planning horizon increases, highlighting a limitation in handling dynamic constraints.  The study uses permutation feature importance to analyze the contribution of constraints and questions, revealing a general limitation in understanding constraints and the diminishing influence of the questions as the planning task becomes more complex. The performance of agents is evaluated on two benchmarks: Blocksworld and TravelPlanner.", "first_cons": "Both episodic and parametric memory updating strategies show limitations when the planning horizon increases, indicating difficulty in handling long-term dependencies and dynamic constraints. This is a major obstacle to achieving high-level planning abilities.", "first_pros": "The study demonstrates the effectiveness of refining or reiterating existing information in episodic memory updating, leading to improved planning performance, particularly in more explicit scenarios. ", "keypoints": ["Episodic memory updating improves performance, especially when refined information is explicit, but gains are small and fine-grained referencing is lacking.", "Parametric memory updating increases the influence of the question on the final plan, but struggles when the planning horizon increases.", "Constraints play a limited role, especially with fine-grained references.  Attribution scores for constraints are less than 25% in several cases, indicating weak understanding.", "The influence of the question diminishes as the planning horizon increases, demonstrating challenges in maintaining focus on the overall goal for complex tasks."], "second_cons": "The study primarily focuses on two benchmarks, which may limit the generalizability of the findings.  Further research is needed to validate the results in other planning domains.", "second_pros": "The use of permutation feature importance provides valuable insights into the inner workings of language agents during planning, clarifying why current approaches struggle.  This detailed analysis helps identify key areas for improvement in future planning strategies.", "summary": "This section analyzes the impact of episodic and parametric memory updating on language agents' planning abilities.  Episodic memory updating leads to modest improvements by refining existing insights, especially when those insights are explicitly stated.  Parametric memory updating enhances the influence of the question, but both methods struggle with increasingly complex and lengthy plans.  The analysis reveals a limited understanding of constraints and the diminishing influence of the original question as planning progresses.  The key findings suggest that current language agents still lack the capability for advanced planning. "}}, {"page_end_idx": 8, "page_start_idx": 7, "section_number": 6, "section_title": "Discussion", "details": {"details": "The discussion section analyzes the combined effects of episodic and parametric memory updating strategies on language agents' planning abilities.  It finds that while both methods offer performance improvements, they do not fully solve the underlying issues of constraint understanding and the diminishing influence of the goal with increasing planning horizon.  Episodic memory updating, while enhancing performance, primarily focuses on global understanding, failing to leverage constraints in a fine-grained manner; it may even worsen performance if constraints are already well-parameterized.  Parametric memory updating, on the other hand, improves the weighting of the question but still struggles with longer horizons.  Both strategies exhibit what the authors term \"shortcut learning,\" suggesting a focus on static rules instead of dynamic problem-solving. The analysis highlights the need for more sophisticated approaches that directly tackle the fundamental limitations of language agents in reasoning about constraints and long-term goals.", "first_cons": "Both episodic and parametric memory updating strategies only offer short-term solutions and fail to address the root problems of constraint understanding and long-term planning.", "first_pros": "The study reveals that both episodic and parametric memory updating strategies improve planning performance, although only to a limited degree.  The findings emphasize the importance of addressing long-term planning limitations.", "keypoints": ["Episodic memory updating improves performance, but primarily works on a global level; it struggles with fine-grained constraint usage and can even worsen performance if constraints are already well-parameterized.", "Parametric memory updating improves the importance of the goal question but still struggles with longer planning horizons. ", "Both strategies exhibit limitations in handling long-term planning, with performance decreasing as the planning horizon extends. ", "Fine-tuned models using both strategies do not show performance improvements and may even degrade them."], "second_cons": "The analysis focuses primarily on two specific memory updating techniques and may not generalize to other approaches.  The study does not propose new concrete methods for improving planning abilities.", "second_pros": "The study provides a detailed analysis of how the two memory updating strategies work and their limitations.  The findings emphasize the challenges faced by language agents in handling constraints, especially in more complex real-world scenarios.", "summary": "This section discusses the limitations of episodic and parametric memory updating strategies for improving language agents' planning abilities.  It finds that while both methods improve performance, they only partially address the underlying issues of limited constraint understanding and the diminishing influence of the planning goal with increasing horizon. The analysis reveals that both strategies resemble 'shortcut learning', focusing on surface-level improvements rather than addressing fundamental reasoning limitations, highlighting the need for more sophisticated approaches."}}]