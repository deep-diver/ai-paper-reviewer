{"references": [{"fullname_first_author": "Jimenez, C. E.", "paper_title": "SWE-Bench: Can language models resolve real-world GitHub issues?", "publication_date": "2024-05-07", "reason": "This paper introduces SWE-Bench, a benchmark dataset crucial for evaluating software engineering agents, heavily influencing the design and evaluation of the SWE-Gym environment."}, {"fullname_first_author": "Wang, X.", "paper_title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents", "publication_date": "2024-07-21", "reason": "This paper presents OpenHands, an agent scaffold that forms the basis for training the general-purpose LMs in this paper, highlighting the effectiveness of the SWE-Gym in improving agent performance."}, {"fullname_first_author": "Cobbe, K.", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-26", "reason": "This paper introduces the concept of training verifiers (reward models), which is a key component of the inference-time scaling method proposed in the current research."}, {"fullname_first_author": "Ouyang, L.", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This study details RLHF (Reinforcement Learning from Human Feedback), a widely used training approach, providing context for the fine-tuning methods and self-improvement strategies used in the paper."}, {"fullname_first_author": "Hui, B.", "paper_title": "Qwen-2.5-coder technical report", "publication_date": "2024-09-18", "reason": "This paper introduces the Qwen-2.5-Coder language model, which is the foundation model used for training SWE agents and verifiers in this research, showcasing its effectiveness in the software engineering domain."}]}