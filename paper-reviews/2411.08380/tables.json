[{"content": "| Dataset | Year | Domain | Gen. | Text | Kinematic | CM. | #Videos | #Frames | Res |\n|---|---|---|---|---|---|---|---|---|---| \n| HowTo100M [43] | 2019 | Open | \u2713 | ASR | \u2717 | \u2717 | 136M | ~90 | 240p |\n| WebVid-10M [2] | 2021 | Open | \u2713 | Alt-Text | \u2717 | \u2717 | 10M | ~430 | Diverse |\n| HD-VILA-100M [68] | 2022 | Open | \u2713 | ASR | \u2717 | \u2717 | 103M | ~320 | 720p |\n| Panda-70M [8] | 2024 | Open | \u2713 | Auto | \u2717 | \u2717 | 70M | ~200 | Diverse |\n| OpenVid-1M [44] | 2024 | Open | \u2713 | Auto | \u2717 | \u2717 | 1M | ~200 | Diverse |\n| VIDGEN-1M [55] | 2024 | Open | \u2713 | Auto | \u2717 | \u2717 | 1M | ~250 | 720p |\n| LSMDC [50] | 2015 | Movie | \u2717 | Human | \u2717 | \u2717 | 118K | ~120 | 1080p |\n| UCF101 [53] | 2015 | Action | \u2717 | Human | \u2717 | \u2717 | 13K | ~170 | 240p |\n| Ego4D [16] | 2022 | Egocentric | \u2717 | Human | IMU | \u2717 | 931 | ~417K | 1080p |\n| Ego-Exo4D [17] | 2024 | Egocentric | \u2717 | Human | MVS | \u2717 | 740 | ~186K | 1080p |\n| **EgoViD-5M (ours)** | 2024 | Egocentric | \u2713 | Auto | VIO | \u2713 | 5M | ~120 | 1080p |", "caption": "Table 1: Comparison of EgoVid-5M and other video datasets, where Gen. denotes whether the dataset is designed for generative training, CM. denotes cleansing metadata, #Videos is the number of videos, and #Frames is the average number of frames in a video.", "description": "This table compares the EgoVid-5M dataset with other publicly available video datasets.  It highlights key characteristics relevant to video generation tasks.  The comparison includes the year the dataset was released, the domain of the videos (e.g., open-domain, egocentric), whether the dataset includes generated videos, the presence of text annotations, kinematic annotations (e.g., motion tracking data), cleansing metadata (information about data cleaning procedures), the number of videos, the average number of frames per video, and the resolution of the videos.  This allows for an evaluation of EgoVid-5M's size, quality, and suitability for various video generation tasks, particularly highlighting its unique features tailored for egocentric video generation.", "section": "1. Introduction"}, {"content": "| Method | w. EgoVid | CD-FVD \u2193 | Semantic Consistency \u2191 | Action Consistency \u2191 | Clarity Score \u2191 | Motion Smoothness \u2191 | Motion Strength \u2191 |\n|---|---|---|---|---|---|---|---| \n| SVD [3] | \u2717 | 591.61 | 0.258 | 0.465 | 0.479 | 0.971 | 18.897 |\n| SVD [3] | \u2713 | **548.32** | **0.266** | **0.471** | **0.485** | **0.974** | **21.032** |\n| DynamiCrafter [65] | \u2717 | 243.63 | 0.257 | 0.481 | 0.473 | 0.986 | 9.357 |\n| DynamiCrafter [65] | \u2713 | **236.82** | **0.265** | **0.494** | **0.483** | **0.987** | **18.329** |\n| OpenSora [81] | \u2717 | 809.46 | 0.260 | 0.489 | 0.520 | 0.983 | 7.608 |\n| OpenSora [81] | \u2713 | **718.32** | **0.266** | **0.494** | **0.528** | **0.986** | **15.871** |", "caption": "Table 2: EgoVid significantly enhances egocentric video generation. Experimental results demonstrate that training with EgoVid improves performance across all three baselines on six metrics.", "description": "This table presents a quantitative comparison of the performance of three different video generation models (SVD, DynamiCrafter, and OpenSora) trained with and without the EgoVid-5M dataset.  Six metrics are used to evaluate the generated videos: CD-FVD (measuring spatial and temporal quality), Semantic Consistency, Action Consistency, Clarity Score, Motion Smoothness, and Motion Strength. The results demonstrate that fine-tuning these models with EgoVid-5M consistently improves performance across all six metrics, showcasing the dataset's effectiveness in improving egocentric video generation.", "section": "5. Experiment"}, {"content": "| w. EgoVid | ControlNet | ControlNeXt | AA | UAE | CD-FVD \u2193 | Semantic Consistency \u2191 | Action Consistency \u2191 | Rot Err \u2193 | Trans Err \u2193 |\n|---|---|---|---|---|---|---|---|---|---| \n|  | \u2713 |  |  |  | 241.90 | 0.263 | 0.490 | 5.32 | 9.27 |\n| \u2713 | \u2713 |  |  |  | 238.87 | 0.266 | 0.493 | 4.01 | 8.66 |\n| \u2713 | \u2713 |  |  | \u2713 | 239.01 | 0.268 | 0.494 | 3.58 | 8.41 |\n| \u2713 |  | \u2713 |  | \u2713 | 234.13 | **0.269** | 0.497 | 3.59 | 7.93 |\n| \u2713 |  |  | \u2713 | \u2713 | **229.82** | 0.268 | **0.498** | **3.28** | **7.62** |", "caption": "Table 3: Ablation study on training strategy and different components of EgoDreamer.", "description": "This ablation study analyzes the impact of different training strategies and components of the EgoDreamer model on egocentric video generation.  It compares the performance of various configurations, including different cleaning strategies for the training data, the use of ControlNet and ControlNeXt for kinematic control, the Unified Action Encoder (UAE) for multimodal action input, and the Adaptive Alignment (AA) module.  The results are evaluated based on several key metrics, including CD-FVD (lower is better), Semantic Consistency, Action Consistency, rotation and translation errors. This table helps determine the optimal combination of techniques for generating high-quality egocentric videos.", "section": "5. Experiment"}]