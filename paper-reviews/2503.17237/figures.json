[{"figure_path": "https://arxiv.org/html/2503.17237/x1.png", "caption": "Figure 1: Demonstration using training and testing data from Track 3. (a) Shows UAV swarms with varying sizes and backgrounds in the training data. (b) Highlights annotation errors and frame defects: MultiUAV-230 (train) has incorrect annotations, MultiUAV-256 (train) contains redundant annotations, MultiUAV-294 (train) has missed annotations, and MultiUAV-068 (test) includes a poor-quality frame.", "description": "Figure 1 demonstrates examples from the Multi-UAV tracking dataset, specifically focusing on Track 3.  Part (a) showcases the diversity in UAV swarm sizes and background complexity present within the training data. Part (b) highlights common issues encountered in the dataset, such as annotation errors (incorrect, redundant, or missing labels) and poor image quality, illustrating the challenges involved in multi-UAV tracking.", "section": "3. Data Analysis and Preparation"}, {"figure_path": "https://arxiv.org/html/2503.17237/x2.png", "caption": "Figure 2: Illustration of cropped image patches from training data annotations. Each patch corresponds to a bounding box from MultiUAV-002, MultiUAV-013, MultiUAV-087, and MultiUAV-223, with sizes approximately 28\u00d724282428\\times 2428 \u00d7 24, 10\u00d710101010\\times 1010 \u00d7 10, 6\u00d76666\\times 66 \u00d7 6, and 11\u00d710111011\\times 1011 \u00d7 10, respectively. The top number denotes the frame sequence (1st to 12th frames), and each row represents the same object (same ID across frames).", "description": "Figure 2 shows example image crops from the training dataset bounding boxes.  Each set of crops shows the same UAV (identified by the same ID) across 12 consecutive frames from four different training videos: MultiUAV-002, MultiUAV-013, MultiUAV-087, and MultiUAV-223.  The figure highlights the variability in UAV size within the dataset, ranging from approximately 28x24 pixels to as small as 6x6 pixels.  This illustrates the challenge of detecting and tracking small UAVs in the thermal infrared videos.", "section": "3.2. Data Analysis and Preparation"}, {"figure_path": "https://arxiv.org/html/2503.17237/x3.png", "caption": "Figure 3: YOLOv12n with BoT-SORT-SBS-S50 workflow diagram. The workflow follows the original BoT-SORT framework\u00a0[1], with a slight revision: incorporating lost tracks to compensate for uninformative frames and improve object continuity. Specifically, for Track 1 and Track 2, lost target information is used to annotate potential object locations, while Track 3 retains the BoT-SORT original output.", "description": "This figure illustrates the workflow of the multi-UAV tracking system using YOLOv12, BoT-SORT, and SBS-S50.  It shows how the system processes each frame, from detection using YOLOv12n to tracking and managing tracks using BoT-SORT. The diagram highlights a key modification: the incorporation of 'lost tracks' to handle frames where objects might be missed due to occlusion or poor image quality. This improves tracking continuity, especially for Tracks 1 and 2, by using information about lost targets to infer potential object locations. Track 3, however, uses the standard BoT-SORT output.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.17237/x4.png", "caption": "Figure 4: Demonstration of YOLOv12n with BoT-SORT-SBS-S50 predictions on Track 3 test data. (a) Predicted bounding boxes with object IDs. (b) Challenging scenarios: MultiUAV-0003 contains multiple overlapping UAVs; MultiUAV-135 includes an occluded UAV (red box, ID: 29) and a flying creature misclassified as a UAV (pink box, ID: 28); MultiUAV-173 features a complex background, where IDs 16, 17, and 18 are misjudgments; and MultiUAV-261 presents nearly invisible UAVs, leading to missed detections and tracking failures. The last row presents heatmaps highlighting the model\u2019s difficulty in UAV perception, especially in MultiUAV-261.", "description": "Figure 4 showcases the performance of the YOLOv12n object detection model combined with the BoT-SORT-SBS-S50 tracking algorithm on Track 3 of the anti-UAV dataset.  Part (a) displays the predicted bounding boxes with their assigned IDs. Part (b) highlights several challenging scenarios encountered during testing, including instances of overlapping UAVs, occlusion, misclassification (a flying creature mistaken for a UAV), complex background interference leading to ID misassignments, and near-invisible UAVs resulting in missed detections and tracking failures. Heatmaps in the bottom row further illustrate the model's struggles with UAV perception, particularly in difficult conditions.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2503.17237/x5.png", "caption": "Figure 5: Potential frame enhancement techniques for multi-UAV tracking on a MultiUAV-262 video frame. From left to right: (1) original thermal infrared frame, (2) Sobel edge-based sharpening\u00a0[10], (3) contrast enhancement via Contrast Limited Adaptive Histogram Equalization (CLAHE)\u00a0[28], and (4) ReynoldsFlow+ visualization highlighting motion patterns to assist UAV detection\u00a0[4].", "description": "Figure 5 demonstrates various image enhancement techniques applied to a thermal infrared video frame (MultiUAV-262) to improve multi-UAV tracking.  The original frame is shown alongside three enhanced versions: one using Sobel edge-based sharpening to highlight edges, another employing Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance contrast, and a final version using ReynoldsFlow+ to visualize motion patterns for better UAV detection.  These enhancements aim to address challenges in thermal infrared video such as low contrast and small object sizes.", "section": "4.5 Discussion and Enhancement Techniques"}]