{"references": [{"fullname_first_author": "Li Siyao", "paper_title": "Bailando: 3d dance generation by actor-critic gpt with choreographic memory", "publication_date": "2022-01-01", "reason": "This paper is a foundational work in 3D dance generation, utilizing VQ-VAE and GPT, and is frequently compared to X-Dancer."}, {"fullname_first_author": "Jonathan Tseng", "paper_title": "Edge: Editable dance generation from music", "publication_date": "2023-01-01", "reason": "This paper presents a diffusion-based approach to human pose prediction conditioned on music, which provides a strong baseline for comparison in the field of music-driven dance generation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces Latent Diffusion Models, a foundational technology employed by X-Dancer for generating high-resolution images, making it a crucial component in the video synthesis pipeline."}, {"fullname_first_author": "Ruilong Li", "paper_title": "Ai choreographer: Music conditioned 3d dance generation with aist++", "publication_date": "2021-01-01", "reason": "This paper presents the AIST++ dataset and a method for 3D music-conditioned dance generation, establishing a benchmark for quantitative evaluation of music alignment."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Jukebox: A generative model for music", "publication_date": "2020-01-01", "reason": "This paper introduces the Jukebox model, which is used in X-Dancer to extract rich musical features, playing a key role in conditioning the dance motion generation."}]}