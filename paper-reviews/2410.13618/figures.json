[{"figure_path": "2410.13618/figures/figures_2_0.png", "caption": "Figure 2. Comparison of LoRA (left) and our LoLDU (right) method. In LoRA, tunable parameters are low-rank (r) matrices A and B, with AW = BA. For each weight W, there are r \u00d7 (din + dout) trainable parameters. LoLDU, however, optimizes a diagonal matrix for scale transformation, preserving original model knowledge during tuning. The weight update in LoLDU is AW = \u03c3 \u22c5 P \u22c5 (Lr, diag(zr), Ur), involving r + 1 trainable parameters. The permutation matrix P, while omitted in this figure for simplicity, is included in Figure 3", "description": "Figure 2 compares the LoRA and LoLDU methods, highlighting LoLDU's optimization of a diagonal matrix for scale transformation to preserve original model knowledge and reduce trainable parameters.", "section": "II. RELATED WORK"}, {"figure_path": "2410.13618/figures/figures_3_0.png", "caption": "Figure 3. Schematic representation of our LoLDU method. The left diagram illustrates the forward pass, demonstrating the transformation of the input x \u2208 Rdin into the output h\u2208 Rdout via a residual subspace matrix L[r:]D[r:]U[r:] and a decomposed subspace matrix oLrDrUr. The right diagram shows the initialization process, where the residual matrix is obtained by performing LDU decomposition on the pre-trained weights, then subtracting the top-r submatrices (top-r rows and columns) from the permutation matrix (P), lower triangular (L), scaled diagonal (D), and upper triangular (U) matrices. Diagonal matrix is trainable (orange), while the other matrices remain fixed (blue). LoLDU enables efficient adaptation of pre-trained models via low-rank updates, reducing both computational cost and parameter count.", "description": "Figure 3 schematically illustrates the LoLDU method, showing the forward pass and the initialization process via LDU decomposition of pre-trained weights, highlighting the trainable diagonal matrix and fixed triangular matrices for efficient model adaptation.", "section": "III. METHOD"}, {"figure_path": "2410.13618/figures/figures_7_0.png", "caption": "Figure 5. Concept Learning Progression In Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~ 100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results of LoLDU, DreamBooth, and Textual Inversion across different training steps, demonstrating LoLDU's faster convergence and better image quality.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_0.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~ 100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows a comparison of image generation results using LoLDU, DreamBooth, and Textual Inversion across different training steps, demonstrating LoLDU's faster convergence.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_1.png", "caption": "Figure 1. Performance vs log-scaled trainable parameters for FGVC (left) and StanfordCars (right) on ViT Base. Our LoLDU methods with r = {1, 8, 16, 32, 64, 128, 256, 512,768} exhibit superior parameter efficiency and performance when contrasted with Linear Probing [13] (LP, fine tuning the classifier head only\u00b9), FourierFT [14] (n = {3000, 10000}), LoRA [9] (r = 16), and Full Fine-Tuning. LoLDU r=768 outperforms LoRAr=16 with 96.837% fewer trainable parameters. Particularly noteworthy is that LoLDU with r = 1 achieves competitive scores with just 24 trainable parameters, while LoLDU with r = 768 attains the highest accuracy: 42.15% for FGVC and 66.66% for StanfordCars, showcasing the scalability and effectiveness of our approach. Full Fine-Tuning (85.8M parameters) and Linear Probing represent the upper and lower performance bounds, respectively.", "description": "The figure shows the performance of LoLDU compared to other parameter-efficient fine-tuning methods across different numbers of trainable parameters on image classification tasks.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_2.png", "caption": "Figure 1. Performance vs log-scaled trainable parameters for FGVC (left) and StanfordCars (right) on ViT Base. Our LoLDU methods with r = {1, 8, 16, 32, 64, 128, 256, 512,768} exhibit superior parameter efficiency and performance when contrasted with Linear Probing [13] (LP, fine tuning the classifier head only\u00b9), FourierFT [14] (n = {3000, 10000}), LoRA [9] (r = 16), and Full Fine-Tuning. LoLDU r=768 outperforms LoRAr=16 with 96.837% fewer trainable parameters. Particularly noteworthy is that LoLDU with r = 1 achieves competitive scores with just 24 trainable parameters, while LoLDU with r = 768 attains the highest accuracy: 42.15% for FGVC and 66.66% for StanfordCars, showcasing the scalability and effectiveness of our approach. Full Fine-Tuning (85.8M parameters) and Linear Probing represent the upper and lower performance bounds, respectively.", "description": "The figure shows the performance of LoLDU compared to other methods on image classification tasks, demonstrating its superior parameter efficiency and accuracy.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_3.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across several concepts, demonstrating LoLDU's ability to generate diverse and high-quality images.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_4.png", "caption": "Figure 1. Performance vs log-scaled trainable parameters for FGVC (left) and StanfordCars (right) on ViT Base. Our LoLDU methods with r = {1, 8, 16, 32, 64, 128, 256, 512,768} exhibit superior parameter efficiency and performance when contrasted with Linear Probing [13] (LP, fine tuning the classifier head only\u00b9), FourierFT [14] (n = {3000, 10000}), LoRA [9] (r = 16), and Full Fine-Tuning. LoLDU r=768 outperforms LoRAr=16 with 96.837% fewer trainable parameters. Particularly noteworthy is that LoLDU with r 1 achieves competitive scores with just 24 trainable parameters, while LoLDU with r = 768 attains the highest accuracy: 42.15% for FGVC and 66.66% for StanfordCars, showcasing the scalability and effectiveness of our approach. Full Fine-Tuning (85.8M parameters) and Linear Probing represent the upper and lower performance bounds, respectively.", "description": "The figure shows the performance of LoLDU compared to other methods (Linear Probing, FourierFT, LoRA, and Full Fine-Tuning) across two image classification datasets (FGVC and StanfordCars) in terms of accuracy and the number of trainable parameters.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_5.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results from LoLDU, DreamBooth, and Textual Inversion at various training steps, demonstrating LoLDU's superior efficiency in concept learning.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_6.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across various prompts.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_7.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's ability to generate diverse, high-quality images that match the given prompts.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_8.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results for LoLDU, DreamBooth, and Textual Inversion across different training steps, highlighting LoLDU's faster convergence.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_9.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results for different methods at various training steps, demonstrating LoLDU's faster convergence and superior efficiency.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_10.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results using LoLDU, DreamBooth, and Textual Inversion across several concepts, demonstrating LoLDU's ability to generate diverse, high-quality images that align with the given prompts.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_11.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the generated images of different methods (LoLDU, DreamBooth, and Textual Inversion) at various training steps for seven image generation tasks, demonstrating LoLDU's faster convergence.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_12.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~ 100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results of LoLDU, DreamBooth, and Textual Inversion across different concepts at various training steps, highlighting LoLDU's faster convergence.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_13.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~ 100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across different training steps, demonstrating LoLDU's faster convergence and superior efficiency.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_14.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results for LoLDU, DreamBooth, and Textual Inversion across various training steps, demonstrating LoLDU's faster convergence and superior efficiency.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_15.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across various training steps, highlighting LoLDU's faster convergence.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_16.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's ability to generate diverse, high-quality images that match the given prompts.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_17.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across various prompts, highlighting LoLDU's ability to generate diverse and high-quality images.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_18.png", "caption": "Figure 5. Concept Learning Progression In Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results of LoLDU compared to DreamBooth and Textual Inversion across different training steps.", "section": "IV. Experiments"}, {"figure_path": "2410.13618/figures/figures_9_19.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion across different training steps for seven concepts.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_20.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's ability to generate diverse and high-quality images.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_21.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's ability to generate diverse, high-quality images that accurately reflect the given prompts.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_22.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows the image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's accelerated convergence and superior efficiency in concept learning.", "section": "D. Image Generation"}, {"figure_path": "2410.13618/figures/figures_9_23.png", "caption": "Figure 5. Concept Learning Progression in Text-to-Image Generation. Top row: target concept. Subsequent rows: generated images using LoLDU (our method), DreamBooth [6], and Textual Inversion [5], respectively, at training steps 0-600. LoLDU exhibits accelerated convergence, achieving concept acquisition within ~ 100 steps, surpassing baseline methods in efficiency.", "description": "Figure 5 shows a comparison of image generation results using LoLDU, DreamBooth, and Textual Inversion across different training steps for several concepts, demonstrating LoLDU's superior efficiency and faster convergence.", "section": "IV. EXPERIMENTS"}, {"figure_path": "2410.13618/figures/figures_9_24.png", "caption": "Figure 6. Visualized Results of the Image Generation Task. From left to right: target reference images, outputs from LoLDU (ours), DreamBooth, and Textual Inversion. Each row represents a distinct category with a specified prompt (annotated under each row). LoLDU demonstrates efficacy in generating diverse, prompt-adherent images while preserving key attributes from the reference set.", "description": "Figure 6 shows a comparison of image generation results from LoLDU, DreamBooth, and Textual Inversion, demonstrating LoLDU's ability to generate diverse and high-quality images while preserving key attributes from the reference images.", "section": "D. Image Generation"}]