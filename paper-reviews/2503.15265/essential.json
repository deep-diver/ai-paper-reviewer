{"importance": "This research introduces a novel approach to **3D mesh generation with human-aligned artistry**, offering new methods for geometric detail & visual appeal. It opens avenues for exploring RL in generative modeling & artistic mesh creation.", "summary": "DeepMesh: RL-guided auto-regressive creation of artist-quality 3D meshes, enhanced by tokenization & DPO for human-aligned aesthetics.", "takeaways": ["Introduces an efficient pre-training strategy that incorporates a novel tokenization algorithm.", "Pioneers the adaptation of Direct Preference Optimization (DPO) for 3D auto-regressive models, aligning model outputs with human preference.", "Achieves state-of-the-art performance in both precision and quality for generating intricate and precise 3D meshes."], "tldr": "Triangle meshes are essential in 3D applications. Existing auto-regressive methods, which generate structured meshes by predicting vertex tokens, often face limitations in face counts and mesh completeness. Moreover, these methods struggle with aligning outputs with human aesthetic preferences, leading to geometric inaccuracies and a lack of artistic refinement. These challenges hinder the creation of high-quality, artist-like 3D meshes.\n\nTo address these issues, this paper presents a framework that optimizes mesh generation through two key innovations. First, an efficient pre-training strategy incorporates a novel tokenization algorithm. Second, Reinforcement Learning (RL) is introduced into 3D mesh generation, achieving human preference alignment via Direct Preference Optimization (DPO). With a scoring standard combining human evaluation and 3D metrics, the framework generates detailed, precise meshes, outperforming existing methods in precision and quality.", "affiliation": "Tsinghua University", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.15265/podcast.wav"}