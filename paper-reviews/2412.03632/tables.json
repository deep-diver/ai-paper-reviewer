[{"content": "| Method | FID \u2193 | IS \u2191 | CLIP Score \u2191 |\n|---|---|---|---|\n| MVDream | 32.15 | 14.38 | 31.76 |\n| SPAD | 48.79 | 12.04 | 30.87 |\n| Ours (SD2.1) | 31.24 | 15.01 | 32.04 |\n| Ours (SDXL) | **29.71** | **16.38** | **33.17** |", "caption": "Table 7: Community models and extensions for evaluation.", "description": "This table lists the various community models and extensions used in the experiments section of the paper.  It's broken down into three categories: Personalized T2I models, Distilled T2I models, and Extensions.  Each row specifies a model, its domain (the style or type of image it generates), and its type (base model, LoRA, or plugin). This allows the reader to understand the range of models and techniques used to test the effectiveness and adaptability of the MV-Adapter across different base models and generation styles.", "section": "5 Experiments"}]