{"references": [{" publication_date": "2009", "fullname_first_author": "Yoshua Bengio", "paper_title": "Curriculum learning", "reason": "This paper introduces the concept of curriculum learning, a training strategy that improves model convergence and generalization. This strategy is adopted in DAWN for training the A2V-FDM, thereby improving the model's ability to generate high-quality, long video sequences.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Dan Bigioi", "paper_title": "Speech driven video editing via an audio-conditioned diffusion model", "reason": "This paper explores the use of audio-conditioned diffusion models for video editing.  This is relevant to DAWN because it suggests a method of effectively using audio input for controlling the generation of video content, a key aspect of DAWN's capabilities. The paper's focus on high-quality results and diffusion models makes it a key reference for DAWN's approach.", "section_number": 2}, {" publication_date": "1999", "fullname_first_author": "Volker Blanz", "paper_title": "A morphable model for the synthesis of 3d faces", "reason": "This foundational paper introduces the 3D Morphable Model (3DMM), a technique often used in facial modeling and animation. While DAWN doesn't directly use 3DMM, it is a significant related work that informed other approaches DAWN builds upon. Understanding 3DMM is crucial for appreciating the techniques used in other more advanced talking head methods.", "section_number": 2}, {" publication_date": "2014", "fullname_first_author": "Houwei Cao", "paper_title": "Crema-d: Crowd-sourced emotional multimodal actors dataset", "reason": "This paper presents the CREMA-D dataset used for evaluating the DAWN model. The CREMA-D dataset is vital because it provides a benchmark for evaluating various aspects of video generation and helps to assess the generalization capabilities of the model. The dataset's characteristics directly influence the experimental setup and results in DAWN's evaluation.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Lele Chen", "paper_title": "Talking-head generation with rhythmic head motion", "reason": "This paper focuses on generating talking head videos with natural-looking rhythmic head motions. It's relevant because rhythmic head motions are a crucial aspect of realistic talking head videos.  It represents the state-of-the-art in a related area; DAWN builds upon and improves these existing approaches.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Joon Son Chung", "paper_title": "Out of time: automated lip sync in the wild", "reason": "This paper addresses the lip-synchronization problem in talking head generation, a crucial aspect of the DAWN model.  The techniques explored in this work are highly relevant to the challenges DAWN aims to address, providing useful insights for evaluating the quality of lip synchronization in generated videos.", "section_number": 4}, {" publication_date": "2016", "fullname_first_author": "\u00d6zg\u00fcn \u00c7i\u00e7ek", "paper_title": "3d u-net: learning dense volumetric segmentation from sparse annotation", "reason": "This paper introduces the 3D U-Net architecture, a convolutional neural network designed for 3D image segmentation and widely used in many computer vision tasks. DAWN employs a 3D U-Net as the backbone of its A2V-FDM, therefore, this paper is fundamental to understanding the core architecture used in DAWN's video generation model.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Jiankang Deng", "paper_title": "Arcface: Additive angular margin loss for deep face recognition", "reason": "This paper introduces ArcFace, a deep learning-based face recognition model.  DAWN utilizes ArcFace to extract facial features for evaluating identity preservation during video generation; this is a key metric for assessing the quality of generated videos in talking head video generation.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Chenpeng Du", "paper_title": "Dae-talker: High fidelity speech-driven talking face generation with diffusion autoencoder", "reason": "This paper presents a method that uses diffusion autoencoders for talking head video generation. This is highly relevant because it demonstrates an approach similar to DAWN's in using diffusion models. Comparing DAWN's performance with this related approach is essential for establishing its novelty and contributions.", "section_number": 2}, {" publication_date": "2016", "fullname_first_author": "Bo Fan", "paper_title": "A deep bidirectional lstm approach for video-realistic talking head", "reason": "This paper explores using bidirectional LSTMs for talking head generation. While DAWN uses different architectures, understanding the LSTM-based approach is beneficial because LSTMs have been widely used in sequence modeling, a key aspect of talking head generation.  The paper serves as a comparison point for the advancement of techniques in the field.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Shiry Ginosar", "paper_title": "Learning individual styles of conversational gesture", "reason": "This paper addresses the challenge of generating individual styles of conversational gestures. This is important for DAWN, which aims to produce realistic talking head videos, as individual style influences motion generation in talking head videos. This paper offers a valuable comparison for DAWN's ability to address the style challenge.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Yudong Guo", "paper_title": "Audio driven neural radiance fields for talking head synthesis", "reason": "This paper introduces a method that generates talking head videos from audio, representing a significant advancement in the field.  The technique used in this paper is directly relevant to the task addressed in the DAWN paper, and provides a strong comparison point to demonstrate DAWN's advancements.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is foundational for diffusion models.  DAWN leverages diffusion models for video generation, which are a core component of the approach. Thus, understanding the foundational concepts and techniques of diffusion models from this paper is crucial for interpreting the technical contributions of DAWN.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Imagen video: High definition video generation with diffusion models", "reason": "This paper showcases the capabilities of diffusion models in high-definition video generation, setting a high benchmark for quality in the field. DAWN utilizes diffusion models as well, and this paper shows a related high quality approach for video generation, which is relevant to DAWN's quality goals.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Video diffusion models", "reason": "This paper presents advancements in diffusion models specifically tailored to video generation.  The application of diffusion models in video generation is central to DAWN's approach, making this paper foundational to understanding the technical underpinnings and potential limitations of the DAWN approach.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "William Harvey", "paper_title": "Flexible diffusion modeling of long videos", "reason": "This paper tackles the challenges of generating long videos using diffusion models.  This directly addresses one of the key limitations of existing talking head generation methods that DAWN aims to overcome. Understanding the approach in this paper is crucial for comparing the performance of the non-autoregressive method used in DAWN.", "section_number": 4}, {" publication_date": "2017", "fullname_first_author": "Martin Heusel", "paper_title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium", "reason": "This paper introduces a training strategy that improves the performance of Generative Adversarial Networks (GANs). While DAWN uses diffusion models rather than GANs, it provides valuable context for understanding the challenges of training generative models in general. Training generative models is a complex problem and this paper offers insights into a successful GAN training method.", "section_number": 3}, {" publication_date": "2016", "fullname_first_author": "Justin Johnson", "paper_title": "Perceptual losses for real-time style transfer and super-resolution", "reason": "This paper introduces perceptual losses for style transfer and super-resolution. DAWN uses perceptual losses to improve the quality of the generated videos by comparing the generated images with ground truth images. Therefore, this is a crucial reference for understanding the techniques used to improve the visual quality of DAWN's outputs.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Diederik P Kingma", "paper_title": "Auto-encoding variational bayes", "reason": "This paper introduces the Variational Autoencoder (VAE), a deep learning model used for dimensionality reduction and generating new data samples.  DAWN employs a VAE-based network for generating pose and blink movements, making this foundational paper relevant to understanding the core architecture of one of DAWN's key components.", "section_number": 3}]}