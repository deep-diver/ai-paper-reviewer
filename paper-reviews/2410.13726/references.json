{"references": [{" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is foundational to the field of diffusion models, introducing the core concepts and techniques used in DAWN. It lays out the theoretical framework for diffusion-based generative models, setting the stage for subsequent advancements in video and image generation.  The introduction of this model is significant because it paved the way for many advancements in image and video generation, including the techniques that are utilized in DAWN.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Hang Zhou", "paper_title": "Pose-controllable talking face generation by implicitly modularized audio-visual representation", "reason": "This paper is highly relevant to the problem of talking head video generation and directly addresses the challenge of controlling pose and expression within a video. The method used in this paper to decouple the pose generation problem is an important contribution that is later applied to DAWN. This paper is important because it is directly related to the pose control part of DAWN. This paper also uses audio and visual cues to generate talking head videos, like DAWN.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Micha\u0142 Stypu\u0142kowski", "paper_title": "Diffused heads: Diffusion models beat gans on talking-face generation", "reason": "This paper is highly relevant as it specifically addresses the application of diffusion models to talking head generation, making it an important reference point for evaluating DAWN. The model's comparison with GANs highlights the superior performance of diffusion models in this context. This work also uses the same metrics (FID and FVD) for evaluation, which further enhances the comparison's meaning.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Weihao Xia", "paper_title": "Gan inversion: A survey", "reason": "This survey provides a comprehensive overview of GAN inversion techniques which have found application in video and image generation. This is a valuable contribution since GAN inversion techniques can also be applied to talking head generation. This survey provides a foundation for comparing the different methods and choosing the appropriate method for specific use cases.  The breadth of techniques discussed within the survey is important to help researchers choose the most appropriate method for specific applications.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Lele Chen", "paper_title": "Talking-head generation with rhythmic head motion", "reason": "This work is highly relevant as it explores the generation of talking heads with rhythmic head motion. The approach to generating rhythmic movements serves as a strong basis for the methodology of DAWN and is used in the experimental evaluation of DAWN. It offers a detailed review of the techniques used for talking head generation and provides insight into the capabilities and limitations of each method. This is very valuable for understanding DAWN.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shuai Shen", "paper_title": "Crafting diffusion models for generalized audio-driven portraits animation", "reason": "This paper is highly relevant to DAWN because it focuses on the application of diffusion models to audio-driven talking head generation. The methods used in this work are relevant for designing new methods for similar applications. The detailed evaluation provided in this work will serve as a strong benchmark for evaluating the performance of DAWN.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Linrui Tian", "paper_title": "Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions", "reason": "This work is highly relevant to DAWN because it demonstrates the use of audio-to-video diffusion models for generating expressive portraits. Comparing DAWN to this work provides insight into the comparative advantages and disadvantages of different diffusion model architectures for this task. The results and methods can be used as a benchmark for comparison.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "William Harvey", "paper_title": "Flexible diffusion modeling of long videos", "reason": "This paper is directly relevant to the problem of generating long videos using diffusion models, which is a key challenge that DAWN addresses.  It introduces techniques for efficient long-video generation, which are particularly relevant to the A2V-FDM component in DAWN. This paper explores the limitations of using diffusion models for long video generation and provides valuable insights that address some of the challenges faced by DAWN.", "section_number": 2}, {" publication_date": "2016", "fullname_first_author": "Phillip Isola", "paper_title": "Image-to-image translation with conditional adversarial networks", "reason": "This paper is foundational for image-to-image translation which is a key component of the talking head video generation problem. The methods used in this paper provide inspiration for tackling similar problems in the future. Many techniques utilized in this paper are relevant to other image generation tasks, including talking head video generation.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Imagen video: High definition video generation with diffusion models", "reason": "This work is important to the field of diffusion models, introducing the application of diffusion models to the generation of high-definition videos. The techniques used in this paper have inspired similar works such as DAWN, and it is important for comparing the capabilities of different diffusion models.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Aliaksandr Siarohin", "paper_title": "Motion representations for articulated animation", "reason": "This paper is directly relevant to the LFG component of DAWN, where it is used to learn the motion representation between video frames. The technique introduced in this paper for learning motion representation has been widely used in other works.  It introduces a novel approach to modeling motion that's applicable to the problem addressed by DAWN, which is talking head generation.  The detailed experimental evaluation of the model\u2019s performance is highly useful for comparison.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Wei-Ning Hsu", "paper_title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units", "reason": "This paper describes a method for learning self-supervised speech representations, which is a crucial step in many audio-driven talking head generation models, including DAWN. This method is used in DAWN for extracting the audio embedding, which conditions the generation of the talking head videos.  The robustness and accuracy of this method directly affect the quality of the generated videos.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Li Siyao", "paper_title": "Bailando: 3d dance generation by actor-critic gpt with choreographic memory", "reason": "This paper is highly relevant because it addresses the generation of long-term temporal dependencies in videos, which is a major challenge in talking head generation and is directly addressed by the PBNet component of DAWN. This paper introduces a novel approach to generating long sequences of data, which is relevant to the generation of talking head videos. This work is also relevant to DAWN due to its focus on generating videos with natural movements.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Jiankang Deng", "paper_title": "Arcface: Additive angular margin loss for deep face recognition", "reason": "This work introduces a method for deep face recognition, which is used in DAWN for evaluating the speaker identity preservation in the generated videos. This is a very relevant contribution to the performance evaluation of DAWN, as the speaker identity is an important aspect to preserve. This paper is important because it is a very common metric in face recognition tasks, providing a widely accepted and relevant technique.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "This paper introduces a scalable diffusion model architecture suitable for generating high-resolution videos, addressing challenges encountered in generating long videos.  The efficient architecture and scalability directly address challenges faced in applying diffusion models to talking head generation, making it highly relevant to DAWN.  This work offers techniques to make diffusion models more scalable which is very relevant to the efficient generation of videos.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "KR Prajwal", "paper_title": "A lip sync expert is all you need for speech to lip generation in the wild", "reason": "This paper focuses on the specific problem of lip synchronization with audio, a critical component in talking head generation. The techniques employed in this paper provide a baseline for comparing the performance of DAWN with other approaches to lip synchronization. This is a key aspect that is evaluated in the experimental section and therefore is highly important to the results of the paper.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Yang Zhou", "paper_title": "Makelttalk: speaker-aware talking-head animation", "reason": "This paper is highly relevant to DAWN because it proposes a method for generating talking head videos that is speaker-aware. This addresses the specific challenge of generating realistic and expressive talking head videos and is an important baseline for comparing DAWN\u2019s performance.  The methods used in this paper are relevant to the methods proposed in DAWN, and therefore serve as a good comparative basis.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Suzhen Wang", "paper_title": "Audio2head: Audio-driven one-shot talking-head generation with natural head motion", "reason": "This paper presents a method for generating talking heads with natural head motion from audio.  DAWN improves upon this method by using a diffusion model and a novel training strategy to improve performance. It offers a direct comparison point for DAWN which also deals with generating natural head motion in the output videos.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Wenxuan Zhang", "paper_title": "Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation", "reason": "This work is closely related to DAWN's approach to generating talking head videos, focusing on the use of 3D motion coefficients.  This is an important contribution to the field because it allows for generating more realistic and natural head movements. The generation of high-fidelity videos serves as an important benchmark for comparison with DAWN. The experimental evaluation of the model's performance can also be used as a benchmark for DAWN.", "section_number": 4}]}