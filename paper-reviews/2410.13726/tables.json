[{"figure_path": "2410.13726/tables/table_8_0.html", "caption": "Table 1: Quantitative comparison with several state-of-the-art methods methods on HDTF (Zhang et al., 2021) and CREMA (Cao et al., 2014) datasets. * Wav2Lip generated videos that only contain lip motions, while the rest remain still images. \u201c\u2191\u201d indicates better performance with higher values, while \u201c\u2193\u201d indicates better performance with lower values. For both BAS and Blink/s, we consider performance to be better when they are closer to the ground truth.", "description": "Table 1 quantitatively compares the performance of DAWN against other state-of-the-art methods on two datasets using various metrics, including FID, FVD, LSE, CSIM, BAS, and Blink/s.", "section": "4.2 OVERALL COMPARISON"}, {"figure_path": "2410.13726/tables/table_9_0.html", "caption": "Table 2: Comparison with other generation strategies. The semi-autoregressive (SAR) generation strategy is similar to He et al. (2023). The two temporal resolution (TTR) generation method is mentioned in Harvey et al. (2022).", "description": "Table 2 compares the proposed non-autoregressive method with SAR and TTR methods in terms of generation time, FID, FVD16, FVD32, LSEC, and LSED scores on the CREMA dataset.", "section": "4.3 COMPARISON WITH OTHER GENERATION STRATEGIES"}, {"figure_path": "2410.13726/tables/table_9_1.html", "caption": "Table 3: The experiment of extrapolation evaluation. \u201cInference length\u201d refers to the number of frames generated in a single inference process.", "description": "Table 3 shows the quantitative results of the extrapolation experiment by changing the inference length, demonstrating the stable performance of the model across different lengths.", "section": "4.4 EXTRAPOLATION VALIDATION"}, {"figure_path": "2410.13726/tables/table_10_0.html", "caption": "Table 4: Ablation study on TCL and PBNet. The \u201cGT PB\u201d refers to whether to use ground truth pose/blink signal.", "description": "Table 4 presents the ablation study results of the two-stage curriculum learning (TCL) and Pose and Blink generation Network (PBNet), comparing different model configurations on various metrics such as FID, FVD16, FVD32, LSEC, and LSED.", "section": "4.5 ABLATION STUDY"}, {"figure_path": "2410.13726/tables/table_16_0.html", "caption": "Table 5: Ablation study on the local attention mechanism. The \"window\" means the window size in the local attention operation. The \u201cNone\u201d means we use the original attention mechanism instead.", "description": "Table 5 shows the ablation study on the local attention mechanism with different window sizes, showing that a window size of 80 yields the best performance.", "section": "4.3 Comparison with other generation strategies"}]