{"references": [{"fullname_first_author": "Alex Graves", "paper_title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks", "publication_date": "2006-01-01", "reason": "This paper introduced Connectionist Temporal Classification (CTC), a fundamental technique used in speech recognition, directly relevant to VITA-1.5's speech processing capabilities."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-01-01", "reason": "This foundational paper established the effectiveness of large language models (LLMs) as few-shot learners, a core concept for VITA-1.5's multimodal learning approach."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper introduced visual instruction tuning, a key technique used in VITA-1.5 to enhance visual and language understanding, demonstrating a direct influence on VITA-1.5's development."}, {"fullname_first_author": "Alexei Baevski", "paper_title": "wav2vec 2.0: A framework for self-supervised learning of speech representations", "publication_date": "2020-01-01", "reason": "This paper introduced wav2vec 2.0, a significant advancement in self-supervised speech representation learning, directly relevant to VITA-1.5's speech encoding and decoding processes."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "VITA: Towards open-source interactive omni multimodal LLM", "publication_date": "2024-01-01", "reason": "This paper introduced VITA-1.0, a precursor to VITA-1.5, forming the foundation of its architecture and multi-modal approach, thus serving as a crucial preceding work."}]}