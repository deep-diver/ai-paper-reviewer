{"references": [{"fullname_first_author": "Joya Chen", "paper_title": "VideoLLM-Online: Online video large language model for streaming video", "publication_date": "2024-00-00", "reason": "This paper proposes a framework similar to the one proposed in the main paper, enabling real-time interactions with video streams, which serves as a strong basis for comparison and validation."}, {"fullname_first_author": "Kristen Grauman", "paper_title": "Ego4D: Around the world in 3,000 hours of egocentric video", "publication_date": "2021-00-00", "reason": "As a large-scale egocentric video dataset, Ego4D is crucial for training and evaluating video large language models, which are the subject of the main paper."}, {"fullname_first_author": "Ranjay Krishna", "paper_title": "Dense-captioning events in videos", "publication_date": "2017-00-00", "reason": "This paper introduces dense video captioning, a task that the main paper improves upon by incorporating a novel interaction format."}, {"fullname_first_author": "Bo Li", "paper_title": "LLaVA-OneVision: Easy visual task transfer", "publication_date": "2024-00-00", "reason": "LLaVA-OneVision is used as the pre-trained model for the main paper, highlighting its importance as a foundational model for the proposed approach."}, {"fullname_first_author": "Andreea-Maria Oncescu", "paper_title": "QueryD: A video dataset with high-quality text and audio narrations", "publication_date": "2021-00-00", "reason": "The QueryD dataset is utilized for the temporal video grounding task in the main paper, highlighting its importance for evaluating time-sensitive video comprehension."}]}