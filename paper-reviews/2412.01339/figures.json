[{"figure_path": "https://arxiv.org/html/2412.01339/x1.png", "caption": "(a) Adversarial Guidance across Different Outputs: State-of-the-art diffusion models are observed to suffer from limited diversity (e.g., ethnic, racial, gender etc.). NegToMe can be used to improve output diversity by simply guiding the features of each image away from each other during reverse diffusion.", "description": "This figure demonstrates how NegToMe enhances the diversity of outputs from diffusion models.  The top row shows the outputs of a state-of-the-art diffusion model without NegToMe, revealing a lack of diversity in terms of ethnicity, race, and gender. The bottom row displays the results when NegToMe is used.  By guiding the features of each image away from one another during reverse diffusion, NegToMe increases the diversity of the generated images.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.01339/x2.png", "caption": "(b) Adversarial Guidance with Copyrighted Content: Diffusion models can generate copyrighted content. Moreover, using negative prompt for avoiding this is often insufficient. NegToMe helps better reduce similarity to copyrighted characters, by guiding diffusion features away from copyrighted images.", "description": "This figure demonstrates how NegToMe reduces the generation of copyrighted content by diffusion models.  The standard approach of using negative prompts is often ineffective at preventing this.  NegToMe improves upon this by directly guiding the diffusion model's features away from copyrighted images, resulting in generated images with significantly reduced similarity to the protected material. This is illustrated by comparing outputs with and without NegToMe applied, showcasing its effectiveness in mitigating copyright infringement.", "section": "Adversarial Guidance with Copyrighted Content"}, {"figure_path": "https://arxiv.org/html/2412.01339/extracted/6048074/assets/fid_vs_guidance_scale.png", "caption": "Figure 1: \nWe introduce NegToMe, a\ntraining-free approach for adversarial guidance directly using images instead of a negative prompt.\nAbove we show its applications for a) improving output diversity (visual, gender, racial) by guiding each image away from others, b) reducing visual similarity to copyrighted characters, by guiding outputs away from copyrighted images. (refer Sec.\u00a04 for further applications).", "description": "This figure demonstrates the capabilities of NegToMe, a novel training-free method for adversarial guidance in image generation models.  It showcases NegToMe's ability to enhance diversity in generated images by guiding features away from each other (illustrated with examples showing improvements in visual, gender, and racial diversity).  Additionally, it highlights NegToMe's effectiveness in mitigating the generation of copyrighted content by guiding the generation process away from copyrighted reference images.  Further applications are mentioned and detailed in Section 4 of the paper.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.01339/extracted/6048074/assets/is_vs_guidance_scale.png", "caption": "Figure 2: \nImage-based adversarial guidance. NegToMe enables directly using images (instead of negative prompt alone) for adversarial guidance. By simply adjusting the used reference, NegToMe allows for a range of custom applications, 1) adversarial guidance for visually complex concepts to improve diversity, 2) Style control for excluding specific artistic styles (e.g., Van Gogh) from generated images, 3) improving output quality by guiding away from a blurry reference, 4) Object feature interpolation or extrapolation by guiding the outputs towards or away from the reference etc.", "description": "Figure 2 demonstrates the versatility of NegToMe in performing image-based adversarial guidance.  Unlike text-based negative prompts, NegToMe uses reference images to directly steer the generation process. This allows for several applications: improving output diversity by guiding features away from each other (e.g., achieving more diverse representation across demographics); controlling style by excluding specific artistic styles; enhancing output quality by guiding away from blurry references; and performing object feature interpolation or extrapolation.  The figure visually shows various scenarios illustrating these capabilities.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.01339/extracted/6048074/assets/dreamsim_vs_guidance_scale.png", "caption": "Figure 3: Method Overview. (a) The core idea of NegToMe is to perform adversarial guidance directly using visual features from a reference image (or other images in the same batch). (b) NegToMe is simple and can be applied in any transformer block. (c) A simple three step process for performing adversarial guidance using NegToMe (refer Sec.\u00a03 and Alg.\u00a01 for the detailed implementation).", "description": "This figure illustrates the core concept and implementation of Negative Token Merging (NegToMe). (a) shows how NegToMe uses visual features from a reference image (or other images in a batch) to perform adversarial guidance.  Instead of relying on text-based negative prompts, it leverages the visual similarity between the reference and generated images. (b) highlights the simplicity of NegToMe, demonstrating its applicability within any transformer block.  (c) provides a step-by-step breakdown of the NegToMe process, which involves semantic token matching, thresholding for similarity, and linear extrapolation to push source tokens away from target tokens.  More details can be found in Section 3 and Algorithm 1 of the paper.", "section": "3. Negative Token Merging"}, {"figure_path": "https://arxiv.org/html/2412.01339/extracted/6048074/assets/entropy_vs_guidance_scale.png", "caption": "Figure 4: Quantitative Results for Output Diversity. NegToMe (ours) helps improve output diversity (lower DreamSim score and higher Entropy) while preserving or improving quality (lower FID and higher IS) across different CFG scales for both SDXL and FLUX.", "description": "This figure presents a quantitative analysis of the impact of NegToMe on the diversity and quality of generated images using two different diffusion models, SDXL and FLUX.  The results are shown across a range of Classifier-Free Guidance (CFG) scales.  Lower DreamSim scores indicate improved diversity, while higher Entropy values also suggest increased diversity.  Simultaneously, lower FID (Fr\u00e9chet Inception Distance) and higher IS (Inception Score) demonstrate that NegToMe either maintains or enhances the quality of the generated images.", "section": "4.1. Increasing Output Diversity"}, {"figure_path": "https://arxiv.org/html/2412.01339/x8.png", "caption": "Figure 5: Increasing Output Diversity. We observe that when performed w.r.t to images in the same batch (the first image of each batch in above), NegToMe significantly improves output diversity (racial, ethnic, visual) while preserving output image quality.", "description": "Figure 5 showcases the impact of NegToMe on enhancing the diversity of generated images.  By using NegToMe with other images from the same batch (specifically, the first image in each batch), the model produces a wider range of outputs in terms of race, ethnicity, and overall visual style. Importantly, this increased diversity is achieved without sacrificing the quality of the generated images.", "section": "4.1. Increasing Output Diversity"}, {"figure_path": "https://arxiv.org/html/2412.01339/x9.png", "caption": "Figure 6: NegToMe helps improve output diversity both with (row-2) and without explicit prompt-rewriting (PW) (row-4).", "description": "Figure 6 presents a comparison of image generation results using different methods.  The top row shows images generated with a base prompt, while the second row shows images generated with NegToMe applied to the base prompt. The third row shows images generated with a prompt rewritten using GPT-4, and the fourth row presents images generated with NegToMe combined with a GPT-4 rewritten prompt.  This illustrates that NegToMe improves image diversity both when used with and without explicit prompt rewriting.", "section": "4.1. Increasing Output Diversity"}]