[{"figure_path": "2410.11900/tables/table_4_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of four large language models across nine reasoning benchmarks using three different reasoning techniques: FLARE, CoT, and F-CoT.", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_6_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "The table presents the performance of different reasoning techniques (FLARE, CoT, and F-CoT) across various models on nine benchmark datasets, highlighting the best-performing method for each dataset and model.", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_7_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of various LLMs across nine reasoning benchmarks using three different reasoning techniques (FLARE, CoT, and F-CoT).", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_8_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of different LLMs using three reasoning techniques (FLARE, CoT, and F-CoT) across nine diverse reasoning benchmarks.", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_9_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of four different large language models across nine reasoning benchmarks, comparing three reasoning techniques: FLARE, CoT, and F-CoT.", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_19_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of various LLMs using three different reasoning techniques (FLARE, CoT, and F-CoT) across nine diverse reasoning benchmarks.", "section": "4 Main Results"}, {"figure_path": "2410.11900/tables/table_20_0.html", "caption": "Table 1: The following table shows the performance of each of the tested models given a technique for reasoning. Each bold, underlined, and italicised element highlights the best, second best and worst technique per specific model. The overall best method per dataset is highlighted in green", "description": "Table 1 presents the performance of different reasoning techniques (FLARE, CoT, F-CoT) across various LLMs and nine benchmark datasets, highlighting the best-performing method for each.", "section": "4 Main Results"}]