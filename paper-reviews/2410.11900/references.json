{"references": [{" publication_date": "2020", "fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is foundational for understanding the capabilities and limitations of large language models (LLMs) in few-shot learning scenarios, which is directly relevant to the core methodology of the current paper.  The authors demonstrate that LLMs can perform surprisingly well on various tasks with minimal training data, but also highlight the limitations, particularly in complex reasoning tasks, which motivates the current paper's approach.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "reason": "This paper introduces Chain-of-Thought (CoT) prompting, a technique that the current paper aims to improve upon. Understanding the strengths and weaknesses of CoT is crucial for evaluating the novelty and significance of FLARE, the proposed method in this paper. The limitations of CoT in terms of faithfulness and performance in complex reasoning tasks directly relate to the motivation and design of FLARE.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Jundong Xu", "paper_title": "Faithful logical reasoning via symbolic chain-of-thought", "reason": "This paper introduces Faithful CoT (F-CoT), an approach the current paper builds upon and aims to improve. By understanding F-CoT's strengths (high faithfulness) and limitations (reliance on strictly formalizable queries), the current paper can more effectively justify the novelty and significance of its proposed FLARE method.", "section_number": 1}, {" publication_date": "2018", "fullname_first_author": "Kenneth A. Bowen", "paper_title": "Prolog", "reason": "This paper describes the fundamental concepts of Prolog, a logic programming language used in the proposed FLARE method.  Understanding Prolog's declarative nature, its search strategies (depth-first search), and its capabilities in symbolic reasoning is essential for grasping the technical details of FLARE and its advantages over existing methods.", "section_number": 2}, {" publication_date": "1985", "fullname_first_author": "Ashok K. Chandra", "paper_title": "Horn clauses queries and generalizations", "reason": "This paper provides a theoretical foundation for the use of Horn clauses and logic programming, which are central to the FLARE approach.  It helps explain the formal underpinnings of the reasoning process employed in FLARE, providing a deeper understanding of the method's theoretical basis.", "section_number": 2}, {" publication_date": "1994", "fullname_first_author": "John W. Lloyd", "paper_title": "Practical advantages of declarative programming", "reason": "This paper discusses the practical benefits of declarative programming, which is highly relevant to the current paper's approach. It supports the choice of using Prolog in FLARE by highlighting the advantages of declarative paradigms in terms of expressiveness, maintainability, and ease of reasoning.", "section_number": 2}, {" publication_date": "2004", "fullname_first_author": "Chin-Yew Lin", "paper_title": "ROUGE: A package for automatic evaluation of summaries", "reason": "This paper describes ROUGE, a widely used metric for evaluating the quality of summaries and text generation.  The current paper utilizes ROUGE-Lsum to quantitatively measure the faithfulness of the LLM's reasoning process in FLARE, comparing the generated search paths to the actual execution paths of the Prolog code. The choice of ROUGE-Lsum is justified by its ability to handle sequence-level comparisons effectively.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "reason": "This paper introduces the GSM8K dataset, one of the benchmarks used to evaluate the performance of FLARE. Understanding the characteristics of this dataset, particularly its focus on mathematical reasoning tasks, is vital for assessing the significance of FLARE's results on this particular benchmark.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Arkil Patel", "paper_title": "Are NLP models really able to solve simple math word problems?", "reason": "This paper introduces the SVAMP dataset, another benchmark dataset used to evaluate FLARE's performance.  Understanding the nature of this dataset is crucial for interpreting the results and demonstrating the applicability of FLARE to diverse mathematical reasoning tasks.", "section_number": 3}, {" publication_date": "2015", "fullname_first_author": "Subhro Roy", "paper_title": "Solving general arithmetic word problems", "reason": "This paper introduces the MultiArith dataset, a benchmark dataset used in the evaluation of FLARE.  Understanding this dataset's focus on arithmetic reasoning is important for correctly interpreting FLARE's results and establishing the relevance of the proposed approach to this specific type of reasoning.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Shen-Yun Miao", "paper_title": "A diverse corpus for evaluating and developing english math word problem solvers", "reason": "This paper introduces the ASDiv dataset, a benchmark dataset used for evaluating FLARE's performance. Understanding the characteristics of this dataset, especially its diversity and focus on arithmetic word problems, is critical for assessing the significance of FLARE's performance on this benchmark dataset.", "section_number": 3}, {" publication_date": "2017", "fullname_first_author": "Wang Ling", "paper_title": "Program induction by rationale generation: Learning to solve and explain algebraic word problems", "reason": "This paper discusses the AQUA dataset, another benchmark dataset used for the evaluation of FLARE.  Understanding the properties of this dataset, such as the type of reasoning required, is essential for interpreting the results and for demonstrating the applicability of FLARE to this type of reasoning.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Mor Geva", "paper_title": "Did aristotle use a laptop?", "reason": "This paper describes the StrategyQA dataset, a benchmark dataset used to assess FLARE's performance.  Understanding this dataset's characteristics (multi-hop reasoning, boolean answers) is critical for evaluating the results and for demonstrating the efficacy of FLARE on this specific reasoning problem type.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Koustuv Sinha", "paper_title": "CLUTRR: A diagnostic benchmark for inductive reasoning from text", "reason": "This paper introduces the CLUTRR dataset, a key benchmark used to evaluate FLARE's performance in relation inference tasks.  Understanding the nature of this dataset is critical for interpreting the results and showcasing FLARE's ability to perform effectively on tasks involving relational reasoning.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Tamera Lanham", "paper_title": "Measuring faithfulness in chain-of-thought reasoning", "reason": "This paper discusses the importance of faithfulness in LLM reasoning, a concept that the current paper addresses directly.  By understanding the challenges of ensuring faithfulness in LLMs, this paper provides context for evaluating the novelty and impact of FLARE's approach to measuring faithfulness, which is a key contribution of the current paper.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Leilani H. Gilpin", "paper_title": "Explaining explanations: An overview of interpretability of machine learning", "reason": "This paper provides a foundational overview of the concept of interpretability in machine learning, which is highly relevant to the work presented in the current paper.  By understanding the broader context of interpretability, this paper helps frame the current paper's focus on improving the interpretability and faithfulness of LLM reasoning.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Alon Jacovi", "paper_title": "A chain-of-thought is as strong as its weakest link: A benchmark for verifiers of reasoning chains", "reason": "This paper emphasizes the importance of the overall chain of reasoning and the significance of its weakest links.  The current paper addresses the inherent limitations of Chain-of-Thought (CoT) prompting, which often produces unfaithful reasoning chains. By improving the consistency and faithfulness of the reasoning process, FLARE directly addresses the issues highlighted in this paper.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Shunyu Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "reason": "This paper proposes the Tree-of-Thoughts (ToT) approach, an alternative method for expanding the reasoning space in LLMs.  The current paper presents FLARE as an advancement over this and other search methods and it is therefore important to understand ToT's strengths and limitations.  By discussing ToT, the authors position FLARE more precisely within the landscape of current LLM reasoning techniques.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Juyong Jiang", "paper_title": "A survey on large language models for code generation", "reason": "This paper reviews the existing literature on using LLMs for code generation, a task directly relevant to the current paper's approach.  By understanding the strengths and limitations of existing code generation techniques, the current paper can better position its own method (FLARE) within the broader context of LLMs and code generation. This is particularly important given FLARE's use of LLMs for generating Prolog code.", "section_number": 5}]}