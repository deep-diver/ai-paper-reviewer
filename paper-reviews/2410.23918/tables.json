[{"content": "## Table 1: Model performance comparison\n\n| Model | Memory (MB) | Method | Wiki2 (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | ARC-e (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | ARC-c (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | PIQA (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | HellaS. (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | WinoG. (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | LAMBADA (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) | Avg. (<img src=\"https://arxiv.org/html/2410.23918/filename.png\">) |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 8B | 15316 | FP 16 | 6.24 | 81.1<sub>\u00b10.8</sub> | 53.6<sub>\u00b11.5</sub> | 81.2<sub>\u00b10.9</sub> | 78.9<sub>\u00b10.4</sub> | 73.9<sub>\u00b11.2</sub> | 75.8<sub>\u00b10.6</sub> | 74.1<sub>\u00b10.9</sub> |\n|  | 3674<sub>(76%)</sub> | GPTQ<sub>w2</sub> | 1.2e6 | 26.0<sub>\u00b10.9</sub> | 27.1<sub>\u00b11.3</sub> | 51.7<sub>\u00b11.2</sub> | 26.0<sub>\u00b10.4</sub> | 48.5<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.9<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w2</sub> | 1.1e6 | 24.9<sub>\u00b10.9</sub> | 23.6<sub>\u00b11.2</sub> | 49.6<sub>\u00b11.2</sub> | 26.2<sub>\u00b10.4</sub> | 52.2<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.4<sub>\u00b10.9</sub> |\n|  |  | BitStack | 3.3e3 | 29.3<sub>\u00b10.9</sub> | 23.4<sub>\u00b11.2</sub> | 53.4<sub>\u00b11.2</sub> | 27.9<sub>\u00b10.4</sub> | 50.7<sub>\u00b11.4</sub> | 0.2<sub>\u00b10.1</sub> | 30.8<sub>\u00b10.9</sub> |\n|  | 3877<sub>(75%)</sub> | GPTQ<sub>w2g128</sub> | 1.7e5 | 25.9<sub>\u00b10.9</sub> | 26.0<sub>\u00b11.3</sub> | 53.9<sub>\u00b11.2</sub> | 26.5<sub>\u00b10.4</sub> | 49.6<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 30.3<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w2g128</sub> | 1.5e6 | 24.6<sub>\u00b10.9</sub> | 24.7<sub>\u00b11.3</sub> | 50.0<sub>\u00b11.2</sub> | 26.4<sub>\u00b10.4</sub> | 46.7<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 28.7<sub>\u00b10.9</sub> |\n|  |  | BitStack | 79.28 | 48.4<sub>\u00b11.0</sub> | 26.0<sub>\u00b11.3</sub> | 66.5<sub>\u00b11.1</sub> | 41.0<sub>\u00b10.5</sub> | 57.1<sub>\u00b11.4</sub> | 15.5<sub>\u00b10.5</sub> | 42.4<sub>\u00b11.0</sub> |\n|  | 4506<sub>(71%)</sub> | GPTQ<sub>w3</sub> | 260.86 | 34.7<sub>\u00b11.0</sub> | 24.5<sub>\u00b11.3</sub> | 57.6<sub>\u00b11.2</sub> | 30.4<sub>\u00b10.5</sub> | 53.0<sub>\u00b11.4</sub> | 3.0<sub>\u00b10.2</sub> | 33.9<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w3</sub> | 17.01 | 67.0<sub>\u00b11.0</sub> | 42.9<sub>\u00b11.4</sub> | 72.6<sub>\u00b11.0</sub> | 67.3<sub>\u00b10.5</sub> | 62.6<sub>\u00b11.4</sub> | 53.3<sub>\u00b10.7</sub> | 61.0<sub>\u00b11.0</sub> |\n|  |  | BitStack | 12.55 | 68.5<sub>\u00b11.0</sub> | 39.4<sub>\u00b11.4</sub> | 75.5<sub>\u00b11.0</sub> | 63.4<sub>\u00b10.5</sub> | 65.8<sub>\u00b11.3</sub> | 66.2<sub>\u00b10.7</sub> | 63.1<sub>\u00b11.0</sub> |\n|  | 4709<sub>(69%)</sub> | GPTQ<sub>w3g128</sub> | 38.28 | 55.3<sub>\u00b11.0</sub> | 33.9<sub>\u00b11.4</sub> | 66.9<sub>\u00b11.1</sub> | 53.1<sub>\u00b10.5</sub> | 61.9<sub>\u00b11.4</sub> | 46.9<sub>\u00b10.7</sub> | 53.0<sub>\u00b11.0</sub> |\n|  |  | AWQ<sub>w3g128</sub> | 8.06 | 74.5<sub>\u00b10.9</sub> | 48.4<sub>\u00b11.5</sub> | 77.7<sub>\u00b11.0</sub> | 73.9<sub>\u00b10.4</sub> | 70.6<sub>\u00b11.3</sub> | 67.8<sub>\u00b10.7</sub> | 68.8<sub>\u00b10.9</sub> |\n|  |  | BitStack | 10.91 | 72.7<sub>\u00b10.9</sub> | 41.6<sub>\u00b11.4</sub> | 76.7<sub>\u00b11.0</sub> | 65.9<sub>\u00b10.5</sub> | 67.8<sub>\u00b11.3</sub> | 69.6<sub>\u00b10.6</sub> | 65.7<sub>\u00b11.0</sub> |\n|  | 5338<sub>(65%)</sub> | GPTQ<sub>w4</sub> | 20.88 | 74.7<sub>\u00b10.9</sub> | 45.6<sub>\u00b11.5</sub> | 77.2<sub>\u00b11.0</sub> | 54.6<sub>\u00b10.5</sub> | 64.5<sub>\u00b11.3</sub> | 40.9<sub>\u00b10.7</sub> | 59.6<sub>\u00b11.0</sub> |\n|  |  | AWQ<sub>w4</sub> | 7.12 | 78.4<sub>\u00b10.8</sub> | 51.1<sub>\u00b11.5</sub> | 79.9<sub>\u00b10.9</sub> | 77.5<sub>\u00b10.4</sub> | 73.3<sub>\u00b11.2</sub> | 70.6<sub>\u00b10.6</sub> | 71.8<sub>\u00b10.9</sub> |\n|  |  | BitStack | 8.39 | 76.6<sub>\u00b10.9</sub> | 47.9<sub>\u00b11.5</sub> | 79.0<sub>\u00b11.0</sub> | 71.6<sub>\u00b10.4</sub> | 69.6<sub>\u00b11.3</sub> | 76.1<sub>\u00b10.6</sub> | 70.1<sub>\u00b10.9</sub> |\n|  | 5541<sub>(64%)</sub> | GPTQ<sub>w4g128</sub> | 6.83 | 78.6<sub>\u00b10.8</sub> | 51.5<sub>\u00b11.5</sub> | 79.1<sub>\u00b10.9</sub> | 77.0<sub>\u00b10.4</sub> | 71.2<sub>\u00b11.3</sub> | 72.9<sub>\u00b10.6</sub> | 71.7<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w4g128</sub> | 6.63 | 79.3<sub>\u00b10.8</sub> | 51.2<sub>\u00b11.5</sub> | 81.0<sub>\u00b10.9</sub> | 78.2<sub>\u00b10.4</sub> | 72.1<sub>\u00b11.3</sub> | 74.2<sub>\u00b10.6</sub> | 72.7<sub>\u00b10.9</sub> |\n|  |  | BitStack | 8.14 | 77.6<sub>\u00b10.9</sub> | 49.7<sub>\u00b11.5</sub> | 79.5<sub>\u00b10.9</sub> | 72.4<sub>\u00b10.4</sub> | 70.6<sub>\u00b11.3</sub> | 76.0<sub>\u00b10.6</sub> | 71.0<sub>\u00b10.9</sub> |\n| 70B | 134570 | FP 16 | 2.81 | 86.7<sub>\u00b10.7</sub> | 64.8<sub>\u00b11.4</sub> | 84.3<sub>\u00b10.8</sub> | 85.1<sub>\u00b10.4</sub> | 79.8<sub>\u00b11.1</sub> | 79.2<sub>\u00b10.6</sub> | 80.0<sub>\u00b10.8</sub> |\n|  | 20356<sub>(85%)</sub> | GPTQ<sub>w2</sub> | NaN | 24.8<sub>\u00b10.9</sub> | 26.2<sub>\u00b11.3</sub> | 50.8<sub>\u00b11.2</sub> | 26.4<sub>\u00b10.4</sub> | 51.4<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.9<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w2</sub> | 9.6e5 | 25.0<sub>\u00b10.9</sub> | 25.5<sub>\u00b11.3</sub> | 51.7<sub>\u00b11.2</sub> | 26.6<sub>\u00b10.4</sub> | 50.4<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.9<sub>\u00b10.9</sub> |\n|  |  | BitStack | 1.0e3 | 27.9<sub>\u00b10.9</sub> | 23.9<sub>\u00b11.2</sub> | 52.3<sub>\u00b11.2</sub> | 30.4<sub>\u00b10.5</sub> | 49.6<sub>\u00b11.4</sub> | 2.6<sub>\u00b10.2</sub> | 31.1<sub>\u00b10.9</sub> |\n|  | 22531<sub>(83%)</sub> | GPTQ<sub>w2g128</sub> | 4.4e5 | 23.9<sub>\u00b10.9</sub> | 25.6<sub>\u00b11.3</sub> | 51.1<sub>\u00b11.2</sub> | 26.4<sub>\u00b10.4</sub> | 50.4<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.6<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w2g128</sub> | 1.8e6 | 24.9<sub>\u00b10.9</sub> | 26.2<sub>\u00b11.3</sub> | 51.3<sub>\u00b11.2</sub> | 26.8<sub>\u00b10.4</sub> | 49.4<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.8<sub>\u00b10.9</sub> |\n|  |  | BitStack | 8.50 | 76.8<sub>\u00b10.9</sub> | 50.6<sub>\u00b11.5</sub> | 77.9<sub>\u00b11.0</sub> | 74.2<sub>\u00b10.4</sub> | 73.7<sub>\u00b11.2</sub> | 73.2<sub>\u00b10.6</sub> | 71.1<sub>\u00b10.9</sub> |\n|  | 28516<sub>(79%)</sub> | GPTQ<sub>w3</sub> | 3.7e6 | 24.7<sub>\u00b10.9</sub> | 26.8<sub>\u00b11.3</sub> | 51.1<sub>\u00b11.2</sub> | 26.3<sub>\u00b10.4</sub> | 50.5<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.9<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w3</sub> | 10.76 | 57.4<sub>\u00b11.0</sub> | 37.0<sub>\u00b11.4</sub> | 71.1<sub>\u00b11.1</sub> | 63.8<sub>\u00b10.5</sub> | 59.0<sub>\u00b11.4</sub> | 49.5<sub>\u00b10.7</sub> | 56.3<sub>\u00b11.0</sub> |\n|  |  | BitStack | 6.38 | 81.7<sub>\u00b10.8</sub> | 56.7<sub>\u00b11.4</sub> | 81.8<sub>\u00b10.9</sub> | 79.3<sub>\u00b10.4</sub> | 76.6<sub>\u00b11.2</sub> | 76.8<sub>\u00b10.6</sub> | 75.5<sub>\u00b10.9</sub> |\n|  | 30691<sub>(77%)</sub> | GPTQ<sub>w3g128</sub> | 4.4e5 | 24.2<sub>\u00b10.9</sub> | 24.2<sub>\u00b11.3</sub> | 51.7<sub>\u00b11.2</sub> | 26.0<sub>\u00b10.4</sub> | 49.3<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.2<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w3g128</sub> | 4.68 | 84.0<sub>\u00b10.8</sub> | 60.6<sub>\u00b11.4</sub> | 83.1<sub>\u00b10.9</sub> | 82.5<sub>\u00b10.4</sub> | 79.2<sub>\u00b11.1</sub> | 75.8<sub>\u00b10.6</sub> | 77.5<sub>\u00b10.9</sub> |\n|  |  | BitStack | 5.94 | 82.6<sub>\u00b10.8</sub> | 58.3<sub>\u00b11.4</sub> | 82.9<sub>\u00b10.9</sub> | 80.9<sub>\u00b10.4</sub> | 78.8<sub>\u00b11.1</sub> | 78.4<sub>\u00b10.6</sub> | 77.0<sub>\u00b10.9</sub> |\n|  | 36676<sub>(73%)</sub> | GPTQ<sub>w4</sub> | NaN | 24.9<sub>\u00b10.9</sub> | 25.3<sub>\u00b11.3</sub> | 51.4<sub>\u00b11.2</sub> | 26.8<sub>\u00b10.4</sub> | 51.1<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.9<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w4</sub> | 4.24 | 83.4<sub>\u00b10.8</sub> | 61.3<sub>\u00b11.4</sub> | 83.5<sub>\u00b10.9</sub> | 83.4<sub>\u00b10.4</sub> | 63.5<sub>\u00b11.4</sub> | 69.1<sub>\u00b10.6</sub> | 74.0<sub>\u00b10.9</sub> |\n|  |  | BitStack | 4.97 | 84.8<sub>\u00b10.7</sub> | 61.4<sub>\u00b11.4</sub> | 83.2<sub>\u00b10.9</sub> | 82.1<sub>\u00b10.4</sub> | 79.3<sub>\u00b11.1</sub> | 79.4<sub>\u00b10.6</sub> | 78.4<sub>\u00b10.9</sub> |\n|  | 38851<sub>(71%)</sub> | GPTQ<sub>w4g128</sub> | 6.5e4 | 23.4<sub>\u00b10.9</sub> | 27.3<sub>\u00b11.3</sub> | 51.9<sub>\u00b11.2</sub> | 26.6<sub>\u00b10.4</sub> | 49.9<sub>\u00b11.4</sub> | 0.0<sub>\u00b10.0</sub> | 29.8<sub>\u00b10.9</sub> |\n|  |  | AWQ<sub>w4g128</sub> | 3.27 | 86.6<sub>\u00b10.7</sub> | 63.3<sub>\u00b11.4</sub> | 83.9<sub>\u00b10.9</sub> | 84.4<sub>\u00b10.4</sub> | 78.8<sub>\u00b11.1</sub> | 77.3<sub>\u00b10.6</sub> | 79.1<sub>\u00b10.8</sub> |\n|  |  | BitStack | 4.96 | 85.1<sub>\u00b10.7</sub> | 61.3<sub>\u00b11.4</sub> | 83.5<sub>\u00b10.9</sub> | 82.6<sub>\u00b10.4</sub> | 78.8<sub>\u00b11.1</sub> | 78.7<sub>\u00b10.6</sub> | 78.3<sub>\u00b10.9</sub> |", "caption": "Table 1: Evaluation results of Llama 3.1 8B/70B models. Perplexity scores on WikiText2 test set and accuracy scores on 6 zero-shot reasoning tasks. (\u2191\u2191\\uparrow\u2191): higher is better; (\u2193\u2193\\downarrow\u2193): lower is better. We denote the overall compression ratio (1\u2212compressed model memoryoriginal model memory1compressed model memoryoriginal model memory1-\\frac{\\text{compressed model memory}}{\\text{original model memory}}1 - divide start_ARG compressed model memory end_ARG start_ARG original model memory end_ARG) after memory consumption.", "description": "This table presents a comprehensive evaluation of the BitStack model's performance on Llama 3.1 8B and 70B models across various compression ratios.  It compares BitStack against several baselines (GPTQ and AWQ) using two key metrics: perplexity (lower is better) on the WikiText2 benchmark, a common language modeling task, and accuracy (higher is better) across six zero-shot reasoning tasks.  The table shows perplexity and accuracy scores for each method at different compression levels, indicated by the model size in MB and the corresponding compression ratio (calculated as 1 minus the ratio of compressed model size to the original model size). This detailed comparison allows for a thorough assessment of BitStack's effectiveness under various memory constraints.", "section": "3.1 Evaluation on Base Models"}, {"content": "Model|Memory (MB)|Method|Wiki2 (\u2193)|ARC-e (\u2191)|ARC-c (\u2191)|PIQA (\u2191)|HellaS. (\u2191)|WinoG. (\u2191)|LAMBADA (\u2191)|Avg. (\u2191)\n---|---|---|---|---|---|---|---|---|---|---\n7B|12852|FP 16|5.47|74.5 \u00b10.9|46.2 \u00b11.5|79.1 \u00b10.9|76.0 \u00b10.4|69.1 \u00b11.3|73.9 \u00b10.6|69.8 \u00b10.9\n|2050<sub>(84%)</sub>|GPTQ<sub>w2</sub>|2.8e4|26.5 \u00b10.9|27.6 \u00b11.3|48.4 \u00b11.2|25.9 \u00b10.4|50.3 \u00b11.4|0.0 \u00b10.0|29.8 \u00b10.9\n||AWQ<sub>w2</sub>|1.8e5|26.3 \u00b10.9|26.7 \u00b11.3|50.9 \u00b11.2|26.5 \u00b10.4|49.3 \u00b11.4|0.0 \u00b10.0|30.0 \u00b10.9\n||BitStack|29.93|32.3 \u00b11.0|25.6 \u00b11.3|62.4 \u00b11.1|42.8 \u00b10.5|53.6 \u00b11.4|24.7 \u00b10.6|40.2 \u00b11.0\n|2238<sub>(83%)</sub>|GPTQ<sub>w2g128</sub>|156.37|28.2 \u00b10.9|27.1 \u00b11.3|51.7 \u00b11.2|28.0 \u00b10.4|51.1 \u00b11.4|0.3 \u00b10.1|31.1 \u00b10.9\n||AWQ<sub>w2g128</sub>|2.3e5|25.8 \u00b10.9|26.7 \u00b11.3|50.2 \u00b11.2|26.1 \u00b10.4|49.8 \u00b11.4|0.0 \u00b10.0|29.8 \u00b10.9\n||BitStack|12.49|51.8 \u00b11.0|30.1 \u00b11.3|71.1 \u00b11.1|53.0 \u00b10.5|61.1 \u00b11.4|53.3 \u00b10.7|53.4 \u00b11.0\n|2822<sub>(78%)</sub>|GPTQ<sub>w3</sub>|9.38|58.1 \u00b11.0|34.0 \u00b11.4|71.9 \u00b11.0|61.7 \u00b10.5|60.6 \u00b11.4|53.3 \u00b10.7|56.6 \u00b11.0\n||AWQ<sub>w3</sub>|14.33|52.7 \u00b11.0|33.0 \u00b11.4|68.3 \u00b11.1|56.3 \u00b10.5|59.3 \u00b11.4|36.3 \u00b10.7|51.0 \u00b11.0\n||BitStack|7.45|62.5 \u00b11.0|37.5 \u00b11.4|74.8 \u00b11.0|67.0 \u00b10.5|66.5 \u00b11.3|68.5 \u00b10.6|62.8 \u00b11.0\n|3010<sub>(77%)</sub>|GPTQ<sub>w3g128</sub>|922.54|26.3 \u00b10.9|25.3 \u00b11.3|52.4 \u00b11.2|27.4 \u00b10.4|49.0 \u00b11.4|0.1 \u00b10.0|30.1 \u00b10.9\n||AWQ<sub>w3g128</sub>|6.14|70.2 \u00b10.9|43.7 \u00b11.4|78.0 \u00b11.0|73.9 \u00b10.4|67.6 \u00b11.3|71.4 \u00b10.6|67.5 \u00b11.0\n||BitStack|7.10|63.8 \u00b11.0|38.2 \u00b11.4|76.0 \u00b11.0|68.4 \u00b10.5|65.9 \u00b11.3|70.7 \u00b10.6|63.8 \u00b11.0\n|3594<sub>(72%)</sub>|GPTQ<sub>w4</sub>|5.91|71.8 \u00b10.9|43.7 \u00b11.4|77.7 \u00b11.0|74.5 \u00b10.4|68.7 \u00b11.3|71.1 \u00b10.6|67.9 \u00b11.0\n||AWQ<sub>w4</sub>|5.81|70.9 \u00b10.9|44.5 \u00b11.5|78.5 \u00b11.0|74.8 \u00b10.4|69.2 \u00b11.3|71.5 \u00b10.6|68.2 \u00b11.0\n||BitStack|6.36|67.0 \u00b11.0|41.4 \u00b11.4|77.1 \u00b11.0|71.4 \u00b10.5|69.5 \u00b11.3|73.1 \u00b10.6|66.6 \u00b11.0\n|3782<sub>(71%)</sub>|GPTQ<sub>w4g128</sub>|5.73|73.6 \u00b10.9|45.3 \u00b11.5|78.7 \u00b11.0|75.4 \u00b10.4|67.6 \u00b11.3|72.7 \u00b10.6|68.9 \u00b10.9\n||AWQ<sub>w4g128</sub>|5.61|73.3 \u00b10.9|45.2 \u00b11.5|78.6 \u00b11.0|75.2 \u00b10.4|68.7 \u00b11.3|72.7 \u00b10.6|68.9 \u00b10.9\n||BitStack|6.27|67.8 \u00b11.0|43.3 \u00b11.4|77.2 \u00b11.0|72.2 \u00b10.4|68.6 \u00b11.3|73.9 \u00b10.6|67.2 \u00b11.0\n13B|24825|FP 16|4.88|77.4 \u00b10.9|49.1 \u00b11.5|80.5 \u00b10.9|79.4 \u00b10.4|72.2 \u00b11.3|76.8 \u00b10.6|72.6 \u00b10.9\n|3659<sub>(85%)</sub>|GPTQ<sub>w2</sub>|1.2e4|26.4 \u00b10.9|28.2 \u00b11.3|50.2 \u00b11.2|26.3 \u00b10.4|48.4 \u00b11.4|0.0 \u00b10.0|29.9 \u00b10.9\n||AWQ<sub>w2</sub>|9.6e4|27.3 \u00b10.9|28.0 \u00b11.3|49.9 \u00b11.2|26.0 \u00b10.4|50.4 \u00b11.4|0.0 \u00b10.0|30.3 \u00b10.9\n||BitStack|68.64|38.1 \u00b11.0|23.5 \u00b11.2|57.3 \u00b11.2|32.2 \u00b10.5|51.6 \u00b11.4|14.0 \u00b10.5|36.1 \u00b11.0\n|4029<sub>(84%)</sub>|GPTQ<sub>w2g128</sub>|3.9e3|26.2 \u00b10.9|28.8 \u00b11.3|50.7 \u00b11.2|26.9 \u00b10.4|48.6 \u00b11.4|0.1 \u00b10.0|30.2 \u00b10.9\n||AWQ<sub>w2g128</sub>|1.2e5|26.9 \u00b10.9|27.5 \u00b11.3|50.0 \u00b11.2|26.1 \u00b10.4|50.8 \u00b11.4|0.0 \u00b10.0|30.2 \u00b10.9\n||BitStack|9.26|64.5 \u00b11.0|34.2 \u00b11.4|73.0 \u00b11.0|60.9 \u00b10.5|64.9 \u00b11.3|65.3 \u00b10.7|60.5 \u00b11.0\n|5171<sub>(79%)</sub>|GPTQ<sub>w3</sub>|6.20|68.2 \u00b11.0|42.8 \u00b11.4|77.1 \u00b11.0|71.4 \u00b10.5|67.6 \u00b11.3|63.1 \u00b10.7|65.0 \u00b11.0\n||AWQ<sub>w3</sub>|6.46|71.1 \u00b10.9|44.4 \u00b11.5|77.6 \u00b11.0|71.2 \u00b10.5|66.8 \u00b11.3|61.9 \u00b10.7|65.5 \u00b11.0\n||BitStack|6.32|74.4 \u00b10.9|45.1 \u00b11.5|77.1 \u00b11.0|71.9 \u00b10.4|69.2 \u00b11.3|74.8 \u00b10.6|68.8 \u00b10.9\n|5541<sub>(78%)</sub>|GPTQ<sub>w3g128</sub>|5.85|73.4 \u00b10.9|45.2 \u00b11.5|78.2 \u00b11.0|74.4 \u00b10.4|68.0 \u00b11.3|67.6 \u00b10.7|67.8 \u00b11.0\n||AWQ<sub>w3g128</sub>|5.29|75.3 \u00b10.9|48.5 \u00b11.5|79.4 \u00b10.9|77.1 \u00b10.4|70.8 \u00b11.3|75.1 \u00b10.6|71.0 \u00b10.9\n||BitStack|6.04|74.4 \u00b10.9|46.2 \u00b11.5|77.9 \u00b11.0|72.6 \u00b10.4|70.6 \u00b11.3|76.6 \u00b10.6|69.7 \u00b10.9\n|6684<sub>(73%)</sub>|GPTQ<sub>w4</sub>|5.09|75.8 \u00b10.9|48.0 \u00b11.5|79.6 \u00b10.9|77.8 \u00b10.4|72.4 \u00b11.3|74.5 \u00b10.6|71.4 \u00b10.9\n||AWQ<sub>w4</sub>|5.07|78.2 \u00b10.8|49.7 \u00b11.5|80.4 \u00b10.9|78.6 \u00b10.4|71.6 \u00b11.3|76.1 \u00b10.6|72.4 \u00b10.9\n||BitStack|5.53|76.7 \u00b10.9|48.4 \u00b11.5|79.0 \u00b11.0|75.2 \u00b10.4|71.7 \u00b11.3|77.4 \u00b10.6|71.4 \u00b10.9\n|7054<sub>(72%)</sub>|GPTQ<sub>w4g128</sub>|4.97|76.4 \u00b10.9|49.2 \u00b11.5|79.9 \u00b10.9|78.8 \u00b10.4|71.7 \u00b11.3|76.0 \u00b10.6|72.0 \u00b10.9\n||AWQ<sub>w4g128</sub>|4.97|77.1 \u00b10.9|48.5 \u00b11.5|80.4 \u00b10.9|78.8 \u00b10.4|73.1 \u00b11.2|76.8 \u00b10.6|72.5 \u00b10.9\n||BitStack|5.47|76.5 \u00b10.9|48.0 \u00b11.5|79.0 \u00b11.0|75.7 \u00b10.4|71.7 \u00b11.3|77.8 \u00b10.6|71.4 \u00b10.9\n70B|131562|FP 16|3.32|81.1 \u00b10.8|57.3 \u00b11.4|82.7 \u00b10.9|83.8 \u00b10.4|78.0 \u00b11.2|79.6 \u00b10.6|77.1 \u00b10.9\n|17348<sub>(87%)</sub>|GPTQ<sub>w2</sub>|152.31|26.8 \u00b10.9|26.0 \u00b11.3|49.0 \u00b11.2|26.1 \u00b10.4|49.8 \u00b11.4|0.0 \u00b10.0|29.6 \u00b10.9\n||AWQ<sub>w2</sub>|8.0e4|25.8 \u00b10.9|28.8 \u00b11.3|50.1 \u00b11.2|25.7 \u00b10.4|48.3 \u00b11.4|0.0 \u00b10.0|29.8 \u00b10.9\n||BitStack|9.41|67.8 \u00b11.0|42.1 \u00b11.4|75.9 \u00b11.0|65.1 \u00b10.5|67.7 \u00b11.3|65.7 \u00b10.7|64.1 \u00b11.0\n|19363<sub>(85%)</sub>|GPTQ<sub>w2g128</sub>|7.79|53.0 \u00b11.0|32.0 \u00b11.4|66.9 \u00b11.1|51.1 \u00b10.5|60.2 \u00b11.4|34.8 \u00b10.7|49.7 \u00b11.0\n||AWQ<sub>w2g128</sub>|7.2e4|26.0 \u00b10.9|28.9 \u00b11.3|49.8 \u00b11.2|25.7 \u00b10.4|51.0 \u00b11.4|0.0 \u00b10.0|30.2 \u00b10.9\n||BitStack|5.30|74.5 \u00b10.9|50.0 \u00b11.5|79.7 \u00b10.9|75.1 \u00b10.4|74.4 \u00b11.2|79.3 \u00b10.6|72.2 \u00b10.9\n|25508<sub>(81%)</sub>|GPTQ<sub>w3</sub>|4.49|75.9 \u00b10.9|52.1 \u00b11.5|80.7 \u00b10.9|79.2 \u00b10.4|75.3 \u00b11.2|74.3 \u00b10.6|72.9 \u00b10.9\n||AWQ<sub>w3</sub>|4.30|79.8 \u00b10.8|55.4 \u00b11.5|81.4 \u00b10.9|81.2 \u00b10.4|73.6 \u00b11.2|73.1 \u00b10.6|74.1 \u00b10.9\n||BitStack|4.33|78.9 \u00b10.8|54.9 \u00b11.5|81.7 \u00b10.9|79.9 \u00b10.4|76.6 \u00b11.2|80.1 \u00b10.6|75.3 \u00b10.9\n|27523<sub>(79%)</sub>|GPTQ<sub>w3g128</sub>|55.43|27.8 \u00b10.9|27.4 \u00b11.3|50.9 \u00b11.2|29.8 \u00b10.5|48.9 \u00b11.4|9.5 \u00b10.4|32.4 \u00b10.9\n||AWQ<sub>w3g128</sub>|3.74|79.0 \u00b10.8|56.7 \u00b11.4|82.8 \u00b10.9|82.3 \u00b10.4|76.6 \u00b11.2|79.3 \u00b10.6|76.1 \u00b10.9\n||BitStack|4.07|79.8 \u00b10.8|55.4 \u00b11.5|82.4 \u00b10.9|80.7 \u00b10.4|77.3 \u00b11.2|81.6 \u00b10.5|76.2 \u00b10.9\n|33668<sub>(74%)</sub>|GPTQ<sub>w4</sub>|3.59|79.3 \u00b10.8|54.9 \u00b11.5|82.2 \u00b10.9|82.8 \u00b10.4|77.2 \u00b11.2|79.1 \u00b10.6|75.9 \u00b10.9\n||AWQ<sub>w4</sub>|3.48|80.6 \u00b10.8|57.9 \u00b11.4|82.8 \u00b10.9|83.2 \u00b10.4|76.5 \u00b11.2|78.8 \u00b10.6|76.6 \u00b10.9\n||BitStack|3.76|79.3 \u00b10.8|57.4 \u00b11.4|82.4 \u00b10.9|81.8 \u00b10.4|77.9 \u00b11.2|81.0 \u00b10.5|76.6 \u00b10.9\n|35683<sub>(73%)</sub>|GPTQ<sub>w4g128</sub>|3.42|81.3 \u00b10.8|57.8 \u00b11.4|83.0 \u00b10.9|83.6 \u00b10.4|76.8 \u00b11.2|79.4 \u00b10.6|77.0 \u00b10.9\n||AWQ<sub>w4g128</sub>|3.41|80.3 \u00b10.8|56.7 \u00b11.4|83.1 \u00b10.9|83.4 \u00b10.4|78.1 \u00b11.2|79.6 \u00b10.6|76.9 \u00b10.9\n||BitStack|3.71|79.7 \u00b10.8|57.1 \u00b11.4|82.2 \u00b10.9|82.1 \u00b10.4|77.9 \u00b11.2|81.7 \u00b10.5|76.8 \u00b10.9", "caption": "Table 2: Evaluation results of Llama 2 7B/13B/70B models. Perplexity scores on WikiText2 test set and accuracy scores on 6 zero-shot reasoning tasks. (\u2191\u2191\\uparrow\u2191): higher is better; (\u2193\u2193\\downarrow\u2193): lower is better. We denote the overall compression ratio (1\u2212compressed model memoryoriginal model memory1compressed model memoryoriginal model memory1-\\frac{\\text{compressed model memory}}{\\text{original model memory}}1 - divide start_ARG compressed model memory end_ARG start_ARG original model memory end_ARG) after memory consumption.", "description": "Table 2 presents a comprehensive evaluation of the BitStack model's performance on three different sizes of Llama 2 language models (7B, 13B, and 70B parameters).  The evaluation includes two key metrics: perplexity scores (lower is better) on the WikiText2 dataset, a common benchmark for language model performance, and accuracy scores (higher is better) across six zero-shot reasoning tasks.  These zero-shot tasks assess the model's ability to perform reasoning tasks without any explicit training on those specific tasks. The table also shows the memory consumption of the compressed models using BitStack, as well as the corresponding compression ratio (percentage reduction in memory usage compared to the original FP16 model). The results are compared to those obtained using other widely used compression methods like GPTQ and AWQ, allowing for a direct performance comparison. This comprehensive evaluation helps to demonstrate the effectiveness of BitStack in achieving a balance between model size and performance in variable memory environments.", "section": "3.1 Evaluation on Base Models"}, {"content": "Model|Memory (MB)|Method|Wiki2 (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|ARC-e (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|ARC-c (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|PIQA (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|HellaS. (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|WinoG. (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|LAMBADA (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)|Avg. (<img src=\"https://arxiv.org/html/2410.23918/uparrow.png\">)\n---|---|---|---|---|---|---|---|---|---|---\n8B|15316|FP 16|6.13|77.7<sub>\u00b10.9</sub>|53.3<sub>\u00b11.5</sub>|80.8<sub>\u00b10.9</sub>|79.2<sub>\u00b10.4</sub>|72.7<sub>\u00b11.3</sub>|76.1<sub>\u00b10.6</sub>|73.3<sub>\u00b10.9</sub>\n|3674<sub>(76%)</sub>|GPTQ<sub>w2</sub>|1.1e6|25.3<sub>\u00b10.9</sub>|26.7<sub>\u00b11.3</sub>|50.6<sub>\u00b11.2</sub>|26.4<sub>\u00b10.4</sub>|51.0<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|30.0<sub>\u00b10.9</sub>\n||AWQ<sub>w2</sub>|1.1e6|25.2<sub>\u00b10.9</sub>|24.1<sub>\u00b11.2</sub>|50.7<sub>\u00b11.2</sub>|26.2<sub>\u00b10.4</sub>|48.6<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.1<sub>\u00b10.9</sub>\n||BitStack|1.5e3|29.5<sub>\u00b10.9</sub>|23.9<sub>\u00b11.2</sub>|53.4<sub>\u00b11.2</sub>|27.7<sub>\u00b10.4</sub>|50.6<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|30.9<sub>\u00b10.9</sub>\n|3877<sub>(75%)</sub>|GPTQ<sub>w2g128</sub>|1.2e5|26.1<sub>\u00b10.9</sub>|25.9<sub>\u00b11.3</sub>|50.7<sub>\u00b11.2</sub>|26.0<sub>\u00b10.4</sub>|50.0<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.8<sub>\u00b10.9</sub>\n||AWQ<sub>w2g128</sub>|1.7e6|24.8<sub>\u00b10.9</sub>|24.4<sub>\u00b11.3</sub>|50.4<sub>\u00b11.2</sub>|26.4<sub>\u00b10.4</sub>|50.5<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.4<sub>\u00b10.9</sub>\n||BitStack|96.87|48.5<sub>\u00b11.0</sub>|25.3<sub>\u00b11.3</sub>|64.0<sub>\u00b11.1</sub>|37.1<sub>\u00b10.5</sub>|56.7<sub>\u00b11.4</sub>|9.4<sub>\u00b10.4</sub>|40.2<sub>\u00b10.9</sub>\n|4506<sub>(71%)</sub>|GPTQ<sub>w3</sub>|9.6e4|26.0<sub>\u00b10.9</sub>|25.7<sub>\u00b11.3</sub>|50.9<sub>\u00b11.2</sub>|27.1<sub>\u00b10.4</sub>|50.3<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|30.0<sub>\u00b10.9</sub>\n||AWQ<sub>w3</sub>|12.08|61.7<sub>\u00b11.0</sub>|38.8<sub>\u00b11.4</sub>|71.4<sub>\u00b11.1</sub>|68.6<sub>\u00b10.5</sub>|65.0<sub>\u00b11.3</sub>|51.9<sub>\u00b10.7</sub>|59.6<sub>\u00b11.0</sub>\n||BitStack|12.79|69.4<sub>\u00b10.9</sub>|38.7<sub>\u00b11.4</sub>|75.6<sub>\u00b11.0</sub>|63.5<sub>\u00b10.5</sub>|65.9<sub>\u00b11.3</sub>|66.6<sub>\u00b10.7</sub>|63.3<sub>\u00b11.0</sub>\n|4709<sub>(69%)</sub>|GPTQ<sub>w3g128</sub>|8.00|73.1<sub>\u00b10.9</sub>|46.4<sub>\u00b11.5</sub>|77.8<sub>\u00b11.0</sub>|74.5<sub>\u00b10.4</sub>|71.6<sub>\u00b11.3</sub>|68.5<sub>\u00b10.6</sub>|68.7<sub>\u00b10.9</sub>\n||AWQ<sub>w3g128</sub>|8.09|70.7<sub>\u00b10.9</sub>|44.0<sub>\u00b11.5</sub>|77.9<sub>\u00b11.0</sub>|73.4<sub>\u00b10.4</sub>|70.5<sub>\u00b11.3</sub>|69.7<sub>\u00b10.6</sub>|67.7<sub>\u00b11.0</sub>\n||BitStack|11.45|71.6<sub>\u00b10.9</sub>|42.2<sub>\u00b11.4</sub>|76.7<sub>\u00b11.0</sub>|65.8<sub>\u00b10.5</sub>|67.3<sub>\u00b11.3</sub>|68.6<sub>\u00b10.6</sub>|65.4<sub>\u00b11.0</sub>\n|5338<sub>(65%)</sub>|GPTQ<sub>w4</sub>|3.7e4|28.2<sub>\u00b10.9</sub>|25.3<sub>\u00b11.3</sub>|51.0<sub>\u00b11.2</sub>|28.7<sub>\u00b10.5</sub>|54.6<sub>\u00b11.4</sub>|0.1<sub>\u00b10.0</sub>|31.3<sub>\u00b10.9</sub>\n||AWQ<sub>w4</sub>|7.08|75.0<sub>\u00b10.9</sub>|51.5<sub>\u00b11.5</sub>|79.5<sub>\u00b10.9</sub>|77.8<sub>\u00b10.4</sub>|72.1<sub>\u00b11.3</sub>|71.1<sub>\u00b10.6</sub>|71.2<sub>\u00b10.9</sub>\n||BitStack|8.58|74.6<sub>\u00b10.9</sub>|46.2<sub>\u00b11.5</sub>|77.5<sub>\u00b11.0</sub>|72.3<sub>\u00b10.4</sub>|70.8<sub>\u00b11.3</sub>|76.0<sub>\u00b10.6</sub>|69.6<sub>\u00b10.9</sub>\n|5541<sub>(64%)</sub>|GPTQ<sub>w4g128</sub>|1.2e4|31.7<sub>\u00b11.0</sub>|23.8<sub>\u00b11.2</sub>|55.1<sub>\u00b11.2</sub>|29.3<sub>\u00b10.5</sub>|56.4<sub>\u00b11.4</sub>|0.7<sub>\u00b10.1</sub>|32.8<sub>\u00b10.9</sub>\n||AWQ<sub>w4g128</sub>|6.54|76.9<sub>\u00b10.9</sub>|52.4<sub>\u00b11.5</sub>|79.9<sub>\u00b10.9</sub>|78.1<sub>\u00b10.4</sub>|73.6<sub>\u00b11.2</sub>|73.6<sub>\u00b10.6</sub>|72.4<sub>\u00b10.9</sub>\n||BitStack|8.26|75.8<sub>\u00b10.9</sub>|47.1<sub>\u00b11.5</sub>|78.7<sub>\u00b11.0</sub>|73.1<sub>\u00b10.4</sub>|70.8<sub>\u00b11.3</sub>|76.3<sub>\u00b10.6</sub>|70.3<sub>\u00b10.9</sub>\n70B|134570|FP 16|2.85|85.9<sub>\u00b10.7</sub>|64.3<sub>\u00b11.4</sub>|84.5<sub>\u00b10.8</sub>|84.9<sub>\u00b10.4</sub>|80.7<sub>\u00b11.1</sub>|79.8<sub>\u00b10.6</sub>|80.0<sub>\u00b10.8</sub>\n|20356<sub>(85%)</sub>|GPTQ<sub>w2</sub>|3.7e5|24.7<sub>\u00b10.9</sub>|26.3<sub>\u00b11.3</sub>|51.5<sub>\u00b11.2</sub>|26.3<sub>\u00b10.4</sub>|50.0<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.8<sub>\u00b10.9</sub>\n||AWQ<sub>w2</sub>|8.6e5|25.1<sub>\u00b10.9</sub>|25.9<sub>\u00b11.3</sub>|52.3<sub>\u00b11.2</sub>|26.6<sub>\u00b10.4</sub>|47.8<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.6<sub>\u00b10.9</sub>\n||BitStack|59.37|46.5<sub>\u00b11.0</sub>|27.3<sub>\u00b11.3</sub>|65.2<sub>\u00b11.1</sub>|39.1<sub>\u00b10.5</sub>|51.9<sub>\u00b11.4</sub>|9.2<sub>\u00b10.4</sub>|39.9<sub>\u00b11.0</sub>\n|22531<sub>(83%)</sub>|GPTQ<sub>w2g128</sub>|4.0e5|25.3<sub>\u00b10.9</sub>|24.7<sub>\u00b11.3</sub>|49.3<sub>\u00b11.2</sub>|26.0<sub>\u00b10.4</sub>|50.1<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.2<sub>\u00b10.9</sub>\n||AWQ<sub>w2g128</sub>|1.7e6|24.9<sub>\u00b10.9</sub>|26.4<sub>\u00b11.3</sub>|51.4<sub>\u00b11.2</sub>|26.8<sub>\u00b10.4</sub>|51.8<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|30.2<sub>\u00b10.9</sub>\n||BitStack|8.86|74.2<sub>\u00b10.9</sub>|48.4<sub>\u00b11.5</sub>|78.1<sub>\u00b11.0</sub>|73.5<sub>\u00b10.4</sub>|73.6<sub>\u00b11.2</sub>|71.8<sub>\u00b10.6</sub>|69.9<sub>\u00b10.9</sub>\n|28516<sub>(79%)</sub>|GPTQ<sub>w3</sub>|NaN|24.6<sub>\u00b10.9</sub>|25.4<sub>\u00b11.3</sub>|51.0<sub>\u00b11.2</sub>|26.2<sub>\u00b10.4</sub>|50.4<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.6<sub>\u00b10.9</sub>\n||AWQ<sub>w3</sub>|14.04|65.5<sub>\u00b11.0</sub>|41.2<sub>\u00b11.4</sub>|73.1<sub>\u00b11.0</sub>|64.3<sub>\u00b10.5</sub>|57.4<sub>\u00b11.4</sub>|46.9<sub>\u00b10.7</sub>|58.1<sub>\u00b11.0</sub>\n||BitStack|6.88|79.8<sub>\u00b10.8</sub>|54.8<sub>\u00b11.5</sub>|80.8<sub>\u00b10.9</sub>|79.6<sub>\u00b10.4</sub>|77.0<sub>\u00b11.2</sub>|75.3<sub>\u00b10.6</sub>|74.5<sub>\u00b10.9</sub>\n|30691<sub>(77%)</sub>|GPTQ<sub>w3g128</sub>|4.8e5|25.5<sub>\u00b10.9</sub>|26.5<sub>\u00b11.3</sub>|51.5<sub>\u00b11.2</sub>|26.3<sub>\u00b10.4</sub>|48.8<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.8<sub>\u00b10.9</sub>\n||AWQ<sub>w3g128</sub>|4.59|82.2<sub>\u00b10.8</sub>|60.6<sub>\u00b11.4</sub>|82.8<sub>\u00b10.9</sub>|82.9<sub>\u00b10.4</sub>|78.4<sub>\u00b11.2</sub>|76.8<sub>\u00b10.6</sub>|77.3<sub>\u00b10.9</sub>\n||BitStack|5.69|81.6<sub>\u00b10.8</sub>|57.8<sub>\u00b11.4</sub>|82.4<sub>\u00b10.9</sub>|81.2<sub>\u00b10.4</sub>|78.5<sub>\u00b11.2</sub>|79.7<sub>\u00b10.6</sub>|76.9<sub>\u00b10.9</sub>\n|36676<sub>(73%)</sub>|GPTQ<sub>w4</sub>|NaN|25.2<sub>\u00b10.9</sub>|25.3<sub>\u00b11.3</sub>|51.6<sub>\u00b11.2</sub>|26.3<sub>\u00b10.4</sub>|50.1<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.8<sub>\u00b10.9</sub>\n||AWQ<sub>w4</sub>|4.16|77.5<sub>\u00b10.9</sub>|54.4<sub>\u00b11.5</sub>|81.5<sub>\u00b10.9</sub>|80.0<sub>\u00b10.4</sub>|60.5<sub>\u00b11.4</sub>|67.4<sub>\u00b10.7</sub>|70.2<sub>\u00b10.9</sub>\n||BitStack|4.88|82.3<sub>\u00b10.8</sub>|61.1<sub>\u00b11.4</sub>|83.4<sub>\u00b10.9</sub>|82.5<sub>\u00b10.4</sub>|79.9<sub>\u00b11.1</sub>|80.1<sub>\u00b10.6</sub>|78.2<sub>\u00b10.9</sub>\n|38851<sub>(71%)</sub>|GPTQ<sub>w4g128</sub>|7.8e5|25.0<sub>\u00b10.9</sub>|26.3<sub>\u00b11.3</sub>|49.9<sub>\u00b11.2</sub>|26.8<sub>\u00b10.4</sub>|47.4<sub>\u00b11.4</sub>|0.0<sub>\u00b10.0</sub>|29.2<sub>\u00b10.9</sub>\n||AWQ<sub>w4g128</sub>|3.23|85.9<sub>\u00b10.7</sub>|63.5<sub>\u00b11.4</sub>|84.2<sub>\u00b10.9</sub>|84.5<sub>\u00b10.4</sub>|80.1<sub>\u00b11.1</sub>|78.1<sub>\u00b10.6</sub>|79.4<sub>\u00b10.8</sub>\n||BitStack|4.80|82.8<sub>\u00b10.8</sub>|60.2<sub>\u00b11.4</sub>|82.9<sub>\u00b10.9</sub>|82.8<sub>\u00b10.4</sub>|79.6<sub>\u00b11.1</sub>|80.1<sub>\u00b10.6</sub>|78.1<sub>\u00b10.9</sub>", "caption": "Table 3: Evaluation results of Llama 3 8B/70B models. Perplexity scores on WikiText2 test set and accuracy scores on 6 zero-shot reasoning tasks. (\u2191\u2191\\uparrow\u2191): higher is better; (\u2193\u2193\\downarrow\u2193): lower is better. We denote the overall compression ratio (1\u2212compressed model memoryoriginal model memory1compressed model memoryoriginal model memory1-\\frac{\\text{compressed model memory}}{\\text{original model memory}}1 - divide start_ARG compressed model memory end_ARG start_ARG original model memory end_ARG) after memory consumption.", "description": "This table presents a comprehensive evaluation of the BitStack model's performance on Llama 3 8B and 70B models.  It assesses both the perplexity scores (lower is better) on the WikiText2 test set and accuracy scores (higher is better) across six distinct zero-shot reasoning tasks.  Crucially, the table highlights the impact of different compression ratios achieved by BitStack, showing how performance varies as the model size is reduced. This allows for a direct comparison of BitStack against other compression techniques on a range of performance metrics, showcasing the efficiency of BitStack at different model sizes.", "section": "3.1 Evaluation on Base Models"}, {"content": "<table class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"A1.SS3.3.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.SS3.3.3.4.1\">\n<th class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" id=\"A1.SS3.3.3.4.1.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.3.3.4.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.SS3.3.3.4.1.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\" id=\"A1.SS3.3.3.4.1.1.1.1.1\">Question:</span> A tech startup invests $8000 in software development in the first year, and then invests half of that amount in software development in the second year. What\u2019s the total amount the startup invested in software development over the two years?</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.SS3.3.3.5.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" id=\"A1.SS3.3.3.5.1.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.3.3.5.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.SS3.3.3.5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.3.3.5.1.1.1.1.1\">AWQ-w4:</span> ## Step 1: Identify the amount invested in the first year. The startup invests $8000 in software development in the first year. ## Step 2: Calculate the amount invested in the second year. The amount invested in the second year is half of the first year\u2019s investment, which is $8000 / 2 = $4000. ## Step 3: Calculate the total amount invested over the two years. Add the investments of the first and second year to get the total amount invested: $8000 + $4000 = $12000. The final answer is: $12000.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.SS3.1.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"A1.SS3.1.1.1.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.SS3.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.1.1.1.1.1.1.1\">BitStack(5338MB):</span> ## Step 1: Calculate the amount invested in the first year. The startup invests $8000 in software development in the first year. ## Step 2: Calculate the amount invested in the second year. The startup invests half of the first year\u2019s investment in the second year, which is $8000 / 2 = $4000. ## Step 3: Calculate the total amount invested over the two years. The total amount invested is the sum of the first year\u2019s investment and the second year\u2019s investment, which is $8000 + $4000 = $12000. The final answer is: <math alttext=\"\\boxed{12000}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.SS3.1.1.1.1.1.1.m1.1\"><semantics id=\"A1.SS3.1.1.1.1.1.1.m1.1a\"><menclose id=\"A1.SS3.1.1.1.1.1.1.m1.1.1\" notation=\"box\" xref=\"A1.SS3.1.1.1.1.1.1.m1.1.1.cmml\"><mn id=\"A1.SS3.1.1.1.1.1.1.m1.1.1a\" xref=\"A1.SS3.1.1.1.1.1.1.m1.1.1.cmml\">12000</mn></menclose><annotation-xml encoding=\"MathML-Content\" id=\"A1.SS3.1.1.1.1.1.1.m1.1b\"><cn id=\"A1.SS3.1.1.1.1.1.1.m1.1.1.cmml\" type=\"integer\" xref=\"A1.SS3.1.1.1.1.1.1.m1.1.1\">12000</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.SS3.1.1.1.1.1.1.m1.1c\">\\boxed{12000}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.SS3.1.1.1.1.1.1.m1.1d\">12000</annotation></semantics></math>.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.SS3.2.2.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle\" id=\"A1.SS3.2.2.2.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.2.2.2.1.1\"><span class=\"ltx_ERROR undefined\" id=\"A1.SS3.2.2.2.1.1.2\">\\cdashline</span>\n<span class=\"ltx_p\" id=\"A1.SS3.2.2.2.1.1.3\">1-1</span>\n<span class=\"ltx_p\" id=\"A1.SS3.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.2.2.2.1.1.1.2\">AWQ-w3:</span> ## Step 1: Calculate the total investment in the first year The total amount invested in the first year is 8000. ## Step 2: Calculate the total investment in the second year The total amount invested in the second year is half of the first year\u2019s amount, which is 4000. ## Step 3: Calculate the total investment over both periods. To find the total amount invested in software development over the two years, we need to add the investment in the first year and the second year. The total amount = 8000 + (half of pound eight thousand five hundred six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six six <span class=\"ltx_text ltx_font_italic\" id=\"A1.SS3.2.2.2.1.1.1.1\">(<math alttext=\"\\cdots\" class=\"ltx_Math\" display=\"inline\" id=\"A1.SS3.2.2.2.1.1.1.1.m1.1\"><semantics id=\"A1.SS3.2.2.2.1.1.1.1.m1.1a\"><mi id=\"A1.SS3.2.2.2.1.1.1.1.m1.1.1\" mathvariant=\"normal\" xref=\"A1.SS3.2.2.2.1.1.1.1.m1.1.1.cmml\">\u22ef</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.SS3.2.2.2.1.1.1.1.m1.1b\"><ci id=\"A1.SS3.2.2.2.1.1.1.1.m1.1.1.cmml\" xref=\"A1.SS3.2.2.2.1.1.1.1.m1.1.1\">\u22ef</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.SS3.2.2.2.1.1.1.1.m1.1c\">\\cdots</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.SS3.2.2.2.1.1.1.1.m1.1d\">\u22ef</annotation></semantics></math> concatenated.)</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.SS3.3.3.6.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle\" id=\"A1.SS3.3.3.6.2.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.3.3.6.2.1.1\">\n<span class=\"ltx_p\" id=\"A1.SS3.3.3.6.2.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.3.3.6.2.1.1.1.1\">BitStack(4506MB):</span> To find the total amount invested in software development over the two years, we need to add the amount invested in the first year to the amount invested in the second year. The amount invested in the first year is $8000, and the amount invested in the second year is half of that amount, which is $4000. So, the total amount invested in software development over the two years is $8000 + $4000, which is $12000.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.SS3.3.3.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle\" id=\"A1.SS3.3.3.3.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.3.3.3.1.1\"><span class=\"ltx_ERROR undefined\" id=\"A1.SS3.3.3.3.1.1.2\">\\cdashline</span>\n<span class=\"ltx_p\" id=\"A1.SS3.3.3.3.1.1.1\">1-1\u00a0\u00a0<span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.3.3.3.1.1.1.2\">AWQ-w2:</span> blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank blank0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u030616 1ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti0\u0306161ti<span class=\"ltx_text ltx_font_italic\" id=\"A1.SS3.3.3.3.1.1.1.1\">(<math alttext=\"\\cdots\" class=\"ltx_Math\" display=\"inline\" id=\"A1.SS3.3.3.3.1.1.1.1.m1.1\"><semantics id=\"A1.SS3.3.3.3.1.1.1.1.m1.1a\"><mi id=\"A1.SS3.3.3.3.1.1.1.1.m1.1.1\" mathvariant=\"normal\" xref=\"A1.SS3.3.3.3.1.1.1.1.m1.1.1.cmml\">\u22ef</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.SS3.3.3.3.1.1.1.1.m1.1b\"><ci id=\"A1.SS3.3.3.3.1.1.1.1.m1.1.1.cmml\" xref=\"A1.SS3.3.3.3.1.1.1.1.m1.1.1\">\u22ef</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.SS3.3.3.3.1.1.1.1.m1.1c\">\\cdots</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.SS3.3.3.3.1.1.1.1.m1.1d\">\u22ef</annotation></semantics></math> concatenated.)</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.SS3.3.3.7.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" id=\"A1.SS3.3.3.7.3.1\" style=\"width:433.6pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.SS3.3.3.7.3.1.1\">\n<span class=\"ltx_p\" id=\"A1.SS3.3.3.7.3.1.1.1\"><span class=\"ltx_text ltx_font_bold ltx_framed ltx_framed_underline\" id=\"A1.SS3.3.3.7.3.1.1.1.1\">BitStack(3674MB):</span> The total amount of the startup is $8000.</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: Qualitative results of BitStack Llama-3.1-8B-Instruct at different compression ratios comparing to AWQ.", "description": "This table presents a qualitative comparison of the BitStack and AWQ model's performance on a math reasoning task across various compression ratios.  It shows the generated responses for each model at different memory footprints (representing various compression levels), highlighting the differences in reasoning capability and correctness as the model size decreases. The goal is to demonstrate BitStack's ability to maintain reasonable performance even under extreme compression.", "section": "3.2 Evaluation on Instruction-Tuned Models"}, {"content": "| User: | Suppose you are a mathematician and poet. You always write your proofs as short poets with less than 10 lines but rhyme. Prove the square root of 2 is irrational number. |\n| AWQ-w4: | A delightful challenge! Here\u2019s my poetic proof: Assume, if you will, that \\sqrt{2} is rational too, A fraction, a ratio, with a finite clue. Let a/b be its value, in simplest form, so fine, With a and b integers, and b not divine. Now multiply by b, to clear the fraction\u2019s sway, And square both sides, to chase the square root away. You\u2019ll get a^{2}=2b^{2}, a simple equation true, But this implies a and b have a common factor anew. This contradicts our assumption, a logical flaw, I\u2019m afraid, so we conclude: \\sqrt{2} is not a rational trade. |\n| BitStack(36676MB): | Here\u2019s my poetic proof: In numbers, a truth we must find, The square root of two, irrational to bind. Assume it\u2019s rational, a contradiction to make, Then a and b, two integers at stake. a/b=\\sqrt{2}, a perfect ratio to claim, But if a^{2}=2b^{2}, then a even must be the name, And b even too, a contradiction to see, So \\sqrt{2} is irrational, a truth to decree. No rational form, it will never be. |\n| AWQ-w3: |  . PRO\u2014 PRO \u2014 PRO \u2014 PRO PRO has PRO: PRO \u2014 PRO was PRO PRO. PRO PROPRO \u2014 is PRO\u2014PRO.. PROSUB is \u2014 \u2014 PROPROSUB PRO PRO PRO,PRO PROSUBPROPROPROPROSUB \u2014PROPROPROSUB \u2014MODPROPROPRO  (\u2026 concatenated.) |\n| BitStack(28516MB): | A delightful challenge! Here\u2019s my poetic proof: In numbers, a tale is told, Of a root, that\u2019s not whole. Two\u2019s square root, a number rare, Cannot be expressed with simple care. For if it were, a fraction fine, A and B, with a and b in line, A times b, a square to make, Would be two, a number to partake. But no such pair, with a and b to share, Proves the root of two, is irrational to spare. (Note: The traditional proof of the irrationality of the square root of 2 is based on the fact that if it were rational, it would have to be an integer or a fraction, and then we can find a and b such that a^{2}=2b^{2}, which leads to a contradiction. This poetic proof is a rhyming version of this idea.) |\n| AWQ-w2: | Pitaquetsalisalis.DataType Thick-transitionala Thickquets://alis Pita.xra adt ThickMigrationalis Thickutowessleranitizea anitizea sublicensealisakeningNx dnerequisite Pit dnMigration Pit Thick Pit Thick dnEGIN  (\u2026 concatenated.) |\n| BitStack(20356MB): | In the realm of math, a number so fine, A square root of two, a number divine, A number so fine, so divine, A square root of two, so fine. A number so fine, so divine, A number so fine, so divine, A square root of two, so fine, A number so fine, so divine, A number so fine, so divine. A number so fine, so divine, A number so fine, so fine, A number so fine, so fine, A number so fine, so divine. A number so fine, so divine, A number so fine, so fine, A number so fine, so divine. (Note: The number square root of two is fine.) I hope you can understand the proof. |", "caption": "Table 5: Qualitative results of BitStack Llama-3.1-70B-Instruct at different compression ratios comparing to AWQ.", "description": "This table presents a qualitative comparison of the BitStack and AWQ model compression techniques on the Llama-3.1-70B-Instruct model.  The comparison focuses on the quality of generated text responses at various compression ratios, illustrating the performance differences between the two methods under different memory constraints. The table uses examples to showcase how response quality degrades as compression increases, revealing the relative strengths and weaknesses of each approach.", "section": "3.2 Evaluation on Instruction-Tuned Models"}, {"content": "| Model | $W_{q\\_proj}$ | $W_{k\\_proj}$ | $W_{v\\_proj}$ | $W_{o\\_proj}$ | $W_{gate\\_proj}$ | $W_{up\\_proj}$ | $W_{down\\_proj}$ |\n|---|---|---|---|---|---|---|---| \n| Llama 2 7B | 2.25 | 2.25 | 2.25 | 2.25 | 5.84 | 5.84 | 5.84 |\n| Llama 2 13B | 3.44 | 3.44 | 3.44 | 3.44 | 9.02 | 9.02 | 9.02 |\n| Llama 2 70B | 8.50 | 1.28 | 1.28 | 8.50 | 29.13 | 29.13 | 29.13 |\n| Llama 3(3.1) 8B | 2.25 | 0.66 | 0.66 | 2.25 | 7.56 | 7.56 | 7.56 |\n| Llama 3(3.1) 70B | 8.50 | 1.28 | 1.28 | 8.50 | 29.13 | 29.13 | 29.13 |", "caption": "Table 6: Size of residual block in various weight matrices in BitStack (k=16\ud835\udc5816k=16italic_k = 16), measures in megabytes(MB).", "description": "This table shows the size of each residual block in megabytes (MB) for various weight matrices within the BitStack model.  The residual blocks are created during the iterative decomposition process, where the original weight matrices are broken down into smaller, manageable units for dynamic loading. The number of singular values retained during singular value decomposition is set to 16 (k=16). The table provides insights into the memory footprint of different weight matrices in BitStack across various model sizes and helps illustrate the fine-grained size control that the model offers.", "section": "A.4 DISCUSSION ON MINIMAL TRANSMISSION UNITS IN BITSTACK"}]