[{"figure_path": "https://arxiv.org/html/2502.13131/x1.png", "caption": "Figure 1: Illustration of the decomposition pipeline in DRMs. In the original single-dimensional head, a prompt\u2013response pair can be predicted incorrectly. In contrast, DRMs capture preferences along multiple dimensions, aligning more effectively with the complex and multifaceted nature of human preferences.", "description": "This figure illustrates how Decomposed Reward Models (DRMs) improve upon traditional reward models in capturing human preferences.  The left side shows a standard single-dimensional reward model, where a single score is assigned to a prompt-response pair. This approach can lead to misclassifications because human preferences are multifaceted and complex.  The right side depicts DRMs.  DRMs use Principal Component Analysis (PCA) to decompose preferences into orthogonal dimensions.  Each dimension represents a distinct aspect of human preference (e.g., helpfulness, safety, humor). This allows DRMs to capture the nuances of human judgment more effectively and provides an interpretable representation.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13131/x2.png", "caption": "Figure 2: Weight distributions of the top 100 decomposed reward heads on RewardBench for DRMs using Gemma-2B-RM as the backbone.", "description": "This figure visualizes the weight distributions of the top 100 most significant decomposed reward heads obtained from the Decomposed Reward Model (DRM) framework. The analysis focuses on the RewardBench dataset and utilizes Gemma-2B-RM as the underlying reward model backbone. Each decomposed head represents a distinct aspect of human preferences, and the weights indicate the relative importance of each head in determining overall reward. The graph provides insights into how these different preference aspects are weighted for various task categories within RewardBench.", "section": "4.2 What information is Captured by DRMs?"}, {"figure_path": "https://arxiv.org/html/2502.13131/x3.png", "caption": "Figure 3: Correlation among weight vectors for DRMs. The feature extractor is Gemma-2B-RM.", "description": "This figure displays a correlation matrix visualizing the relationships between different attributes within the RewardBench and RPR datasets. Each cell in the matrix represents the Pearson correlation coefficient between two attributes, indicating the strength and direction of their linear association.  The feature extractor used to generate this correlation matrix is the Gemma-2B-RM model.  Strong positive correlations suggest that these attributes frequently co-occur, while negative correlations indicate that they tend not to occur together. The magnitude of the correlation coefficient, ranging from -1 to +1, represents the strength of the relationship. This visualization helps to elucidate the underlying structure and dependencies of human preferences as captured by the DRMs.", "section": "4.4 Quantitative Attribute Explainability"}, {"figure_path": "https://arxiv.org/html/2502.13131/x4.png", "caption": "Figure 4: Ablations on the adaptation set size and number of reward heads for test-time adaptation based on Gemma-2B-RM.", "description": "This figure displays ablation studies on the Gemma-2B reward model to determine optimal hyperparameters for test-time adaptation.  It shows how the model's performance changes based on two key factors: 1) the size of the adaptation dataset used to fine-tune the model to a new user's preferences and 2) the number of reward heads used by the model. The plots visualize how accuracy on the RewardBench and RPR benchmarks change as these parameters vary.  The results reveal the effects of dataset size and the number of heads on performance, indicating optimal values for achieving the best test-time adaptation results.", "section": "4.5 Ablation Study"}, {"figure_path": "https://arxiv.org/html/2502.13131/x5.png", "caption": "Figure 5: Ablations on the adaptation set size and number of reward heads for test-time adaptation on Llama3-8B-RM.", "description": "This figure displays the results of ablation studies conducted on the Llama3-8B-RM model to assess the impact of adaptation set size and the number of reward heads on the test-time adaptation performance. The left panel illustrates the effect of varying the adaptation set size (n) on the overall accuracy for both RewardBench and RPR benchmarks across different numbers of reward heads. The right panel shows how accuracy varies with the number of reward heads for a fixed adaptation set size.  These experiments reveal the optimal balance between adaptation set size, number of reward heads, and model performance during test-time adaptation.", "section": "4.3 Test-time Preference Adaptation"}, {"figure_path": "https://arxiv.org/html/2502.13131/x6.png", "caption": "Figure 6: Weight distributions of the top 100 decomposed reward heads on RPR for DRMs using Gemma-2B-RM as the backbone.", "description": "This figure visualizes the weight distribution of the top 100 most significant decomposed reward heads in the Decomposed Reward Models (DRMs) framework.  These heads are ranked by their eigenvalues, representing the strength of their correlation with human preferences.  The analysis is performed using the RPR dataset (Reasonable Preference Reversal), and Gemma-2B-RM serves as the backbone language model. Each line in the graph corresponds to a specific attribute from the RPR dataset. The x-axis shows the head index (ranking), while the y-axis shows the weight assigned to that particular head in relation to the corresponding attribute. This visualization helps understand which decomposed reward heads are most influential in capturing different aspects of human preferences within the RPR dataset when using Gemma-2B-RM as the backbone model.", "section": "4.2 What information is Captured by DRMs?"}]