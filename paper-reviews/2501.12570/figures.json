[{"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p1.png", "caption": "Figure 1: Accuracy-Length Relationship at Instance level. The relationship between length and accuracy varies significantly across problems, with peak accuracy occurring at short, medium, or long intervals. Notably, high accuracy often persists in shorter intervals.", "description": "This figure visualizes the relationship between the length of reasoning processes and the accuracy of the model's predictions on a per-problem basis.  For each problem, the model generates multiple solutions of varying lengths. The plot shows that the relationship between length and accuracy is inconsistent across problems.  In some cases, the highest accuracy is achieved with short reasoning sequences, while in others, longer sequences are necessary. Importantly, many problems display high accuracy even with short solutions, highlighting the redundancy present in longer reasoning processes.", "section": "3. Length Disharmony in Long Thought Reasoning"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p4.png", "caption": "Figure 2: Length-Harmonizing Fine-Tuning. During the training phase, for each problem, we sample multiple times from the reference model. Subsequently, we sample from the model to be optimized and compute the reward based on the reference samples, followed by a RL-style fine-tuning. During the inference phase, the model optimized through O1-Pruner demonstrates a significant improvement in inference speed, along with a noticeable enhancement in accuracy.", "description": "Figure 2 illustrates the Length-Harmonizing Fine-Tuning process using the O1-Pruner method.  The left panel shows the training phase, where multiple samples are drawn from a reference model for each problem.  A sample is then taken from the model being optimized, and a reward is calculated based on the comparison with the reference samples.  Reinforcement learning (RL) is used to fine-tune the model. The right panel displays the inference phase, highlighting the significant improvements in both inference speed and accuracy achieved by the O1-Pruner optimized model compared to the original. ", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p5.png", "caption": "Figure 3: Comparison of inference time-cost on MATH among different models and methods. O1-Pruner achieves the shortest inference times (slightly over 1 minute for Marco-o1-7B and \u00a04 minutes for QwQ-32B-Preview), demonstrating its effectiveness in accelerating long-thought model inference for both small and large long thought models.", "description": "Figure 3 presents a comparison of inference time costs for different models and methods on the MATH dataset.  It shows that the O1-Pruner method significantly reduces inference time compared to baseline models and other optimization methods (Fast-Solving Prompt, SFT, and DPO).  Specifically, O1-Pruner achieves inference times of just over 1 minute for the smaller Marco-01-7B model and approximately 4 minutes for the larger QwQ-32B-Preview model. This demonstrates the effectiveness of O1-Pruner in accelerating inference, particularly for large long-thought language models.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/qwq/p0.png", "caption": "Figure 4:  Performance on MATH Test-set When Trained on Problems of Different Difficulty Levels. Models trained on more challenging datasets tend to generate longer solutions, while learning to solve harder problems enhances model accuracy. In contrast, for less challenging datasets, shorter solutions are produced without a corresponding accuracy improvement.", "description": "This figure displays the performance of models trained on subsets of the MATH dataset categorized by difficulty level.  The x-axis represents the difficulty level of the training data (e.g., easiest 0-40%, medium 30-70%, hardest 60-100%). The y-axis shows both the average solution length and the average accuracy achieved on the MATH test set by models trained on each difficulty level.  The results reveal that models trained on more challenging datasets generate longer solutions, but also achieve higher accuracy on the test set. Conversely, models trained on easier datasets produce shorter solutions without a corresponding increase in accuracy.", "section": "6.2. Performance Under Dataset of Different Difficulty Levels"}]