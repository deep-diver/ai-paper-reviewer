[{"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/teaser/teaser.jpg", "caption": "(a) Text-to-image generation", "description": "The figure shows a photorealistic image of a couple engaging in pottery, set in a well-lit room. This exemplifies the model's capability to generate high-quality images from text descriptions, a key feature of text-to-image generation.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/edifyctrl_results/controled_generation.jpg", "caption": "(b) Finetuning", "description": "This figure demonstrates the finetuning capability of Edify Image.  It shows an example of a finetuning image used to customize the model's output, alongside the control input that was used during the finetuning process. The goal of finetuning is to adapt the pre-trained model to generate images with specific characteristics, such as a particular style or to generate images of specific individuals.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.07126/x1.png", "caption": "(c) Additional control", "description": "This image shows an example of Edify Image's ability to generate images with additional control beyond just text prompts.  The input image on the left shows a finetuning image used to customize the output, and the control input (a simple sketch) is shown in the bottom left corner. The generated image on the right illustrates how the model incorporates this additional control to produce a more tailored result.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.07126/x2.jpeg", "caption": "(d) Panorama", "description": "The image showcases the capability of Edify Image in generating photorealistic high-resolution panoramas.  It highlights the model's ability to create seamless, wide-angle views from a text prompt, demonstrating its potential in applications like virtual reality content creation and game development.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.07126/x3.jpeg", "caption": "Figure 1: Edify Image can generate photorealistic high-resolution images from text prompts. Our models support a range of capabilities, including (a) Text-to-image generation, (b) Finetuning, (c) Generation with additional control, and (d) Panorama generation. For (b) and (c), an example of a finetuning image and the control input are provided in the bottom left corner, respectively. Best viewed with Acrobat Reader. Click the panorama image to play the video clip.", "description": "This figure showcases the versatility of Edify Image in generating high-quality, photorealistic images from textual descriptions. It demonstrates four key capabilities: (a) direct text-to-image synthesis, producing detailed images from text prompts; (b) finetuning, where the model is adapted to generate images in a specific style or with particular characteristics using example images; (c) generation with additional control, allowing users to guide the image creation process using various parameters, such as depth of field and camera controls; and (d) the generation of interactive 360\u00b0 panoramic HDR videos, offering dynamic visuals with high resolution and color accuracy.  Examples of finetuning images and control inputs are included in the figure for better understanding.  The best viewing experience is achieved with Acrobat Reader; a clickable panorama image initiates a video.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.07126/x4.png", "caption": "Figure 2: \nLaplacian diffusion for multi-resolution image generation.\n(Top) Image Laplacian Decomposition. Each image sample \ud835\udc31\ud835\udc31{\\mathbf{x}}bold_x can be decomposed into a set of components. The example shows three components, \ud835\udc31=\ud835\udc31(1)+up\u2062(\ud835\udc31(2))+up\u2062(up\u2062(\ud835\udc31(3)))\ud835\udc31superscript\ud835\udc311upsuperscript\ud835\udc312upupsuperscript\ud835\udc313{\\mathbf{x}}={\\mathbf{x}}^{(1)}+\\text{up}({\\mathbf{x}}^{(2)})+\\text{up}(\\text{%\nup}({\\mathbf{x}}^{(3)}))bold_x = bold_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT + up ( bold_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ) + up ( up ( bold_x start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT ) ). This decomposition is implemented using basic upsampling and downsampling operations, where each component corresponds to different frequency bands. The function \u03bc\u2062(\ud835\udc31,t)\ud835\udf07\ud835\udc31\ud835\udc61\\mu({\\mathbf{x}},t)italic_\u03bc ( bold_x , italic_t ) represents a weighted sum of these components across different frequency spaces.\n(Middle) Forward Noising Process. Components are attenuated at different rates, with higher frequencies attenuated more rapidly than lower ones. We use the decaying background color in the top part of the figure to illustrate the attenuation factors. As a result, the signal-to-noise ratio (SNR) diminishes faster in the high-frequency components, allowing them to be discarded without significant loss of information once their attenuation coefficients approach zero.\n(Bottom) Backward Sampling Process. Denoisers are trained at multiple stages to generate images at various resolutions. We decompose the noise into a noise Laplacian pyramid. The Laplacian Diffusion process synthesizes higher-resolution images by first upsampling a lower-resolution noisy sample and then denoising it, with random noise injected into the corresponding components during upsampling. When operating solely at the lowest resolution, the process reduces to standard EDM.", "description": "Figure 2 illustrates the Laplacian diffusion process for multi-resolution image generation.  The top panel shows the image Laplacian decomposition, breaking down an image into components representing different frequency bands (low, mid, high). The middle panel depicts the forward noise process where each frequency band is attenuated at a varying rate.  Higher frequencies decay faster, reducing noise accumulation. The bottom panel shows the backward sampling process. Denoisers, trained at multiple stages, upsample lower-resolution noisy images and add noise to higher-frequency components, progressively generating higher-resolution outputs.  At the lowest resolution, this process simplifies to standard energy-based diffusion models.", "section": "Laplacian Diffusion Model"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/controlnet_result2.jpg", "caption": "Figure 3: Model architecture. As shown in the left panel, our diffusion models use a U-Net based architecture with a sequence of residual blocks with skip connections. We use wavelet and Inverse wavelet transform at the beginning and end of the network to bring down the spatial resolution of the images. In the right panel, we show how the 256256256256 and 1\u2062K1\ud835\udc3e1K1 italic_K-resolution models are combined in a 2-stage cascade to generate the 1024102410241024-resolution image.", "description": "This figure illustrates the architecture of the Edify Image model. The left panel shows the U-Net based architecture used for both the base and upsampling models. This architecture consists of residual blocks with skip connections and employs wavelet and inverse wavelet transforms at the beginning and end of the network to reduce the spatial resolution of images, improving computational efficiency. The right panel details the two-stage cascade process used for generating 1024x1024 resolution images. First, a base model generates a 256x256 resolution image, which is then upsampled to 1024x1024 resolution by a second model.", "section": "3.1K Generation Using Two-Stage Laplacian Diffusion Models"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/control_strength.jpg", "caption": "Figure 4: Samples generated by our text-to-image model with 16:9, 1:1 and 9:16 aspect ratios.", "description": "This figure showcases example images generated by the Edify Image text-to-image model, demonstrating its ability to produce high-quality images at various aspect ratios.  The model successfully generates photorealistic images for different scenarios, subjects, and styles, highlighting its versatility and adherence to input text prompts. The images represent three common aspect ratios: 16:9 (wide screen), 1:1 (square), and 9:16 (vertical).", "section": "3. 1K Generation Using Two-Stage Laplacian Diffusion Models"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result1.jpg", "caption": "Figure 5: Long prompt generation. Edify Image can faithfully generate images from long descriptive prompts.", "description": "This figure showcases Edify Image's ability to generate high-quality images from lengthy and detailed text descriptions.  The examples demonstrate the model's capacity to interpret and render complex scenes involving various elements, relationships, and attributes, highlighting its robustness in handling long-form textual input and producing faithful visual representations.", "section": "3.6. Results"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result2.jpg", "caption": "Figure 6: Human diversity. Our model is able to generate images with good gender and race diversity. The prompt used is \"A studio portrait of a smart CEO\".", "description": "Figure 6 showcases the model's capability to generate diverse images, demonstrating good representation across various genders and races. The prompt used was a simple request for \"A studio portrait of a smart CEO\", highlighting the model's ability to generate realistic and inclusive results even with minimal instructions.", "section": "3.6.1. Fairness and Diversity"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result3.jpg", "caption": "Figure 7: Camera controls - Pitch.", "description": "This figure demonstrates the impact of pitch control on image generation. Three images are shown, each representing a different camera pitch: descending, eye level, and ascending. The subject remains consistent across all three, highlighting how pitch adjustment changes the perspective and composition while maintaining scene consistency.", "section": "Camera controls - Pitch"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop0.jpg", "caption": "Figure 8: Camera controls - Depth of field.", "description": "This figure demonstrates the effect of controlling the depth of field during image generation.  The top row shows images generated with a shallow depth of field, resulting in a blurred background that emphasizes the subject in the foreground. The bottom row shows images generated with a deep depth of field, where both the foreground and background elements are in sharp focus.  This showcases the ability of the Edify Image model to control image focus.", "section": "3.6.2. Camera Control"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-2.jpg", "caption": "Figure 9: 4\u2062K4\ud835\udc3e4K4 italic_K Upsampling results. Full (top) and zoomed-in images (bottom) show the additional details.", "description": "This figure showcases the results of 4K upsampling performed on images initially generated at 1K resolution. The top row presents the full upsampled images at 4K resolution, demonstrating the overall enhancement in detail and clarity.  The bottom row provides zoomed-in views of specific image sections, allowing for a closer examination of the added fine details and textures achieved through the upsampling process. This visual comparison effectively highlights the significant improvement in image quality and resolution resulting from the upscaling technique applied by the model.", "section": "4. 4K Upsampling"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-5.jpg", "caption": "Figure 10: 4\u2062K4\ud835\udc3e4K4 italic_K Upsampling results. Full (top) and zoomed-in images (bottom) show the additional details.", "description": "This figure showcases the results of 4K upsampling performed on images. The top row presents the full images after upsampling, highlighting their overall quality and detail.  The bottom row provides zoomed-in sections of the same images, emphasizing the increased level of detail achieved through the upsampling process.  This comparison effectively demonstrates the enhancement in resolution and clarity brought about by the upsampling technique, illustrating its effectiveness in generating high-resolution images.", "section": "4. 4K Upsampling"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-9.jpg", "caption": "Figure 11: Model architecture with additional control inputs. The base model is frozen when training the ControlNet encoders. The Image Input Blocks are initialized from the base model U-Net. The Hint Input Blocks are randomly initialized.", "description": "This figure illustrates the architecture of the Edify Image model enhanced with ControlNet.  The original, pre-trained base model (a U-Net) remains frozen during ControlNet training. The ControlNet's \"Image Input Blocks\" receive initial values derived from the base U-Net's parameters.  This allows the ControlNet to leverage the knowledge learned by the base model. In contrast, the \"Hint Input Blocks\", which process additional control inputs (like sketches, depth maps, or inpainting masks), start with randomly initialized weights.  The combined outputs of these blocks influence the final image generation. This design ensures that the ControlNet effectively modifies the base model's outputs without disrupting its pre-trained knowledge.", "section": "5. Generation with Additional Control"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/fangyin_120_selected_grid_improved-min.jpg", "caption": "Figure 12: Results with additional control inputs for inpainting, depth, and edge. For each input condition, we generate 3 variants using different text prompts.", "description": "This figure demonstrates the effectiveness of Edify Image's ControlNet in handling various control inputs, such as inpainting masks, depth maps, and edge maps.  Each column represents a different type of control input, and for each control input, three rows of generated images are shown, each produced using different text prompts. This highlights the model's ability to generate varied and high-quality images that precisely adhere to the provided controls and textual descriptions.", "section": "5. Results with Additional Control"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/sid_sj_grid_improved-min.jpg", "caption": "Figure 13: Results with different control weight values for depth-to-image and edge-to-image.", "description": "This figure visualizes the impact of adjusting the control weight parameter on image generation using depth and edge control inputs. By varying the weight, the model's adherence to the specified depth and edge cues is modified.  Higher control weights result in more precise alignment with the input depth and edge information, while lower weights allow for greater stylistic freedom and less strict adherence to the controls.", "section": "5. Results with Additional Control"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/icon_grid_improved-min.jpg", "caption": "(a) sunset at a lookout point in a gravel parking lot with blue sky and a few autumn maple trees and beautiful smokey mountains in the background, scenic nature, inspiring, landscape panoramic, mountains.", "description": "A panoramic landscape photo depicting a gravel parking lot at sunset.\u00a0 The scene includes a mostly clear blue sky, several autumn maple trees, and a range of smoky mountains in the background. The overall aesthetic aims for scenic beauty, and the intended mood is inspiring.", "section": "6. 360\u00b0 HDR Panorama Generation"}, {"figure_path": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/car_grid_improved-min.jpg", "caption": "(b) flat sand beach by a lake in the swiss alps mountains at noon with beautiful swiss alps mountains in the background, god rays, scenic nature, inspiring, landscape panoramic.", "description": "A panoramic view of a flat, sandy beach beside a lake. The lake is nestled in a valley surrounded by the majestic Swiss Alps, which are visible in the background.  The scene is bathed in the bright sunlight of midday, with sunbeams (god rays) breaking through the atmosphere. The overall impression is one of serene, scenic natural beauty, inspiring awe and wonder.", "section": "6. 360\u00b0 HDR Panorama Generation"}]