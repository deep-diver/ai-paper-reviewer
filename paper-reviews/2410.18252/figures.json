[{"figure_path": "2410.18252/figures/figures_7_0.png", "caption": "Figure 6: Asynchronous RLHF can be training-bound (left) or generation-bound (right). In practice, generation and training speeds differ so a challenge of asynchronous learning is how best to balance usage and leverage idle compute time to further improve training.", "description": "This figure illustrates two scenarios in asynchronous RLHF: training-bound and generation-bound. The left panel shows a training-bound scenario where the training process takes longer than the generation process, resulting in idle time for the training GPU(s).  The right panel depicts a generation-bound scenario, where generation takes longer than training, leading to idle time for the generation GPU(s).  In both cases, the figure uses a visual representation of GPU usage over time to highlight the imbalance between generation and training speeds, emphasizing the need to optimize resource utilization and mitigate idle time.", "section": "Optimizing Asynchronous RLHF"}]