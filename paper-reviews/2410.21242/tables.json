[{"figure_path": "2410.21242/tables/table_5_0.html", "caption": "Table 1: Results (NDCG@10) on TREC and BEIR. We report the mean NDCG@10 across three runs for HyDE, HYDEPRF, and ReDE-RF (Default: HyDEPRF). The average standard deviation across all datasets for HyDE, HYDEPRF and ReDE-RF (Default:HyDEPRF) was \u2248 0.4%, \u2248 0.5% and \u2248 0.1% respectively. Exact numbers can be found in Appendix C.", "description": "Table 1 presents the evaluation results of various zero-shot and supervised dense retrieval methods on the TREC and BEIR datasets, comparing their NDCG@10 scores across high and low resource domains.", "section": "3.2 Results on Benchmarks"}, {"figure_path": "2410.21242/tables/table_6_1.html", "caption": "Table 3: Impact of the number of documents used to update the ReDE-RF (No Default) query embedding.", "description": "This table shows the impact of varying the number of documents used to update the ReDE-RF query embedding on NDCG@10 for three datasets.", "section": "3.3 Comparing Latencies"}, {"figure_path": "2410.21242/tables/table_6_3.html", "caption": "Table 5: Impact of different prompts on ReDE-RF (No Default). For Thomas et al. (2024), we make the relevance options binary. Prompts are in Appendix G.", "description": "Table 5 shows the impact of different prompt variations on the ReDE-RF model's performance, measured by NDCG@10 and NDCG@20 on DL19 and DL20 datasets.", "section": "3.2 Results on Benchmarks"}, {"figure_path": "2410.21242/tables/table_8_0.html", "caption": "Table 6: NDCG@10 of ReDE-RF when implemented with DistillReDE. Hybrid* is a hybrid system that combines results from BM25 and DistillReDE. Hybrid is BM25 + Contriever, as in Table 1.", "description": "Table 6 presents the NDCG@10 scores of ReDE-RF using Contriever, HyDEPRF, and DistillReDE as initial retrievers, comparing their performance across various low-resource datasets.", "section": "3.3 Comparing Latencies"}, {"figure_path": "2410.21242/tables/table_8_1.html", "caption": "Table 7: Comparing ReDE-RF (Default: HyDEPRF) to pointwise reranking (PR). ReDE-RF + PR reranks the top-20 passages returned from ReDE-RF. Bold denotes best overall system. Underline denotes best between ReDE-RF and Hybrid + PR.", "description": "Table 7 compares ReDE-RF's performance against pointwise re-ranking using three different LLMs across multiple metrics, showing that ReDE-RF consistently outperforms pointwise re-ranking in terms of NDCG@20.", "section": "6 ReDE-RF vs. Pointwise Reranking"}, {"figure_path": "2410.21242/tables/table_12_0.html", "caption": "Table 1: Results (NDCG@10) on TREC and BEIR. We report the mean NDCG@10 across three runs for HyDE, HYDEPRF, and ReDE-RF (Default: HyDEPRF). The average standard deviation across all datasets for HyDE, HYDEPRF and ReDE-RF (Default:HyDEPRF) was \u2248 0.4%, \u2248 0.5% and \u2248 0.1% respectively. Exact numbers can be found in Appendix C.", "description": "Table 1 presents the NDCG@10 results on the TREC and BEIR datasets for various zero-shot and supervised dense retrieval methods, showing ReDE-RF's superiority in low-resource settings and competitive performance in high-resource ones.", "section": "3.2 Results on Benchmarks"}, {"figure_path": "2410.21242/tables/table_13_0.html", "caption": "Table 8: NDCG@10 of HyDE-Mistral-7B-Instruct and ReDE-RF (w/ HyDE) with standard deviations across three runs.", "description": "Table 8 presents the NDCG@10 scores of HyDE, HyDEPRF, and ReDE-RF across multiple datasets, showing the mean and standard deviation across three runs for each model.", "section": "3.2 Results on Benchmarks"}, {"figure_path": "2410.21242/tables/table_13_1.html", "caption": "Table 9: NDCG@10 of HyDEPRF across different number of initially retrieved documents used as context.", "description": "Table 9 shows the NDCG@10 scores of HyDEPRF using different numbers of initially retrieved documents as context on various datasets.", "section": "3.2 Results on Benchmarks"}]