[{"figure_path": "2410.15017/figures/figures_2_0.png", "caption": "Figure 1: An overview of speech tokenization approaches using discrete acoustic, semantic, and contextual tokens. DM-Codec integrates these multimodal representations for robust speech tokenization, learning comprehensive speech representations.", "description": "Figure 1 provides a comparison of existing speech tokenization approaches that utilize discrete acoustic and semantic tokens, highlighting their limitations and introducing DM-Codec as a novel approach that incorporates contextual information for improved performance.", "section": "INTRODUCTION"}, {"figure_path": "2410.15017/figures/figures_4_0.png", "caption": "Figure 2: DM-Codec framework consists of an encoder that extracts latent representations from the input speech signal. These latent vectors are subsequently quantized using a Residual Vector Quantizer (RVQ). We designed two distinct distillation approaches: (i) distillation from a language model, and (ii) a combined distillation from both a language model (LM) and a speech model (SM). These approaches integrate acoustic, semantic, and contextual representations into the quantized vectors to improve speech representation for downstream tasks.", "description": "The figure illustrates the DM-Codec framework, which uses an encoder, RVQ, decoder, and discriminators to process speech signals and integrate acoustic, semantic, and contextual representations through LM and SM-guided distillation.", "section": "2 PROPOSED METHOD"}]