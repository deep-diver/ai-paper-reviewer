[{"figure_path": "2410.15017/figures/figures_2_0.png", "caption": "Figure 1: An overview of speech tokenization approaches using discrete acoustic, semantic, and contextual tokens. DM-Codec integrates these multimodal representations for robust speech tokenization, learning comprehensive speech representations.", "description": "Figure 1 provides a visual comparison of existing speech tokenization techniques that use only acoustic or semantic tokens, highlighting their limitations, and introduces DM-Codec which integrates acoustic, semantic, and contextual information for improved speech tokenization.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.15017/figures/figures_4_0.png", "caption": "Figure 2: DM-Codec framework consists of an encoder that extracts latent representations from the input speech signal. These latent vectors are subsequently quantized using a Residual Vector Quantizer (RVQ). We designed two distinct distillation approaches: (i) distillation from a language model, and (ii) a combined distillation from both a language model (LM) and a speech model (SM). These approaches integrate acoustic, semantic, and contextual representations into the quantized vectors to improve speech representation for downstream tasks.", "description": "The figure illustrates the DM-Codec framework, which uses an encoder, RVQ, decoder, and discriminators to integrate acoustic, semantic, and contextual representations for speech tokenization via two distillation approaches.", "section": "Proposed Method"}]