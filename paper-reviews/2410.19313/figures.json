[{"figure_path": "2410.19313/figures/figures_1_0.png", "caption": "Figure 1: (a,b) Comparing the quantization flow of Transformer Engine and COAT. Both the optimizer states and activations are quantized to FP8 in COAT. (c) End-to-end per-GPU memory comparison when training Llama-2-13B on 8\u00d780G H100 using FSDP.", "description": "The figure compares the quantization flow of Transformer Engine and COAT, highlighting COAT's reduction in memory footprint by quantizing both optimizer states and activations to FP8.", "section": "INTRODUCTION"}, {"figure_path": "2410.19313/figures/figures_15_0.png", "caption": "Figure 1: (a,b) Comparing the quantization flow of Transformer Engine and COAT. Both the optimizer states and activations are quantized to FP8 in COAT. (c) End-to-end per-GPU memory comparison when training Llama-2-13B on 8\u00d780G H100 using FSDP.", "description": "The figure compares the quantization flow of Transformer Engine and COAT, highlighting COAT's quantization of both optimizer states and activations to FP8, resulting in reduced memory usage.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.19313/figures/figures_15_1.png", "caption": "Figure 8: Comparison of BF16 and COAT on VLM captioning. COAT can accurately summarize the figure and identify the key points in the figure.", "description": "The figure shows a comparison of captions generated by BF16 and COAT for the same image, highlighting COAT's ability to produce more accurate and concise summaries.", "section": "B Qualitative Example - Vision Language Model Captioning"}, {"figure_path": "2410.19313/figures/figures_16_0.png", "caption": "Figure 9: Axis is of base 2.", "description": "The figure visualizes the distribution of optimizer states before and after applying dynamic range expansion, showing how the expansion improves the utilization of the FP8 representation range.", "section": "C VISUALIZATION OF EXPAND FUCTION"}]