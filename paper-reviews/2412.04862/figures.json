[{"figure_path": "https://arxiv.org/html/2412.04862/x1.png", "caption": "Figure 1: A procedure of instruction-tuning data construction. First, we extract the core knowledge from large-volume web corpora and classify it within the taxonomy we defined in advance. Next, instruction-tuning data is generated based on the knowledge. To construct additional training data that is more complex, we leverage an instruction-evolving method\u00a0[58] that lets the final dataset cover various fields with varying levels of difficulty.", "description": "The figure illustrates the process of creating instruction-tuning data.  It starts by extracting core knowledge from a massive web corpus and organizing it using a pre-defined taxonomy. This structured knowledge then serves as the basis for generating instruction-tuning datasets. To increase the complexity and diversity of these datasets, an instruction-evolving method is employed, resulting in a final dataset that spans various fields and difficulty levels.", "section": "2.3.1 Supervised Fine-tuning"}, {"figure_path": "https://arxiv.org/html/2412.04862/x2.png", "caption": "Figure 2: Overview of the preference optimization pipeline. (Top) Preference Data Creation: It shows the process of constructing preference data {x,yw,yl}\ud835\udc65subscript\ud835\udc66\ud835\udc64subscript\ud835\udc66\ud835\udc59\\{x,y_{w},y_{l}\\}{ italic_x , italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT } by scoring the responses y\ud835\udc66yitalic_y generated from a model for the prompt x\ud835\udc65xitalic_x using a reward model. (Bottom) Preference Optimization: Sequential training process where M0subscript\ud835\udc400M_{0}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT initialized from the SFT model is trained through DAA to obtain M1subscript\ud835\udc401M_{1}italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and M2subscript\ud835\udc402M_{2}italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.", "description": "Figure 2 illustrates the two-stage preference optimization process.  The top half shows how preference data is created:  multiple model responses (y) are generated for a given prompt (x), and a reward model ranks these responses. The best (yw) and worst (yl) responses are then paired with the prompt (x) to form a preference dataset. The bottom half depicts the sequential training process using Direct Alignment Algorithms (DAA): an initial model (M0), pretrained with Supervised Fine-Tuning (SFT), is iteratively improved to create M1 and finally M2, using the preference dataset to refine its alignment with human preferences.", "section": "2 Model Training"}, {"figure_path": "https://arxiv.org/html/2412.04862/x3.png", "caption": "Figure 3: NIAH results of EXAONE 3.5 language models. The x-axis represents the token length of the input text, while the y-axis shows the relative position within the text, expressed as a percentage (0% corresponds to the beginning, and 100% to the end). The results are represented using a color-coded scheme: green indicates successful retrievals, and red represents unsuccessful ones. EXAONE 3.5 language models achieve near-perfect accuracy in retrieving information across various document depths and context lengths in English and Korean.", "description": "This figure displays the performance of EXAONE 3.5 language models on the Needle-in-a-Haystack (NIAH) benchmark, which tests the ability of models to locate and retrieve specific information within long documents.  The x-axis shows the length of the input document in tokens (1k, 4k, 8k, 16k, 32k), while the y-axis indicates the relative position of the target information within the document (0% being the start and 100% the end).  The color-coding (green for success, red for failure) visually represents the model's accuracy in retrieving the information at different positions and context lengths.  The results demonstrate that EXAONE 3.5 models achieve near-perfect accuracy across various document depths and context lengths, in both English and Korean.", "section": "3.4 Long Context"}, {"figure_path": "https://arxiv.org/html/2412.04862/extracted/6036302/figures/decontam_fixed.png", "caption": "Figure 4: A summary of the decontamination method employed to train EXAONE 3.5 language models. Adopting an approach borrowed from the GPT-4 method, we increase the number of random sample to N=10\ud835\udc4110N=10italic_N = 10 for stricter decontamination.", "description": "Figure 4 illustrates the data decontamination process used in training the EXAONE 3.5 language models.  The process aims to remove training examples that overlap with the test data, a technique to prevent contamination that would otherwise bias evaluation results and reduce the model's ability to generalize. The figure shows a flowchart summarizing the steps involved: (1) extracting substrings from the test set to create a substring pool, (2) sampling substrings from a training example, (3) checking for matches between the sampled substrings and those in the pool, and (4) removing the training example if matches exceed a threshold.  The improvement over the GPT-4 approach is highlighted: the number of random substrings sampled from each training example (N) is increased from 5 to 10 for stricter decontamination, ensuring a more rigorous removal of contaminated data.", "section": "2.2 Pre-training"}]