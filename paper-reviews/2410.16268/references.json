{"references": [{" publication_date": "2024", "fullname_first_author": "Nikhila Ravi", "paper_title": "SAM 2: Segment anything in images and videos", "reason": "This paper introduces SAM 2, a significant advancement in promptable object segmentation for both images and videos, which forms the foundation for the proposed SAM2Long model.  Understanding SAM 2's strengths and limitations is crucial for evaluating the effectiveness of SAM2Long's improvements.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This is the foundational paper for the Segment Anything Model (SAM), upon which SAM 2 and consequently SAM2Long are built.  It establishes the base model and its capabilities, providing a context for understanding the improvements introduced by SAM2Long.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Lingyi Hong", "paper_title": "LVOS: A benchmark for long-term video object segmentation", "reason": "This paper introduces the LVOS benchmark dataset, which is specifically designed for evaluating the performance of long-term video object segmentation models.  The inclusion of LVOS as a benchmark dataset is crucial in demonstrating SAM2Long's improvement over SAM 2 in handling long-term videos and the challenges associated with them.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Lingyi Hong", "paper_title": "LVOS v2: A benchmark for long-term video object segmentation", "reason": "This paper introduces the LVOS v2 dataset, an extension of the original LVOS dataset. This updated dataset is used as an important benchmark for evaluating the performance of SAM2Long, providing a rigorous test of its capabilities in handling even more complex, long-term video object segmentation scenarios.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Henghui Ding", "paper_title": "MOSE: A new dataset for video object segmentation in complex scenes", "reason": "The MOSE dataset is another crucial benchmark dataset in the experiments.  The evaluation on MOSE validates the performance of the SAM2Long model under complex and challenging real-world video scenarios.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Pavel Tokmakov", "paper_title": "VOST: A novel video dataset designed for benchmarking challenging segmentation tasks", "reason": "The VOST dataset presents a particularly challenging set of video object segmentation tasks, focusing on extreme object transformations.  Including VOST in the evaluations helps illustrate the robustness and generality of SAM2Long's performance.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "PUMAVOS: A novel video dataset designed for benchmarking challenging segmentation tasks", "reason": "PUMAVOS is another challenging benchmark dataset that focuses on difficult visual cues in videos.  The evaluation on PUMAVOS demonstrates the improved robustness of SAM2Long, especially for cases with ambiguous or poorly defined object boundaries.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Ali Athar", "paper_title": "Hodor: High-level object descriptors for object re-segmentation in video learned from static images", "reason": "This paper explores advanced techniques for object re-segmentation in video, providing valuable context for the challenges faced in memory-based video object segmentation.  The work highlights the importance of robust memory mechanisms in handling object reappearance and occlusion.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Ali Athar", "paper_title": "Tarvis: A unified approach for target-based video segmentation", "reason": "This paper provides insights into unified approaches for target-based video segmentation.  The research helps to contextualize SAM2Long's approach within the broader landscape of video object segmentation methods and highlights its contribution to the field.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Linchao Bao", "paper_title": "CNN in MRF: Video object segmentation via inference in a CNN-based higher-order spatio-temporal MRF", "reason": "This early work on video object segmentation using CNNs and MRFs demonstrates the progression of methods within the field and highlights the challenges and complexity inherent in long-term video object segmentation.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Sergi Caelles", "paper_title": "One-shot video object segmentation", "reason": "This paper introduces one-shot video object segmentation, which is a significant advancement over previous methods. It also highlights the limitations of simpler methods, and provides a relevant context for the improvements introduced by SAM2Long.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Ho Kei Cheng", "paper_title": "XMem: Long-term video object segmentation with an atkinson-shiffrin memory model", "reason": "This paper introduces XMem, a model utilizing a hierarchical memory structure for video object segmentation. XMem's memory mechanism provides important context and a comparison point for the tree-structured memory in SAM2Long.  The comparison demonstrates how SAM2Long further enhances the effectiveness of memory-based approaches.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Ho Kei Cheng", "paper_title": "XMem: Long-term video object segmentation with an atkinson-shiffrin memory model", "reason": "This paper introduces a novel memory mechanism based on the Atkinson-Shiffrin model, providing a more efficient way to store and access long-term memories compared to traditional approaches.  The novel memory design is directly relevant to and compared against SAM2Long.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Ho Kei Cheng", "paper_title": "Tracking anything with decoupled video segmentation", "reason": "This work presents an innovative decoupled approach to video segmentation.  The study helps to show the trend towards more sophisticated and robust techniques for tracking objects across complex scenes.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Ho Kei Cheng", "paper_title": "Putting the object back into video object segmentation", "reason": "The research expands on existing video object segmentation methods by reintroducing object-level information.  This is highly relevant to the object-aware memory mechanism in SAM2Long.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Yuhua Chen", "paper_title": "Blazingly fast video object segmentation with pixel-wise metric learning", "reason": "This work focuses on enhancing efficiency and speed in video object segmentation. The research highlights the importance of efficient processing techniques for long videos, a crucial consideration for SAM2Long.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Goutam Bhat", "paper_title": "Learning what to learn for video object segmentation", "reason": "This paper explores the concept of learning what to learn for video object segmentation.  It addresses the challenges of handling complex variations in video data, which is relevant to SAM2Long's ability to manage occlusions and object reappearance.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Mingxing Li", "paper_title": "Video object segmentation with joint re-identification and attention-aware mask propagation", "reason": "This research emphasizes the importance of combining re-identification and attention mechanisms in video object segmentation.  The study provides context and demonstrates the trend toward more advanced techniques for object tracking and segmentation in complex scenarios.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Joakim Johnander", "paper_title": "A generative appearance model for end-to-end video object segmentation", "reason": "This research introduces a generative model for end-to-end video object segmentation.  The work provides an alternative perspective to memory-based approaches, highlighting the diversity of methods used within the field and showcasing the importance of SAM2Long's focus on enhancing existing models.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Yu Li", "paper_title": "Fast video object segmentation using the global context module", "reason": "This paper presents a fast video object segmentation method that uses global context information. This is relevant to the efficiency considerations for SAM2Long and highlights the need for balancing accuracy and speed.", "section_number": 2}]}