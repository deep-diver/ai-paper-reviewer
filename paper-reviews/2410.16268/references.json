{"references": [{" publication_date": "2024", "fullname_first_author": "Nikhila Ravi", "paper_title": "SAM 2: Segment anything in images and videos", "reason": "This paper introduces SAM 2, a significant advancement in video object segmentation that serves as the foundation for the proposed SAM2Long model.  Its introduction of a memory module for video object segmentation, although suffering from limitations in handling complex scenarios, is crucial for understanding the context of SAM2Long's improvements.  The paper's detailed description of SAM 2's architecture and its performance on various benchmarks is essential for evaluating the impact and contributions of SAM2Long.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This paper introduces the original SAM model, which forms the basis for SAM 2 and consequently, SAM2Long. Understanding SAM's architecture and capabilities is crucial for comprehending the advancements made by SAM 2 and the subsequent improvements introduced by the proposed method.  It is a foundational paper that provides context for the subsequent research building upon its capabilities.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ali Athar", "paper_title": "Hodor: High-level object descriptors for object re-segmentation in video learned from static images", "reason": "This paper addresses the challenge of object re-segmentation in videos, directly relevant to the problem SAM2Long tackles.  Understanding the approaches used to re-identify objects after occlusion helps appreciate the novelty and significance of SAM2Long's memory tree structure in enhancing the accuracy of object tracking across long video sequences.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Ali Athar", "paper_title": "Tarvis: A unified approach for target-based video segmentation", "reason": "This paper proposes a unified approach to target-based video segmentation, relevant because SAM2Long also aims to improve video object segmentation.  The paper's focus on target-based segmentation, where a specific object is tracked, is aligned with the goals of SAM2Long, highlighting the importance of efficient and accurate object tracking in challenging video scenarios.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "Xmem++: Production-level video segmentation from few annotated frames", "reason": "This paper presents XMem++, a production-level video segmentation model, providing a benchmark against which SAM2Long's performance can be compared.  Understanding the advancements made by XMem++ helps gauge the improvements SAM2Long achieves, particularly considering that SAM2Long aims to improve upon SAM 2, another state-of-the-art method.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Goutam Bhat", "paper_title": "Learning what to learn for video object segmentation", "reason": "This paper explores learning strategies for video object segmentation, a topic directly relevant to SAM2Long's improvements. The methods used to improve learning efficiency are relevant to understanding the context and impact of SAM2Long's training-free enhancements in improving video object segmentation accuracy and efficiency.", "section_number": 2}, {" publication_date": "2010", "fullname_first_author": "Thomas Brox", "paper_title": "Object segmentation by long term analysis of point trajectories", "reason": "This early work on object segmentation using long-term analysis of point trajectories provides foundational knowledge that helps to contextualize the advancements in memory-based approaches, such as those used by SAM2Long, to address the challenges of long-term video object segmentation.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Sergi Caelles", "paper_title": "One-shot video object segmentation", "reason": "This paper introduces a significant approach to video object segmentation, providing a key comparison point for the subsequent advancements in the field.  It lays the groundwork for understanding the challenges and limitations of early one-shot approaches, such as the absence of robust mechanisms to manage occlusions and reappearing objects, challenges addressed by SAM2Long.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Yuhua Chen", "paper_title": "Blazingly fast video object segmentation with pixel-wise metric learning", "reason": "This paper explores a fast approach to video object segmentation, providing a contrast to the memory-based techniques used in SAM2Long. It helps to demonstrate the potential of a memory-based approach such as SAM2Long to improve the quality of video segmentation without sacrificing speed. The trade-off between speed and quality is relevant to assessing the contribution of SAM2Long.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Ho Kei Cheng", "paper_title": "Xmem: Long-term video object segmentation with an atkinson-shiffrin memory model", "reason": "This paper introduces XMem, a model leveraging a hierarchical memory structure for long-term video object segmentation, directly addressing the issues SAM2Long aims to solve.  Comparing XMem's architecture and performance against SAM2Long's allows for a better assessment of the proposed method's innovation and effectiveness.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Ho Kei Cheng", "paper_title": "Tracking anything with decoupled video segmentation", "reason": "This paper presents a method for tracking any object in a video, a task directly related to the challenges in video object segmentation, making it an important reference for understanding the overall landscape of research. This method is directly relevant to the goals of SAM2Long, emphasizing the need for robust and accurate tracking in challenging video scenarios.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Ho Kei Cheng", "paper_title": "Putting the object back into video object segmentation", "reason": "This paper focuses on incorporating object-level information into video object segmentation, which is directly relevant to the goals of the SAM2Long model. The improvements obtained using object-level cues are relevant to comparing the methods employed by SAM2Long for enhancing object-aware segmentation.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Yuhua Chen", "paper_title": "Long-term video object segmentation with an atkinson-shiffrin memory model", "reason": "This paper explores long-term video object segmentation, a challenging task that SAM2Long aims to improve upon.  The techniques used in this work to address long-term tracking are significant in understanding the context and contributions of SAM2Long's memory tree structure for maintaining object coherence across extended video sequences.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Henghui Ding", "paper_title": "MOSE: A new dataset for video object segmentation in complex scenes", "reason": "The MOSE dataset is used in the experimental evaluation of SAM2Long.  Understanding its characteristics and challenges is crucial for interpreting SAM2Long's performance, which demonstrates robustness and effectiveness even in these highly challenging video sequences.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Pavel Tokmakov", "paper_title": "Breaking the \"object\" in video object segmentation", "reason": "This paper introduces a new dataset, VOST, focusing on challenging video scenarios with complex object transformations.   The use of the VOST dataset in the evaluation of SAM2Long provides a strong test of its robustness in handling challenging visual situations, and understanding this dataset's characteristics is important for properly interpreting SAM2Long's performance results.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "Xmem++: Production-level video segmentation from few annotated frames", "reason": "The PUMAVOS dataset, introduced in this paper, is another benchmark dataset used to evaluate the performance of SAM2Long. Understanding this dataset's properties, especially its focus on difficult segmentation scenarios, is crucial for correctly interpreting SAM2Long's performance and its ability to generalize to real-world challenges.", "section_number": 4}, {" publication_date": "2016", "fullname_first_author": "Federico Perazzi", "paper_title": "A benchmark dataset and evaluation methodology for video object segmentation", "reason": "This paper introduces the DAVIS benchmark dataset, foundational for evaluating video object segmentation methods.  Understanding its design and metrics allows for comparing and contextualizing the performance of SAM2Long against other state-of-the-art models, providing a solid basis for evaluating its contributions to the field.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Lingyi Hong", "paper_title": "Lvos: A benchmark for long-term video object segmentation", "reason": "The LVOS dataset, introduced in this paper, is used extensively in evaluating the performance of SAM2Long, particularly its ability to handle long-term tracking. Understanding its design and challenges is critical for interpreting the results of the experiments and the overall contributions of SAM2Long.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Lingyi Hong", "paper_title": "Lvos: A benchmark for large-scale long-term video object segmentation", "reason": "This paper introduces the updated LVOS v2 dataset, another key benchmark used to evaluate the performance of SAM2Long. The dataset's improvements and expanded scale provide a robust testbed for assessing the model's performance in handling long-term video sequences and object reappearances.", "section_number": 4}]}