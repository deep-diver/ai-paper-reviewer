[{"content": "| Model | 02 | 03 | 07 | 08 | 09 | 11 | 13 | 14 | 15 | 16 | 18 | 19 | 21 | 22 | 23 | 25 | 26 | 28 | 30 | 31 | 32 | 33 | 35 | 36 | 37 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| _Baseline_ | 22 | 47 | 40 | 25 | 26 | 27 | 28 | 24 | 22 | 24 | 25 | 23 | 49 | 26 | 25 | 24 | 49 | 30 | 49 | 21 | 49 | 20 | 25 | 23 | 19 |\n| _Single-task Training_ | 24 | 49 | 50 | 68 | 65 | 76 | 83 | 53 | 61 | 32 | 29 | 26 | 57 | 53 | 28 | 24 | 57 | 64 | 89 | 60 | 97 | 54 | 29 | 51 | 49 |\n| _Multi-task Training_ | **96** | **89** | **80** | **80** | **79** | **97** | **92** | **88** | **76** | **57** | **88** | **74** | **87** | **86** | **93** | **52** | **98** | **72** | **94** | **61** | **100** | **72** | **75** | **60** | **50** |", "caption": "Table 1: Accuracy of different models on In-Distribution Dataset. Within each segment, bold highlights the best scores, and underlines indicate the second-best.", "description": "This table presents the accuracy results of three different models on an in-distribution dataset.  The models are compared across 37 different subsets of the dataset.  For each subset, the table shows the accuracy of a baseline model, a model trained with a single task, and a model trained with multiple tasks. The best score in each subset is highlighted in bold, and the second-best score is underlined. This demonstrates the impact of single-task versus multi-task training on model performance.", "section": "2.2 A Pilot Study of Data Composition"}, {"content": "| Model | 01 | 04 | 05 | 06 | 10 | 12 | 17 | 20 | 24 | 27 | 29 | 34 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| *Baseline* | 32 | 25 | 33 | **33** | 48 | 27 | 33 | 13 | 34 | 37 | 31 | 20 |\n| *Multi-task Training* | **39** | **26** | **70** | 31 | **58** | **38** | **61** | **40** | **35** | **41** | **55** | **50** |", "caption": "Table 2: Accuracy of different models on Out-Of-Distribution Dataset. Bold highlights the best scores.", "description": "This table presents the accuracy of different models on an Out-of-Distribution (OOD) dataset.  The OOD dataset consists of medical images not seen during the model's training phase.  The table compares the performance of a baseline model, a single-task training model, and a multi-task training model. Bold text highlights the best accuracy scores achieved for each task by any of the models, indicating which model performed best on each OOD dataset subset.", "section": "2.2 A Pilot Study of Data Composition"}, {"content": "Related Combination|Target Subset|Baseline|Baseline+|Trained\n---|---|---|---|---\nLung, COVID|Brain, **Cancer**|Lung, Cancer|25|25|27\nLung, Cancer|Brain, **State**|Lung, State|47|46|50\nBrain, Cancer|Lung, **State**|Brain, State|33|50|57\nBones, Level|Lung, **State**|Bones, State|49|53|51\nBones, Level|Brain, **State**|Bones, State|49|53|72\nBones, Level|Breast, **Diseases**|Bones, Diseases|37|33|39\nBones, Level|Lung, **Diseases**|Bones, Diseases|37|33|43\nBones, Level|Chest, **Diseases**|Bones, Diseases|37|31|43\nBones, State|Breast, **Diseases**|Bones, Diseases|37|37|43\nBones, State|Lung, **Diseases**|Bones, Diseases|37|37|43\nBones, State|Chest, **Diseases**|Bones, Diseases|37|37|41\nLung, COVID|Breast, **Diseases**|Lung, Diseases|49|48|51\nLung, COVID|Bones, **Diseases**|Lung, Diseases|49|48|52\nLung, COVID|Chest, **Diseases**|Lung, Diseases|49|48|51\nCT, Cancer|X-ray, **COVID**|CT, COVID|47|46|72\nCT, COVID|X-ray, **Diseases**|X-ray, COVID|30|21|49\nCT, State|X-ray, **Diseases**|X-ray, State|30|21|46\nCT, State|X-ray, **Cancer**|CT, Cancer|33|28|28\nCT, Brain(State)|X-ray, **Bones**|X-ray, Brain|49|49|91\nCT, Brain|X-ray, **Lung**|X-ray, Brain|49|50|81\nCT, Brain(Cancer)|X-ray, **Bones**|X-ray, Brain|25|51|74\nCT, Brain|X-ray, **Lung**|X-ray, Brain|49|52|52\nX-ray, Brain|CT, Lung(State)|CT, Brain(State)|33|50|60\nX-ray, Lung|CT, Brain|CT, Lung(Cancer)|25|25|36\nX-ray, Lung|CT, Brain(State)|CT, Lung|47|50|81\nX-ray, Lung|CT, Brain(Cancer)|CT, Lung|47|50|71\nCT, Lung (State)|X-ray, Bones|X-ray, Lung|30|32|28\nCT, Lung (State)|X-ray, Brain|X-ray, Lung|30|32|35\nCT, Lung (Cancer)|X-ray, Bones|X-ray, Lung|30|32|41\nCT, Lung (Cancer)|X-ray, Brain|X-ray, Lung|30|32|42\nDer, Skin, Cancer|FP, Fundus, **Diseases**|Der, Skin, Diseases|25|29|33\nDer, Skin, Cancer|OCT, Retine, **Diseases**|Der, Skin, Diseases|25|29|33\nDer, Skin, Diseases|DP, Mouth, **Cancer**|Der, Skin, Cancer|40|33|63\nDer, Skin, Diseases|Mic, Cell, **Cancer**|Der, Skin, Cancer|40|33|63\nDP, Mouth, State|Der, Skin, **Cancer**|DP, Mouth, Cancer|48|50|52\nDP, Mouth, State|Mic, Cell, **Cancer**|DP, Mouth, Cancer|48|50|55\nFP, Fundus, Diseases|Mic, Cell, **Level**|FP, Fundus, Level|33|36|42\nMic, Cell, Cell Identification|FP, Fundus, **Level**|Mic, Cell, Level|23|33|32\nMic, Cell, Cell identification|Der, Skin, **Cancer**|Mic, Cell, Cancer|49|50|50\nMic, Cell, Cell identification|DP, Mouth, **Cancer**|Mic, Cell, Cancer|49|51|62\nMic, Cell, Level|Der, Skin, **Cancer**|Mic, Cell, Cancer|49|51|52\nMic, Cell, Level|DP, Mouth, **Cancer**|Mic, Cell, Cancer|49|51|58\nMic, Cell, Cancer|FP, Fundus, **Level**|Mic, Cell, Level|23|24|27", "caption": "Table 3: Generalization results on classification datasets: \"Related Combination\" is the training set, \"Target Subset\" is the goal. Baseline, Baseline+, and Trained represent the model\u2019s accuracy without training, trained on randomly sampled unrelated data, and trained on related data, respectively. Green section indicates successful generalization, while red section denotes failure. The 4 segmented areas represent different Direction Types: fixed modality, fixed area, fixed task, and modality-area paired combinations.", "description": "Table 3 presents the results of a controlled experiment evaluating compositional generalization (CG) in a medical image classification task.  The table shows the accuracy of a multimodal large language model (MLLM) on various target datasets (unseen during training).  Each row represents a different target dataset and its associated training set. The \"Related Combination\" column specifies the training set of datasets containing images with similar characteristics (same Modality, Anatomical Area, and Task). The \"Target Subset\" column identifies the dataset tested.  Three accuracy scores are provided: Baseline (no training), Baseline+ (trained on randomly selected unrelated datasets), and Trained (trained on the \"Related Combination\" dataset). The green sections highlight successful generalization (accuracy improved by using related data), while red sections indicate unsuccessful generalization (no improvement or decrease in accuracy by using related data). The table is divided into four sections that represent different combinations of fixed elements (modality, area, or task) within the MAT-Triplet, allowing for analysis of how compositional generalization varies based on the combination of similar data.", "section": "3.1 Controlled Variable Study on CG"}, {"content": "| Related Combination | Target Subset | Baseline | Trained |\n|---|---|---|---|\n| CT - Subset02 | Brain - Subset22 | Cancer - Subset07 | CT, Brain, Cancer | 28 | 26 |\n| CT - Subset03 | Brain - Subset22 | Cancer - Subset21 | CT, Brain, Cancer | 28 | 25 |\n| CT - Subset02 | Brain - Subset22 | State - Subset09 | CT, Brain, State | 33 | 64 |\n| CT - Subset03 | Brain - Subset22 | State - Subset26 | CT, Brain, State | 33 | 70 |\n| X-ray - Subset25 | Lung - Subset03 | Diseases - Subset02 | X-ray, Lung, Diseases | 30 | 45 |\n| X-ray - Subset26 | Lung - Subset03 | Diseases - Subset02 | X-ray, Lung, Diseases | 30 | 38 |\n| X-ray - Subset26 | Lung - Subset03 | Diseases - Subset08 | X-ray, Lung, Diseases | 30 | 44 |\n| X-ray - Subset26 | Breast - Subset24 | Diseases - Subset02 | X-ray, Breast, Diseases | 31 | 32 |\n| X-ray - Subset28 | Breast - Subset24 | Diseases - Subset08 | X-ray, Breast, Diseases | 31 | 52 |", "caption": "Table 4: Generalization results from 3 datasets providing different elements of MAT-Triplet (RQ 3). \"Related Combination\" is the training set, \"Target Subset\" is the goal. Baseline, and Trained represent the model\u2019s accuracy without training and trained on Related data, respectively. Green section indicates successful generalization, while red section denotes failure.", "description": "This table presents the results of a controlled experiment designed to investigate compositional generalization (CG) in multi-modal large language models (MLLMs).  Three datasets were selected, each providing different combinations of MAT-Triplet elements (Modality, Anatomical area, and Task).  The experiment tested whether the model could generalize to a target subset (a new combination of MAT-Triplet elements) by training only on related combinations of MAT-Triplet elements. The table shows the baseline performance (no training), and the accuracy of the model trained on related combinations. Green indicates successful generalization (the model correctly predicted the target task using only related training data), while red indicates failure.", "section": "3 Proof of Concept on CG"}, {"content": "| Related Combination | Target Subset | Target Subset | Baseline | Trained |\n|---|---|---|---|---|\n| Lung, Lung Det | Bones, **Diseases** | Lung, Diseases | 49 | 52 |\n| Lung, Lung Det | Breast, **Diseases** | Lung, Diseases | 49 | 54 |\n| Bones, Spinal Error Det | Breast, **Diseases** | Bones, Diseases | 20 | 30 |\n| Bones, Spinal Error Det | Lung, **Diseases** | Bones, Diseases | 20 | 33 |\n| MRI, **Diseases Det** | End, Level | End, Diseases | 24 | 27 |\n| X-ray, Lung Det | CT, **COVID** | X-ray, COVID | 23 | 26 |\n| Der, Skin, Cancer Det | FP, Fundus, **Diseases** | Der, Skin, Diseases | 24 | 29 |\n| Mic, Cell, Cancer Det | CT, Kidney, **Diseases** | Mic, Cell, Diseases | 24 | 26 |", "caption": "Table 5: Result of NEXT-Chat on CG by using detection and classification tasks to generalize classification Target dataset. Generalization results on classification datasets: \"Related Combination\" is the training set, \"Target Subset\" is the goal. Baseline and Trained represent the model\u2019s accuracy without training and trained on related data, respectively. Green section indicates successful generalization, while red section denotes failure. The 4 segmented areas represent different Direction Types: fixed modality, fixed area, and modality-area paired combinations.", "description": "Table 5 presents the results of using the NEXT-Chat model to assess compositional generalization (CG).  The experiment focuses on whether training with a combination of detection and classification datasets improves the model's ability to generalize to unseen classification tasks.  The table shows different combinations of related datasets used for training ('Related Combination'), the target dataset tested ('Target Subset'), and the model's accuracy with no training ('Baseline'), and after training on related data ('Trained').  The results are categorized into four 'Direction Types' based on how the related and target datasets were related: fixed modality, fixed area, fixed task, and paired modality-area combinations. Green highlights successful generalization, while red indicates failure. This helps understand how different relationships between training and target datasets impact generalization performance.", "section": "3.1 Controlled Variable Study on CG"}, {"content": "| Related Combination | Target Subset | Target Subset | Baseline | Trained |\n|---|---|---|---|---|\n| Lung, Lung Det | Bones, **Diseases** | Lung, Diseases | 41 | 47 |\n| Lung, Lung Det | Breast, **Diseases** | Lung, Diseases | 41 | 49 |\n| Bones, Spinal Error Det | Breast, **Diseases** | Bones, Diseases | 31 | 35 |\n| Bones, Spinal Error Det | Lung, **Diseases** | Bones, Diseases | 31 | 37 |\n| MRI, **Diseases Det** | End, Level | End, Diseases | 24 | 26 |\n| X-ray, Lung Det | CT, **COVID** | X-ray, COVID | 22 | 23 |\n| Der, Skin, Cancer Det | FP, Fundus, **Diseases** | Der, Skin, Diseases | 27 | 30 |\n| Mic, Cell, Cancer Det | CT, Kidney, **Diseases** | Mic, Cell, Diseases | 20 | 24 |", "caption": "Table 6: Result of MiniGPT-v2 on CG by using detection and classification tasks to generalize classification Target dataset. Generalization results on classification datasets: \"Related Combination\" is the training set, \"Target Subset\" is the goal. Baseline and Trained represent the model\u2019s accuracy without training and trained on related data, respectively. Green section indicates successful generalization, while red section denotes failure. The 3 segmented areas represent different Direction Types: fixed modality, fixed area, and modality-area paired combinations.", "description": "This table presents the results of using MiniGPT-v2, a multimodal large language model, to perform a compositional generalization task.  The model was trained on various combinations of datasets ('Related Combination')  with a shared MAT-Triplet (Modality, Anatomical Area, Task) to predict the accuracy on a target dataset ('Target Subset') with unseen combinations of these elements.  'Baseline' represents the model's accuracy without any training on related datasets, while 'Trained' reflects the accuracy after training with related datasets.  The table highlights successful ('Green') and unsuccessful ('Red') generalization, categorized by three 'Direction Types' that reflect variations in dataset selection: fixed modality, fixed area, and modality-area paired combinations. This helps understand how the model's ability to generalize depends on the relationships between the training and test data based on shared MAT-Triplets.", "section": "3.1 Controlled Variable Study on CG"}, {"content": "| Related Combination | Target Subset | Baseline | Trained |\n|---|---|---|---| \n| Bones, State | Breast, **Diseases** | Bones, Diseases | 61 | 65 |\n| Lung, COVID | Bones, **Diseases** | Lung, Diseases | 80 | 91 |\n| CT, **COVID** | X-ray, Diseases | X-ray, COVID | 35 | 40 |\n| CT, **State** | X-ray, Diseases | X-ray, State | 35 | 43 |\n| X-ray, **Lung** | CT, Brain(Cancer) | CT, Lung | 32 | 33 |\n| X-ray, **Lung** | CT, Brain | CT, Lung(Cancer) | 65 | 72 |\n| FP, Fundus, Diseases | Mic, Cell, **Level** | FP, Fundus, Level | 48 | 45 |\n| Mic, Cell, Cell Identification | FP, Fundus, **Level** | Mic, Cell, Level | 34 | 41 |", "caption": "Table 7: Result of Qwen2-VL on selected classification datasets in Med-MAT. Green section indicates successful generalization, while red section denotes failure.", "description": "Table 7 presents the results of using the Qwen2-VL model on a subset of classification datasets from the Med-MAT dataset. The table showcases the model's performance in generalizing to unseen data based on training with related and unrelated data. Green highlights successful generalization, while red denotes failure. Each row represents a pair of related and target datasets, indicating which combinations successfully promote generalization to the target dataset.", "section": "3.1 Controlled Variable Study on CG"}, {"content": "| Related Combination | Target Subset | Baseline | Trained |\n|---|---|---|---| \n| **Bones**, State, Breast, **Diseases** | **Bones**, Diseases | 52 | 59 |\n| **Lung**, COVID, Bones, **Diseases** | **Lung**, Diseases | 64 | 75 |\n| CT, **COVID**, X-ray, **Diseases** | **X-ray**, COVID | 33 | 38 |\n| CT, **State**, X-ray, **Diseases** | **X-ray**, State | 33 | 41 |\n| X-ray, **Lung**, CT, Brain(Cancer) | **CT**, Lung | 31 | 29 |\n| X-ray, **Lung**, CT, Brain | **CT**, Lung(Cancer) | 49 | 57 |\n| **FP**, Fundus, Diseases, Mic, Cell, **Level** | **FP**, Fundus, Level | 55 | 61 |\n| **Mic**, Cell, Cell Identification, FP, Fundus, **Level** | **Mic**, Cell, Level | 10 | 32 |", "caption": "Table 8: Result of Llama-3.2-Vision on selected classification datasets in Med-MAT. Green section indicates successful generalization, while red section denotes failure.", "description": "Table 8 presents the results of using the Llama-3.2-Vision model on a subset of classification datasets from the Med-MAT dataset.  The table shows the model's performance on unseen data ('Target Subset') after being trained on related datasets ('Related Combination').  The results are categorized to show successful generalization (green) or failure (red). The categories represent different types of relationships between the training and target datasets, based on fixed modalities, anatomical areas, tasks, or combinations of these factors.", "section": "3.2 Scaling the Combination Number of CG"}, {"content": "| Subset No. | Modality | Anatomical Area | Task | Datasets No. |\n|---|---|---|---|---|\n| 01 | Co | Cervix | Cervical Picture Quality Evaluation | 1 |\n| 02 | CT | Kidney | Kidney Diseases Classification | 2 |\n| 03 | CT | Lung | COVID-19 Classification | 3,4,6 |\n| 04 | CT | Lung | Lung Cancer Classification | 5 |\n| 05 | CT | Brain | Brain Hemorrhage Classification | 7 |\n| 06 | CT | Brain | Brain Cancer Classification | 8 |\n| 07 | Der | Skin | Melanoma Type Classification | 10 |\n| 08 | Der | Skin | Skin Diseases Classification | 9, 11-15, 71, 72, 74 |\n| 09 | DP | Mouth | Teeth Condition Classification | 16 |\n| 10 | DP | Mouth | Oral Cancer Classification | 17 |\n| 11 | End | Intestine | Intestine Cleanliness Level | 18 |\n| 12 | End | Bladder | Cancer Degree Classification | 19 |\n| 13 | End | Intestine | Intestine Diseases Classification | 20 |\n| 14 | FP | Fundus | Eye Diseases Classification | 21-23, 26-28, 31, 32, 75 |\n| 15 | FP | Fundus | Multiple-labels Eye Diseases Classification | 24, 25, 68 |\n| 16 | FP | Fundus | Blindness Level | 29 |\n| 17 | FP | Fundus | Retinal Images Quality Evaluation | 30 |\n| 18 | Mic | Cell | Cell Type Classification | 33, 36-38, 39-41, 44, 65, 70 |\n| 19 | Mic | Cell | Prostate Cancer Degree Classification | 34 |\n| 20 | Mic | Cell | Multiple-labels Blood Cell Classification | 35 |\n| 21 | Mic | Cell | Cancer Classification | 42, 67 |\n| 22 | MRI | Brain | Head Diseases Classification | 44, 45 |\n| 23 | OCT | Retina | Retina Diseases Classification | 46, 47 |\n| 24 | US | Breast | Breast Cancer Classification | 48 |\n| 25 | X-ray | Bones | Degree Classification of Knee | 49, 53 |\n| 26 | X-ray | Bones | Fractured Classification | 50, 51 |\n| 27 | X-ray | Bones | Vertebrae Diseases Classification | 52 |\n| 28 | X-ray | Lung | COVID-19 and Pneumonia Classification | 54-57, 60, 62, 81 |\n| 29 | X-ray | Breast | Breast Diseases Classification | 58, 78 |\n| 30 | X-ray | Lung | Tuberculosis Classification | 59, 79 |\n| 31 | X-ray | Chest | Multiple-labels Chest Classification | 61, 73, 76, 77, 80, 85, 87 |\n| 32 | X-ray | Brain | Tumor Classification | 63 |\n| 33 | Mic | Cell | Multi-labels Diseases | 84 |\n| 34 | FP | Fundus | Level Identification | 66 |\n| 35 | X-ray | Bones | Level Identification | 69 |\n| 36 | X-ray | Bones | Spinal lesion Classification | 86 |\n| 37 | X-ray | Breast | Multi-labels Diseases | 82 |\n| 38 | Der | Skin | Lesion Det/Seg | 88-91 |\n| 39 | End | Intestine | PolyP Det/Seg | 92-93 |\n| 40 | End | Intestine | Surgical Procedures Det/Seg | 94 |\n| 41 | End | Intestine | Multi-labels Det/Seg | 95 |\n| 42 | Mic | Cell | Cancer Cell Det/Seg | 96 |\n| 43 | US | Chest | Cancer Det/Seg | 97 |\n| 44 | US | Thyroid | Thyroid Nodule Region Det/Seg | 98 |\n| 45 | MRI | Intestine | Multi-labels Det/Seg | 103 |\n| 46 | MRI | Liver | Liver Det/Seg | 104, 105 |\n| 47 | X-ray | Lung | Lung Det/Seg | 99 |\n| 48 | X-ray | Lung | Pneumothorax Det/Seg | 106 |\n| 49 | X-ray | Bones | Spinal Anomaly Det | 100 |\n| 50 | X-ray | Chest | Multi-labels Det | 101, 102 |\n| 51 | FP | Fundus | Vessel Seg | 107 |\n| 52 | FP | Fundus | Optic Disc and Cup Seg | 108 |", "caption": "Table 9: The details of subset. In particular, Co stands for Colposcopy, CT represents Computed Tomography, DP refers to Digital Photography, FP is for Fundus Photography, MRI denotes Magnetic Resonance Imaging, OCT signifies Optical Coherence Tomography, Der refers to Dermoscopy, End stands for Endoscopy, Mic indicates Microscopy Images, and US represents Ultrasound. The blue section represents the classification dataset and the green section represents the detection", "description": "Table 9 details the composition of the Med-MAT dataset, showing how it's divided into subsets.  Each subset contains medical images categorized by three elements: Modality (e.g., CT scan, MRI), Anatomical Area (e.g., lung, brain), and Task (e.g., cancer detection, disease classification). The table lists each subset, specifying its modality, anatomical area, task, and the number of datasets included.  It also uses color-coding to distinguish between classification and detection tasks within the subsets. Abbreviations for modalities (e.g., Co for Colposcopy, CT for Computed Tomography, etc.) are provided in the caption to aid understanding.", "section": "2 Med-MAT"}, {"content": "| No. | Name | Description | Citation |\n|---|---|---|---| \n| 1 | [Intel & MobileODT Cervical Screening](https://www.kaggle.com/competitions/intel-mobileodt-cervical-cancer-screening/data) | Cervix Type in Screening | BenO et al. ([2017](https://arxiv.org/html/2412.20070v1#bib.bib11)) |\n| 2 | [CT Kindney Dataset](https://www.kaggle.com/datasets/nazmul0087/ct-kidney-dataset-normal-cyst-tumor-and-stone) | Normal or Cyst or Tumor | Islam et al. ([2022a](https://arxiv.org/html/2412.20070v1#bib.bib39)) |\n| 3 | [SARS-COV-2 Ct-Scan](https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset) | COVID19, Classification Dataset | Soares et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib99)) |\n| 4 | [COVID CT COVID-CT](https://tianchi.aliyun.com/dataset/106604) | COVID19, Classification Dataset. | Zhao et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib124)) |\n| 5 | [Chest CT-Scan](https://tianchi.aliyun.com/dataset/93929) | Cancer Classification | SunneYi ([2021](https://arxiv.org/html/2412.20070v1#bib.bib102)) |\n| 6 | [COVID-19-CT SCAN IMAGES](https://tianchi.aliyun.com/dataset/93666) | COVID19, Classification | wjXiaochuangw ([2019](https://arxiv.org/html/2412.20070v1#bib.bib113)) |\n| 7 | [Head CT](https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage?select=labels.csv) | Head Hemorrhage | Kitamura ([2018](https://arxiv.org/html/2412.20070v1#bib.bib50)) |\n| 8 | [CT of Brain](https://www.kaggle.com/datasets/trainingdatapro/computed-tomography-ct-of-the-brain) | Head Cancer | Data ([2023](https://arxiv.org/html/2412.20070v1#bib.bib26)) |\n| 9 | [MED-NODE](https://www.cs.rug.nl/%C2%A0imaging/databases/melanoma_naevi/) | Melanoma or Naevus | Giotis et al. ([2015](https://arxiv.org/html/2412.20070v1#bib.bib32)) |\n| 10 | [ISIC 2020](https://challenge2020.isic-archive.com/) | Melanoma, Benign or Malignant | Rotemberg et al. ([2021](https://arxiv.org/html/2412.20070v1#bib.bib94)) |\n| 11 | [PED-UFES-20](https://data.mendeley.com/datasets/zr7vgbcyr2/1) | Skin Multi Classification | Pacheco et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib79)) |\n| 12 | [Web-scraped Skin Image](https://www.kaggle.com/datasets/arafathussain/monkeypox-skin-image-dataset-2022,%20https://www.heywhale.com/mw/dataset/62eb75d6fef0903951b1f199) | Skin Desease Multi Classification | Islam et al. ([2022b](https://arxiv.org/html/2412.20070v1#bib.bib40)) |\n| 13 | [ISBI 2016](https://www.kaggle.com/datasets/angelachristabel/isbi-2016?select=Training_GroundTruth.csv) | Skin Lesion Classification | Gutman et al. ([2016](https://arxiv.org/html/2412.20070v1#bib.bib37)) |\n| 14 | [ISIC 2019](https://www.kaggle.com/datasets/andrewmvd/isic-2019) | Skin Desease Multi Classification | Combalia et al. ([2019](https://arxiv.org/html/2412.20070v1#bib.bib24)) |\n| 15 | [Skin Cancer ISIC](https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic) | Skin Cancer Multi Classification | Katanskiy ([2019](https://arxiv.org/html/2412.20070v1#bib.bib47)) |\n| 16 | [Dental Condition Dataset](https://www.kaggle.com/datasets/salmansajid05/oral-diseases/data) | Teeth condition classification | Sajid ([2024](https://arxiv.org/html/2412.20070v1#bib.bib96)) |\n| 17 | [Oral Cancer Dataset](https://www.kaggle.com/datasets/zaidpy/oral-cancer-dataset) | Oral cancer Classification | RASHID ([2024](https://arxiv.org/html/2412.20070v1#bib.bib91)) |\n| 18 | [The Nerthus Dataset](https://datasets.simula.no/nerthus/) | Cleanliness level | Pogorelov et al. ([2017a](https://arxiv.org/html/2412.20070v1#bib.bib84)) |\n| 19 | [Endoscopic Bladder Tissue](https://commons.datacite.org/doi.org/10.5281/zenodo.7741475) | Canser Degree Classification | Lazo et al. ([2023](https://arxiv.org/html/2412.20070v1#bib.bib51)) |\n| 20 | [Kvasir](https://www.kaggle.com/datasets/meetnagadia/kvasir-dataset) | Multi Disease Classification | Pogorelov et al. ([2017b](https://arxiv.org/html/2412.20070v1#bib.bib85)) |\n| 21 | [ACRIMA](https://figshare.com/s/c2d31f850af14c5b5232) | Glaucoma | Ovreiu et al. ([2021](https://arxiv.org/html/2412.20070v1#bib.bib78)) |\n| 22 | [Augemnted ocular diseases AOD](https://www.kaggle.com/datasets/nurmukhammed7/augemnted-ocular-diseases) | Multi Classification of eye diseases | \u0411\u0430\u049b\u0442\u044b\u0431\u0435\u043a\u04b1\u043b\u044b ([2021](https://arxiv.org/html/2412.20070v1#bib.bib129)) |\n| 23 | [JSIEC](https://www.kaggle.com/datasets/linchundan/fundusimage1000) | Multi Classification of eye diseases | Cen et al. ([2021](https://arxiv.org/html/2412.20070v1#bib.bib15)) |\n| 24 | [Multi-Label Retinal Diseases](https://data.mendeley.com/datasets/pc4mb3h8hz/1) | Multi Classification of eye diseases | Rodr\u00edguez et al. ([2022](https://arxiv.org/html/2412.20070v1#bib.bib93)) |\n| 25 | [RFMiD 2.0](https://github.com/openmedlab/Awesome-Medical-Dataset/blob/main/resources/RFMiD.md) | Multi Classification of eye diseases | Panchal et al. ([2023](https://arxiv.org/html/2412.20070v1#bib.bib80)) |\n| 26 | [ToxoFundus(Data Processed Paper)](https://www.kaggle.com/datasets/nafin59/ocular-toxoplasmosis-fundus-images-dataset) | Ocular toxoplasmosis | Cardozo et al. ([2023](https://arxiv.org/html/2412.20070v1#bib.bib14)) |\n| 27 | [ToxoFundus(Data Raw 6class All)](https://www.kaggle.com/datasets/nafin59/ocular-toxoplasmosis-fundus-images-dataset) | Ocular toxoplasmosis | Cardozo et al. ([2023](https://arxiv.org/html/2412.20070v1#bib.bib14)) |\n| 28 | [Adam dataset](https://www.kaggle.com/datasets/xiaoliang2121/adamdataset) | Age-related Macular Degeneration | Liang ([2021](https://arxiv.org/html/2412.20070v1#bib.bib60)) |\n| 29 | [APTOS 2019 Blindness](https://www.kaggle.com/competitions/aptos2019-blindness-detection) | Blindness Level Identification 0 4 | Karthik et al. ([2019](https://arxiv.org/html/2412.20070v1#bib.bib46)) |\n| 30 | [DRIMBD](https://www.kaggle.com/datasets/subhajournal/drimdb-diabetic-retinopathy-images-database) | Quality Testing of Retinal Images | Prentasic et al. ([2013](https://arxiv.org/html/2412.20070v1#bib.bib87)) |\n| 31 | [Glaucoma Detection](https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection) | Glaucoma Classification | Zhang and Das ([2022](https://arxiv.org/html/2412.20070v1#bib.bib118)) |\n| 32 | [AIROGS](https://zenodo.org/records/5793241) | Glaucoma Classification | de Vente et al. ([2023](https://arxiv.org/html/2412.20070v1#bib.bib27)) |\n| 33 | [ICPR-HEp-2](https://github.com/KaikaiZhao/HEp-2_cell_classification) | Multi Classification | Qi et al. ([2016](https://arxiv.org/html/2412.20070v1#bib.bib88)) |\n| 34 | [SICAPv2](https://data.mendeley.com/datasets/9xxm58dvs3/1) | Cancer Degree Classification | Silva-Rodr\u00edguez et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib98)) |\n| 35 | [Blood Cell Images](https://www.kaggle.com/datasets/paultimothymooney/blood-cells) | Blood Cell Classificaion (Multi) | Mooney ([2017](https://arxiv.org/html/2412.20070v1#bib.bib70)) |\n| 36 | [BreakHis](https://www.kaggle.com/datasets/ambarish/breakhis) | Cell type and beginormag | Bukun ([2019](https://arxiv.org/html/2412.20070v1#bib.bib13)) |\n| 37 | [Chaoyang](https://bupt-ai-cz.github.io/HSA-NRL/) | Multi Classification of pathologists | [Zhu et al.](https://arxiv.org/html/2412.20070v1#bib.bib125) |\n| 38 | [HuSHeM](https://data.mendeley.com/datasets/tt3yj2pf38/3) | Sperm Head Morphology Classificaion | Shaker ([2018](https://arxiv.org/html/2412.20070v1#bib.bib97)) |\n| 39 | [Bone Marrow Cell Classification](https://www.kaggle.com/datasets/andrewmvd/bone-marrow-cell-classification) | Bone Marrow Cell Classification | Matek et al. ([2021](https://arxiv.org/html/2412.20070v1#bib.bib65)) |\n| 40 | [NCT-CRC-HE-100K](https://zenodo.org/records/1214456) | Multi Classification | Kather et al. ([2018](https://arxiv.org/html/2412.20070v1#bib.bib48)) |\n| 41 | [Malignant Lymphoma Classification](https://www.kaggle.com/datasets/andrewmvd/malignant-lymphoma-classification) | Multi Classification | Orlov et al. ([2010a](https://arxiv.org/html/2412.20070v1#bib.bib76)) |\n| 42 | [Histopathologic Cancer Detection](https://www.kaggle.com/c/histopathologic-cancer-detection/data) | Cancer Classification | Cukierski ([2018](https://arxiv.org/html/2412.20070v1#bib.bib25)) |\n| 43 | [LC25000](https://www.kaggle.com/datasets/xilezhu/lc25000) | Multi Classification of Lung and Colon | Zhu ([2022](https://arxiv.org/html/2412.20070v1#bib.bib128)) |\n| 44 | [Brain Tumor 17 Classes](https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-17-classes) | Multi Classification | Feltrin ([2022](https://arxiv.org/html/2412.20070v1#bib.bib29)) |\n| 45 | [Tumor Classification](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset) | Pituitary or Glioma or Meningioma or Notumor | Nickparvar ([2021a](https://arxiv.org/html/2412.20070v1#bib.bib74)) |\n| 46 | [Malignant Lymphoma Classification](https://www.kaggle.com/datasets/andrewmvd/malignant-lymphoma-classification) | Multi Classification of eye diseases | Orlov et al. ([2010b](https://arxiv.org/html/2412.20070v1#bib.bib77)) |\n| 47 | [Retinal OCT-C8](https://www.kaggle.com/datasets/obulisainaren/retinal-oct-c8) | Multi Classification of eye diseases | Subramanian et al. ([2022](https://arxiv.org/html/2412.20070v1#bib.bib100)) |\n| 48 | [BUSI](https://www.kaggle.com/datasets/sabahesaraki/breast-ultrasound-images-dataset) | Breast Cancer | Al-Dhabyani et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib2)) |\n| 49 | [Digital Knee X-Ray Images](https://data.mendeley.com/datasets/t9ndx37v5h/1) | Degree Classification of Knee | Gornale and Patravali ([2020](https://arxiv.org/html/2412.20070v1#bib.bib35)) |\n| 50 | [Bone Fracture Multi-Region X-ray Data](https://www.kaggle.com/datasets/preetviradiya/brian-tumor-dataset) | Fractured Classification | Nickparvar ([2021b](https://arxiv.org/html/2412.20070v1#bib.bib75)) |\n| 51 | [Fracture detection](https://www.kaggle.com/datasets/devbatrax/fracture-detection-using-x-ray-images) | Fractured Classification | Batra ([2024](https://arxiv.org/html/2412.20070v1#bib.bib9)) |\n| 52 | [The vertebrae X-ray image](https://www.kaggle.com/datasets/yasserhessein/the-vertebrae-xray-images) | Vertebrae | Fraiwan et al. ([2022](https://arxiv.org/html/2412.20070v1#bib.bib30)) |\n| 53 | [Knee Osteoarthritis Dataset](https://www.kaggle.com/datasets/shashwatwork/knee-osteoarthritis-dataset-with-severity) | Knee Osteoarthritis with severity grading | Chen ([2018](https://arxiv.org/html/2412.20070v1#bib.bib20)) |\n| 54 | [Shenzhen Chest X-Ray Set](https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#tuberculosis-image-data-sets) | COVID19, Classification Dataset. | Jaeger et al. ([2014](https://arxiv.org/html/2412.20070v1#bib.bib41)) |\n| 55 | [Chest X-ray PD](https://data.mendeley.com/datasets/jctsfj2sfn/1) | COVID and Pneumonia | Asraf and Islam ([2021](https://arxiv.org/html/2412.20070v1#bib.bib7)) |\n| 56 | [COVID-19 CHEST X-RAY DATABASE](https://www.heywhale.com/mw/dataset/6027caee891f960015c863d7/content) | COVID and Pneumonia | Chowdhury et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib21)) |\n| 57 | [COVIDGR](https://github.com/ari-dasci/covidgr) | COVID19, Classification | Tabik et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib103)) |\n| 58 | [MIAS](https://www.kaggle.com/datasets/kmader/mias-mammography) | Multi Classification of Breast | Mader ([2017](https://arxiv.org/html/2412.20070v1#bib.bib63)) |\n| 59 | [Tuberculosis Chest X-Ray Database](https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset) | Tuberculosis | Rahman et al. ([2020](https://arxiv.org/html/2412.20070v1#bib.bib90)) |\n| 60 | [Pediatric Pneumonia Chest X-Ray](https://www.kaggle.com/datasets/andrewmvd/pediatric-pneumonia-chest-xray) | Pneumonia Classification | Kermany ([2018](https://arxiv.org/html/2412.20070v1#bib.bib49)) |", "caption": "Table 10: The details of the medical datasets are provided", "description": "Table 10 provides detailed information on the 109 medical datasets used in the study.  For each dataset, it lists the dataset name, a brief description of its contents (e.g., type of medical images, specific diseases or conditions), and the corresponding citation from the literature where the dataset is originally described. This table is crucial for understanding the breadth and diversity of the data used to train and evaluate the multimodal large language models (MLLMs) in the paper, particularly concerning compositional generalization.", "section": "2 Med-MAT"}, {"content": "| No. | Name | Description | Citation |\n|---|---|---|---|\n| 61 | [Random Sample of NIH Chest X-Ray Dataset](https://www.kaggle.com/datasets/nih-chest-xrays/sample) | Multi Classificaiton of Chest | Wang et al. (2017) |\n| 62 | [CoronaHack-Chest X-Ray](https://www.kaggle.com/datasets/praveengovi/coronahack-chest-xraydataset) | Pnemonia Classifcition with Virus type | Praveen (2019) |\n| 63 | [Brain Tumor Dataset](https://www.kaggle.com/datasets/preetviradiya/brian-tumor-dataset) | Tumor Classification | Viradiya (2020) |\n| 64 | [Fitzpatrick 17k (Nine Labels)](https://github.com/mattgroh/fitzpatrick17k) | Multi Classification | Groh et al. (2021) |\n| 65 | [BioMediTech](https://figshare.com/s/d6fb591f1beb4f8efa6f) | Multi Classification | Nanni et al. (2016) |\n| 66 | [Diabetic retinopathy](https://zenodo.org/records/4891308) | Diabetic Retinopathy Level | Ben\u00edtez et al. (2021) |\n| 67 | [Leukemia](https://tianchi.aliyun.com/dataset/90101/notebook) | Cancer Classification | Codella et al. (2019) |\n| 68 | [ODIR-5K](https://odir2019.grand-challenge.org/introduction/) | Multiple Labels Classification | University (2019) |\n| 69 | [Arthrosis](https://aistudio.baidu.com/datasetdetail/69582/0) | Bone Age Classification | Zha (2021) |\n| 70 | [HSA-NRL](https://bupt-ai-cz.github.io/HSA-NRL/) | Multi Classification of pathologists | Zhu et al. (2021) |\n| 71 | [ISIC 2018 (Task 3)](https://challenge.isic-archive.com/data/#2018) | Multi Classification | Codella et al. (2019) |\n| 72 | [ISIC 2017 (Task 3)](https://challenge.isic-archive.com/data/#2018) | Multi Classification | Codella et al. (2018) |\n| 73 | [ChestX-Det](https://opendatalab.com/OpenDataLab/ChestX-Det) | Multi Classification | Lian et al. (2021) |\n| 74 | [Monkeypox Skin Lesion Dataset](https://www.kaggle.com/datasets/nafin59/monkeypox-skin-lesion-dataset) | Only Monkeypox | Ali et al. (2022) |\n| 75 | [Cataract Dataset](https://www.kaggle.com/datasets/jr2ngb/cataractdataset) | Multi Classification | JR2NGB (2019) |\n| 76 | [ChestX-rays IndianaUniversity](https://www.kaggle.com/datasets/raddar/chest-xrays-indiana-university?select=indiana_reports.csv) | Multi-label Classification | Raddar (2019) |\n| 77 | [CheXpert v1.0 small](https://www.kaggle.com/datasets/willarevalo/chexpert-v10-small) | Multi-label Classification | Arevalo (2020) |\n| 78 | [CBIS-DDSM](https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset) | Multi Classification | Lee et al. (2017) |\n| 79 | [NLM-TB](https://www.kaggle.com/datasets/nurkaraca/nlm-montgomerycxrset) | Tuberculosis | Karaca (2022) |\n| 80 | [ChestXray-NIHCC](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345) | Multi-label Classification | Summers and Ronald (2020) |\n| 81 | [COVIDx CXR-4](https://www.kaggle.com/datasets/andyczhao/covidx-cxr2) | COVID19, Classification | Wang et al. (2020) |\n| 82 | [VinDr-Mammo](https://www.kaggle.com/datasets/ssmann/vindr-mammo-dataset) | Multi-label Classification | Nguyen et al. (2023) |\n| 83 | [PBC dataset normal DIB](https://data.mendeley.com/datasets/snkd93bnjr/1) | Multi Classification | Acevedo et al. (2020) |\n| 84 | [Human Protein Atlas](https://www.kaggle.com/competitions/hpa-single-cell-image-classification/data?select=train.csv) | Multi-label Classification (Only green) | Le et al. (2022) |\n| 85 | [RSNA Pneumonia Detection Challenge 2018](https://www.rsna.org/rsnai/ai-image-challenge/rsna-pneumonia-detection-challenge-2018) | Multi-label Classification | Anouk Stein et al. (2018) |\n| 86 | [VinDr-SpineXR](https://www.physionet.org/content/vindr-spinexr/1.0.0/) | Multi Classification of Bones Diseases | Pham et al. (2021) |\n| 87 | [VinDr-PCXR](https://physionet.org/content/vindr-pcxr/1.0.0/) | Multi-label Classification | Pham et al. (2022) |\n| 88 | [PH2](https://paperswithcode.com/dataset/ph2) | Melanoma Segmentation | Mendonca et al. (2015) |\n| 89 | [ISBI 2016 (Task3B)](https://www.kaggle.com/datasets/angelachristabel/isbi-2016?select=Training_GroundTruth.csv) | Melanoma Segmentation | Gutman et al. (2016) |\n| 90 | [ISIC 2016 (Task 1)](https://challenge.isic-archive.com/data/#2018) | Melanoma Segmentation | Gutman et al. (2016) |\n| 91 | [ISIC 2017](https://challenge.isic-archive.com/data/#2018) | Melanoma Segmentation | Codella et al. (2018) |\n| 92 | [CVC-ClinicDB](https://polyp.grand-challenge.org/CVCClinicDB/) | Polyp Segmentation | Bernal et al. (2015) |\n| 93 | [Kvasir-SEG](https://datasets.simula.no/kvasir-seg/, https://github.com/DebeshJha/2020-MediaEval-Medico-polyp-segmentation/tree/master) | Polyp segmentation | Jha et al. (2020) |\n| 94 | [m2caiseg](https://www.kaggle.com/datasets/salmanmaq/m2caiseg) | Surgical Instrument Segmentation | Maqbool et al. (2020) |\n| 95 | [EDD 2020](https://edd2020.grand-challenge.org/Data/) | Multiple Diseases Segmentation in Intestine | Ali et al. (2020) |\n| 96 | [SICAPv2](https://data.mendeley.com/datasets/9xxm58dvs3/1) | Cancer Cells Segmentation | Silva-Rodr\u00edguez et al. (2020) |\n| 97 | [BUSI](https://www.kaggle.com/datasets/sabahesaraki/breast-ultrasound-images-dataset) | Cancer Segmentation | Hesaraki (2022) |\n| 98 | [TN3K](https://github.com/haifangong/TRFE-Net-for-thyroid-nodule-segmentation) | Thyroid Nodule Segmentation | Gong et al. (2022) |\n| 99 | [NLM-TB](https://openi.nlm.nih.gov/imgs/collections/NLM-MontgomeryCXRSet.zip) | Lung Segmentation (With left or right) | Gong et al. (2021) |\n| 100 | [VinDr-SpineXR](https://www.physionet.org/content/vindr-spinexr/1.0.0/) | Spinal X-ray Anaomaly Detection | Pham et al. (2021) |\n| 101 | [VinDr-PCXR](https://physionet.org/content/vindr-pcxr/1.0.0/) | Multiple Diseases Segmentation in Chest | Pham et al. (2022) |\n| 102 | [ChestX-Det](https://opendatalab.com/OpenDataLab/ChestX-Det) | Multiple Diseases Segmentation in Chest | Lian et al. (2021) |\n| 103 | [UW-Madison Gl Tract Image Segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/overview) | Surgical Instrument Segmentation | Lee et al. (2024) |\n| 104 | [Duke Liver Dataset MRI v1](https://zenodo.org/records/7774566) | Liver Segmentation | Macdonald et al. (2020) |\n| 105 | [Duke Liver Dataset MRI v2](https://zenodo.org/records/7774566) | Liver Segmentation | Macdonald et al. (2020) |\n| 106 | [SIIM-ACR Pneumothorax Segmentation](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation) | Pneumothorax Segmentation | Zawacki et al. (2019) |\n| 107 | [FIVES](https://figshare.com/articles/figure/FIVES_A_Fundus_Image_Dataset_for_AI-based_Vessel_Segmentation/19688169/1?file=34969398) | Fundus Vascular Segmentation | Jin et al. (2022) |\n| 108 | [RIM-ONE DL](https://github.com/miag-ull/rim-one-dl?tab=readme-ov-file) | Optic Disc and Cup Segmentation | Batista et al. (2020) |\n| 109 | [PALM19](https://ieee-dataport.org/documents/palm-pathologic-myopia-challenge) | Optic Disc Segmentation | Fu et al. (2019) |", "caption": "Table 11: Continued from Table\u00a010.", "description": "Table 11 provides a continuation of the dataset descriptions started in Table 10.  It lists additional medical image datasets used in the study, detailing their names, descriptions of the medical tasks involved (e.g., classification, segmentation, detection), and the citation for each dataset's source.  The table is crucial for understanding the breadth and diversity of data used to evaluate the model's capabilities and generalization performance.", "section": "Related Work"}]