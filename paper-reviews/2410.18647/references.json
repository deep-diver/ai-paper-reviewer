{"references": [{" publication_date": "2020", "fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is foundational in establishing the effectiveness of scaling laws in large language models (LLMs), showing that performance improves significantly with increases in dataset size, model size, and computational resources.  This is highly relevant to the current research as it provides a basis for investigating the possibility of similar scaling laws in robotic manipulation.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "This paper demonstrates the power of scaling laws in computer vision, showing that large models trained on massive datasets with natural language supervision can achieve remarkable generalization capabilities. This is directly relevant because it provides evidence of the potential for scaling to improve generalization in robotics.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Jared Kaplan", "paper_title": "Scaling laws for neural language models", "reason": "This paper is seminal in establishing the concept of scaling laws in deep learning, providing quantitative relationships between model size, dataset size, and compute and performance metrics.  Its methodology of establishing power-law relationships serves as a template for the current research, which seeks to find similar relationships in robotic manipulation.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Tom Henighan", "paper_title": "Scaling laws for autoregressive generative modeling", "reason": "This paper extends the understanding of scaling laws to generative models, demonstrating that similar relationships between model size, data size, and compute hold for this important class of models.  This is relevant because generative models are becoming increasingly important in robotics, and understanding scaling laws in this context is crucial.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "reason": "This paper provides a comprehensive analysis of the GPT-4 model, a large language model that showcases the power of scaling.  It's relevant to this study because it offers insights into the performance improvements that can be achieved through scaling and the challenges of effectively utilizing large datasets.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This paper presents a groundbreaking model for image segmentation that demonstrates the power of scaling in computer vision. Its success in achieving robust and generalizable segmentation across a wide range of images is relevant to the current work which seeks to achieve similar generalization performance in robotics.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "This paper demonstrates the scalability and effectiveness of diffusion models, a type of generative model.  The use of diffusion models in robotics is increasing, and understanding their scaling properties is crucial for the development of more efficient and effective robotic systems. ", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "reason": "This report details the development of GPT-4, a large language model that highlights the importance of scaling laws and resource allocation in achieving state-of-the-art performance.  Its discussion on resource efficiency and model scaling provides valuable context for optimizing data collection in robotics.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Abhishek Padalkar", "paper_title": "Open x-embodiment: Robotic learning datasets and rt-x models", "reason": "This paper introduces OXE, a large-scale dataset for robotic manipulation. While OXE is valuable, its limitation in achieving zero-shot generalization to new environments and unseen objects highlights the need for further research into data scaling for improving generalization in robotics, directly motivating the current study.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Alexander Khazatsky", "paper_title": "Droid: A large-scale in-the-wild robot manipulation dataset", "reason": "This paper introduces DROID, a large-scale dataset for robotic manipulation focusing on real-world scenarios.  Its emphasis on in-the-wild data and focus on a variety of tasks makes it highly relevant to the current research which aims for real-world generalization in robotic manipulation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Haritheja Etukuru", "paper_title": "General policies for zero-shot deployment in new environments", "reason": "This paper explores zero-shot generalization in robotics, which is a key goal of the current research.  By studying a method capable of performing zero-shot deployment, the authors provide valuable context to the approaches used in the current paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Cheng Chi", "paper_title": "Diffusion policy: Visuomotor policy learning via action diffusion", "reason": "This paper introduces the Diffusion Policy, the core method used in the current research for learning robotic manipulation policies. Understanding the strengths and limitations of the Diffusion Policy is crucial for interpreting the results and contributions of this study.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "reason": "This paper introduces the Denoising Diffusion Implicit Models (DDIM), a key component of the Diffusion Policy used in the current research.  DDIM is employed to improve the efficiency of inference, making real-time control possible.  Understanding the underlying mechanism of DDIM is crucial for evaluating the contributions of the current study.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "reason": "This paper introduces DINOv2, a self-supervised vision transformer used as the visual encoder in the current research.  DINOv2 is chosen for its ability to improve spatial reasoning and scene understanding, which is directly relevant to the effectiveness of robotic manipulation policies.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This paper introduces the Vision Transformer (ViT) architecture, a fundamental component of the DINOv2 visual encoder used in the current research.  The ViT architecture is crucial for the high performance of the visual encoder in learning robotic manipulation policies.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Tony Z Zhao", "paper_title": "Learning fine-grained bimanual manipulation with low-cost hardware", "reason": "This paper provides insights into the challenges and opportunities associated with learning complex manipulation tasks using low-cost hardware. These insights are highly relevant to the current study, particularly as it uses a low-cost gripper for data collection and seeks to make robotic learning more cost-effective.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Jensen Gao", "paper_title": "Efficient data collection for robotic manipulation via compositional generalization", "reason": "This work explores efficient data collection for robotic manipulation, a crucial aspect of the current research. By focusing on compositional generalization, the authors provide insights into methods for improving data collection efficiency and data utilization, making it highly relevant to the current study\u2019s emphasis on efficient data acquisition.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Cheng Chi", "paper_title": "Universal manipulation interface: In-the-wild robot teaching without in-the-wild robots", "reason": "This paper introduces the Universal Manipulation Interface (UMI), the key hardware used for data collection in the current study. Understanding the design and capabilities of UMI is essential for interpreting the results and understanding the feasibility of the proposed data collection strategy.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Annie Xie", "paper_title": "Decomposing the generalization gap in imitation learning for visual robotic manipulation", "reason": "This paper directly addresses the problem of generalization in imitation learning for robotic manipulation, making it highly relevant to the current research. By analyzing the factors contributing to the generalization gap, the authors provide insights into strategies for improving generalization performance, directly informing the current study.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Eliot Xing", "paper_title": "Kitchenshift: Evaluating zero-shot generalization of imitation-based policy learning under domain shifts", "reason": "This work focuses on evaluating zero-shot generalization in robotic manipulation, a key goal of the current research.  The focus on domain shifts is particularly relevant, as the current paper also aims to achieve generalization to new environments and objects.  Understanding the challenges and successes of zero-shot generalization is crucial for evaluating the contributions of this study.", "section_number": 4}]}