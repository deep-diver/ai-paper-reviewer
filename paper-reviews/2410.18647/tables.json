[{"figure_path": "2410.18647/tables/table_9_0.html", "caption": "Table 1: Success rate across all tasks. We report the average success rate and standard deviation across 8 unseen environments. The performance in each environment is detailed in Table 12.", "description": "The table presents the average success rate and standard deviation of the policies across four tasks and eight unseen environments.", "section": "5 VERIFICATION OF DATA COLLECTION STRATEGY"}, {"figure_path": "2410.18647/tables/table_10_0.html", "caption": "Table 2: Model related experiments on Pour Water. The entries marked in gray are the same, which specify the default settings: the visual encoder is a fully fine-tuned ViT-L/14 model pre-trained with DINOv2, while the action diffusion model employs a base-size 1D CNN U-Net.", "description": "Table 2 shows the results of experiments conducted to investigate the impact of training strategies and model size on the performance of a diffusion policy for the Pour Water task.", "section": "6 MODEL SIZE AND TRAINING STRATEGY: BEYOND DATA SCALING"}, {"figure_path": "2410.18647/tables/table_10_1.html", "caption": "Table 2: Model related experiments on Pour Water. The entries marked in gray are the same, which specify the default settings: the visual encoder is a fully fine-tuned ViT-L/14 model pre-trained with DINOv2, while the action diffusion model employs a base-size 1D CNN U-Net.", "description": "The table shows the results of model-related experiments on Pour Water, comparing different visual encoder sizes and training strategies, and the effect of scaling the action diffusion model.", "section": "6 MODEL SIZE AND TRAINING STRATEGY: BEYOND DATA SCALING"}, {"figure_path": "2410.18647/tables/table_23_0.html", "caption": "Table 3: A default set of hyper-parameters.", "description": "Table 3 shows the default set of hyperparameters used in the policy training process, including image observation horizon, action horizon, optimizer, and learning rate.", "section": "C POLICY TRAINING"}, {"figure_path": "2410.18647/tables/table_32_1.html", "caption": "Table 5: Environment generalization on Pour Water. Normalizing these scores by dividing them by 9 yields the results shown in Fig. 3.", "description": "Table 5 shows the results of an experiment on Pour Water, measuring the effect of increasing the number of training environments on the policy's generalization ability while controlling for the number of training objects and demonstrating the power-law relationship of the data.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/tables/table_32_3.html", "caption": "Table 7: Number of demonstrations on Pour Water. Normalizing these scores by dividing them by 9 yields the results shown in Fig. 7.", "description": "Table 7 shows the relationship between the number of demonstrations and the normalized score for the Pour Water task, after normalizing the raw scores by dividing them by 9.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_0.html", "caption": "Table 8: Object generalization on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 2.", "description": "The table shows the raw test scores of object generalization on Mouse Arrangement before normalization, where scores are shown for different fractions of demonstrations used and numbers of training objects.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_1.html", "caption": "Table 9: Environment generalization on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 3.", "description": "The table shows the raw test scores of environment generalization on Mouse Arrangement before normalization.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_2.html", "caption": "Table 10: Generlization across environments and objects on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 4.", "description": "The table presents the raw success scores for the Mouse Arrangement task before normalization, categorized by the number of training environment-object pairs and the fraction of demonstrations used.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_3.html", "caption": "Table 11: Number of demonstrations on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 7.", "description": "Table 11 presents the normalized scores for the Mouse Arrangement task based on varying numbers of demonstrations, used to generate Figure 7 in the paper.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_34_0.html", "caption": "Table 12: Success rate across all tasks. For each task, we report the success rate in each evaluation environment.", "description": "This table presents the success rates of the policies trained across 32 environment-object pairs for each task, showing the success rate in each of eight evaluation environments.", "section": "5 Verification of Data Collection Strategy"}]