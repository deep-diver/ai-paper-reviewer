[{"figure_path": "2410.18647/tables/table_9_0.html", "caption": "Table 1: Success rate across all tasks. We report the average success rate and standard deviation across 8 unseen environments. The performance in each environment is detailed in Table 12.", "description": "This table summarizes the success rate and standard deviation of the trained policies across four different manipulation tasks in eight unseen environments.", "section": "5 VERIFICATION OF DATA COLLECTION STRATEGY"}, {"figure_path": "2410.18647/tables/table_10_0.html", "caption": "Table 2: Model related experiments on Pour Water. The entries marked in gray are the same, which specify the default settings: the visual encoder is a fully fine-tuned ViT-L/14 model pre-trained with DINOv2, while the action diffusion model employs a base-size 1D CNN U-Net.", "description": "The table shows the results of model-related experiments on the Pour Water task, comparing different training strategies, visual encoder sizes, and action diffusion model sizes.", "section": "6 MODEL SIZE AND TRAINING STRATEGY: BEYOND DATA SCALING"}, {"figure_path": "2410.18647/tables/table_10_1.html", "caption": "Table 2: Model related experiments on Pour Water. The entries marked in gray are the same, which specify the default settings: the visual encoder is a fully fine-tuned ViT-L/14 model pre-trained with DINOv2, while the action diffusion model employs a base-size 1D CNN U-Net.", "description": "The table presents the results of experiments on the Pour Water task, comparing the performance of different model sizes and training strategies for the visual encoder and action diffusion model.", "section": "6 MODEL SIZE AND TRAINING STRATEGY: BEYOND DATA SCALING"}, {"figure_path": "2410.18647/tables/table_23_0.html", "caption": "Table 3: A default set of hyper-parameters.", "description": "This table lists the default hyperparameters used in the policy training process, specifying values for image observation horizon, proprioception observation horizon, action horizon, observation resolution, environment frequency, optimizer, optimizer momentum, learning rate for action diffusion model, learning rate for visual encoder, learning rate schedule, batch size, inference denoising iterations, temporal ensemble steps, and temporal ensemble adaptation rate.", "section": "C POLICY TRAINING"}, {"figure_path": "2410.18647/tables/table_32_1.html", "caption": "Table 5: Environment generalization on Pour Water. Normalizing these scores by dividing them by 9 yields the results shown in Fig. 3.", "description": "Table 5 shows the results of the environment generalization experiment on the Pour Water task, presenting the normalized scores as a function of the number of training environments and the fraction of demonstrations used.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/tables/table_32_3.html", "caption": "Table 7: Number of demonstrations on Pour Water. Normalizing these scores by dividing them by 9 yields the results shown in Fig. 7.", "description": "The table shows the raw test scores before normalization for the Pour Water task, varying the number of demonstrations used for training.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_1.html", "caption": "Table 9: Environment generalization on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 3.", "description": "Table 9 shows the results of the environment generalization experiment on the Mouse Arrangement task, where the normalized scores are obtained by dividing the raw scores by 6.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_2.html", "caption": "Table 6: Generlization across environments and objects on Pour Water. Normalizing these scores by dividing them by 9 yields the results shown in Fig. 4.", "description": "Table 6 presents the normalized scores for Pour Water experiments evaluating generalization across both environments and objects, showing the impact of different fractions of demonstrations.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_33_3.html", "caption": "Table 11: Number of demonstrations on Mouse Arrangement. Normalizing these scores by dividing them by 6 yields the results shown in Fig. 7.", "description": "Table 11 shows the normalized scores for the Mouse Arrangement task based on varying numbers of demonstrations.", "section": "G.3 RAW TEST SCORES"}, {"figure_path": "2410.18647/tables/table_34_0.html", "caption": "Table 12: Success rate across all tasks. For each task, we report the success rate in each evaluation environment.", "description": "This table presents the success rates of the policies trained across 32 environment-object pairs for four different manipulation tasks, showing the performance in each of eight unseen evaluation environments.", "section": "5 VERIFICATION OF DATA COLLECTION STRATEGY"}]