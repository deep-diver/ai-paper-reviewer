[{"figure_path": "2410.16198/tables/table_3_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning experiments comparing different combinations of training data (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) on the performance of vision language models in both direct prediction and chain-of-thought prediction tasks.", "section": "SFT experiments for chain-of-thought learning"}, {"figure_path": "2410.16198/tables/table_5_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the performance of different models trained with varying combinations of direct and chain-of-thought (CoT) response data, demonstrating that combining both improves performance on both direct and CoT prediction tasks.", "section": "SFT experiments for chain-of-thought learning"}, {"figure_path": "2410.16198/tables/table_6_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on different combinations of training data (format alignment, direct responses, and chain-of-thought responses), showing the best performance is achieved when combining both direct and chain-of-thought data.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_6_1.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning experiments comparing different data compositions (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) on various tasks and prompting methods (direct and CoT).", "section": "SFT Experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_7_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments using different combinations of data (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and shows that combining CoT and direct responses leads to the best performance.", "section": "4 SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_8_0.html", "caption": "Table 6: DPO experiment with LLAVA-Reasoner-SFT as the base policy model. We compare two DPO datasets: \u2464 RLAIF-V Yu et al. (2024) and \u2465 our preference dataset comprising A-OKVQA, ChartQA, and math. The best CoT prediction is highlighted in orange. Our DPO dataset shows the better improvements in chain-of-thought reasoning.", "description": "The table compares the performance of different prompting methods (direct and CoT) on various vision-language tasks using different DPO datasets (RLAIF-V and a custom dataset).", "section": "5 RL EXPERIMENTS FOR ENHANCED CHAIN-OF-THOUGHT REASONING"}, {"figure_path": "2410.16198/tables/table_17_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments on various datasets using different combinations of direct and chain-of-thought (CoT) training data.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_18_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments with different data compositions (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and shows that combining CoT and direct responses yields the best performance.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_19_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on four different data compositions, comparing the performance of direct and chain-of-thought prediction using various prompting methods.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_21_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on various data compositions, comparing the performance of direct and chain-of-thought prediction on several vision-language reasoning tasks.", "section": "SFT experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_22_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments on four different data compositions, comparing the performance of direct and chain-of-thought (CoT) prediction on various tasks.", "section": "SFT Experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_24_0.html", "caption": "Table C.1: Evaluation of VLM performance on benchmark datasets with direct and CoT inference.", "description": "The table presents the baseline performance of LLAVA-NEXT-8B and LLAVA-NEXT-FORMAT models on various benchmark datasets using direct and chain-of-thought (CoT) inference methods.", "section": "C BASELINE EVALUATION"}, {"figure_path": "2410.16198/tables/table_28_0.html", "caption": "Table D.1: We study a self-taught reasoner with minimal CoT data (only 450 format-aligned examples). LLAVA-NEXT-DIRECT is used as the baseline, and our LLaVA-Next-STaR is trained with a rejection sampling method. The best CoT predictions are highlighted in orange, and the best direct predictions are highlighted in blue. Our rejection sampling method outperforms both CoT and direct prediction, with the exception of two data points.", "description": "This table presents a comparison of the performance of different models on various visual question answering tasks using both direct and chain-of-thought prediction methods, highlighting the effectiveness of a self-taught reasoning approach with minimal chain-of-thought data.", "section": "D NEARLY ZERO DATA LEARNING FOR COT REASONING"}, {"figure_path": "2410.16198/tables/table_30_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments on different combinations of training data (format alignment, direct responses, and CoT responses) and their impact on both direct and chain-of-thought (CoT) prediction performance.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_30_1.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table shows the performance of four different supervised fine-tuning (SFT) models on various vision-language reasoning tasks, trained with different combinations of direct and chain-of-thought (CoT) data.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}]