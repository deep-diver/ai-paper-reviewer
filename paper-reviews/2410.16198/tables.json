[{"figure_path": "2410.16198/tables/table_3_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments on various vision-language models with different data compositions, comparing the performance of direct prediction and chain-of-thought (CoT) reasoning.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_5_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments on vision language models, comparing different data compositions and prompting strategies for both direct and chain-of-thought prediction.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_6_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on four different data compositions, comparing the performance of direct and chain-of-thought prediction across various vision-language reasoning tasks.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_6_1.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table shows the results of supervised fine-tuning experiments on vision language models using different combinations of training data (format-aligned, direct, and chain-of-thought), comparing their performance on direct prediction and chain-of-thought prediction tasks.", "section": "SFT Experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_7_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments on vision language models (VLMs) using different combinations of direct and chain-of-thought (CoT) reasoning data, showing that combining both data types leads to the best performance.", "section": "SFT experiments for chain-of-thought learning"}, {"figure_path": "2410.16198/tables/table_8_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on four different data compositions, comparing the performance of direct and chain-of-thought prediction on various vision-language reasoning tasks.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_17_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on various vision-language models, comparing different data compositions (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and their impact on model performance across both direct prediction and chain-of-thought prompting.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_18_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning experiments on various vision-language models with different data compositions, showing that combining both direct and chain-of-thought data leads to improved performance on both prompt types.", "section": "SFT Experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_19_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments with different combinations of data (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and prompting methods (direct and CoT) on various vision-language reasoning tasks, showing that combining direct and CoT responses during training improves performance.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_20_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments on four different data compositions, comparing the performance of direct and chain-of-thought (CoT) prediction across various reasoning tasks.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_21_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments comparing different data compositions (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) on the performance of vision language models in both direct and chain-of-thought prediction.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_22_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "The table presents the results of supervised fine-tuning (SFT) experiments on various vision-language models with different data compositions (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and prompting methods (direct and chain-of-thought), showing that combining both direct and CoT data leads to the best performance.", "section": "SFT Experiments for Chain-of-Thought Learning"}, {"figure_path": "2410.16198/tables/table_24_0.html", "caption": "Table C.1: Evaluation of VLM performance on benchmark datasets with direct and CoT inference.", "description": "The table presents the baseline performance of LLAVA-NEXT-8B and LLAVA-NEXT-FORMAT models on various benchmark datasets using direct and chain-of-thought (CoT) inference methods.", "section": "C BASELINE EVALUATION"}, {"figure_path": "2410.16198/tables/table_28_0.html", "caption": "Table D.1: We study a self-taught reasoner with minimal CoT data (only 450 format-aligned examples). LLAVA-NEXT-DIRECT is used as the baseline, and our LLaVA-Next-STaR is trained with a rejection sampling method. The best CoT predictions are highlighted in orange, and the best direct predictions are highlighted in blue. Our rejection sampling method outperforms both CoT and direct prediction, with the exception of two data points.", "description": "This table presents the results of experiments comparing the performance of a self-taught reasoner trained with minimal chain-of-thought (CoT) data against a baseline model on various benchmark datasets, highlighting the superior performance of the self-taught reasoner.", "section": "D NEARLY ZERO DATA LEARNING FOR COT REASONING"}, {"figure_path": "2410.16198/tables/table_30_0.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments using different combinations of data (format alignment only, direct responses only, CoT responses only, and both direct and CoT responses) and demonstrates that combining CoT and direct responses during training yields the best performance.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}, {"figure_path": "2410.16198/tables/table_30_1.html", "caption": "Table 2: SFT experiments with data composition in fig. 5: \u2460 format alignment only, \u2461 direct responses only, \u2462 CoT responses only and \u2463 both direct and CoT responses. Inference is performed using both direct and CoT templates. The best CoT prediction result is highlighted in orange, while the best direct prediction result is marked in blue. The results demonstrate that combining CoT and direct responses during training leads to the best performance across both types of prompts. Refer to section 4 for detailed analysis.", "description": "This table presents the results of supervised fine-tuning (SFT) experiments on vision language models using different combinations of direct and chain-of-thought (CoT) reasoning data, showing that combining both data types leads to the best performance.", "section": "SFT EXPERIMENTS FOR CHAIN-OF-THOUGHT LEARNING"}]