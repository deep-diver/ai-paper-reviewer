{"references": [{" publication_date": "2024", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A frontier large vision-language model with versatile abilities", "reason": "This paper is highly relevant because it introduces Qwen-VL, a state-of-the-art vision-language model that exhibits versatile abilities and could serve as a strong baseline or comparison point for evaluating the performance of the proposed model in the paper.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "\u0141ukasz Borchmann", "paper_title": "Notes on applicability of gpt-4 to document understanding", "reason": "This paper explores GPT-4's capabilities in document understanding, which is directly relevant to the task of generating detailed rationales for vision-language tasks, as proposed in this work. The insights from this study on prompt optimization and GPT-4's strengths and weaknesses could inform the design of the GPT-4 prompts used for data distillation.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Jun Chen", "paper_title": "Minigpt-v2: large language model as a unified interface for vision-language multi-task learning", "reason": "This paper is significant because it proposes MiniGPT-V2, a large language model used as a unified interface for vision-language multi-task learning, a concept that relates to the use of GPT-40 in the proposed method for generating CoT reasoning. Studying MiniGPT-V2's architecture and training methods can provide valuable insights for improving the current VLM chain-of-thought performance.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Lin Chen", "paper_title": "Are we on the right way for evaluating large vision-language models?", "reason": "This paper critically examines existing benchmarks for evaluating large vision-language models, a topic highly relevant to the evaluation methodology in this work. The findings on how to effectively assess the reasoning capabilities of VLMs are crucial for comparing the proposed method's performance against state-of-the-art models.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Zhe Chen", "paper_title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "reason": "InternVL is a scaled-up vision foundation model that demonstrates strong performance across various visual-linguistic tasks.  This is highly relevant as it provides a strong baseline for comparing the capabilities of the proposed model and can inform the design of training approaches for improving VLM performance on similar tasks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yihe Deng", "paper_title": "Enhancing large vision language models with self-training on image comprehension", "reason": "This paper focuses on enhancing large vision-language models through self-training, which is relevant to the SFT step in the proposed method.  Understanding techniques for self-training and their impact on model performance can help to evaluate and improve the proposed model's efficiency and effectiveness.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Haodong Duan", "paper_title": "Vlmevalkit: An open-source toolkit for evaluating large multi-modality models", "reason": "This paper introduces Vlmevalkit, an open-source toolkit for evaluating large multi-modality models. This is crucial for this work as it provides a standardized and comprehensive evaluation framework to ensure a fair and robust comparison of the proposed model with other existing methods.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "reason": "This paper introduces the LLaMA 3 family of models, providing relevant context for the choice of base architecture (LLaMA3-LLaVA-NeXT-8B) in the proposed method. Understanding the strengths and weaknesses of LLaMA 3 models helps in selecting an appropriate baseline for comparisons and in designing effective fine-tuning strategies.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jiahui Gao", "paper_title": "G-llava: Solving geometric problem with multi-modal large language model", "reason": "This paper is highly relevant because it introduces G-LLaVA, a multi-modal large language model that solves geometric problems, providing a strong baseline and potential comparison model for evaluating the effectiveness of the proposed model in solving similar visual reasoning tasks.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Anisha Gunjal", "paper_title": "Detecting and preventing hallucinations in large vision language models", "reason": "This paper directly addresses the issue of hallucinations in large vision-language models, a problem the authors aim to mitigate in their work through techniques like DPO.  Understanding methods for detecting and preventing hallucinations is crucial for evaluating the robustness and reliability of the proposed model.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Arian Hosseini", "paper_title": "V-star: Training verifiers for self-taught reasoners", "reason": "This paper introduces V-Star, a method for training verifiers for self-taught reasoners, which is highly relevant to the DPO component of the proposed method. The insights from this study on verifier training and evaluation are crucial for designing effective DPO strategies and assessing the effectiveness of the proposed method.", "section_number": 5}, {" publication_date": "2016", "fullname_first_author": "Aniruddha Kembhavi", "paper_title": "A diagram is worth a dozen images", "reason": "This paper is relevant because it introduces the concept of using diagrams for visual question answering (VQA), which is relevant to the dataset and tasks used in the research.  The insights from this study on how diagrams enhance VQA can inform the design of the CoT data distillation process and prompt design for the GPT-40 model.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Bo Li", "paper_title": "Llava-onevision: Easy visual task transfer", "reason": "This paper explores visual task transfer in the context of LLAVAs, which is relevant to the broader objective of improving the reasoning capabilities of VLMs.  Understanding techniques for visual task transfer can potentially inform strategies for improving CoT reasoning in VLMs.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Lei Li", "paper_title": "Silkie: Preference distillation for large visual language models", "reason": "This paper is highly relevant as it proposes Silkie, a method for preference distillation in large visual language models, which is closely related to the use of DPO in this work.  Studying Silkie's approach to preference modeling can provide valuable insights for designing and improving the DPO component of the proposed method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "reason": "This paper focuses on improving baselines using visual instruction tuning, a concept that is relevant to the supervised fine-tuning (SFT) used in the proposed method. The insights gained from this study can help to optimize the SFT process and improve the model's performance on CoT reasoning tasks.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "reason": "This paper explores visual instruction tuning, which is highly relevant to the SFT step in the proposed method.  Understanding the effectiveness of visual instruction tuning in improving VLM performance is crucial for evaluating and improving the proposed model's performance on CoT reasoning tasks.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Yuliang Liu", "paper_title": "On the hidden mystery of ocr in large multimodal models", "reason": "This paper investigates the role of OCR in large multimodal models, a topic relevant to the datasets used in this work, many of which involve visual information extraction. Understanding how OCR impacts model performance is crucial for accurately interpreting the results and designing effective training strategies.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Pan Lu", "paper_title": "Learn to explain: Multimodal reasoning via thought chains for science question answering", "reason": "This paper introduces the concept of using 'thought chains' for multimodal reasoning, which is highly relevant to the core concept of chain-of-thought (CoT) reasoning in this work. The techniques and findings from this study can directly inform the design of the CoT data distillation process and prompt engineering in this research.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Pan Lu", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts", "reason": "This paper is highly relevant as it introduces MathVista, a benchmark for evaluating mathematical reasoning capabilities in visual contexts.  This is crucial for this work because MathVista serves as one of the benchmark datasets used for evaluating the proposed method's performance on mathematical reasoning tasks. Understanding MathVista's design and evaluation metrics can inform the design and analysis of the experiments.", "section_number": 4}]}