[{"figure_path": "2410.22304/tables/table_4_0.html", "caption": "Table 1: Main results of comparing the quality of traces used for SFT. We report the accuracy (%) for each model fine-tuned on an identical set of prompts, but with varying answer sources. For Phi-3, we does not include GSM8K due to its already optimized performance on the dataset.", "description": "Table 1 compares the accuracy of three different fine-tuning methods (ground-truth, self-generated, and Flow-generated traces) on two datasets (GSM8K and MATH) for two different LLMs.", "section": "3.3 Compile"}, {"figure_path": "2410.22304/tables/table_9_0.html", "caption": "Table 2: Online DPO Fine-tuning hyperparameters.", "description": "Table 2 presents the hyperparameters used for online direct preference optimization (DPO) fine-tuning in the Flow-DPO model.", "section": "A.2 Hyperparameters"}, {"figure_path": "2410.22304/tables/table_9_1.html", "caption": "Table 3: Comiple (SFT) hyperparameters.", "description": "Table 3 presents the hyperparameters used in the Compile (SFT) step of the proposed method.", "section": "3.3 Compile"}]