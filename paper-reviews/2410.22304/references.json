{"references": [{" publication_date": "2021", "fullname_first_author": "Cobbe K.", "paper_title": "Training verifiers to solve math word problems", "reason": "This paper introduces the MATH dataset, a benchmark specifically designed for evaluating mathematical reasoning capabilities in large language models.  It is a crucial dataset used in many subsequent studies, including this one,  making it foundational to the field of LLM mathematical reasoning research.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Hendrycks D.", "paper_title": "Measuring mathematical problem solving with the math dataset", "reason": "This work is highly influential as it provides a comprehensive benchmark (MATH) for evaluating mathematical problem-solving skills in machine learning models. Its impact is evident in the extensive use of the MATH dataset for evaluating mathematical reasoning capabilities in numerous research papers, including this one.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Hosseini A.", "paper_title": "V-star: Training verifiers for self-taught reasoners", "reason": "This paper explores the concept of training verifier models to improve the quality of LLM-generated reasoning traces.  It introduces a novel approach for self-improvement of LLMs in mathematical reasoning, contributing to the overall advancement of methods that focus on LLM self-improvement.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Lightman H.", "paper_title": "Let's verify step by step", "reason": "This paper is highly relevant as it tackles the problem of generating high-quality reasoning traces through a step-by-step verification process. This approach directly addresses the challenges mentioned in the introduction regarding the conciseness and disorganization of human-generated reasoning steps, proposing a method to generate more detailed and accurate reasoning traces.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Yu L.", "paper_title": "Metamath: Bootstrap your own mathematical questions for large language models", "reason": "This paper is significant for introducing the MetaMath dataset, which serves as the primary training dataset in the current work. The MetaMath dataset is a carefully curated and augmented version of other established datasets, making it a valuable resource for training LLMs in mathematical reasoning tasks.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Yuan Z.", "paper_title": "Scaling relationship on learning mathematical reasoning with large language models", "reason": "This work is important as it investigates the scaling relationships in training LLMs for mathematical reasoning. The findings presented in this paper provide valuable insights into the effectiveness of different training strategies and dataset sizes.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Lai X.", "paper_title": "Step-dpo: Step-wise preference optimization for long-chain reasoning of llms", "reason": "This paper explores the application of step-wise DPO for improving the performance of LLMs on long-chain reasoning tasks. The approach is similar to this paper's method in using incremental steps for feedback, but is distinct in the use of DPO for training the model iteratively.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Pang R.", "paper_title": "Iterative reasoning preference optimization", "reason": "This paper introduces a novel iterative reasoning preference optimization approach, which aligns with the incremental nature of the proposed Flow method in the paper.  The idea of iterative refinement of reasoning traces is central to both approaches.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Rafailov R.", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "reason": "This paper is important due to its introduction of Direct Preference Optimization (DPO), which is the core training method employed in this paper's proposed Flow.  DPO is shown to be an effective method for training LLMs on complex reasoning tasks, which aligns perfectly with the focus of this study.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Singh A.", "paper_title": "Beyond human data: Scaling self-training for problem-solving with language models", "reason": "This paper investigates the use of self-training for improving the capabilities of LLMs in problem-solving tasks. The results of this paper are particularly relevant to this study, as both papers use similar training strategies and explore the challenges of generating high-quality training data.", "section_number": 1}, {" publication_date": "2024a", "fullname_first_author": "Wang P.", "paper_title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations", "reason": "This work presents an approach to verify and reinforce LLM's step-by-step reasoning without human annotation.  The focus on step-by-step verification aligns with the incremental output production flow approach proposed in the paper.", "section_number": 1}, {" publication_date": "2024b", "fullname_first_author": "Wang Z.", "paper_title": "Multi-step problem solving through a verifier: An empirical analysis on model-induced process supervision", "reason": "This study investigates the use of verifiers for multi-step problem-solving and empirically analyzes model-induced process supervision.  The findings provide useful insights on leveraging process-oriented feedback during LLM training, closely aligning with the approach taken in this paper.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Gao B.", "paper_title": "Omni-math: A universal olympiad level mathematic benchmark for large language models", "reason": "This paper introduces a new benchmark for evaluating LLMs in mathematical reasoning, which is relevant because it highlights the ongoing need for robust and challenging evaluation datasets in the field.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Liu H.", "paper_title": "Mathbench: Evaluating the theory and application proficiency of llms with a hierarchical mathematics benchmark", "reason": "This paper introduces Mathbench, a benchmark for evaluating the theoretical understanding and application proficiency of LLMs.  The hierarchical structure of the benchmark makes it relevant to this paper's exploration of step-by-step reasoning.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Lu P.", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts", "reason": "This paper focuses on evaluating mathematical reasoning in visual contexts, which is a related but distinct area of research.  The methods and evaluation metrics explored in this paper offer valuable insights into evaluating reasoning capabilities.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Zelikman E.", "paper_title": "Quiet-star: Language models can teach themselves to think before speaking", "reason": "This study presents Quiet-Star, a method for teaching language models to think before speaking.  While focusing on a different aspect of language modeling, the method's focus on iterative refinement and self-improvement is relevant to the current paper's approach.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Zelikman E.", "paper_title": "Star: Self-taught reasoner", "reason": "This paper introduces Star, an early approach to self-taught reasoning in LLMs.  While not directly employing the same methods, its contribution to the field of self-improving LLMs makes it an important antecedent to the current study.", "section_number": 1}, {" publication_date": "2024a", "fullname_first_author": "Zhang D.", "paper_title": "Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning", "reason": "This paper explores pairwise optimization techniques for improving LLM performance on mathematical reasoning. This method shares a similar spirit to the DPO used in this work, but explores a different approach to leveraging pairwise comparisons for training.", "section_number": 1}, {" publication_date": "2024c", "fullname_first_author": "Zhang R.", "paper_title": "Mathverse: Does your multi-modal llm truly see the diagrams in visual math problems?", "reason": "This work investigates the performance of multi-modal LLMs on visual mathematical problems. Although focusing on a different modality, the evaluation metrics and challenges addressed in this paper are relevant to this paper's evaluation of LLM performance on mathematical reasoning.", "section_number": 1}]}