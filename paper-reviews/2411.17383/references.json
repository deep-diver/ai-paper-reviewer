{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper is foundational to the video diffusion models used in AnchorCrafter."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-22", "reason": "This paper introduces a significant advancement in video diffusion models, directly relevant to AnchorCrafter's architecture."}, {"fullname_first_author": "Li Hu", "paper_title": "Animate anyone: Consistent and controllable image-to-video synthesis for character animation", "publication_date": "2024-06-01", "reason": "This paper proposes a method for image-to-video generation that is directly compared against in the AnchorCrafter results."}, {"fullname_first_author": "Ziyao Huang", "paper_title": "Make-your-anchor: A diffusion-based 2d avatar generation framework", "publication_date": "2024-06-01", "reason": "This paper is closely related to AnchorCrafter, offering insights into personalized anchor-style video generation techniques."}, {"fullname_first_author": "Binghui Chen", "paper_title": "VirtualModel: Generating object-id-retentive human-object interaction image by diffusion model for e-commerce marketing", "publication_date": "2024-05-01", "reason": "This paper tackles the challenge of human-object interaction image generation, a problem directly addressed by AnchorCrafter."}]}