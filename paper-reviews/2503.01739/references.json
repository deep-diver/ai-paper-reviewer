{"references": [{"fullname_first_author": "Wenhao Wang", "paper_title": "Vidprom: A million-scale real prompt-gallery dataset for text-to-video diffusion models.", "publication_date": "2024-01-01", "reason": "This paper is very important because it introduced the VidProM dataset, which is used to analyze user focus and preferences, and for selecting prompts in this study."}, {"fullname_first_author": "Hongwei Xue", "paper_title": "Advancing high-resolution video-language representation with large-scale video transcriptions.", "publication_date": "2022-01-01", "reason": "This paper is very important because this is where HD-VILA-100M was first introduced, a dataset that several other video datasets (including Panda-70M, LVD-2M, Koala-36M, VidGen-1M, and OpenVid-1M) are derived from."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70m: Captioning 70m videos with multiple cross-modality teachers.", "publication_date": "2024-01-01", "reason": "This paper is important because it contains similar data processing steps that are followed in this paper, such as shot boundary detection, stitching, and video splitting."}, {"fullname_first_author": "Max Bain", "paper_title": "Frozen in time: A joint video and image encoder for end-to-end retrieval.", "publication_date": "2021-01-01", "reason": "This paper provides a joint video and image encoder, which is used in this work to search for relevant topics in video."}, {"fullname_first_author": "Kepan Nan", "paper_title": "Openvid-1m: A large-scale high-quality dataset for text-to-video generation.", "publication_date": "2025-01-01", "reason": "This paper contains data processing steps that are followed in this paper, and the OpenVid-1M dataset is one of the datasets compared to the new dataset."}]}