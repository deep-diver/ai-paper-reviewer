[{"figure_path": "2410.16048/figures/figures_2_0.png", "caption": "Figure 1: Continuous vs. discrete modeling", "description": "The figure illustrates the difference between continuous and discrete speech modeling approaches, showing how continuous latent variables are processed using a diffusion head versus discrete RVQ codes processed using RVQ prediction heads.", "section": "3 METHOD"}, {"figure_path": "2410.16048/figures/figures_4_0.png", "caption": "Figure 2: The per-token diffusion head", "description": "The figure illustrates the per-token diffusion head architecture used in the SALAD model, showing both the training and inference processes.", "section": "3. \u041c\u0415\u0422\u041dOD"}, {"figure_path": "2410.16048/figures/figures_5_0.png", "caption": "Figure 3: Synthesis using Semantic-to-Acoustic models", "description": "The figure illustrates the process of speech synthesis using semantic-to-acoustic models, showing the flow of information from text and speaker prompt to the final synthesized audio.", "section": "3.2 SALAD: SPEECH SYNTHESIS USING AUTOREGRESSIVE LATENT DIFFUSION"}]