{"references": [{" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This paper introduced the Transformer architecture, a fundamental building block for many modern sequence-to-sequence models, including the autoregressive models discussed in the paper.  Its impact on the field of natural language processing and its subsequent adoption in other areas like speech synthesis make it a highly influential work.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper demonstrated the remarkable ability of large language models to perform various tasks without explicit supervision, significantly impacting the development of autoregressive models and influencing approaches to zero-shot learning in speech synthesis.", "section_number": 1}, {" publication_date": "2017", "fullname_first_author": "Aaron Van Den Oord", "paper_title": "Neural discrete representation learning", "reason": "This work is foundational to the use of Vector Quantized Variational Autoencoders (VQ-VAEs) in representing continuous data such as audio and images with discrete codes which is directly relevant to the paper's discussion on the tradeoffs between discrete and continuous representations for audio.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "reason": "This paper presents advancements in using transformer networks for high-resolution image generation, relevant to the paper's discussion on applying similar techniques (diffusion models) to speech synthesis which is a continuous modality similar to images.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Neil Zeghidour", "paper_title": "SoundStream: An end-to-end neural audio codec", "reason": "This paper introduced SoundStream, a significant advancement in neural audio codecs that uses residual vector quantization (RVQ).  The paper heavily discusses RVQ which is directly related to the model proposed in the paper and therefore makes this paper highly relevant to the content.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Michael Tschannen", "paper_title": "GIVT: Generative infinite-vocabulary transformers", "reason": "This paper proposed GIVT which models the continuous distribution using a Gaussian Mixture Model. This is directly relevant to the paper since the authors mention that GIVT is used to generate multimodal distributions compared to simple regression models.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Tianhong Li", "paper_title": "Autoregressive image generation without vector quantization", "reason": "This work is highly relevant because it proposes a per-token diffusion head for image generation. The present paper extends this concept to speech synthesis, making this prior work foundational to their novel approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Zal\u00e1n Borsos", "paper_title": "Soundstorm: Efficient parallel audio generation", "reason": "This paper introduced SoundStorm, a method for audio generation using semantic tokens and a MaskGIT approach. Since SALAD uses semantic tokens and compares its performance to SoundStorm, this prior work is crucial for understanding the context and novelty of SALAD.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Eugene Kharitonov", "paper_title": "Speak, read and prompt: High-fidelity text-to-speech with minimal supervision", "reason": "This paper focuses on high-fidelity text-to-speech synthesis using semantic tokens. SALAD also leverages semantic tokens, making this prior work highly relevant in understanding the background and contribution of SALAD.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Rongjie Huang", "paper_title": "Make-a-voice: Unified voice synthesis with discrete representation", "reason": "This paper presents Make-a-Voice, a method for voice synthesis using a discrete representation. It provides a relevant comparison point to SALAD's continuous approach in understanding how discrete vs. continuous representations impact the quality and efficiency of the model.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Huiwen Chang", "paper_title": "MaskGIT: Masked generative image transformer", "reason": "This paper introduced MaskGIT, a non-autoregressive method that is used in SALAD's S2A-NAR approach. Understanding MaskGIT is critical to understanding this specific variant of SALAD, thereby making this paper essential to the paper.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This foundational work introduced diffusion models as a way to generate samples from complex probability distributions. This makes it an essential reference because diffusion models are central to the design and functioning of the proposed SALAD model.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Lingwei Meng", "paper_title": "Autoregressive speech synthesis without vector quantization", "reason": "This work is closely related to SALAD because it presents a model for speech synthesis that doesn't utilize vector quantization. Understanding this alternative continuous approach provides more context and a comparison point to SALAD\u2019s methodology and results.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Matthew Le", "paper_title": "Voicebox: Text-guided multilingual universal speech generation at scale", "reason": "Voicebox is a state-of-the-art zero-shot speech synthesis model which uses a significant amount of data for training which is also the case for SALAD.  Comparing SALAD to Voicebox would greatly benefit the work.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "reason": "This paper introduces a robust speech recognition model that serves as a benchmark for the intelligibility metric (CER) used to evaluate SALAD in the experiments. The evaluation of SALAD relies heavily on this paper making it critically important.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Takaaki Saeki", "paper_title": "Utmos: Utokyo-sarulab system for voicemos challenge 2022", "reason": "This paper introduced UTMOS, a metric used to evaluate the audio quality of the synthesized speech in SALAD. The quality score is a crucial metric used to evaluate the success of the model making this paper highly important.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Sanyuan Chen", "paper_title": "Wavlm: Large-scale self-supervised pre-training for full stack speech processing", "reason": "This paper presents WavLM, which is used to generate speaker embeddings in the speaker similarity metric. This makes the paper important for understanding the specific metric used in the paper and is thus important to the work.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Rithesh Kumar", "paper_title": "High-fidelity audio compression with improved rvqgan", "reason": "This paper delves into high-fidelity audio compression using RVQGAN, which is relevant to SALAD's exploration of high-fidelity continuous representations.  The paper further explores high-fidelity models which is what the authors look to do, making this paper important.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Michael Tschannen", "paper_title": "GIVT: Generative infinite-vocabulary transformers", "reason": "This paper proposed GIVT which is used as an alternative approach for continuous audio generation. The authors also compare GIVT models to their own model in the additional results section.", "section_number": 5}, {" publication_date": "2020", "fullname_first_author": "Vineel Pratap", "paper_title": "Mls: A large-scale multilingual dataset for speech research", "reason": "This paper introduced the Multi-lingual LibriSpeech (MLS) dataset, which is used to train the models in the paper.  A good understanding of the data used to train the models is critical to understanding the paper, and this is a description of that data.", "section_number": 4}]}