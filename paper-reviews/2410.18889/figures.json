[{"figure_path": "2410.18889/figures/figures_2_0.png", "caption": "Figure 1: An illustration of our approach for detecting and addressing mislabeled data: (1) Re-label examples from existing datasets using an ensemble of LLMs. (2) Identify strong disagreements between the LLM's predictions and the original labels (i.e., high confidence in a different label), flagging examples based on confidence levels. Our findings show that LLMs detect between 6% and 21% of label errors, and higher LLM confidence is strongly associated with improved precision in error detection. (3) In the training set, we either filter or flip flagged examples to improve model performance, leading to an increase of up to 4%. For the test set, flagged examples are re-annotated by experts to make sure the evaluation is accurate. We found that under accurate evaluation, the performance of LLMs is up to 15% higher than the original mislabeled data.", "description": "The figure illustrates a method for detecting and handling mislabeled data in datasets using LLMs as judges, improving model performance and evaluation accuracy.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18889/figures/figures_23_0.png", "caption": "Figure 1: An illustration of our approach for detecting and addressing mislabeled data: (1) Re-label examples from existing datasets using an ensemble of LLMs. (2) Identify strong disagreements between the LLM's predictions and the original labels (i.e., high confidence in a different label), flagging examples based on confidence levels. Our findings show that LLMs detect between 6% and 21% of label errors, and higher LLM confidence is strongly associated with improved precision in error detection. (3) In the training set, we either filter or flip flagged examples to improve model performance, leading to an increase of up to 4%. For the test set, flagged examples are re-annotated by experts to make sure the evaluation is accurate. We found that under accurate evaluation, the performance of LLMs is up to 15% higher than the original mislabeled data.", "description": "The figure illustrates the process of detecting and handling mislabeled data using an ensemble of LLMs, showing how flagged examples are either filtered or flipped in the training set, and re-annotated by experts in the test set to improve model performance and evaluation accuracy.", "section": "1 INTRODUCTION"}]