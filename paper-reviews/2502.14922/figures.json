[{"figure_path": "https://arxiv.org/html/2502.14922/x1.png", "caption": "Figure 1: Applying SIFT to DeepSeek-R1 demonstrates highly competitive reasoning performance on AIME2024, AIME2025, and MATH-500 (pass@1 accuracy). The results for o1-mini and o3-mini on AIME are referenced from Ye et\u00a0al. (2025).", "description": "This figure showcases the effectiveness of the Stick to the Facts (SIFT) method when applied to the DeepSeek-R1 large language model.  The bar chart presents the pass@1 accuracy (meaning the model correctly answered the question on the first try) across three different reasoning benchmarks: AIME2024, AIME2025, and MATH-500. For context, the performance of  o1-mini and o3-mini models on the AIME benchmarks (as reported in a separate study by Ye et al., 2025) is also shown for comparison.  The results clearly demonstrate that SIFT significantly boosts the accuracy of DeepSeek-R1 on all three benchmarks, highlighting its ability to enhance the reasoning capabilities of large language models.", "section": "4.1 Enhancing LLM Reasoning with SIFT"}, {"figure_path": "https://arxiv.org/html/2502.14922/x2.png", "caption": "Figure 2: An example of a query and its Sticker.", "description": "The figure shows an example of a query used in the SIFT model and the corresponding Sticker generated by the model. The query is a word problem: \"Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?\"  The Sticker summarizes the key information from the query into a structured format, including conditions and the question, such as: \"1. Josh buys a house for $80,000. 2. He spends $50,000 on repairs. 3. The value of the house increases by 150%. Question: What is the total profit Josh made from flipping the house?\"", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.14922/x3.png", "caption": "Figure 3: Factual drift occurs during (i) Sticker generation and (ii) prediction generation from Sticker.", "description": "This figure illustrates two scenarios where factual drift, the misinterpretation of key information in the context, occurs during the SIFT process.  In (i), the model generates an incorrect 'Sticker' by neglecting key constraints from the query, demonstrating that factual drift can occur even during the summarization stage.  In (ii), the model correctly generates the Sticker but misinterprets its information during prediction generation, highlighting that the problem is not solely limited to the initial summarization.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.14922/x4.png", "caption": "Figure 4: Self-verification occurs during DeepSeek-R1\u2019s reasoning, where the model revisiting the query, focusing on key information, and paraphrasing it.", "description": "This figure shows an example of DeepSeek-R1's self-verification process during reasoning.  The model demonstrates its ability to mitigate factual drift by revisiting the original query, identifying key details, and rephrasing critical elements for a more accurate understanding before proceeding with its reasoning steps. This highlights the model's capacity for introspection and self-correction, improving the overall reliability of its reasoning process.", "section": "3.1 Factual Drift in LLM Reasoning"}, {"figure_path": "https://arxiv.org/html/2502.14922/x5.png", "caption": "Figure 5: Four core operations in SIFT: (i) Sticker Generation (SG), (ii) Consensus Prediction (CP), (iii) Forward Optimization (FO), (iv) Inverse Generation (IG).", "description": "This figure illustrates the four core components of the Stick to the Facts (SIFT) framework.  It details the process of generating a \"Sticker\" which summarizes key facts from the input query. This sticker is then used in a consensus prediction step to compare two predictions made by the language model: one using only the sticker and the other using both the sticker and the original query.  If discrepancies arise, the sticker is refined through forward optimization to better align with the query and through inverse generation to ensure alignment with the model's inherent reasoning. This iterative refinement aims to improve the faithfulness of the language model's reasoning by grounding it in the most important details of the problem context.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.14922/x6.png", "caption": "Figure 6: \nComparison of SIFT and traditional Zero-shot CoT across multiple models and datasets.\nWe divide SIFT into three stages: Stage 1 only uses SG & CP, while Stage 2 and Stage 3 optimize the Sticker through forward (+FO) and inverse (+IG) direction, respectively.\nThe bidirectional arrows in the figure highlight the performance gap between Zero-shot CoT and the complete SIFT (i.e., Stage 3).\nWe see that in nearly all scenarios, SIFT leads to a significant performance improvement.", "description": "Figure 6 presents a comprehensive comparison of the proposed SIFT method and the traditional zero-shot Chain-of-Thought (CoT) approach across a range of LLMs and benchmark datasets.  SIFT is broken down into three stages to illustrate its iterative improvement process.  Stage 1 uses Sticker Generation (SG) and Consensus Prediction (CP).  Stages 2 and 3 refine the Sticker through forward optimization (+FO) and inverse generation (+IG), respectively.  The figure uses bidirectional arrows to visually emphasize the significant performance gains achieved by the complete SIFT method (Stage 3) over the baseline zero-shot CoT method.", "section": "4.1 Enhancing LLM Reasoning with SIFT"}, {"figure_path": "https://arxiv.org/html/2502.14922/x7.png", "caption": "Figure 7: Iterative optimization results for SIFT.\nThe performance improves as the number of tokens per sample increases across different stages.\nSignificant gains are observed in the first repeats of Stage 2 and Stage 3.", "description": "Figure 7 shows the performance gains achieved by iteratively optimizing the Sticker in the SIFT framework.  The x-axis represents the average number of tokens used per sample, while the y-axis shows the accuracy.  Three stages are depicted: Stage 1 (SG & CP), Stage 2 (+FO), and Stage 3 (+IG).  As the average number of tokens increases (reflecting more iterative refinement), the accuracy consistently improves. The largest improvements in accuracy are seen in the initial iterations of Stage 2 (introducing forward optimization) and Stage 3 (adding inverse generation).  This indicates that the initial refinements of the Sticker are most impactful on the overall reasoning accuracy, with diminishing returns on subsequent iterations.", "section": "4.2 Iterative Optimization"}, {"figure_path": "https://arxiv.org/html/2502.14922/x8.png", "caption": "Figure 8: Venn diagrams illustrating the accuracy of predictions obtained from the \u201cOnly Sticker\u201d and \u201cQuery & Sticker\u201d representations at each stage.\nThe percentages represent the accuracy where both methods correctly predict the same outcomes.\nFrom Stage 1 to Stage 2, the accuracy increases by 6.14%, and from Stage 2 to Stage 3, it increases by 4.85%.\nThe results show the significant impact of Forward Optimization (FO) and Inverse Generation (IG) in improving prediction alignment from the two representations.", "description": "Figure 8 presents Venn diagrams that visually represent the agreement between predictions made using two different approaches: one using only the generated 'Sticker,' and the other using both the 'Sticker' and the original 'Query.' The percentages shown indicate the accuracy of instances where both methods produced identical predictions.  Analyzing the diagrams reveals a substantial improvement in prediction alignment.  From Stage 1 to Stage 2 (incorporating Forward Optimization), accuracy increases by 6.14%, and from Stage 2 to Stage 3 (adding Inverse Generation), the accuracy improves another 4.85%. This demonstrates that the combination of Forward Optimization and Inverse Generation significantly enhances the consistency of predictions.", "section": "4.4 Ablation"}, {"figure_path": "https://arxiv.org/html/2502.14922/x9.png", "caption": "Figure 9: Comparison of SIFT and standard Self-Consistency (SC) in terms of accuracy versus average tokens per sample. The solid lines represent the output tokens used by SC (blue) and SIFT (red), while the dashed lines indicate the total tokens consumed. The \u201c*\u201d symbol in the legend denotes that the total tokens for SIFT fluctuate due to the additional formatting and example constraints used during inference. SIFT achieves comparable accuracy to SC while using significantly fewer output tokens, demonstrating its efficiency.", "description": "Figure 9 illustrates a comparison of SIFT and Self-Consistency (SC) methods in terms of their accuracy and efficiency.  The x-axis represents the average number of tokens per sample, while the y-axis shows the accuracy achieved. Solid lines depict the number of output tokens used by each method (blue for SC, red for SIFT), and dashed lines represent the total tokens consumed (including prompts and formatting).  Crucially, the caption highlights that SIFT's total token count fluctuates because of additional formatting requirements and example constraints in the prompts.  Despite this fluctuation, the results demonstrate that SIFT achieves comparable accuracy to SC while using considerably fewer output tokens, showcasing its superior efficiency.", "section": "4.4 Ablation"}, {"figure_path": "https://arxiv.org/html/2502.14922/x10.png", "caption": "Figure 10: Comparison of SIFT-Consistency and Self-Consistency across different numbers of sampled responses per query. SIFT-Consistency consistently outperforms Self-Consistency.", "description": "This figure compares the performance of SIFT-Consistency and Self-Consistency methods on the GSM8K dataset using Llama3.2-3B-Instruct model.  The x-axis represents the number of sampled responses per query, while the y-axis shows the accuracy.  The results demonstrate that SIFT-Consistency consistently achieves higher accuracy than Self-Consistency across different sampling numbers.", "section": "4.3 Sample Augmentation"}, {"figure_path": "https://arxiv.org/html/2502.14922/x11.png", "caption": "Figure 11: SIFT performance on DeepSeek-R1 with increasing average token count.", "description": "This figure shows how the performance of the SIFT method changes as the average number of tokens used during inference increases, specifically when applied to the DeepSeek-R1 language model.  The x-axis represents the average number of tokens, and the y-axis shows the accuracy achieved on two benchmark datasets: AIME2024 and MATH-500.  Multiple lines represent different stages of the SIFT process, revealing performance improvement as more tokens are used.", "section": "4.1 Enhancing LLM Reasoning with SIFT"}, {"figure_path": "https://arxiv.org/html/2502.14922/x12.png", "caption": "Figure 12: Prompt format for generating a Sticker inversely from the prediction.", "description": "This figure shows the prompt template used in the SIFT framework for generating a sticker from a prediction. The process takes the prediction as input and reconstructs the abstract which led to that prediction. The abstract must include conditions and a question, which are then used to generate the sticker. The prompt is formatted to elicit a response that contains the essential facts and constraints of the problem, which is crucial to SIFT's ability to ground LLM reasoning in contexts and mitigate factual drift.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.14922/x13.png", "caption": "Figure 13: Prompt format for generating predictions.", "description": "This figure shows the prompt templates used in the SIFT method for generating predictions.  Three different prediction generation scenarios are presented: using only the query, only the sticker, and a combination of both the query and sticker. Each template instructs the large language model (LLM) to reason step-by-step and provide the final answer within a box.", "section": "Prompting for SIFT"}, {"figure_path": "https://arxiv.org/html/2502.14922/x14.png", "caption": "Figure 14: Prompt format for generating a Sticker from the query.", "description": "This figure shows the prompt template used in the SIFT method for generating a 'Sticker' from a given query.  The prompt instructs the language model to extract key information from the query and organize it into a structured format. This format includes a numbered list of conditions (extracted facts) and a concise statement of the question. The instructions emphasize that each condition should be atomic and indivisible, and that any part of the reasoning process should not be included.  The goal is to extract the core factual information, clearly separating it from any inferential or reasoning steps.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.14922/x15.png", "caption": "Figure 15: Prompt format for forward optimization of the Sticker.", "description": "This figure shows the prompt template used in the forward optimization step of the SIFT algorithm.  The prompt aims to refine the 'Sticker' (a summary of key information from the query) by comparing it to the original query and correcting any inaccuracies or omissions. The goal is to ensure the Sticker accurately represents the essential facts and question before proceeding with the prediction. The prompt provides detailed instructions, including formats for presenting conditions, and sample inputs and outputs to guide the model's generation of the optimized sticker.", "section": "3 Method"}]