[{"content": "| Method | Input | Img. Backbone | Anchor | NC \u2191 | DAC \u2191 | TTC \u2191 | Comf. \u2191 | EP \u2191 | PDMS \u2191 |\n|---|---|---|---|---|---|---|---|---|---| \n| UniAD [13] | Camera | ResNet-34 [11] | 0 | 97.8 | 91.9 | 92.9 | **100** | 78.8 | 83.4 |\n| PARA-Drive [38] | Camera | ResNet-34 [11] | 0 | 97.9 | 92.4 | 93.0 | 99.8 | 79.3 | 84.0 |\n| LTF [6] | Camera | ResNet-34 [11] | 0 | 97.4 | 92.8 | 92.4 | **100** | 79.0 | 83.8 |\n| Transfuser [6] | C & L | ResNet-34 [11] | 0 | 97.7 | 92.8 | 92.8 | **100** | 79.2 | 84.0 |\n| DRAMA [43] | C & L | ResNet-34 [11] | 0 | 98.0 | 93.1 | **94.8** | **100** | <ins>80.1</ins> | 85.5 |\n| VADv2-\ud835\udcac8192 [3] | C & L | ResNet-34 [11] | 8192 | 97.2 | 89.1 | 91.6 | **100** | 76.0 | 80.9 |\n| Hydra-MDP-\ud835\udcac8192 [22] | C & L | ResNet-34 [11] | 8192 | 97.9 | 91.7 | 92.9 | **100** | 77.6 | 83.0 |\n| Hydra-MDP-\ud835\udcac8192-W-EP [22] | C & L | ResNet-34 [11] | 8192 | **98.3** | <ins>96.0</ins> | 94.6 | **100** | 78.7 | 86.5 |\n| DiffusionDrive (Ours) | C & L | ResNet-34 [11] | 20 | <ins>98.2</ins> | **96.2** | <ins>94.7</ins> | **100** | **82.2** | **88.1** |", "caption": "Table 1: Comparison on planning-oriented NAVSIM navtest split with closed-loop metrics. \u201cC & L\u201d denotes the use of both camera and LiDAR as sensor inputs. \u201c\ud835\udcb18192subscript\ud835\udcb18192\\mathcal{V}_{8192}caligraphic_V start_POSTSUBSCRIPT 8192 end_POSTSUBSCRIPT\u201d denotes 8192 anchors. \u201cHydra-MDP-\ud835\udcb18192subscript\ud835\udcb18192\\mathcal{V}_{8192}caligraphic_V start_POSTSUBSCRIPT 8192 end_POSTSUBSCRIPT-W-EP\u201d is a variant of Hydra-MDP\u00a0[22], which is further trained to fit the EP evaluation metric with additional supervision from the rule-based evaluator and uses weighted confidence post-processing. DiffusionDrive simply learns from human demonstrations and infers without post-processing. The best and the second best results are denoted by bold and underline.", "description": "Table 1 presents a comparison of different methods for end-to-end autonomous driving on the NAVSIM navtest split, using closed-loop evaluation metrics.  The table shows the performance of various methods in terms of several key metrics: No At-Fault Collisions (NC), Drivable Area Compliance (DAC), Time-to-Collision (TTC), Comfort (Comf), and Ego Progress (EP), as well as the overall Planning-Driven Metric Score (PDMS).  The methods compared include various state-of-the-art models and the proposed DiffusionDrive.  The table highlights the use of different sensor inputs (Camera, LiDAR, or both), different numbers of anchors used in the methods (especially for those based on vocabulary-based approaches), and whether or not post-processing steps were employed (like weighted confidence and additional supervision).  It also points out that DiffusionDrive is unique in that it learns directly from human driving data without post-processing steps, resulting in its superior performance.", "section": "4. Experiment"}, {"content": "| Method | NC\u2191 | DAC\u2191 | TTC\u2191 | Comf.\u2191 | EP\u2191 | PDMS\u2191 | Arch. | Step Time\u2193 | Steps \u2193 | Total \u2193 | Para.\u2193 | FPS\u2191 | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Transfuser | 97.7 | 92.8 | 92.8 | **100** | 79.2 | **84.0** | MLP | **0.2ms** | **1** | **0.2ms** | 0% | **56M** | **60** |\n| Transfuser<sub>DP</sub> | 97.5 | 93.7 | 92.7 | **100** | 79.4 | **84.6<sub>+0.6</sub>** | UNet | 6.5ms | 20 | 130.0ms | 11% | 101M | 7 |\n| Transfuser<sub>TD</sub> | **97.9** | **94.2** | **93.9** | **100** | **80.2** | **85.7<sub>+1.7</sub>** | UNet | 6.9ms | 2 | 13.8ms | **70%** | 102M | 27 |\n| DiffusionDrive | **98.2** | **96.2** | **94.7** | **100** | **82.2** | **88.1<sub>+4.1</sub>** | Dec. | **3.8ms** | **2** | **7.6ms** | **74%** | **60M** | **45** |", "caption": "Table 2: Roadmap from Transfuser to DiffusionDrive on NAVSIM navtest split. \u201cTransfuserDPDP{}_{\\text{DP}}start_FLOATSUBSCRIPT DP end_FLOATSUBSCRIPT\u201d denotes Transfuser with vanilla DDIM diffusion policy\u00a0[5]. \u201cTransfuserTDTD{}_{\\text{TD}}start_FLOATSUBSCRIPT TD end_FLOATSUBSCRIPT\u201d denotes Transfuser with truncated diffusion policy. \u201cStep Time\u201d denotes the runtime of each denoising step. \u201cFPS\u201d and runtime are measured on an NVIDIA 4090 GPU. \u201c\ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D\u201d denotes the mode diversity score defined in Eq.\u00a0(3).", "description": "This table shows the evolution of the model from a baseline Transfuser model to the final DiffusionDrive model.  It illustrates the impact of incorporating different diffusion policy types (vanilla DDIM and the truncated version) on various metrics.  The metrics include performance (PDMS score, which combines multiple aspects of driving performance), efficiency (steps, step time, and FPS), and trajectory diversity (D). This allows for a comparison of the trade-offs between performance, efficiency, and diversity achieved with different model modifications.  The runtime measurements are all performed on the same NVIDIA 4090 GPU.", "section": "3. Method"}, {"content": "| ID | UNet | Ego Query | Spatial | Agent/Map | Cascade | Param.\u2193 | Planning Metric |  |  |  |  |  | \n|---|---|---|---|---|---|---|---|---|---|---|---|---| \n| 1 | \u2713 | \u2713 | \u2717 | \u2717 | \u2717 | 102M | NC\u2191 | DAC\u2191 | TTC\u2191 | Comf.\u2191 | EP\u2191 | PDMS\u2191 | \n|  | Decoder | Interaction | Cross-attn | Cross-attn | Decoder |  | 97.9 | 94.2 | 93.9 | 100 | 80.2 | 85.7 | \n| 2 | \u2717 | \u2713 | \u2717 | \u2717 | \u2717 | 57M | 88.7 | 83.2 | 80.0 | 84.8 | 43.3 | 55.1 | \n| 3 | \u2717 | \u2713 | \u2713 | \u2717 | \u2717 | 58M | 98.2 | 95.4 | 94.4 | 100 | 81.3 | 87.1 | \n| 4 | \u2717 | \u2713 | \u2717 | \u2713 | \u2717 | 58M | 97.9 | 93.5 | 93.8 | 100 | 79.8 | 85.1 | \n| 5 | \u2717 | \u2713 | \u2713 | \u2713 | \u2717 | 59M | 98.0 | 95.8 | 94.4 | 100 | 81.7 | 87.4 | \n| 6 | \u2717 | \u2713 | \u2713 | \u2713 | \u2713 | 60M | 98.2 | 96.2 | 94.7 | 100 | 82.2 | 88.1 |", "caption": "Table 3: Ablation for design choices. \u201cCascade Decoder\u201d indicates that we stack 2 cascade diffusion decoder layers. ID-1 refers to TransfuserTDTD{}_{\\text{TD}}start_FLOATSUBSCRIPT TD end_FLOATSUBSCRIPT in Tab.\u00a02, utilizing conditional UNet and interaction with the ego-query, which Transfuser uses to directly regress the single-mode trajectory.", "description": "This ablation study analyzes the impact of different design choices in the DiffusionDrive model's architecture.  It examines the effects of using a cascade decoder (stacking two decoder layers), incorporating a conditional UNet, and including interaction with ego-queries (similar to the Transfuser model).  The baseline (ID-1) is the TransfuserTD model from Table 2 which already uses a conditional UNet. The study systematically removes or adds components to assess their individual contributions to the overall model performance, as measured by several metrics.", "section": "3.3 Truncated Diffusion"}, {"content": "| Steps | Param. | NC | DAC | TTC | Comf. | EP | PDMS |\n|---|---|---|---|---|---|---|---| \n| 1 | 60M | 98.3 | 96.0 | 94.7 | 100 | 82.1 | 87.9 |\n| 2 | 60M | 98.2 | 96.2 | 94.7 | 100 | 82.2 | 88.1 |\n| 3 | 60M | 98.2 | 96.3 | 94.7 | 100 | 92.2 | 88.1 |", "caption": "Table 7: Comparison on nuScenes dataset with open-loop metrics. FPS is measured on a single NVIDIA 4090 GPU following the recipe of SparseDrive\u00a0[32]. Metric calculation follows ST-P3\u00a0[12].", "description": "This table presents a comparison of different methods for autonomous driving on the nuScenes dataset using open-loop metrics.  The metrics evaluated include the average L2 error (in meters) at 1, 2, and 3 seconds into the future, and the collision rate (in percentage) over those same timeframes.  The performance is assessed across different methods, considering the input data (camera only), the backbone architecture used (e.g., ResNet-50), and the frames per second (FPS) achieved on a single NVIDIA 4090 GPU. The experimental setup and metric calculation follow the SparseDrive [32] and ST-P3 [12] methodologies, ensuring consistency and comparability.", "section": "4.7. Quantitative Comparison on nuScenes dataset"}]