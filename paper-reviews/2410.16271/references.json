{"references": [{" publication_date": "2020", "fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "reason": "This is the seminal NeRF paper that introduced the concept of representing scenes as neural radiance fields.  It laid the foundation for subsequent work in novel view synthesis and is foundational to the field of NeRF research, including the current paper's improvements and advancements.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Kangle Deng", "paper_title": "Depth-supervised nerf: Fewer views and faster training for free", "reason": "This paper is a significant contribution to few-shot NeRF, showing that depth supervision can substantially reduce training time and improve quality even with limited views. It directly addresses the problem of limited data, a core focus of the FrugalNeRF paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Wenjing Bian", "paper_title": "Nope-nerf: Optimising neural radiance field with no pose prior", "reason": "This work provides a strong baseline for the few-shot NeRF problem by explicitly avoiding pose priors, focusing on improving quality without relying on external information. The current paper draws similar inspiration by reducing reliance on external information.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Michael Niemeyer", "paper_title": "Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs", "reason": "RegNeRF tackles the challenge of few-shot NeRF by introducing a novel pose sampling strategy and regularization technique to improve geometric consistency and reduce artifacts. This is highly relevant to the FrugalNeRF approach which similarly focuses on improving robustness and geometric accuracy.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiawei Yang", "paper_title": "Freenerf: Improving few-shot neural rendering with free frequency regularization", "reason": "This paper addresses the challenges of few-shot NeRFs by introducing a novel frequency regularization method that gradually increases input frequency during training to improve generalization, allowing for the exploration of high-frequency details without overfitting. This is conceptually related to FrugalNeRF's approach which balances frequency representation across multiple scales.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nagabhushan Somraj", "paper_title": "Simplenerf: Regularizing sparse input neural radiance fields with simpler solutions", "reason": "SimpleNeRF presents a solution that addresses the limitations of other few-shot methods by training separate models for low and high-frequency details, improving the speed and quality of the few-shot synthesis.  This is directly comparable to FrugalNeRF's approach to balancing frequency components across scales.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Minseop Kwak", "paper_title": "Geconerf: Few-shot neural radiance fields via geometric consistency", "reason": "This paper addresses the few-shot NeRF problem by employing geometric consistency modeling between sparse images and warped counterparts. This is relevant to FrugalNeRF's focus on achieving geometric consistency and improving depth accuracy.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "reason": "Mip-NeRF 360 significantly improved NeRF's ability to render high-quality images with anti-aliasing and unbounded views. This advancement is directly relevant to FrugalNeRF's goal of achieving both high quality and efficiency in view synthesis.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Ajay Jain", "paper_title": "Putting nerf on a diet: Semantically consistent few-shot view synthesis", "reason": "This paper explored few-shot NeRF using semantically consistent methods. The approach is similar to FrugalNeRF, which focuses on efficient and accurate 3D scene reconstruction using few-shot input data.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nagabhushan Somraj", "paper_title": "Vip-nerf: Visibility prior for sparse input neural radiance fields", "reason": "ViP-NeRF incorporates a visibility prior to address challenges in few-shot scenarios. This is related to FrugalNeRF's focus on handling sparse data and improving robustness to prevent artifacts, although FrugalNeRF does so without relying on external priors.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Thomas M\u00fcller", "paper_title": "Instant neural graphics primitives with a multiresolution hash encoding", "reason": "Instant-NGP introduced a fast and efficient NeRF implementation using a hash encoding technique, which is highly relevant to FrugalNeRF's focus on speed and efficiency.  FrugalNeRF leverages ideas of efficiency in representation.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Anpei Chen", "paper_title": "Tensorf: Tensorial radiance fields", "reason": "Tensorf introduced a novel representation for NeRF using tensor decomposition, improving both efficiency and quality.  FrugalNeRF is also a voxel based method focused on efficient representation.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Julian Chibane", "paper_title": "Stereo radiance fields (srf): Learning view synthesis for sparse views of novel scenes", "reason": "This paper demonstrated the use of stereo data to learn view synthesis for sparse views, improving both quality and robustness. This is relevant to FrugalNeRF's approach in using limited training data, although FrugalNeRF leverages different mechanisms for supervision.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shoukang Hu", "paper_title": "Sherf: Generalizable human nerf from a single image", "reason": "This paper tackles the single-image NeRF problem, which is highly relevant to few-shot NeRF. It directly addresses the challenge of limited input data, which is a central problem also handled by FrugalNeRF.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Di Chen", "paper_title": "Geoaug: Data augmentation for few-shot nerf with geometry constraints", "reason": "This paper explores data augmentation techniques for improving few-shot NeRF performance.  FrugalNeRF also enhances robustness using novel view regularization techniques, demonstrating the importance of techniques that improve handling of limited data.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Matteo Bortolon", "paper_title": "Vm-nerf: Tackling sparsity in nerf with view morphing", "reason": "This paper proposes using view morphing to tackle sparsity in NeRF, providing a method to synthesize views from limited data. This is a conceptually similar approach to that used in FrugalNeRF, which enhances the use of limited data through novel training strategies.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Shoukang Hu", "paper_title": "Consistentnerf: Enhancing neural radiance fields with 3d consistency for sparse view synthesis", "reason": "This paper tackles the problem of inconsistent 3D geometry in few-shot NeRF by enforcing 3D consistency during training, directly addressing the challenge of limited training views that is handled by FrugalNeRF as well.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Eric R Chan", "paper_title": "pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis", "reason": "This paper introduced a novel approach to 3D-aware image synthesis using periodic implicit generative adversarial networks (GANs), demonstrating a different method for generating high-quality 3D models from limited information, which relates to the underlying goals of FrugalNeRF in generating high-quality novel views.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Eric R Chan", "paper_title": "Efficient geometry-aware 3d generative adversarial networks", "reason": "This paper demonstrates an efficient GAN-based approach to generating geometry-aware 3D models, which is related to the broader context of FrugalNeRF in that both works aim for efficient and high-quality 3D scene representation from limited input.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Zehao Zhu", "paper_title": "Fsgs: Real-time few-shot view synthesis using gaussian splatting", "reason": "This paper presents a real-time few-shot novel view synthesis method using Gaussian splatting, demonstrating that high-quality results can be achieved with fast convergence speed.  This is directly compared against in the experiments section of the current paper.", "section_number": 2}]}