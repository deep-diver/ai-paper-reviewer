{"references": [{" publication_date": "2020", "fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "reason": "This is the foundational paper that introduced Neural Radiance Fields (NeRFs), which are the basis for FrugalNeRF and many of the methods discussed in the \"Related Work\" section. Its impact on the field is immense, shaping the research direction and serving as a benchmark for subsequent advancements.  The core concepts and techniques presented in this work are crucial for understanding the context of FrugalNeRF's contributions.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Kangle Deng", "paper_title": "Depth-supervised nerf: Fewer views and faster training for free", "reason": "This paper is highly relevant to FrugalNeRF's goal of efficient few-shot novel view synthesis.  It introduces a depth-supervised approach that significantly improves training speed and reduces the number of required views.  The concepts of depth supervision and efficiency are central to FrugalNeRF's design and are explicitly discussed in the \"Related Work\" section.  The improvements in speed and view reduction are directly relevant to FrugalNeRF's core contributions.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Michael Niemeyer", "paper_title": "Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs", "reason": "This paper directly addresses the challenges of few-shot NeRF synthesis by introducing regularization techniques.  The \"Related Work\" section extensively covers regularization techniques like this, highlighting their limitations, and motivating the need for FrugalNeRF's alternative approach.   RegNeRF's focus on regularization and its performance are directly compared against FrugalNeRF in the experimental section.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiawei Yang", "paper_title": "Freenerf: Improving few-shot neural rendering with free frequency regularization", "reason": "This paper is cited extensively in the \"Related Work\" section as it addresses the challenge of few-shot NeRF by introducing frequency regularization, a technique that FrugalNeRF contrasts and improves upon.  The discussion of the limitations of frequency regularization and the proposal of FrugalNeRF's alternative cross-scale geometric adaptation are directly influenced by this paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nagabhushan Somraj", "paper_title": "Simplenerf: Regularizing sparse input neural radiance fields with simpler solutions", "reason": "This paper explores the use of simpler solutions to address the limitations of few-shot NeRFs and is compared directly against FrugalNeRF throughout the paper. The comparison highlights FrugalNeRF's superior performance while maintaining efficiency.  SimpleNeRF's approach and its limitations are critically analyzed and compared with FrugalNeRF's approach in the \"Related Work\" and \"Experiments\" sections.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Minseop Kwak", "paper_title": "Geconerf: Few-shot neural radiance fields via geometric consistency", "reason": "GeCoNeRF is a key comparative method in this paper.  It addresses few-shot NeRFs but relies on a pre-trained feature extractor and uses warped features as pseudo labels. FrugalNeRF contrasts its approach, emphasizing its efficiency and avoidance of reliance on pre-trained models.  The differences and relative merits are discussed in the \"Related Work\" and \"Experiments\" sections and further detailed in the supplementary material.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shoukang Hu", "paper_title": "Sparsenerf: Distilling depth ranking for few-shot novel view synthesis", "reason": "This paper is a major comparative method in the experimental section, particularly for evaluating on the DTU dataset.  SparseNeRF uses dense prediction transformers for depth priors, contrasting FrugalNeRF's approach which avoids reliance on pre-trained models.  The performance of both methods is extensively compared across multiple metrics and datasets, illustrating FrugalNeRF's superior results.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Ajay Jain", "paper_title": "Putting nerf on a diet: Semantically consistent few-shot view synthesis", "reason": "This paper is highly relevant to the context of few-shot NeRFs, discussed in the \"Related Work\" section.  It addresses challenges related to data scarcity in few-shot settings, a problem central to the paper's main contribution.  The techniques and results of this paper are compared and contrasted against FrugalNeRF's approach to demonstrate the advantages of the proposed method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nagabhushan Somraj", "paper_title": "Vip-nerf: Visibility prior for sparse input neural radiance fields", "reason": "ViP-NeRF is a significant comparative method, particularly for evaluating on the DTU dataset.  It addresses the challenges of few-shot NeRF using visibility priors. The \"Related Work\" and \"Experiments\" sections extensively compare and contrast ViP-NeRF with FrugalNeRF, highlighting FrugalNeRF's superiority in both speed and quality.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Anpei Chen", "paper_title": "Tensorf: Tensorial radiance fields", "reason": "TensoRF is an important reference for FrugalNeRF's implementation, which is based on TensoRF's architecture.  The method section details how FrugalNeRF leverages TensoRF's efficient voxel-based representation while introducing novel improvements for few-shot settings. This makes TensoRF a crucial methodological reference.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Julian Chibane", "paper_title": "Stereo radiance fields (srf): Learning view synthesis for sparse views of novel scenes", "reason": "This paper's contribution of stereo radiance fields is relevant to the context of few-shot novel view synthesis discussed in the \"Related Work\" section.  The techniques and limitations are compared against FrugalNeRF's approach, highlighting the advantages of FrugalNeRF's cross-scale geometric adaptation.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "reason": "Mip-NeRF 360 is referenced for its distortion loss, which is used in FrugalNeRF to improve scene quality.  The \"Method\" section clearly states the use of Mip-NeRF 360's distortion loss and its role in preventing visual artifacts. Therefore, this is a key technical component in FrugalNeRF's implementation.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Thomas M\u00fcller", "paper_title": "Instant neural graphics primitives with a multiresolution hash encoding", "reason": "This paper's technique of using voxels coupled with hash encoding for efficient representation is relevant to FrugalNeRF's architecture, and the \"Method\" section references Instant-NGP as a relevant approach.  This is a key methodological inspiration that underlies the efficiency gains achieved by FrugalNeRF.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Alex Yu", "paper_title": "pixelnerf: Neural radiance fields from one or few images", "reason": "PixelNeRF is used as a baseline comparison for the experimental evaluation, especially for the DTU dataset.  Its performance is explicitly compared against FrugalNeRF to show the superiority of FrugalNeRF's method.  PixelNeRF's approach and its limitations are discussed in the \"Related Work\" and \"Experiments\" sections.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Zehao Zhu", "paper_title": "Fsgs: Real-time few-shot view synthesis using gaussian splatting", "reason": "FSGS is a significant comparative method in the paper.  It is a state-of-the-art few-shot NeRF approach using Gaussian splatting.  Its limitations and FrugalNeRF's superior performance in speed and quality are extensively compared in the experimental section and supplementary materials.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Rasmus Jensen", "paper_title": "Large scale multi-view stereopsis evaluation", "reason": "The DTU dataset, used in the experiments, is based on this paper's multi-view stereo dataset.  The experimental section uses the same evaluation protocols as established in this work for fair comparison with previous methods.  This makes it a crucial reference for the experimental setup and evaluation.", "section_number": 4}, {" publication_date": "2014", "fullname_first_author": "Diederik P Kingma", "paper_title": "Adam: A method for stochastic optimization", "reason": "The Adam optimizer, used in training FrugalNeRF, is a fundamental algorithm in deep learning.  The implementation details mention using the Adam optimizer, making this paper a crucial reference for understanding the training process of FrugalNeRF and how it differs from other methods.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "The DPT (Dense Prediction Transformer) model, used in FrugalNeRF to generate monocular depth maps, is based on this work.  The implementation details describe the use of DPT, establishing its importance in FrugalNeRF's pre-processing steps and indirectly influencing its performance.", "section_number": 4}, {" publication_date": "2016", "fullname_first_author": "Johannes Lutz Sch\u00f6nberger", "paper_title": "Structure-from-motion revisited", "reason": "COLMAP, used for obtaining camera poses in the DTU dataset, is based on this paper's structure-from-motion method.  The experimental setup mentions using COLMAP, making this a critical reference for the data processing and experimental setup in the DTU experiments.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Ren\u00e9 Ranftl", "paper_title": "Vision transformers for dense prediction", "reason": "The DPT (Dense Prediction Transformer) model, used in FrugalNeRF to generate monocular depth maps, builds upon this work.  The implementation details describe the use of DPT, establishing its importance in FrugalNeRF's pre-processing steps and indirectly influencing its performance.", "section_number": 4}]}