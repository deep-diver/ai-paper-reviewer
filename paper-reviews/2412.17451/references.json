{"references": [{"fullname_first_author": "Hunter Lightman", "paper_title": "Let's verify step by step", "publication_date": "2023-05-20", "reason": "This paper introduces the Process Reward Model (PRM), a crucial component of the proposed M-STAR framework for improving multimodal reasoning."}, {"fullname_first_author": "Avi Singh", "paper_title": "Beyond human data: Scaling self-training for problem-solving with language models", "publication_date": "2023-12-06", "reason": "This work is highly relevant because it explores self-evolving training, a key technique used in the M-STAR framework, and provides insights into scaling this approach for enhanced performance."}, {"fullname_first_author": "Caglar Gulcehre", "paper_title": "Reinforced self-training (ReST) for language modeling", "publication_date": "2023-08-08", "reason": "This paper is a seminal work on self-evolving training which directly inspired the development of the M-STAR framework."}, {"fullname_first_author": "Yuan Yao", "paper_title": "MiniCPM-V: A GPT-4V level MLLM on your phone", "publication_date": "2024-08-01", "reason": "This paper introduces the MiniCPM-V-2.5 model, one of the main models used in the experimental evaluation of the M-STAR framework."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "DeepSeekMath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-03", "reason": "This paper provides a strong baseline for comparison and helps contextualize the advancements achieved by the M-STAR framework in mathematical reasoning."}]}