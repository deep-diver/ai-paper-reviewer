[{"figure_path": "2410.13232/figures/figures_4_0.png", "caption": "Figure 3: Framework overview. We first collect training data for world models (top). After training, we perform policy optimization by selecting the action leading to an optimal next state (bottom).", "description": "This figure illustrates the overall framework of the World-Model-Augmented (WMA) web agent, showing the training process of the world model and the inference-time policy optimization using the trained model.", "section": "4 WORLD-MODEL-AUGMENTED WEB AGENTS"}, {"figure_path": "2410.13232/figures/figures_4_1.png", "caption": "Figure 3: Framework overview. We first collect training data for world models (top). After training, we perform policy optimization by selecting the action leading to an optimal next state (bottom).", "description": "The figure illustrates the World-Model-Augmented (WMA) web agent framework, showing the training process for world models and the inference-time policy optimization using the world model.", "section": "4 WORLD-MODEL-AUGMENTED WEB AGENTS"}, {"figure_path": "2410.13232/figures/figures_6_0.png", "caption": "Figure 5: The overview of transition-focused observation abstraction.", "description": "This figure illustrates the process of transition-focused observation abstraction, showing how the Hungarian algorithm matches elements between consecutive observations and how an LLM generates a free-form natural language description highlighting the key differences.", "section": "4.1 World Model Training"}, {"figure_path": "2410.13232/figures/figures_6_1.png", "caption": "Figure 5: The overview of transition-focused observation abstraction.", "description": "The figure illustrates the transition-focused observation abstraction process, showing how the Hungarian algorithm matches elements between consecutive observations to generate a free-form description highlighting important state differences.", "section": "4.1 World Model Training"}, {"figure_path": "2410.13232/figures/figures_6_2.png", "caption": "Figure 5: The overview of transition-focused observation abstraction.", "description": "The figure illustrates the process of transition-focused observation abstraction, showing how the Hungarian algorithm matches elements between consecutive observations to highlight state differences, which are then used to generate a free-form natural language description of the next observation.", "section": "4.1 World Model Training"}, {"figure_path": "2410.13232/figures/figures_20_0.png", "caption": "Figure 8: Human annotation interface for preliminary analysis I in \u00a73.1.", "description": "The figure shows the interface used for human annotation in the preliminary analysis I, which involved a binary classification task to evaluate LLMs' ability to predict next states based on current states and actions.", "section": "3.1 Preliminary Analysis I: LLMs Struggle With Predicting the Next States Caused by Their Actions"}, {"figure_path": "2410.13232/figures/figures_20_1.png", "caption": "Figure 10: Erroneous example (Counterfactual imagination). The model predicts that specific products (96 TY CITY86 Bmw 740i Limited Collector Hoodie Men's Close; Toyota 86 Bad Institute Monkey Champagne Cup, Volkswagen A9 Bug Pick Dead Red) will appear in the next observation, while this specific page does not list them as the products for sell.", "description": "The figure shows an example of a counterfactual imagination error in the world model's prediction, where non-existent products are predicted to appear in the next observation.", "section": "6.2 Types of Errors in World Models\u2019 Predictions"}, {"figure_path": "2410.13232/figures/figures_21_0.png", "caption": "Figure 11: Erroneous example (Correct yet overly generic statements). \u201cComprehensive layout\u201d and \u201cvarious order-related functionalities\u201d are ambiguous and unclear expressions.", "description": "The figure shows an example of an erroneous prediction where the model generates overly generic and unclear descriptions of the next observation, failing to capture specific details about the changes.", "section": "6.2 Types of Errors in World Models\u2019 Predictions"}, {"figure_path": "2410.13232/figures/figures_21_1.png", "caption": "Figure 12: Erroneous example (Others). The predicted next state (i.e., contributions and activities) is actually several steps further away from the current time step.", "description": "The figure shows an example of an erroneous prediction by the world model where the predicted next state is several steps away from the actual next state.", "section": "6.2 Types of Errors in World Models' Predictions"}, {"figure_path": "2410.13232/figures/figures_22_0.png", "caption": "Figure 13: Successful example (Mind2Web). WMA web agent successfully inferences on the Mind2Web benchmark (menards task #0). Using the policy model (i.e., GPT-40), WMA web agent selects the most proper action click [208] by leveraging its learned environment dynamics.", "description": "The figure shows a successful example of the WMA web agent performing a task on the Mind2Web benchmark by leveraging its learned environment dynamics to select the optimal action.", "section": "5.2 MAIN RESULTS"}, {"figure_path": "2410.13232/figures/figures_23_0.png", "caption": "Figure 14: Successful example (WebArena). WMA web agent successfully infers on Gitlab domain in the WebArena benchmark (instance #175). Using the policy model (i.e., GPT-40), WMA web agent selects the most proper action click [88] by leveraging its learned environment dynamics.", "description": "The figure shows a successful example of WMA web agent in WebArena benchmark, where the agent correctly selects the action by leveraging its learned environment dynamics.", "section": "5 Experiments"}]