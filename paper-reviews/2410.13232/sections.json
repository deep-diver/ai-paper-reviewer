[{"page_end_idx": 2, "page_start_idx": 1, "section_number": 1, "section_title": "Introduction", "details": {"details": "Large language models (LLMs) have shown promise in web navigation, generating action sequences to accomplish user goals on websites.  However, their performance in long-horizon tasks remains significantly suboptimal, particularly in complex environments like WebArena.  Current LLM-based web agents often repeat irreversible actions (e.g., repeatedly buying a non-refundable flight ticket) due to a lack of \"world model\"\u2014an understanding of potential outcomes.  In contrast, humans avoid such mistakes by considering the possible consequences of their actions. This introductory section highlights this crucial performance gap between human web navigation and current LLM-based approaches, setting the stage for the paper's investigation into the benefits of incorporating world models into LLM agents to improve performance in long-horizon tasks.  The section cites a task success rate of only 14.41% for GPT-4 in WebArena, compared to a human success rate of 78.24%, demonstrating the significant room for improvement.", "first_cons": "The introduction focuses heavily on the limitations of current LLMs without providing concrete examples of the types of errors LLMs make in long-horizon web navigation tasks beyond the general example of repeatedly buying a non-refundable flight ticket. More diverse and specific examples would strengthen the argument.", "first_pros": "The introduction effectively establishes the core problem that motivates the rest of the paper: the significant performance gap between LLMs and humans in complex web navigation tasks, especially those involving long horizons.  The use of concrete numbers (14.41% vs. 78.24%) effectively highlights the magnitude of the problem.", "keypoints": ["Significant performance gap between LLMs and humans in long-horizon web navigation tasks (14.41% success rate for GPT-4 vs. 78.24% for humans in WebArena).", "Lack of \"world model\" in current LLMs is identified as a key factor contributing to poor performance.", "LLM-based agents often make irreversible mistakes due to the absence of a world model.", "The introduction sets the stage for exploring the use of world models to improve LLM performance in long-horizon web navigation tasks. "], "second_cons": "The introduction doesn't offer a clear definition of what constitutes a \"world model\" within the context of web navigation.  A more precise definition would help to clarify the scope of the paper and its contribution.", "second_pros": "The introduction effectively contrasts the capabilities of LLMs with the capabilities of human web navigators, highlighting the intuitive and insightful nature of human decision-making in contrast to the more limited and error-prone approach of current LLMs.  This contrast effectively emphasizes the need for improvement and innovation.", "summary": "The introduction highlights the significant performance gap between large language models (LLMs) and humans in long-horizon web navigation tasks.  This gap is attributed to the lack of a \"world model\" in current LLMs, which leads to irreversible errors.  The study will focus on exploring the use of world models to enhance the decision-making capabilities of LLM-based agents to address this limitation, with the goal of closing the performance gap between LLMs and humans in complex web navigation scenarios."}}, {"page_end_idx": 3, "page_start_idx": 3, "section_number": 3, "section_title": "Preliminary Analyses: Are Current LLMs Aware of Environment Dynamics in Web Navigation?", "details": {"details": "This section investigates whether Large Language Models (LLMs) understand the relationship between actions and their effects within web navigation.  The authors conduct two preliminary analyses. The first examines whether LLMs can predict the outcomes of their actions; they find that LLMs perform poorly at this task (around 54.75% accuracy on average), significantly worse than humans (83% accuracy). The second analysis tests the LLMs' ability to choose the optimal action when provided with the outcomes of each action candidate.  Here, LLMs demonstrate improved performance (average accuracy increased by around 37%),  highlighting the importance of access to outcome information.  These findings suggest the absence of a \"world model\"\u2014an understanding of how actions influence the environment\u2014in current LLMs, which impacts their decision-making capabilities in complex web navigation scenarios.", "first_cons": "The study's preliminary analyses rely on a limited set of LLMs and a specific benchmark, potentially limiting the generalizability of the findings to other LLMs or web navigation scenarios.", "first_pros": "The preliminary analyses clearly and effectively demonstrate the lack of a robust world model in current LLMs, providing a strong foundation for the subsequent introduction of a World-Model-Augmented (WMA) web agent.", "keypoints": ["LLMs struggle with predicting next states: LLMs achieve an average accuracy of only 54.75% in predicting the next state after an action, significantly underperforming humans (83%).", "LLMs make better action selection with outcome information: When provided with the outcome of each action candidate, LLM accuracy improves dramatically, highlighting the value of access to outcome information.", "Absence of world models in current LLMs: The findings strongly suggest that current LLMs lack an internal representation of how actions change the environment (world model)."], "second_cons": "The analyses primarily focus on closed-source LLMs; an examination of open-source models could provide further insights and increase the reproducibility of the study.", "second_pros": "The findings motivate the development and testing of the World-Model-Augmented (WMA) web agent, a key contribution of the paper. The clear demonstration of the limitations of current LLMs strengthens the justification for this novel approach.", "summary": "This study's preliminary analyses reveal a critical deficiency in current LLMs: a lack of \"world model\" capabilities for web navigation.  Experiments show that LLMs struggle to accurately predict the consequences of their actions (around 55% accuracy compared to 83% for humans), but their performance improves significantly (around 37% increase) when given access to potential outcomes, demonstrating that a world model is crucial for effective decision-making in such scenarios."}}, {"page_end_idx": 6, "page_start_idx": 4, "section_number": 4, "section_title": "World-Model-Augmented Web Agents", "details": {"details": "The World-Model-Augmented (WMA) web agent framework is introduced to improve the performance of Large Language Model (LLM)-based web agents in long-horizon tasks.  The core idea is to equip LLMs with a *world model* that simulates the outcomes of actions before they are taken, thus improving decision-making.  This addresses the limitations of current LLMs that struggle with predicting the consequences of their actions. The proposed WMA agent uses a novel *transition-focused observation abstraction* to overcome challenges in training LLMs as world models. Instead of predicting the entire webpage (which contains a lot of repetition), the LLM only predicts the key differences between consecutive observations, represented in a free-form natural language description. During inference, the agent simulates outcomes for several action candidates using the world model. Then, it selects the action that leads to the most favorable simulated outcome according to a value function.  Experiments on WebArena and Mind2Web demonstrate the effectiveness of the proposed approach, showing significant improvements in task success rate and improved cost- and time-efficiency compared to other state-of-the-art (SOTA) agents.", "first_cons": "The WMA framework relies on a separate world model, which adds complexity to the system and requires additional training data.  The effectiveness of the world model heavily depends on the quality of the training data and the ability of the LLM to abstract state transitions accurately.", "first_pros": "The proposed WMA framework significantly improves the performance of LLM-based web agents in long-horizon tasks, achieving a higher success rate and better cost- and time-efficiency compared to previous SOTA methods.", "keypoints": ["The core idea is to augment LLMs with a world model that simulates the outcomes of actions before they are taken.", "A novel transition-focused observation abstraction is proposed to overcome challenges in training LLMs as world models, focusing on predicting only the key differences between consecutive observations.", "During inference, the agent simulates outcomes for several action candidates using the world model and selects the action leading to the most favorable simulated outcome according to a value function.", "Experiments show significant improvements in task success rate and cost- and time-efficiency compared to recent tree-search-based agents (6.8x and 5.3x respectively)."], "second_cons": "The accuracy of the world model's predictions is crucial for the success of the WMA agent. Errors in the world model's predictions can lead to suboptimal decisions, potentially even more costly than the trial-and-error approach of previous methods.", "second_pros": "The transition-focused observation abstraction significantly reduces the computational cost and training time compared to naively training an LLM to predict the entire next observation state.", "summary": "This section introduces a World-Model-Augmented (WMA) web agent framework designed to address the limitations of existing LLM-based web agents in handling long-horizon tasks.  The WMA agent uses a world model, trained using a transition-focused observation abstraction, to simulate the outcomes of actions. This allows for better decision-making by selecting actions leading to optimal next states, resulting in significant improvements in performance and efficiency compared to existing methods."}}, {"page_end_idx": 10, "page_start_idx": 6, "section_number": 5, "section_title": "Experiments", "details": {"details": "## 5 Experiments\n\nThis section details the experimental setup and results of the World-Model-Augmented (WMA) web agent.  Two benchmarks were used for evaluation: WebArena and Mind2Web. WebArena contains 812 real-life tasks across five diverse websites and four domains (e-commerce, social forums, software development, and content management), while Mind2Web includes over 2000 open-ended tasks from 137 websites across 31 domains.  The primary evaluation metric was Success Rate (SR), representing the percentage of successfully completed tasks.  For Mind2Web, Step SR (step success rate) and element accuracy were also considered.\n\nThe experiments compared the WMA agent against several baselines, including a prompting-based LLM, AutoEval, BrowserGym, SteP, HTML-T5, Agent Workflow Memory (AWM), and a Tree search agent.  The WMA agent consistently outperformed the baselines on both benchmarks, achieving a new state-of-the-art (SOTA) performance on Mind2Web. In WebArena, the WMA agent's performance improvements compared to the vanilla chain-of-thought (CoT) approach varied across domains, but significant gains (+28% to +44%) were observed in several domains. Notably, when GPT-40-mini was used as the policy model, the WMA agent achieved impressive improvements (+43.6% overall and +181% in one specific domain).  Ablation studies investigated the impact of various design choices in the WMA agent (e.g., the use of a world model, the transition-focused observation abstraction, and different value functions).  The results confirmed the benefits of the proposed design choices.\n\nFinally, the authors compared the WMA agent with the Tree search agent in terms of time and API cost efficiency. The WMA agent showed significant improvements, being 5.3 times faster and requiring 6.8 times less API cost than the Tree search agent. This demonstrates the WMA agent's superior cost- and time-efficiency.", "first_cons": "The WebArena results showed varied performance improvements across different domains, suggesting potential limitations in generalizability.", "first_pros": "The WMA web agent achieved state-of-the-art performance on Mind2Web, significantly outperforming various baselines.", "keypoints": ["The WMA agent significantly outperformed various baselines on both WebArena and Mind2Web benchmarks.", "The WMA agent achieved a new state-of-the-art (SOTA) performance on Mind2Web.", "In WebArena, significant performance gains (+28% to +44%) were observed in several domains compared to the vanilla CoT.", "The WMA agent demonstrated superior cost- and time-efficiency compared to the Tree search agent, being 5.3 times faster and requiring 6.8 times less API cost. ", "Ablation studies confirmed the benefits of the proposed design choices in the WMA agent architecture. "], "second_cons": "The study lacked a detailed analysis and discussion on the types of errors made by the world model during the prediction process. ", "second_pros": "The ablation studies provided valuable insights into the individual contributions of different components in the WMA agent architecture.", "summary": "The experiments section evaluates the proposed World-Model-Augmented (WMA) web agent using WebArena and Mind2Web benchmarks, demonstrating significant performance improvements over several baselines, achieving a new state-of-the-art on Mind2Web, and showcasing superior cost and time efficiency compared to the tree search agent. Ablation studies validate the effectiveness of the key design choices within the WMA architecture."}}, {"page_end_idx": 10, "page_start_idx": 10, "section_number": 6, "section_title": "Further Analyses", "details": {"details": "This section explores two avenues for enhancing the performance of the World-Model-Augmented (WMA) web agent.  First, it investigates combining the WMA agent's inference-time policy optimization with a self-refinement technique, where the agent's policy model refines its action predictions based on simulated outcomes from the world model.  Experiments in the Map domain of WebArena show a modest improvement in success rate (SR) from 11.6% to 13.4% compared to the vanilla chain-of-thought approach. However, the standard WMA approach (without self-refinement) achieves a significantly better SR of 22.3%, suggesting self-refinement may not be the most effective strategy in all cases.  Second, the section analyzes the types of errors made by the world model's predictions, categorizing them into four types: overly generic statements (24%), low competence in web elements/functions (26%), counterfactual imagination (42%), and others (8%).  This error analysis provides valuable insights into the model's strengths and weaknesses, guiding future improvements.", "first_cons": "The self-refinement technique, while showing some improvement, doesn't significantly outperform the standard WMA approach (13.4% vs. 22.3% success rate), suggesting that this method might not be universally beneficial and further investigation is required.", "first_pros": "The error analysis offers valuable insights into the world model's limitations.  Categorizing the errors into four distinct types (overly generic statements, low function competence, counterfactual imagination, and others) provides actionable information for developers to focus improvement efforts.", "keypoints": ["Self-refinement modestly improves success rate in the Map domain (11.6% to 13.4%), but the standard WMA approach significantly outperforms it (22.3%).", "World model error analysis reveals counterfactual imagination is the most frequent type of error (42%), followed by overly generic statements (24%), low competence in web elements/functions (26%), and other miscellaneous errors (8%)."], "second_cons": "The error analysis is limited to a sample of 50 erroneous predictions and may not be fully representative of the overall performance of the world model. A larger, more comprehensive analysis would enhance the reliability of the findings.", "second_pros": "The section presents a thorough investigation of two different strategies to enhance the WMA agent\u2019s performance, namely self-refinement and error analysis of the world model. This dual approach provides a more complete understanding of the model's capabilities and limitations.", "summary": "This section delves into two aspects of refining the WMA web agent: combining self-refinement with the existing policy optimization and analyzing the types of errors in the world model's predictions.  Self-refinement shows modest improvements but underperforms the standard approach. The error analysis, categorizing errors into four types, provides valuable insights into the model's flaws, highlighting counterfactual imagination as the most frequent error (42%).  The findings guide future improvements by pinpointing areas requiring attention."}}]