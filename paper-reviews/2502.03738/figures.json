[{"figure_path": "https://arxiv.org/html/2502.03738/x1.png", "caption": "(a) DeiT-B, 64\u00d7\\times\u00d764 Input, CLS", "description": "This figure shows the test loss results for DeiT-Base model with 64x64 input image size on the ImageNet-1k classification task. The x-axis represents the patch size used for image tokenization, ranging from 16 to 1. The y-axis shows the corresponding test loss. The plot demonstrates a clear trend where the test loss decreases as the patch size decreases, indicating that smaller patch sizes lead to improved performance.", "section": "4.1 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2502.03738/x2.png", "caption": "(b) Adventurer-B, 128\u00d7\\times\u00d7128 Input, CLS", "description": "The figure shows the test loss for the Adventurer-B model with a 128x128 input image on the ImageNet-1k classification task.  The x-axis represents different patch sizes used for image tokenization, and the y-axis shows the corresponding test loss.  The plot demonstrates how the test loss varies as the patch size is changed, illustrating the effect of patch size on model performance for this specific model and task.", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x3.png", "caption": "(c) Adventurer-B, 224\u00d7\\times\u00d7224 Input, CLS", "description": "The figure shows the test loss for image classification on the ImageNet-1k dataset using the Adventurer-B model with a 224x224 input image and the classification head being the [CLS] token.  It displays how the test loss changes as the patch size used in the patchification process is varied.  The x-axis represents the patch size, and the y-axis represents the test loss. The plot demonstrates the relationship between patch size and model performance for this specific model and dataset.", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x4.png", "caption": "(d) ADE20k Semantic Segmentation", "description": "This figure shows the results of patch size scaling experiments on the ADE20k semantic segmentation dataset.  It demonstrates how test loss changes as the patch size used for image tokenization decreases. The x-axis represents the patch size, and the y-axis represents the test loss.  The graph visually depicts the scaling law observed in patchification, showing a consistent decrease in test loss as patch size decreases, indicating improved performance with smaller patches.", "section": "4.1. Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2502.03738/x5.png", "caption": "(e) COCO Object Detection", "description": "This figure shows the test loss (in terms of bounding box) for COCO object detection across different patch sizes.  The x-axis represents the patch size used for image tokenization, and the y-axis shows the corresponding test loss.  The results demonstrate the impact of patch size on the performance of the object detection model. Smaller patch sizes generally lead to lower test loss, indicating improved performance.", "section": "4.1 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2502.03738/x6.png", "caption": "(f) COCO Instance Segmentation", "description": "This figure shows the test loss (mask) for COCO instance segmentation plotted against patch size.  The graph displays the impact of varying patch sizes on the model's performance for this specific task. The results are presented in log scale for both the x and y axes.", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x7.png", "caption": "(g) DeiT-B, 128\u00d7\\times\u00d7128 Input, CLS", "description": "This figure shows the test loss for different patch sizes when training a DeiT-Base model on the ImageNet-1k classification task. The input image size is 128x128 pixels, and the classification is performed using the CLS token.  The x-axis represents the patch size (on a log scale), and the y-axis represents the test loss (also on a log scale). The figure demonstrates the impact of reducing patch size on model performance.", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x8.png", "caption": "(h) Adventurer-L, 128\u00d7\\times\u00d7128, CLS", "description": "This figure shows the test loss for the Adventurer-Large model with a 128x128 input image on the ImageNet-1k classification task (CLS).  The x-axis represents the patch size used for image tokenization, and the y-axis represents the test loss. The plot demonstrates how test loss changes as the patch size decreases, illustrating the impact of patch size on model performance.  This plot shows that consistently decreasing the patch size improves the performance, reaching the minimum at 1x1(pixel tokenization).", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x9.png", "caption": "(i) Adventurer-T, 224\u00d7\\times\u00d7224, CLS", "description": "This figure displays the results of patch size scaling experiments conducted on the Adventurer-T model with a 224x224 input image for ImageNet-1k classification (CLS). It visually represents how the model's test loss changes as the patch size decreases, demonstrating the impact of patch size on model performance.", "section": "Patchification Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2502.03738/x10.png", "caption": "Figure 1: Patchification Scaling Laws. We observe a smooth and consistent decrease in test loss across different vision tasks, input resolutions, and model architectures when reducing the patch size. The performance gains remain considerably significant even when scaling down the patch size to 1\u00d7\\times\u00d71. In all sub-figures, both x\ud835\udc65xitalic_x and y\ud835\udc66yitalic_y axes are in log scale. CLS denotes ImageNet-1k classification.", "description": "This figure visualizes the impact of patch size on the performance of various vision models across different tasks.  The x-axis represents the patch size (on a logarithmic scale), while the y-axis shows the test loss (also on a logarithmic scale).  The plots demonstrate a consistent trend: as the patch size decreases, the test loss decreases, indicating improved model performance.  This trend is observed across various vision tasks (classification, semantic segmentation, object detection, and instance segmentation), input resolutions, and model architectures (DeiT and Adventurer).  Even when the patch size is reduced to the minimum of 1x1 (pixel-level processing), significant performance gains are maintained.  The ImageNet-1k classification task is specifically highlighted using the abbreviation 'CLS'.", "section": "4. Main Results"}, {"figure_path": "https://arxiv.org/html/2502.03738/x11.png", "caption": "Figure 2: Decoder\u2019s impact on semantic segmentation. We train a semantic segmentation model with the same backbone but different decoder heads: an UperNet with 13M parameters and a simple linear layer with 0.2M parameters. We observe that as patch size decreases, the impact of the decoder head diminishes.", "description": "This figure compares the performance of semantic segmentation models using two different decoder heads: a complex UperNet with 13 million parameters and a simple linear layer with only 0.2 million parameters.  Both models share the same backbone network. The x-axis represents the patch size used in the model, showing the results as the patch size decreases from 16x16 to 2x2. The y-axis represents the mean Intersection over Union (mIoU), a common metric for evaluating semantic segmentation accuracy. The results demonstrate that as the patch size decreases, the performance difference between the two decoder types diminishes, suggesting that the complex decoder becomes less crucial when using smaller patch sizes and the resulting increased level of detail. This implies that the additional complexity of the UperNet offers diminishing returns as the input's spatial resolution increases.", "section": "4. Main Results"}, {"figure_path": "https://arxiv.org/html/2502.03738/x12.png", "caption": "(a) Scaling from Adventurer-Base/16, 224\u00d7\\times\u00d7224 input.", "description": "This figure compares the impact of increasing model parameters versus reducing patch size on the performance of the Adventurer model for ImageNet classification.  The x-axis represents FLOPS (floating point operations per second), a measure of computational cost. The y-axis represents ImageNet top-1 accuracy.  Different colored lines represent models with varying parameter counts, showing the impact of simply increasing model size.  The lines with different patch sizes show how reducing the patch size (and therefore increasing the sequence length) impacts accuracy while controlling for model size. The figure demonstrates that reducing patch size consistently improves accuracy more effectively than increasing model size beyond a certain point.", "section": "4.3 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2502.03738/x13.png", "caption": "(b) Scaling form ViT-Base/16, 128\u00d7\\times\u00d7128 input.", "description": "This figure compares the impact of increasing model parameters versus decreasing patch size on the performance of a ViT-Base model with a 128x128 input image.  The x-axis represents FLOPs (floating-point operations), a measure of computational cost, and the y-axis represents ImageNet top-1 accuracy.  It shows that increasing model parameters leads to diminishing returns in accuracy after a certain point, while reducing patch size consistently improves accuracy.", "section": "4.3 Ablation Studies"}]