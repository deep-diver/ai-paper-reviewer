{"references": [{"fullname_first_author": "Dosovitskiy, A.", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduced the Vision Transformer (ViT), a foundational model for the current work, which is why it is considered among the most important."}, {"fullname_first_author": "Touvron, H.", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-00-00", "reason": "This paper introduced DeiT, a data-efficient training method for Vision Transformers, which is crucial for scaling experiments in the current work."}, {"fullname_first_author": "Kaplan, J.", "paper_title": "Scaling laws for neural language models", "publication_date": "2020-00-00", "reason": "This paper established scaling laws in language models, providing a theoretical framework for the scaling experiments conducted in this paper."}, {"fullname_first_author": "Wang, F.", "paper_title": "Mamba-R: Vision Mamba also needs registers", "publication_date": "2024-00-00", "reason": "This paper introduced the Adventurer model, an efficient architecture used extensively in the current work's experiments."}, {"fullname_first_author": "Dao, T.", "paper_title": "Transformers are ssms: Generalized models and efficient algorithms through structured state space duality", "publication_date": "2024-00-00", "reason": "This paper introduced the Mamba module, a key component of the Adventurer architecture, which is essential for achieving linear complexity in scaling experiments."}]}