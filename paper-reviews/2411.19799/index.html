<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge &#183; AI Paper Reviews by AI</title>
<meta name=title content="INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge &#183; AI Paper Reviews by AI"><meta name=description content="New multilingual LLM benchmark, INCLUDE, tackles regional knowledge gaps by using 197K QA pairs from 44 languages, improving cross-lingual evaluation."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ EPFL,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge"><meta property="og:description" content="New multilingual LLM benchmark, INCLUDE, tackles regional knowledge gaps by using 197K QA pairs from 44 languages, improving cross-lingual evaluation."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-29T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ EPFL"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/cover.png"><meta name=twitter:title content="INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge"><meta name=twitter:description content="New multilingual LLM benchmark, INCLUDE, tackles regional knowledge gaps by using 197K QA pairs from 44 languages, improving cross-lingual evaluation."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge","headline":"INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge","abstract":"New multilingual LLM benchmark, INCLUDE, tackles regional knowledge gaps by using 197K QA pairs from 44 languages, improving cross-lingual evaluation.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2411.19799\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2024","dateCreated":"2024-11-29T00:00:00\u002b00:00","datePublished":"2024-11-29T00:00:00\u002b00:00","dateModified":"2024-11-29T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ EPFL"],"mainEntityOfPage":"true","wordCount":"7526"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2411.19799/cover_hu9741768563798816362.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2411.19799/>INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span>7526 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">36 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2411.19799/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2411.19799/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-epfl/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ EPFL</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#multilingual-llm-gaps>Multilingual LLM Gaps</a></li><li><a href=#include-benchmark>INCLUDE Benchmark</a></li><li><a href=#regional-knowledge>Regional Knowledge</a></li><li><a href=#prompting-strategies>Prompting Strategies</a></li><li><a href=#future-directions>Future Directions</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#multilingual-llm-gaps>Multilingual LLM Gaps</a></li><li><a href=#include-benchmark>INCLUDE Benchmark</a></li><li><a href=#regional-knowledge>Regional Knowledge</a></li><li><a href=#prompting-strategies>Prompting Strategies</a></li><li><a href=#future-directions>Future Directions</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2411.19799</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Angelika Romanou et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-12-03</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2411.19799 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2411.19799 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/include-evaluating-multilingual-language target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2411.19799/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large language models (LLMs) show performance disparities across languages, hindering their deployment in many regions. This is largely due to a <strong>lack of high-quality evaluation resources</strong> in low-resource languages and the <strong>neglect of regional and cultural nuances</strong> in benchmark creation. Current benchmarks often translate from English, ignoring cultural contexts.</p><p>To address this, the researchers created INCLUDE, a multilingual benchmark comprising <strong>197,243 question-answer pairs</strong> from diverse exams across <strong>44 languages</strong>. INCLUDE tests LLMs&rsquo; knowledge and reasoning abilities in various regional settings, using questions from educational and professional exams, thus evaluating performance in their intended environments. The <strong>release of INCLUDE</strong> provides a crucial resource for researchers and developers in the field.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-3618028b6284ec285f5b2b57c341e925></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-3618028b6284ec285f5b2b57c341e925",{strings:[" The INCLUDE benchmark offers a large-scale, comprehensive evaluation suite for multilingual LLMs, addressing the lack of high-quality resources in many languages. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-c2d8c72c0b0f6e9e58b424f1f264207a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-c2d8c72c0b0f6e9e58b424f1f264207a",{strings:[" INCLUDE effectively measures LLMs' capabilities in various regional contexts, going beyond simple translation by incorporating regional and cultural knowledge. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-6c30c6de096809c1e705eeff26b385e5></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-6c30c6de096809c1e705eeff26b385e5",{strings:[" The findings highlight significant performance variations across languages and models, revealing the need for further development of multilingual LLMs and prompting strategies. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial because <strong>it addresses the critical gap in multilingual LLM evaluation</strong>. Existing benchmarks often lack high-quality resources and ignore regional knowledge. This work provides a valuable, large-scale, multilingual benchmark (INCLUDE) to evaluate LLMs&rsquo; performance in real-world language environments, significantly advancing research in this area and fostering equitable AI development.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/main_figure.png alt></figure></p><blockquote><p>üîº Figure 1(a) illustrates the importance of incorporating cultural and regional knowledge into multilingual benchmarks for evaluating large language models (LLMs). It highlights how the same question, when posed in different languages, can require different contextual understandings due to variations in regional laws, cultural norms, or historical contexts. This highlights the need for more representative and nuanced evaluation datasets. Figure 1(b) shows the structure of the INCLUDE benchmark, which addresses these issues by compiling questions from a wide range of academic exams, professional certification tests, and occupational licensing examinations. This diverse dataset covers 44 languages, ensuring that regional and cultural knowledge are accurately reflected in the evaluation of multilingual LLMs.</p><details><summary>read the caption</summary>Figure 1: Overview of Include. (a) Motivation: Multilingual benchmarks must reflect the cultural and regional knowledge of the language environments in which they would used. (b) Include is a multilingual benchmark compiled from academic, professional, and occupational license examinations reflecting regional and cultural knowledge in 44 languages.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th></th><th>Include-lite</th><th></th><th></th><th></th><th>Include-base</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>#</td><td>Langs</td><td>IL Prompt</td><td>Eng. Prompt</td><td>Reg. + IL Prompt</td><td>Reg. + Eng. Prompt</td><td>IL Prompt</td><td>Eng. Prompt</td><td>Reg. + IL Prompt</td><td>Reg. + Eng. Prompt</td></tr><tr><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td></tr><tr><td><strong>GPT-4o</strong></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td></td><td>77.1</td><td>76.2</td><td>76.3</td><td>76.3</td><td>77.3</td><td>76.3</td><td>76.2</td><td>76.2</td><td></td></tr><tr><td>- Zero-shot CoT</td><td></td><td><strong>78.2</strong></td><td><strong>78.4</strong></td><td><strong>77.7</strong></td><td><strong>77.8</strong></td><td><strong>79.0</strong></td><td><strong>78.9</strong></td><td><strong>77.6</strong></td><td><strong>78.5</strong></td><td></td></tr><tr><td><strong>Llama-3.1-70B-Inst.</strong></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td></td><td>70.5</td><td>70.4</td><td>70.6</td><td>70.6</td><td>70.6</td><td>70.7</td><td>70.6</td><td>70.6</td><td></td></tr><tr><td>- Zero-shot CoT</td><td></td><td>60.6</td><td>55.3</td><td>60.2</td><td>55.4</td><td>60.6</td><td>56.0</td><td>60.6</td><td>55.6</td><td></td></tr><tr><td><strong>Aya-expanse-32B</strong></td><td>23</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td></td><td>52.6</td><td>57.2</td><td>49.0</td><td>60.0</td><td>52.4</td><td>56.6</td><td>49.7</td><td>60.0</td><td></td></tr><tr><td>- Zero-shot CoT</td><td></td><td>50.6</td><td>57.1</td><td>52.5</td><td>58.0</td><td>51.4</td><td>57.7</td><td>52.9</td><td>57.8</td><td></td></tr><tr><td><strong>Qwen2.5-14B</strong></td><td>22</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td></td><td>60.9</td><td>61.3</td><td>60.9</td><td>60.8</td><td>61.4</td><td>61.7</td><td>61.1</td><td>61.0</td><td></td></tr><tr><td>- Zero-shot CoT</td><td></td><td>46.8</td><td>50.7</td><td>46.5</td><td>51.4</td><td>47.3</td><td>51.0</td><td>47.1</td><td>51.6</td><td></td></tr><tr><td>[]cdashline1-10<strong>Aya-expanse-8B</strong></td><td>23</td><td>37.6</td><td>46.3</td><td>38.1</td><td>48.0</td><td>37.2</td><td>46.0</td><td>37.9</td><td>47.8</td><td></td></tr><tr><td><strong>Mistral-7B (v0.3)</strong></td><td>-</td><td>44.0</td><td>45.0</td><td>44.0</td><td>45.2</td><td>43.3</td><td>44.9</td><td>43.8</td><td>45.0</td><td></td></tr><tr><td><strong>Mistral-7B-Inst. (v0.3)</strong></td><td>-</td><td>43.5</td><td>44.6</td><td>44.2</td><td>44.7</td><td>43.6</td><td>44.5</td><td>44.2</td><td>44.7</td><td></td></tr><tr><td><strong>Gemma-7B</strong></td><td>-</td><td>54.4</td><td>54.9</td><td>54.3</td><td>54.9</td><td>54.5</td><td>54.9</td><td>54.2</td><td>54.7</td><td></td></tr><tr><td><strong>Gemma-7B-Inst.</strong></td><td>-</td><td>39.2</td><td>40.2</td><td>38.7</td><td>39.7</td><td>38.7</td><td>39.7</td><td>38.1</td><td>39.2</td><td></td></tr><tr><td><strong>Qwen2.5-7B</strong></td><td>22</td><td>53.4</td><td>54.8</td><td>53.3</td><td>54.2</td><td>54.1</td><td>55.2</td><td>54.0</td><td>54.5</td><td></td></tr><tr><td><strong>Qwen2.5-7B-Inst.</strong></td><td>22</td><td>53.4</td><td>54.2</td><td>52.8</td><td>53.7</td><td>53.8</td><td>54.6</td><td>53.2</td><td>53.9</td><td></td></tr><tr><td><strong>Llama-3.1-8B</strong></td><td>-</td><td>50.9</td><td>52.3</td><td>50.9</td><td>51.9</td><td>51.0</td><td>51.8</td><td>51.0</td><td>51.6</td><td></td></tr><tr><td><strong>Llama-3.1-8B-Inst.</strong></td><td>-</td><td>53.4</td><td>54.8</td><td>52.7</td><td>53.4</td><td>53.4</td><td>54.6</td><td>53.0</td><td>54.4</td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of evaluating various large language models (LLMs) on two subsets of the INCLUDE benchmark: INCLUDE-LITE and INCLUDE-BASE. The evaluation measures the models&rsquo; accuracy across 44 languages under four prompting conditions: in-language prompts (IL), English prompts (Eng.), in-language prompts with a regional prefix (Reg.+IL), and English prompts with a regional prefix (Reg.+Eng.). The table also indicates the number of languages each model explicitly reports having been pre-trained on.</p><details><summary>read the caption</summary>Table 1: Results on Include-lite and Include-base. In-language Prompt (IL) reports model accuracy when the prompt instructions are presented in the same language as the sample. English Prompt (Eng.) reports model accuracy when the prompt instructions are provided in English. In-language Regional Prompt (Reg. + IL) reports model accuracy when a regional prefix is added to the In-language Prompt. English Regional Prompt (Reg. + Eng.) reports model accuracy when a regional prefix is added to the English Prompt. # Langs reports the number of languages from Include publicly reported to be intentionally included in the pretraining data of each model.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Multilingual LLM Gaps<div id=multilingual-llm-gaps class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#multilingual-llm-gaps aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Multilingual LLM Gaps&rdquo; highlights the significant disparities in performance between large language models (LLMs) across different languages. <strong>These gaps aren&rsquo;t merely technical limitations; they reflect deep-seated biases and inequalities in the data used to train these models.</strong> The overrepresentation of high-resource languages like English creates a feedback loop: models perform well on English, leading to further development focused on it, while low-resource languages are neglected. This disparity <strong>exacerbates existing digital divides</strong>, hindering access to beneficial AI technologies for speakers of low-resource languages. Furthermore, the methods used to create multilingual benchmarks often rely on translation from high-resource languages, failing to capture the nuances of regional and cultural contexts. <strong>Addressing these gaps requires a multifaceted approach.</strong> This includes actively developing high-quality evaluation resources in diverse languages, employing data collection techniques that are more inclusive and representative, and designing more culturally sensitive benchmarks that account for regional knowledge. <strong>Only with concerted effort to mitigate these biases can we ensure fair and equitable access to the benefits of advanced LLMs for all.</strong></p><h4 class="relative group">INCLUDE Benchmark<div id=include-benchmark class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#include-benchmark aria-label=Anchor>#</a></span></h4><p>The INCLUDE benchmark is a significant contribution to multilingual language understanding evaluation. Its strength lies in its <strong>comprehensive nature</strong>, encompassing a large number of multiple-choice questions across 44 languages, derived from diverse sources including academic exams and professional certifications. This broad scope allows for a nuanced understanding of model performance, going beyond simple translation tasks and assessing proficiency in real-world language use. Furthermore, <strong>INCLUDE&rsquo;s focus on regional knowledge</strong> is crucial, as it directly addresses the limitations of existing benchmarks that often lack cultural and contextual awareness. By including questions that require regional understanding, INCLUDE offers a more equitable and comprehensive evaluation framework that better reflects the diversity and challenges of real-world applications of multilingual LLMs. The benchmark&rsquo;s impact is magnified by its public release, which will facilitate further research and development in this critical area. However, the <strong>reliance on existing benchmarks</strong> for a portion of the data, while acknowledging and accounting for dataset contamination, may necessitate further analysis to ensure complete independence and unbiased evaluation.</p><h4 class="relative group">Regional Knowledge<div id=regional-knowledge class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#regional-knowledge aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Regional Knowledge&rdquo; in the context of multilingual large language models (LLMs) is crucial. The paper highlights how <strong>current LLMs often struggle with questions requiring regional knowledge</strong>, showcasing a significant performance gap across different languages. This gap stems from the fact that existing multilingual benchmarks often translate resources from high-resource languages like English, ignoring the unique cultural and regional nuances of other environments. This underscores the <strong>importance of using locally sourced, high-quality evaluation resources to accurately measure LLM performance</strong>. The authors stress that benchmarks must <strong>reflect actual language usage scenarios</strong> to address the limitations of translating existing resources, which can lead to biases and inaccuracies. Creating evaluations based on regional contexts is essential for equitable and effective LLM deployment, <strong>reducing the digital divide</strong> and fostering a more inclusive development of AI tools.</p><h4 class="relative group">Prompting Strategies<div id=prompting-strategies class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#prompting-strategies aria-label=Anchor>#</a></span></h4><p>Prompting strategies in large language model (LLM) evaluation are crucial for uncovering valuable insights into model capabilities and limitations. <strong>Effective prompting techniques</strong> can significantly influence the performance of LLMs across diverse tasks and languages. The choice of prompting methods (e.g., zero-shot, few-shot, chain-of-thought) directly impacts the model&rsquo;s ability to generate accurate and coherent responses. <strong>In-language prompting</strong>, where instructions are provided in the native language of the task, often yields better results compared to using a common language like English, especially for tasks requiring regional or cultural knowledge. <strong>However, the use of a common language might help in scenarios with limited resources for specific languages</strong>. Investigating the impact of various prompting strategies on LLMs will reveal important information on how to develop and refine them. Further analysis might even explore the impact of incorporating regional contexts into the prompts to improve the performance on questions requiring such knowledge.</p><h4 class="relative group">Future Directions<div id=future-directions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-directions aria-label=Anchor>#</a></span></h4><p>Future research should prioritize expanding INCLUDE&rsquo;s language coverage to encompass more under-resourced languages and dialects, thereby reducing evaluation biases. <strong>Improving data collection methodology is vital</strong> to ensure accurate representation of regional knowledge, perhaps by refining the exam selection process and incorporating more rigorous quality control measures. Investigating the impact of various prompting strategies on model performance across languages and regions is crucial to optimize evaluation methodologies. <strong>A deeper investigation into why specific model architectures or training paradigms perform better on certain languages than others is warranted.</strong> This includes exploring factors like the size and diversity of training data, and the inherent linguistic properties of the languages themselves. Finally, understanding how to better incorporate cultural and regional context into the models&rsquo; training data is a key challenge that requires focused investigation, potentially through the development of innovative data augmentation techniques.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/descriptives.png alt></figure></p><blockquote><p>üîº Figure 2 shows the number of samples collected for each of the 15 scripts used in the INCLUDE benchmark. For each script, the figure displays the languages using that script, the total number of samples for that script, and the percentage of those samples that are from original, unpublished sources. This illustrates the diversity of languages and scripts included in the benchmark, as well as the proportion of novel data that was collected.</p><details><summary>read the caption</summary>Figure 2: Overview of the collected data grouped by script. We depict the languages associated with each script, the total samples in each script, and the percentage of the samples that were collected from new sources that have not been published by the community yet.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/knowledge_transfer.png alt></figure></p><blockquote><p>üîº This figure displays the performance of three large language models (LLMs) across different languages, categorized based on their relationship to the models&rsquo; training data. The x-axis represents the accuracy of each model on various languages, while the y-axis represents the languages. Languages are grouped into three categories: &lsquo;Trained on Language&rsquo; (languages explicitly included in the training data), &lsquo;Trained on Script&rsquo; (languages sharing the same script as languages in the training data), and &lsquo;Neither&rsquo; (languages not linguistically similar to those in the training data). The colored dotted lines show the average performance for each language category within each model, while the black dotted lines indicate the average performance across all languages that share a script.</p><details><summary>read the caption</summary>Figure 3: Performance of models stratified by language using in-language prompting. Results are grouped by whether the language was explicitly included in the pretraining dataset of the model (Trained on Language), whether a similar language with the same script was in the pretraining corpus (Trained on Script), or whether there was no linguistically similar language in the pretraining corpus (Neither). Color dotted lines represent average performance for each category for a particular model. Black dotted lines represent average performance across all script-aligned languages.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/regional_results.png alt></figure></p><blockquote><p>üîº This figure displays the performance of the GPT-40 language model on history-related questions from the INCLUDE benchmark. The questions are categorized into two types: regional history (cultural knowledge specific to a region) and global history (general historical knowledge). The results show that GPT-40 performs better on global history questions than on regional history questions, across most languages. This suggests that the model may struggle with questions requiring nuanced cultural knowledge specific to particular regions. The dataset included a total of 11,148 questions in this analysis.</p><details><summary>read the caption</summary>Figure 4: GPT-4o performance (In-language Prompt) on regional history exams (cultural) and global history exams from that region (region-implicit) based on a total of 11,148 questions from Include. In each language (except Telugu), models perform better on the global history exam than the regional history exam.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/languages.png alt></figure></p><blockquote><p>üîº This figure displays GPT-40&rsquo;s performance across various academic disciplines for six different languages: Korean, Persian, Armenian, Hindi, Greek, and Russian. Each bar graph represents a specific language and is further broken down by academic disciplines within that language. The height of each bar visually represents the model&rsquo;s accuracy (percentage of correctly answered questions) for that specific discipline within that language. The number of questions used to calculate the accuracy for each discipline is also indicated on each bar.</p><details><summary>read the caption</summary>Figure 5: GPT-4o performance across academic disciplines for Korean, Persian, Armenian, Hindi, Greek, and Russian. Each bar is annotated with the number of questions with correct answers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/regional_stem.png alt></figure></p><blockquote><p>üîº Figure 6 shows GPT-4&rsquo;s performance on the INCLUDE-BASE benchmark. Panel (a) compares performance across three question categories based on their regional knowledge dependence: region-agnostic (no regional knowledge needed), region-explicit (requiring specific regional knowledge), and region-implicit (regional knowledge potentially relevant but not explicitly required). The figure reveals that while performance is generally higher on explicit and implicit regional questions, this may be confounded by the fact that region-agnostic questions often involve STEM topics, which are known to be more challenging for LLMs. Panel (b) focuses specifically on STEM subjects and shows that the model&rsquo;s accuracy is particularly low for math and chemistry questions.</p><details><summary>read the caption</summary>Figure 6: GPT-4o model performance on Include-base. (a) Performance across regional labels. While models typically perform better across region-explicit and regional-implicit questions, it is difficult to disentangle the difficult of questions due to regionality from the subject matter itself (i.e., region-agnostic questions may contain more STEM subjects that are traditionally harder for LLMs). (b) Performance across academic disciplines within STEM area. We observe models perform particularly poorly on Math and Chemistry questions.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/Cat_A_Cat_B.png alt></figure></p><blockquote><p>üîº This figure provides a visual representation of the distribution of questions across different academic domains and fields within the INCLUDE benchmark. The figure uses a circular layout, with each academic area (e.g., Humanities, STEM, Social Sciences) represented as a section. Within each section, the different academic fields are further broken down and shown with the number of questions from that field. The size of each section and the visual representation of each field within it are scaled according to the number of questions in that area or field, offering a clear representation of the dataset&rsquo;s composition across various disciplines.</p><details><summary>read the caption</summary>Figure 7: Academic domain and academic fields with the number of examples across all languages.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/form.png alt></figure></p><blockquote><p>üîº This figure shows the Google Form used to solicit exam questions from the academic community to create the INCLUDE benchmark. The form requests details such as the name and description of the exam, the language used, URLs to the exam source, and a description of how the answers are provided. It specifically targets three types of exams: educational (high school, university), professional (law, medical licenses), and practical tests (driver&rsquo;s license). The form also collects additional metadata about the exam, such as the approximate number of questions and their format.</p><details><summary>read the caption</summary>Figure 8: Exam source collection form sent to the academic community.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19799/extracted/6034225/figures/original_published_scatter_all.png alt></figure></p><blockquote><p>üîº This figure visualizes the performance of various large language models (LLMs) on a multilingual question-answering benchmark. It compares the models&rsquo; accuracy across different languages, offering insights into their cross-lingual capabilities. Panel (a) focuses on a single model&rsquo;s accuracy across multiple languages, while panel (b) displays multiple models&rsquo; accuracy in a single language. This dual perspective helps analyze both the strengths and weaknesses of individual models and the overall challenges of multilingual language understanding.</p><details><summary>read the caption</summary>Figure 9: Accuracy of different models on languages where both existing benchmark data and newly collected data are available. Each point represents the accuracy score of a model for a specific language. (a) Points of the same color represent the accuracy scores of a single model across different languages. (b) Points of the same color represent the accuracy scores for a single language across different models.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Humanities</th><th>STEM</th><th>Domain-Specific</th><th>Professional</th><th>Licenses</th></tr></thead><tbody><tr><td># samples</td><td>13294</td><td>2478</td><td>1964</td><td>3165</td><td>1736</td></tr><tr><td><strong>GPT-4o</strong></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>79.0</td><td>74.2</td><td>76.8</td><td>70.1</td><td>82.1</td></tr><tr><td>- Zero-shot CoT</td><td>79.9</td><td>78.6</td><td>80.4</td><td>73.8</td><td>81.1</td></tr><tr><td><strong>Llama-3.1-70B-Instruct</strong></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>71.2</td><td>69.9</td><td>74.2</td><td>64.4</td><td>73.7</td></tr><tr><td>- Zero-shot CoT</td><td>61.9</td><td>57.5</td><td>63.5</td><td>56.7</td><td>58.4</td></tr><tr><td><strong>Aya-expanse-32B</strong></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>49.6</td><td>43.0</td><td>49.1</td><td>34.7</td><td>49.5</td></tr><tr><td>- Zero-shot CoT</td><td>52.9</td><td>47.8</td><td>55.4</td><td>44.3</td><td>52.9</td></tr><tr><td><strong>Qwen2.5-14B</strong></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>61.4</td><td>60.9</td><td>66.0</td><td>57.1</td><td>65.1</td></tr><tr><td>- Zero-shot CoT</td><td>48.6</td><td>44.4</td><td>51.6</td><td>41.6</td><td>46.9</td></tr><tr><td><strong>Aya-expanse-8B</strong></td><td>37.8</td><td>32.3</td><td>37.3</td><td>40.2</td><td>29.7</td></tr><tr><td><strong>Mistral-7B (v0.3)</strong></td><td>44.2</td><td>43.4</td><td>43.9</td><td>38.6</td><td>44.3</td></tr><tr><td><strong>Mistral-7B-Instruct (v0.3)</strong></td><td>44.5</td><td>42.7</td><td>43.2</td><td>40.1</td><td>43.7</td></tr><tr><td><strong>Gemma-7B</strong></td><td>55.1</td><td>53.6</td><td>55.5</td><td>47.7</td><td>62.2</td></tr><tr><td><strong>Gemma-7B-Instruct</strong></td><td>38.6</td><td>37.7</td><td>42.0</td><td>34.5</td><td>44.9</td></tr><tr><td><strong>Qwen2.5-7B</strong></td><td>53.4</td><td>54.2</td><td>59.1</td><td>51.3</td><td>57.8</td></tr><tr><td><strong>Qwen2.5-7B-Instruct</strong></td><td>53.5</td><td>53.3</td><td>58.1</td><td>49.5</td><td>58.6</td></tr><tr><td><strong>Llama-3-8B</strong></td><td>51.7</td><td>49.8</td><td>52.1</td><td>43.4</td><td>51.3</td></tr><tr><td><strong>Llama-3-8B-Instruct</strong></td><td>50.7</td><td>46.9</td><td>52.9</td><td>44.3</td><td>54.4</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the accuracy scores achieved by the GPT-40 language model across different categories of questions from the INCLUDE benchmark dataset. The questions are grouped into high-level topics: Humanities (encompassing Social Sciences, Humanities, and General Knowledge), STEM (including Applied Sciences and STEM fields), Domain-Specific (covering Business & Commerce and Health-oriented education), Professional (including professional certifications), and Licenses (including Marine, Fishing, and Driving licenses). The table shows the model&rsquo;s performance in each topic area, offering insight into its strengths and weaknesses across various question types and knowledge domains. Note that the &lsquo;In-language prompting&rsquo; condition is implied, as specified in the table&rsquo;s caption.</p><details><summary>read the caption</summary>Table 2: Accuracy performance of GPT-4o (In-language prompting) on Include-base grouped by high-level topics. Where Humanities include Social Science, Humanities, and General knowledge. STEM includes Applied Science and STEM. Domain-specific covers Business & Commerce and Health oriented education. Professional includes professional certifications. Licenses cover Marine, Fishing, and Driving licenses.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>In-language Prompt</th><th></th><th></th><th>English Prompt</th><th></th><th></th></tr></thead><tbody><tr><td></td><td><strong>Total Acc.</strong></td><td><strong>Answer Acc.</strong></td><td><strong>Format Errors (%)</strong></td><td><strong>Total Acc.</strong></td><td><strong>Answer Acc.</strong></td><td><strong>Format Errors (%)</strong></td></tr><tr><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td><td>&mdash;</td></tr><tr><td><strong>GPT-4o</strong></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>77.3</td><td>79.0</td><td>2.5</td><td>76.3</td><td>78.0</td><td>2.2</td></tr><tr><td>- Zero-shot CoT</td><td>79.0</td><td>79.2</td><td>0.2</td><td>78.9</td><td>79.1</td><td>0.2</td></tr><tr><td><strong>Llama-3.1-70B-Instruct</strong></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>70.6</td><td>70.6</td><td>0.0</td><td>70.7</td><td>70.7</td><td>0.0</td></tr><tr><td>- Zero-shot CoT</td><td>60.6</td><td>67.9</td><td>10.9</td><td>56.3</td><td>67.8</td><td>17.0</td></tr><tr><td><strong>Aya-expanse-32B</strong></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>52.4</td><td>56.2</td><td>16.9</td><td>56.6</td><td>62.7</td><td>9.7</td></tr><tr><td>- Zero-shot CoT</td><td>51.4</td><td>57.2</td><td>10.2</td><td>57.7</td><td>58.4</td><td>1.1</td></tr><tr><td><strong>Qwen2.5-14B</strong></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>- 5-shot</td><td>61.4</td><td>62.4</td><td>1.5</td><td>61.7</td><td>61.7</td><td>0.0</td></tr><tr><td>- Zero-shot CoT</td><td>47.3</td><td>53.1</td><td>10.9</td><td>51.0</td><td>52.0</td><td>1.9</td></tr><tr><td>\cdashline1-7 <strong>Aya-expanse-8B</strong></td><td>37.2</td><td>43.8</td><td>18.0</td><td>46.0</td><td>50.7</td><td>9.2</td></tr><tr><td><strong>Mistral-7B (v0.3)</strong></td><td>43.3</td><td>43.3</td><td>0.0</td><td>44.9</td><td>44.9</td><td>0.0</td></tr><tr><td><strong>Mistral-7B-Instruct (v0.3)</strong></td><td>43.6</td><td>43.8</td><td>0.4</td><td>44.5</td><td>44.5</td><td>0.1</td></tr><tr><td><strong>Gemma-7B</strong></td><td>54.5</td><td>54.5</td><td>0.0</td><td>54.9</td><td>54.9</td><td>0.0</td></tr><tr><td><strong>Gemma-7B-Instruct</strong></td><td>38.7</td><td>38.7</td><td>0.0</td><td>39.7</td><td>39.7</td><td>0.1</td></tr><tr><td><strong>Qwen2.5-7B</strong></td><td>54.1</td><td>55.1</td><td>1.9</td><td>55.2</td><td>55.2</td><td>0.0</td></tr><tr><td><strong>Qwen2.5-7B-Instruct</strong></td><td>53.8</td><td>54.0</td><td>0.5</td><td>54.6</td><td>54.6</td><td>0.0</td></tr><tr><td><strong>Llama-3.1-8B</strong></td><td>51.0</td><td>51.0</td><td>0.0</td><td>51.8</td><td>51.8</td><td>0.0</td></tr><tr><td><strong>Llama-3.1-8B-Instruct</strong></td><td>53.4</td><td>53.4</td><td>0.0</td><td>54.6</td><td>54.6</td><td>0.0</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a detailed performance analysis of various large language models (LLMs) on the INCLUDE benchmark. It breaks down the accuracy into three key metrics: Total Accuracy (overall accuracy, including formatting errors), Answer Accuracy (accuracy considering only correctly formatted answers), and Formatting Errors (percentage of incorrectly formatted responses). By separating correctly formatted answers from those with formatting issues, the table provides a nuanced view of model performance, distinguishing between true comprehension failures and problems with output formatting. The analysis is further broken down by whether prompts were given in the native language or in English, offering insights into the effect of prompting language on both the raw accuracy and the ability of the model to produce correctly formatted outputs.</p><details><summary>read the caption</summary>Table 3: Results on Include-base for In-language and English prompting strategies. Total Accuracy represents the raw accuracy of the model for answering Include questions in each respective subset. Answer Accuracy represents the accuracy of the model when only considering samples where an answer is extracted from the model‚Äôs output in the correct response format. Formatting Errors (%) describes the percentage of model responses that are not formatted correctly and so do not output any answer option. We mark these incorrect by default in Total Accuracy and do not include them when computing Answer Accuracy.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Include-lite</th><th></th><th>Include-base</th><th></th></tr></thead><tbody><tr><td></td><td>In-Language Prompt</td><td>English Prompt</td><td>In-Language Prompt</td><td>English Prompt</td></tr><tr><td><strong>Llama3.1-70B-Instruct</strong></td><td>70.3</td><td>70.6</td><td>70.6</td><td>70.9</td></tr><tr><td><strong>Aya-expanse-32B</strong></td><td>58.9</td><td>59.5</td><td>47.2</td><td>47.8</td></tr><tr><td><strong>Qwen2.5-14B</strong></td><td>61.8</td><td>61.9</td><td>62.3</td><td>62.6</td></tr><tr><td><strong>Aya-expanse-8B</strong></td><td>47.3</td><td>48.0</td><td>47.2</td><td>47.8</td></tr><tr><td><strong>Mistral-7B</strong></td><td>44.5</td><td>44.7</td><td>44.1</td><td>44.6</td></tr><tr><td><strong>Mistral-7B-Instruct</strong></td><td>43.8</td><td>43.9</td><td>44.2</td><td>44.3</td></tr><tr><td><strong>Gemma-7B</strong></td><td>53.6</td><td>53.1</td><td>53.5</td><td>53.2</td></tr><tr><td><strong>Gemma-7B-Instruct</strong></td><td>39.1</td><td>39.7</td><td>38.6</td><td>39.3</td></tr><tr><td><strong>Qwen2.5-7B</strong></td><td>54.4</td><td>54.9</td><td>55.0</td><td>55.5</td></tr><tr><td><strong>Qwen2.5-7B-Instruct</strong></td><td>54.5</td><td>54.6</td><td>54.8</td><td>54.8</td></tr><tr><td><strong>Llama-3.1-8B</strong></td><td>51.2</td><td>52.1</td><td>51.2</td><td>51.9</td></tr><tr><td><strong>Llama-3.1-8B-Instruct</strong></td><td>53.5</td><td>54.4</td><td>53.5</td><td>54.4</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of evaluating various large language models using the Harness-Eval framework on the INCLUDE-BASE benchmark. It shows the performance of each model, broken down by prompting type (in-language and English) for both INCLUDE-LITE and INCLUDE-BASE subsets. This allows for a comparison of model performance across different language settings and resource constraints.</p><details><summary>read the caption</summary>Table 4: Harness evaluation results on Include-base.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th><strong>Academic area</strong></th><th><strong>Academic field</strong></th><th><strong>Label</strong></th></tr></thead><tbody><tr><td>Humanities</td><td>Logic</td><td>Agnostic</td></tr><tr><td></td><td>Law</td><td>Region Explicit</td></tr><tr><td></td><td>Language</td><td>Culture</td></tr><tr><td></td><td>Visual Arts, History, Philosophy, Religious studies, Performing arts, Culturology, Literature</td><td>Region implicit/ Culture</td></tr><tr><td>Social Science</td><td>Sociology, Political sciences, Anthropology</td><td>Region implicit/Culture</td></tr><tr><td></td><td>Economics</td><td>Region implicit/Agnostic/Region explicit</td></tr><tr><td></td><td>Psychology</td><td>Region implicit/Region explicit</td></tr><tr><td></td><td>Geography</td><td>Region implicit/Agnostic</td></tr><tr><td>STEM</td><td>Math, Physics, CS, Biology, Earth science, Chemistry, Engineering</td><td>Agnostic</td></tr><tr><td></td><td>Qualimetry</td><td>Region explicit</td></tr><tr><td>Health oriented education</td><td>Medicine</td><td>Agnostic/Region implicit/Region explicit</td></tr><tr><td></td><td>Health</td><td>Region implicit/Region explicit</td></tr><tr><td>Business and Commerce</td><td>Accounting</td><td>Region explicit</td></tr><tr><td></td><td>Management, Marketing, Industrial and labor relations, International trade, Risk management and insurance, Business administration, Business ethics, Business, Finance</td><td>Region implicit/Region explicit/Agnostic</td></tr><tr><td>Applied Science</td><td>Agriculture, Library and museum studies, Transportation</td><td>Region implicit/Agnostic</td></tr><tr><td></td><td>Military Sciences, Public Administration, Public Policy</td><td>Region implicit/Region explicit</td></tr><tr><td></td><td>Architecture and Design, Family and consumer science, Environmental studies and forestry, Education</td><td></td></tr><tr><td>Journalism, media studies, and communication, Social Work, Human physical performance and recreation</td><td>Region implicit</td><td></td></tr><tr><td>Other</td><td>Driving license, Marine license, Fishing license, Medical license, Public administration, Professional certification</td><td>Region explicit</td></tr><tr><td>General knowledge</td><td>Multiple exams</td><td>Region implicit/Culture</td></tr></tbody></table></table></figure><blockquote><p>üîº This table details the annotation schema used to categorize the exams included in the INCLUDE benchmark. It maps high-level academic areas (like Humanities or STEM) to more specific academic fields (e.g., History, Biology). Critically, it also assigns a regionality label to each exam, indicating whether the knowledge required to answer the questions is region-agnostic (doesn&rsquo;t require regional knowledge), culture-related (requires cultural understanding of a region), region-explicit (explicitly requires knowledge about laws or regulations specific to a region), or region-implicit (implicitly relies on regional context). While the table shows the most frequent regionality label for each exam, it&rsquo;s important to note that each exam in the dataset was individually labeled with one of these four regionality categories.</p><details><summary>read the caption</summary>Table 5: Annotation schema for high-level Academic area and fine-grained Academic field. The Label column lists the most likely regionality label for these exams in our dataset (e.g., region-{agnostic, implicit, explicit} or cultural), though all exams from which we collect data are individually labeled with a regionality category. The first label is the most frequent one.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><p>| Language | Academic
Humanities | Academic
STEM studies | Academic
Domain-specific</p><table><thead><tr><th>studi es</th><th>Professional</th><th>License</th><th>Avg (%)</th><th></th><th></th><th></th></tr></thead><tbody><tr><td><strong>Albanian</strong></td><td>95.0</td><td>88.0</td><td>83.5</td><td>-</td><td>-</td><td>89.50</td></tr><tr><td><strong>Arabic</strong></td><td>77.8</td><td>82.0</td><td>80.5</td><td>-</td><td>76.2</td><td>78.30</td></tr><tr><td><strong>Armenian</strong></td><td>52.7</td><td>32.0</td><td>-</td><td>-</td><td>72.2</td><td>53.60</td></tr><tr><td><strong>Azerbaijani</strong></td><td>71.3</td><td>73.6</td><td>71.4</td><td>-</td><td>-</td><td>71.90</td></tr><tr><td><strong>Basque</strong></td><td>-</td><td>-</td><td>-</td><td>64.8</td><td>-</td><td>64.80</td></tr><tr><td><strong>Belarusian</strong></td><td>51.8</td><td>42.0</td><td>-</td><td>-</td><td>-</td><td>50.90</td></tr><tr><td><strong>Bengali</strong></td><td>71.1</td><td>90.0</td><td>-</td><td>84.3</td><td>-</td><td>76.80</td></tr><tr><td><strong>Bulgarian</strong></td><td>93.8</td><td>60.0</td><td>-</td><td>-</td><td>-</td><td>90.70</td></tr><tr><td><strong>Chinese</strong></td><td>71.5</td><td>66.7</td><td>58.2</td><td>52.1</td><td>84.5</td><td>66.10</td></tr><tr><td><strong>Croatian</strong></td><td>89.0</td><td>82.0</td><td>-</td><td>-</td><td>-</td><td>88.40</td></tr><tr><td><strong>Dutch; Flemish</strong></td><td>86.6</td><td>87.5</td><td>80.0</td><td>-</td><td>-</td><td>86.40</td></tr><tr><td><strong>Estonian</strong></td><td>90.7</td><td>98.0</td><td>100.0</td><td>-</td><td>-</td><td>92.40</td></tr><tr><td><strong>Finnish</strong></td><td>67.0</td><td>87.0</td><td>77.8</td><td>-</td><td>-</td><td>69.90</td></tr><tr><td><strong>French</strong></td><td>83.8</td><td>50.0</td><td>81.2</td><td>-</td><td>68.1</td><td>80.70</td></tr><tr><td><strong>Georgian</strong></td><td>87.6</td><td>-</td><td>-</td><td>-</td><td>-</td><td>87.60</td></tr><tr><td><strong>German</strong></td><td>62.6</td><td>64.0</td><td>-</td><td>-</td><td>87.0</td><td>66.90</td></tr><tr><td><strong>Greek</strong></td><td>84.7</td><td>84.0</td><td>89.2</td><td>58.6</td><td>-</td><td>71.50</td></tr><tr><td><strong>Hebrew</strong></td><td>62.0</td><td>-</td><td>-</td><td>-</td><td>88.6</td><td>86.20</td></tr><tr><td><strong>Hindi</strong></td><td>77.7</td><td>71.9</td><td>91.5</td><td>71.8</td><td>57.7</td><td>75.10</td></tr><tr><td><strong>Hungarian</strong></td><td>66.3</td><td>80.6</td><td>-</td><td>-</td><td>-</td><td>75.80</td></tr><tr><td><strong>Indonesian</strong></td><td>84.0</td><td>69.1</td><td>-</td><td>84.8</td><td>-</td><td>79.50</td></tr><tr><td><strong>Italian</strong></td><td>87.7</td><td>87.2</td><td>91.7</td><td>95.5</td><td>-</td><td>90.00</td></tr><tr><td><strong>Japanese</strong></td><td>-</td><td>-</td><td>-</td><td>78.1</td><td>96.0</td><td>81.60</td></tr><tr><td><strong>Kazakh</strong></td><td>80.4</td><td>-</td><td>-</td><td>-</td><td>-</td><td>80.40</td></tr><tr><td><strong>Korean</strong></td><td>91.6</td><td>-</td><td>-</td><td>46.4</td><td>-</td><td>69.00</td></tr><tr><td><strong>Lithuanian</strong></td><td>92.0</td><td>97.1</td><td>82.5</td><td>81.2</td><td>-</td><td>90.60</td></tr><tr><td><strong>Malay</strong></td><td>84.5</td><td>-</td><td>80.3</td><td>-</td><td>-</td><td>83.00</td></tr><tr><td><strong>Malayalam</strong></td><td>69.6</td><td>66.0</td><td>55.0</td><td>-</td><td>80.9</td><td>70.80</td></tr><tr><td><strong>Nepali</strong></td><td>-</td><td>-</td><td>-</td><td>61.6</td><td>83.2</td><td>72.40</td></tr><tr><td><strong>Macedonian</strong></td><td>96.0</td><td>86.0</td><td>89.3</td><td>-</td><td>-</td><td>92.40</td></tr><tr><td><strong>Persian</strong></td><td>66.0</td><td>25.0</td><td>-</td><td>49.6</td><td>81.6</td><td>64.60</td></tr><tr><td><strong>Polish</strong></td><td>100.0</td><td>64.6</td><td>-</td><td>80.0</td><td>-</td><td>78.80</td></tr><tr><td><strong>Portuguese</strong></td><td>84.7</td><td>63.3</td><td>67.9</td><td>-</td><td>-</td><td>76.40</td></tr><tr><td><strong>Serbian</strong></td><td>92.2</td><td>86.0</td><td>-</td><td>-</td><td>-</td><td>91.60</td></tr><tr><td><strong>Spanish</strong></td><td>83.6</td><td>88.0</td><td>96.0</td><td>-</td><td>-</td><td>84.40</td></tr><tr><td><strong>Tagalog</strong></td><td>86.8</td><td>-</td><td>-</td><td>-</td><td>90.7</td><td>87.40</td></tr><tr><td><strong>Tamil</strong></td><td>70.6</td><td>54.0</td><td>-</td><td>-</td><td>-</td><td>69.10</td></tr><tr><td><strong>Telugu</strong></td><td>66.9</td><td>70.7</td><td>-</td><td>-</td><td>-</td><td>68.20</td></tr><tr><td><strong>Turkish</strong></td><td>62.0</td><td>52.0</td><td>75.9</td><td>-</td><td>-</td><td>65.30</td></tr><tr><td><strong>Ukrainian</strong></td><td>85.8</td><td>84.0</td><td>-</td><td>-</td><td>-</td><td>85.60</td></tr><tr><td><strong>Urdu</strong></td><td>61.7</td><td>65.3</td><td>100.0</td><td>-</td><td>-</td><td>62.50</td></tr><tr><td><strong>Uzbek</strong></td><td>63.6</td><td>84.0</td><td>-</td><td>73.3</td><td>-</td><td>69.70</td></tr><tr><td><strong>Vietnamese</strong></td><td>84.4</td><td>86.0</td><td>-</td><td>-</td><td>-</td><td>84.50</td></tr><tr><td><strong>Russian</strong></td><td>77.5</td><td>83.4</td><td>70.8</td><td>-</td><td>63.9</td><td>75.00</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of the GPT-40 language model on the INCLUDE benchmark dataset. For each of the 44 languages in the dataset, the accuracy of GPT-40 (using a 5-shot prompting technique) is shown across five categories of questions: Humanities (including Social Sciences and general knowledge), STEM (Science, Technology, Engineering, and Mathematics, including applied sciences), Domain-Specific (questions relating to Business & Commerce and health-oriented education), Professional (questions related to professional certifications), and Licenses (questions related to licenses such as Marine, Fishing and Driving). The percentages represent the accuracy achieved by the model for each language in each category.</p><details><summary>read the caption</summary>Table 6: Accuracy performance of GPT-4o (5-shot) on Include-base for each language. Humanities include Social Science, Humanities, and General knowledge. STEM includes Applied Science and STEM. Domain-specific covers Business & Commerce and Health oriented education. Professional includes professional certifications. Licenses cover Marine, Fishing, and Driving licenses.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Full Benchmark</th><th>Newly collected</th></tr></thead><tbody><tr><td><strong>Aya-expanse-8B</strong></td><td>0.02</td><td>0.01</td></tr><tr><td><strong>XGLM-7B</strong></td><td>0.17</td><td>0.14</td></tr><tr><td><strong>Qwen-2.5-7B</strong></td><td>0.13</td><td>0.11</td></tr><tr><td><strong>LLaMA-3.1-8B</strong></td><td>0.29</td><td>0.25</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the percentage of questions in the INCLUDE-BASE benchmark that were identified as potentially originating from the training data of various large language models (LLMs). It shows the contamination rates, indicating the degree to which each model&rsquo;s training data may overlap with the benchmark dataset. Lower percentages suggest less contamination, implying the benchmark is less likely to be biased by the models&rsquo; prior knowledge.</p><details><summary>read the caption</summary>Table 7: Data contamination rates per model on Include-base.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Script</th><th>Family</th><th>Branch</th><th>Availability</th><th>Count</th></tr></thead><tbody><tr><td>Albanian</td><td>latin</td><td>Indo-European</td><td>Albanian</td><td>Mid</td><td>2365</td></tr><tr><td>Amharic</td><td>ge‚Äôez</td><td>Afro-Asiatic</td><td>Semitic</td><td>Low</td><td>131</td></tr><tr><td>Arabic</td><td>perso-arabic</td><td>Afro-Asiatic</td><td>Semitic</td><td>High</td><td>15137</td></tr><tr><td>Armenian</td><td>armenian</td><td>Indo-European</td><td>Armenian</td><td>Low</td><td>1669</td></tr><tr><td>Assamese</td><td>bengali-assamese</td><td>Indo-European</td><td>Indo-Iranian</td><td>Low</td><td>323</td></tr><tr><td>Azerbaijani</td><td>latin</td><td>Turkic</td><td>Azerbaijani North</td><td>Mid</td><td>6937</td></tr><tr><td>Basque</td><td>latin</td><td>Isolate</td><td></td><td>Low</td><td>719</td></tr><tr><td>Belarusian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic East</td><td>Low</td><td>687</td></tr><tr><td>Bengali</td><td>bengali-assamese</td><td>Indo-European</td><td>Indo-Iranian</td><td>Mid</td><td>15259</td></tr><tr><td>Bulgarian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic South Eastern</td><td>Mid</td><td>2937</td></tr><tr><td>Chinese</td><td>chinese</td><td>Sino-Tibetan</td><td>Chinese</td><td>High</td><td>12977</td></tr><tr><td>Croatian</td><td>latin</td><td>Indo-European</td><td>Slavic South Western</td><td>Mid</td><td>2879</td></tr><tr><td>Czech</td><td>latin</td><td>Indo-European</td><td>Slavic West</td><td>High</td><td>50</td></tr><tr><td>Danish</td><td>latin</td><td>Indo-European</td><td>Germanic</td><td>Mid</td><td>732</td></tr><tr><td>Dutch; Flemish</td><td>latin</td><td>Indo-European</td><td>Germanic</td><td>High</td><td>2222</td></tr><tr><td>Estonian</td><td>latin</td><td>Uralic</td><td>Finnic</td><td>Mid</td><td>952</td></tr><tr><td>Finnish</td><td>latin</td><td>Uralic</td><td>Finnic</td><td>Mid</td><td>1574</td></tr><tr><td>French</td><td>latin</td><td>Indo-European</td><td>Italic</td><td>High</td><td>2457</td></tr><tr><td>Georgian</td><td>mkherduli</td><td>Kartvelian</td><td>Georgian</td><td>Low</td><td>599</td></tr><tr><td>German</td><td>latin</td><td>Indo-European</td><td>Germanic</td><td>High</td><td>1590</td></tr><tr><td>Greek</td><td>greek</td><td>Indo-European</td><td>Greek</td><td>Mid</td><td>6570</td></tr><tr><td>Hebrew</td><td>hebrew</td><td>Afro-Asiatic</td><td>Semitic</td><td>Mid</td><td>2457</td></tr><tr><td>Hindi</td><td>devanagari</td><td>Indo-European</td><td>Indo-Iranian</td><td>Mid</td><td>5167</td></tr><tr><td>Hungarian</td><td>latin</td><td>Uralic</td><td>Hungarian</td><td>Mid</td><td>2267</td></tr><tr><td>Indonesian</td><td>latin</td><td>Austronesian</td><td>Malayo-Polynesian</td><td>High</td><td>12013</td></tr><tr><td>Italian</td><td>latin</td><td>Indo-European</td><td>Italic</td><td>High</td><td>3038</td></tr><tr><td>Japanese</td><td>kanji</td><td>Japonic</td><td>Japanese</td><td>High</td><td>2699</td></tr><tr><td>Kannada</td><td>kannada</td><td>Dravidian</td><td>Southern</td><td>Low</td><td>335</td></tr><tr><td>Kazakh</td><td>cyrillic</td><td>Turkic</td><td>Western</td><td>Low</td><td>5736</td></tr><tr><td>Korean</td><td>hangul</td><td>Koreanic</td><td>Korean</td><td>Mid</td><td>1781</td></tr><tr><td>Lithuanian</td><td>latin</td><td>Indo-European</td><td>Eastern Baltic</td><td>Mid</td><td>1397</td></tr><tr><td>Malay</td><td>latin</td><td>Austronesian</td><td>Malayo-Polynesian</td><td>Mid</td><td>1021</td></tr><tr><td>Malayalam</td><td>vatteluttu</td><td>Dravidian</td><td>Southern</td><td>Low</td><td>275</td></tr><tr><td>Marathi</td><td>devanagari</td><td>Indo-European</td><td>Indo-Iranian</td><td>Mid</td><td>313</td></tr><tr><td>Nepali</td><td>devanagari</td><td>Indo-European</td><td>Indo-Iranian</td><td>Mid</td><td>1470</td></tr><tr><td>Macedonian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic South Eastern</td><td>Low</td><td>2075</td></tr><tr><td>Oriya</td><td>odia</td><td>Indo-European</td><td>Indo-Iranian</td><td>Low</td><td>241</td></tr><tr><td>Panjabi; Punjabi</td><td>gurmukhi</td><td>Indo-European</td><td>Indo-Iranian</td><td>Low</td><td>453</td></tr><tr><td>Persian</td><td>perso-arabic</td><td>Indo-European</td><td>Indo-Iranian</td><td>High</td><td>23990</td></tr><tr><td>Polish</td><td>latin</td><td>Indo-European</td><td>Slavic West</td><td>High</td><td>2023</td></tr><tr><td>Portuguese</td><td>latin</td><td>Indo-European</td><td>Italic</td><td>High</td><td>1407</td></tr><tr><td>Russian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic East</td><td>High</td><td>10169</td></tr><tr><td>Serbian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic South</td><td>Mid</td><td>1636</td></tr><tr><td>Sinhala; Sinhalese</td><td>sinhala</td><td>Indo-European</td><td>Indo-Iranian</td><td>Low</td><td>325</td></tr><tr><td>Slovak</td><td>latin</td><td>Indo-European</td><td>Slavic West</td><td>Mid</td><td>131</td></tr><tr><td>Spanish</td><td>latin</td><td>Indo-European</td><td>Italic</td><td>High</td><td>2559</td></tr><tr><td>Swedish</td><td>latin</td><td>Indo-European</td><td>Germanic</td><td>Mid</td><td>5102</td></tr><tr><td>Tagalog</td><td>latin</td><td>Austronesian</td><td>Malayo-Polynesian</td><td>Low</td><td>530</td></tr><tr><td>Tamil</td><td>tamil</td><td>Dravidian</td><td>Southern</td><td>Mid</td><td>945</td></tr><tr><td>Telugu</td><td>telugu</td><td>Dravidian</td><td>South-Central</td><td>Low</td><td>11568</td></tr><tr><td>Turkish</td><td>latin</td><td>Turkic</td><td>Southern</td><td>High</td><td>2710</td></tr><tr><td>Ukrainian</td><td>cyrillic</td><td>Indo-European</td><td>Slavic East</td><td>Mid</td><td>1482</td></tr><tr><td>Urdu</td><td>perso-arabic</td><td>Indo-European</td><td>Indo-Iranian</td><td>Low</td><td>122</td></tr><tr><td>Uzbek</td><td>latin</td><td>Turkic</td><td>Eastern</td><td>Low</td><td>2878</td></tr><tr><td>Vietnamese</td><td>latin</td><td>Austro-Asiatic</td><td>Mon-Khmer</td><td>High</td><td>8901</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists all 44 languages included in the INCLUDE benchmark dataset. For each language, it provides metadata including the script used, the language family and branch it belongs to, and its resource availability level (High, Mid, or Low). Finally, it indicates the total number of samples available for each language within the dataset.</p><details><summary>read the caption</summary>Table 8: Languages in Include with their associated metadata and the total count of the samples per language.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Academic Area</th><th>Accuracy</th><th>Count</th></tr></thead><tbody><tr><td><strong>Albanian</strong></td><td>Humanities</td><td>95.1</td><td>223</td></tr><tr><td></td><td>Business & Commerce</td><td>85.7</td><td>223</td></tr><tr><td></td><td>Social Science</td><td>94.5</td><td>55</td></tr><tr><td><strong>Arabic</strong></td><td>Humanities</td><td>79.0</td><td>105</td></tr><tr><td></td><td>Business & Commerce</td><td>79.3</td><td>82</td></tr><tr><td></td><td>General Knowledge</td><td>86.7</td><td>105</td></tr><tr><td></td><td>Other</td><td>76.2</td><td>105</td></tr><tr><td></td><td>STEM</td><td>82.0</td><td>50</td></tr><tr><td></td><td>Social Science</td><td>67.6</td><td>105</td></tr><tr><td><strong>Armenian</strong></td><td>Humanities</td><td>34.7</td><td>225</td></tr><tr><td></td><td>Other</td><td>72.2</td><td>79</td></tr><tr><td></td><td>STEM</td><td>28.0</td><td>50</td></tr><tr><td></td><td>Social Science</td><td>50.5</td><td>196</td></tr><tr><td><strong>Azerbaijani</strong></td><td>Applied Science</td><td>75.9</td><td>108</td></tr><tr><td></td><td>Humanities</td><td>74.1</td><td>108</td></tr><tr><td></td><td>Business & Commerce</td><td>62.5</td><td>96</td></tr><tr><td></td><td>Health-Oriented Education</td><td>80.2</td><td>96</td></tr><tr><td></td><td>Social Science</td><td>67.6</td><td>108</td></tr><tr><td>Basque</td><td>Other</td><td>64.8</td><td>500</td></tr><tr><td><strong>Belarusian</strong></td><td>Humanities</td><td>50.8</td><td>490</td></tr><tr><td></td><td>STEM</td><td>42.0</td><td>50</td></tr><tr><td><strong>Bengali</strong></td><td>Humanities</td><td>62.0</td><td>166</td></tr><tr><td></td><td>General Knowledge</td><td>80.1</td><td>166</td></tr><tr><td></td><td>Other</td><td>84.3</td><td>166</td></tr><tr><td></td><td>STEM</td><td>88.0</td><td>50</td></tr><tr><td><strong>Bulgarian</strong></td><td>Humanities</td><td>96.4</td><td>250</td></tr><tr><td></td><td>STEM</td><td>60.0</td><td>50</td></tr><tr><td></td><td>Social Science</td><td>91.2</td><td>250</td></tr><tr><td><strong>Chinese</strong></td><td>Applied Science</td><td>73.2</td><td>71</td></tr><tr><td></td><td>Humanities</td><td>67.8</td><td>87</td></tr><tr><td></td><td>Business & Commerce</td><td>53.5</td><td>71</td></tr><tr><td></td><td>Health-Oriented Education</td><td>60.9</td><td>87</td></tr><tr><td></td><td>Other</td><td>68.3</td><td>142</td></tr><tr><td></td><td>Social Science</td><td>76.1</td><td>71</td></tr><tr><td><strong>Croatian</strong></td><td>Humanities</td><td>86.8</td><td>250</td></tr><tr><td></td><td>STEM</td><td>82.0</td><td>50</td></tr><tr><td></td><td>Social Science</td><td>90.8</td><td>250</td></tr><tr><td><strong>Dutch; Flemish</strong></td><td>Humanities</td><td>86.0</td><td>243</td></tr><tr><td></td><td>Social Science</td><td>86.8</td><td>243</td></tr><tr><td><strong>Estonian</strong></td><td>Humanities</td><td>90.1</td><td>161</td></tr><tr><td></td><td>STEM</td><td>97.2</td><td>36</td></tr><tr><td><strong>Finnish</strong></td><td>Humanities</td><td>69.5</td><td>226</td></tr><tr><td></td><td>Health-Oriented Education</td><td>75.6</td><td>45</td></tr><tr><td></td><td>Social Science</td><td>64.6</td><td>226</td></tr><tr><td><strong>French</strong></td><td>Humanities</td><td>86.5</td><td>266</td></tr><tr><td></td><td>Other</td><td>68.1</td><td>47</td></tr><tr><td></td><td>Social Science</td><td>74.3</td><td>74</td></tr><tr><td>Georgian</td><td>Humanities</td><td>87.6</td><td>500</td></tr><tr><td>German</td><td>Social Science</td><td>62.6</td><td>91</td></tr><tr><td><strong>Greek</strong></td><td>Humanities</td><td>83.8</td><td>37</td></tr><tr><td></td><td>Business & Commerce</td><td>89.1</td><td>64</td></tr><tr><td></td><td>Other</td><td>57.5</td><td>266</td></tr><tr><td></td><td>Social Science</td><td>84.2</td><td>133</td></tr><tr><td><strong>Hebrew</strong></td><td>Humanities</td><td>60.0</td><td>50</td></tr><tr><td></td><td>Other</td><td>88.6</td><td>500</td></tr><tr><td><strong>Hindi</strong></td><td>Applied Science</td><td>83.1</td><td>71</td></tr><tr><td></td><td>Humanities</td><td>72.9</td><td>96</td></tr><tr><td></td><td>General Knowledge</td><td>83.1</td><td>71</td></tr><tr><td></td><td>Health-Oriented Education</td><td>91.5</td><td>71</td></tr><tr><td></td><td>Other</td><td>64.1</td><td>142</td></tr><tr><td></td><td>Social Science</td><td>74.6</td><td>71</td></tr><tr><td><strong>Hungarian</strong></td><td>Applied Science</td><td>79.8</td><td>341</td></tr><tr><td></td><td>Social Science</td><td>66.3</td><td>184</td></tr><tr><td><strong>Indonesian</strong></td><td>Applied Science</td><td>71.2</td><td>125</td></tr><tr><td></td><td>Humanities</td><td>82.4</td><td>125</td></tr><tr><td></td><td>Other</td><td>83.2</td><td>125</td></tr><tr><td></td><td>STEM</td><td>60.0</td><td>50</td></tr><tr><td></td><td>Social Science</td><td>84.8</td><td>125</td></tr><tr><td><strong>Italian</strong></td><td>Applied Science</td><td>85.7</td><td>35</td></tr><tr><td></td><td>Humanities</td><td>85.0</td><td>167</td></tr><tr><td></td><td>Other</td><td>95.5</td><td>155</td></tr><tr><td></td><td>Social Science</td><td>89.8</td><td>167</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of the GPT-4o language model on the INCLUDE benchmark dataset. Specifically, it shows the accuracy of GPT-4o (using a 5-shot, in-language prompting method) across 44 languages, broken down by academic area (Humanities, STEM, Domain-Specific, Professional, Licenses). The table only includes results for academic areas with at least 30 examples per language to ensure statistical reliability. The accuracy scores represent the percentage of correctly answered multiple choice questions in each category. This allows for an analysis of GPT-4o&rsquo;s performance across various languages and knowledge domains.</p><details><summary>read the caption</summary>Table 9: GPT-4o (5-shot, In-language prompting) performance on Include-base per language and academic area. Areas with less than 30 examples were excluded from the analysis.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Academic Area</th><th>Accuracy</th><th>Count</th></tr></thead><tbody><tr><td>Japanese</td><td>Other</td><td>80.2</td><td>501</td></tr><tr><td>Kazakh</td><td>Humanities</td><td>80.4</td><td>500</td></tr><tr><td>Korean</td><td>Other</td><td>46.0</td><td>250</td></tr><tr><td>Korean</td><td>Social Science</td><td>91.6</td><td>250</td></tr><tr><td>Lithuanian</td><td>Humanities</td><td>91.6</td><td>335</td></tr><tr><td>Lithuanian</td><td>Business & Commerce</td><td>77.5</td><td>40</td></tr><tr><td>Lithuanian</td><td>Other</td><td>81.2</td><td>48</td></tr><tr><td>Lithuanian</td><td>STEM</td><td>97.1</td><td>34</td></tr><tr><td>Lithuanian</td><td>Social Science</td><td>93.5</td><td>77</td></tr><tr><td>Malay</td><td>Humanities</td><td>84.3</td><td>178</td></tr><tr><td>Malay</td><td>Business & Commerce</td><td>79.8</td><td>178</td></tr><tr><td>Malay</td><td>Social Science</td><td>84.8</td><td>145</td></tr><tr><td>Malayalam</td><td>Humanities</td><td>64.3</td><td>56</td></tr><tr><td>Malayalam</td><td>General Knowledge</td><td>73.1</td><td>78</td></tr><tr><td>Malayalam</td><td>Health-Oriented Education</td><td>55.0</td><td>100</td></tr><tr><td>Malayalam</td><td>Other</td><td>80.9</td><td>194</td></tr><tr><td>Malayalam</td><td>STEM</td><td>66.0</td><td>47</td></tr><tr><td>Nepali</td><td>Other</td><td>72.4</td><td>500</td></tr><tr><td>Macedonian</td><td>Humanities</td><td>96.9</td><td>224</td></tr><tr><td>Macedonian</td><td>Business & Commerce</td><td>89.3</td><td>224</td></tr><tr><td>Macedonian</td><td>STEM</td><td>86.0</td><td>50</td></tr><tr><td>Macedonian</td><td>Social Science</td><td>92.5</td><td>53</td></tr><tr><td>Persian</td><td>Humanities</td><td>55.3</td><td>141</td></tr><tr><td>Persian</td><td>Other</td><td>62.4</td><td>250</td></tr><tr><td>Persian</td><td>Social Science</td><td>74.5</td><td>141</td></tr><tr><td>Polish</td><td>Other</td><td>80.0</td><td>496</td></tr><tr><td>Polish</td><td>STEM</td><td>62.5</td><td>48</td></tr><tr><td>Portuguese</td><td>Applied Science</td><td>58.3</td><td>84</td></tr><tr><td>Portuguese</td><td>Humanities</td><td>81.8</td><td>154</td></tr><tr><td>Portuguese</td><td>Business & Commerce</td><td>56.9</td><td>84</td></tr><tr><td>Portuguese</td><td>Health-Oriented Education</td><td>67.1</td><td>67</td></tr><tr><td>Portuguese</td><td>Other</td><td>67.6</td><td>169</td></tr><tr><td>Russian</td><td>Applied Science</td><td>87.0</td><td>69</td></tr><tr><td>Russian</td><td>Humanities</td><td>76.8</td><td>69</td></tr><tr><td>Russian</td><td>Business & Commerce</td><td>66.7</td><td>69</td></tr><tr><td>Russian</td><td>Health oriented education</td><td>74.1</td><td>85</td></tr><tr><td>Russian</td><td>Other</td><td>63.9</td><td>97</td></tr><tr><td>Russian</td><td>STEM</td><td>80.9</td><td>94</td></tr><tr><td>Russian</td><td>Social Science</td><td>76.8</td><td>69</td></tr><tr><td>Serbian</td><td>Humanities</td><td>90.4</td><td>313</td></tr><tr><td>Serbian</td><td>STEM</td><td>84.0</td><td>50</td></tr><tr><td>Serbian</td><td>Social Science</td><td>95.2</td><td>187</td></tr><tr><td>Spanish</td><td>Humanities</td><td>77.2</td><td>250</td></tr><tr><td>Spanish</td><td>Health oriented education</td><td>96.0</td><td>25</td></tr><tr><td>Spanish</td><td>STEM</td><td>88.0</td><td>25</td></tr><tr><td>Spanish</td><td>Social Science</td><td>89.6</td><td>250</td></tr><tr><td>Tagalog</td><td>Humanities</td><td>86.8</td><td>425</td></tr><tr><td>Tagalog</td><td>Other</td><td>90.7</td><td>75</td></tr><tr><td>Tamil</td><td>General knowledge</td><td>70.6</td><td>500</td></tr><tr><td>Tamil</td><td>STEM</td><td>54.0</td><td>50</td></tr><tr><td>Telugu</td><td>Applied Science</td><td>73.5</td><td>166</td></tr><tr><td>Telugu</td><td>Humanities</td><td>66.0</td><td>191</td></tr><tr><td>Telugu</td><td>Social Science</td><td>66.9</td><td>166</td></tr><tr><td>Turkish</td><td>Humanities</td><td>62.0</td><td>166</td></tr><tr><td>Turkish</td><td>Business & Commerce</td><td>75.9</td><td>166</td></tr><tr><td>Turkish</td><td>STEM</td><td>52.0</td><td>50</td></tr><tr><td>Turkish</td><td>Social Science</td><td>62.0</td><td>166</td></tr><tr><td>Ukrainian</td><td>Humanities</td><td>92.4</td><td>250</td></tr><tr><td>Ukrainian</td><td>STEM</td><td>84.0</td><td>50</td></tr><tr><td>Ukrainian</td><td>Social Science</td><td>79.2</td><td>250</td></tr><tr><td>Urdu</td><td>Humanities</td><td>61.7</td><td>300</td></tr><tr><td>Urdu</td><td>STEM</td><td>63.3</td><td>49</td></tr><tr><td>Uzbek</td><td>Humanities</td><td>62.9</td><td>240</td></tr><tr><td>Uzbek</td><td>Other</td><td>73.3</td><td>240</td></tr><tr><td>Uzbek</td><td>STEM</td><td>84.0</td><td>50</td></tr><tr><td>Uzbek</td><td>Social Science</td><td>71.4</td><td>21</td></tr><tr><td>Vietnamese</td><td>Humanities</td><td>88.0</td><td>250</td></tr><tr><td>Vietnamese</td><td>STEM</td><td>86.0</td><td>50</td></tr><tr><td>Vietnamese</td><td>Social Science</td><td>80.8</td><td>250</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of GPT-4, a large language model, on the INCLUDE benchmark. The benchmark evaluates multilingual language understanding, focusing on regional knowledge. The table is broken down by language, academic field (e.g., History, Economics, STEM subjects), and the type of regional knowledge required to answer the question (agnostic, culture-related, explicit, implicit). The accuracy of GPT-4&rsquo;s responses is shown for each combination of language, field, and regional knowledge type, providing a detailed view of its performance across diverse contexts and language groups. Fields with fewer than 30 examples were excluded from the analysis to ensure statistical reliability.</p><details><summary>read the caption</summary>Table 10: GPT-4o (5-shot, In-language prompting) performance on Include-base per language, academic field, and regional label. Fields with less than 30 examples were excluded from the analysis (Part 1)</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Academic Field</th><th>Regional Feature</th><th>Accuracy</th><th>Count</th></tr></thead><tbody><tr><td>Albanian</td><td>History</td><td>Implicit</td><td>93.1</td><td>58</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>97.6</td><td>82</td></tr><tr><td></td><td>Visual Arts</td><td>Implicit</td><td>94.0</td><td>83</td></tr><tr><td></td><td>Business</td><td>Implicit</td><td>85.7</td><td>223</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>94.5</td><td>55</td></tr><tr><td>Arabic</td><td>History</td><td>Implicit</td><td>73.3</td><td>30</td></tr><tr><td></td><td>Language</td><td>Culture</td><td>80.0</td><td>40</td></tr><tr><td></td><td>Accounting</td><td>Explicit</td><td>89.5</td><td>57</td></tr><tr><td></td><td>Multiple exams</td><td>Implicit</td><td>86.7</td><td>105</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>76.2</td><td>105</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>65.3</td><td>49</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>66.7</td><td>33</td></tr><tr><td>Armenian</td><td>History</td><td>Culture</td><td>26.3</td><td>95</td></tr><tr><td></td><td>History</td><td>Implicit</td><td>41.1</td><td>95</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>40.0</td><td>35</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>72.2</td><td>79</td></tr><tr><td></td><td>Chemistry</td><td>Agnostic</td><td>20.0</td><td>30</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>50.5</td><td>196</td></tr><tr><td>Azerbaijani</td><td>Agriculture</td><td>Implicit</td><td>85.3</td><td>34</td></tr><tr><td></td><td>Law</td><td>Explicit</td><td>76.2</td><td>42</td></tr><tr><td></td><td>Management</td><td>Implicit</td><td>66.7</td><td>36</td></tr><tr><td></td><td>Health</td><td>Implicit</td><td>80.2</td><td>96</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>70.7</td><td>58</td></tr><tr><td>Basque</td><td>Professional certification</td><td>Explicit</td><td>64.8</td><td>500</td></tr><tr><td>Belarusian</td><td>Language</td><td>Culture</td><td>47.9</td><td>426</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>67.4</td><td>43</td></tr><tr><td></td><td>Math</td><td>Agnostic</td><td>40.8</td><td>49</td></tr><tr><td>Bengali</td><td>Language</td><td>Culture</td><td>62.5</td><td>40</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>61.9</td><td>126</td></tr><tr><td></td><td>Multiple exams</td><td>Implicit</td><td>80.1</td><td>166</td></tr><tr><td></td><td>Professional certification</td><td>Explicit</td><td>84.3</td><td>166</td></tr><tr><td></td><td>Biology</td><td>Agnostic</td><td>89.5</td><td>38</td></tr><tr><td>Bulgarian</td><td>History</td><td>Implicit</td><td>93.9</td><td>115</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>98.5</td><td>135</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>91.2</td><td>250</td></tr><tr><td>Chinese</td><td>Medicine</td><td>Explicit</td><td>57.1</td><td>35</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>84.5</td><td>71</td></tr><tr><td></td><td>Professional certification</td><td>Explicit</td><td>52.1</td><td>71</td></tr><tr><td></td><td>Political sciences</td><td>Implicit</td><td>84.8</td><td>33</td></tr><tr><td>Croatian</td><td>History</td><td>Implicit</td><td>88.2</td><td>119</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>83.5</td><td>79</td></tr><tr><td></td><td>Religious Studies</td><td>Implicit</td><td>90.2</td><td>51</td></tr><tr><td></td><td>Psychology</td><td>Implicit</td><td>95.7</td><td>93</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>94.8</td><td>135</td></tr><tr><td>Dutch; Flemish</td><td>History</td><td>Culture</td><td>89.4</td><td>141</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>81.4</td><td>102</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>81.7</td><td>109</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>93.9</td><td>33</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>90.1</td><td>101</td></tr><tr><td>Estonian</td><td>Language</td><td>Culture</td><td>89.1</td><td>147</td></tr><tr><td>Finnish</td><td>Law</td><td>Explicit</td><td>69.3</td><td>215</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>73.7</td><td>95</td></tr><tr><td></td><td>Political Sciences</td><td>Implicit</td><td>61.5</td><td>96</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>48.6</td><td>35</td></tr><tr><td>French</td><td>Culturology</td><td>Culture</td><td>94.8</td><td>77</td></tr><tr><td></td><td>Language</td><td>Culture</td><td>79.0</td><td>124</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>68.1</td><td>47</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>68.1</td><td>47</td></tr><tr><td>Georgian</td><td>History</td><td>Implicit</td><td>93.8</td><td>161</td></tr><tr><td></td><td>Language</td><td>Culture</td><td>85.7</td><td>168</td></tr><tr><td></td><td>Law</td><td>Explicit</td><td>83.6</td><td>171</td></tr><tr><td>German</td><td>Geography</td><td>Implicit</td><td>50.0</td><td>54</td></tr><tr><td>Greek</td><td>Visual Arts</td><td>Implicit</td><td>90.6</td><td>32</td></tr><tr><td></td><td>Management</td><td>Implicit</td><td>89.1</td><td>64</td></tr><tr><td></td><td>Medical License</td><td>Explicit</td><td>54.1</td><td>133</td></tr><tr><td></td><td>Professional Certification</td><td>Explicit</td><td>60.9</td><td>133</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>85.8</td><td>120</td></tr><tr><td>Hebrew</td><td>Logic</td><td>Agnostic</td><td>60.0</td><td>50</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>88.6</td><td>500</td></tr><tr><td>Hindi</td><td>Education</td><td>Implicit</td><td>84.3</td><td>70</td></tr><tr><td></td><td>History</td><td>Implicit</td><td>86.7</td><td>30</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>73.2</td><td>41</td></tr><tr><td></td><td>Multiple Exams</td><td>Implicit</td><td>83.1</td><td>71</td></tr><tr><td></td><td>Medicine</td><td>Explicit</td><td>91.5</td><td>71</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>57.7</td><td>71</td></tr><tr><td></td><td>Professional Certification</td><td>Explicit</td><td>70.4</td><td>71</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>75.0</td><td>48</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of the GPT-4o language model on the INCLUDE-BASE benchmark. It breaks down the model&rsquo;s accuracy per language, academic field (e.g., History, Economics, Physics), and type of regional knowledge required to answer the questions (e.g., region-agnostic, culture-related, region-explicit, region-implicit). Only fields with at least 30 examples are included in this part of the analysis. The table helps to illustrate how well the model performs across different languages, topics, and the types of knowledge needed to correctly answer the questions, showing potential regional biases in the model&rsquo;s performance.</p><details><summary>read the caption</summary>Table 11: GPT-4o (5-shot, In-language prompting) performance on Include-base per language, academic field, and regional label. Fields with less than 30 examples were excluded from the analysis (Part 2)</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Academic Field</th><th>Regional Feature</th><th>Accuracy</th><th>Count</th></tr></thead><tbody><tr><td>Hungarian</td><td>Agriculture</td><td>Implicit</td><td>82.4</td><td>170</td></tr><tr><td></td><td>Architecture and Design</td><td>Explicit</td><td>85.7</td><td>42</td></tr><tr><td></td><td>Environmental Studies and Forestry</td><td>Implicit</td><td>74.4</td><td>129</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>80.8</td><td>78</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>48.1</td><td>81</td></tr><tr><td>Indonesian</td><td>Human Physical Performance and Recreation</td><td>Implicit</td><td>71.2</td><td>125</td></tr><tr><td></td><td>Language</td><td>Culture</td><td>79.5</td><td>78</td></tr><tr><td></td><td>Professional Certification</td><td>Region explicit</td><td>83.2</td><td>125</td></tr><tr><td></td><td>Economics</td><td>Region explicit</td><td>77.8</td><td>36</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>87.5</td><td>32</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>87.7</td><td>57</td></tr><tr><td>Italian</td><td>Agriculture</td><td>Implicit</td><td>85.7</td><td>35</td></tr><tr><td></td><td>History</td><td>Implicit</td><td>90.4</td><td>94</td></tr><tr><td></td><td>Professional Certification</td><td>Region explicit</td><td>95.5</td><td>155</td></tr><tr><td></td><td>Psychology</td><td>Implicit</td><td>95.0</td><td>60</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>87.7</td><td>65</td></tr><tr><td>Japanese</td><td>Driving License</td><td>Region explicit</td><td>96.0</td><td>99</td></tr><tr><td></td><td>Medical License</td><td>Region explicit</td><td>86.1</td><td>201</td></tr><tr><td></td><td>Professional Certification</td><td>Region explicit</td><td>66.7</td><td>201</td></tr><tr><td>Kazakh</td><td>History</td><td>Culture</td><td>78.4</td><td>241</td></tr><tr><td></td><td>History</td><td>Implicit</td><td>94.9</td><td>79</td></tr><tr><td></td><td>Literature</td><td>Culture</td><td>76.7</td><td>180</td></tr><tr><td>Korean</td><td>Professional Certification</td><td>Region explicit</td><td>46.0</td><td>250</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>91.6</td><td>250</td></tr><tr><td>Lithuanian</td><td>History</td><td>Implicit</td><td>91.6</td><td>335</td></tr><tr><td></td><td>Finance</td><td>Implicit</td><td>77.5</td><td>40</td></tr><tr><td></td><td>Professional Certification</td><td>Region explicit</td><td>81.2</td><td>48</td></tr><tr><td></td><td>Earth Science</td><td>Agnostic</td><td>97.1</td><td>34</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>93.5</td><td>77</td></tr><tr><td>Malay</td><td>History</td><td>Implicit</td><td>84.3</td><td>178</td></tr><tr><td></td><td>Accounting</td><td>Region explicit</td><td>79.8</td><td>178</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>85.3</td><td>129</td></tr><tr><td>Malayalam</td><td>History</td><td>Implicit</td><td>61.5</td><td>52</td></tr><tr><td></td><td>Multiple Exams</td><td>Culture</td><td>72.7</td><td>77</td></tr><tr><td></td><td>Health</td><td>Implicit</td><td>55.0</td><td>100</td></tr><tr><td></td><td>Marine License</td><td>Explicit</td><td>80.9</td><td>194</td></tr><tr><td>Nepali</td><td>Driving License</td><td>Explicit</td><td>83.2</td><td>250</td></tr><tr><td></td><td>Professional Certification</td><td>Explicit</td><td>61.6</td><td>250</td></tr><tr><td>North Macedonian</td><td>History</td><td>Implicit</td><td>95.8</td><td>48</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>97.3</td><td>74</td></tr><tr><td></td><td>Visual Arts</td><td>Implicit</td><td>97.1</td><td>102</td></tr><tr><td></td><td>Business</td><td>Implicit</td><td>89.3</td><td>224</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>92.5</td><td>53</td></tr><tr><td>Persian</td><td>Literature</td><td>Culture</td><td>51.6</td><td>31</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>81.6</td><td>125</td></tr><tr><td></td><td>Professional Certification</td><td>Explicit</td><td>43.2</td><td>125</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>66.0</td><td>47</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>74.6</td><td>63</td></tr><tr><td>Polish</td><td>Professional Certification</td><td>Explicit</td><td>80.0</td><td>496</td></tr><tr><td></td><td>Math</td><td>Agnostic</td><td>61.7</td><td>47</td></tr><tr><td>Portuguese</td><td>Agriculture</td><td>Implicit</td><td>70.0</td><td>40</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>83.3</td><td>84</td></tr><tr><td></td><td>Management</td><td>Implicit</td><td>57.9</td><td>57</td></tr><tr><td></td><td>Health</td><td>Implicit</td><td>70.3</td><td>37</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>89.7</td><td>126</td></tr><tr><td>Russian</td><td>Education</td><td>Implicit</td><td>87.0</td><td>69</td></tr><tr><td></td><td>Law</td><td>Explicit</td><td>72.2</td><td>36</td></tr><tr><td></td><td>Management</td><td>Implicit</td><td>66.2</td><td>65</td></tr><tr><td></td><td>Medicine</td><td>Explicit</td><td>73.3</td><td>60</td></tr><tr><td></td><td>Marine License</td><td>Explicit</td><td>56.5</td><td>69</td></tr><tr><td></td><td>Qualimetry</td><td>Explicit</td><td>79.7</td><td>69</td></tr><tr><td></td><td>Economics</td><td>Implicit</td><td>63.9</td><td>36</td></tr><tr><td>Serbian</td><td>History</td><td>Implicit</td><td>91.5</td><td>235</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>87.5</td><td>56</td></tr><tr><td></td><td>Psychology</td><td>Implicit</td><td>99.2</td><td>125</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>91.1</td><td>45</td></tr><tr><td>Spanish</td><td>Language</td><td>Culture</td><td>69.6</td><td>46</td></tr><tr><td></td><td>Law</td><td>Explicit</td><td>67.0</td><td>109</td></tr><tr><td></td><td>Literature</td><td>Implicit</td><td>93.8</td><td>64</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>90.3</td><td>31</td></tr><tr><td></td><td>Economics</td><td>Explicit</td><td>95.6</td><td>91</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>86.2</td><td>159</td></tr><tr><td>Tagalog</td><td>Culturology</td><td>Culture</td><td>91.6</td><td>203</td></tr><tr><td></td><td>History</td><td>Culture</td><td>85.3</td><td>116</td></tr><tr><td></td><td>Language</td><td>Culture</td><td>79.2</td><td>106</td></tr><tr><td></td><td>Driving License</td><td>Explicit</td><td>90.7</td><td>75</td></tr><tr><td>Tamil</td><td>Multiple Exams</td><td>Implicit</td><td>70.6</td><td>500</td></tr><tr><td>Telugu</td><td>Education</td><td>Implicit</td><td>73.0</td><td>100</td></tr><tr><td></td><td>History</td><td>Culture</td><td>64.7</td><td>119</td></tr><tr><td></td><td>History</td><td>Implicit</td><td>63.9</td><td>36</td></tr><tr><td></td><td>Economics</td><td>Explicit</td><td>60.0</td><td>45</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>73.2</td><td>82</td></tr><tr><td></td><td>Political Sciences</td><td>Implicit</td><td>63.3</td><td>30</td></tr><tr><td>Turkish</td><td>History</td><td>Implicit</td><td>71.2</td><td>73</td></tr><tr><td></td><td>Philosophy</td><td>Implicit</td><td>74.6</td><td>63</td></tr><tr><td></td><td>Business</td><td>Implicit</td><td>75.9</td><td>166</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>53.8</td><td>130</td></tr><tr><td></td><td>Sociology</td><td>Implicit</td><td>91.7</td><td>36</td></tr><tr><td>Ukrainian</td><td>Law</td><td>Explicit</td><td>92.4</td><td>250</td></tr><tr><td></td><td>Physics</td><td>Agnostic</td><td>84.0</td><td>50</td></tr><tr><td></td><td>Psychology</td><td>Implicit</td><td>79.2</td><td>250</td></tr><tr><td>Urdu</td><td>Culturology</td><td>Culture</td><td>61.7</td><td>300</td></tr><tr><td>Uzbek</td><td>History</td><td>Implicit</td><td>66.1</td><td>124</td></tr><tr><td></td><td>Law</td><td>Explicit</td><td>60.6</td><td>109</td></tr><tr><td></td><td>Medical License</td><td>Explicit</td><td>73.3</td><td>240</td></tr><tr><td>Vietnamese</td><td>History</td><td>Implicit</td><td>88.3</td><td>239</td></tr><tr><td></td><td>Geography</td><td>Implicit</td><td>80.8</td><td>250</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the performance of the GPT-40 model on the INCLUDE-BASE benchmark for different output generation lengths (k). For each language, it shows the accuracy achieved at different values of k (50, 100, 200, and 512 tokens). The &lsquo;Total gain&rsquo; column indicates the improvement in accuracy observed when increasing the generation length from k=50 to k=512. This allows for analyzing the impact of increasing the response length on the model&rsquo;s performance and identifying which languages benefit most from longer generations.</p><details><summary>read the caption</summary>Table 12: GPT-4o performance for different values of kùëòkitalic_k for in-language prompting (the output generation length) per language on Include-base and total performance gain from kùëòkitalic_k = 50 to 512.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>Acc (k:50)</th><th>Acc (k:100)</th><th>Acc (k:200)</th><th>Acc (k:512)</th><th>Total gain</th></tr></thead><tbody><tr><td>Uzbek</td><td>51.4</td><td>60.6</td><td>66.6</td><td>68.6</td><td>17.2</td></tr><tr><td>Armenian</td><td>28.0</td><td>30.7</td><td>36.0</td><td>41.1</td><td>13.1</td></tr><tr><td>Malayalam</td><td>57.0</td><td>57.4</td><td>61.0</td><td>69.9</td><td>12.9</td></tr><tr><td>Urdu</td><td>53.7</td><td>56.8</td><td>58.8</td><td>62.2</td><td>8.5</td></tr><tr><td>Greek</td><td>58.0</td><td>58.2</td><td>63.8</td><td>66.4</td><td>8.4</td></tr><tr><td>Korean</td><td>60.4</td><td>61.0</td><td>62.4</td><td>68.8</td><td>8.4</td></tr><tr><td>Chinese</td><td>57.2</td><td>61.8</td><td>63.5</td><td>65.5</td><td>8.3</td></tr><tr><td>Finnish</td><td>63.3</td><td>64.4</td><td>67.0</td><td>69.1</td><td>5.8</td></tr><tr><td>Basque</td><td>60.0</td><td>60.8</td><td>63.8</td><td>64.8</td><td>4.8</td></tr><tr><td>Polish</td><td>74.1</td><td>75.2</td><td>75.4</td><td>78.1</td><td>4.0</td></tr><tr><td>Azerbaijani</td><td>67.7</td><td>69.2</td><td>70.4</td><td>71.5</td><td>3.8</td></tr><tr><td>Dutch; Flemish</td><td>81.9</td><td>82.9</td><td>83.8</td><td>85.3</td><td>3.4</td></tr><tr><td>Telugu</td><td>63.9</td><td>63.9</td><td>64.8</td><td>66.6</td><td>2.7</td></tr><tr><td>Hindi</td><td>72.0</td><td>72.4</td><td>73.7</td><td>74.4</td><td>2.4</td></tr><tr><td>German</td><td>64.0</td><td>65.5</td><td>65.5</td><td>66.2</td><td>2.2</td></tr><tr><td>Malay</td><td>80.6</td><td>81.8</td><td>82.4</td><td>82.8</td><td>2.2</td></tr><tr><td>Tamil</td><td>67.3</td><td>67.3</td><td>67.8</td><td>69.5</td><td>2.2</td></tr><tr><td>Arabic</td><td>76.3</td><td>76.8</td><td>77.9</td><td>78.4</td><td>2.1</td></tr><tr><td>russian</td><td>72.6</td><td>73.6</td><td>74.1</td><td>74.6</td><td>2.0</td></tr><tr><td>Italian</td><td>88.0</td><td>88.5</td><td>89.2</td><td>89.6</td><td>1.6</td></tr><tr><td>Spanish</td><td>82.4</td><td>83.1</td><td>83.3</td><td>84.0</td><td>1.6</td></tr><tr><td>Japanese</td><td>78.6</td><td>78.6</td><td>79.4</td><td>80.0</td><td>1.4</td></tr><tr><td>Georgian</td><td>86.2</td><td>86.4</td><td>87.0</td><td>87.6</td><td>1.4</td></tr><tr><td>Vietnamese</td><td>82.4</td><td>82.5</td><td>84.9</td><td>83.8</td><td>1.4</td></tr><tr><td>Turkish</td><td>63.5</td><td>64.1</td><td>64.4</td><td>64.8</td><td>1.3</td></tr><tr><td>Kazakh</td><td>79.2</td><td>79.6</td><td>80.4</td><td>80.4</td><td>1.2</td></tr><tr><td>Portuguese</td><td>72.8</td><td>73.5</td><td>73.5</td><td>74.0</td><td>1.2</td></tr><tr><td>Bengali</td><td>75.2</td><td>75.4</td><td>76.1</td><td>76.3</td><td>1.1</td></tr><tr><td>Persian</td><td>60.9</td><td>61.1</td><td>61.3</td><td>61.9</td><td>1.0</td></tr><tr><td>Belarusian</td><td>49.5</td><td>50.0</td><td>50.0</td><td>50.2</td><td>0.7</td></tr><tr><td>French</td><td>80.0</td><td>80.2</td><td>80.4</td><td>80.7</td><td>0.7</td></tr><tr><td>Indonesian</td><td>77.8</td><td>78.2</td><td>78.4</td><td>78.5</td><td>0.7</td></tr><tr><td>Albanian</td><td>88.9</td><td>89.3</td><td>89.3</td><td>89.5</td><td>0.6</td></tr><tr><td>Lithuanian</td><td>89.7</td><td>89.7</td><td>90.1</td><td>90.3</td><td>0.6</td></tr><tr><td>Estonian</td><td>92.0</td><td>92.0</td><td>92.4</td><td>92.4</td><td>0.4</td></tr><tr><td>Croatian</td><td>87.8</td><td>88.0</td><td>88.2</td><td>88.0</td><td>0.2</td></tr><tr><td>Hungarian</td><td>75.3</td><td>75.3</td><td>75.5</td><td>75.5</td><td>0.2</td></tr><tr><td>Nepali</td><td>71.8</td><td>72.0</td><td>71.6</td><td>72.0</td><td>0.2</td></tr><tr><td>Bulgarian</td><td>90.7</td><td>90.7</td><td>90.7</td><td>90.7</td><td>0.0</td></tr><tr><td>Hebrew</td><td>86.0</td><td>86.0</td><td>86.0</td><td>86.0</td><td>0.0</td></tr><tr><td>Macedonian</td><td>92.4</td><td>92.4</td><td>92.4</td><td>92.4</td><td>0.0</td></tr><tr><td>Serbian</td><td>91.5</td><td>91.5</td><td>91.5</td><td>91.5</td><td>0.0</td></tr><tr><td>Tagalog</td><td>87.4</td><td>87.4</td><td>87.4</td><td>87.4</td><td>0.0</td></tr><tr><td>Ukrainian</td><td>85.5</td><td>85.5</td><td>85.5</td><td>85.5</td><td>0.0</td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares the performance of various multilingual and monolingual large language models (LLMs) on the INCLUDE-BASE benchmark. It shows the accuracy of each model on specific target languages, highlighting the differences in performance between multilingual and monolingual approaches for various languages. The benchmark focuses on evaluating models&rsquo; ability to understand and reason within the actual linguistic environments where they are meant to be used.</p><details><summary>read the caption</summary>Table 13: Accuracy of the multilingual and monolingual models for answering Include-base questions for specific target languages.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Major training language</th><th>SoTA Monolingual</th><th>Monolingual Acc</th><th>GPT-4o</th><th>Qwen2.5-14B</th><th>Qwen2.5-7B</th></tr></thead><tbody><tr><td>Chinese</td><td>Baichuan-7B</td><td>38.7</td><td>68.1</td><td>82.2</td><td>78.3</td></tr><tr><td>Arabic</td><td>SILMA-9B-Instruct</td><td>56.9</td><td>78.1</td><td>70.5</td><td>61.6</td></tr><tr><td>Japanese</td><td>calm2-7b-chat</td><td>25.0</td><td>75.0</td><td>69.2</td><td>64.7</td></tr><tr><td>Korean</td><td>Korean-Mistral-Nemo-sft-dpo-12B</td><td>35.3</td><td>75.0</td><td>83.2</td><td>76.8</td></tr><tr><td>Russian</td><td>ruGPT-3.5-13B</td><td>53.8</td><td>69.0</td><td>68.2</td><td>59.6</td></tr><tr><td>German</td><td>SauerkrautLM-v2-14b-DPO</td><td>56.8</td><td>66.2</td><td>58.3</td><td>56.1</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the R-squared (R¬≤) values, a statistical measure indicating the goodness of fit of a model, comparing the performance of different language models on newly collected data against existing benchmarks. The R¬≤ values are calculated separately for each language and for each model, illustrating the correlation between the model&rsquo;s performance on the new dataset and its performance on established benchmarks. This allows for an assessment of how well a model&rsquo;s performance on known datasets predicts its performance on this new multilingual dataset.</p><details><summary>read the caption</summary>Table 14: R2superscriptùëÖ2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT scores between the performance different models for newly-collected data and existing benchmarks stratified by language and model.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Language</th><th>R<sup>2</sup></th><th>Model</th><th>R<sup>2</sup></th></tr></thead><tbody><tr><td><strong>Albanian</strong></td><td>0.646</td><td><strong>GPT-4o</strong></td><td>0.077</td></tr><tr><td><strong>Chinese</strong></td><td>0.985</td><td><strong>Qwen2.5-14B</strong></td><td>0.546</td></tr><tr><td><strong>French</strong></td><td>0.770</td><td><strong>Aya-expanse-32B</strong></td><td>0.290</td></tr><tr><td><strong>German</strong></td><td>0.495</td><td><strong>Aya-expanse-8B</strong></td><td>0.333</td></tr><tr><td><strong>Italian</strong></td><td>0.953</td><td><strong>Qwen2.5-7B</strong></td><td>0.412</td></tr><tr><td><strong>Lithuanian</strong></td><td>0.945</td><td><strong>Mistral-7B</strong></td><td>0.231</td></tr><tr><td><strong>Persian</strong></td><td>0.833</td><td><strong>Gemma-7B</strong></td><td>0.001</td></tr><tr><td><strong>Polish</strong></td><td>0.831</td><td><strong>Llama 3.1-70B</strong></td><td>0.020</td></tr><tr><td><strong>Portuguese</strong></td><td>0.930</td><td><strong>Llama 3.1-8B</strong></td><td>0.001</td></tr></tbody></table></table></figure><blockquote><p>üîº This table provides a comparison of INCLUDE with existing multilingual benchmarks. It details the languages covered by each benchmark, the types of knowledge assessed (e.g., academic, region-specific, or general knowledge), and the percentage of questions in each benchmark focusing on region-agnostic vs. region-related topics. This allows for a clear understanding of how INCLUDE differs from and builds upon previous efforts in evaluating multilingual language models.</p><details><summary>read the caption</summary>Table 15: Existing published benchmarks descriptives and the comparison with Include-base.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Benchmark</th><th>Language</th><th>Knowledge Coverage</th><th>Region agnostic (%)</th><th>Region related (%)</th></tr></thead><tbody><tr><td>ArabicMMLU</td><td>Arabic</td><td>Academic knowledge (elementary school, high school, university), Driving License</td><td>24.8%</td><td>75.2%</td></tr><tr><td>CMMLU</td><td>Chinese</td><td>Academic knowledge (elementary school, high school, university)</td><td>25.6%</td><td>74.4%</td></tr><tr><td>PersianMMLU</td><td>Persian</td><td>Academic knowledge (elementary school, high school, university)</td><td>63.1%</td><td>36.9%</td></tr><tr><td>TurkishMMLU</td><td>Turkish</td><td>Academic knowledge (elementary school, high school, university)</td><td>34.8%</td><td>65.2%</td></tr><tr><td>VNHSGE</td><td>Vietnamese</td><td>High school examinations</td><td>40.4%</td><td>59.6%</td></tr><tr><td>EXAMS</td><td>16 languages</td><td>High school examinations</td><td>43.7%</td><td>56.3%</td></tr><tr><td><strong>Include (ours)</strong></td><td><strong>44 languages</strong></td><td>Academic knowledge (elementary school, high school, university), Professional examinations (Medical exam, Bar exam, Teaching exam), Occupational Licenses (Driving license, Marine license and more)</td><td>7.8%</td><td><strong>92.2%</strong></td></tr></tbody></table></table></figure><blockquote><p>üîº This table breaks down the types of errors made by the model during the evaluation, categorizing them into four main types: computational errors, factual knowledge errors, regional knowledge errors, and model hallucinations. It provides the percentage of total errors that fall into each category, offering insights into the specific areas where the model struggles.</p><details><summary>read the caption</summary>Table 16: Breakdown of error types.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-1cd30910a19613c5b7e5157d0fc497d1 class=gallery><img src=https://ai-paper-reviewer.com/2411.19799/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19799/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/&amp;title=INCLUDE:%20Evaluating%20Multilingual%20Language%20Understanding%20with%20Regional%20Knowledge" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/&amp;text=INCLUDE:%20Evaluating%20Multilingual%20Language%20Understanding%20with%20Regional%20Knowledge" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19799/&amp;subject=INCLUDE:%20Evaluating%20Multilingual%20Language%20Understanding%20with%20Regional%20Knowledge" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2411.19799/index.md",oid_likes="likes_paper-reviews/2411.19799/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2411.19574/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">KV Shifting Attention Enhances Language Modeling</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2411.19527/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>