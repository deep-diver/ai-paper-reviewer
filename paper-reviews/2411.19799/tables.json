[{"content": "| Model |  | Include-lite |  |  |  | Include-base |  |  |  |\n|---|---|---|---|---|---|---|---|---|---|---| \n|  | # | Langs | IL Prompt | Eng. Prompt | Reg. + IL Prompt | Reg. + Eng. Prompt | IL Prompt | Eng. Prompt | Reg. + IL Prompt | Reg. + Eng. Prompt |\n|---|---|---|---|---|---|---|---|---|---|---|\n| **GPT-4o** | - |  |  |  |  |  |  |  |  |  |\n| - 5-shot |  | 77.1 | 76.2 | 76.3 | 76.3 | 77.3 | 76.3 | 76.2 | 76.2 |\n| - Zero-shot CoT |  | **78.2** | **78.4** | **77.7** | **77.8** | **79.0** | **78.9** | **77.6** | **78.5** |\n| **Llama-3.1-70B-Inst.** | - |  |  |  |  |  |  |  |  |  |\n| - 5-shot |  | 70.5 | 70.4 | 70.6 | 70.6 | 70.6 | 70.7 | 70.6 | 70.6 |\n| - Zero-shot CoT |  | 60.6 | 55.3 | 60.2 | 55.4 | 60.6 | 56.0 | 60.6 | 55.6 |\n| **Aya-expanse-32B** | 23 |  |  |  |  |  |  |  |  |  |\n| - 5-shot |  | 52.6 | 57.2 | 49.0 | 60.0 | 52.4 | 56.6 | 49.7 | 60.0 |\n| - Zero-shot CoT |  | 50.6 | 57.1 | 52.5 | 58.0 | 51.4 | 57.7 | 52.9 | 57.8 |\n| **Qwen2.5-14B** | 22 |  |  |  |  |  |  |  |  |  |\n| - 5-shot |  | 60.9 | 61.3 | 60.9 | 60.8 | 61.4 | 61.7 | 61.1 | 61.0 |\n| - Zero-shot CoT |  | 46.8 | 50.7 | 46.5 | 51.4 | 47.3 | 51.0 | 47.1 | 51.6 |\n| \\[\\]cdashline1-10**Aya-expanse-8B** | 23 | 37.6 | 46.3 | 38.1 | 48.0 | 37.2 | 46.0 | 37.9 | 47.8 |\n| **Mistral-7B (v0.3)** | - | 44.0 | 45.0 | 44.0 | 45.2 | 43.3 | 44.9 | 43.8 | 45.0 |\n| **Mistral-7B-Inst. (v0.3)** | - | 43.5 | 44.6 | 44.2 | 44.7 | 43.6 | 44.5 | 44.2 | 44.7 |\n| **Gemma-7B** | - | 54.4 | 54.9 | 54.3 | 54.9 | 54.5 | 54.9 | 54.2 | 54.7 |\n| **Gemma-7B-Inst.** | - | 39.2 | 40.2 | 38.7 | 39.7 | 38.7 | 39.7 | 38.1 | 39.2 |\n| **Qwen2.5-7B** | 22 | 53.4 | 54.8 | 53.3 | 54.2 | 54.1 | 55.2 | 54.0 | 54.5 |\n| **Qwen2.5-7B-Inst.** | 22 | 53.4 | 54.2 | 52.8 | 53.7 | 53.8 | 54.6 | 53.2 | 53.9 |\n| **Llama-3.1-8B** | - | 50.9 | 52.3 | 50.9 | 51.9 | 51.0 | 51.8 | 51.0 | 51.6 |\n| **Llama-3.1-8B-Inst.** | - | 53.4 | 54.8 | 52.7 | 53.4 | 53.4 | 54.6 | 53.0 | 54.4 |", "caption": "Table 1: Results on Include-lite and Include-base.\nIn-language Prompt (IL) reports model accuracy when the prompt instructions are presented in the same language as the sample.\nEnglish Prompt (Eng.) reports model accuracy when the prompt instructions are provided in English.\nIn-language Regional Prompt (Reg. + IL) reports model accuracy when a regional prefix is added to the In-language Prompt.\nEnglish Regional Prompt (Reg. + Eng.) reports model accuracy when a regional prefix is added to the English Prompt.\n# Langs reports the number of languages from Include publicly reported to be intentionally included in the pretraining data of each model.", "description": "This table presents the results of evaluating various large language models (LLMs) on two subsets of the INCLUDE benchmark: INCLUDE-LITE and INCLUDE-BASE.  The evaluation measures the models' accuracy across 44 languages under four prompting conditions: in-language prompts (IL), English prompts (Eng.), in-language prompts with a regional prefix (Reg.+IL), and English prompts with a regional prefix (Reg.+Eng.).  The table also indicates the number of languages each model explicitly reports having been pre-trained on.", "section": "4 Experimental Setup"}, {"content": "| Model | Humanities | STEM | Domain-Specific | Professional | Licenses |\n|---|---|---|---|---|---| \n| # samples | 13294 | 2478 | 1964 | 3165 | 1736 |\n| **GPT-4o** |  |  |  |  |  |\n| - 5-shot | 79.0 | 74.2 | 76.8 | 70.1 | 82.1 |\n| - Zero-shot CoT | 79.9 | 78.6 | 80.4 | 73.8 | 81.1 |\n| **Llama-3.1-70B-Instruct** |  |  |  |  |  |\n| - 5-shot | 71.2 | 69.9 | 74.2 | 64.4 | 73.7 |\n| - Zero-shot CoT | 61.9 | 57.5 | 63.5 | 56.7 | 58.4 |\n| **Aya-expanse-32B** |  |  |  |  |  |\n| - 5-shot | 49.6 | 43.0 | 49.1 | 34.7 | 49.5 |\n| - Zero-shot CoT | 52.9 | 47.8 | 55.4 | 44.3 | 52.9 |\n| **Qwen2.5-14B** |  |  |  |  |  |\n| - 5-shot | 61.4 | 60.9 | 66.0 | 57.1 | 65.1 |\n| - Zero-shot CoT | 48.6 | 44.4 | 51.6 | 41.6 | 46.9 |\n| **Aya-expanse-8B** | 37.8 | 32.3 | 37.3 | 40.2 | 29.7 |\n| **Mistral-7B (v0.3)** | 44.2 | 43.4 | 43.9 | 38.6 | 44.3 |\n| **Mistral-7B-Instruct (v0.3)** | 44.5 | 42.7 | 43.2 | 40.1 | 43.7 |\n| **Gemma-7B** | 55.1 | 53.6 | 55.5 | 47.7 | 62.2 |\n| **Gemma-7B-Instruct** | 38.6 | 37.7 | 42.0 | 34.5 | 44.9 |\n| **Qwen2.5-7B** | 53.4 | 54.2 | 59.1 | 51.3 | 57.8 |\n| **Qwen2.5-7B-Instruct** | 53.5 | 53.3 | 58.1 | 49.5 | 58.6 |\n| **Llama-3-8B** | 51.7 | 49.8 | 52.1 | 43.4 | 51.3 |\n| **Llama-3-8B-Instruct** | 50.7 | 46.9 | 52.9 | 44.3 | 54.4 |", "caption": "Table 2: Accuracy performance of GPT-4o (In-language prompting) on Include-base grouped by high-level topics. Where Humanities include Social Science, Humanities, and General knowledge. STEM includes Applied Science and STEM.  Domain-specific covers Business & Commerce and Health oriented education. Professional includes professional certifications. Licenses cover Marine, Fishing, and Driving licenses.", "description": "This table presents the accuracy scores achieved by the GPT-40 language model across different categories of questions from the INCLUDE benchmark dataset.  The questions are grouped into high-level topics: Humanities (encompassing Social Sciences, Humanities, and General Knowledge), STEM (including Applied Sciences and STEM fields), Domain-Specific (covering Business & Commerce and Health-oriented education), Professional (including professional certifications), and Licenses (including Marine, Fishing, and Driving licenses).  The table shows the model's performance in each topic area, offering insight into its strengths and weaknesses across various question types and knowledge domains. Note that the 'In-language prompting' condition is implied, as specified in the table's caption.", "section": "5.1 General Performance"}, {"content": "| Model | In-language Prompt |  |  | English Prompt |  |  |\n|---|---|---|---|---|---|---|\n|  | **Total Acc.** | **Answer Acc.** | **Format Errors (%)** | **Total Acc.** | **Answer Acc.** | **Format Errors (%)** |\n|---|---|---|---|---|---|---|\n| **GPT-4o** |  |  |  |  |  |  |\n| - 5-shot | 77.3 | 79.0 | 2.5 | 76.3 | 78.0 | 2.2 |\n| - Zero-shot CoT | 79.0 | 79.2 | 0.2 | 78.9 | 79.1 | 0.2 |\n| **Llama-3.1-70B-Instruct** |  |  |  |  |  |  |\n| - 5-shot | 70.6 | 70.6 | 0.0 | 70.7 | 70.7 | 0.0 |\n| - Zero-shot CoT | 60.6 | 67.9 | 10.9 | 56.3 | 67.8 | 17.0 |\n| **Aya-expanse-32B** |  |  |  |  |  |  |\n| - 5-shot | 52.4 | 56.2 | 16.9 | 56.6 | 62.7 | 9.7 |\n| - Zero-shot CoT | 51.4 | 57.2 | 10.2 | 57.7 | 58.4 | 1.1 |\n| **Qwen2.5-14B** |  |  |  |  |  |  |\n| - 5-shot | 61.4 | 62.4 | 1.5 | 61.7 | 61.7 | 0.0 |\n| - Zero-shot CoT | 47.3 | 53.1 | 10.9 | 51.0 | 52.0 | 1.9 |\n| \\cdashline1-7 **Aya-expanse-8B** | 37.2 | 43.8 | 18.0 | 46.0 | 50.7 | 9.2 |\n| **Mistral-7B (v0.3)** | 43.3 | 43.3 | 0.0 | 44.9 | 44.9 | 0.0 |\n| **Mistral-7B-Instruct (v0.3)** | 43.6 | 43.8 | 0.4 | 44.5 | 44.5 | 0.1 |\n| **Gemma-7B** | 54.5 | 54.5 | 0.0 | 54.9 | 54.9 | 0.0 |\n| **Gemma-7B-Instruct** | 38.7 | 38.7 | 0.0 | 39.7 | 39.7 | 0.1 |\n| **Qwen2.5-7B** | 54.1 | 55.1 | 1.9 | 55.2 | 55.2 | 0.0 |\n| **Qwen2.5-7B-Instruct** | 53.8 | 54.0 | 0.5 | 54.6 | 54.6 | 0.0 |\n| **Llama-3.1-8B** | 51.0 | 51.0 | 0.0 | 51.8 | 51.8 | 0.0 |\n| **Llama-3.1-8B-Instruct** | 53.4 | 53.4 | 0.0 | 54.6 | 54.6 | 0.0 |", "caption": "Table 3: Results on Include-base for In-language and English prompting strategies. Total Accuracy represents the raw accuracy of the model for answering Include questions in each respective subset. Answer Accuracy represents the accuracy of the model when only considering samples where an answer is extracted from the model\u2019s output in the correct response format. Formatting Errors (%) describes the percentage of model responses that are not formatted correctly and so do not output any answer option. We mark these incorrect by default in Total Accuracy and do not include them when computing Answer Accuracy.", "description": "This table presents a detailed performance analysis of various large language models (LLMs) on the INCLUDE benchmark.  It breaks down the accuracy into three key metrics: Total Accuracy (overall accuracy, including formatting errors), Answer Accuracy (accuracy considering only correctly formatted answers), and Formatting Errors (percentage of incorrectly formatted responses).  By separating correctly formatted answers from those with formatting issues, the table provides a nuanced view of model performance, distinguishing between true comprehension failures and problems with output formatting. The analysis is further broken down by whether prompts were given in the native language or in English, offering insights into the effect of prompting language on both the raw accuracy and the ability of the model to produce correctly formatted outputs.", "section": "5.1 General Performance"}, {"content": "| Model | Include-lite |  | Include-base |  |\n|---|---|---|---|---|\n|  | In-Language Prompt | English Prompt | In-Language Prompt | English Prompt |\n| **Llama3.1-70B-Instruct** | 70.3 | 70.6 | 70.6 | 70.9 |\n| **Aya-expanse-32B** | 58.9 | 59.5 | 47.2 | 47.8 |\n| **Qwen2.5-14B** | 61.8 | 61.9 | 62.3 | 62.6 |\n| **Aya-expanse-8B** | 47.3 | 48.0 | 47.2 | 47.8 |\n| **Mistral-7B** | 44.5 | 44.7 | 44.1 | 44.6 |\n| **Mistral-7B-Instruct** | 43.8 | 43.9 | 44.2 | 44.3 |\n| **Gemma-7B** | 53.6 | 53.1 | 53.5 | 53.2 |\n| **Gemma-7B-Instruct** | 39.1 | 39.7 | 38.6 | 39.3 |\n| **Qwen2.5-7B** | 54.4 | 54.9 | 55.0 | 55.5 |\n| **Qwen2.5-7B-Instruct** | 54.5 | 54.6 | 54.8 | 54.8 |\n| **Llama-3.1-8B** | 51.2 | 52.1 | 51.2 | 51.9 |\n| **Llama-3.1-8B-Instruct** | 53.5 | 54.4 | 53.5 | 54.4 |", "caption": "Table 4: Harness evaluation results on Include-base.", "description": "This table presents the results of evaluating various large language models using the Harness-Eval framework on the INCLUDE-BASE benchmark.  It shows the performance of each model, broken down by prompting type (in-language and English) for both INCLUDE-LITE and INCLUDE-BASE subsets. This allows for a comparison of model performance across different language settings and resource constraints.", "section": "4 Experimental Setup"}, {"content": "| **Academic area** | **Academic field** | **Label** |\n|---|---|---|\n| Humanities | Logic | Agnostic |\n|  | Law | Region Explicit |\n|  | Language | Culture |\n|  | Visual Arts, History, Philosophy, Religious studies, Performing arts, Culturology, Literature | Region implicit/ Culture |\n| Social Science | Sociology, Political sciences, Anthropology | Region implicit/Culture |\n|  | Economics | Region implicit/Agnostic/Region explicit |\n|  | Psychology | Region implicit/Region explicit |\n|  | Geography | Region implicit/Agnostic |\n| STEM | Math, Physics, CS, Biology, Earth science, Chemistry, Engineering | Agnostic |\n|  | Qualimetry | Region explicit |\n| Health oriented education | Medicine | Agnostic/Region implicit/Region explicit |\n|  | Health | Region implicit/Region explicit |\n| Business and Commerce | Accounting | Region explicit |\n|  | Management, Marketing, Industrial and labor relations, International trade, Risk management and insurance, Business administration, Business ethics, Business, Finance | Region implicit/Region explicit/Agnostic |\n| Applied Science | Agriculture, Library and museum studies, Transportation | Region implicit/Agnostic |\n|  | Military Sciences, Public Administration, Public Policy | Region implicit/Region explicit |\n|  | Architecture and Design, Family and consumer science, Environmental studies and forestry, Education\nJournalism, media studies, and communication, Social Work, Human physical performance and recreation | Region implicit |\n| Other | Driving license, Marine license, Fishing license, Medical license, Public administration, Professional certification | Region explicit |\n| General knowledge | Multiple exams | Region implicit/Culture |", "caption": "Table 5: Annotation schema for high-level Academic area and fine-grained Academic field. The Label column lists the most likely regionality label for these exams in our dataset (e.g., region-{agnostic, implicit, explicit} or cultural), though all exams from which we collect data are individually labeled with a regionality category. The first label is the most frequent one.", "description": "This table details the annotation schema used to categorize the exams included in the INCLUDE benchmark.  It maps high-level academic areas (like Humanities or STEM) to more specific academic fields (e.g., History, Biology). Critically, it also assigns a regionality label to each exam, indicating whether the knowledge required to answer the questions is region-agnostic (doesn't require regional knowledge), culture-related (requires cultural understanding of a region), region-explicit (explicitly requires knowledge about laws or regulations specific to a region), or region-implicit (implicitly relies on regional context).  While the table shows the most frequent regionality label for each exam, it's important to note that each exam in the dataset was individually labeled with one of these four regionality categories. ", "section": "3.2 CATEGORIZING KNOWLEDGE"}, {"content": "| Language | Academic\nHumanities | Academic\nSTEM studies | Academic\nDomain-specific\nstudi es | Professional | License | Avg (%) |\n|---|---|---|---|---|---|---|\n| **Albanian** | 95.0 | 88.0 | 83.5 | - | - | 89.50 |\n| **Arabic** | 77.8 | 82.0 | 80.5 | - | 76.2 | 78.30 |\n| **Armenian** | 52.7 | 32.0 | - | - | 72.2 | 53.60 |\n| **Azerbaijani** | 71.3 | 73.6 | 71.4 | - | - | 71.90 |\n| **Basque** | - | - | - | 64.8 | - | 64.80 |\n| **Belarusian** | 51.8 | 42.0 | - | - | - | 50.90 |\n| **Bengali** | 71.1 | 90.0 | - | 84.3 | - | 76.80 |\n| **Bulgarian** | 93.8 | 60.0 | - | - | - | 90.70 |\n| **Chinese** | 71.5 | 66.7 | 58.2 | 52.1 | 84.5 | 66.10 |\n| **Croatian** | 89.0 | 82.0 | - | - | - | 88.40 |\n| **Dutch; Flemish** | 86.6 | 87.5 | 80.0 | - | - | 86.40 |\n| **Estonian** | 90.7 | 98.0 | 100.0 | - | - | 92.40 |\n| **Finnish** | 67.0 | 87.0 | 77.8 | - | - | 69.90 |\n| **French** | 83.8 | 50.0 | 81.2 | - | 68.1 | 80.70 |\n| **Georgian** | 87.6 | - | - | - | - | 87.60 |\n| **German** | 62.6 | 64.0 | - | - | 87.0 | 66.90 |\n| **Greek** | 84.7 | 84.0 | 89.2 | 58.6 | - | 71.50 |\n| **Hebrew** | 62.0 | - | - | - | 88.6 | 86.20 |\n| **Hindi** | 77.7 | 71.9 | 91.5 | 71.8 | 57.7 | 75.10 |\n| **Hungarian** | 66.3 | 80.6 | - | - | - | 75.80 |\n| **Indonesian** | 84.0 | 69.1 | - | 84.8 | - | 79.50 |\n| **Italian** | 87.7 | 87.2 | 91.7 | 95.5 | - | 90.00 |\n| **Japanese** | - | - | - | 78.1 | 96.0 | 81.60 |\n| **Kazakh** | 80.4 | - | - | - | - | 80.40 |\n| **Korean** | 91.6 | - | - | 46.4 | - | 69.00 |\n| **Lithuanian** | 92.0 | 97.1 | 82.5 | 81.2 | - | 90.60 |\n| **Malay** | 84.5 | - | 80.3 | - | - | 83.00 |\n| **Malayalam** | 69.6 | 66.0 | 55.0 | - | 80.9 | 70.80 |\n| **Nepali** | - | - | - | 61.6 | 83.2 | 72.40 |\n| **Macedonian** | 96.0 | 86.0 | 89.3 | - | - | 92.40 |\n| **Persian** | 66.0 | 25.0 | - | 49.6 | 81.6 | 64.60 |\n| **Polish** | 100.0 | 64.6 | - | 80.0 | - | 78.80 |\n| **Portuguese** | 84.7 | 63.3 | 67.9 | - | - | 76.40 |\n| **Serbian** | 92.2 | 86.0 | - | - | - | 91.60 |\n| **Spanish** | 83.6 | 88.0 | 96.0 | - | - | 84.40 |\n| **Tagalog** | 86.8 | - | - | - | 90.7 | 87.40 |\n| **Tamil** | 70.6 | 54.0 | - | - | - | 69.10 |\n| **Telugu** | 66.9 | 70.7 | - | - | - | 68.20 |\n| **Turkish** | 62.0 | 52.0 | 75.9 | - | - | 65.30 |\n| **Ukrainian** | 85.8 | 84.0 | - | - | - | 85.60 |\n| **Urdu** | 61.7 | 65.3 | 100.0 | - | - | 62.50 |\n| **Uzbek** | 63.6 | 84.0 | - | 73.3 | - | 69.70 |\n| **Vietnamese** | 84.4 | 86.0 | - | - | - | 84.50 |\n| **Russian** | 77.5 | 83.4 | 70.8 | - | 63.9 | 75.00 |", "caption": "Table 6: Accuracy performance of GPT-4o (5-shot) on Include-base for each language. Humanities include Social Science, Humanities, and General knowledge. STEM includes Applied Science and STEM.  Domain-specific covers Business & Commerce and Health oriented education. Professional includes professional certifications. Licenses cover Marine, Fishing, and Driving licenses.", "description": "This table presents the performance of the GPT-40 language model on the INCLUDE benchmark dataset.  For each of the 44 languages in the dataset, the accuracy of GPT-40 (using a 5-shot prompting technique) is shown across five categories of questions: Humanities (including Social Sciences and general knowledge), STEM (Science, Technology, Engineering, and Mathematics, including applied sciences), Domain-Specific (questions relating to Business & Commerce and health-oriented education), Professional (questions related to professional certifications), and Licenses (questions related to licenses such as Marine, Fishing and Driving).  The percentages represent the accuracy achieved by the model for each language in each category.", "section": "5.1 GENERAL PERFORMANCE"}, {"content": "| Model | Full Benchmark | Newly collected |\n|---|---|---|\n| **Aya-expanse-8B** | 0.02 | 0.01 |\n| **XGLM-7B** | 0.17 | 0.14 |\n| **Qwen-2.5-7B** | 0.13 | 0.11 |\n| **LLaMA-3.1-8B** | 0.29 | 0.25 |", "caption": "Table 7: Data contamination rates per model on Include-base.", "description": "This table presents the percentage of questions in the INCLUDE-BASE benchmark that were identified as potentially originating from the training data of various large language models (LLMs).  It shows the contamination rates, indicating the degree to which each model's training data may overlap with the benchmark dataset. Lower percentages suggest less contamination, implying the benchmark is less likely to be biased by the models' prior knowledge.", "section": "4 Experimental Setup"}, {"content": "| Language | Script | Family | Branch | Availability | Count |\n|---|---|---|---|---|---| \n| Albanian | latin | Indo-European | Albanian | Mid | 2365 |\n| Amharic | ge\u2019ez | Afro-Asiatic | Semitic | Low | 131 |\n| Arabic | perso-arabic | Afro-Asiatic | Semitic | High | 15137 |\n| Armenian | armenian | Indo-European | Armenian | Low | 1669 |\n| Assamese | bengali-assamese | Indo-European | Indo-Iranian | Low | 323 |\n| Azerbaijani | latin | Turkic | Azerbaijani North | Mid | 6937 |\n| Basque | latin | Isolate |  | Low | 719 |\n| Belarusian | cyrillic | Indo-European | Slavic East | Low | 687 |\n| Bengali | bengali-assamese | Indo-European | Indo-Iranian | Mid | 15259 |\n| Bulgarian | cyrillic | Indo-European | Slavic South Eastern | Mid | 2937 |\n| Chinese | chinese | Sino-Tibetan | Chinese | High | 12977 |\n| Croatian | latin | Indo-European | Slavic South Western | Mid | 2879 |\n| Czech | latin | Indo-European | Slavic West | High | 50 |\n| Danish | latin | Indo-European | Germanic | Mid | 732 |\n| Dutch; Flemish | latin | Indo-European | Germanic | High | 2222 |\n| Estonian | latin | Uralic | Finnic | Mid | 952 |\n| Finnish | latin | Uralic | Finnic | Mid | 1574 |\n| French | latin | Indo-European | Italic | High | 2457 |\n| Georgian | mkherduli | Kartvelian | Georgian | Low | 599 |\n| German | latin | Indo-European | Germanic | High | 1590 |\n| Greek | greek | Indo-European | Greek | Mid | 6570 |\n| Hebrew | hebrew | Afro-Asiatic | Semitic | Mid | 2457 |\n| Hindi | devanagari | Indo-European | Indo-Iranian | Mid | 5167 |\n| Hungarian | latin | Uralic | Hungarian | Mid | 2267 |\n| Indonesian | latin | Austronesian | Malayo-Polynesian | High | 12013 |\n| Italian | latin | Indo-European | Italic | High | 3038 |\n| Japanese | kanji | Japonic | Japanese | High | 2699 |\n| Kannada | kannada | Dravidian | Southern | Low | 335 |\n| Kazakh | cyrillic | Turkic | Western | Low | 5736 |\n| Korean | hangul | Koreanic | Korean | Mid | 1781 |\n| Lithuanian | latin | Indo-European | Eastern Baltic | Mid | 1397 |\n| Malay | latin | Austronesian | Malayo-Polynesian | Mid | 1021 |\n| Malayalam | vatteluttu | Dravidian | Southern | Low | 275 |\n| Marathi | devanagari | Indo-European | Indo-Iranian | Mid | 313 |\n| Nepali | devanagari | Indo-European | Indo-Iranian | Mid | 1470 |\n| Macedonian | cyrillic | Indo-European | Slavic South Eastern | Low | 2075 |\n| Oriya | odia | Indo-European | Indo-Iranian | Low | 241 |\n| Panjabi; Punjabi | gurmukhi | Indo-European | Indo-Iranian | Low | 453 |\n| Persian | perso-arabic | Indo-European | Indo-Iranian | High | 23990 |\n| Polish | latin | Indo-European | Slavic West | High | 2023 |\n| Portuguese | latin | Indo-European | Italic | High | 1407 |\n| Russian | cyrillic | Indo-European | Slavic East | High | 10169 |\n| Serbian | cyrillic | Indo-European | Slavic South | Mid | 1636 |\n| Sinhala; Sinhalese | sinhala | Indo-European | Indo-Iranian | Low | 325 |\n| Slovak | latin | Indo-European | Slavic West | Mid | 131 |\n| Spanish | latin | Indo-European | Italic | High | 2559 |\n| Swedish | latin | Indo-European | Germanic | Mid | 5102 |\n| Tagalog | latin | Austronesian | Malayo-Polynesian | Low | 530 |\n| Tamil | tamil | Dravidian | Southern | Mid | 945 |\n| Telugu | telugu | Dravidian | South-Central | Low | 11568 |\n| Turkish | latin | Turkic | Southern | High | 2710 |\n| Ukrainian | cyrillic | Indo-European | Slavic East | Mid | 1482 |\n| Urdu | perso-arabic | Indo-European | Indo-Iranian | Low | 122 |\n| Uzbek | latin | Turkic | Eastern | Low | 2878 |\n| Vietnamese | latin | Austro-Asiatic | Mon-Khmer | High | 8901 |", "caption": "Table 8: Languages in Include with their associated metadata and the total count of the samples per language.", "description": "This table lists all 44 languages included in the INCLUDE benchmark dataset.  For each language, it provides metadata including the script used, the language family and branch it belongs to, and its resource availability level (High, Mid, or Low). Finally, it indicates the total number of samples available for each language within the dataset.", "section": "3 THE INCLUDE BENCHMARK"}, {"content": "| Language | Academic Area | Accuracy | Count |\n|---|---|---|---| \n| **Albanian** | Humanities | 95.1 | 223 |\n|  | Business & Commerce | 85.7 | 223 |\n|  | Social Science | 94.5 | 55 |\n| **Arabic** | Humanities | 79.0 | 105 |\n|  | Business & Commerce | 79.3 | 82 |\n|  | General Knowledge | 86.7 | 105 |\n|  | Other | 76.2 | 105 |\n|  | STEM | 82.0 | 50 |\n|  | Social Science | 67.6 | 105 |\n| **Armenian** | Humanities | 34.7 | 225 |\n|  | Other | 72.2 | 79 |\n|  | STEM | 28.0 | 50 |\n|  | Social Science | 50.5 | 196 |\n| **Azerbaijani** | Applied Science | 75.9 | 108 |\n|  | Humanities | 74.1 | 108 |\n|  | Business & Commerce | 62.5 | 96 |\n|  | Health-Oriented Education | 80.2 | 96 |\n|  | Social Science | 67.6 | 108 |\n| Basque | Other | 64.8 | 500 |\n| **Belarusian** | Humanities | 50.8 | 490 |\n|  | STEM | 42.0 | 50 |\n| **Bengali** | Humanities | 62.0 | 166 |\n|  | General Knowledge | 80.1 | 166 |\n|  | Other | 84.3 | 166 |\n|  | STEM | 88.0 | 50 |\n| **Bulgarian** | Humanities | 96.4 | 250 |\n|  | STEM | 60.0 | 50 |\n|  | Social Science | 91.2 | 250 |\n| **Chinese** | Applied Science | 73.2 | 71 |\n|  | Humanities | 67.8 | 87 |\n|  | Business & Commerce | 53.5 | 71 |\n|  | Health-Oriented Education | 60.9 | 87 |\n|  | Other | 68.3 | 142 |\n|  | Social Science | 76.1 | 71 |\n| **Croatian** | Humanities | 86.8 | 250 |\n|  | STEM | 82.0 | 50 |\n|  | Social Science | 90.8 | 250 |\n| **Dutch; Flemish** | Humanities | 86.0 | 243 |\n|  | Social Science | 86.8 | 243 |\n| **Estonian** | Humanities | 90.1 | 161 |\n|  | STEM | 97.2 | 36 |\n| **Finnish** | Humanities | 69.5 | 226 |\n|  | Health-Oriented Education | 75.6 | 45 |\n|  | Social Science | 64.6 | 226 |\n| **French** | Humanities | 86.5 | 266 |\n|  | Other | 68.1 | 47 |\n|  | Social Science | 74.3 | 74 |\n| Georgian | Humanities | 87.6 | 500 |\n| German | Social Science | 62.6 | 91 |\n| **Greek** | Humanities | 83.8 | 37 |\n|  | Business & Commerce | 89.1 | 64 |\n|  | Other | 57.5 | 266 |\n|  | Social Science | 84.2 | 133 |\n| **Hebrew** | Humanities | 60.0 | 50 |\n|  | Other | 88.6 | 500 |\n| **Hindi** | Applied Science | 83.1 | 71 |\n|  | Humanities | 72.9 | 96 |\n|  | General Knowledge | 83.1 | 71 |\n|  | Health-Oriented Education | 91.5 | 71 |\n|  | Other | 64.1 | 142 |\n|  | Social Science | 74.6 | 71 |\n| **Hungarian** | Applied Science | 79.8 | 341 |\n|  | Social Science | 66.3 | 184 |\n| **Indonesian** | Applied Science | 71.2 | 125 |\n|  | Humanities | 82.4 | 125 |\n|  | Other | 83.2 | 125 |\n|  | STEM | 60.0 | 50 |\n|  | Social Science | 84.8 | 125 |\n| **Italian** | Applied Science | 85.7 | 35 |\n|  | Humanities | 85.0 | 167 |\n|  | Other | 95.5 | 155 |\n|  | Social Science | 89.8 | 167 |", "caption": "Table 9: GPT-4o (5-shot, In-language prompting) performance on Include-base per language and academic area. Areas with less than 30 examples were excluded from the analysis.", "description": "This table presents the performance of the GPT-4o language model on the INCLUDE benchmark dataset.  Specifically, it shows the accuracy of GPT-4o (using a 5-shot, in-language prompting method) across 44 languages, broken down by academic area (Humanities, STEM, Domain-Specific, Professional, Licenses). The table only includes results for academic areas with at least 30 examples per language to ensure statistical reliability.  The accuracy scores represent the percentage of correctly answered multiple choice questions in each category. This allows for an analysis of GPT-4o's performance across various languages and knowledge domains.", "section": "5.1 General Performance"}, {"content": "| Language | Academic Area | Accuracy | Count |\n|---|---|---|---| \n| Japanese | Other | 80.2 | 501 |\n| Kazakh | Humanities | 80.4 | 500 |\n| Korean | Other | 46.0 | 250 |\n| Korean | Social Science | 91.6 | 250 |\n| Lithuanian | Humanities | 91.6 | 335 |\n| Lithuanian | Business & Commerce | 77.5 | 40 |\n| Lithuanian | Other | 81.2 | 48 |\n| Lithuanian | STEM | 97.1 | 34 |\n| Lithuanian | Social Science | 93.5 | 77 |\n| Malay | Humanities | 84.3 | 178 |\n| Malay | Business & Commerce | 79.8 | 178 |\n| Malay | Social Science | 84.8 | 145 |\n| Malayalam | Humanities | 64.3 | 56 |\n| Malayalam | General Knowledge | 73.1 | 78 |\n| Malayalam | Health-Oriented Education | 55.0 | 100 |\n| Malayalam | Other | 80.9 | 194 |\n| Malayalam | STEM | 66.0 | 47 |\n| Nepali | Other | 72.4 | 500 |\n| Macedonian | Humanities | 96.9 | 224 |\n| Macedonian | Business & Commerce | 89.3 | 224 |\n| Macedonian | STEM | 86.0 | 50 |\n| Macedonian | Social Science | 92.5 | 53 |\n| Persian | Humanities | 55.3 | 141 |\n| Persian | Other | 62.4 | 250 |\n| Persian | Social Science | 74.5 | 141 |\n| Polish | Other | 80.0 | 496 |\n| Polish | STEM | 62.5 | 48 |\n| Portuguese | Applied Science | 58.3 | 84 |\n| Portuguese | Humanities | 81.8 | 154 |\n| Portuguese | Business & Commerce | 56.9 | 84 |\n| Portuguese | Health-Oriented Education | 67.1 | 67 |\n| Portuguese | Other | 67.6 | 169 |\n| Russian | Applied Science | 87.0 | 69 |\n| Russian | Humanities | 76.8 | 69 |\n| Russian | Business & Commerce | 66.7 | 69 |\n| Russian | Health oriented education | 74.1 | 85 |\n| Russian | Other | 63.9 | 97 |\n| Russian | STEM | 80.9 | 94 |\n| Russian | Social Science | 76.8 | 69 |\n| Serbian | Humanities | 90.4 | 313 |\n| Serbian | STEM | 84.0 | 50 |\n| Serbian | Social Science | 95.2 | 187 |\n| Spanish | Humanities | 77.2 | 250 |\n| Spanish | Health oriented education | 96.0 | 25 |\n| Spanish | STEM | 88.0 | 25 |\n| Spanish | Social Science | 89.6 | 250 |\n| Tagalog | Humanities | 86.8 | 425 |\n| Tagalog | Other | 90.7 | 75 |\n| Tamil | General knowledge | 70.6 | 500 |\n| Tamil | STEM | 54.0 | 50 |\n| Telugu | Applied Science | 73.5 | 166 |\n| Telugu | Humanities | 66.0 | 191 |\n| Telugu | Social Science | 66.9 | 166 |\n| Turkish | Humanities | 62.0 | 166 |\n| Turkish | Business & Commerce | 75.9 | 166 |\n| Turkish | STEM | 52.0 | 50 |\n| Turkish | Social Science | 62.0 | 166 |\n| Ukrainian | Humanities | 92.4 | 250 |\n| Ukrainian | STEM | 84.0 | 50 |\n| Ukrainian | Social Science | 79.2 | 250 |\n| Urdu | Humanities | 61.7 | 300 |\n| Urdu | STEM | 63.3 | 49 |\n| Uzbek | Humanities | 62.9 | 240 |\n| Uzbek | Other | 73.3 | 240 |\n| Uzbek | STEM | 84.0 | 50 |\n| Uzbek | Social Science | 71.4 | 21 |\n| Vietnamese | Humanities | 88.0 | 250 |\n| Vietnamese | STEM | 86.0 | 50 |\n| Vietnamese | Social Science | 80.8 | 250 |", "caption": "Table 10: GPT-4o (5-shot, In-language prompting) performance on Include-base per language, academic field, and regional label. Fields with less than 30 examples were excluded from the analysis (Part 1)", "description": "This table presents the performance of GPT-4, a large language model, on the INCLUDE benchmark.  The benchmark evaluates multilingual language understanding, focusing on regional knowledge. The table is broken down by language, academic field (e.g., History, Economics, STEM subjects), and the type of regional knowledge required to answer the question (agnostic, culture-related, explicit, implicit).  The accuracy of GPT-4's responses is shown for each combination of language, field, and regional knowledge type, providing a detailed view of its performance across diverse contexts and language groups.  Fields with fewer than 30 examples were excluded from the analysis to ensure statistical reliability.", "section": "5.3 REGIONAL & ACADEMIC DOMAIN KNOWLEDGE PERFORMANCE"}, {"content": "| Language | Academic Field | Regional Feature | Accuracy | Count |\n|---|---|---|---|---|\n| Albanian | History | Implicit | 93.1 | 58 |\n|  | Philosophy | Implicit | 97.6 | 82 |\n|  | Visual Arts | Implicit | 94.0 | 83 |\n|  | Business | Implicit | 85.7 | 223 |\n|  | Sociology | Implicit | 94.5 | 55 |\n| Arabic | History | Implicit | 73.3 | 30 |\n|  | Language | Culture | 80.0 | 40 |\n|  | Accounting | Explicit | 89.5 | 57 |\n|  | Multiple exams | Implicit | 86.7 | 105 |\n|  | Driving License | Explicit | 76.2 | 105 |\n|  | Geography | Implicit | 65.3 | 49 |\n|  | Sociology | Implicit | 66.7 | 33 |\n| Armenian | History | Culture | 26.3 | 95 |\n|  | History | Implicit | 41.1 | 95 |\n|  | Literature | Culture | 40.0 | 35 |\n|  | Driving License | Explicit | 72.2 | 79 |\n|  | Chemistry | Agnostic | 20.0 | 30 |\n|  | Geography | Implicit | 50.5 | 196 |\n| Azerbaijani | Agriculture | Implicit | 85.3 | 34 |\n|  | Law | Explicit | 76.2 | 42 |\n|  | Management | Implicit | 66.7 | 36 |\n|  | Health | Implicit | 80.2 | 96 |\n|  | Economics | Implicit | 70.7 | 58 |\n| Basque | Professional certification | Explicit | 64.8 | 500 |\n| Belarusian | Language | Culture | 47.9 | 426 |\n|  | Literature | Culture | 67.4 | 43 |\n|  | Math | Agnostic | 40.8 | 49 |\n| Bengali | Language | Culture | 62.5 | 40 |\n|  | Literature | Culture | 61.9 | 126 |\n|  | Multiple exams | Implicit | 80.1 | 166 |\n|  | Professional certification | Explicit | 84.3 | 166 |\n|  | Biology | Agnostic | 89.5 | 38 |\n| Bulgarian | History | Implicit | 93.9 | 115 |\n|  | Philosophy | Implicit | 98.5 | 135 |\n|  | Geography | Implicit | 91.2 | 250 |\n| Chinese | Medicine | Explicit | 57.1 | 35 |\n|  | Driving License | Explicit | 84.5 | 71 |\n|  | Professional certification | Explicit | 52.1 | 71 |\n|  | Political sciences | Implicit | 84.8 | 33 |\n| Croatian | History | Implicit | 88.2 | 119 |\n|  | Philosophy | Implicit | 83.5 | 79 |\n|  | Religious Studies | Implicit | 90.2 | 51 |\n|  | Psychology | Implicit | 95.7 | 93 |\n|  | Sociology | Implicit | 94.8 | 135 |\n| Dutch; Flemish | History | Culture | 89.4 | 141 |\n|  | Literature | Culture | 81.4 | 102 |\n|  | Economics | Implicit | 81.7 | 109 |\n|  | Geography | Implicit | 93.9 | 33 |\n|  | Sociology | Implicit | 90.1 | 101 |\n| Estonian | Language | Culture | 89.1 | 147 |\n| Finnish | Law | Explicit | 69.3 | 215 |\n|  | Economics | Implicit | 73.7 | 95 |\n|  | Political Sciences | Implicit | 61.5 | 96 |\n|  | Sociology | Implicit | 48.6 | 35 |\n| French | Culturology | Culture | 94.8 | 77 |\n|  | Language | Culture | 79.0 | 124 |\n|  | Driving License | Explicit | 68.1 | 47 |\n|  | Geography | Implicit | 68.1 | 47 |\n| Georgian | History | Implicit | 93.8 | 161 |\n|  | Language | Culture | 85.7 | 168 |\n|  | Law | Explicit | 83.6 | 171 |\n| German | Geography | Implicit | 50.0 | 54 |\n| Greek | Visual Arts | Implicit | 90.6 | 32 |\n|  | Management | Implicit | 89.1 | 64 |\n|  | Medical License | Explicit | 54.1 | 133 |\n|  | Professional Certification | Explicit | 60.9 | 133 |\n|  | Economics | Implicit | 85.8 | 120 |\n| Hebrew | Logic | Agnostic | 60.0 | 50 |\n|  | Driving License | Explicit | 88.6 | 500 |\n| Hindi | Education | Implicit | 84.3 | 70 |\n|  | History | Implicit | 86.7 | 30 |\n|  | Literature | Culture | 73.2 | 41 |\n|  | Multiple Exams | Implicit | 83.1 | 71 |\n|  | Medicine | Explicit | 91.5 | 71 |\n|  | Driving License | Explicit | 57.7 | 71 |\n|  | Professional Certification | Explicit | 70.4 | 71 |\n|  | Geography | Implicit | 75.0 | 48 |", "caption": "Table 11: GPT-4o (5-shot, In-language prompting) performance on Include-base per language, academic field, and regional label. Fields with less than 30 examples were excluded from the analysis (Part 2)", "description": "This table presents the performance of the GPT-4o language model on the INCLUDE-BASE benchmark.  It breaks down the model's accuracy per language, academic field (e.g., History, Economics, Physics), and type of regional knowledge required to answer the questions (e.g., region-agnostic, culture-related, region-explicit, region-implicit).  Only fields with at least 30 examples are included in this part of the analysis.  The table helps to illustrate how well the model performs across different languages, topics, and the types of knowledge needed to correctly answer the questions, showing potential regional biases in the model's performance.", "section": "5.3 REGIONAL & ACADEMIC DOMAIN KNOWLEDGE PERFORMANCE"}, {"content": "| Language | Academic Field | Regional Feature | Accuracy | Count |\n|---|---|---|---|---|\n| Hungarian | Agriculture | Implicit | 82.4 | 170 |\n|  | Architecture and Design | Explicit | 85.7 | 42 |\n|  | Environmental Studies and Forestry | Implicit | 74.4 | 129 |\n|  | Economics | Implicit | 80.8 | 78 |\n|  | Geography | Implicit | 48.1 | 81 |\n| Indonesian | Human Physical Performance and Recreation | Implicit | 71.2 | 125 |\n|  | Language | Culture | 79.5 | 78 |\n|  | Professional Certification | Region explicit | 83.2 | 125 |\n|  | Economics | Region explicit | 77.8 | 36 |\n|  | Geography | Implicit | 87.5 | 32 |\n|  | Sociology | Implicit | 87.7 | 57 |\n| Italian | Agriculture | Implicit | 85.7 | 35 |\n|  | History | Implicit | 90.4 | 94 |\n|  | Professional Certification | Region explicit | 95.5 | 155 |\n|  | Psychology | Implicit | 95.0 | 60 |\n|  | Sociology | Implicit | 87.7 | 65 |\n| Japanese | Driving License | Region explicit | 96.0 | 99 |\n|  | Medical License | Region explicit | 86.1 | 201 |\n|  | Professional Certification | Region explicit | 66.7 | 201 |\n| Kazakh | History | Culture | 78.4 | 241 |\n|  | History | Implicit | 94.9 | 79 |\n|  | Literature | Culture | 76.7 | 180 |\n| Korean | Professional Certification | Region explicit | 46.0 | 250 |\n|  | Economics | Implicit | 91.6 | 250 |\n| Lithuanian | History | Implicit | 91.6 | 335 |\n|  | Finance | Implicit | 77.5 | 40 |\n|  | Professional Certification | Region explicit | 81.2 | 48 |\n|  | Earth Science | Agnostic | 97.1 | 34 |\n|  | Economics | Implicit | 93.5 | 77 |\n| Malay | History | Implicit | 84.3 | 178 |\n|  | Accounting | Region explicit | 79.8 | 178 |\n|  | Geography | Implicit | 85.3 | 129 |\n| Malayalam | History | Implicit | 61.5 | 52 |\n|  | Multiple Exams | Culture | 72.7 | 77 |\n|  | Health | Implicit | 55.0 | 100 |\n|  | Marine License | Explicit | 80.9 | 194 |\n| Nepali | Driving License | Explicit | 83.2 | 250 |\n|  | Professional Certification | Explicit | 61.6 | 250 |\n| North Macedonian | History | Implicit | 95.8 | 48 |\n|  | Philosophy | Implicit | 97.3 | 74 |\n|  | Visual Arts | Implicit | 97.1 | 102 |\n|  | Business | Implicit | 89.3 | 224 |\n|  | Sociology | Implicit | 92.5 | 53 |\n| Persian | Literature | Culture | 51.6 | 31 |\n|  | Driving License | Explicit | 81.6 | 125 |\n|  | Professional Certification | Explicit | 43.2 | 125 |\n|  | Geography | Implicit | 66.0 | 47 |\n|  | Sociology | Implicit | 74.6 | 63 |\n| Polish | Professional Certification | Explicit | 80.0 | 496 |\n|  | Math | Agnostic | 61.7 | 47 |\n| Portuguese | Agriculture | Implicit | 70.0 | 40 |\n|  | Philosophy | Implicit | 83.3 | 84 |\n|  | Management | Implicit | 57.9 | 57 |\n|  | Health | Implicit | 70.3 | 37 |\n|  | Economics | Implicit | 89.7 | 126 |\n| Russian | Education | Implicit | 87.0 | 69 |\n|  | Law | Explicit | 72.2 | 36 |\n|  | Management | Implicit | 66.2 | 65 |\n|  | Medicine | Explicit | 73.3 | 60 |\n|  | Marine License | Explicit | 56.5 | 69 |\n|  | Qualimetry | Explicit | 79.7 | 69 |\n|  | Economics | Implicit | 63.9 | 36 |\n| Serbian | History | Implicit | 91.5 | 235 |\n|  | Philosophy | Implicit | 87.5 | 56 |\n|  | Psychology | Implicit | 99.2 | 125 |\n|  | Sociology | Implicit | 91.1 | 45 |\n| Spanish | Language | Culture | 69.6 | 46 |\n|  | Law | Explicit | 67.0 | 109 |\n|  | Literature | Implicit | 93.8 | 64 |\n|  | Philosophy | Implicit | 90.3 | 31 |\n|  | Economics | Explicit | 95.6 | 91 |\n|  | Geography | Implicit | 86.2 | 159 |\n| Tagalog | Culturology | Culture | 91.6 | 203 |\n|  | History | Culture | 85.3 | 116 |\n|  | Language | Culture | 79.2 | 106 |\n|  | Driving License | Explicit | 90.7 | 75 |\n| Tamil | Multiple Exams | Implicit | 70.6 | 500 |\n| Telugu | Education | Implicit | 73.0 | 100 |\n|  | History | Culture | 64.7 | 119 |\n|  | History | Implicit | 63.9 | 36 |\n|  | Economics | Explicit | 60.0 | 45 |\n|  | Geography | Implicit | 73.2 | 82 |\n|  | Political Sciences | Implicit | 63.3 | 30 |\n| Turkish | History | Implicit | 71.2 | 73 |\n|  | Philosophy | Implicit | 74.6 | 63 |\n|  | Business | Implicit | 75.9 | 166 |\n|  | Geography | Implicit | 53.8 | 130 |\n|  | Sociology | Implicit | 91.7 | 36 |\n| Ukrainian | Law | Explicit | 92.4 | 250 |\n|  | Physics | Agnostic | 84.0 | 50 |\n|  | Psychology | Implicit | 79.2 | 250 |\n| Urdu | Culturology | Culture | 61.7 | 300 |\n| Uzbek | History | Implicit | 66.1 | 124 |\n|  | Law | Explicit | 60.6 | 109 |\n|  | Medical License | Explicit | 73.3 | 240 |\n| Vietnamese | History | Implicit | 88.3 | 239 |\n|  | Geography | Implicit | 80.8 | 250 |", "caption": "Table 12: GPT-4o performance for different values of k\ud835\udc58kitalic_k for in-language prompting (the output generation length) per language on Include-base and total performance gain from k\ud835\udc58kitalic_k = 50 to 512.", "description": "This table presents the performance of the GPT-40 model on the INCLUDE-BASE benchmark for different output generation lengths (k).  For each language, it shows the accuracy achieved at different values of k (50, 100, 200, and 512 tokens). The \"Total gain\" column indicates the improvement in accuracy observed when increasing the generation length from k=50 to k=512. This allows for analyzing the impact of increasing the response length on the model's performance and identifying which languages benefit most from longer generations.", "section": "5.1 GENERAL PERFORMANCE"}, {"content": "| Language | Acc (k:50) | Acc (k:100) | Acc (k:200) | Acc (k:512) | Total gain |\n|---|---|---|---|---|---| \n| Uzbek | 51.4 | 60.6 | 66.6 | 68.6 | 17.2 |\n| Armenian | 28.0 | 30.7 | 36.0 | 41.1 | 13.1 |\n| Malayalam | 57.0 | 57.4 | 61.0 | 69.9 | 12.9 |\n| Urdu | 53.7 | 56.8 | 58.8 | 62.2 | 8.5 |\n| Greek | 58.0 | 58.2 | 63.8 | 66.4 | 8.4 |\n| Korean | 60.4 | 61.0 | 62.4 | 68.8 | 8.4 |\n| Chinese | 57.2 | 61.8 | 63.5 | 65.5 | 8.3 |\n| Finnish | 63.3 | 64.4 | 67.0 | 69.1 | 5.8 |\n| Basque | 60.0 | 60.8 | 63.8 | 64.8 | 4.8 |\n| Polish | 74.1 | 75.2 | 75.4 | 78.1 | 4.0 |\n| Azerbaijani | 67.7 | 69.2 | 70.4 | 71.5 | 3.8 |\n| Dutch; Flemish | 81.9 | 82.9 | 83.8 | 85.3 | 3.4 |\n| Telugu | 63.9 | 63.9 | 64.8 | 66.6 | 2.7 |\n| Hindi | 72.0 | 72.4 | 73.7 | 74.4 | 2.4 |\n| German | 64.0 | 65.5 | 65.5 | 66.2 | 2.2 |\n| Malay | 80.6 | 81.8 | 82.4 | 82.8 | 2.2 |\n| Tamil | 67.3 | 67.3 | 67.8 | 69.5 | 2.2 |\n| Arabic | 76.3 | 76.8 | 77.9 | 78.4 | 2.1 |\n| russian | 72.6 | 73.6 | 74.1 | 74.6 | 2.0 |\n| Italian | 88.0 | 88.5 | 89.2 | 89.6 | 1.6 |\n| Spanish | 82.4 | 83.1 | 83.3 | 84.0 | 1.6 |\n| Japanese | 78.6 | 78.6 | 79.4 | 80.0 | 1.4 |\n| Georgian | 86.2 | 86.4 | 87.0 | 87.6 | 1.4 |\n| Vietnamese | 82.4 | 82.5 | 84.9 | 83.8 | 1.4 |\n| Turkish | 63.5 | 64.1 | 64.4 | 64.8 | 1.3 |\n| Kazakh | 79.2 | 79.6 | 80.4 | 80.4 | 1.2 |\n| Portuguese | 72.8 | 73.5 | 73.5 | 74.0 | 1.2 |\n| Bengali | 75.2 | 75.4 | 76.1 | 76.3 | 1.1 |\n| Persian | 60.9 | 61.1 | 61.3 | 61.9 | 1.0 |\n| Belarusian | 49.5 | 50.0 | 50.0 | 50.2 | 0.7 |\n| French | 80.0 | 80.2 | 80.4 | 80.7 | 0.7 |\n| Indonesian | 77.8 | 78.2 | 78.4 | 78.5 | 0.7 |\n| Albanian | 88.9 | 89.3 | 89.3 | 89.5 | 0.6 |\n| Lithuanian | 89.7 | 89.7 | 90.1 | 90.3 | 0.6 |\n| Estonian | 92.0 | 92.0 | 92.4 | 92.4 | 0.4 |\n| Croatian | 87.8 | 88.0 | 88.2 | 88.0 | 0.2 |\n| Hungarian | 75.3 | 75.3 | 75.5 | 75.5 | 0.2 |\n| Nepali | 71.8 | 72.0 | 71.6 | 72.0 | 0.2 |\n| Bulgarian | 90.7 | 90.7 | 90.7 | 90.7 | 0.0 |\n| Hebrew | 86.0 | 86.0 | 86.0 | 86.0 | 0.0 |\n| Macedonian | 92.4 | 92.4 | 92.4 | 92.4 | 0.0 |\n| Serbian | 91.5 | 91.5 | 91.5 | 91.5 | 0.0 |\n| Tagalog | 87.4 | 87.4 | 87.4 | 87.4 | 0.0 |\n| Ukrainian | 85.5 | 85.5 | 85.5 | 85.5 | 0.0 |", "caption": "Table 13: Accuracy of the multilingual and monolingual models for answering Include-base questions for specific target languages.", "description": "This table compares the performance of various multilingual and monolingual large language models (LLMs) on the INCLUDE-BASE benchmark.  It shows the accuracy of each model on specific target languages, highlighting the differences in performance between multilingual and monolingual approaches for various languages.  The benchmark focuses on evaluating models' ability to understand and reason within the actual linguistic environments where they are meant to be used.", "section": "5 Results & Analysis"}, {"content": "| Major training language | SoTA Monolingual | Monolingual Acc | GPT-4o | Qwen2.5-14B | Qwen2.5-7B |\n|---|---|---|---|---|---| \n| Chinese | Baichuan-7B | 38.7 | 68.1 | 82.2 | 78.3 |\n| Arabic | SILMA-9B-Instruct | 56.9 | 78.1 | 70.5 | 61.6 |\n| Japanese | calm2-7b-chat | 25.0 | 75.0 | 69.2 | 64.7 |\n| Korean | Korean-Mistral-Nemo-sft-dpo-12B | 35.3 | 75.0 | 83.2 | 76.8 |\n| Russian | ruGPT-3.5-13B | 53.8 | 69.0 | 68.2 | 59.6 |\n| German | SauerkrautLM-v2-14b-DPO | 56.8 | 66.2 | 58.3 | 56.1 |", "caption": "Table 14: R2superscript\ud835\udc452R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT scores between the performance different models for newly-collected data and existing benchmarks stratified by language and model.", "description": "This table presents the R-squared (R\u00b2) values, a statistical measure indicating the goodness of fit of a model, comparing the performance of different language models on newly collected data against existing benchmarks.  The R\u00b2 values are calculated separately for each language and for each model, illustrating the correlation between the model's performance on the new dataset and its performance on established benchmarks. This allows for an assessment of how well a model's performance on known datasets predicts its performance on this new multilingual dataset.", "section": "5.2 Language Analysis"}, {"content": "| Language | R<sup>2</sup> | Model | R<sup>2</sup> |\n|---|---|---|---| \n| **Albanian** | 0.646 | **GPT-4o** | 0.077 |\n| **Chinese** | 0.985 | **Qwen2.5-14B** | 0.546 |\n| **French** | 0.770 | **Aya-expanse-32B** | 0.290 |\n| **German** | 0.495 | **Aya-expanse-8B** | 0.333 |\n| **Italian** | 0.953 | **Qwen2.5-7B** | 0.412 |\n| **Lithuanian** | 0.945 | **Mistral-7B** | 0.231 |\n| **Persian** | 0.833 | **Gemma-7B** | 0.001 |\n| **Polish** | 0.831 | **Llama 3.1-70B** | 0.020 |\n| **Portuguese** | 0.930 | **Llama 3.1-8B** | 0.001 |", "caption": "Table 15: Existing published benchmarks descriptives and the comparison with Include-base.", "description": "This table provides a comparison of INCLUDE with existing multilingual benchmarks.  It details the languages covered by each benchmark, the types of knowledge assessed (e.g., academic, region-specific, or general knowledge), and the percentage of questions in each benchmark focusing on region-agnostic vs. region-related topics. This allows for a clear understanding of how INCLUDE differs from and builds upon previous efforts in evaluating multilingual language models.", "section": "Related Work"}, {"content": "| Benchmark | Language | Knowledge Coverage | Region agnostic (%) | Region related (%) |\n|---|---|---|---|---|\n| ArabicMMLU | Arabic | Academic knowledge (elementary school, high school, university), Driving License | 24.8% | 75.2% |\n| CMMLU | Chinese | Academic knowledge (elementary school, high school, university) | 25.6% | 74.4% |\n| PersianMMLU | Persian | Academic knowledge (elementary school, high school, university) | 63.1% | 36.9% |\n| TurkishMMLU | Turkish | Academic knowledge (elementary school, high school, university) | 34.8% | 65.2% |\n| VNHSGE | Vietnamese | High school examinations | 40.4% | 59.6% |\n| EXAMS | 16 languages | High school examinations | 43.7% | 56.3% |\n| **Include (ours)** | **44 languages** | Academic knowledge (elementary school, high school, university), Professional examinations (Medical exam, Bar exam, Teaching exam), Occupational Licenses (Driving license, Marine license and more) | 7.8% | **92.2%** |", "caption": "Table 16: Breakdown of error types.", "description": "This table breaks down the types of errors made by the model during the evaluation, categorizing them into four main types: computational errors, factual knowledge errors, regional knowledge errors, and model hallucinations.  It provides the percentage of total errors that fall into each category, offering insights into the specific areas where the model struggles.", "section": "5.2 Language Analysis"}]