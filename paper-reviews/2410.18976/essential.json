{"importance": "This paper is crucial for researchers working on large multimodal models (LMMs), particularly those focusing on Arabic language processing.  It introduces a much-needed comprehensive benchmark, CAMEL-Bench, addressing the scarcity of Arabic-centric LMM evaluation resources.  The benchmark's open-source nature and diverse tasks will significantly advance research and development in cross-lingual and cross-cultural LMMs.", "summary": "CAMEL-Bench: a new open-source benchmark rigorously evaluates Arabic LMMs across 8 diverse domains and 38 sub-domains, revealing significant room for improvement even in top models.", "takeaways": ["CAMEL-Bench, a new comprehensive Arabic LMM benchmark with 29,036 questions across 8 diverse domains, is introduced.", "Evaluation reveals substantial performance gaps in current Arabic LMMs, highlighting areas for improvement.", "The benchmark and evaluation scripts are publicly available, fostering further research and development in Arabic language LMMs."], "tldr": "Researchers have developed CAMEL-Bench, a first-of-its-kind extensive benchmark for evaluating large multimodal models (LMMs) that understand and reason using Arabic.  Most existing LMM benchmarks primarily focus on English, neglecting the significant Arabic-speaking population. CAMEL-Bench includes eight diverse domains (like image understanding, video analysis, and medical imaging) with 38 sub-domains and over 29,000 questions.  The questions were carefully checked by native Arabic speakers.  Testing several LMMs (both open-source and closed-source) revealed a need for improvement, even among advanced models like GPT-4.  CAMEL-Bench is open-source, allowing researchers worldwide to contribute to and further develop Arabic LMMs."}