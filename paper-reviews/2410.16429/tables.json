[{"figure_path": "2410.16429/tables/table_13_0.html", "caption": "Table 1: LLM parameters for DSP Experiment", "description": "The table lists the maximum number of tokens, top P, and temperature values used for both the GPT-4 and GPT-01-preview language models in the DSP experiment.", "section": "5 Evaluation"}, {"figure_path": "2410.16429/tables/table_14_0.html", "caption": "Table 2: DSP's proof success rate (in %) using the Pantograph interface on the MiniF2F formal theorem proving benchmark. We used GPT-40 (labeled 40) and ol-preview (labeled o1) for the DSP experiments.", "description": "Table 2 presents the success rate of the Draft-Sketch-Proof (DSP) approach using different language models and varying numbers of proof sketches on the MiniF2F benchmark.", "section": "5 Evaluation"}]