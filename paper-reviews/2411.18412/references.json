{"references": [{"fullname_first_author": "Samira Abnar", "paper_title": "Exploring the limits of large scale pre-training", "publication_date": "2022-00-00", "reason": "This paper explores the benefits of large-scale pre-training which is a core concept used in the proposed method."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2021-00-00", "reason": "This paper introduces the Low Rank Adaptation (LoRA) technique, a crucial component of the proposed adaptive model."}, {"fullname_first_author": "Syed Waqas Zamir", "paper_title": "Restormer: Efficient transformer for high-resolution image restoration", "publication_date": "2022-00-00", "reason": "This paper presents the Restormer architecture, which is the foundation of the baseline model."}, {"fullname_first_author": "Boyun Li", "paper_title": "All-in-one image restoration for unknown corruption", "publication_date": "2022-00-00", "reason": "This paper introduces the all-in-one image restoration model which is directly related to the proposed model."}, {"fullname_first_author": "Sangdoo Yun", "paper_title": "CutMix: Regularization strategy to train strong classifiers with localizable features", "publication_date": "2019-00-00", "reason": "This paper introduces CutMix data augmentation, used in the pre-training phase of the proposed method."}]}