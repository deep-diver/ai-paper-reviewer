[{"figure_path": "https://arxiv.org/html/2411.10499/x2.png", "caption": "Figure 1: FitDiT demonstrates exceptional performance in virtual try-on, addressing challenges related to texture-aware preservation and size-aware fitting across various scenarios.", "description": "Figure 1 showcases the superior performance of the FitDiT model in virtual try-on scenarios. It highlights the model's ability to accurately reproduce fine garment details, such as textures and patterns, while maintaining correct garment sizing across different body types and clothing styles.  This demonstrates FitDiT's effectiveness in overcoming common challenges in virtual try-on, namely preserving texture quality and achieving accurate size-aware fitting.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2411.10499/x3.png", "caption": "Figure 2: FitDiT employs a two-stage training strategy. In the first stage, Garment Priors Evolution is utilized to fine-tune GarmentDiT for enhanced clothing feature extraction. In the second stage, we customize the DiT blocks through structure slimming, garment condition modulation, and high-resolution garment feature injection, resulting in DenoisingDiT for the try-on. DenoisingDiT is trained jointly using frequency loss and denoising loss.", "description": "FitDiT uses a two-stage training process.  The first stage, Garment Priors Evolution, refines the GarmentDiT model to better extract clothing features. The second stage customizes the DiT blocks within the model. This customization involves three key steps: structure slimming (reducing model complexity), garment condition modulation (adapting the model to different garment types), and high-resolution garment feature injection (enhancing fine details). The final model, DenoisingDiT, is then trained using both a frequency loss (to improve high-frequency details like textures and patterns) and a standard denoising loss.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.10499/x4.png", "caption": "Figure 3: Previous works tend to fill the entire inpainting area due to a strict mask strategy. In contrast, FitDiT can accurately restore the shape of the garment with the dilated-relaxed mask strategy.", "description": "Figure 3 illustrates the difference between conventional approaches and FitDiT in handling the inpainting mask for virtual try-on. Traditional methods often use a strict mask, leading to inaccurate garment shapes by filling the entire masked area.  In contrast, FitDiT employs a 'dilated-relaxed mask' strategy. This allows for more accurate garment shape restoration by adapting the mask's size and position to fit the garment, preventing the unnatural effect of the garment overflowing the boundaries of the intended area.  This strategy is particularly beneficial for cross-category try-ons where garment sizes and shapes differ significantly.", "section": "3.3 Dilated-relaxed Mask Strategy"}, {"figure_path": "https://arxiv.org/html/2411.10499/x5.png", "caption": "Figure 4: Frequency domain gaps between the real and the generated images by different algorithms.", "description": "Figure 4 visualizes the differences in frequency domain between real garment images and those generated by various virtual try-on algorithms.  A Discrete Fourier Transform (DFT) is applied to both real and generated images to convert them from spatial domain to frequency domain. The resulting frequency spectrums are then compared, revealing the gaps or discrepancies between real and synthesized images. The visualization highlights how well each algorithm captures high-frequency details, such as fine textures and patterns, which are crucial for realistic garment rendering. Larger gaps indicate a poorer performance in terms of detail preservation.", "section": "3.4 Garment Texture Enhancement"}, {"figure_path": "https://arxiv.org/html/2411.10499/x6.png", "caption": "Figure 5: Attention-related parameter ratios at various resolutions.", "description": "This figure shows a bar chart comparing the proportion of model parameters allocated to different attention resolutions across various diffusion models.  It highlights the varying emphasis different models place on high-resolution features (important for detail preservation) versus low-resolution features.  The models compared include SD v1.5, SDXL, SD3, and FitDiT.  The x-axis represents different attention resolutions, and the y-axis shows the percentage of parameters assigned to each resolution.", "section": "3. Customization of DiT for Virtual Try-on"}, {"figure_path": "https://arxiv.org/html/2411.10499/x7.png", "caption": "Figure 6: Visual results on CVDD with complex garment texture, cross-categories, and in-the-wild try-on. Best viewed when zoomed in.", "description": "Figure 6 presents a qualitative comparison of virtual try-on results on the Complex Virtual Dressing Dataset (CVDD).  It showcases the performance of FitDiT and other state-of-the-art methods on three challenging scenarios: garments with complex textures (e.g., intricate patterns and text), cross-category try-ons (applying garments designed for different body parts to the same person), and in-the-wild try-ons (applying garments to images of people in various unconstrained settings). The figure visually demonstrates FitDiT's ability to generate more realistic and accurate try-on results compared to other models, particularly in handling complex textures and mismatched garment types.", "section": "4. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2411.10499/x8.png", "caption": "Figure 7: Visual results on DressCode and VTON-HD test set. Best viewed when zoomed in.", "description": "Figure 7 presents a qualitative comparison of virtual try-on results on the DressCode and VITON-HD datasets.  The figure displays pairs of input images (person and garment) followed by the virtual try-on results generated by FitDiT and several other state-of-the-art methods (CatVTON, OOTDiffusion, IDM, and Kolors). This allows for a visual assessment of the different methods' abilities to generate realistic and accurate virtual try-ons, considering various garment types, styles, and poses. The results showcase FitDiT's superior performance in terms of fidelity, detail preservation, and overall visual quality.  For optimal viewing, zooming in is recommended.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.10499/x9.png", "caption": "Figure 8: Visual validation of the role of dilated-relaxed mask.", "description": "Figure 8 presents a comparison of virtual try-on results generated using different masking strategies.  It demonstrates the improved garment fitting achieved by FitDiT's dilated-relaxed mask compared to a standard, strict mask, particularly in cross-category try-on scenarios where the garment and person image may have size mismatches.  The dilated-relaxed mask allows for more accurate shape prediction of the garment and prevents unrealistic covering of the entire masked area.", "section": "4.5. Ablation Study"}]