{"references": [{"fullname_first_author": "Jacob Austin", "paper_title": "Program synthesis with large language models", "publication_date": "2021-00-00", "reason": "This paper is foundational for research on using large language models for program synthesis, a key technique used in training Android agents."}, {"fullname_first_author": "Andrea Burns", "paper_title": "Mobile app tasks with iterative feedback (motif): Addressing task feasibility in interactive visual environments", "publication_date": "2021-00-00", "reason": "This paper introduced the MOTIF benchmark, which directly inspired the design of ANDROIDLAB's benchmark for evaluating Android agents."}, {"fullname_first_author": "Mark Chen", "paper_title": "Evaluating large language models trained on code", "publication_date": "2021-00-00", "reason": "This paper provides a comprehensive evaluation of large language models trained on code, which is relevant to evaluating Android agents that interact with code-based apps."}, {"fullname_first_author": "Xiang Deng", "paper_title": "Mind2web: Towards a generalist agent for the web", "publication_date": "2023-00-00", "reason": "Mind2Web is a relevant benchmark for evaluating generalist agents, and the ideas of this work were referenced when designing the ANDROIDLAB framework."}, {"fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents", "publication_date": "2024-00-00", "reason": "ANDROIDWORLD is a recent and highly relevant benchmark for Android agents, and many design choices in ANDROIDLAB were made in response to this work."}]}