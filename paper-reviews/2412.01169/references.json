{"references": [{"fullname_first_author": "Dosovitskiy Alexey", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-10-11", "reason": "This paper introduced the Vision Transformer (ViT), a foundational model for many image processing tasks, which is directly relevant to the multi-modal approach in OmniFlow."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-MM-DD", "reason": "This paper introduces the Rectified Flow framework, which is the basis for OmniFlow's multi-modal extension and performance improvements."}, {"fullname_first_author": "Fan Bao", "paper_title": "One transformer fits all distributions in multi-modal diffusion at scale", "publication_date": "2023-MM-DD", "reason": "This paper explores multi-modal diffusion models, providing a relevant comparison and context for OmniFlow's approach."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2022-07-12", "reason": "This paper introduces classifier-free guidance, a technique used to improve the control and quality of generated images, which is adapted for OmniFlow's multi-modal setting."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-MM-DD", "reason": "This paper presents Stable Diffusion, a key model in the field, which OmniFlow builds upon and extends to achieve any-to-any generation."}]}