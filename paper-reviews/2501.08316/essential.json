{"importance": "This paper is important because it presents **a novel Adversarial Post-Training (APT) method** for achieving one-step video generation. This is a significant advancement in the field of diffusion models as it addresses the slow and expensive iterative generation process inherent in traditional methods. The approach of directly training against real data following diffusion pre-training is innovative and **achieves comparable or better quality than state-of-the-art methods** while offering real-time generation capability, opening new doors for research on high-quality, efficient video generation. The use of approximated R1 regularization is a valuable contribution, addressing a key challenge in large-scale GAN training. The findings offer valuable insights for improving the efficiency and quality of video generation using diffusion models, a highly active area of research. ", "summary": "Seaweed-APT: Real-time, one-step video generation via adversarial post-training, achieving state-of-the-art quality.", "takeaways": ["Adversarial Post-Training (APT) enables real-time one-step video generation.", "Seaweed-APT achieves high-resolution (1280x720, 24fps) video generation comparable to state-of-the-art methods.", "Approximated R1 regularization improves the stability and quality of adversarial training for large diffusion models."], "tldr": "Current diffusion models for image and video generation are often slow and resource-intensive due to their iterative nature.  Existing distillation methods aim to accelerate this, but often result in significant quality loss, especially for video generation.  Prior works have primarily focused on image generation and video generation remains challenging.  High-resolution video generation is particularly computationally expensive, making real-time generation even more difficult. \nThis paper introduces Adversarial Post-Training (APT) to tackle these issues.  APT uses a pre-trained diffusion model as initialization and then fine-tunes it using an adversarial training objective against real data.  Several key improvements are introduced to stabilize training, including an approximated R1 regularization loss and architectural modifications to the discriminator.  The results demonstrate real-time generation of high-resolution (1280x720, 24fps) videos in a single step, showing comparable quality to state-of-the-art methods.  This is a substantial advancement, significantly reducing the computational cost and time required for video generation.", "affiliation": "ByteDance Seed", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2501.08316/podcast.wav"}