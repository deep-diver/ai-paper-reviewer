[{"figure_path": "2410.17897/tables/table_8_0.md", "caption": "Table 1: Zero-shot accuracy on commonsense reasoning tasks.", "description": "This table presents the zero-shot accuracy results of various models on several commonsense reasoning tasks.  The models compared are the vanilla Transformer and the ResFormer, each tested with maximum sequence lengths of 2,048 and 64,000. The tasks evaluated include HellaSwag, Obqa, WinoGrande, ARC-Challenge, ARC-Easy, and PIQA.  The table shows the zero-shot accuracy achieved by each model on each task, allowing for a comparison of performance between the vanilla Transformer and the ResFormer across different sequence lengths.", "section": "4.4 DOWNSTREAM EVALUATIONS"}, {"figure_path": "2410.17897/tables/table_14_0.md", "caption": "Table 2: The details of pre-train dataset.", "description": "This table presents the composition of the pre-training dataset used in the experiments. It lists seven different data sources: Commoncrawl, C4, GitHub, Books, ArXiv, Wikipedia, and StackExchange.  Each source is assigned a proportion representing its contribution to the overall dataset (ranging from 5% to 50%), and the approximate number of tokens (in billions) from each source is also indicated.  The total number of tokens across all sources is 20B.", "section": "4.1 SETTING"}, {"figure_path": "2410.17897/tables/table_15_0.md", "caption": "Table 5: Validation loss on slimpajama.", "description": "Table 5 presents the validation loss results on the SlimPajama dataset for different model sizes. It compares the performance of vanilla Transformer models (82M, 180M, 468M parameters) with their Resformer counterparts.  The loss is broken down for each model across several subsets of the SlimPajama dataset: Common Crawl, C4, Github, Stack Exchange, Wikipedia, Books, and Arxiv, along with a final average loss. This allows for a detailed performance comparison of both model types across different data sources and scales.", "section": "A.4 VALIDATION LOSS ON SLIMPAJAMA"}, {"figure_path": "2410.17897/tables/table_15_1.md", "caption": "Table 4: Training details for models with different size.", "description": "This table presents the training hyperparameters used for different model sizes in the experiments. It lists the settings for the number of layers, attention heads, hidden dimension, FFN dimension, whether word embeddings are tied, peak and final learning rates, learning rate schedule, vocabulary size, activation function, positional embedding method, batch size, data size, warmup steps, training steps, Adam beta parameters, dropout rate and weight decay.  These specifications are provided for four model sizes: 2M, 82M, 180M and 468M parameters.", "section": "4.1 SETTING"}, {"figure_path": "2410.17897/tables/table_15_2.md", "caption": "Table 5: Validation loss on slimpajama.", "description": "Table 5 presents the validation loss for different transformer models on the SlimPajama dataset.  It shows the average validation loss across seven categories (Common Crawl, C4, Github, Stack Exchange, Wikipedia, Book, and Arxiv) for three different sizes of vanilla Transformer models (82M, 180M, 468M parameters) and their corresponding ResFormer variants. The table allows for a comparison of the performance of the vanilla Transformer and the proposed ResFormer models across different model sizes and datasets. ", "section": "A.4 VALIDATION LOSS ON SLIMPAJAMA"}]