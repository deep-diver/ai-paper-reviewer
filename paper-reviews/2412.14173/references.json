{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets.", "publication_date": "2023-11-20", "reason": "This paper introduces Stable Video Diffusion (SVD), a foundational model for video generation upon which AniDoc is built, leveraging its ability to capture temporal dynamics and visual coherence."}, {"fullname_first_author": "Zhitong Huang", "paper_title": "LVCD: reference-based lineart video colorization with diffusion models.", "publication_date": "2024-09-21", "reason": "This work represents the state-of-the-art in reference-based line art video colorization using diffusion models and serves as a primary comparison and benchmark for AniDoc."}, {"fullname_first_author": "Philipp Lindenberger", "paper_title": "LightGlue: Local feature matching at light speed.", "publication_date": "2023-10-26", "reason": "LightGlue provides an efficient keypoint matching method used in AniDoc's training process for establishing correspondence between the reference image and sketches."}, {"fullname_first_author": "Luming Tang", "paper_title": "Emergent correspondence from image diffusion.", "publication_date": "2024-04-26", "reason": "This paper introduces DIFT, a semantic keypoint matching method employed by AniDoc during inference to robustly match keypoints between the color reference image and the sketch."}, {"fullname_first_author": "Xinyuan Chen", "paper_title": "SEINE: Short-to-long video diffusion model for generative transition and prediction.", "publication_date": "2023-04-28", "reason": "SEINE introduces a video interpolation technique that leverages pre-trained text-to-video diffusion models and additional image conditions, inspiring AniDoc's approach to handling sparse sketch inputs."}]}