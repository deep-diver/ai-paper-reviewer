[{"figure_path": "https://arxiv.org/html/2412.19638/x1.png", "caption": "Figure 1: Average Scores on Complex Reasoning Benchmarks (GSM8K, MATH, BBH, MMLU, HumanEval and MBPP).", "description": "This figure displays the average scores achieved by various large language models (LLMs) on six complex reasoning benchmarks: GSM8K, MATH, BBH, MMLU, HumanEval, and MBPP. The x-axis represents the model size in billions of parameters, and the y-axis represents the average score across the six benchmarks.  Each point represents a different LLM, with Xmodel-2 highlighted.  The figure visually compares the performance of Xmodel-2 to other LLMs of similar size, demonstrating its competitive performance on complex reasoning tasks.", "section": "3 Results"}, {"figure_path": "https://arxiv.org/html/2412.19638/x4.png", "caption": "Figure 2: Data mixture of different training stages.The left side represents the stable training phase, and the right side represents the decay phase.", "description": "This figure shows the composition of the datasets used during the training of the Xmodel-2 language model.  The training process is divided into two stages: a stable training phase and a decay phase. The left pie chart details the data sources and their proportions used in the stable training phase.  The right pie chart illustrates the distribution of data sources in the decay phase, which includes additional supervised fine-tuning (SFT) data.  The difference in dataset compositions highlights the shift in training strategies between the two phases.", "section": "2 Pretraining"}, {"figure_path": "https://arxiv.org/html/2412.19638/x5.png", "caption": "Figure 3: Loss curve for Xmodel-2-1.2B.", "description": "This figure shows the training loss curve for the Xmodel-2 1.2 billion parameter model. The x-axis represents the number of tokens processed in billions, and the y-axis represents the loss value. The curve shows a general downward trend, indicating that the model is learning and improving over time. There are two notable drops in the loss, which may correspond to changes in the training process, such as the introduction of supervised fine-tuning data or adjustments to the learning rate scheduler. The figure provides a visual representation of the model's training progress and its convergence to a lower loss, suggesting that the model is being trained effectively.", "section": "2 Pretraining"}, {"figure_path": "https://arxiv.org/html/2412.19638/x6.png", "caption": "Figure 4: Calibration plot for the pre-trained Xmodel-2-1.2B model on the MMLU dataset.", "description": "This calibration plot visualizes the reliability of the pre-trained Xmodel-2-1.2B model's confidence scores when predicting answers on the MMLU (Massive Multitask Language Understanding) dataset.  The x-axis represents the model's predicted probability (confidence) of a given answer being correct, ranging from 0 to 1. The y-axis shows the actual accuracy or proportion of correctly predicted answers among those with the corresponding confidence score. A perfectly calibrated model would show a diagonal line, indicating that a prediction with, for example, 70% confidence is correct 70% of the time. Deviations from this line highlight areas where the model is either overconfident (predicting high probability but having low accuracy) or underconfident (predicting low probability but achieving high accuracy).  The plot helps assess the trustworthiness and reliability of the model's predictions.", "section": "4 Case Study"}, {"figure_path": "https://arxiv.org/html/2412.19638/x7.png", "caption": "Figure 5: Post-training Scaling Law for Xmodel-2-1.2B on the Wikitext-2 dataset.", "description": "This figure illustrates the relationship between the number of tokens used during testing and the resulting loss (perplexity) for the Xmodel-2-1.2B model on the Wikitext-2 dataset.  The x-axis represents the number of test-time tokens, while the y-axis displays the loss.  The curve demonstrates a power-law relationship, indicating that increasing the context length initially leads to significant reductions in loss, though this improvement diminishes with further increases in context length. A fitted curve is included to capture this diminishing returns effect, showing the power-law relationship between loss and token index.", "section": "4.2 Post-training Scaling Law"}]