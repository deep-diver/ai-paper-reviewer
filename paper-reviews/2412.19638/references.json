{"references": [{"fullname_first_author": "S. Hu", "paper_title": "Minicpm: Unveiling the potential of small language models with scalable training strategies", "publication_date": "2024-04-06", "reason": "This paper introduces the Warmup-Stable-Decay (WSD) learning rate scheduler used in Xmodel-2, crucial for training efficiency and stability."}, {"fullname_first_author": "G. Yang", "paper_title": "Tensor programs v: Tuning large neural networks via zero-shot hyperparameter transfer", "publication_date": "2022-03-03", "reason": "This paper describes the Tensor Programs architecture employed in Xmodel-2, enabling efficient hyperparameter search and transfer across different model scales."}, {"fullname_first_author": "Z. Yang", "paper_title": "Qwen2 technical report", "publication_date": "2024-07-10", "reason": "This paper introduces Qwen-2, a large language model that serves as an important baseline for comparison with Xmodel-2 in the experiments."}, {"fullname_first_author": "D. Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "publication_date": "2021-03-03", "reason": "This paper introduces the MATH dataset, a key benchmark used for evaluating Xmodel-2's performance on complex reasoning tasks."}, {"fullname_first_author": "J. Thorne", "paper_title": "FEVER: A large-scale dataset for fact extraction and verification", "publication_date": "2018-03-05", "reason": "This paper introduces the FEVER dataset, one of the benchmarks used to evaluate Xmodel-2's performance on agent capabilities."}]}