{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-31", "reason": "This paper is foundational for instruction-following in LLMs, a core concept addressed and built upon in the current research."}, {"fullname_first_author": "Seongyun Lee", "paper_title": "Aligning to thousands of preferences via system message generalization", "publication_date": "2024-05-31", "reason": "This paper directly addresses system message generation and alignment, a central theme of the current work, providing a benchmark and related techniques."}, {"fullname_first_author": "Marah Abdin", "paper_title": "Phi-4 technical report", "publication_date": "2024-12-31", "reason": "This paper introduces a significant open-source LLM used in the current research for both system message generation and knowledge distillation."}, {"fullname_first_author": "An Yang", "paper_title": "Qwen2.5 technical report", "publication_date": "2024-12-31", "reason": "This paper details another important open-source LLM leveraged in the current research for system message generation and model training."}, {"fullname_first_author": "Aidar Myrzakhan", "paper_title": "Open-LLM-leaderboard: From multi-choice to open-style questions for LLMs evaluation, benchmark, and arena", "publication_date": "2024-06-30", "reason": "This paper provides a crucial benchmark for evaluating LLM performance, used to assess the impact of the proposed approach on unseen data."}]}