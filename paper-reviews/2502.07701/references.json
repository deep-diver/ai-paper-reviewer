{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2022-07-27", "reason": "This paper introduces a technique to improve the fidelity of generated images in diffusion models, which is crucial for improving the quality of the video generation in this work."}, {"fullname_first_author": "Tim Salimans", "paper_title": "Progressive distillation for fast sampling of diffusion models", "publication_date": "2022-02-01", "reason": "This paper presents a method to accelerate the sampling process of diffusion models, which is essential for efficient video generation."}, {"fullname_first_author": "Chenlin Meng", "paper_title": "On distillation of guided diffusion models", "publication_date": "2023-06-01", "reason": "This paper proposes a distillation approach for classifier-free guided diffusion models, leading to faster inference speeds which is highly relevant to the paper's goal of efficient video generation."}, {"fullname_first_author": "Rohit Girdhar", "paper_title": "Emu Video: Factorizing text-to-video generation by explicit image conditioning", "publication_date": "2023-11-07", "reason": "This paper introduces an approach to simplify the video generation task by factorizing it into two separate subtasks, which is directly adopted and improved by the current paper."}, {"fullname_first_author": "Ben Watson", "paper_title": "EM distillation for one-step diffusion models", "publication_date": "2024-05-21", "reason": "This paper presents a method to distill a diffusion model into a single-step generator, which is related to the paper's approach of accelerating the generative process through distillation."}]}