[{"page_end_idx": 2, "page_start_idx": 1, "section_number": 1, "section_title": "INTRODUCTION", "details": {"details": "Multimodal Large Language Models (MLLMs) have rapidly advanced due to their training on massive multimodal data, exhibiting capabilities beyond traditional dialogue or control systems.  They demonstrate emergent abilities like Chain-of-Thought (CoT) reasoning and In-Context Learning (ICL), making them suitable for various tasks including structured rich-content understanding and reasoning, multimodal recognition and content creation, and numerous industry applications.  The application of MLLMs to agent systems has revolutionized environment observation, task decomposition, and action decision-making.  However, applying MLLMs to mobile phone assistants presents challenges due to the dynamic and unpredictable nature of real-world GUIs. Mobile interfaces are often cluttered, contain irrelevant distractions, and require different execution methods for similar tasks. User instructions can also be ambiguous, making accurate intent interpretation difficult. Traditional mobile assistants, relying on slot-filling and API calls, struggle with complex scenarios, while end-to-end pre-trained models lack adaptability.  Recent MLLM-based agent systems show promise, but limitations remain, such as overlooking finer details, missing necessary actions, getting stuck in loops, and failing to extract and utilize relevant information efficiently.  These limitations highlight the need for more sophisticated agent architectures to address these challenges and unlock the full potential of MLLMs in mobile assistance.", "first_cons": "Current mobile assistants struggle with complex scenarios and lack adaptability across diverse applications and tasks due to their reliance on slot-filling techniques and API calls.", "first_pros": "MLLMs offer significantly enhanced capabilities for environment observation, task decomposition, and action decision-making compared to traditional dialogue or control systems.", "keypoints": ["MLLMs have seen rapid development, exhibiting emergent abilities like CoT reasoning and ICL.", "Applying MLLMs to mobile assistants presents unique challenges due to dynamic and unpredictable real-world GUIs.", "Traditional mobile assistants struggle with complex scenarios and lack versatility, while end-to-end pre-trained models are limited.", "Recent MLLM-based agents show promise but have limitations in handling details, executing necessary actions, avoiding loops, and information extraction."], "second_cons": "Existing MLLM-based mobile assistants often fail to handle finer details, miss necessary actions, get stuck in loops, and struggle to extract and effectively utilize information.", "second_pros": "The rise of MLLMs has revolutionized the development of agent systems, enabling significantly enhanced capabilities for environment observation, task decomposition, and action decision-making.", "summary": "The introduction details the rapid advancements in Multimodal Large Language Models (MLLMs) and their potential for revolutionizing agent systems, particularly mobile phone assistants. While MLLMs offer significant advantages in reasoning and decision-making, their application to mobile assistants is challenged by the dynamic and unpredictable nature of real-world GUIs, ambiguous user instructions, and the limitations of traditional methods.  Although recent MLLM-based agent systems show promise, several key limitations persist, highlighting the need for improved architectures to fully leverage the capabilities of MLLMs in mobile assistance."}}, {"page_end_idx": 3, "page_start_idx": 2, "section_number": 2, "section_title": "RELATED WORK", "details": {"details": "This section delves into existing research on Large Language Models (LLMs) and their application in creating intelligent agents, specifically focusing on those interacting with Graphical User Interfaces (GUIs). It begins by acknowledging the rapid advancement of MLLMs and their capabilities in various tasks, including reasoning and multimodal understanding.  The authors then highlight the challenges of applying these models to mobile phone assistants, emphasizing the complexity of mobile interfaces.  These complexities include cluttered screens, task-irrelevant distractions, varying execution methods for similar tasks, and the ambiguity of user instructions.  Traditional mobile assistants relying on slot-filling techniques and API calls are noted as insufficient for handling complex scenarios, while end-to-end pre-trained models lack the adaptability needed for dynamic environments.  The section then discusses existing MLLM-based agent systems and their limitations.  These limitations include overlooking finer details in task execution, failing to execute necessary but unstated actions, getting stuck in loops, and the inability to effectively extract and utilize relevant information from various sources. This is followed by an overview of existing GUI agents, categorized as traditional and MLLM-empowered. Traditional GUI agents relied on pre-defined rules and scripts, limiting their adaptability, whereas MLLM-powered GUI agents leverages multimodal data for improved understanding and more robust execution. The section concludes by highlighting the advancements in MLLMs impacting the development of GUI agents, emphasizing their enhanced capabilities in reasoning and decision-making, enabling improvements over previous approaches.", "first_cons": "Traditional mobile assistants, relying on slot-filling and API calls, struggle to handle the complexity of real-world mobile interfaces and ambiguous user instructions.", "first_pros": "MLLMs offer significant advantages over traditional methods due to their advanced capabilities in understanding, reasoning, decision-making, and self-reflection, making them ideal candidates for powering mobile assistants.", "keypoints": ["Traditional GUI agents, using slot-filling and API calls, are insufficient for handling complex mobile interface scenarios.", "MLLM-based agents offer significant improvements but still face limitations, such as overlooking finer details (56) and getting stuck in loops (31).", "End-to-end pre-trained models struggle with complex scenarios and lack the versatility needed for diverse applications."], "second_cons": "Existing MLLM-based agent systems have several limitations, including overlooking finer details in task execution, missing necessary actions, getting stuck in loops, and struggling to extract information from multiple sources. These limitations impede their effectiveness in real-world scenarios.", "second_pros": "The rise of MLLMs has revolutionized agent systems, leading to significant enhancements in environment observation, task decomposition, and action decision-making capabilities, especially in comparison to traditional dialogue or control systems.", "summary": "This section reviews the existing literature on LLM-based agents for mobile task automation, highlighting the challenges of using LLMs in this context and evaluating previous approaches' strengths and limitations. It underscores the need for more robust and adaptive agents capable of handling the complexities of real-world mobile interfaces and user instructions, setting the stage for the introduction of the proposed MOBA system in the following section."}}, {"page_end_idx": 3, "page_start_idx": 3, "section_number": 3, "section_title": "THE MOBA SYSTEM", "details": {"details": "The MOBA system is a two-level agent system designed for efficient mobile task automation. It leverages a multimodal large language model (MLLM) to enhance comprehension and planning capabilities.  The system consists of a Global Agent (GA) and a Local Agent (LA). The GA is responsible for high-level task planning and decomposition, while the LA concentrates on selecting target actions for each sub-task.  This division of responsibilities facilitates better task management and reduces the complexity of decision-making.  A crucial component is the Plan Module, which decomposes complex tasks into smaller, manageable sub-tasks. The system also incorporates a double-reflection mechanism to verify sub-task completion, correct errors, and prevent ineffective operations. The system employs a Multi-aspect Memory Module which stores task execution traces, user preferences, application information, and contextual information to enhance the agent's adaptability and reduce redundancy. The workflow is described in Algorithm 1, which highlights task execution process, including validation of complete possibility, action generation, and reflection.  The system's architecture, as shown in Figure 2, illustrates this detailed workflow, highlighting the interaction between various modules, especially the double-reflection mechanism to ensure task accuracy.  The Local Agent uses various actions listed in Table 1 to execute tasks, ranging from simple clicks to more complex app-opening and text input functions. ", "first_cons": "The effectiveness of MOBA heavily relies on accurate initial task decomposition.  Incorrect decomposition can lead to task failures or cyclical failures if sub-tasks cannot be further decomposed or completed.", "first_pros": "The two-level agent structure, inspired by the human brain, facilitates better task management and enhances efficiency by dividing responsibilities between high-level planning and low-level execution.", "keypoints": ["Two-level agent structure (Global Agent for planning, Local Agent for execution)", "Double-reflection mechanism for error correction and efficiency", "Multi-aspect Memory Module for enhanced adaptability and reduced redundancy", "Task decomposition into manageable sub-tasks (Plan Module)", "Algorithm 1 details the task execution process", "66.2% milestone score rate in MOBBENCH evaluation"], "second_cons": "MOBA's performance depends heavily on the accuracy of view hierarchy (VH) information from XML files for understanding the mobile interface. Discrepancies between XML content and actual screen elements can negatively impact performance.", "second_pros": "MOBA demonstrates significant improvements in task execution efficiency and completion rate (66.2% milestone score rate). The double-reflection mechanism enhances the system's robustness.", "summary": "The MOBA system is a two-level agent system for mobile task automation that uses a multimodal large language model for enhanced understanding and planning.  It features a Global Agent for high-level task planning and a Local Agent for execution, along with a double-reflection mechanism and a multi-aspect memory module for improved accuracy and efficiency.  This sophisticated design results in a 66.2% milestone score rate in real-world evaluations, significantly outperforming other approaches."}}, {"page_end_idx": 11, "page_start_idx": 9, "section_number": 4, "section_title": "EXPERIMENTS", "details": {"details": "The experiments section evaluates the performance of MobA, a novel mobile phone agent system, using the MOBBENCH test set, which consists of 50 real-world tasks across 10 applications.  The tasks are categorized by difficulty (Easy, Medium, Hard, Indirect Comprehension) and include cross-application tasks involving multiple apps.  MobA is compared against several baseline agents: Human Baseline, GPT-4 + Human Baseline, AppAgent, and MobileAgent(v2).  The evaluation uses three metrics: Milestone Score (MS), Complete Rate (CR), and Execution Efficiency (EE).  MobA demonstrates the highest milestone score rate of 66.2%, surpassing the second-highest baseline agent by over 17%. Ablation studies show the significant contribution of both the Memory and Plan Modules to MobA's performance.  Case studies illustrate MobA's ability to handle complex tasks through task decomposition and reflection mechanisms. The paper notes that while MobA shows significant improvement, there are still limitations, such as dependence on accurate initial task decomposition and the availability of view hierarchy information for the interface.", "first_cons": "MobA's performance relies heavily on accurate initial task decomposition and the availability of view hierarchy (VH) information. Inaccurate decomposition can lead to task failure, and the absence of VH information, due to technical limitations, forces reliance on less reliable visual methods such as OCR and object detection.", "first_pros": "MobA achieves a milestone score rate of 66.2%, significantly outperforming other baseline agents (the second-best performed at 48.9%). This demonstrates a substantial improvement in task execution efficiency and completion rate.", "keypoints": ["MobA achieves a 66.2% milestone score rate, exceeding the second-best baseline by over 17%.", "The MOBBENCH test set includes 50 real-world tasks across 10 applications and varying difficulty levels.", "Three evaluation metrics are used: Milestone Score, Complete Rate, and Execution Efficiency.", "Ablation studies highlight the significant contribution of the Memory and Plan Modules to MobA's performance."], "second_cons": "The execution pipeline's frequent calls to large language models (LLMs) increase both time and token consumption, potentially hindering efficiency.  The reliance on VH information makes MobA vulnerable to inaccuracies in the XML file representing the interface.", "second_pros": "The two-level agent structure and inclusion of Memory and Plan Modules enhance MobA's ability to learn from past experiences, improving both efficiency and accuracy.  The use of multiple metrics (Milestone Score, Complete Rate, and Execution Efficiency) provides a comprehensive evaluation of MobA's capabilities.", "summary": "The experiments section rigorously evaluates MobA's performance on 50 real-world mobile tasks using three metrics and compares it against four baselines.  MobA significantly outperforms the baselines, achieving a 66.2% milestone score rate, highlighting the effectiveness of its two-level agent architecture, memory module, and task planning pipeline. However, limitations exist concerning its dependence on accurate task decomposition and reliable view hierarchy information."}}]