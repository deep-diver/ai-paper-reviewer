{"references": [{"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-31", "reason": "This paper is foundational, establishing the superiority of diffusion models over GANs for image synthesis, which heavily influenced the field of video generation models."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-31", "reason": "This work introduced denoising diffusion probabilistic models (DDPMs), a fundamental concept underlying many modern diffusion models, including those for video generation."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-12-31", "reason": "This paper introduced Diffusion Transformers (DiT), a crucial architectural advancement enabling the scaling of diffusion models to higher capacities, directly relevant to video generation's increased demand for larger models."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with clip latents", "publication_date": "2022-04-01", "reason": "This work demonstrated the effectiveness of leveraging CLIP for text-conditional image generation, a technique that has also proven highly impactful in video generation which often requires text prompts."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-12-31", "reason": "This paper significantly advanced the capabilities of text-to-image diffusion models by integrating deep language understanding, which directly influences the development of text-to-video models."}]}