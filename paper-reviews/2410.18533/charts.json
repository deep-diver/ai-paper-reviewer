[{"figure_path": "2410.18533/charts/charts_1_0.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various long-context models (LCMs) on real-world tasks, their retrieval and recall scores on a synthetic task, and their training data sizes.", "section": "ABSTRACT"}, {"figure_path": "2410.18533/charts/charts_1_1.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various long-context models (LCMs) on real-world and synthetic tasks, showing their retrieval and recall scores along with the training data size.", "section": "Introduction"}, {"figure_path": "2410.18533/charts/charts_1_2.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various Long-Context Models (LCMs) on real-world and synthetic tasks, showing their retrieval and recall scores, and relating performance to training data size.", "section": "INTRODUCTION"}, {"figure_path": "2410.18533/charts/charts_8_0.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various Long-Context Models (LCMs) on real-world and synthetic tasks, showing retrieval and recall scores, and relating them to the training data size.", "section": "INTRODUCTION"}, {"figure_path": "2410.18533/charts/charts_8_1.png", "caption": "Figure 4: Evaluation results of language modeling task. The solid and dashed curves represent the PPL of the baselines and LOGO, respectively.", "description": "The chart displays the perplexity (PPL) scores of several large language models (LLMs) with and without LOGO training across varying context lengths, showing LOGO's impact on language modeling performance.", "section": "4.3 PERFORMANCE ON SHORT-CONTEXT TASKS"}, {"figure_path": "2410.18533/charts/charts_9_0.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart compares the performance of various long-context models (LCMs) on real-world and synthetic tasks, showing retrieval and recall scores, and training data sizes.", "section": "INTRODUCTION"}, {"figure_path": "2410.18533/charts/charts_9_1.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various long-context models (LCMs) on real-world tasks, their retrieval and recall scores on a synthetic task, and their respective training data sizes.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18533/charts/charts_9_2.png", "caption": "Figure 6: Ablation study results. (a) Comparison among different settings on the language modeling task (PPL) and real-world tasks (Avg. score on LongBench testing set); (b) Reward difference distribution under different M settings; (c) Training GPU memory consumption of different settings.", "description": "The chart displays ablation study results, showing the impact of different settings (number of dis-preference instances, SFT regularization, context length) on language modeling performance and real-world task performance, as well as GPU memory consumption.", "section": "5 ABLATION STUDY"}, {"figure_path": "2410.18533/charts/charts_10_0.png", "caption": "Figure 1: (a) Performance of LCMs on real-world long-context tasks; (b) Retrieval score (long-context understanding ability) and recall score (generation ability) of LCMs on the synthetic retrieval long-context task (multi-value NIAH); (c) Long-context (pre-)training data size for each LCM.", "description": "The chart displays the performance of various long-context models (LCMs) on real-world and synthetic tasks, showing retrieval and recall scores and correlating them with training data size.", "section": "Introduction"}]