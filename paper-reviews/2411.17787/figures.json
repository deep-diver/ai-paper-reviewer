[{"figure_path": "https://arxiv.org/html/2411.17787/x1.png", "caption": "Figure 1: We partition the next-scale prediction process into the efficient collaboration between large and small VAR models.", "description": "This figure illustrates the core concept of Collaborative Decoding (CoDe).  The original Visual Autoregressive (VAR) model's next-scale prediction process is computationally expensive due to the lengthy token sequence involved. CoDe addresses this by dividing the process into two collaborative stages.  A larger VAR model (2B parameters) acts as the 'drafter', generating low-frequency content at smaller scales quickly. A smaller VAR model (0.3B parameters) acts as the 'refiner', focusing on predicting high-frequency details at larger scales. This collaboration reduces computational redundancy and memory usage without significant quality loss, resulting in increased efficiency. The figure visually shows the parallel processing of drafting and refining steps in the multi-scale inference process, showcasing the time and memory savings achieved by CoDe compared to the traditional VAR approach.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.17787/x2.png", "caption": "Figure 2: Comparison of generation results between original VAR-d30 (up) and our VAR-CoDE (bottom) for ImageNet 256\u00d7\\times\u00d7256. Our method achieves 1.7x speedup (3.62s to 2.11s), and needs only 0.5x memory space (40GB to 20GB), with negligible quality degradation.", "description": "This figure compares image generation results between the original VAR-d30 model and the proposed VAR-CoDe model on the ImageNet 256x256 dataset.  The top row shows images generated using the original VAR-d30 model, highlighting its generation time of 3.62 seconds and memory usage of 40GB. The bottom row displays images generated by the VAR-CoDe method, demonstrating a 1.7x speedup (2.11 seconds) and a 50% reduction in memory usage (20GB). Importantly, the visual quality remains almost identical between the two methods, indicating negligible quality degradation due to the efficiency improvements achieved by VAR-CoDe.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.17787/x3.png", "caption": "Figure 3: (a) Effectiveness of increasing parameters at the k\ud835\udc58kitalic_k-th scale is evaluated by predicting token map rksubscript\ud835\udc5f\ud835\udc58r_{k}italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT using four VAR models with different parameter sizes (2B, 1B, 0.6B, and 0.3B), while other scales (r1,r2,\u2026,rk\u22121,rk+1,\u2026,r10)subscript\ud835\udc5f1subscript\ud835\udc5f2\u2026subscript\ud835\udc5f\ud835\udc581subscript\ud835\udc5f\ud835\udc581\u2026subscript\ud835\udc5f10(r_{1},r_{2},\\dots,r_{k-1},r_{k+1},\\dots,r_{10})( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_r start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT , \u2026 , italic_r start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) are generated using the largest VAR-d30 model. (b) Fourier spectrum analysis is conducted on generated content at the first 3 scales and the last 3 scales. (c) Training-free performance comparison of model collaboration decoding across various settings of draft tokens M\ud835\udc40Mitalic_M and refiner tokens 680\u2212M680\ud835\udc40680-M680 - italic_M.", "description": "Figure 3 demonstrates three key aspects of the Collaborative Decoding (CoDe) method. (a) It shows that increasing model parameters is more effective in improving the quality of generated content at smaller scales than at larger scales. This is done by using different sized models to generate tokens at different scales. (b) Fourier analysis shows that smaller scales generate low-frequency information, while larger scales generate high-frequency detail. (c) Shows the effect of varying the number of drafting and refining tokens on the final model's performance.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.17787/x4.png", "caption": "Figure 4: Overview of the collaborative decoding process, we use a drafting step N=6\ud835\udc416N=6italic_N = 6 for instance. CoDe uses a large VAR model as the drafter \u03f5\u03b8dsubscriptitalic-\u03f5subscript\ud835\udf03\ud835\udc51\\epsilon_{\\theta_{d}}italic_\u03f5 start_POSTSUBSCRIPT italic_\u03b8 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT to generate the token maps RL=(r1,r2,\u2026,rN)subscript\ud835\udc45\ud835\udc3fsubscript\ud835\udc5f1subscript\ud835\udc5f2\u2026subscript\ud835\udc5f\ud835\udc41R_{L}=(r_{1},r_{2},\\ldots,r_{N})italic_R start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_r start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) at smaller scales. The small refiner model \u03f5\u03b8rsubscriptitalic-\u03f5subscript\ud835\udf03\ud835\udc5f\\epsilon_{\\theta_{r}}italic_\u03f5 start_POSTSUBSCRIPT italic_\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT then uses RLsubscript\ud835\udc45\ud835\udc3fR_{L}italic_R start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT as an initial prefix to efficiently predict the remaining token maps RH=(rN+1,rN+2,\u2026,rK)subscript\ud835\udc45\ud835\udc3bsubscript\ud835\udc5f\ud835\udc411subscript\ud835\udc5f\ud835\udc412\u2026subscript\ud835\udc5f\ud835\udc3eR_{H}=(r_{N+1},r_{N+2},\\ldots,r_{K})italic_R start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT = ( italic_r start_POSTSUBSCRIPT italic_N + 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_N + 2 end_POSTSUBSCRIPT , \u2026 , italic_r start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT ) at larger scales. Both models are fine-tuned on their designated predictive scales using ground truth labels rk\u2217superscriptsubscript\ud835\udc5f\ud835\udc58r_{k}^{*}italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT and teacher logits pteacher\u2062(rk)subscript\ud835\udc5dteachersubscript\ud835\udc5f\ud835\udc58p_{\\text{teacher}}(r_{k})italic_p start_POSTSUBSCRIPT teacher end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), respectively.", "description": "This figure illustrates the collaborative decoding process used in the proposed CoDe method. A large VAR model (the drafter) initially generates low-frequency token maps for smaller scales (up to scale N, where N=6 in this example). Then, a smaller VAR model (the refiner), using these token maps as a prefix, efficiently predicts the remaining high-frequency token maps for larger scales. Both models undergo fine-tuning using ground truth labels and teacher logits to optimize their performance at specific scales.", "section": "3.3. Collaborative Decoding"}, {"figure_path": "https://arxiv.org/html/2411.17787/x5.png", "caption": "Figure 5: (a) Our CoDe demonstrates the optimal efficiency-quality trade-off among all evaluated methods. (b) Inference latency is measured across varying batch sizes for the original VAR-d30, our CoDe (N=6), and the VQVAE decoder. (c) We analyze the time cost associated with parallel decoding at each scale, showing that the refiner model is significantly more efficient than the drafter at larger scales.", "description": "Figure 5 presents a comparison of different image generation methods, focusing on efficiency and quality. (a) shows that CoDe achieves the best balance between speed and FID score compared to other methods. (b) compares the inference latency of CoDe and VAR-d30 across different batch sizes, demonstrating CoDe's efficiency. Finally, (c) shows that in the multi-scale decoding process of CoDe, the refiner model is more efficient at larger scales than the drafter model.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.17787/x6.png", "caption": "Figure 6: Qualitative comparison between the original VAR-d30 model and our proposed CoDe model, with different drafting steps.", "description": "This figure displays a qualitative comparison of image generation results between the original VAR-d30 model and the proposed CoDe model with varying drafting steps (N=6, 7, 8).  Each row shows generated images from a model, highlighting the speed and memory efficiency gains achieved by CoDe while maintaining comparable image quality.  The original VAR-d30 serves as the baseline, illustrating the trade-off between speed and quality as the number of drafting steps decreases.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.17787/x7.png", "caption": "Figure 7: Qualitative results of CoDe\u2019s zero-shot generalization on image inpainting and image editing.", "description": "This figure showcases the zero-shot generalization capabilities of the Collaborative Decoding (CoDe) method on image inpainting and image editing tasks.  The results demonstrate CoDe's ability to perform these tasks without any additional training.  The images presented illustrate examples of the inpainting and editing results achieved using CoDe.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.17787/x8.png", "caption": "Figure 8: Up: images generated by the original VAR-d16 models. Down: images generated by the perturbation fine-tuned VAR-d16.", "description": "This figure shows a comparison of image generation results between the original VAR-d16 model and a version fine-tuned using a perturbation technique.  The \"Up\" section displays images generated by the standard VAR-d16 model, showcasing its typical output. The \"Down\" section shows images generated after the model underwent perturbation fine-tuning, which selectively modifies the model's parameters for higher-frequency components in the final scales, specifically focusing on details. By comparing the two sets of images, one can visually assess the impact of this perturbation method on the generated image quality and detail preservation.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.17787/x9.png", "caption": "Figure 9: Qualitative comparison between the original VAR-d30 model and our proposed CoDe model, with different drafting steps.", "description": "This figure presents a qualitative comparison of images generated by the original VAR-d30 model and the CoDe model with varying numbers of drafting steps (N=9, 8, 7, 6).  Each row shows a set of generated images for the same set of prompts. The goal is to visually demonstrate how CoDe's speed improvements (shown numerically in the caption) do not significantly impact image quality.  The increasing speed is achieved by reducing the number of drafting steps and thereby reducing computational demands.  A visual inspection allows assessing whether the speed improvements come at the cost of image quality.", "section": "4. Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.17787/x10.png", "caption": "Figure 10: Qualitative comparison between the original VAR-d30 model and our proposed CoDe model, with different drafting steps.", "description": "Figure 10 presents a qualitative comparison of image generation results between the original VAR-d30 model and the proposed CoDe model with varying numbers of drafting steps (N). Each row displays images generated using a different model (original VAR-d30 or CoDe with N=9, 8, 7, or 6).  The figure visually demonstrates the impact of reducing the number of drafting steps on image quality while increasing speed and reducing memory usage.  The FID (Fr\u00e9chet Inception Distance) scores for each model are also provided, showing a small increase in FID (a measure of image quality) as the number of drafting steps decreases, and speedup factors are given.", "section": "4. Experimental Results"}]