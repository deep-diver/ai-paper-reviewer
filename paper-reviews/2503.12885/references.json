{"references": [{"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces the T5 text encoder, which the DreamRenderer paper uses to encode text prompts."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper proposes a high-resolution image synthesis method with latent diffusion models, which forms the basis of the DreamRenderer."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture and the attention mechanism, which is the cornerstone of the Joint Attention process in DreamRenderer."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper proposes a method for adding conditional control to text-to-image diffusion models, allowing for depth and canny conditioning, which is a key feature of DreamRenderer."}, {"fullname_first_author": "Yuheng Li", "paper_title": "Gligen: Open-set grounded text-to-image generation", "publication_date": "2023-01-01", "reason": "This paper introduces GLIGEN, a method for open-set grounded text-to-image generation, which DreamRenderer enhances by enabling attribute control."}]}