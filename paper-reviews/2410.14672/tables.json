[{"figure_path": "2410.14672/tables/table_7_0.html", "caption": "Table 1: Uniformity comparison. We compare the generative and discriminative performance of our model against LlamaGen (Sun et al., 2024) and three other settings, varying by tokenizers, training objectives, and modeling types.", "description": "Table 1 compares the generative and discriminative performance of BiGR against LlamaGen and three other models, varying tokenizers, training objectives, and modeling types.", "section": "4.2 UNIFORM PERFORMANCE"}, {"figure_path": "2410.14672/tables/table_7_1.html", "caption": "Table 2: Binary transcoder comparison.", "description": "The table compares the performance of BiGR's binary transcoder using different training objectives and whether or not Bernoulli denoising is used, evaluating both generative and discriminative metrics.", "section": "4.3 MODEL ANALYSIS"}, {"figure_path": "2410.14672/tables/table_7_2.html", "caption": "Table 3: Sampling order comparison. We include the autoregressive variant for reference.", "description": "This table compares the generative and discriminative performance of different sampling methods used in the BiGR model.", "section": "4.3 MODEL ANALYSIS"}, {"figure_path": "2410.14672/tables/table_9_0.html", "caption": "Table 4: Linear-probe evaluation of conditional and unconditional counterparts.", "description": "Table 4 presents the linear-probe top-1 accuracy results on ImageNet-1K for both conditional and unconditional versions of the BiGR model.", "section": "4.3 MODEL ANALYSIS"}, {"figure_path": "2410.14672/tables/table_9_1.html", "caption": "Table 1: Uniformity comparison. We compare the generative and discriminative performance of our model against LlamaGen (Sun et al., 2024) and three other settings, varying by tokenizers, training objectives, and modeling types.", "description": "Table 1 compares the generative and discriminative performance of BiGR against LlamaGen and other models with varying tokenizers, training objectives, and modeling types.", "section": "4.2 UNIFORM PERFORMANCE"}, {"figure_path": "2410.14672/tables/table_14_0.html", "caption": "Table 7: The default configuration settings of three models: BiGR-L, BiGR-XL, BiGR-XXL.", "description": "Table 7 details the default architectural, training, and inference configurations used for three different sizes of the BiGR model: BiGR-L, BiGR-XL, and BiGR-XXL.", "section": "A ADDITIONAL IMPLEMENTATION DETAILS"}, {"figure_path": "2410.14672/tables/table_14_1.html", "caption": "Table 8: Comparison of deterministic and non-deterministic sampling.", "description": "Table 8 compares the generative and discriminative performance of deterministic and non-deterministic sampling methods in BiGR, showing that non-deterministic sampling performs slightly better.", "section": "4.3 MODEL ANALYSIS"}, {"figure_path": "2410.14672/tables/table_15_0.html", "caption": "Table 9: Model comparison of generative performance on ImageNet-1K. Metrics include Frechet inception distance (FID), inception score (IS), precision (Pre.) and recall (Rec.). All models are tested on 256x256 ImageNet-1K benchmark. The suffix \"-re\" denotes the use of rejection sampling.", "description": "Table 9 compares the generative performance of BiGR with other state-of-the-art models on the ImageNet-1K dataset using various metrics such as FID, IS, precision, and recall.", "section": "4.2 UNIFORM PERFORMANCE"}, {"figure_path": "2410.14672/tables/table_16_0.html", "caption": "Table 10: Linear-probe top-1 accuracy on ImageNet-1K. MIM denotes masked image modeling. \u2020: our evaluation results.", "description": "Table 10 compares the linear-probe top-1 accuracy on ImageNet-1K for various models, categorized by their types (Contrastive methods, MIM, Conditional generative methods, and Generative methods), showcasing BiGR's superior performance.", "section": "4.2 UNIFORM PERFORMANCE"}]