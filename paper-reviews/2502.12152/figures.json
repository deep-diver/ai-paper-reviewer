[{"figure_path": "https://arxiv.org/html/2502.12152/x2.png", "caption": "Figure 1: HumanUP provides a simple and general two-stage training method for humanoid getting-up tasks, which can be directly deployed on Unitree G1 humanoid robots\u00a0[70]. Our policies showcase robust and smooth behavior that can get up from diverse lying postures (both supine and prone) on varied terrains such as grass slopes and stone tile.", "description": "This figure showcases the effectiveness of the HumanUP framework.  It demonstrates the ability of a Unitree G1 humanoid robot to recover from various lying positions (both on its back and stomach) on different terrains. HumanUP uses a two-stage training approach, resulting in robust and smooth getting-up motions.  The image displays the robot successfully getting up from different lying positions on diverse surfaces like grass, slopes and tiles.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2502.12152/x3.png", "caption": "Figure 2: HumanUP system overview.\nOur getting-up policy (Section\u00a0III-A) is trained in simulation using two-stage RL training, after which it is directly deployed in the real world.\n(a) Stage I (Section\u00a0III-B1) learns a discovery policy f\ud835\udc53fitalic_f that figures out a getting-up trajectory with minimal deployment constraints.\n(b) Stage II (Section\u00a0III-B2) converts the trajectory discovered by Stage I into a policy \u03c0\ud835\udf0b\\piitalic_\u03c0 that is deployable, robust, and generalizable. This policy \u03c0\ud835\udf0b\\piitalic_\u03c0 is trained by learning to track a slowed down version of the discovered trajectory under strong control regularization on varied terrains and from varied initial poses.\n(c) The two-stage training induces a curriculum (Section\u00a0III-C). Stage I targets motion discovery in easier settings (simpler collision geometry, same starting poses, weak regularization, no variations in terrain), while Stage II solves the task of making the learned motion deployable and generalizable.", "description": "This figure details the HUMANUP system's two-stage reinforcement learning approach for training humanoid robot getting-up policies. Stage I focuses on discovering an effective getting-up trajectory with minimal constraints, while Stage II refines this trajectory to create a deployable, robust, and generalizable policy that handles various terrains and starting poses.  The two-stage process incorporates a curriculum, starting with simpler settings in Stage I (simplified collision model, fixed starting pose, weak regularization) and progressing to more complex scenarios in Stage II (full collision model, varied starting poses, strong regularization). The final policy is then directly deployed on a real-world robot.", "section": "III. HUMANUP: SIM-TO-REAL HUMANOID GETTING UP"}, {"figure_path": "https://arxiv.org/html/2502.12152/x4.png", "caption": "Figure 3: Real-world results. We evaluate HumanUP (ours) in several real-world setups that span diverse surface properties, including both man-made and natural surfaces, and cover a wide range of roughness (rough concrete to slippery snow), bumpiness (flat concrete to tiles), ground compliance (completely firm concrete to being swampy muddy grass), and slope (flat to about 10\u2218superscript1010^{\\circ}10 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPT). We compare HumanUP with G1\u2019s built-in getting-up controller and our HumanUP w/o posture randomization (PR). HumanUP succeeds more consistently (78.3% vs 41.7%) and can solve terrains that the G1\u2019s controller can\u2019t.", "description": "Figure 3 showcases the real-world performance evaluation of the HumanUP getting-up policy.  The experiments were conducted on a Unitree G1 humanoid robot across six diverse terrains: concrete, brick, stone tiles, muddy grass, a grassy slope (approximately 10 degrees), and a snowfield.  These terrains were selected to test the robustness of the policy against variations in surface roughness (smooth to very rough), bumpiness (flat to uneven), ground compliance (firm to soft), and slope. The results compare the success rate of HumanUP with the G1's built-in getting-up controller and a version of HumanUP without posture randomization.  The figure visually demonstrates HumanUP's superior performance, achieving a significantly higher success rate (78.3%) compared to the G1 controller (41.7%) and showcasing its ability to successfully navigate terrains where the G1 controller fails.", "section": "VI. REAL WORLD RESULTS"}, {"figure_path": "https://arxiv.org/html/2502.12152/x5.png", "caption": "Figure 4: Learning curve.\n(a) Termination height of the torso, indicating whether the robot can lift the body.\n(b) Body uprightness, computed as the projected gravity on the z\ud835\udc67zitalic_z-axis, normalized to [0,1]01[0,1][ 0 , 1 ] for better comparison.\nThe overall number of simulation sampling steps is about 5B, normalized to [0,1]01[0,1][ 0 , 1 ].", "description": "Figure 4 presents the learning curves for two key metrics during the training process of the humanoid robot's getting-up policy. The first metric, shown in (a), is the termination height of the robot's torso, which represents how effectively the robot can lift its body during the getting-up motion. The second metric, displayed in (b), is the body uprightness, calculated as the projected gravity on the z-axis. This metric is normalized to a range of 0 to 1 to allow for easier comparison between different simulation runs and stages of training. The x-axis of both plots represents the normalized number of simulation steps, indicating the progress of the training process. The total number of simulation steps used in the training is approximately 5 billion.  These curves illustrate the performance improvement over time and help in evaluating the effectiveness of the two-stage training approach. ", "section": "III. HUMANUP: SIM-TO-REAL HUMANOID GETTING UP"}, {"figure_path": "https://arxiv.org/html/2502.12152/x6.png", "caption": "Figure 5: Getting up comparison with G1 controller.\nG1 controller uses a handcrafted motion trajectory, which can be divided into three phases, while our HumanUP learns a continuous and more efficient whole-body getting-up motion.\nOur HumanUP enables the humanoid to get up within 6 seconds, half of the G1 controller\u2019s 11 seconds of control.\n(a), (b), and (c) record the corresponding mean motor temperature of the upper body, lower body, and waist, respectively. G1\u2019s default controller\u2019s execution causes the arm motors to heat up significantly, whereas our policy makes more use of the leg motors that are larger (higher torque limit of 83N as opposed to 25N for the arm motors) and thus able to take more load.", "description": "This figure compares the getting-up performance of the HumanUP method with that of the G1 controller. The G1 controller uses a pre-designed three-phase motion, while HumanUP learns a continuous, whole-body motion. HumanUP enables the robot to get up in 6 seconds, half the time taken by the G1 controller (11 seconds). The figure also displays the mean motor temperatures for the upper body, lower body, and waist.  The G1 controller leads to excessive heating of the arm motors, while HumanUP utilizes the higher-torque leg motors more effectively, mitigating this issue.", "section": "VI. REAL WORLD RESULTS"}, {"figure_path": "https://arxiv.org/html/2502.12152/x7.png", "caption": "Figure 6: Qualitative examples of failure modes on grass slope and snow field. G1 controller isn\u2019t able to squat on the sloping grass and slips on the slow. HumanUP policy is able to partially get up on both the slope and the snow but falls due to unstable feet placement on the slope and slippage on the snow.", "description": "Figure 6 shows qualitative examples of how the G1 controller and the HumanUP policy fail on challenging terrains like grass slopes and snowy fields. The G1 controller struggles to squat on the slope due to high friction and insufficient torque, ultimately slipping on the snow.  HumanUP, although capable of partially getting up on both surfaces, ultimately fails due to unstable foot placement on the slope and slippage on the snow. This highlights the challenges of robust fall recovery in diverse real-world conditions.", "section": "VII. LIMITATIONS"}]