<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective &#183; HF Daily Paper Reviews by AI"><meta name=description content="Unveiling the surprising potential of noise: transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA)."><meta name=keywords content="Machine Learning,Transfer Learning,üè¢ Beijing Teleinfo Technology Company Ltd.,China Academy of Information and Communications Technology,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective"><meta property="og:description" content="Unveiling the surprising potential of noise: transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA)."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-02-19T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-19T00:00:00+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Transfer Learning"><meta property="article:tag" content="üè¢ Beijing Teleinfo Technology Company Ltd., China Academy of Information and Communications Technology"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/cover.png"><meta name=twitter:title content="Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective"><meta name=twitter:description content="Unveiling the surprising potential of noise: transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA)."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective","headline":"Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective","abstract":"Unveiling the surprising potential of noise: transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA).","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2502.13573\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-02-19T00:00:00\u002b00:00","datePublished":"2025-02-19T00:00:00\u002b00:00","dateModified":"2025-02-19T00:00:00\u002b00:00","keywords":["Machine Learning","Transfer Learning","üè¢ Beijing Teleinfo Technology Company Ltd., China Academy of Information and Communications Technology"],"mainEntityOfPage":"true","wordCount":"6916"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-03-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-20</p></a><a href=/ai-paper-reviewer/2025-03-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-21</p></a><a href=/ai-paper-reviewer/2025-03-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-24</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-20</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-21</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-24</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2502.13573/cover_hu11554087451395793673.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2502.13573/>Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-02-19T00:00:00+00:00>19 February 2025</time><span class="px-2 text-primary-500">&#183;</span><span>6916 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">33 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2502.13573/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2502.13573/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/machine-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Machine Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/transfer-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Transfer Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-beijing-teleinfo-technology-company-ltd.-china-academy-of-information-and-communications-technology/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Beijing Teleinfo Technology Company Ltd., China Academy of Information and Communications Technology</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#shdas-noise-core>SHDA&rsquo;s Noise Core</a></li><li><a href=#ktf-for-shda>KTF for SHDA</a></li><li><a href=#transferability-core>Transferability Core</a></li><li><a href=#domain-alignment>Domain Alignment</a></li><li><a href=#sfda-alternative>SFDA Alternative</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#shdas-noise-core>SHDA&rsquo;s Noise Core</a></li><li><a href=#ktf-for-shda>KTF for SHDA</a></li><li><a href=#transferability-core>Transferability Core</a></li><li><a href=#domain-alignment>Domain Alignment</a></li><li><a href=#sfda-alternative>SFDA Alternative</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2502.13573</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Yuan Yao et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-02-20</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2502.13573 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2502.13573 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2502.13573/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p><strong>Semi-supervised heterogeneous domain adaptation (SHDA)</strong> tackles learning across different data types and distributions, but the nature of knowledge transfer remains unclear. This paper investigates this issue, revealing that characteristics of source data like category and feature information don&rsquo;t greatly affect target domain performance. Surprisingly, <strong>even noise can be useful source!</strong> The study employs two supervised learning methods and seven SHDA techniques on approximately 330 SHDA tasks, challenging traditional assumptions about informative source data. These counter-intuitive findings are very novel.</p><p>The key to unlocking knowledge transfer in SHDA lies in the transferability and discriminability of the source domain itself. To illustrate the discovery, the paper introduces a unified <strong>Knowledge Transfer Framework (KTF)</strong> and designs experiments with various noise domains. The study finds that ensuring these properties in source samples boosts knowledge transfer, regardless of their origin (image, text, noise). Datasets and codes are publicly available, encouraging further research.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-40e877a8a49b6dc656c274de69550f1c></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-40e877a8a49b6dc656c274de69550f1c",{strings:[" Category/feature info of source samples minimally impacts target domain performance in SHDA. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-94161caedebd0ba6945b676d15524b58></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-94161caedebd0ba6945b676d15524b58",{strings:[" Noise from simple distributions can serve as transferable knowledge in SHDA. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-0512b10065c091dd831bb49c45f3cc86></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-0512b10065c091dd831bb49c45f3cc86",{strings:[" Transferability and discriminability in the source domain are critical for knowledge transfer in SHDA. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper offers <strong>a new perspective on SHDA by demonstrating noise as a valuable resource for knowledge transfer.</strong> This finding challenges conventional views and has <strong>potential to inspire novel DA algorithms,</strong> ultimately advancing machine learning research and applications in heterogeneous domains.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x1.png alt></figure></p><blockquote><p>üîº This figure illustrates a common scenario in semi-supervised heterogeneous domain adaptation (SHDA). A textual source domain (e.g., labeled descriptions of animals) and a visual target domain (e.g., images of animals, some labeled, most unlabeled) are shown. The key aspects highlighted are: the difference in data representation between the domains (text vs. images), the semi-supervised nature of the target domain (mostly unlabeled data), and the absence of a direct correspondence between source and target samples (no pairwise links between specific text descriptions and images). The overall question posed is: what type of knowledge successfully transfers from the text to the image domain in this situation?</p><details><summary>read the caption</summary>Figure 1: Example scenario of SHDA with a textual source domain and a visual target domain. Here, all texts are labeled, but most images remain unlabeled, with only a small number having labels. Also, there is no one-to-one relationship between texts and images. We do not know what knowledge is transferred across heterogeneous domains.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S2.T1.24><thead class=ltx_thead><tr class=ltx_tr id=S2.T1.24.25.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S2.T1.24.25.1.1>Notation</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S2.T1.24.25.1.2>Description</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S2.T1.2.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S2.T1.2.2.2><math alttext="\mathcal{X}_{s}" class="ltx_Math" display="inline" id="S2.T1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.m1.1a"><msub id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.1.1.1.m1.1.1.2" xref="S2.T1.1.1.1.m1.1.1.2.cmml">ùí≥</mi><mi id="S2.T1.1.1.1.m1.1.1.3" xref="S2.T1.1.1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><apply id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.1.1.1.m1.1.1.2">ùí≥</ci><ci id="S2.T1.1.1.1.m1.1.1.3.cmml" xref="S2.T1.1.1.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\mathcal{X}_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.m1.1d">caligraphic_X start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="\mathcal{X}_{t}" class="ltx_Math" display="inline" id="S2.T1.2.2.2.m2.1"><semantics id="S2.T1.2.2.2.m2.1a"><msub id="S2.T1.2.2.2.m2.1.1" xref="S2.T1.2.2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.2.2.2.m2.1.1.2" xref="S2.T1.2.2.2.m2.1.1.2.cmml">ùí≥</mi><mi id="S2.T1.2.2.2.m2.1.1.3" xref="S2.T1.2.2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m2.1b"><apply id="S2.T1.2.2.2.m2.1.1.cmml" xref="S2.T1.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.2.2.2.m2.1.1.1.cmml" xref="S2.T1.2.2.2.m2.1.1">subscript</csymbol><ci id="S2.T1.2.2.2.m2.1.1.2.cmml" xref="S2.T1.2.2.2.m2.1.1.2">ùí≥</ci><ci id="S2.T1.2.2.2.m2.1.1.3.cmml" xref="S2.T1.2.2.2.m2.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m2.1c">\mathcal{X}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.m2.1d">caligraphic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left ltx_border_t" id=S2.T1.2.2.3>Source/Target feature space</td></tr><tr class=ltx_tr id=S2.T1.4.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S2.T1.4.4.2><math alttext="\mathcal{D}_{s}" class="ltx_Math" display="inline" id="S2.T1.3.3.1.m1.1"><semantics id="S2.T1.3.3.1.m1.1a"><msub id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.3.3.1.m1.1.1.2" xref="S2.T1.3.3.1.m1.1.1.2.cmml">ùíü</mi><mi id="S2.T1.3.3.1.m1.1.1.3" xref="S2.T1.3.3.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><apply id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.3.3.1.m1.1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1">subscript</csymbol><ci id="S2.T1.3.3.1.m1.1.1.2.cmml" xref="S2.T1.3.3.1.m1.1.1.2">ùíü</ci><ci id="S2.T1.3.3.1.m1.1.1.3.cmml" xref="S2.T1.3.3.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\mathcal{D}_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="\mathcal{D}_{t}" class="ltx_Math" display="inline" id="S2.T1.4.4.2.m2.1"><semantics id="S2.T1.4.4.2.m2.1a"><msub id="S2.T1.4.4.2.m2.1.1" xref="S2.T1.4.4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.4.4.2.m2.1.1.2" xref="S2.T1.4.4.2.m2.1.1.2.cmml">ùíü</mi><mi id="S2.T1.4.4.2.m2.1.1.3" xref="S2.T1.4.4.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m2.1b"><apply id="S2.T1.4.4.2.m2.1.1.cmml" xref="S2.T1.4.4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.4.4.2.m2.1.1.1.cmml" xref="S2.T1.4.4.2.m2.1.1">subscript</csymbol><ci id="S2.T1.4.4.2.m2.1.1.2.cmml" xref="S2.T1.4.4.2.m2.1.1.2">ùíü</ci><ci id="S2.T1.4.4.2.m2.1.1.3.cmml" xref="S2.T1.4.4.2.m2.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m2.1c">\mathcal{D}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.4.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=S2.T1.4.4.3>Source/Target domain</td></tr><tr class=ltx_tr id=S2.T1.6.6><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S2.T1.6.6.2><math alttext="\mathcal{D}_{l}" class="ltx_Math" display="inline" id="S2.T1.5.5.1.m1.1"><semantics id="S2.T1.5.5.1.m1.1a"><msub id="S2.T1.5.5.1.m1.1.1" xref="S2.T1.5.5.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.5.5.1.m1.1.1.2" xref="S2.T1.5.5.1.m1.1.1.2.cmml">ùíü</mi><mi id="S2.T1.5.5.1.m1.1.1.3" xref="S2.T1.5.5.1.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.m1.1b"><apply id="S2.T1.5.5.1.m1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.5.5.1.m1.1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1">subscript</csymbol><ci id="S2.T1.5.5.1.m1.1.1.2.cmml" xref="S2.T1.5.5.1.m1.1.1.2">ùíü</ci><ci id="S2.T1.5.5.1.m1.1.1.3.cmml" xref="S2.T1.5.5.1.m1.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.m1.1c">\mathcal{D}_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.5.5.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="\mathcal{D}_{u}" class="ltx_Math" display="inline" id="S2.T1.6.6.2.m2.1"><semantics id="S2.T1.6.6.2.m2.1a"><msub id="S2.T1.6.6.2.m2.1.1" xref="S2.T1.6.6.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.6.6.2.m2.1.1.2" xref="S2.T1.6.6.2.m2.1.1.2.cmml">ùíü</mi><mi id="S2.T1.6.6.2.m2.1.1.3" xref="S2.T1.6.6.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.2.m2.1b"><apply id="S2.T1.6.6.2.m2.1.1.cmml" xref="S2.T1.6.6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.6.6.2.m2.1.1.1.cmml" xref="S2.T1.6.6.2.m2.1.1">subscript</csymbol><ci id="S2.T1.6.6.2.m2.1.1.2.cmml" xref="S2.T1.6.6.2.m2.1.1.2">ùíü</ci><ci id="S2.T1.6.6.2.m2.1.1.3.cmml" xref="S2.T1.6.6.2.m2.1.1.3">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.2.m2.1c">\mathcal{D}_{u}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.6.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=S2.T1.6.6.3>Labeled/Unlabeled target domain</td></tr><tr class=ltx_tr id=S2.T1.13.13><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S2.T1.9.9.3><math alttext="\mathbf{x}_{i}^{s}" class="ltx_Math" display="inline" id="S2.T1.7.7.1.m1.1"><semantics id="S2.T1.7.7.1.m1.1a"><msubsup id="S2.T1.7.7.1.m1.1.1" xref="S2.T1.7.7.1.m1.1.1.cmml"><mi id="S2.T1.7.7.1.m1.1.1.2.2" xref="S2.T1.7.7.1.m1.1.1.2.2.cmml">ùê±</mi><mi id="S2.T1.7.7.1.m1.1.1.2.3" xref="S2.T1.7.7.1.m1.1.1.2.3.cmml">i</mi><mi id="S2.T1.7.7.1.m1.1.1.3" xref="S2.T1.7.7.1.m1.1.1.3.cmml">s</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.1.m1.1b"><apply id="S2.T1.7.7.1.m1.1.1.cmml" xref="S2.T1.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.7.7.1.m1.1.1.1.cmml" xref="S2.T1.7.7.1.m1.1.1">superscript</csymbol><apply id="S2.T1.7.7.1.m1.1.1.2.cmml" xref="S2.T1.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.7.7.1.m1.1.1.2.1.cmml" xref="S2.T1.7.7.1.m1.1.1">subscript</csymbol><ci id="S2.T1.7.7.1.m1.1.1.2.2.cmml" xref="S2.T1.7.7.1.m1.1.1.2.2">ùê±</ci><ci id="S2.T1.7.7.1.m1.1.1.2.3.cmml" xref="S2.T1.7.7.1.m1.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.7.7.1.m1.1.1.3.cmml" xref="S2.T1.7.7.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.1.m1.1c">\mathbf{x}_{i}^{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.7.7.1.m1.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT</annotation></semantics></math> / <math alttext="\mathbf{x}_{i}^{l}" class="ltx_Math" display="inline" id="S2.T1.8.8.2.m2.1"><semantics id="S2.T1.8.8.2.m2.1a"><msubsup id="S2.T1.8.8.2.m2.1.1" xref="S2.T1.8.8.2.m2.1.1.cmml"><mi id="S2.T1.8.8.2.m2.1.1.2.2" xref="S2.T1.8.8.2.m2.1.1.2.2.cmml">ùê±</mi><mi id="S2.T1.8.8.2.m2.1.1.2.3" xref="S2.T1.8.8.2.m2.1.1.2.3.cmml">i</mi><mi id="S2.T1.8.8.2.m2.1.1.3" xref="S2.T1.8.8.2.m2.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.2.m2.1b"><apply id="S2.T1.8.8.2.m2.1.1.cmml" xref="S2.T1.8.8.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.8.8.2.m2.1.1.1.cmml" xref="S2.T1.8.8.2.m2.1.1">superscript</csymbol><apply id="S2.T1.8.8.2.m2.1.1.2.cmml" xref="S2.T1.8.8.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.8.8.2.m2.1.1.2.1.cmml" xref="S2.T1.8.8.2.m2.1.1">subscript</csymbol><ci id="S2.T1.8.8.2.m2.1.1.2.2.cmml" xref="S2.T1.8.8.2.m2.1.1.2.2">ùê±</ci><ci id="S2.T1.8.8.2.m2.1.1.2.3.cmml" xref="S2.T1.8.8.2.m2.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.8.8.2.m2.1.1.3.cmml" xref="S2.T1.8.8.2.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.2.m2.1c">\mathbf{x}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.8.8.2.m2.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> /<math alttext="\mathbf{x}_{i}^{u}" class="ltx_Math" display="inline" id="S2.T1.9.9.3.m3.1"><semantics id="S2.T1.9.9.3.m3.1a"><msubsup id="S2.T1.9.9.3.m3.1.1" xref="S2.T1.9.9.3.m3.1.1.cmml"><mi id="S2.T1.9.9.3.m3.1.1.2.2" xref="S2.T1.9.9.3.m3.1.1.2.2.cmml">ùê±</mi><mi id="S2.T1.9.9.3.m3.1.1.2.3" xref="S2.T1.9.9.3.m3.1.1.2.3.cmml">i</mi><mi id="S2.T1.9.9.3.m3.1.1.3" xref="S2.T1.9.9.3.m3.1.1.3.cmml">u</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.3.m3.1b"><apply id="S2.T1.9.9.3.m3.1.1.cmml" xref="S2.T1.9.9.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.9.9.3.m3.1.1.1.cmml" xref="S2.T1.9.9.3.m3.1.1">superscript</csymbol><apply id="S2.T1.9.9.3.m3.1.1.2.cmml" xref="S2.T1.9.9.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.9.9.3.m3.1.1.2.1.cmml" xref="S2.T1.9.9.3.m3.1.1">subscript</csymbol><ci id="S2.T1.9.9.3.m3.1.1.2.2.cmml" xref="S2.T1.9.9.3.m3.1.1.2.2">ùê±</ci><ci id="S2.T1.9.9.3.m3.1.1.2.3.cmml" xref="S2.T1.9.9.3.m3.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.9.9.3.m3.1.1.3.cmml" xref="S2.T1.9.9.3.m3.1.1.3">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.3.m3.1c">\mathbf{x}_{i}^{u}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.9.9.3.m3.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=S2.T1.13.13.7>the <math alttext="i" class="ltx_Math" display="inline" id="S2.T1.10.10.4.m1.1"><semantics id="S2.T1.10.10.4.m1.1a"><mi id="S2.T1.10.10.4.m1.1.1" xref="S2.T1.10.10.4.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.4.m1.1b"><ci id="S2.T1.10.10.4.m1.1.1.cmml" xref="S2.T1.10.10.4.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.4.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.T1.10.10.4.m1.1d">italic_i</annotation></semantics></math>-th sample in <math alttext="\mathcal{D}_{s}" class="ltx_Math" display="inline" id="S2.T1.11.11.5.m2.1"><semantics id="S2.T1.11.11.5.m2.1a"><msub id="S2.T1.11.11.5.m2.1.1" xref="S2.T1.11.11.5.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.11.11.5.m2.1.1.2" xref="S2.T1.11.11.5.m2.1.1.2.cmml">ùíü</mi><mi id="S2.T1.11.11.5.m2.1.1.3" xref="S2.T1.11.11.5.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.5.m2.1b"><apply id="S2.T1.11.11.5.m2.1.1.cmml" xref="S2.T1.11.11.5.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.11.11.5.m2.1.1.1.cmml" xref="S2.T1.11.11.5.m2.1.1">subscript</csymbol><ci id="S2.T1.11.11.5.m2.1.1.2.cmml" xref="S2.T1.11.11.5.m2.1.1.2">ùíü</ci><ci id="S2.T1.11.11.5.m2.1.1.3.cmml" xref="S2.T1.11.11.5.m2.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.5.m2.1c">\mathcal{D}_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.11.11.5.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> / <math alttext="\mathcal{D}_{l}" class="ltx_Math" display="inline" id="S2.T1.12.12.6.m3.1"><semantics id="S2.T1.12.12.6.m3.1a"><msub id="S2.T1.12.12.6.m3.1.1" xref="S2.T1.12.12.6.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.12.12.6.m3.1.1.2" xref="S2.T1.12.12.6.m3.1.1.2.cmml">ùíü</mi><mi id="S2.T1.12.12.6.m3.1.1.3" xref="S2.T1.12.12.6.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.6.m3.1b"><apply id="S2.T1.12.12.6.m3.1.1.cmml" xref="S2.T1.12.12.6.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.12.12.6.m3.1.1.1.cmml" xref="S2.T1.12.12.6.m3.1.1">subscript</csymbol><ci id="S2.T1.12.12.6.m3.1.1.2.cmml" xref="S2.T1.12.12.6.m3.1.1.2">ùíü</ci><ci id="S2.T1.12.12.6.m3.1.1.3.cmml" xref="S2.T1.12.12.6.m3.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.6.m3.1c">\mathcal{D}_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.12.12.6.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="\mathcal{D}_{u}" class="ltx_Math" display="inline" id="S2.T1.13.13.7.m4.1"><semantics id="S2.T1.13.13.7.m4.1a"><msub id="S2.T1.13.13.7.m4.1.1" xref="S2.T1.13.13.7.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.13.13.7.m4.1.1.2" xref="S2.T1.13.13.7.m4.1.1.2.cmml">ùíü</mi><mi id="S2.T1.13.13.7.m4.1.1.3" xref="S2.T1.13.13.7.m4.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.7.m4.1b"><apply id="S2.T1.13.13.7.m4.1.1.cmml" xref="S2.T1.13.13.7.m4.1.1"><csymbol cd="ambiguous" id="S2.T1.13.13.7.m4.1.1.1.cmml" xref="S2.T1.13.13.7.m4.1.1">subscript</csymbol><ci id="S2.T1.13.13.7.m4.1.1.2.cmml" xref="S2.T1.13.13.7.m4.1.1.2">ùíü</ci><ci id="S2.T1.13.13.7.m4.1.1.3.cmml" xref="S2.T1.13.13.7.m4.1.1.3">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.7.m4.1c">\mathcal{D}_{u}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.13.13.7.m4.1d">caligraphic_D start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=S2.T1.17.17><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S2.T1.15.15.2><math alttext="\mathbf{y}_{i}^{s}" class="ltx_Math" display="inline" id="S2.T1.14.14.1.m1.1"><semantics id="S2.T1.14.14.1.m1.1a"><msubsup id="S2.T1.14.14.1.m1.1.1" xref="S2.T1.14.14.1.m1.1.1.cmml"><mi id="S2.T1.14.14.1.m1.1.1.2.2" xref="S2.T1.14.14.1.m1.1.1.2.2.cmml">ùê≤</mi><mi id="S2.T1.14.14.1.m1.1.1.2.3" xref="S2.T1.14.14.1.m1.1.1.2.3.cmml">i</mi><mi id="S2.T1.14.14.1.m1.1.1.3" xref="S2.T1.14.14.1.m1.1.1.3.cmml">s</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.1.m1.1b"><apply id="S2.T1.14.14.1.m1.1.1.cmml" xref="S2.T1.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.14.14.1.m1.1.1.1.cmml" xref="S2.T1.14.14.1.m1.1.1">superscript</csymbol><apply id="S2.T1.14.14.1.m1.1.1.2.cmml" xref="S2.T1.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.14.14.1.m1.1.1.2.1.cmml" xref="S2.T1.14.14.1.m1.1.1">subscript</csymbol><ci id="S2.T1.14.14.1.m1.1.1.2.2.cmml" xref="S2.T1.14.14.1.m1.1.1.2.2">ùê≤</ci><ci id="S2.T1.14.14.1.m1.1.1.2.3.cmml" xref="S2.T1.14.14.1.m1.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.14.14.1.m1.1.1.3.cmml" xref="S2.T1.14.14.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.1.m1.1c">\mathbf{y}_{i}^{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.14.14.1.m1.1d">bold_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT</annotation></semantics></math> /<math alttext="\mathbf{y}_{i}^{l}" class="ltx_Math" display="inline" id="S2.T1.15.15.2.m2.1"><semantics id="S2.T1.15.15.2.m2.1a"><msubsup id="S2.T1.15.15.2.m2.1.1" xref="S2.T1.15.15.2.m2.1.1.cmml"><mi id="S2.T1.15.15.2.m2.1.1.2.2" xref="S2.T1.15.15.2.m2.1.1.2.2.cmml">ùê≤</mi><mi id="S2.T1.15.15.2.m2.1.1.2.3" xref="S2.T1.15.15.2.m2.1.1.2.3.cmml">i</mi><mi id="S2.T1.15.15.2.m2.1.1.3" xref="S2.T1.15.15.2.m2.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.2.m2.1b"><apply id="S2.T1.15.15.2.m2.1.1.cmml" xref="S2.T1.15.15.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.15.15.2.m2.1.1.1.cmml" xref="S2.T1.15.15.2.m2.1.1">superscript</csymbol><apply id="S2.T1.15.15.2.m2.1.1.2.cmml" xref="S2.T1.15.15.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.15.15.2.m2.1.1.2.1.cmml" xref="S2.T1.15.15.2.m2.1.1">subscript</csymbol><ci id="S2.T1.15.15.2.m2.1.1.2.2.cmml" xref="S2.T1.15.15.2.m2.1.1.2.2">ùê≤</ci><ci id="S2.T1.15.15.2.m2.1.1.2.3.cmml" xref="S2.T1.15.15.2.m2.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.15.15.2.m2.1.1.3.cmml" xref="S2.T1.15.15.2.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.2.m2.1c">\mathbf{y}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.15.15.2.m2.1d">bold_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=S2.T1.17.17.4>One-hot label of <math alttext="\mathbf{x}_{i}^{s}" class="ltx_Math" display="inline" id="S2.T1.16.16.3.m1.1"><semantics id="S2.T1.16.16.3.m1.1a"><msubsup id="S2.T1.16.16.3.m1.1.1" xref="S2.T1.16.16.3.m1.1.1.cmml"><mi id="S2.T1.16.16.3.m1.1.1.2.2" xref="S2.T1.16.16.3.m1.1.1.2.2.cmml">ùê±</mi><mi id="S2.T1.16.16.3.m1.1.1.2.3" xref="S2.T1.16.16.3.m1.1.1.2.3.cmml">i</mi><mi id="S2.T1.16.16.3.m1.1.1.3" xref="S2.T1.16.16.3.m1.1.1.3.cmml">s</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.3.m1.1b"><apply id="S2.T1.16.16.3.m1.1.1.cmml" xref="S2.T1.16.16.3.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.16.16.3.m1.1.1.1.cmml" xref="S2.T1.16.16.3.m1.1.1">superscript</csymbol><apply id="S2.T1.16.16.3.m1.1.1.2.cmml" xref="S2.T1.16.16.3.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.16.16.3.m1.1.1.2.1.cmml" xref="S2.T1.16.16.3.m1.1.1">subscript</csymbol><ci id="S2.T1.16.16.3.m1.1.1.2.2.cmml" xref="S2.T1.16.16.3.m1.1.1.2.2">ùê±</ci><ci id="S2.T1.16.16.3.m1.1.1.2.3.cmml" xref="S2.T1.16.16.3.m1.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.16.16.3.m1.1.1.3.cmml" xref="S2.T1.16.16.3.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.3.m1.1c">\mathbf{x}_{i}^{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.16.16.3.m1.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT</annotation></semantics></math> /<math alttext="\mathbf{x}_{i}^{l}" class="ltx_Math" display="inline" id="S2.T1.17.17.4.m2.1"><semantics id="S2.T1.17.17.4.m2.1a"><msubsup id="S2.T1.17.17.4.m2.1.1" xref="S2.T1.17.17.4.m2.1.1.cmml"><mi id="S2.T1.17.17.4.m2.1.1.2.2" xref="S2.T1.17.17.4.m2.1.1.2.2.cmml">ùê±</mi><mi id="S2.T1.17.17.4.m2.1.1.2.3" xref="S2.T1.17.17.4.m2.1.1.2.3.cmml">i</mi><mi id="S2.T1.17.17.4.m2.1.1.3" xref="S2.T1.17.17.4.m2.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.4.m2.1b"><apply id="S2.T1.17.17.4.m2.1.1.cmml" xref="S2.T1.17.17.4.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.17.17.4.m2.1.1.1.cmml" xref="S2.T1.17.17.4.m2.1.1">superscript</csymbol><apply id="S2.T1.17.17.4.m2.1.1.2.cmml" xref="S2.T1.17.17.4.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.17.17.4.m2.1.1.2.1.cmml" xref="S2.T1.17.17.4.m2.1.1">subscript</csymbol><ci id="S2.T1.17.17.4.m2.1.1.2.2.cmml" xref="S2.T1.17.17.4.m2.1.1.2.2">ùê±</ci><ci id="S2.T1.17.17.4.m2.1.1.2.3.cmml" xref="S2.T1.17.17.4.m2.1.1.2.3">ùëñ</ci></apply><ci id="S2.T1.17.17.4.m2.1.1.3.cmml" xref="S2.T1.17.17.4.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.4.m2.1c">\mathbf{x}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.17.17.4.m2.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=S2.T1.23.23><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S2.T1.20.20.3><math alttext="n_{s}" class="ltx_Math" display="inline" id="S2.T1.18.18.1.m1.1"><semantics id="S2.T1.18.18.1.m1.1a"><msub id="S2.T1.18.18.1.m1.1.1" xref="S2.T1.18.18.1.m1.1.1.cmml"><mi id="S2.T1.18.18.1.m1.1.1.2" xref="S2.T1.18.18.1.m1.1.1.2.cmml">n</mi><mi id="S2.T1.18.18.1.m1.1.1.3" xref="S2.T1.18.18.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.18.18.1.m1.1b"><apply id="S2.T1.18.18.1.m1.1.1.cmml" xref="S2.T1.18.18.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.18.18.1.m1.1.1.1.cmml" xref="S2.T1.18.18.1.m1.1.1">subscript</csymbol><ci id="S2.T1.18.18.1.m1.1.1.2.cmml" xref="S2.T1.18.18.1.m1.1.1.2">ùëõ</ci><ci id="S2.T1.18.18.1.m1.1.1.3.cmml" xref="S2.T1.18.18.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.18.1.m1.1c">n_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.18.18.1.m1.1d">italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> / <math alttext="n_{l}" class="ltx_Math" display="inline" id="S2.T1.19.19.2.m2.1"><semantics id="S2.T1.19.19.2.m2.1a"><msub id="S2.T1.19.19.2.m2.1.1" xref="S2.T1.19.19.2.m2.1.1.cmml"><mi id="S2.T1.19.19.2.m2.1.1.2" xref="S2.T1.19.19.2.m2.1.1.2.cmml">n</mi><mi id="S2.T1.19.19.2.m2.1.1.3" xref="S2.T1.19.19.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.19.19.2.m2.1b"><apply id="S2.T1.19.19.2.m2.1.1.cmml" xref="S2.T1.19.19.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.19.19.2.m2.1.1.1.cmml" xref="S2.T1.19.19.2.m2.1.1">subscript</csymbol><ci id="S2.T1.19.19.2.m2.1.1.2.cmml" xref="S2.T1.19.19.2.m2.1.1.2">ùëõ</ci><ci id="S2.T1.19.19.2.m2.1.1.3.cmml" xref="S2.T1.19.19.2.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.19.19.2.m2.1c">n_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.19.19.2.m2.1d">italic_n start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="n_{u}" class="ltx_Math" display="inline" id="S2.T1.20.20.3.m3.1"><semantics id="S2.T1.20.20.3.m3.1a"><msub id="S2.T1.20.20.3.m3.1.1" xref="S2.T1.20.20.3.m3.1.1.cmml"><mi id="S2.T1.20.20.3.m3.1.1.2" xref="S2.T1.20.20.3.m3.1.1.2.cmml">n</mi><mi id="S2.T1.20.20.3.m3.1.1.3" xref="S2.T1.20.20.3.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.20.20.3.m3.1b"><apply id="S2.T1.20.20.3.m3.1.1.cmml" xref="S2.T1.20.20.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.20.20.3.m3.1.1.1.cmml" xref="S2.T1.20.20.3.m3.1.1">subscript</csymbol><ci id="S2.T1.20.20.3.m3.1.1.2.cmml" xref="S2.T1.20.20.3.m3.1.1.2">ùëõ</ci><ci id="S2.T1.20.20.3.m3.1.1.3.cmml" xref="S2.T1.20.20.3.m3.1.1.3">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.20.20.3.m3.1c">n_{u}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.20.20.3.m3.1d">italic_n start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></th><td class="ltx_td ltx_align_left" id=S2.T1.23.23.6>Number of samples in <math alttext="\mathcal{D}_{s}" class="ltx_Math" display="inline" id="S2.T1.21.21.4.m1.1"><semantics id="S2.T1.21.21.4.m1.1a"><msub id="S2.T1.21.21.4.m1.1.1" xref="S2.T1.21.21.4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.21.21.4.m1.1.1.2" xref="S2.T1.21.21.4.m1.1.1.2.cmml">ùíü</mi><mi id="S2.T1.21.21.4.m1.1.1.3" xref="S2.T1.21.21.4.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.21.21.4.m1.1b"><apply id="S2.T1.21.21.4.m1.1.1.cmml" xref="S2.T1.21.21.4.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.21.21.4.m1.1.1.1.cmml" xref="S2.T1.21.21.4.m1.1.1">subscript</csymbol><ci id="S2.T1.21.21.4.m1.1.1.2.cmml" xref="S2.T1.21.21.4.m1.1.1.2">ùíü</ci><ci id="S2.T1.21.21.4.m1.1.1.3.cmml" xref="S2.T1.21.21.4.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.21.21.4.m1.1c">\mathcal{D}_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.21.21.4.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> / <math alttext="\mathcal{D}_{l}" class="ltx_Math" display="inline" id="S2.T1.22.22.5.m2.1"><semantics id="S2.T1.22.22.5.m2.1a"><msub id="S2.T1.22.22.5.m2.1.1" xref="S2.T1.22.22.5.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.22.22.5.m2.1.1.2" xref="S2.T1.22.22.5.m2.1.1.2.cmml">ùíü</mi><mi id="S2.T1.22.22.5.m2.1.1.3" xref="S2.T1.22.22.5.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.22.22.5.m2.1b"><apply id="S2.T1.22.22.5.m2.1.1.cmml" xref="S2.T1.22.22.5.m2.1.1"><csymbol cd="ambiguous" id="S2.T1.22.22.5.m2.1.1.1.cmml" xref="S2.T1.22.22.5.m2.1.1">subscript</csymbol><ci id="S2.T1.22.22.5.m2.1.1.2.cmml" xref="S2.T1.22.22.5.m2.1.1.2">ùíü</ci><ci id="S2.T1.22.22.5.m2.1.1.3.cmml" xref="S2.T1.22.22.5.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.22.22.5.m2.1c">\mathcal{D}_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.22.22.5.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> /<math alttext="\mathcal{D}_{u}" class="ltx_Math" display="inline" id="S2.T1.23.23.6.m3.1"><semantics id="S2.T1.23.23.6.m3.1a"><msub id="S2.T1.23.23.6.m3.1.1" xref="S2.T1.23.23.6.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.T1.23.23.6.m3.1.1.2" xref="S2.T1.23.23.6.m3.1.1.2.cmml">ùíü</mi><mi id="S2.T1.23.23.6.m3.1.1.3" xref="S2.T1.23.23.6.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.23.23.6.m3.1b"><apply id="S2.T1.23.23.6.m3.1.1.cmml" xref="S2.T1.23.23.6.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.23.23.6.m3.1.1.1.cmml" xref="S2.T1.23.23.6.m3.1.1">subscript</csymbol><ci id="S2.T1.23.23.6.m3.1.1.2.cmml" xref="S2.T1.23.23.6.m3.1.1.2">ùíü</ci><ci id="S2.T1.23.23.6.m3.1.1.3.cmml" xref="S2.T1.23.23.6.m3.1.1.3">ùë¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.23.23.6.m3.1c">\mathcal{D}_{u}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.23.23.6.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td></tr><tr class=ltx_tr id=S2.T1.24.24><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S2.T1.24.24.1><math alttext="C" class="ltx_Math" display="inline" id="S2.T1.24.24.1.m1.1"><semantics id="S2.T1.24.24.1.m1.1a"><mi id="S2.T1.24.24.1.m1.1.1" xref="S2.T1.24.24.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.T1.24.24.1.m1.1b"><ci id="S2.T1.24.24.1.m1.1.1.cmml" xref="S2.T1.24.24.1.m1.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.24.24.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.T1.24.24.1.m1.1d">italic_C</annotation></semantics></math></th><td class="ltx_td ltx_align_left ltx_border_bb" id=S2.T1.24.24.2>Number of categories</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the notations used throughout the paper. It defines the symbols for key concepts such as source and target domains, labeled and unlabeled data, feature spaces, and the number of samples and categories.</p><details><summary>read the caption</summary>TABLE I: Notations.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">SHDA&rsquo;s Noise Core<div id=shdas-noise-core class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#shdas-noise-core aria-label=Anchor>#</a></span></h4><p>The core idea revolves around <strong>transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA)</strong>, questioning traditional reliance on source data&rsquo;s semantic relevance. Instead, <strong>noise, surprisingly, can be a potent source of transferable knowledge</strong>. The emphasis shifts to the <strong>transferability and discriminability of the noise domain itself</strong>. The research highlights the importance of properties within the noise, rather than its origin, redefining knowledge transfer in SHDA. The study challenges existing assumptions and opens new avenues for leveraging noise in domain adaptation.</p><h4 class="relative group">KTF for SHDA<div id=ktf-for-shda class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ktf-for-shda aria-label=Anchor>#</a></span></h4><p>The Knowledge Transfer Framework (<strong>KTF</strong>) for Semi-supervised Heterogeneous Domain Adaptation (<strong>SHDA</strong>) seems like a crucial component for understanding knowledge transfer. The framework likely aims to create a unified space for source and target domains, enabling a <strong>more direct</strong> analysis of transferable knowledge within source noise. By constructing a common subspace and generating source noise directly, the authors eliminate the need for learning a source feature projector, <strong>simplifying analysis</strong> and focusing on the essence of transferable knowledge. KTF incorporates factors like the <strong>empirical risk</strong> of labeled target samples (<strong>discriminability</strong>), the <strong>empirical risk of source noise</strong> (<strong>discriminability</strong>), and the <strong>distributional divergence</strong> between domains (<strong>transferability</strong>). The formulation of KTF&rsquo;s objective function, likely a minimization problem balancing these factors, would be essential for guiding the transfer process. This unified approach allows systematic manipulation and study of noise characteristics and their influence on target domain performance. The use of a softmax classifier, cross-entropy loss, and soft maximum mean discrepancy (<strong>MMD</strong>) indicates a standard yet effective approach to knowledge transfer in KTF.</p><h4 class="relative group">Transferability Core<div id=transferability-core class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#transferability-core aria-label=Anchor>#</a></span></h4><p>The paper empirically investigates transferable knowledge in semi-supervised heterogeneous domain adaptation (SHDA). A key finding is that <strong>noise from simple distributions can transfer knowledge</strong>, challenging the reliance on vanilla source samples. The category and feature information of source samples are surprisingly less influential. A unified Knowledge Transfer Framework (KTF) is introduced, revealing that <strong>transferable knowledge stems from the source domain&rsquo;s transferability and discriminability.</strong> Regardless of the data origin (image, text, noise), ensuring these properties in source samples boosts SHDA effectiveness. The research highlights noise as a valuable resource and <strong>emphasizes the importance of transferability and discriminability</strong> rather than specific source data characteristics. It offers a new perspective on domain adaptation, applicable in scenarios with limited access to source data.</p><h4 class="relative group">Domain Alignment<div id=domain-alignment class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#domain-alignment aria-label=Anchor>#</a></span></h4><p><strong>Domain alignment</strong> is a crucial aspect of domain adaptation, particularly in heterogeneous scenarios where feature spaces differ. Effective alignment seeks to bridge the gap between source and target data distributions, enabling knowledge transfer. Approaches often involve learning feature transformations or projecting data into a shared subspace, thereby minimizing distributional divergence. <strong>Marginal and conditional distribution alignment</strong> are key strategies. Additionally, methods focusing on aligning category-level representations or utilizing pseudo-labels for unlabeled target data have shown promise. Addressing the challenge of <strong>negative transfer</strong> and ensuring discriminability within the aligned space remain important research directions to enhance the robustness and effectiveness of domain alignment techniques.</p><h4 class="relative group">SFDA Alternative<div id=sfda-alternative class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sfda-alternative aria-label=Anchor>#</a></span></h4><p>The &ldquo;SFDA Alternative&rdquo; presents a compelling approach by <strong>sampling noise from random distributions</strong> as source samples, bypassing the need for real-world data. This is advantageous in scenarios where data is restricted due to privacy, confidentiality, or copyright. <strong>Domain adaptation</strong> is done in a semi-supervised manner after <strong>noise is sampled</strong> for source training. The focus on simple distribution of noise <strong>eliminates the need of carefully curate</strong> source data and <strong>maintains privacy</strong>. Furthermore, it removes the need to identify the perfect domain and train on that domain for transfer learning. Finally, it <strong>reduces dependency on publicly available samples</strong>.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x2.png alt></figure></p><blockquote><p>üîº Figure 2 presents a comparative analysis of various domain adaptation methods&rsquo; performance on the NUS-WIDE+ImageNet-8 dataset. Two scenarios are compared: a standard semi-supervised heterogeneous domain adaptation (SHDA) task (&lsquo;Text ‚Üí Image&rsquo;), and a novel task (&lsquo;Noise ‚Üí Image&rsquo;) where synthetic noise replaces the actual source data. The figure showcases the performance of two supervised learning methods (SVMt, NNt) and seven SHDA methods (SHFA, CDLS, DDACL, TNT, STN, SSAN, JMEA). The results surprisingly show comparable performance between the standard SHDA task and the noise-based task, suggesting that noise itself may contain transferable knowledge in the context of SHDA.</p><details><summary>read the caption</summary>Figure 2: Experimental results on the NUS-WIDE+ImageNet-8 dataset [31, 32], which demonstrates that noise may contain transferable knowledge. Here, Text ‚Üí‚Üí\rightarrow‚Üí Image is a vanilla SHDA task, whilst Noise ‚Üí‚Üí\rightarrow‚Üí Image is a specialized SHDA task with pure noise as the source sample. In addition, SVMt and NNt are two supervised learning methods, whereas SHFA, CDLS, DDACL, TNT, STN, SSAN, and JMEA are seven SHDA methods.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x3.png alt></figure></p><blockquote><p>üîº The figure illustrates the typical pipeline of semi-supervised heterogeneous domain adaptation (SHDA) methods. It shows how SHDA approaches use both classification adaptation (adjusting the classifier to handle the differences between domains) and distribution alignment (making the distributions of source and target data more similar) to learn feature projectors (functions that transform data from each domain into a common space) and a shared classifier. The key point is that the feature projectors are specific to each domain (source and target), reflecting the differences in their data representations. This process allows the algorithm to effectively learn from labeled source data and a mix of labeled and unlabeled target data, even though the data across domains is not directly comparable.</p><details><summary>read the caption</summary>Figure 3: In general, the SHDA pipeline integrates the classification adaptation and distribution alignment mechanisms to jointly learn the source and target feature projectors, along with the classifier, from scratch in a semi-supervised manner. Notably, the feature projectors are unique to each domain.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x4.png alt></figure></p><blockquote><p>üîº This figure illustrates a scenario in semi-supervised heterogeneous domain adaptation (SHDA). It shows how the order of category indices can differ between the source and target domains, even though the categories themselves are the same. The source domain has labeled samples, while the target domain has both labeled and unlabeled samples. This setup is used to investigate how the ordering of categories affects the performance of SHDA methods.</p><details><summary>read the caption</summary>Figure 4: An illustration of the category-permutated SHDA task, where source and target samples have identical categories but with different orders of category indices.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x5.png alt></figure></p><blockquote><p>üîº This figure shows how the order of categories affects the performance of semi-supervised heterogeneous domain adaptation (SHDA) tasks. Across three datasets (Office+Caltech-10, Multilingual Reuters Collection, and NUS-WIDE+ImageNet-8), the order of category indices for target samples remains consistent, while the order of categories in the source samples is systematically permuted. Each permutation represents a separate SHDA task. The original, unpermuted order (Order 1) represents a standard SHDA task; all other permutations represent variations where the source category order is shuffled. This experimental design allows researchers to isolate and analyze the impact of the source data&rsquo;s category order on SHDA performance.</p><details><summary>read the caption</summary>Figure 5: The orders of category indices for source and target samples on all datasets. Here, we preserve the order of category indices for target samples while exclusively modifying that of source samples. Consequently, the task is considered as a vanilla SHDA task only when the category indices of both source and target samples are aligned in order 1.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x6.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy results for different methods on a semi-supervised heterogeneous domain adaptation task. The task involves transferring knowledge from the Amazon (A) domain with 800-dimensional SURF features to the Caltech-256 (C) domain with 4096-dimensional DeCAF6 features. The x-axis represents different orders of category indices for the source domain samples, demonstrating the impact of varying category information on the adaptation performance. The y-axis represents the classification accuracy. Different colored lines represent various SHDA methods, and the impact of the different methods can be compared against two supervised methods (SVM and NN). The results are compared across different orderings of categories to show that the category ordering does not greatly influence results.</p><details><summary>read the caption</summary>(a) A (S800subscriptùëÜ800S_{800}italic_S start_POSTSUBSCRIPT 800 end_POSTSUBSCRIPT) ‚Üí‚Üí\rightarrow‚ÜíC (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x7.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy results for a semi-supervised heterogeneous domain adaptation (SHDA) task. Specifically, it illustrates the performance of various SHDA methods when adapting from a source domain with SURF features (S800) in the Caltech-256 dataset (C) to a target domain with DeCAF features (D4096) in the Webcam dataset (W). The x-axis represents different permutations of category indices in the source domain, while the y-axis shows the classification accuracy. The purpose is to investigate the impact of category information ordering in the source data on the effectiveness of SHDA.</p><details><summary>read the caption</summary>(b) C (S800subscriptùëÜ800S_{800}italic_S start_POSTSUBSCRIPT 800 end_POSTSUBSCRIPT) ‚Üí‚Üí\rightarrow‚Üí W (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x8.png alt></figure></p><blockquote><p>üîº This figure shows the results of a semi-supervised heterogeneous domain adaptation (SHDA) experiment. Specifically, it visualizes the classification accuracy across different orderings of category indices in the source domain samples. The experiment uses a Webcam (W) domain with SURF features (S800) as the source domain and a DSLR (D) domain with DeCAF features (D4096) as the target domain. The x-axis represents the different orderings, and the y-axis represents the classification accuracy. This helps to understand the impact of category information order in source data on the SHDA performance. Different SHDA algorithms are likely compared in the figure, although the algorithms are not explicitly mentioned in the given caption.</p><details><summary>read the caption</summary>(c) W (S800subscriptùëÜ800S_{800}italic_S start_POSTSUBSCRIPT 800 end_POSTSUBSCRIPT) ‚Üí‚Üí\rightarrow‚ÜíD (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x9.png alt></figure></p><blockquote><p>üîº This figure shows the experimental results on the NUS-WIDE+ImageNet-8 dataset. It compares the performance of various semi-supervised heterogeneous domain adaptation (SHDA) methods and two supervised learning methods (SVMt and NNt) on a text-to-image domain adaptation task. The results show that using pure noise as source samples does not significantly impair the performance compared to using actual text data as the source.</p><details><summary>read the caption</summary>(d) Text‚Üí‚Üí\rightarrow‚ÜíImage</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x10.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy for different methods across various orders of category indices in a semi-supervised heterogeneous domain adaptation (SHDA) task. The specific task shown is the transfer from English (E) to Spanish (S) domains, where English is the source domain and Spanish is the target domain. The x-axis represents the order of category indices for source samples, and the y-axis represents the classification accuracy. Different colored lines represent different SHDA methods used in the study.</p><details><summary>read the caption</summary>(e) E‚Üí‚Üí\rightarrow‚ÜíS</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x11.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy for different orders of category indices in source samples for a semi-supervised heterogeneous domain adaptation task. The task involves adapting from the French (F) language domain to the Spanish (S) language domain. The x-axis represents different permutations of category indices (order 1 is the original order), and the y-axis shows the classification accuracy. Multiple lines represent different domain adaptation methods.</p><details><summary>read the caption</summary>(f) F‚Üí‚Üí\rightarrow‚ÜíS</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x12.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy results for various domain adaptation methods on a semi-supervised heterogeneous domain adaptation (SHDA) task. The specific task depicted is transferring knowledge from the German (G) language domain to the Spanish (S) language domain. The x-axis represents different permutations of the category indices in the source domain (German), while the y-axis shows the classification accuracy. Each line represents a different domain adaptation method, illustrating their performance under various category index orderings. The purpose is to analyze how the category information in the source domain impacts the accuracy of the model.</p><details><summary>read the caption</summary>(g) G‚Üí‚Üí\rightarrow‚ÜíS</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x13.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy for different methods across various orders of category indices for source samples in a semi-supervised heterogeneous domain adaptation (SHDA) task where Italian (I) is the source domain and Spanish (S) is the target domain. The experiment permutes the order of categories in the source domain while keeping the target domain&rsquo;s category order constant to analyze how category order impacts performance. The goal is to understand the impact of category information from the source domain on the target domain in SHDA.</p><details><summary>read the caption</summary>(h) I‚Üí‚Üí\rightarrow‚ÜíS</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x14.png alt></figure></p><blockquote><p>üîº Figure 6 presents the results of an experiment investigating how the order of category indices in source samples affects the performance of various SHDA methods on eight different transfer tasks. The x-axis represents the different permutation orders of category indices for source samples (Order 1 being the original order), while the y-axis displays the classification accuracy. The results show that permuting the category indices of source samples has minimal impact on the performance of various SHDA methods, suggesting that the exact alignment of source and target category labels is not crucial for effective SHDA.</p><details><summary>read the caption</summary>Figure 6: Classification accuracies (%) with distinct orders of category indices for source samples.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x15.png alt></figure></p><blockquote><p>üîº This figure illustrates a scenario in semi-supervised heterogeneous domain adaptation (SHDA). It demonstrates the challenge of adapting between domains where source and target data have different underlying categories (e.g., different types of features). The key point is that, despite the different original categories, a mapping is artificially imposed to force the categories to align numerically. This highlights the difficulty of SHDA, which requires adaptation despite the lack of a natural one-to-one correspondence between source and target categories.</p><details><summary>read the caption</summary>Figure 7: Example illustration of the cross-dataset SHDA task. Here, source and target samples have different categories but are forcibly mapped to the same category indices.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x16.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracies of different machine learning methods when using various types of source samples for the image domain in semi-supervised heterogeneous domain adaptation (SHDA). The x-axis represents different types of source samples, while the y-axis represents the classification accuracy. Different colors represent different SHDA methods. The figure demonstrates that using noise samples, as opposed to traditional source data, can achieve similar or even better performance in SHDA tasks.</p><details><summary>read the caption</summary>(a) Target domain: Image</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x17.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracies achieved by different methods when various proportions of noises are injected into source samples in semi-supervised heterogeneous domain adaptation (SHDA) tasks. The target domain is S. The x-axis represents different proportions of noise, and the y-axis represents classification accuracy. Each line corresponds to a different SHDA method, including supervised learning methods and several typical SHDA methods.</p><details><summary>read the caption</summary>(b) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x18.png alt></figure></p><blockquote><p>üîº This figure displays the classification accuracy achieved by various semi-supervised heterogeneous domain adaptation (SHDA) methods across different SHDA tasks. The key aspect highlighted is the performance variation when using source samples with differing feature representations. The goal is to show whether the origin (e.g., text, image, or noise) of the source data significantly impacts the success of knowledge transfer to the target domain. Specifically, it investigates whether the choice of feature representation in the source samples significantly affects the accuracy of SHDA methods on the target domain.</p><details><summary>read the caption</summary>Figure 8: Classification accuracies (%) of different source samples with distinct feature information.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x19.png alt></figure></p><blockquote><p>üîº This figure illustrates a noise-injection SHDA task. In a standard SHDA task, the goal is to learn from labeled source data and limited labeled target data to classify unlabeled target data. Here, the source data is augmented by mixing it with different ratios of noise. This allows the researchers to analyze how the introduction of noise into the source data impacts the SHDA model&rsquo;s ability to classify the unlabeled target data, helping to understand how robust the models are to noisy inputs. The noise is not added directly into the original feature space, but into the representation learned by the network itself.</p><details><summary>read the caption</summary>Figure 9: Example illustration of the noise-injection SHDA task. Here, source samples are mixed with distinct ratios of noise.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x20.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy for different source samples with distinct feature information. Specifically, it displays the performance of several machine learning methods (SVMt, NNt, SHFA, CDLS, DDACL, TNT, STN, SSAN, JMEA) when using various source domains (Text, A (S800), C (S800), W (S800), A (D4096), C (D4096), W (D4096)) to predict the target domain, which is &lsquo;S&rsquo; in this subfigure. The x-axis represents the source domain, and the y-axis represents the classification accuracy. The purpose is to investigate how different feature representations in source samples impact the target prediction accuracy in semi-supervised heterogeneous domain adaptation (SHDA).</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x21.png alt></figure></p><blockquote><p>üîº This figure displays the classification accuracy results for different source samples (with distinct feature information) when the target domain is C (D4096). The x-axis represents the different source domains used, showing the performance of several SHDA methods (and two supervised learning baselines) on the target domain&rsquo;s classification task. It&rsquo;s part of an empirical study exploring the influence of different types of source samples on SHDA performance. The goal is to determine whether the category or feature information in source samples impacts the target domain&rsquo;s performance.</p><details><summary>read the caption</summary>(b) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x22.png alt></figure></p><blockquote><p>üîº This figure displays the classification accuracy results obtained from applying various domain adaptation methods to tasks where the source data is increasingly contaminated with noise. The x-axis represents the proportion of noise added to the original source data, ranging from 0% to 100% (in increments of 20%). The y-axis displays the classification accuracy. Two target domains were used: domain S (textual data) and domain C (images). The results illustrate how each method&rsquo;s performance changes with increasing noise levels, showing its resilience (or lack thereof) to noisy source data in semi-supervised heterogeneous domain adaptation (SHDA).</p><details><summary>read the caption</summary>Figure 10: Classification accuracies (%) with different proportions of nosies.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x23.png alt></figure></p><blockquote><p>üîº This figure illustrates a noise-based semi-supervised heterogeneous domain adaptation (SHDA) task. Instead of using actual data as source samples, the source domain consists entirely of noise generated from a random distribution. This noise lacks any semantic meaning or relationship to real-world categories. To connect the noise to the target domain, the category indices (labels) of the target domain are randomly and uniquely mapped to each category of the source noise. This setup is used to investigate whether transferable knowledge can be extracted from purely random data in the context of SHDA.</p><details><summary>read the caption</summary>Figure 11: Example illustration of the noise-based SHDA task. Here, source samples consist of noise drawn from a random distribution without any semantic meaning, where the category indices of the target domain are randomly and uniquely assigned to each category of source noise.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x24.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy for different methods across various source noise samples with the target domain being the multilingual Reuters dataset (S). It illustrates how the performance of different domain adaptation methods changes as increasing proportions of noise are injected into the source samples. The x-axis represents the increasing proportion of noise, and the y-axis represents the classification accuracy. Each line represents a different domain adaptation method, allowing for comparison of their robustness to noise in the source data.</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x25.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy results on the target domain C (using 4096-dimensional DeCAF features). The x-axis represents different proportions of noise injected into the source samples, ranging from 0% (no noise) to 100% (pure noise). The y-axis represents the classification accuracy. The plot displays the performance of various SHDA methods under different levels of noise in the source data. This experiment investigates the impact of noise in the source domain on the SHDA performance.</p><details><summary>read the caption</summary>(b) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x26.png alt></figure></p><blockquote><p>üîº Figure 12 presents the classification accuracy results for various noise-based semi-supervised heterogeneous domain adaptation (SHDA) tasks. Different noise domains are generated using Gaussian mixture distributions with varying means and covariances. The performance across nine different SHDA methods (and two supervised learning baselines) are shown for two target domains: the &lsquo;S&rsquo; domain and the &lsquo;C (D4096)&rsquo; domain. The purpose of the experiment is to investigate how the statistical properties of the noise (means and covariances) impact the success of domain adaptation.</p><details><summary>read the caption</summary>Figure 12: Classification accuracies (%) with various noise domains characterized by distinct means and covariances.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x27.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy for different source samples with distinct feature information. The x-axis represents different source domains (text, A(S800), C(S800), W(S800), A(D4096), C(D4096), W(D4096)), while the y-axis represents the classification accuracy. The plot shows that the accuracy remains relatively stable across different source domains, indicating that the type of source sample may have less impact on the overall performance than other factors, and suggesting that noise may contain transferable knowledge.</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x28.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy results for different source samples with distinct feature information when the target domain is C (D4096). The x-axis represents different source data types, and the y-axis represents the accuracy. The plot visualizes the performance of different SHDA methods and supervised learning methods (SVMt, NNt) under this condition.</p><details><summary>read the caption</summary>(b) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x29.png alt></figure></p><blockquote><p>üîº This figure displays the classification accuracy results for several semi-supervised heterogeneous domain adaptation (SHDA) methods. The accuracy is measured using different noise domains where the number of samples in each noise category is varied. The noise samples are used as the source domain in these SHDA experiments. The purpose is to study the impact of the number of noise samples on the performance of the target domain. Different target domains are included in this experiment.</p><details><summary>read the caption</summary>Figure 13: Classification accuracies (%) with different noise domains characterized by distinct sample numbers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x30.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy for different source samples with distinct feature information. The x-axis lists various source domains, representing different types of data used (e.g., text, images from different sources). The y-axis displays the classification accuracy on the target domain S. Each bar represents a different SHDA method tested. The plot illustrates the impact of different source data on the performance of SHDA algorithms in terms of classification accuracy on the target domain.</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x31.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy for different source samples with distinct feature information, specifically focusing on the target domain C (D4096). It demonstrates the performance of various methods (SVMt, NNt, SHFA, CDLS, DDACL, TNT, STN, SSAN, JMEA) when using different source domains (Text, A (S800), C (S800), W (S800), A (D4096), C (D4096), W (D4096)) for semi-supervised heterogeneous domain adaptation (SHDA). The x-axis represents the different source domains, while the y-axis shows the classification accuracy.</p><details><summary>read the caption</summary>(b) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x32.png alt></figure></p><blockquote><p>üîº This figure displays the classification accuracy results for various machine learning methods across multiple experiments. Each experiment uses a different noise domain as the source of training data. The key difference between the experiments is the dimensionality of the noise data (ranging from 100 to 500). The results illustrate how the performance of the algorithms changes with varying dimensionality of the noise used as training input, and helps to assess the impact of this feature on overall accuracy.</p><details><summary>read the caption</summary>Figure 14: Classification accuracies (%) with different noise domains characterized by distinct dimensionalities.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x33.png alt></figure></p><blockquote><p>üîº This figure visualizes the classification accuracies achieved by different methods across various noise-injection SHDA tasks, specifically focusing on the target domain &lsquo;S&rsquo;. The x-axis represents different proportions of noise injected into the source samples, ranging from 0 to 1. The y-axis displays the classification accuracy. The various lines represent different SHDA methods and supervised learning baselines. The figure demonstrates the robustness of the methods across different levels of noise in the source domain.</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x34.png alt></figure></p><blockquote><p>üîº This figure shows the classification accuracy results for different source samples with varying feature information when the target domain is the Caltech-256 dataset represented with 4096-dimensional DeCAF features (D4096). Different source domains are used, and the plot illustrates how the choice of source data affects the performance of the target domain classification task.</p><details><summary>read the caption</summary>(b) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x35.png alt></figure></p><blockquote><p>üîº Figure 15 displays the results of classification accuracy for various SHDA methods when different types of noise distributions are used as source data. Specifically, six types of noise domains were generated: three with 6 categories (NG6, NU6, NL6) and three with 10 categories (NG10, NU10, NL10). NG denotes noise drawn from Gaussian distributions, NU from uniform distributions, and NL from Laplace distributions. The figure shows how each method&rsquo;s performance varies across these different noise distributions for two target domains (S and C). This helps analyze the impact of the source noise&rsquo;s distribution on SHDA performance.</p><details><summary>read the caption</summary>Figure 15: Classification accuracies (%) with different noise domains characterized by distinct types of distributions.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x36.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracies of different supervised learning methods and semi-supervised heterogeneous domain adaptation (SHDA) methods on the target domain S. The x-axis represents different types of source samples, showing that performance is relatively stable regardless of whether source data comes from text, images, or noise. This visualization supports the hypothesis that noise can contain transferable knowledge for SHDA.</p><details><summary>read the caption</summary>(a) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x37.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy results for various noise-injection SHDA tasks, where the target domain is the &lsquo;S&rsquo; domain (Multilingual Reuters Collection dataset). Different methods are compared, and the x-axis represents different ratios of noise added to the source samples. The plot illustrates how the performance of SHDA methods changes as the amount of noise in the source samples increases, showcasing the robustness or sensitivity of the methods to noisy input.</p><details><summary>read the caption</summary>(b) Target domain: S</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x38.png alt></figure></p><blockquote><p>üîº The figure shows the classification accuracy for different source noise with varying proportions on the target domain C (D4096). The x-axis represents the ratio of noise added to the source data, ranging from 0 to 1. The y-axis shows the classification accuracy. Multiple lines represent different SHDA methods used in the experiment, illustrating the effect of different levels of noise on model performance in a heterogeneous domain adaptation task.</p><details><summary>read the caption</summary>(c) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x39.png alt></figure></p><blockquote><p>üîº Figure 10(d) presents the classification accuracy results for various noise injection methods on the Caltech-256 dataset (using DeCAF6 features), where source samples contain varying levels of noise from a Gaussian distribution. The x-axis shows the different methods, and the y-axis shows the accuracy. Different colored lines represent different noise levels (from 0% to 100%). The figure demonstrates that even with 100% noise as source data, the SHDA methods achieve comparable performance to those with real source samples, suggesting the surprising conclusion that noise can contain transferable knowledge.</p><details><summary>read the caption</summary>(d) Target domain: C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x40.png alt></figure></p><blockquote><p>üîº Figure 16 shows the correlation between the discriminability and transferability of the source domain and the performance improvement in the target domain. The discriminability (‚Ñí<sub>s</sub>) measures how well the source data is separated; lower values indicate better separation. Transferability (‚Ñí<sub>s,t</sub>) measures how similar the source and target domains are; lower values indicate better transferability. The performance improvement ratio (ùí´<sub>r</sub>) shows how much better the KTF model performs compared to a standard supervised learning model (NNt). The plots and correlation coefficients demonstrate a strong negative correlation: Better discriminability and transferability in the source domain lead to better performance improvements in the target domain.</p><details><summary>read the caption</summary>Figure 16: Correlation between ‚Ñíssubscript‚Ñíùë†\mathcal{L}_{s}caligraphic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT and ùí´rsubscriptùí´ùëü\mathcal{P}_{r}caligraphic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, as well as between ‚Ñís,tsubscript‚Ñíùë†ùë°\mathcal{L}_{s,t}caligraphic_L start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT and ùí´rsubscriptùí´ùëü\mathcal{P}_{r}caligraphic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT. Here, ‚Ñíssubscript‚Ñíùë†\mathcal{L}_{s}caligraphic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT represents the discriminability of the source domain, ‚Ñís,tsubscript‚Ñíùë†ùë°\mathcal{L}_{s,t}caligraphic_L start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT characterizes the transferability of the source domain, and ùí´rsubscriptùí´ùëü\mathcal{P}_{r}caligraphic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT denotes the performance improvement ratio in the target domain.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x41.png alt></figure></p><blockquote><p>üîº This figure shows a t-SNE visualization of the source and target data distributions for the task of transferring knowledge from a noise-based source domain (N6) to a target domain (S) at iteration 1 (t=1). The &lsquo;+&rsquo; symbols represent source samples, &lsquo;x&rsquo; symbols represent labeled target samples, and &lsquo;o&rsquo; symbols represent unlabeled target samples. Each color corresponds to a different category, illustrating the separation (or lack thereof) of categories in both domains at the start of the adaptation process.</p><details><summary>read the caption</summary>(a) N6 ‚Üí‚Üí\rightarrow‚Üí S: t=1ùë°1t=1italic_t = 1</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x42.png alt></figure></p><blockquote><p>üîº This figure shows a t-SNE visualization of the data from a semi-supervised heterogeneous domain adaptation (SHDA) experiment. Specifically, it displays the results for the task N6 ‚Üí S at iteration 200. The plot visualizes the features of source samples (represented by &lsquo;+&rsquo;), labeled target samples (&rsquo;*&rsquo;), and unlabeled target samples (&lsquo;o&rsquo;). Each color corresponds to a distinct category. The figure illustrates how the features of source and target samples are distributed and how well-separated they are in the feature space after 200 iterations of the adaptation process. This is used to analyze the alignment of source and target domains throughout the adaptation process, helping to understand knowledge transfer in SHDA.</p><details><summary>read the caption</summary>(b) N6 ‚Üí‚Üí\rightarrow‚Üí S: t=200ùë°200t=200italic_t = 200</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x43.png alt></figure></p><blockquote><p>üîº This figure displays a t-distributed stochastic neighbor embedding (t-SNE) visualization of the results from the N6 ‚Üí S experiment at iteration 400. The visualization shows the separation of source noise samples (marked with &lsquo;+&rsquo;) and target samples (labeled with &lsquo;x&rsquo; and unlabeled with &lsquo;o&rsquo;). Each color represents a different category. The figure illustrates the degree of separation achieved between source and target categories in the common subspace at this training iteration.</p><details><summary>read the caption</summary>(c) N6 ‚Üí‚Üí\rightarrow‚Üí S: t=400ùë°400t=400italic_t = 400</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x44.png alt></figure></p><blockquote><p>üîº This t-SNE visualization shows the results of applying the Knowledge Transfer Framework (KTF) to the N6 ‚Üí S task (source noise with 6 categories mapped to the target domain S) at iteration 600. Each point represents a sample. The &lsquo;+&rsquo; symbol denotes a source noise sample; the &lsquo;*&rsquo; symbol denotes a labeled target sample; and the &lsquo;o&rsquo; symbol denotes an unlabeled target sample. Each color represents a different category. The figure illustrates the clustering and separation of samples in the common subspace learned by the KTF, demonstrating the alignment of source and target domains.</p><details><summary>read the caption</summary>(d) N6 ‚Üí‚Üí\rightarrow‚Üí S: t=600ùë°600t=600italic_t = 600</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x45.png alt></figure></p><blockquote><p>üîº This figure shows a t-distributed stochastic neighbor embedding (t-SNE) visualization of the source and target data distributions for a specific semi-supervised heterogeneous domain adaptation (SHDA) task. The task involves using a noise-based source domain (N10) with 10 categories to adapt to a target image domain (C(D4096)). The visualization is shown at the very beginning of the adaptation process (t=1). Each point represents a data sample, colored according to its category. The &lsquo;+&rsquo; symbol indicates source samples, the &lsquo;*&rsquo; symbol indicates labeled target samples, and the &lsquo;o&rsquo; symbol indicates unlabeled target samples. This visualization illustrates the initial separation (or lack thereof) of the source and target data points before the adaptation process begins.</p><details><summary>read the caption</summary>(e) N10 ‚Üí‚Üí\rightarrow‚Üí C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT): t=1ùë°1t=1italic_t = 1</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x46.png alt></figure></p><blockquote><p>üîº This figure shows a t-SNE visualization of the features of source and target samples for the task N10 -> C(D4096) at iteration 200. The plus sign (+) represents source noise samples, while the circles (o) and squares (‚ñ†) denote unlabeled and labeled target samples, respectively. Each color corresponds to a different category. The visualization demonstrates how the separation of the target sample categories improves as the model trains. This is a visualization to show discriminability and transferability.</p><details><summary>read the caption</summary>(f) N10 ‚Üí‚Üí\rightarrow‚Üí C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT): t=200ùë°200t=200italic_t = 200</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x47.png alt></figure></p><blockquote><p>üîº This figure shows a t-SNE visualization of the results for the task where source samples consist of noise (N10) and the target domain is C (D4096). The visualization is at time step t=400, showing the separation of different categories in the target domain. The &lsquo;+&rsquo; symbols represent source samples (noise), while &lsquo;‚óè&rsquo; indicates labeled target samples, and &lsquo;o&rsquo; represents unlabeled target samples. Each color represents a different category.</p><details><summary>read the caption</summary>(g) N10 ‚Üí‚Üí\rightarrow‚Üí C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT): t=400ùë°400t=400italic_t = 400</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x48.png alt></figure></p><blockquote><p>üîº This figure shows the t-distributed stochastic neighbor embedding (t-SNE) visualization of the N10 ‚Üí C(D4096) task at iteration 600. The plus signs (+) represent source samples (noise), the asterisks (*) denote labeled target samples, and the circles (o) represent unlabeled target samples. Each color corresponds to a different category. The visualization demonstrates the separation of categories in the common subspace achieved by the model, highlighting the alignment of source and target data distributions.</p><details><summary>read the caption</summary>(h) N10 ‚Üí‚Üí\rightarrow‚Üí C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT): t=600ùë°600t=600italic_t = 600</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x49.png alt></figure></p><blockquote><p>üîº This figure visualizes the results of t-SNE dimensionality reduction applied to source and target data in two semi-supervised heterogeneous domain adaptation (SHDA) tasks: N6‚ÜíS and N10‚ÜíC(D4096). Different shapes represent different data types: &lsquo;+&rsquo; for source samples, &lsquo;‚àô&rsquo; for labeled target samples, and &lsquo;‚àò&rsquo; for unlabeled target samples. Each color represents a distinct category. The four columns for each task show the data points at different iteration numbers (t), demonstrating how the data clusters evolve as the SHDA algorithm proceeds. This visualization helps illustrate the gradual alignment of source and target data distributions during the adaptation process, highlighting the discriminability of the source domain and the increasing separability of target samples as iterations progress.</p><details><summary>read the caption</summary>Figure 17: t-SNE visualization on the tasks of N6 ‚Üí‚Üí\rightarrow‚Üí S and N10 ‚Üí‚Üí\rightarrow‚Üí C (D4096subscriptùê∑4096D_{4096}italic_D start_POSTSUBSCRIPT 4096 end_POSTSUBSCRIPT). Here, the ‚Äò+‚Äô sign denotes a source sample, the ‚Äò‚àô‚àô\bullet‚àô‚Äô sign represents a labeled target sample, and the ‚Äò‚àò\circ‚àò‚Äô sign stands for an unlabeled target sample. Each color corresponds to a distinct category, and tùë°titalic_t is the current number of iterations.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x50.png alt></figure></p><blockquote><p>üîº This figure displays a t-distributed stochastic neighbor embedding (t-SNE) visualization of the results from a noise-based semi-supervised heterogeneous domain adaptation (SHDA) task. Specifically, it shows the feature distribution of source noise (represented by &lsquo;+&rsquo;), labeled target samples (&rsquo;*&rsquo;), and unlabeled target samples (&lsquo;o&rsquo;) at the beginning of the training process (iteration 1). Each color represents a different category. The figure is part of an analysis investigating the transferability of knowledge from noise to target samples, revealing how noise samples separate by category in the common subspace.</p><details><summary>read the caption</summary>(a) N6 ‚Üí‚Üí\rightarrow‚Üí S: t = 1</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x51.png alt></figure></p><blockquote><p>üîº This figure shows the t-SNE visualization of the transfer process on the task of N6 &ndash;> S (Noise with 6 categories as source domain to the S target domain) at iteration 200. The &lsquo;+&rsquo; sign represents source samples, the &lsquo;*&rsquo; sign represents labeled target samples, and the &lsquo;o&rsquo; sign represents unlabeled target samples. Each color represents a distinct category. The plot visualizes how the source and target samples are distributed in the common subspace, and how their distributions change as the training progresses. The visualization helps to understand how the knowledge from the source domain is transferred to the target domain during the domain adaptation process.</p><details><summary>read the caption</summary>(b) N6 ‚Üí‚Üí\rightarrow‚Üí S: t = 200</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x52.png alt></figure></p><blockquote><p>üîº This figure shows a t-SNE visualization of the results from a semi-supervised heterogeneous domain adaptation (SHDA) task where the source domain is noise (N6) and the target domain is the Reuters dataset (S). The visualization is shown at iteration 400 of the training process. Each point represents a sample and the color indicates the true class label of the sample. The visualization demonstrates the gradual alignment of the distributions of the source and target domains as training progresses. This alignment is important because it shows the positive transfer of knowledge from the source noise to the target dataset.</p><details><summary>read the caption</summary>(c) N6 ‚Üí‚Üí\rightarrow‚Üí S: t = 400</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.13573/x53.png alt></figure></p><blockquote><p>üîº This t-SNE visualization shows the results of the N6 ‚Üí S task in the study on transferable knowledge in SHDA. The image displays the distribution of source noise (represented by &lsquo;+&rsquo;), labeled target samples (&rsquo;*&rsquo;), and unlabeled target samples (&lsquo;o&rsquo;) in the common subspace at iteration 600. Each color represents a different category. The visualization aims to illustrate the alignment between the source and target domains, demonstrating how the discriminability of the source noise is transferred to the target samples as the transferability of the source domain improves.</p><details><summary>read the caption</summary>(d) N6 ‚Üí‚Üí\rightarrow‚Üí S: t = 600</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S3.T2.1><thead class=ltx_thead><tr class=ltx_tr id=S3.T2.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S3.T2.1.1.1.1 style=padding-left:4pt;padding-right:4pt>Method</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S3.T2.1.1.1.2 style=padding-left:4pt;padding-right:4pt>Type</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S3.T2.1.1.1.3 style=padding-left:4pt;padding-right:4pt>URL for Code</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S3.T2.1.1.1.4 style=padding-left:4pt;padding-right:4pt>Publication</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S3.T2.1.2.1><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T2.1.2.1.1 style=padding-left:4pt;padding-right:4pt>SVMt <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib33 title>33</a>]</cite></td><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T2.1.2.1.2 style=padding-left:4pt;padding-right:4pt>Supervised Learning</td><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T2.1.2.1.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_url ltx_font_typewriter" href=https://www.csie.ntu.edu.tw/~cjlin/libsvm/ title>https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a></td><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T2.1.2.1.4 style=padding-left:4pt;padding-right:4pt>ACM TIST 2011</td></tr><tr class=ltx_tr id=S3.T2.1.3.2><td class="ltx_td ltx_align_left" id=S3.T2.1.3.2.1 style=padding-left:4pt;padding-right:4pt>NNt <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib34 title>34</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.3.2.2 style=padding-left:4pt;padding-right:4pt>Supervised Learning</td><td class="ltx_td ltx_align_left" id=S3.T2.1.3.2.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_url ltx_font_typewriter" href=https://github.com/tensorflow/tensorflow title>https://github.com/tensorflow/tensorflow</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.3.2.4 style=padding-left:4pt;padding-right:4pt>OSDI 2016</td></tr><tr class=ltx_tr id=S3.T2.1.4.3><td class="ltx_td ltx_align_left" id=S3.T2.1.4.3.1 style=padding-left:4pt;padding-right:4pt>SHFA <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib35 title>35</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.4.3.2 style=padding-left:4pt;padding-right:4pt>Shallow Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.4.3.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/wenli-vision/SHFA_release title>https://github.com/wenli-vision/SHFA_release</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.4.3.4 style=padding-left:4pt;padding-right:4pt>TPAMI 2014</td></tr><tr class=ltx_tr id=S3.T2.1.5.4><td class="ltx_td ltx_align_left" id=S3.T2.1.5.4.1 style=padding-left:4pt;padding-right:4pt>CDLS <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib36 title>36</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.5.4.2 style=padding-left:4pt;padding-right:4pt>Shallow Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.5.4.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/yaohungt/Cross-Domain-Landmarks-Selection-CDLS-/tree/master title>https://github.com/yaohungt/Cross-Domain-Landmarks-Selection-CDLS-/tree/master</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.5.4.4 style=padding-left:4pt;padding-right:4pt>CVPR 2016</td></tr><tr class=ltx_tr id=S3.T2.1.6.5><td class="ltx_td ltx_align_left" id=S3.T2.1.6.5.1 style=padding-left:4pt;padding-right:4pt>DDACL <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib27 title>27</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.6.5.2 style=padding-left:4pt;padding-right:4pt>Shallow Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.6.5.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/yyyaoyuan/DDA title>https://github.com/yyyaoyuan/DDA</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.6.5.4 style=padding-left:4pt;padding-right:4pt>Pattern Recognition 2020</td></tr><tr class=ltx_tr id=S3.T2.1.7.6><td class="ltx_td ltx_align_left" id=S3.T2.1.7.6.1 style=padding-left:4pt;padding-right:4pt>TNT <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib37 title>37</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.7.6.2 style=padding-left:4pt;padding-right:4pt>Deep Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.7.6.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/wyharveychen/TransferNeuralTrees title>https://github.com/wyharveychen/TransferNeuralTrees</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.7.6.4 style=padding-left:4pt;padding-right:4pt>ECCV 2016</td></tr><tr class=ltx_tr id=S3.T2.1.8.7><td class="ltx_td ltx_align_left" id=S3.T2.1.8.7.1 style=padding-left:4pt;padding-right:4pt>STN <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib24 title>24</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.8.7.2 style=padding-left:4pt;padding-right:4pt>Deep Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.8.7.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/yyyaoyuan/STN title>https://github.com/yyyaoyuan/STN</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.8.7.4 style=padding-left:4pt;padding-right:4pt>ACM MM 2019</td></tr><tr class=ltx_tr id=S3.T2.1.9.8><td class="ltx_td ltx_align_left" id=S3.T2.1.9.8.1 style=padding-left:4pt;padding-right:4pt>SSAN <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib29 title>29</a>]</cite></td><td class="ltx_td ltx_align_left" id=S3.T2.1.9.8.2 style=padding-left:4pt;padding-right:4pt>Deep Projection SHDA</td><td class="ltx_td ltx_align_left" id=S3.T2.1.9.8.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/BIT-DA/SSAN title>https://github.com/BIT-DA/SSAN</a></td><td class="ltx_td ltx_align_left" id=S3.T2.1.9.8.4 style=padding-left:4pt;padding-right:4pt>ACM MM 2020</td></tr><tr class=ltx_tr id=S3.T2.1.10.9><td class="ltx_td ltx_align_left ltx_border_bb" id=S3.T2.1.10.9.1 style=padding-left:4pt;padding-right:4pt>JMEA <cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2502.13573v1#bib.bib25 title>25</a>]</cite></td><td class="ltx_td ltx_align_left ltx_border_bb" id=S3.T2.1.10.9.2 style=padding-left:4pt;padding-right:4pt>Deep Projection SHDA</td><td class="ltx_td ltx_align_left ltx_border_bb" id=S3.T2.1.10.9.3 style=padding-left:4pt;padding-right:4pt><a class="ltx_ref ltx_href" href=https://github.com/fang-zhen/Semi-supervised-Heterogeneous-Domain-Adaptation title>https://github.com/fang-zhen/Semi-supervised-Heterogeneous-Domain-Adaptation</a></td><td class="ltx_td ltx_align_left ltx_border_bb" id=S3.T2.1.10.9.4 style=padding-left:4pt;padding-right:4pt>TPAMI 2023</td></tr></tbody></table></table></figure><blockquote><p>üîº Table II lists the nine baseline methods used in the paper&rsquo;s experiments for comparison. It includes two supervised learning methods (SVMt and NNt) and seven semi-supervised heterogeneous domain adaptation (SHDA) methods (SHFA, CDLS, DDACL, TNT, STN, SSAN, and JMEA). For each method, the table provides the method&rsquo;s type (supervised learning or SHDA), a short description, and a URL to the source code.</p><details><summary>read the caption</summary>TABLE II: Baselines utilized in the paper.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S5.T3.20><thead class=ltx_thead><tr class=ltx_tr id=S5.T3.10.2><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S5.T3.10.2.3>Domain</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T3.9.1.1><math alttext="\frac{1}{C}\sum_{c=1}^{C}\|\bm{\mu}_{c}\|_{2}" class="ltx_Math" display="inline" id="S5.T3.9.1.1.m1.1"><semantics id="S5.T3.9.1.1.m1.1a"><mrow id="S5.T3.9.1.1.m1.1.1" xref="S5.T3.9.1.1.m1.1.1.cmml"><mfrac id="S5.T3.9.1.1.m1.1.1.3" xref="S5.T3.9.1.1.m1.1.1.3.cmml"><mn id="S5.T3.9.1.1.m1.1.1.3.2" xref="S5.T3.9.1.1.m1.1.1.3.2.cmml">1</mn><mi id="S5.T3.9.1.1.m1.1.1.3.3" xref="S5.T3.9.1.1.m1.1.1.3.3.cmml">C</mi></mfrac><mo id="S5.T3.9.1.1.m1.1.1.2" xref="S5.T3.9.1.1.m1.1.1.2.cmml">‚Å¢</mo><mrow id="S5.T3.9.1.1.m1.1.1.1" xref="S5.T3.9.1.1.m1.1.1.1.cmml"><msubsup id="S5.T3.9.1.1.m1.1.1.1.2" xref="S5.T3.9.1.1.m1.1.1.1.2.cmml"><mo id="S5.T3.9.1.1.m1.1.1.1.2.2.2" rspace="0em" xref="S5.T3.9.1.1.m1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S5.T3.9.1.1.m1.1.1.1.2.2.3" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.cmml"><mi id="S5.T3.9.1.1.m1.1.1.1.2.2.3.2" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.2.cmml">c</mi><mo id="S5.T3.9.1.1.m1.1.1.1.2.2.3.1" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.T3.9.1.1.m1.1.1.1.2.2.3.3" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.T3.9.1.1.m1.1.1.1.2.3" xref="S5.T3.9.1.1.m1.1.1.1.2.3.cmml">C</mi></msubsup><msub id="S5.T3.9.1.1.m1.1.1.1.1" xref="S5.T3.9.1.1.m1.1.1.1.1.cmml"><mrow id="S5.T3.9.1.1.m1.1.1.1.1.1.1" xref="S5.T3.9.1.1.m1.1.1.1.1.1.2.cmml"><mo id="S5.T3.9.1.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.T3.9.1.1.m1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><msub id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.2" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.2.cmml">ùùÅ</mi><mi id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.3" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S5.T3.9.1.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.T3.9.1.1.m1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S5.T3.9.1.1.m1.1.1.1.1.3" xref="S5.T3.9.1.1.m1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.9.1.1.m1.1b"><apply id="S5.T3.9.1.1.m1.1.1.cmml" xref="S5.T3.9.1.1.m1.1.1"><times id="S5.T3.9.1.1.m1.1.1.2.cmml" xref="S5.T3.9.1.1.m1.1.1.2"></times><apply id="S5.T3.9.1.1.m1.1.1.3.cmml" xref="S5.T3.9.1.1.m1.1.1.3"><divide id="S5.T3.9.1.1.m1.1.1.3.1.cmml" xref="S5.T3.9.1.1.m1.1.1.3"></divide><cn id="S5.T3.9.1.1.m1.1.1.3.2.cmml" type="integer" xref="S5.T3.9.1.1.m1.1.1.3.2">1</cn><ci id="S5.T3.9.1.1.m1.1.1.3.3.cmml" xref="S5.T3.9.1.1.m1.1.1.3.3">ùê∂</ci></apply><apply id="S5.T3.9.1.1.m1.1.1.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1"><apply id="S5.T3.9.1.1.m1.1.1.1.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.9.1.1.m1.1.1.1.2.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2">superscript</csymbol><apply id="S5.T3.9.1.1.m1.1.1.1.2.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.9.1.1.m1.1.1.1.2.2.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2">subscript</csymbol><sum id="S5.T3.9.1.1.m1.1.1.1.2.2.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2.2.2"></sum><apply id="S5.T3.9.1.1.m1.1.1.1.2.2.3.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3"><eq id="S5.T3.9.1.1.m1.1.1.1.2.2.3.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.1"></eq><ci id="S5.T3.9.1.1.m1.1.1.1.2.2.3.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.2">ùëê</ci><cn id="S5.T3.9.1.1.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.T3.9.1.1.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.T3.9.1.1.m1.1.1.1.2.3.cmml" xref="S5.T3.9.1.1.m1.1.1.1.2.3">ùê∂</ci></apply><apply id="S5.T3.9.1.1.m1.1.1.1.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.9.1.1.m1.1.1.1.1.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1">subscript</csymbol><apply id="S5.T3.9.1.1.m1.1.1.1.1.1.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T3.9.1.1.m1.1.1.1.1.1.2.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.2">ùùÅ</ci><ci id="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.T3.9.1.1.m1.1.1.1.1.1.1.1.3">ùëê</ci></apply></apply><cn id="S5.T3.9.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S5.T3.9.1.1.m1.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.1.1.m1.1c">\frac{1}{C}\sum_{c=1}^{C}\|\bm{\mu}_{c}\|_{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.1.1.m1.1d">divide start_ARG 1 end_ARG start_ARG italic_C end_ARG ‚àë start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT ‚à• bold_italic_Œº start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ‚à• start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T3.10.2.2><math alttext="\frac{1}{C}\sum_{c=1}^{C}\|\bm{\Sigma}_{c}\|_{F}" class="ltx_Math" display="inline" id="S5.T3.10.2.2.m1.1"><semantics id="S5.T3.10.2.2.m1.1a"><mrow id="S5.T3.10.2.2.m1.1.1" xref="S5.T3.10.2.2.m1.1.1.cmml"><mfrac id="S5.T3.10.2.2.m1.1.1.3" xref="S5.T3.10.2.2.m1.1.1.3.cmml"><mn id="S5.T3.10.2.2.m1.1.1.3.2" xref="S5.T3.10.2.2.m1.1.1.3.2.cmml">1</mn><mi id="S5.T3.10.2.2.m1.1.1.3.3" xref="S5.T3.10.2.2.m1.1.1.3.3.cmml">C</mi></mfrac><mo id="S5.T3.10.2.2.m1.1.1.2" xref="S5.T3.10.2.2.m1.1.1.2.cmml">‚Å¢</mo><mrow id="S5.T3.10.2.2.m1.1.1.1" xref="S5.T3.10.2.2.m1.1.1.1.cmml"><msubsup id="S5.T3.10.2.2.m1.1.1.1.2" xref="S5.T3.10.2.2.m1.1.1.1.2.cmml"><mo id="S5.T3.10.2.2.m1.1.1.1.2.2.2" rspace="0em" xref="S5.T3.10.2.2.m1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S5.T3.10.2.2.m1.1.1.1.2.2.3" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.cmml"><mi id="S5.T3.10.2.2.m1.1.1.1.2.2.3.2" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.2.cmml">c</mi><mo id="S5.T3.10.2.2.m1.1.1.1.2.2.3.1" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.T3.10.2.2.m1.1.1.1.2.2.3.3" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.T3.10.2.2.m1.1.1.1.2.3" xref="S5.T3.10.2.2.m1.1.1.1.2.3.cmml">C</mi></msubsup><msub id="S5.T3.10.2.2.m1.1.1.1.1" xref="S5.T3.10.2.2.m1.1.1.1.1.cmml"><mrow id="S5.T3.10.2.2.m1.1.1.1.1.1.1" xref="S5.T3.10.2.2.m1.1.1.1.1.1.2.cmml"><mo id="S5.T3.10.2.2.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.T3.10.2.2.m1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><msub id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.2" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.2.cmml">ùö∫</mi><mi id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.3" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S5.T3.10.2.2.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.T3.10.2.2.m1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mi id="S5.T3.10.2.2.m1.1.1.1.1.3" xref="S5.T3.10.2.2.m1.1.1.1.1.3.cmml">F</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.10.2.2.m1.1b"><apply id="S5.T3.10.2.2.m1.1.1.cmml" xref="S5.T3.10.2.2.m1.1.1"><times id="S5.T3.10.2.2.m1.1.1.2.cmml" xref="S5.T3.10.2.2.m1.1.1.2"></times><apply id="S5.T3.10.2.2.m1.1.1.3.cmml" xref="S5.T3.10.2.2.m1.1.1.3"><divide id="S5.T3.10.2.2.m1.1.1.3.1.cmml" xref="S5.T3.10.2.2.m1.1.1.3"></divide><cn id="S5.T3.10.2.2.m1.1.1.3.2.cmml" type="integer" xref="S5.T3.10.2.2.m1.1.1.3.2">1</cn><ci id="S5.T3.10.2.2.m1.1.1.3.3.cmml" xref="S5.T3.10.2.2.m1.1.1.3.3">ùê∂</ci></apply><apply id="S5.T3.10.2.2.m1.1.1.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1"><apply id="S5.T3.10.2.2.m1.1.1.1.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.10.2.2.m1.1.1.1.2.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2">superscript</csymbol><apply id="S5.T3.10.2.2.m1.1.1.1.2.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.T3.10.2.2.m1.1.1.1.2.2.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2">subscript</csymbol><sum id="S5.T3.10.2.2.m1.1.1.1.2.2.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2.2.2"></sum><apply id="S5.T3.10.2.2.m1.1.1.1.2.2.3.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3"><eq id="S5.T3.10.2.2.m1.1.1.1.2.2.3.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.1"></eq><ci id="S5.T3.10.2.2.m1.1.1.1.2.2.3.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.2">ùëê</ci><cn id="S5.T3.10.2.2.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.T3.10.2.2.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.T3.10.2.2.m1.1.1.1.2.3.cmml" xref="S5.T3.10.2.2.m1.1.1.1.2.3">ùê∂</ci></apply><apply id="S5.T3.10.2.2.m1.1.1.1.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.10.2.2.m1.1.1.1.1.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1">subscript</csymbol><apply id="S5.T3.10.2.2.m1.1.1.1.1.1.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.T3.10.2.2.m1.1.1.1.1.1.2.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.2">ùö∫</ci><ci id="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.1.1.1.3">ùëê</ci></apply></apply><ci id="S5.T3.10.2.2.m1.1.1.1.1.3.cmml" xref="S5.T3.10.2.2.m1.1.1.1.1.3">ùêπ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.2.2.m1.1c">\frac{1}{C}\sum_{c=1}^{C}\|\bm{\Sigma}_{c}\|_{F}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.2.2.m1.1d">divide start_ARG 1 end_ARG start_ARG italic_C end_ARG ‚àë start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT ‚à• bold_Œ£ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ‚à• start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT</annotation></semantics></math></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T3.11.3><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id=S5.T3.11.3.1><span class="ltx_text ltx_font_bold" id=S5.T3.11.3.1.1>N<math alttext="{}_{1}^{6}" class="ltx_Math" display="inline" id="S5.T3.11.3.1.1.m1.1"><semantics id="S5.T3.11.3.1.1.m1.1a"><mmultiscripts id="S5.T3.11.3.1.1.m1.1.1" xref="S5.T3.11.3.1.1.m1.1.1.cmml"><mi id="S5.T3.11.3.1.1.m1.1.1.2.2" xref="S5.T3.11.3.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.11.3.1.1.m1.1.1a" xref="S5.T3.11.3.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.11.3.1.1.m1.1.1b" xref="S5.T3.11.3.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.11.3.1.1.m1.1.1.3" xref="S5.T3.11.3.1.1.m1.1.1.3.cmml">6</mn><mn id="S5.T3.11.3.1.1.m1.1.1.2.3" xref="S5.T3.11.3.1.1.m1.1.1.2.3.cmml">1</mn><mrow id="S5.T3.11.3.1.1.m1.1.1c" xref="S5.T3.11.3.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.11.3.1.1.m1.1b"><apply id="S5.T3.11.3.1.1.m1.1.1.cmml" xref="S5.T3.11.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.11.3.1.1.m1.1.1.1.cmml" xref="S5.T3.11.3.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.11.3.1.1.m1.1.1.2.cmml" xref="S5.T3.11.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.11.3.1.1.m1.1.1.2.1.cmml" xref="S5.T3.11.3.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.11.3.1.1.m1.1.1.2.2.cmml" xref="S5.T3.11.3.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.11.3.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.11.3.1.1.m1.1.1.2.3">1</cn></apply><cn id="S5.T3.11.3.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.11.3.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.3.1.1.m1.1c">{}_{1}^{6}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.3.1.1.m1.1d">start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.11.3.2>12.62</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.11.3.3>105.34</td></tr><tr class=ltx_tr id=S5.T3.12.4><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.12.4.1><span class="ltx_text ltx_font_bold" id=S5.T3.12.4.1.1>N<math alttext="{}_{2}^{6}" class="ltx_Math" display="inline" id="S5.T3.12.4.1.1.m1.1"><semantics id="S5.T3.12.4.1.1.m1.1a"><mmultiscripts id="S5.T3.12.4.1.1.m1.1.1" xref="S5.T3.12.4.1.1.m1.1.1.cmml"><mi id="S5.T3.12.4.1.1.m1.1.1.2.2" xref="S5.T3.12.4.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.12.4.1.1.m1.1.1a" xref="S5.T3.12.4.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.12.4.1.1.m1.1.1b" xref="S5.T3.12.4.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.12.4.1.1.m1.1.1.3" xref="S5.T3.12.4.1.1.m1.1.1.3.cmml">6</mn><mn id="S5.T3.12.4.1.1.m1.1.1.2.3" xref="S5.T3.12.4.1.1.m1.1.1.2.3.cmml">2</mn><mrow id="S5.T3.12.4.1.1.m1.1.1c" xref="S5.T3.12.4.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.12.4.1.1.m1.1b"><apply id="S5.T3.12.4.1.1.m1.1.1.cmml" xref="S5.T3.12.4.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.12.4.1.1.m1.1.1.1.cmml" xref="S5.T3.12.4.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.12.4.1.1.m1.1.1.2.cmml" xref="S5.T3.12.4.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.12.4.1.1.m1.1.1.2.1.cmml" xref="S5.T3.12.4.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.12.4.1.1.m1.1.1.2.2.cmml" xref="S5.T3.12.4.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.12.4.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.12.4.1.1.m1.1.1.2.3">2</cn></apply><cn id="S5.T3.12.4.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.12.4.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.4.1.1.m1.1c">{}_{2}^{6}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.12.4.1.1.m1.1d">start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.12.4.2>24.44</td><td class="ltx_td ltx_align_center" id=S5.T3.12.4.3>210.32</td></tr><tr class=ltx_tr id=S5.T3.13.5><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.13.5.1><span class="ltx_text ltx_font_bold" id=S5.T3.13.5.1.1>N<math alttext="{}_{3}^{6}" class="ltx_Math" display="inline" id="S5.T3.13.5.1.1.m1.1"><semantics id="S5.T3.13.5.1.1.m1.1a"><mmultiscripts id="S5.T3.13.5.1.1.m1.1.1" xref="S5.T3.13.5.1.1.m1.1.1.cmml"><mi id="S5.T3.13.5.1.1.m1.1.1.2.2" xref="S5.T3.13.5.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.13.5.1.1.m1.1.1a" xref="S5.T3.13.5.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.13.5.1.1.m1.1.1b" xref="S5.T3.13.5.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.13.5.1.1.m1.1.1.3" xref="S5.T3.13.5.1.1.m1.1.1.3.cmml">6</mn><mn id="S5.T3.13.5.1.1.m1.1.1.2.3" xref="S5.T3.13.5.1.1.m1.1.1.2.3.cmml">3</mn><mrow id="S5.T3.13.5.1.1.m1.1.1c" xref="S5.T3.13.5.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.13.5.1.1.m1.1b"><apply id="S5.T3.13.5.1.1.m1.1.1.cmml" xref="S5.T3.13.5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.13.5.1.1.m1.1.1.1.cmml" xref="S5.T3.13.5.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.13.5.1.1.m1.1.1.2.cmml" xref="S5.T3.13.5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.13.5.1.1.m1.1.1.2.1.cmml" xref="S5.T3.13.5.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.13.5.1.1.m1.1.1.2.2.cmml" xref="S5.T3.13.5.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.13.5.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.13.5.1.1.m1.1.1.2.3">3</cn></apply><cn id="S5.T3.13.5.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.13.5.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.13.5.1.1.m1.1c">{}_{3}^{6}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.13.5.1.1.m1.1d">start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.13.5.2>36.16</td><td class="ltx_td ltx_align_center" id=S5.T3.13.5.3>315.39</td></tr><tr class=ltx_tr id=S5.T3.14.6><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.14.6.1><span class="ltx_text ltx_font_bold" id=S5.T3.14.6.1.1>N<math alttext="{}_{4}^{6}" class="ltx_Math" display="inline" id="S5.T3.14.6.1.1.m1.1"><semantics id="S5.T3.14.6.1.1.m1.1a"><mmultiscripts id="S5.T3.14.6.1.1.m1.1.1" xref="S5.T3.14.6.1.1.m1.1.1.cmml"><mi id="S5.T3.14.6.1.1.m1.1.1.2.2" xref="S5.T3.14.6.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.14.6.1.1.m1.1.1a" xref="S5.T3.14.6.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.14.6.1.1.m1.1.1b" xref="S5.T3.14.6.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.14.6.1.1.m1.1.1.3" xref="S5.T3.14.6.1.1.m1.1.1.3.cmml">6</mn><mn id="S5.T3.14.6.1.1.m1.1.1.2.3" xref="S5.T3.14.6.1.1.m1.1.1.2.3.cmml">4</mn><mrow id="S5.T3.14.6.1.1.m1.1.1c" xref="S5.T3.14.6.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.14.6.1.1.m1.1b"><apply id="S5.T3.14.6.1.1.m1.1.1.cmml" xref="S5.T3.14.6.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.14.6.1.1.m1.1.1.1.cmml" xref="S5.T3.14.6.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.14.6.1.1.m1.1.1.2.cmml" xref="S5.T3.14.6.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.14.6.1.1.m1.1.1.2.1.cmml" xref="S5.T3.14.6.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.14.6.1.1.m1.1.1.2.2.cmml" xref="S5.T3.14.6.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.14.6.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.14.6.1.1.m1.1.1.2.3">4</cn></apply><cn id="S5.T3.14.6.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.14.6.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.14.6.1.1.m1.1c">{}_{4}^{6}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.14.6.1.1.m1.1d">start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.14.6.2>46.74</td><td class="ltx_td ltx_align_center" id=S5.T3.14.6.3>420.53</td></tr><tr class=ltx_tr id=S5.T3.15.7><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.15.7.1><span class="ltx_text ltx_font_bold" id=S5.T3.15.7.1.1>N<math alttext="{}_{5}^{6}" class="ltx_Math" display="inline" id="S5.T3.15.7.1.1.m1.1"><semantics id="S5.T3.15.7.1.1.m1.1a"><mmultiscripts id="S5.T3.15.7.1.1.m1.1.1" xref="S5.T3.15.7.1.1.m1.1.1.cmml"><mi id="S5.T3.15.7.1.1.m1.1.1.2.2" xref="S5.T3.15.7.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.15.7.1.1.m1.1.1a" xref="S5.T3.15.7.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.15.7.1.1.m1.1.1b" xref="S5.T3.15.7.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.15.7.1.1.m1.1.1.3" xref="S5.T3.15.7.1.1.m1.1.1.3.cmml">6</mn><mn id="S5.T3.15.7.1.1.m1.1.1.2.3" xref="S5.T3.15.7.1.1.m1.1.1.2.3.cmml">5</mn><mrow id="S5.T3.15.7.1.1.m1.1.1c" xref="S5.T3.15.7.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.15.7.1.1.m1.1b"><apply id="S5.T3.15.7.1.1.m1.1.1.cmml" xref="S5.T3.15.7.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.15.7.1.1.m1.1.1.1.cmml" xref="S5.T3.15.7.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.15.7.1.1.m1.1.1.2.cmml" xref="S5.T3.15.7.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.15.7.1.1.m1.1.1.2.1.cmml" xref="S5.T3.15.7.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.15.7.1.1.m1.1.1.2.2.cmml" xref="S5.T3.15.7.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.15.7.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.15.7.1.1.m1.1.1.2.3">5</cn></apply><cn id="S5.T3.15.7.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.15.7.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.15.7.1.1.m1.1c">{}_{5}^{6}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.15.7.1.1.m1.1d">start_FLOATSUBSCRIPT 5 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.15.7.2>60.43</td><td class="ltx_td ltx_align_center" id=S5.T3.15.7.3>525.05</td></tr><tr class=ltx_tr id=S5.T3.16.8><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.16.8.1><span class="ltx_text ltx_font_bold" id=S5.T3.16.8.1.1>N<math alttext="{}_{1}^{10}" class="ltx_Math" display="inline" id="S5.T3.16.8.1.1.m1.1"><semantics id="S5.T3.16.8.1.1.m1.1a"><mmultiscripts id="S5.T3.16.8.1.1.m1.1.1" xref="S5.T3.16.8.1.1.m1.1.1.cmml"><mi id="S5.T3.16.8.1.1.m1.1.1.2.2" xref="S5.T3.16.8.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.16.8.1.1.m1.1.1a" xref="S5.T3.16.8.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.16.8.1.1.m1.1.1b" xref="S5.T3.16.8.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.16.8.1.1.m1.1.1.3" xref="S5.T3.16.8.1.1.m1.1.1.3.cmml">10</mn><mn id="S5.T3.16.8.1.1.m1.1.1.2.3" xref="S5.T3.16.8.1.1.m1.1.1.2.3.cmml">1</mn><mrow id="S5.T3.16.8.1.1.m1.1.1c" xref="S5.T3.16.8.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.16.8.1.1.m1.1b"><apply id="S5.T3.16.8.1.1.m1.1.1.cmml" xref="S5.T3.16.8.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.16.8.1.1.m1.1.1.1.cmml" xref="S5.T3.16.8.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.16.8.1.1.m1.1.1.2.cmml" xref="S5.T3.16.8.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.16.8.1.1.m1.1.1.2.1.cmml" xref="S5.T3.16.8.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.16.8.1.1.m1.1.1.2.2.cmml" xref="S5.T3.16.8.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.16.8.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.16.8.1.1.m1.1.1.2.3">1</cn></apply><cn id="S5.T3.16.8.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.16.8.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.16.8.1.1.m1.1c">{}_{1}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.16.8.1.1.m1.1d">start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.16.8.2>19.45</td><td class="ltx_td ltx_align_center" id=S5.T3.16.8.3>164.80</td></tr><tr class=ltx_tr id=S5.T3.17.9><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.17.9.1><span class="ltx_text ltx_font_bold" id=S5.T3.17.9.1.1>N<math alttext="{}_{2}^{10}" class="ltx_Math" display="inline" id="S5.T3.17.9.1.1.m1.1"><semantics id="S5.T3.17.9.1.1.m1.1a"><mmultiscripts id="S5.T3.17.9.1.1.m1.1.1" xref="S5.T3.17.9.1.1.m1.1.1.cmml"><mi id="S5.T3.17.9.1.1.m1.1.1.2.2" xref="S5.T3.17.9.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.17.9.1.1.m1.1.1a" xref="S5.T3.17.9.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.17.9.1.1.m1.1.1b" xref="S5.T3.17.9.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.17.9.1.1.m1.1.1.3" xref="S5.T3.17.9.1.1.m1.1.1.3.cmml">10</mn><mn id="S5.T3.17.9.1.1.m1.1.1.2.3" xref="S5.T3.17.9.1.1.m1.1.1.2.3.cmml">2</mn><mrow id="S5.T3.17.9.1.1.m1.1.1c" xref="S5.T3.17.9.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.17.9.1.1.m1.1b"><apply id="S5.T3.17.9.1.1.m1.1.1.cmml" xref="S5.T3.17.9.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.17.9.1.1.m1.1.1.1.cmml" xref="S5.T3.17.9.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.17.9.1.1.m1.1.1.2.cmml" xref="S5.T3.17.9.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.17.9.1.1.m1.1.1.2.1.cmml" xref="S5.T3.17.9.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.17.9.1.1.m1.1.1.2.2.cmml" xref="S5.T3.17.9.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.17.9.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.17.9.1.1.m1.1.1.2.3">2</cn></apply><cn id="S5.T3.17.9.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.17.9.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.17.9.1.1.m1.1c">{}_{2}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.17.9.1.1.m1.1d">start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.17.9.2>38.43</td><td class="ltx_td ltx_align_center" id=S5.T3.17.9.3>330.82</td></tr><tr class=ltx_tr id=S5.T3.18.10><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.18.10.1><span class="ltx_text ltx_font_bold" id=S5.T3.18.10.1.1>N<math alttext="{}_{3}^{10}" class="ltx_Math" display="inline" id="S5.T3.18.10.1.1.m1.1"><semantics id="S5.T3.18.10.1.1.m1.1a"><mmultiscripts id="S5.T3.18.10.1.1.m1.1.1" xref="S5.T3.18.10.1.1.m1.1.1.cmml"><mi id="S5.T3.18.10.1.1.m1.1.1.2.2" xref="S5.T3.18.10.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.18.10.1.1.m1.1.1a" xref="S5.T3.18.10.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.18.10.1.1.m1.1.1b" xref="S5.T3.18.10.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.18.10.1.1.m1.1.1.3" xref="S5.T3.18.10.1.1.m1.1.1.3.cmml">10</mn><mn id="S5.T3.18.10.1.1.m1.1.1.2.3" xref="S5.T3.18.10.1.1.m1.1.1.2.3.cmml">3</mn><mrow id="S5.T3.18.10.1.1.m1.1.1c" xref="S5.T3.18.10.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.18.10.1.1.m1.1b"><apply id="S5.T3.18.10.1.1.m1.1.1.cmml" xref="S5.T3.18.10.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.18.10.1.1.m1.1.1.1.cmml" xref="S5.T3.18.10.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.18.10.1.1.m1.1.1.2.cmml" xref="S5.T3.18.10.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.18.10.1.1.m1.1.1.2.1.cmml" xref="S5.T3.18.10.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.18.10.1.1.m1.1.1.2.2.cmml" xref="S5.T3.18.10.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.18.10.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.18.10.1.1.m1.1.1.2.3">3</cn></apply><cn id="S5.T3.18.10.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.18.10.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.18.10.1.1.m1.1c">{}_{3}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.18.10.1.1.m1.1d">start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.18.10.2>57.24</td><td class="ltx_td ltx_align_center" id=S5.T3.18.10.3>496.16</td></tr><tr class=ltx_tr id=S5.T3.19.11><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=S5.T3.19.11.1><span class="ltx_text ltx_font_bold" id=S5.T3.19.11.1.1>N<math alttext="{}_{4}^{10}" class="ltx_Math" display="inline" id="S5.T3.19.11.1.1.m1.1"><semantics id="S5.T3.19.11.1.1.m1.1a"><mmultiscripts id="S5.T3.19.11.1.1.m1.1.1" xref="S5.T3.19.11.1.1.m1.1.1.cmml"><mi id="S5.T3.19.11.1.1.m1.1.1.2.2" xref="S5.T3.19.11.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.19.11.1.1.m1.1.1a" xref="S5.T3.19.11.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.19.11.1.1.m1.1.1b" xref="S5.T3.19.11.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.19.11.1.1.m1.1.1.3" xref="S5.T3.19.11.1.1.m1.1.1.3.cmml">10</mn><mn id="S5.T3.19.11.1.1.m1.1.1.2.3" xref="S5.T3.19.11.1.1.m1.1.1.2.3.cmml">4</mn><mrow id="S5.T3.19.11.1.1.m1.1.1c" xref="S5.T3.19.11.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.19.11.1.1.m1.1b"><apply id="S5.T3.19.11.1.1.m1.1.1.cmml" xref="S5.T3.19.11.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.19.11.1.1.m1.1.1.1.cmml" xref="S5.T3.19.11.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.19.11.1.1.m1.1.1.2.cmml" xref="S5.T3.19.11.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.19.11.1.1.m1.1.1.2.1.cmml" xref="S5.T3.19.11.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.19.11.1.1.m1.1.1.2.2.cmml" xref="S5.T3.19.11.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.19.11.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.19.11.1.1.m1.1.1.2.3">4</cn></apply><cn id="S5.T3.19.11.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.19.11.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.19.11.1.1.m1.1c">{}_{4}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.19.11.1.1.m1.1d">start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center" id=S5.T3.19.11.2>77.02</td><td class="ltx_td ltx_align_center" id=S5.T3.19.11.3>661.60</td></tr><tr class=ltx_tr id=S5.T3.20.12><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id=S5.T3.20.12.1><span class="ltx_text ltx_font_bold" id=S5.T3.20.12.1.1>N<math alttext="{}_{5}^{10}" class="ltx_Math" display="inline" id="S5.T3.20.12.1.1.m1.1"><semantics id="S5.T3.20.12.1.1.m1.1a"><mmultiscripts id="S5.T3.20.12.1.1.m1.1.1" xref="S5.T3.20.12.1.1.m1.1.1.cmml"><mi id="S5.T3.20.12.1.1.m1.1.1.2.2" xref="S5.T3.20.12.1.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.20.12.1.1.m1.1.1a" xref="S5.T3.20.12.1.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.20.12.1.1.m1.1.1b" xref="S5.T3.20.12.1.1.m1.1.1.cmml"></mrow><mn id="S5.T3.20.12.1.1.m1.1.1.3" xref="S5.T3.20.12.1.1.m1.1.1.3.cmml">10</mn><mn id="S5.T3.20.12.1.1.m1.1.1.2.3" xref="S5.T3.20.12.1.1.m1.1.1.2.3.cmml">5</mn><mrow id="S5.T3.20.12.1.1.m1.1.1c" xref="S5.T3.20.12.1.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.20.12.1.1.m1.1b"><apply id="S5.T3.20.12.1.1.m1.1.1.cmml" xref="S5.T3.20.12.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.20.12.1.1.m1.1.1.1.cmml" xref="S5.T3.20.12.1.1.m1.1.1">superscript</csymbol><apply id="S5.T3.20.12.1.1.m1.1.1.2.cmml" xref="S5.T3.20.12.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.20.12.1.1.m1.1.1.2.1.cmml" xref="S5.T3.20.12.1.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.20.12.1.1.m1.1.1.2.2.cmml" xref="S5.T3.20.12.1.1.m1.1.1.2.2">absent</csymbol><cn id="S5.T3.20.12.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T3.20.12.1.1.m1.1.1.2.3">5</cn></apply><cn id="S5.T3.20.12.1.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.20.12.1.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.20.12.1.1.m1.1c">{}_{5}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.20.12.1.1.m1.1d">start_FLOATSUBSCRIPT 5 end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math></span></th><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.20.12.2>95.54</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.20.12.3>824.46</td></tr></tbody></table></table></figure><blockquote><p>üîº Table III presents the statistical measures for various noise domains generated using Gaussian mixture distributions. Specifically, it shows the norms (magnitude) of the mean vectors (ùùÅc) and covariance matrices (ùö∫c) for each category (c) within each noise domain. The table helps in understanding the variability and distribution characteristics of the different noise datasets used in the experiments.</p><details><summary>read the caption</summary>TABLE III: The statistics of norms of the means and covariances for the noise domains, where Cùê∂Citalic_C denotes the total number of categories in each noise domain, and ùùÅcsubscriptùùÅùëê\bm{\mu}_{c}bold_italic_Œº start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT, ùö∫csubscriptùö∫ùëê\bm{\Sigma}_{c}bold_Œ£ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT represent the mean and covariance of category cùëêcitalic_c in each noise domain, respectively.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-59c197edf72f2c467693160d626f1f33 class=gallery><img src=https://ai-paper-reviewer.com/2502.13573/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.13573/16.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/&amp;title=Noise%20May%20Contain%20Transferable%20Knowledge:%20Understanding%20Semi-supervised%20Heterogeneous%20Domain%20Adaptation%20from%20an%20Empirical%20Perspective" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/&amp;text=Noise%20May%20Contain%20Transferable%20Knowledge:%20Understanding%20Semi-supervised%20Heterogeneous%20Domain%20Adaptation%20from%20an%20Empirical%20Perspective" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13573/&amp;subject=Noise%20May%20Contain%20Transferable%20Knowledge:%20Understanding%20Semi-supervised%20Heterogeneous%20Domain%20Adaptation%20from%20an%20Empirical%20Perspective" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2502.13573/index.md",oid_likes="likes_paper-reviews/2502.13573/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2502.13622/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-19T00:00:00+00:00>19 February 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2502.13685/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">MoM: Linear Sequence Modeling with Mixture-of-Memories</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-19T00:00:00+00:00>19 February 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>