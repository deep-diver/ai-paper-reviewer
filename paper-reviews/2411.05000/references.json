{"references": [{"fullname_first_author": "S\u00e9bastien Bubeck", "paper_title": "Sparks of artificial general intelligence: Early experiments with gpt-4", "publication_date": "2023-03-12", "reason": "This paper is a foundational work evaluating GPT-4's capabilities, providing a benchmark for subsequent long-context research."}, {"fullname_first_author": "Nelson F Liu", "paper_title": "Lost in the middle: How language models use long contexts", "publication_date": "2024-00-00", "reason": "This paper significantly impacts the understanding of how LLMs use context, particularly regarding the positional influence of relevant information, shaping subsequent benchmarks."}, {"fullname_first_author": "Machel Reid", "paper_title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context", "publication_date": "2024-03-05", "reason": "The introduction of Gemini 1.5, with its extended context window, significantly advances the capabilities of LLMs and drives the research on long-context models."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This paper presents LLaMA 3, a powerful open-source LLM, providing a valuable resource for the long-context research community."}, {"fullname_first_author": "Rishabh Agarwal", "paper_title": "Many-shot in-context learning", "publication_date": "2024-04-11", "reason": "This work significantly influences the understanding of in-context learning, which is fundamental to the evaluation of long-context capabilities in LLMs."}]}