[{"figure_path": "https://arxiv.org/html/2411.05000/x1.png", "caption": "Figure 1: Contextualising context lengths of LLMs and classic literature111Using the LLaMA-3.1 tokenizer (Dubey et\u00a0al., 2024).. Books sourced from Project Gutenberg (2024).", "description": "This figure compares the context window sizes of various large language models (LLMs) with the token counts of several classic books.  The token counts are calculated using the LLaMA-3.1 tokenizer. The figure visually represents the relative capabilities of current LLMs to process information contained within works of literature, highlighting that many contemporary LLMs can now handle entire novels within their context window.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2411.05000/x2.png", "caption": "Figure 2: Schematics for our long-context key-value retrieval tasks. See \u00a73 for descriptions.", "description": "This figure provides a visual representation of the four key-value retrieval tasks used in the paper.  Each task is illustrated using a schematic diagram showing the arrangement of keys and values within a haystack (a long sequence of data). The tasks vary in complexity, ranging from a simple single-needle retrieval (finding a single value corresponding to a given key) to more complex scenarios involving multiple needles (retrieving values for multiple keys simultaneously), conditional needles (retrieving values based on a specific condition), and threading (following a chain of linked keys and values). The diagrams clearly show the differences in the structures and processes of each task, making it easier to understand the experimental design.", "section": "3 TASKS"}, {"figure_path": "https://arxiv.org/html/2411.05000/x3.png", "caption": "Figure 3: Tokenization. LLMs tokenize UUIDs at significantly different granularities.", "description": "Different large language models (LLMs) process the same text differently.  This figure demonstrates that the tokenization of  Universally Unique Identifiers (UUIDs) varies greatly between LLMs.  UUIDs are frequently used in testing LLMs because they provide a consistent, easily measurable unit of text. The differences in tokenization highlight the need to be cautious when comparing context lengths reported in tokens across different models, as the actual amount of processed textual information might differ significantly.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2411.05000/x10.png", "caption": "Figure 4: Single Needle overall performance with 95% Wilson confidence intervals.", "description": "This figure displays the overall performance of 17 different Large Language Models (LLMs) on a single-needle retrieval task.  The x-axis represents the context length (in thousands of LLaMA 3.1 tokens), and the y-axis shows the accuracy of the models in retrieving the correct value associated with a single key within that context.  The plot includes 95% Wilson confidence intervals to show the uncertainty in the accuracy measurements. The results demonstrate how accuracy varies across different models and how it changes as the context length increases.", "section": "4.1 Single Needle"}, {"figure_path": "https://arxiv.org/html/2411.05000/x11.png", "caption": "Figure 5: Single Needle heatmaps. For most models, the effective context length is less than the context limit. At longer contexts, retrieval precision decreases towards the middle of the context.", "description": "This figure visualizes the performance of different large language models (LLMs) on a single-needle retrieval task across varying context lengths.  Each heatmap represents a model's accuracy in retrieving a specific value (the 'needle') from a large text (the 'haystack'). The heatmaps show that the effective context length, i.e., the length of text within which the model can reliably find the needle, is considerably shorter than the maximum context window supported by the model.  Furthermore, at longer contexts, the accuracy of retrieval decreases significantly in the middle of the haystack, while better accuracy is observed towards the beginning and end. This suggests that the position of the 'needle' relative to the context start or end significantly impacts the accuracy.", "section": "4.1 Single Needle"}, {"figure_path": "https://arxiv.org/html/2411.05000/x15.png", "caption": "Figure 6: Overall accuracy for Multiple Needles (left) and Conditional Needles (right). Shaded regions show 95% confidence intervals.", "description": "This figure displays the overall accuracy of various LLMs (Large Language Models) on two tasks: Multiple Needles and Conditional Needles.  The left panel shows the accuracy for the Multiple Needles task, where the goal was to retrieve the values associated with multiple randomly selected keys from a large JSON dataset. The right panel presents the results for the Conditional Needles task, where the goal is to find values associated with keys containing a specific character.  The performance of each LLM is shown across different context lengths. The shaded regions represent 95% confidence intervals, indicating the uncertainty associated with the accuracy measurements.", "section": "4.2 Multiple Needles and 4.3 Conditional Needles"}, {"figure_path": "https://arxiv.org/html/2411.05000/x16.png", "caption": "Figure 7: Multiple Needles heatmaps. Context length has a substantially greater effect on performance than needle placement positions or the number of needles.", "description": "This figure displays heatmaps illustrating the performance of different LLMs on a \"Multiple Needles\" task, which involves retrieving multiple values from a haystack of key-value pairs.  Each heatmap represents a single model's performance across various context lengths (x-axis) and numbers of needles (y-axis).  The color intensity reflects the accuracy of the retrieval task. The results reveal that context length has a significantly greater effect on performance than the number of needles or their placement within the context window.  Stronger models exhibit more consistent performance across different numbers of needles, but all models show decreased accuracy as context length increases.", "section": "4.2 Multiple Needles"}, {"figure_path": "https://arxiv.org/html/2411.05000/x19.png", "caption": "Figure 8: Conditional Needles heatmaps. Needles prove easier to retrieve when clustered.", "description": "This figure displays heatmaps visualizing the performance of different LLMs on a conditional needle retrieval task.  The task involves retrieving values associated with keys that contain a specific character.  The heatmaps show accuracy as a function of context length and the number of needles. Different color shades represent different accuracy levels. The results show a clear trend: when the needles (keys with the specific character) are clustered together within the haystack, the models achieve higher accuracy compared to scenarios with randomly placed needles. This indicates that the proximity or clustering of relevant information in the context improves the models' ability to retrieve the correct values.", "section": "4.3 Conditional Needles"}]