[{"figure_path": "https://arxiv.org/html/2411.14951/x1.png", "caption": "Figure 1: Examples of physical inconsistencies in generations.", "description": "The figure showcases examples of common physical inaccuracies generated by existing human motion generation models.  These inconsistencies include instances of ground penetration, where body parts appear to intersect with the ground; unnatural backward leaning; body parts intersecting with each other (interpenetration); foot sliding, where feet do not maintain proper contact with the ground; characters appearing to float above the ground; and unnatural rotations of body parts.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.14951/x2.png", "caption": "Figure 2: An overview of the Morph framework. Morph comprises a Motion Generator and a Motion Physics Refinement module. Morph employs a two-stage training process: Motion Physics Refinement module training and Motion Generator fine-tuning. And a Imitation Selection Operation is employed to ensure the motion quality after physics refinement.", "description": "The Morph framework consists of two main modules: a Motion Generator (MG) and a Motion Physics Refinement (MPR) module.  The framework uses a two-stage training process. Stage one trains the MPR module using synthetic noisy motion data generated by the MG. The MPR module projects noisy motions into a physically plausible space using a motion imitator within a physics simulator, enforcing physical constraints and learning from feedback from a motion discriminator. Stage two uses the physically refined motions from the MPR module to fine-tune the MG, enhancing its ability to generate physically plausible motions. Finally, an Imitation Selection Operation filters out non-grounded motions.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.14951/x3.png", "caption": "Table 2: Comparison results for text-to-motion task on HumanML3D dataset. Morph is combined with different types of motion generators. MG: Motion Generator; MPR: Motion Physics Refinement module; FT: fine-tuning motion generator with the physics-refined motion data. \u2020\u2020\\dagger\u2020 denotes Morph without fine-tuning the motion generator (only Stage 1 training)", "description": "This table presents a comparison of different models' performance on the text-to-motion task using the HumanML3D dataset.  The models are categorized by their underlying motion generation techniques (e.g., diffusion-based, autoregressive) and whether they incorporate Morph, a physics-based optimization framework.  Metrics include standard generation quality scores (RTOP-1, RTOP-3, FID, Diversity) as well as physical plausibility measures (PFC, Penetration, Float, Skate, IFR).  The table shows how adding Morph improves physical accuracy without significantly sacrificing overall generation quality.  Results are shown both with and without the fine-tuning stage (FT) of Morph, highlighting the impact of this enhancement.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2411.14951/x4.png", "caption": "Table 3: Comparison results on common generation metrics for text-to-motion on HumanML3D dataset.", "description": "This table presents a quantitative comparison of various text-to-motion generation models on the HumanML3D dataset.  The models are evaluated using several common metrics assessing the quality and diversity of the generated motions. These metrics include RTOP-1, RTOP-2, RTOP-3 (retrieval top-k accuracy), FID (Fr\u00e9chet Inception Distance, measuring the difference between generated and real motion distributions), MM-Dist (multimodal distance, a measure of the spread of generated motions), Diversity (diversity of generated motions), and MModality (multimodality score, capturing the diversity of motion styles). The table allows for a direct comparison of the performance of different models in generating human motions from textual descriptions.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2411.14951/x5.png", "caption": "Figure 3: Qualitative comparison between our Morph-MoMask and MoMask in text-to-motion task. Morph-MoMask significantly reduces physical artifacts such as leaning forward, floating and penetration.", "description": "Figure 3 presents a qualitative comparison of human motion generation results between two models: Morph-MoMask and MoMask, for the text-to-motion task.  The figure showcases several motion examples, each initiated by a textual description.  For each example, the motion generated by both models is displayed.  The comparison highlights how Morph-MoMask significantly mitigates common physical artifacts found in generated motions, such as characters floating above the ground, parts of the body penetrating the ground, and unnatural leaning postures, which are present in the MoMask output. This visualization serves to illustrate the effectiveness of the proposed Morph framework in enhancing physical plausibility during motion generation.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2411.14951/x6.png", "caption": "Figure 4: A flowchart illustrating the data preprocessing process. The parameters are calculated from the first frame and then applied to all generated motion sequences before they are fed into the MPR module.", "description": "This flowchart details the preprocessing steps applied to generated motion sequences before they are input to the Motion Physics Refinement (MPR) module.  The process begins by analyzing the first frame of each sequence to compute the body's tilt angle and the lowest point of the mesh.  Based on these parameters, adjustments are made to correct for postural issues (like leaning) and ground penetration or floating. These corrections ensure that the motions are physically plausible before being used by the MPR module. The final step is to apply the calculated parameters to all frames of the given sequence.", "section": "3. Method"}]