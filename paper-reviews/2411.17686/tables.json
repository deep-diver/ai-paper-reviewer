[{"content": "| Method | Original | Deconstructed | \u0394 |\n|---|---|---|---| \n|  |  | **SQA** |  |\n| ToMe [3] | 65.43 | 65.42 | 0.01 |\n| EViT [21] | 65.21 | 65.18 | 0.03 |\n| FastV [5] | 66.98 | 66.99 | -0.01 |\n|  |  | **TextVQA** |  |\n| ToMe [3] | 52.14 | 52.14 | 0.00 |\n| EViT [21] | 51.72 | 51.74 | -0.02 |\n| FastV [5] | 52.83 | 52.82 | 0.01 |", "caption": "Table 1: Performance discrepancy of original and deconstructed methods on SQA and TextVQA benchmarks.", "description": "This table presents a comparison of the performance of three original training-free token reduction methods (ToMe, EVIT, FastV) against their deconstructed counterparts, which are re-implemented according to the proposed \"filter-correlate-compress\" paradigm. The performance is evaluated on two benchmarks: SQA and TextVQA.  The \"\u0394\" column shows the difference in performance between the original and deconstructed versions of each method, demonstrating the equivalence of the methods when expressed within the unified paradigm.", "section": "2.3.4 Empirical Equivalency of Paradigm"}, {"content": "| Stage | Method | SQA | TextVQA |\n|---|---|---|---|\n| **Stage** | **Method** | **SQA** | **TextVQA** |\n| _FiCoCo-V_ | _FiCoCo-V_ | 68.37 | 55.46 |\n| Filter | w/o local redundancy | 67.81 | 52.51 |\n|  | w/o task redundancy | 64.67 | 48.74 |\n|  | w/o local penalty | 68.12 | 53.24 |\n| Compress | fixed K=0 | 67.82 | 53.56 |\n|  | fixed K=1 | 67.43 | 46.97 |\n|  | fixed K=2 | 67.21 | 51.36 |\n|  | average compression | 67.92 | 53.34 |", "caption": "Table 2: Ablation results of FiCoCo-V.", "description": "This table presents an ablation study on the FiCoCo-V model, showing the impact of different components on the model's performance.  It breaks down the results by examining the effects of removing the local redundancy calculation, task redundancy calculation, the local penalty strategy, and different fixed values for the hyperparameter K.  This allows for a detailed analysis of each component's contribution to the overall accuracy and efficiency of FiCoCo-V on the SQA and TextVQA benchmarks.", "section": "3. Methodology: FiCoCo"}, {"content": "Method | Training-free | TFLOPs\u2193 | SQA | VQA<sup>T</sup> | POPE | Vizwiz | MM-Vet | MMBCN | GQA | LLAVA-W | MMB | VQAv2\n---|---|---|---|---|---|---|---|---|---|---|---|---\nLLaVA-1.5 [24] | \u2713 | 8.5 | 69.5 | 58.2 | 86.4 | 50.0 | 31.6 | 59.3 | 62.5 | 63.7 | 66.1 | 79.1\n*TFLOPs=4.2* |  |  |  |  |  |  |  |  |  |  |  | \nFitPrune [38] | \u2713 | 4.4 | 67.8 | 58.2 | 86.5 | 50.4 | 32.8 | 58.4 | 61.5 | - | 64.6 | 78.3\n**FiCoCo-V** | \u2713 | 4.2 | 67.9 | 55.9 | 84.3 | 51.1 | 30.2 | 55.9 | 58.6 | 58.8 | 62.7 | 76.6\n**FiCoCo-L** | \u2713 | 4.2 | 69.2 | 57.4 | 84.7 | 49.1 | 30.3 | 53.9 | 61.2 | 61.9 | 65.0 | 77.4\n**FiCoCo-VL** | \u2713 | 4.2 | 68.1 | 55.7 | 84.7 | 50.2 | 29.7 | 56.5 | 58.7 | 58.4 | 62.5 | 76.8\n*TFLOPs=3.3* |  |  |  |  |  |  |  |  |  |  |  | \nSparseVLM [44] | \u2713 | 3.3 | 69.1 | 56.1 | 83.6 | - | - | - | 57.6 | - | 62.5 | 75.6\nFastV [5] | \u2713 | 3.3 | 67.3 | 52.5 | 64.8 | - | - | - | 52.7 | - | 61.2 | 67.1\nToMe [3] | \u2713 | 3.3 | 65.2 | 52.1 | 72.4 | - | - | - | 54.3 | - | 60.5 | 68.0\n**FiCoCo-V** | \u2713 | 3.3 | 67.8 | 55.7 | 82.5 | 51.5 | 29.7 | 55.3 | 58.5 | 60.4 | 62.3 | 74.4\n**FiCoCo-L** | \u2713 | 3.3 | 69.6 | 56.6 | 84.6 | 48.7 | 31.4 | 53.6 | 61.1 | 60.3 | 64.6 | 76.8\n**FiCoCo-VL** | \u2713 | 3.3 | 68.3 | 55.1 | 84.7 | 50.5 | 28.4 | 56.2 | 58.7 | 55.7 | 63.7 | 74.8\n*TFLOPs=2.4* |  |  |  |  |  |  |  |  |  |  |  | \nTRIM [33] | \u2717 | 2.4 | 69.1 | 53.7 | 85.3 | 48.1 | 28.0 | 54.9 | 61.4 | 58.7 | 67.4 | 76.4\nSparseVLM [44] | \u2713 | 2.5 | 67.1 | 54.9 | 80.5 | - | - | - | 56.0 | - | 60.0 | 73.8\nFastV [5] | \u2713 | 2.5 | 60.2 | 50.6 | 59.6 | - | - | - | 49.6 | - | 56.1 | 61.8\nToMe [3] | \u2713 | 2.5 | 59.6 | 49.1 | 62.8 | - | - | - | 52.4 | - | 53.3 | 63.0\n**FiCoCo-V** | \u2713 | 2.4 | 68.3 | 55.6 | 82.2 | 49.4 | 28.2 | 54.3 | 57.6 | 56.6 | 61.1 | 73.1\n**FiCoCo-L** | \u2713 | 2.4 | 69.4 | 56.3 | 84.4 | 48.4 | 30.1 | 53.5 | 60.6 | 59.4 | 64.4 | 76.4\n**FiCoCo-VL** | \u2713 | 2.4 | 68.2 | 54.9 | 79.5 | 48.9 | 28.1 | 55.5 | 57.7 | 57.6 | 61.9 | 73.9\n*TFLOPs=1.5* |  |  |  |  |  |  |  |  |  |  |  | \nHoneybee [4] | \u2717 | 1.6 | 67.8 | 50.9 | 84.0 | 47.2 | 27.1 | 55.2 | 59.0 | 59.4 | 57.8 | 74.8\nLLaMA-VID [20] | \u2717 | 1.6 | 67.9 | 51.4 | 83.1 | 46.8 | 29.7 | 55.4 | 59.2 | 58.9 | 57.0 | 74.3\nQwen-VL [2] | \u2717 | 1.6 | 68.1 | 54.4 | 83.4 | 47.3 | 27.2 | 55.0 | 58.9 | 59.2 | 57.4 | 74.9\nIVTP [14] | \u2717 | 1.6 | 67.8 | 58.2 | 85.7 | 47.9 | 30.5 | 57.4 | 60.4 | 62.8 | 66.1 | 77.8\nPyramidDrop [37] | \u2717 | 1.8 | - | - | 86.0 | - | - | 58.5 | - | - | 66.1 | -\nSparseVLM [44] | \u2713 | 1.5 | 62.2 | 51.8 | 75.1 | - | - | - | 52.4 | - | 56.2 | 68.2\nRandom Sampling [14] | \u2713 | 1.6 | 67.2 | 48.5 | 82.5 | 37.9 | 23.6 | 48.0 | 57.1 | 55.8 | 55.4 | 69.0\nTopK [14] | \u2713 | 1.6 | 66.9 | 52.4 | 83.8 | 47.0 | 26.5 | 55.2 | 58.1 | 59.2 | 55.2 | 72.4\nSpatial Pooling [14] | \u2713 | 1.6 | 67.7 | 52.5 | 82.3 | 46.5 | 28.3 | 53.3 | 59.6 | 59.7 | 56.6 | 73.9\nEViT [21] | \u2713 | 1.6 | 67.7 | 54.7 | 82.8 | 47.0 | 27.3 | 55.7 | 59.4 | 60.0 | 57.8 | 74.1\nFastV [5] | \u2713 | 1.6 | 51.1 | 47.8 | 48.0 | - | - | - | 46.1 | - | 48.0 | 61.8\nToMe [3] | \u2713 | 1.6 | 50.0 | 45.3 | 52.5 | - | - | - | 48.6 | - | 43.7 | 57.1\nLLaVA-PruMerge [31] | \u2713 | 1.5 | 67.9 | 53.3 | 76.3 | - | - | - | - | - | 56.8 | 65.9\nRecoverable Compression [6] | \u2713 | 1.5 | 69.0 | 55.3 | 72.0 | - | - | - | - | - | 57.9 | 70.4\n**FiCoCo-V** | \u2713 | 1.5 | 68.4 | 55.5 | 79.8 | 52.4 | 26.8 | 53.0 | 57.4 | 58.6 | 60.2 | 74.8\n**FiCoCo-L** | \u2713 | 1.5 | 69.5 | 55.7 | 84.1 | 48.2 | 27.4 | 53.3 | 60.0 | 57.3 | 64.0 | 75.6\n**FiCoCo-VL** | \u2713 | 1.5 | 68.1 | 54.7 | 79.3 | 49.7 | 29.6 | 54.4 | 57.4 | 56.6 | 60.2 | 75.3", "caption": "Table 3: Comparison results on MLLMs with a 7B LLM. For baselines, we reference results reported in other papers, which may exhibit slight discrepancies from the experimental results presented earlier. Our methods are primarily compared with training-free approaches.", "description": "This table presents a comparison of the performance of various methods for accelerating multimodal large language models (MLLMs), specifically focusing on models with 7 billion parameters.  It shows the results across ten different benchmark datasets, comparing the performance (accuracy) and computational cost (TFLOPs) of different approaches. The baselines include several existing methods from the literature, while the authors' methods (FiCoCo-V, FiCoCo-L, and FiCoCo-VL) are also included.  Note that because the baselines come from different publications, there might be small variations in reported performance numbers due to differences in experimental setups.  The table primarily compares the authors' methods with other training-free techniques, meaning methods that do not require retraining the model to achieve speed improvements.", "section": "4. Experiments"}, {"content": "| Stage | Method | SQA | TextVQA |\n|---|---|---|---| \n| **Stage** | **Method** | **SQA** | **TextVQA** |\n| FiCoCo-L | **_FiCoCo-L_** | **69.46** | **55.72** |\n| Filter | w/o local redundancy | 69.16 | 55.43 |\n|  | w/o task redundancy | 68.22 | 55.64 |\n|  | w/ local penalty | 68.79 | 55.38 |\n| Correlate | w/o indirect correlation | 68.89 | 54.78 |\n|  | w/o direct correlation | 68.45 | 55.45 |\n| Compress | fixed K=0 | 68.96 | 50.33 |\n|  | fixed K=1 | 68.57 | 50.11 |\n|  | fixed K=2 | 68.32 | 50.18 |\n|  | average compression | 68.32 | 54.66 |", "caption": "Table 4: Ablation results of FiCoCo-L.", "description": "This table presents the ablation study results for the FiCoCo-L model, demonstrating the impact of removing different components on the model's performance. It analyzes the contribution of each of the three stages (Filter, Correlate, and Compress) and various design choices within those stages on two benchmark datasets, SQA and TextVQA.  The results show the effect of removing or modifying elements such as local and task redundancy in the Filter stage, direct and indirect correlation in the Correlate stage, and different compression strategies (e.g., fixed K-values versus adaptive K) in the Compress stage. The table aims to provide a detailed understanding of the individual components' contribution to the overall model performance.", "section": "2.3 One Paradigm Unifies Current Methods"}, {"content": "| Method | Training-free | TFLOPs\u2193 | SQA | VQA<sup>T</sup> | POPE | VizWiz | MM-Vet | MMBCN | GQA | LLAVA-W | MMB | VQAv2 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| LLaVA-1.5 [24] | \u2713 | 28.6 | 71.4 | 61.3 | 86.2 | 54.1 | 36.1 | 63.2 | 63.4 | 70.1 | 68.0 | 80.0 |\n| *TFlops=15.4* |  |  |  |  |  |  |  |  |  |  |  |  |\n| TRIM [33] | \u2717 | 16.4 | 72.8 | 54.8 | 86.3 | 53.2 | 30.3 | 58.3 | 59.0 | 57.0 | 69.2 | 75.4 |\n| Honeybee [4] | \u2717 | 15.4 | 70.5 | 59.7 | 83.5 | 46.6 | 24.6 | 54.8 | 59.2 | 58.8 | 60.3 | 74.8 |\n| LLaMA-VID [20] | \u2717 | 15.4 | 70.4 | 57.2 | 83.3 | 50.8 | 26.5 | 58.0 | 61.7 | 62.8 | 60.5 | 76.5 |\n| Qwen-VL [2] | \u2717 | 15.4 | 70.8 | 56.4 | 84.0 | 51.1 | 27.4 | 54.9 | 61.2 | 64.2 | 61.7 | 77.3 |\n| IVTP [14] | \u2717 | 15.4 | 70.1 | 60.0 | 85.4 | 53.4 | 28.6 | 55.4 | 62.3 | 64.6 | 66.7 | 78.4 |\n| Random Sampling [14] | \u2713 | 15.4 | 68.0 | 51.5 | 83.3 | 52.9 | 32.7 | 55.4 | 56.7 | 66.0 | 58.0 | 72.3 |\n| TopK [14] | \u2713 | 15.4 | 68.9 | 54.2 | 84.5 | 53.1 | 30.1 | 56.1 | 59.2 | 65.3 | 58.3 | 74.8 |\n| Spatial Pooling [14] | \u2713 | 15.4 | 69.5 | 55.0 | 84.8 | 54.1 | 33.5 | 57.3 | 59.7 | 68.8 | 60.2 | 75.1 |\n| EViT [21] | \u2713 | 15.4 | 70.1 | 57.9 | 84.6 | 50.0 | 24.4 | 52.4 | 60.2 | 45.5 | 61.0 | 77.2 |\n| ToMe [3] | \u2713 | 15.4 | 70.1 | 57.1 | 85.3 | - | - | - | 61.4 | - | 61.2 | 76.9 |\n| **FiCoCo-V** | \u2713 | 15.4 | 72.1 | 57.2 | 82.3 | 53.0 | 32.6 | 60.7 | 59.2 | 62.3 | 63.1 | 76.8 |\n| **FiCoCo-L** | \u2713 | 15.4 | 72.4 | 58.3 | 83.1 | 53.9 | 34.2 | 61.1 | 60.1 | 67.9 | 65.2 | 77.6 |\n| **FiCoCo-VL** | \u2713 | 15.4 | 72.0 | 57.2 | 82.1 | 53.2 | 33.1 | 60.3 | 59.4 | 65.9 | 64.6 | 77.3 |", "caption": "Table 5: Comparison results on MLLMs with a 13B LLM. For baselines, we reference results reported in other papers. Our methods are primarily compared with training-free approaches.", "description": "Table 5 presents a detailed comparison of various methods' performance on multimodal large language models (MLLMs) using a 13B parameter LLM.  It showcases the accuracy achieved by different techniques across ten widely-used benchmark datasets.  The table highlights the trade-off between computational efficiency (measured in TeraFLOPs) and accuracy.  A key aspect of the table is its focus on comparing training-free methods against existing methods. This is crucial because training-free methods offer a more practical and accessible approach for accelerating the inference of these large models. The results allow for direct comparison between the proposed FiCoCo methods and existing state-of-the-art techniques, demonstrating the effectiveness of the proposed approaches.", "section": "4. Experiments"}, {"content": "|   | FiCoCo-V                     | FiCoCo-L                     |\n|---|---|---| \n| \u03b5 | SQA | TextVQA | SQA | TextVQA |\n|---|---|---|---|---|\n| 0.998 | 68.37 | **55.46** | 69.46 | **55.72** |\n| 0.996 | 68.33 | 53.15  | **69.51** | 55.62 |\n| 0.994 | 68.21 | 52.05  | 69.32 | 55.42 |\n| 0.992 | **68.47** | 52.29  | 69.36 | 55.14 |", "caption": "Table 6: \nHyperparameter sensitivity analysis of \u03b5\ud835\udf00\\varepsilonitalic_\u03b5 on TextVQA and SQA benchmarks.", "description": "This table presents the results of an ablation study evaluating the impact of the hyperparameter  \u03b5 (epsilon) on the performance of the FiCoCo model.  Epsilon controls the threshold for determining which tokens are considered correlated during the compression stage. The table shows how varying epsilon affects the accuracy on two benchmarks: TextVQA and SQA, indicating the optimal setting for epsilon that balances efficiency and accuracy.", "section": "4.2 Ablation Study"}, {"content": "| scaling coefficient | FiCoCo-V | SQA | TextVQA |\n|---|---|---|---|\n| **in local penalty strategy** | _FiCoCo-V_ | **SQA** | **TextVQA** |\n| 1 | 68.12 | 53.24 |\n| 2 | **68.37** | 55.46 |\n| 3 | 68.21 | 55.04 |\n| 4 | 68.11 | **55.49** |", "caption": "Table 7: \nHyperparameter sensitivity analysis of scaling coefficient in local penalty strategy on TextVQA and SQA benchmarks.", "description": "This table presents the results of an ablation study investigating the impact of the scaling coefficient hyperparameter used in the local penalty strategy within the FiCoCo-V method.  The study evaluates performance on two benchmarks: TextVQA and SQA.  Different scaling coefficient values are tested to determine their effect on model accuracy. The goal is to identify the optimal balance between preventing spatial-centralized information loss and achieving efficient performance.", "section": "4.2 Ablation Study"}, {"content": "| Method | LLM Backbone | Quantization | TFLOPs\u2193 | Total Memory (GB)\u2193 | KV-Cache (MB)\u2193 |\n|---|---|---|---|---|---| \n| LLaVA-1.5 | Vicuna-7B | FP16 | 8.5 | 22.4 | 333 |\n| FiCoCo-V | Vicuna-7B | FP16 | 1.5 (\u219382%) | 14.4 (\u219336%) | 65.0 (\u219380%) |\n| FiCoCo-L | Vicuna-7B | FP16 | 1.5 (\u219382%) | 14.3 (\u219336%) | 64.2 (\u219381%) |\n| FiCoCo-VL | Vicuna-7B | FP16 | 1.5 (\u219382%) | 13.0 (\u219342%) | 60.8 (\u219382%) |\n| LLaVA-1.5 | Vicuna-7B | INT8 | 4.3 | 11.2 | 167 |\n| FiCoCo-V | Vicuna-7B | INT8 | 0.8 (\u219381%) | 7.8 (\u219330%) | 32.5 (\u219381%) |\n| FiCoCo-L | Vicuna-7B | INT8 | 0.8 (\u219381%) | 7.2 (\u219336%) | 32.1 (\u219381%) |\n| FiCoCo-VL | Vicuna-7B | INT8 | 0.7 (\u219384%) | 6.5 (\u219342%) | 30.4 (\u219382%) |\n| LLaVA-1.5 | Vicuna-7B | INT4 | 2.1 | 6.2 | 83.4 |\n| FiCoCo-V | Vicuna-7B | INT4 | 0.4 (\u219381%) | 4.4 (\u219329%) | 16.3 (\u219381%) |\n| FiCoCo-L | Vicuna-7B | INT4 | 0.4 (\u219381%) | 3.3 (\u219347%) | 16.1 (\u219381%) |\n| FiCoCo-VL | Vicuna-7B | INT4 | 0.4 (\u219381%) | 3.3 (\u219347%) | 15.2 (\u219382%) |", "caption": "Table 8: Efficiency analysis of methods based on LLaVA-1.5-7B.", "description": "This table presents a detailed efficiency analysis of various methods for accelerating inference in Multimodal Large Language Models (MLLMs), specifically using the LLaVA-1.5-7B model.  It compares the original LLaVA-1.5 model with three variants of the FiCoCo method (FiCoCo-V, FiCoCo-L, FiCoCo-VL) under different quantization levels (FP16, INT8, INT4). The metrics presented include total inference time (TFLOPs), total memory usage (GB), and KV-Cache usage (MB).  This allows for a comprehensive comparison of the efficiency gains achieved by FiCoCo in reducing computational cost and memory requirements while maintaining performance.", "section": "4. Experiments"}, {"content": "| Method | LLM Backbone | Quantization | TFLOPs\u2193 | Total Memory (GB)\u2193 | KV-Cache (MB)\u2193 |\n|---|---|---|---|---|---| \n| LLaVA-1.5 | Vicuna-13B | FP16 | 28.6 | 56.1 | 891 |\n| FiCoCo-V | Vicuna-13B | FP16 | 15.4 (\u219346%) | 38.6 (\u219331%) | 488 (\u219343%) |\n| FiCoCo-L | Vicuna-13B | FP16 | 15.4 (\u219346%) | 38.4 (\u219332%) | 485 (\u219346%) |\n| FiCoCo-VL | Vicuna-13B | FP16 | 15.4 (\u219346%) | 38.3 (\u219332%) | 482 (\u219346%) |\n| LLaVA-1.5 | Vicuna-13B | INT8 | 14.3 | 28 | 446 |\n| FiCoCo-V | Vicuna-13B | INT8 | 7.7 (\u219346%) | 19.3 (\u219331%) | 244 (\u219345%) |\n| FiCoCo-L | Vicuna-13B | INT8 | 7.7 (\u219346%) | 19.2 (\u219331%) | 242 (\u219346%) |\n| FiCoCo-VL | Vicuna-13B | INT8 | 7.6 (\u219347%) | 19.2 (\u219331%) | 241 (\u219346%) |\n| LLaVA-1.5 | Vicuna-13B | INT4 | 7.6 | 14 | 223 |\n| FiCoCo-V | Vicuna-13B | INT4 | 3.9 (\u219346%) | 9.6 (\u219332%) | 122 (\u219349%) |\n| FiCoCo-L | Vicuna-13B | INT4 | 3.9 (\u219349%) | 9.5 (\u219332%) | 121 (\u219346%) |\n| FiCoCo-VL | Vicuna-13B | INT4 | 3.8 (\u219350%) | 9.5 (\u219332%) | 120 (\u219346%) |", "caption": "Table 9: Efficiency analysis of methods based on LLaVA-1.5-13B.", "description": "This table presents a comprehensive efficiency analysis of various methods, including the proposed FiCoCo variants, using the LLaVA-1.5-13B model as the base. It compares the performance of these methods across different quantization levels (FP16, INT8, INT4), showing the trade-offs between computational cost (TFLOPs), total memory usage, and KV-cache size.  The results highlight the efficiency gains achieved by FiCoCo in reducing computational cost and memory footprint while maintaining comparable accuracy.", "section": "4. Experiments"}, {"content": "| Method | TFLOPs\u2193 | FlashAttn | SQA Acc | SQA Time\u2193 |  | MMB Acc | MMB Time\u2193 |\n|---|---|---|---|---|---|---|---|\n| Open-LLaVA-NeXT-7B | 20.8 | \u2713 | 69.06 | 12m01s |  | 66.07 | 22m47s |\n| *FiCoCo-V* | 9.5 (\u219354.3%) | \u2713 | 68.86 | 8m35s (\u219328.6%) |  | 65.03 | 14m39s (\u219335.7%) |\n| Open-LLaVA-NeXT-7B | 20.8 | \u2717 | 69.01 | 17m34s |  | 66.07 | 34m02s |\n| *FiCoCo-L* | 9.5 (\u219354.3%) | \u2717 | 68.21 | 13m23s (\u219323.8%) |  | 64.67 | 25m13s (\u219325.9%) |\n| *FiCoCo-VL* | 9.5 (\u219354.3%) | \u2717 | 69.26 | 11m06s (\u219336.8%) |  | 65.30 | 21m45s (\u219336.1%) |", "caption": "Table 10: Comparisons based on Open-LLaVA-NeXT-7B.\nWe categorize the methods based on the availability of FlashAttention and provide FLOPs and time measurements to demonstrate that our methods can effectively accelerate across different scenarios.", "description": "This table presents a comparison of performance metrics for different models on the Open-LLaVA-NeXT-7B benchmark. The models are categorized based on whether they utilize FlashAttention, a technique for accelerating inference.  The key performance indicators (KPIs) presented include FLOPs (floating-point operations), inference time, and accuracy on two specific benchmarks (SQA and MMB).  The purpose of the table is to demonstrate that the proposed FiCoCo methods effectively improve efficiency across various scenarios, even when using or not using FlashAttention.", "section": "4. Experiments"}]