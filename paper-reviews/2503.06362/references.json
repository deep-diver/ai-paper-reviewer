{"references": [{"fullname_first_author": "Triantafyllos Afouras", "paper_title": "Deep audio-visual speech recognition", "publication_date": "2018-12-01", "reason": "This paper presents a deep learning approach to audio-visual speech recognition, which is a fundamental technique in the field."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "publication_date": "2021-06-01", "reason": "This paper introduces Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning technique used extensively in the current paper for adapting the LLM."}, {"fullname_first_author": "Aditya Kusupati", "paper_title": "Matryoshka Representation Learning", "publication_date": "2022-01-01", "reason": "This paper introduces the concept of Matryoshka Representation Learning, which is the core idea behind the proposed Llama-MTSK model."}, {"fullname_first_author": "Pingchuan Ma", "paper_title": "Auto-avsr: Audio-visual speech recognition with automatic labels", "publication_date": "2023-01-01", "reason": "This paper presents a method of audio-visual speech recognition using automatically generated labels and is a comparison point for results in this paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "publication_date": "2023-01-01", "reason": "This paper introduces the Whisper model, which is used as the pre-trained audio encoder in the current paper."}]}