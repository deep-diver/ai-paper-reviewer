[{"figure_path": "2410.13841/charts/charts_5_0.png", "caption": "Figure 1: The performance of LLaMA3-8B-Instruct on the GSM8K, TruthfulQA, and HumanEval datasets under varying p and k.", "description": "The chart displays the performance of LLaMA3-8B-Instruct on three datasets (GSM8K, TruthfulQA, and HumanEval) across different drop rates (p) and adjustment factors (k).", "section": "4.2 EXTENSION OF DARE"}, {"figure_path": "2410.13841/charts/charts_6_0.png", "caption": "Figure 2: The performance of ViT-B-32 on the DTD, EuroSAT, and GTSRB datasets under varying p and k.", "description": "The chart displays the performance of ViT-B-32 on three datasets (DTD, EuroSAT, and GTSRB) across different drop rates (p) and adjustment factors (k) for delta parameter editing.", "section": "4.2 EXTENSION OF DARE"}, {"figure_path": "2410.13841/charts/charts_7_0.png", "caption": "Figure 3: Validation of our theoretical derivation of DARE, BitDelta, Twin-Merge(sparsity rate=0.9), and Ties-Merge.", "description": "The box plot visualizes the performance comparison of DARE, BitDelta, Twin-Merging, and TIES-Merging across different drop rates.", "section": "5 UNIFYING EDITING OPERATIONS WITH DECREASED PERFORMANCE"}, {"figure_path": "2410.13841/charts/charts_9_0.png", "caption": "Figure 4: Effectiveness of increasing the number of bits in BitDelta. The left subplot shows the performance of LLaMA3-8B-Instruct and Mistral-7B-Instruct-v0.3 on the GSM8K dataset as the number of bits increases. The right subplot shows the performance on the TruthfulQA dataset. In each subplot, we use the dashed line to represent the performance of the original post-trained model.", "description": "The chart displays the effectiveness of increasing the number of bits in the BitDelta model on the GSM8K and TruthfulQA datasets, comparing performance against the original post-trained model.", "section": "5 UNIFYING EDITING OPERATIONS WITH DECREASED PERFORMANCE"}, {"figure_path": "2410.13841/charts/charts_9_1.png", "caption": "Figure 12: Validation of the extension of BitDelta on LLaMA3-8B-Instruct.", "description": "The chart displays the performance of the extended BitDelta model on three different datasets (GSM8K, TruthfulQA, and HumanEval) as the multiple of the original average magnitude changes.", "section": "B.2 EXTENSION OF BITDELTA"}, {"figure_path": "2410.13841/charts/charts_10_0.png", "caption": "Figure 3: Validation of our theoretical derivation of DARE, BitDelta, Twin-Merge(sparsity rate=0.9), and Ties-Merge.", "description": "The box plot shows the comparison of the approximation term calculated by DARE, BitDelta, Twin-Merging, and TIES-Merging on the GSM8K dataset.", "section": "5 UNIFYING EDITING OPERATIONS WITH DECREASED PERFORMANCE"}, {"figure_path": "2410.13841/charts/charts_10_1.png", "caption": "Figure 7: Comparison of Extrapolation and Interpolation Performance.", "description": "The chart compares the performance difference between interpolation and extrapolation methods on various datasets for LLaMA3-8B-Instruct, showing that interpolation generally outperforms extrapolation except for the IFEval dataset.", "section": "6.2 FUTHER DISCUSSIONS ON EXPO"}, {"figure_path": "2410.13841/charts/charts_17_0.png", "caption": "Figure 13: Comparison of Extrapolation and Interpolation Performance.", "description": "The chart compares the performance gap between interpolation and extrapolation methods on various tasks for two different models.", "section": "B.3 DISCUSSION ON EXPO"}]