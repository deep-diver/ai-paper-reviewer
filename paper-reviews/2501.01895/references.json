{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper is foundational as it details the capabilities of GPT-4, a large language model whose capabilities are referenced in the context of multimodal alignment for robotic tasks."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets", "publication_date": "2023-11-15", "reason": "This paper is highly relevant due to its focus on video generation through diffusion models, a core technique used in the proposed EnerVerse framework for embodied future space generation."}, {"fullname_first_author": "Cheng Chi", "paper_title": "Diffusion Policy: Visuomotor Policy Learning via Action Diffusion", "publication_date": "2024-00-00", "reason": "This is a crucial reference as it introduces the concept of diffusion policies, which the authors adapt and integrate into their system for robotic action prediction and planning."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "DynamicCrafter: Animating Open-Domain Images with Video Diffusion Priors", "publication_date": "2025-00-00", "reason": "This is a key reference because it presents a model for video generation that the authors build upon; they use it as their base model for image-to-video tasks."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Video diffusion models", "publication_date": "2022-00-00", "reason": "This paper is important due to its contribution to the field of video diffusion models, a technique that is leveraged in the proposed EnerVerse architecture for generating realistic and coherent future video sequences for robotic tasks."}]}