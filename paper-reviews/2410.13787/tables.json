[{"figure_path": "2410.13787/tables/table_1_0.html", "caption": "Figure 1: Left: Each LLM predicts its own behavior better than a second model can. The green bars represent each model's accuracy in predicting its own hypothetical responses across unseen datasets after finetuning on facts about itself. The blue bars show how well a second model, finetuned on the same facts about the first model, can predict the first model. The results imply that models have privileged access to information about themselves (introspection). Error bars show 95% confidence intervals calculated from the standard error of the mean. Right: Our task for testing self-prediction. A model is asked to predict properties of its behavior on a hypothetical prompt. This self-prediction is evaluated against the model's ground-truth behavior (object-level) on the prompt. The figure shows a single example from one task, but results (Left) average over many examples and many tasks (Figure 3).", "description": "The table shows that each LLM predicts its own behavior better than a second model can, providing evidence for introspection.", "section": "Experiments"}, {"figure_path": "2410.13787/tables/table_4_0.html", "caption": "Figure 2: Summary of two main experiments for introspection.", "description": "The table summarizes the two main experiments used in the paper to test for introspection in LLMs, outlining the setup and evidence for each.", "section": "2.1 EXPERIMENTS RELATED TO INTROSPECTION"}, {"figure_path": "2410.13787/tables/table_5_0.html", "caption": "Figure 3: Across a set of tasks (e.g., MMLU), we show hypothetical questions asking for a behavior property (e.g., second character) with the corresponding object-level prompt. We use \u201c{\u2026}\u201d to indicate the object-level prompt above. See Section A.1.3 for the full set of behavior properties.", "description": "The table presents examples of hypothetical questions asking for behavior properties and corresponding object-level prompts to elicit those properties from LLMs.", "section": "2 OVERVIEW OF METHODS"}, {"figure_path": "2410.13787/tables/table_38_0.html", "caption": "Table 1: GPT-40 Models with Overall Scores", "description": "The table presents the overall scores achieved by different GPT-40 models (untrained, baseline finetuned, and self-prediction finetuned) on the Situational Awareness Dataset (SAD).", "section": "A.4.2 SAD DATASET"}, {"figure_path": "2410.13787/tables/table_39_0.html", "caption": "Table 2: GPT-40 Models Performance on SAD Predict Tokens Task", "description": "The table presents the performance of various GPT-40 models on the Predict Tokens task from the Situational Awareness Dataset.", "section": "A.4.2 SAD DATASET"}, {"figure_path": "2410.13787/tables/table_43_0.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The figure shows the self-prediction accuracy of multiple models on a set of representative behavior properties. Before (purple) and after training (green). We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "The table presents the self-prediction accuracy of multiple language models (LLMs) on various behavior prediction tasks, both before and after self-prediction training, demonstrating the improvement achieved after training.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_43_1.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The figure shows self-prediction accuracy of multiple models on a set of representative behavior properties. The purple bars indicate accuracy before training, and the green bars indicate accuracy after training. We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "This table presents the self-prediction accuracy of multiple models (GPT-40, Llama 70B, GPT-3.5) before and after training, showing improvement on several behavior properties.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_43_2.html", "caption": "Figure 11: The rate of compliant responses on the object-level (top) and for hypothetical questions (bottom) is shown. Models do not refuse and correctly follow most requests, except for untrained models being asked hypothetical questions.", "description": "The table shows the rate of compliant responses for both object-level and hypothetical questions across various models, highlighting the differences in compliance between trained and untrained models.", "section": "A.1 SELF-PREDICTION TRAINING DETAILS"}, {"figure_path": "2410.13787/tables/table_44_0.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The self-prediction accuracy of multiple models on a set of representative behavior properties is shown before (purple) and after training (green). We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "The table shows the self-prediction accuracy of multiple language models on various behavior properties before and after self-prediction training, demonstrating generalization to held-out datasets.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_44_1.html", "caption": "Figure 14: The self-/cross-prediction results are shown for a selection of behavior properties.", "description": "The table presents the self-prediction and cross-prediction accuracy for several behavior properties across different models.", "section": "3.2 Cross-Prediction Results"}, {"figure_path": "2410.13787/tables/table_44_2.html", "caption": "Figure 14: The self-/cross-prediction results are shown for a selection of behavior properties.", "description": "The table presents a breakdown of self-prediction and cross-prediction accuracy across various behavior properties, highlighting the consistent advantage of self-prediction.", "section": "3.2 Cross-Prediction Results"}, {"figure_path": "2410.13787/tables/table_44_3.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The self-prediction accuracy of multiple models on a set of representative behavior properties is shown before (purple) and after training (green). We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "The table displays the self-prediction accuracy of multiple LLMs on various behavioral properties before and after self-prediction training, showing the improvement achieved after the training.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_45_0.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The self-prediction accuracy of multiple models on a set of representative behavior properties is shown before (purple) and after training (green). We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "This table shows the self-prediction accuracy of multiple models on various response properties before and after self-prediction training, demonstrating generalization to held-out datasets.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_45_1.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The figure shows self-prediction accuracy of multiple models on a set of representative behavior properties before (purple) and after training (green). We show generalization to held-out datasets - for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "The table displays the self-prediction accuracy of different models (GPT-40, Llama 70B, and GPT-3.5) before and after training on various response properties (first word, third word, second character, if even, starts with vowel, ethical stance, among options) and an average of these properties across multiple datasets.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}, {"figure_path": "2410.13787/tables/table_45_2.html", "caption": "Figure 39: Example conversation for the \u201cAre you sure bias detection\u201d response property. Unlike most of response properties, it involves two turns.", "description": "This table provides an example conversation demonstrating the \"Are you sure bias detection\" response property, which involves a two-turn exchange.", "section": "A.5 EXAMPLE PROMPTS AND ANSWERS OF RESPONSE PROPERTIES"}, {"figure_path": "2410.13787/tables/table_46_0.html", "caption": "Figure 10: Self-prediction training effect across multiple models and response properties. The self-prediction accuracy of multiple models on a set of representative behavior properties is shown before (purple) and after training (green). We show generalization to held-out datasets \u2013 for example, we train models to predict their ethical stance for preferring wealth and test on datasets regarding myopic preferences.", "description": "The table displays the self-prediction accuracy of multiple models (GPT-40, Llama 70B, and GPT-3.5) before and after training on predicting different properties of their own responses, demonstrating improvement after training.", "section": "3.1 MODELS CAN BE TRAINED TO SELF-PREDICT"}]