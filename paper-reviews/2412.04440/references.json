{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-MM-DD", "reason": "This paper introduces denoising diffusion probabilistic models, a fundamental technique used in many modern text-to-video generation models, including those discussed in the provided research paper."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-14", "reason": "This paper details advancements in latent video diffusion models, which are directly relevant to the techniques used in the research paper for generating high-quality videos."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "Maskgit: Masked generative image transformer", "publication_date": "2022-MM-DD", "reason": "This work introduces MaskGIT, a masked generative image transformer, which is a foundational model that enables various capabilities utilized in the text-to-video generation method described."}, {"fullname_first_author": "Kaiyi Huang", "paper_title": "T2I-CompBench: A comprehensive benchmark for open-world compositional text-to-image generation", "publication_date": "2024-MM-DD", "reason": "This benchmark paper is crucial for evaluating the compositional capabilities of text-to-image models, which is directly relevant to the assessment and comparison of methods discussed in the current paper."}, {"fullname_first_author": "Kaiyue Sun", "paper_title": "T2V-CompBench: Compositional Evaluation for Text-to-Video Generation", "publication_date": "2024-MM-DD", "reason": "This paper provides a benchmark specifically designed for evaluating compositional aspects in text-to-video generation, which are central to the methodology and results of the research."}]}