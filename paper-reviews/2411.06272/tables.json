[{"content": "| Benchmarks | Sent. Anal. | Classif. | Ent. Extr. | Rel. Extr. | Multi. Choice | Summ. | Quest. Ans. | Stock Pred. |\n|---|---|---|---|---|---|---|---|---|\n| FinGPT-Bench [2023a] | \u2713 | \u2713 | \u2713 | \u2713 |  |  |  |  |\n| FinBen [2024] | \u2713 | \u2713 | \u2713 | \u2713 |  | \u2713 | \u2713 | \u2713 |\n| BBT-Fin [2023a] | \u2713 | \u2713 | \u2713 | \u2713 |  | \u2713 | \u2713 |  |\n| Fin-Eval [2023] |  |  |  |  | \u2713 |  |  |  |\n| FinanceIQ [2023] |  |  |  |  | \u2713 |  |  |  |\n| CFBenchmark [2023] | \u2713 | \u2713 | \u2713 |  |  | \u2713 | \u2713 |  |\n| Golden-Touchstone | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |", "caption": "Table 1: Diversity of Financial Analysis Tasks Across Different Financial Large Language Model Benchmarks", "description": "This table compares the features of various publicly available financial large language model (FinLLM) benchmarks.  It shows which benchmarks include tasks focused on sentiment analysis, classification, entity extraction, relation extraction, multiple-choice questions, summarization, question answering, and stock price prediction.  The table also indicates whether each benchmark supports English or Chinese language, helping to illustrate the range of capabilities present in existing FinLLM evaluation resources.", "section": "3. Benchmark Design"}, {"content": "| Benchmarks | Language | Language | Systematicity | Adaptability | Model Training | Model Training | \n|---|---|---|---|---|---|---|\n|  | EN | CN |  |  | Cont. Pre-train | Instr. Tuning | \n| FinGPT-Bench (Wang et al., 2023a) | \u2713 |  | Medium | High |  | \u2713 | \n| FinBen (Xie et al., 2024) | \u2713 |  | High | Medium |  | \u2713 | \n| BBT-Fin (Lu et al., 2023a) |  | \u2713 | Medium | High |  | \u2713 | \n| Fin-Eval (Zhang et al., 2023) |  | \u2713 | High | High |  |  | \n| FinanceIQ (Zhang and Yang, 2023) |  | \u2713 | Medium | High | \u2713 | \u2713 | \n| CFBenchmark (Lei et al., 2023) |  | \u2713 | High | High | \u2713 | \u2713 | \n| Golden-Touchstone | \u2713 | \u2713 | High | High | \u2713 | \u2713 |", "caption": "Table 2: Language Coverage, Systematicity, Adaptability, and Model Training Stage for Benchmarks. Systematicity refers to whether benchmarks are established according to a comprehensive system standard. Adaptability indicates whether the tasks are suitable for large language models.", "description": "This table compares various financial benchmarks based on four key aspects: language coverage (English and/or Chinese), systematicity (whether the benchmark follows a well-defined standard), adaptability to large language models (LLMs), and the model training stage (whether continuous pre-training or instruction tuning is involved).  Systematicity refers to the presence of a structured and comprehensive framework for creating the benchmark, while adaptability highlights whether the tasks included are appropriate for evaluating LLMs. This detailed comparison helps assess the strengths and limitations of existing financial benchmarks for LLMs.", "section": "3. Benchmark Design"}, {"content": "| Task | Dataset | Train | Valid | Test | Metrics |\n|---|---|---|---|---|---| \n| **Sentiment Analysis** | **FPB** | 3100 | 776 | 970 | Weighted-F1, ACC |\n|  | **FiQA-SA** | 750 | 188 | 235 | Weighted-F1, ACC |\n| **Classification** | **Headlines** | 71900 | 10300 | 20500 | Weighted-F1, ACC |\n|  | **FOMC** | 1984 | - | 496 | Weighted-F1, ACC |\n|  | **lendingclub** | 9417 | 1345 | 2691 | Weighted-F1, MCC |\n| **Entity Recognition** | **NER** | 408 | 103 | 98 | Entity-F1 |\n| **Relation Extraction** | **FinRE** | 27558 | - | 5112 | Relation-F1 |\n| **Multiple Choice** | **CFA** | 1884 | 100 | 20 | Weighted-F1, ACC |\n| **Summarization** | **EDTSUM** | 8000 | - | 2000 | ROUGE, BLEU |\n| **Question Answering** | **FinQa** | 6251 | 883 | 1147 | RMACC |\n|  | **ConvfinQa** | 8890 | 2210 | 1490 | RMACC |\n| **Stock Movement Prediction** | **DJIA** | 1591 | - | 398 | Weighted-F1, ACC |", "caption": "Table 3: Overview of English Finance Evaluation Datasets by Task Type, Sample Sizes (Training, Validation, Test), and Evaluation Metrics", "description": "This table details the English financial datasets used in the Golden Touchstone benchmark.  For each of the eight tasks (Sentiment Analysis, Classification, Entity Recognition, Relation Extraction, Multiple Choice, Summarization, Question Answering, and Stock Movement Prediction), it lists the specific dataset used, the number of samples in the training, validation, and test sets, and the evaluation metrics employed (e.g., Weighted-F1, Accuracy, ROUGE). This provides a comprehensive overview of the data used for evaluating financial LLMs in the English language portion of the benchmark.", "section": "3. Benchmark Design"}, {"content": "| Task | Dataset | Train | Valid | Test | Metrics |\n|---|---|---|---|---|---| \n| **Sentiment Analysis** | **FinFE-CN** | 16157 | 2020 | 2020 | Weighted-F1<br>ACC |\n| **Classification** | **FinNL-CN** | 7071 | 884 | 884 | ORMACC |\n| **Entity Extraction** | **FinESE-CN** | 14252 | 1781 | 1782 | ORMACC |\n| **Relation Extraction** | **FinRE-CN** | 13486 | 1489 | 3727 | RMACC |\n| **Multiple Choice** | **FinEval** | 1071 | 170 | 3340 | Weighted-F1<br>ACC |\n|  | **CPA** | 6268 | 1444 | 6 | Weighted-F1<br>ACC |\n| **Summarization** | **FinNA-CN** | 28800 | 3600 | 3600 | ROUGE<br>BLEU |\n| **Question Answering** | **FinQa-CN** | 19906 | 2469 | 2480 | RMACC |\n|  | **FincQa-CN** | 21965 | 2741 | 2745 | RMACC |\n| **Stock Movement Prediction** | **AStock** | 11815 | 1477 | 1477 | Weighted-F1<br>ACC |", "caption": "Table 4: Overview of Chinese Finance Evaluation Datasets by Task Type, Sample Sizes (Training, Validation, Test), and Evaluation Metrics", "description": "This table presents a detailed breakdown of the Chinese financial evaluation datasets used in the Golden Touchstone benchmark.  It lists each dataset by its associated task type (e.g., sentiment analysis, classification), provides the sample sizes for training, validation, and testing sets, and specifies the evaluation metrics employed for each task (e.g., weighted F1 score, accuracy, ORMACC).  This information is crucial for understanding the scale and characteristics of the data used to evaluate the performance of financial large language models (FinLLMs) in the benchmark.", "section": "3. Benchmark Design"}, {"content": "| Task | Dataset | Metrics | GPT-4o | FinMA-7B | Qwen-2-7B | Llama-3-8B | FinGPT-8B | Touchstone | \n|---|---|---|---|---|---|---|---|---|---|\n| Sentiment Analysis | FPB | Weighted-F1 | 0.8084 | **0.9400** | 0.7965 | 0.7631 | 0.2727 | 0.8576 | \n|  |  | ACC | 0.8093 | **0.9402** | 0.8000 | 0.7660 | 0.3072 | 0.8557 | \n|  | Fiqa-SA | Weighted-F1 | 0.8106 | 0.8370 | 0.6726 | 0.7515 | 0.5885 | **0.8591** | \n|  |  | ACC | 0.7702 | 0.8340 | 0.5957 | 0.7064 | 0.5872 | **0.8638** | \n| Classification | Headlines | Weighted-F1 | 0.7857 | 0.9739 | 0.7278 | 0.7006 | 0.4516 | **0.9866** | \n|  |  | ACC | 0.7931 | 0.9739 | 0.7252 | 0.7004 | 0.4331 | **0.9866** | \n|  | FOMC | Weighted-F1 | 0.6603 | 0.3988 | 0.6112 | 0.4904 | 0.2758 | **0.8788** | \n|  |  | ACC | 0.6794 | 0.4274 | 0.6210 | 0.5625 | 0.2702 | **0.8790** | \n|  | lendingclub | Weighted-F1 | 0.6730 | 0.1477 | 0.5938 | 0.5943 | 0.5480 | **0.9783** | \n|  |  | MCC | 0.1642 | -0.6218 | 0.1714 | 0.1670 | -0.1120 | **0.9297** | \n| Entity Extraction | NER | Entity-F1 | 0.1800 | 0.6200 | 0.2875 | 0.2973 | 0.0231 | **0.6993** | \n| Relation Extraction | FinRE | Relation-F1 | 0.1613 | 0.0054 | 0.1083 | 0.0540 | 0.0100 | **0.5331** | \n| Multiple Choice | CFA | Weighted-F1 | **0.7700** | 0.2200 | 0.6697 | 0.5800 | 0.3993 | 0.7497 | \n|  |  | ACC | **0.7700** | 0.2400 | 0.6700 | 0.5800 | 0.3800 | 0.7500 | \n| Summarization | EDTSUM | Rouge-1 | 0.1675 | 0.1566 | 0.1466 | 0.1467 | 0.0622 | **0.5254** | \n|  |  | Rouge-2 | 0.0556 | 0.0491 | 0.0433 | 0.0429 | 0.0085 | **0.3446** | \n|  |  | Rouge-L | 0.1069 | 0.1060 | 0.0857 | 0.0930 | 0.0412 | **0.4705** | \n|  |  | BLEU | 0.1192 | 0.1361 | 0.0999 | 0.1085 | 0.0592 | **0.4512** | \n| Question Answering | Finqa | RMACC | 0.1037 | 0.0497 | 0.0270 | 0.0470 | 0.0110 | **0.2258** | \n|  | Convfinqa | RMACC | 0.2540 | 0.0953 | 0.0644 | 0.1477 | 0.0772 | **0.5053** | \n| Stock Movement Prediction | DJIA | Weighted-F1 | 0.4241 | 0.3211 | 0.2744 | **0.5116** | 0.2171 | 0.4396 | \n|  |  | ACC | 0.4648 | 0.3291 | 0.4372 | **0.5101** | 0.2211 | 0.4749 | ", "caption": "Table 5: Performance metrics of financial large language models across english tasks like Sentiment Analysis, Classification, and Summarization. Models include GPT-4o, Llama-3-8B, Qwen-2-7B, FinMA-7B, FinGPT-8B, and Touchstone-GPT. The best results of each dataset are marked in bold.", "description": "Table 5 presents a comprehensive comparison of various large language models' performance on several English financial NLP tasks.  The tasks assessed include Sentiment Analysis, Classification, Entity Recognition, Relation Extraction, Multiple Choice Question Answering, Summarization, and Stock Movement Prediction.  Six prominent models are compared: GPT-40, Llama-3-8B, Qwen-2-7B, FinMA-7B, FinGPT-8B, and Touchstone-GPT.  The table details the performance metrics (such as Weighted-F1, Accuracy, BLEU, ROUGE) for each model on each task and dataset. The best-performing model for each dataset is highlighted in bold, allowing for easy identification of relative strengths and weaknesses.", "section": "4.2. Evaluation Results"}, {"content": "| Task | Dataset | Metrics | GPT-4o | Qwen-2-7B\nInstruct | Llama-3-8B\nInstruct | CFGPT1-7B\nFull | DISC-FinLLM\nFull | Touchstone\nGPT | | Sentiment\nAnalysis | FinFe-CN | Weighted-F1 | 0.6593 | 0.6274 | 0.3633 | 0.2528 | 0.4177 | **0.7888** | | ACC | 0.6500 | 0.6436 | 0.4891 | 0.2732 | 0.4292 | **0.7936** | | Classification | FinNL-CN | ORMACC | 0.3303 | 0.0622 | 0.0747 | 0.0894 | 0.0011 | **0.8360** | | Entity\nExtraction | FinESE-CN | ORMACC | 0.6867 | 0.3678 | 0.3088 | 0.3863 | 0.4346 | **0.9074** | | Relation\nExtraction | FinRE-CN | RMACC | 0.2754 | 0.1330 | 0.1296 | 0.0678 | 0.1182 | **0.6541** | | Multiple\nChoice | FinEval | Weighted-F1 | **0.7364** | 0.7230 | 0.4432 | 0.3543 | 0.4288 | 0.7361 | | ACC | **0.7353** | 0.7235 | 0.4471 | 0.3529 | 0.4294 | **0.7353** | | CPA | FinEval | Weighted-F1 | 0.6312 | 0.6957 | 0.3421 | 0.3543 | 0.3451 | **0.9238** | | ACC | 0.6309 | 0.6960 | 0.3504 | 0.3553 | 0.3518 | **0.9238** | | Summarization | FinNA-CN | Rouge-1 | 0.3197 | 0.3326 | 0.3477 | 0.1018 | 0.3486 | **0.5526** | | Rouge-2 | 0.1434 | 0.1597 | 0.1702 | 0.0263 | 0.1678 | **0.3603** | | Rouge-L | 0.2511 | 0.2644 | 0.2802 | 0.0650 | 0.2997 | **0.5214** | | BLEU | 0.1423 | 0.1541 | 0.1672 | 0.0238 | 0.1885 | **0.3944** | | Question\nAnswering | FinQa-CN | RMACC | 0.6578 | 0.5043 | 0.4540 | 0.1126 | 0.3949 | **0.9214** | | FinCQa-CN | RMACC | 0.4765 | 0.3422 | 0.3787 | 0.2714 | 0.2134 | **0.8552** | | Stock Movement\nPrediction | AStock | Weighted-F1 | **0.5007** | 0.4906 | 0.4903 | 0.4631 | 0.4142 | 0.4003 | | ACC | 0.5017 | 0.4915 | 0.4956 | 0.4888 | 0.4144 | **0.5587** |", "caption": "Table 6: Performance metrics of financial large language models across chinese tasks like Sentiment Analysis, Classification, and Summarization. Models include GPT-4o, Llama-3-8B, Qwen-2-7B, CFGPT-7B, DISC-FinLLM, and Touchstone-GPT. The best results of each dataset are marked in bold.", "description": "Table 6 presents a comprehensive evaluation of six different large language models (LLMs) on various Chinese financial tasks.  These tasks include sentiment analysis, classification, entity extraction, relation extraction, multiple-choice question answering, summarization, and stock movement prediction.  The models assessed are GPT-40, Llama-3-8B, Qwen-2-7B, CFGPT-7B, DISC-FinLLM, and Touchstone-GPT.  The table displays performance metrics for each model on each task, with the best result for each dataset highlighted in bold. This allows for a direct comparison of the strengths and weaknesses of different LLMs in the context of Chinese financial language processing.", "section": "4.2.2. Results of Chinese Benchmark"}, {"content": "| Task Type | Language | Instruction | Input | Output |\n|---|---|---|---|---|\n| Sentiment Analysis | English | What is the sentiment of the following financial post: Positive, Negative, or Neutral? | RT @tomhend777 $MU needs to hold here -Broken for now. Needs big flush. Still not technically oversold so now big bounce yet | neutral |\n|  | Chinese | \u4ee5\u4e0b\u662f\u80a1\u6c11\u8bba\u575b\u4e2d\u7684\u4e00\u5219\u80a1\u6c11\u8bc4\u8bba,\u5176\u4e2d\u5305\u542b\u6709\u611f\u6027\u7684\u60c5\u611f\u8f93\u51fa\u548c\u7406\u6027\u7684\u6da8\u8dcc\u9884\u6d4b\u7b49\u5185\u5bb9\u2026\u2026 | \u5224\u65ad\u7684\u975e\u5e38\u51c6\u786e\uff0c\u51e0\u6b21T\u7684\u76f8\u5f53\u7a33\u59a5\uff01 | 1 |\n| Classification | English | Review the sentence from a central bank\u2019s communiqu\u00e9\u2026\u2026 | In their discussion of prices, participants indicated that data over the intermeeting period\u2026\u2026 | neutral |\n|  | Chinese | \u628a\u63a5\u4e0b\u6765\u8f93\u5165\u7684\u91d1\u878d\u65b0\u95fb\u5206\u7c7b\u4e3a\u4e00\u4e2a\u6216\u591a\u4e2a\u4e0e\u5176\u63cf\u8ff0\u5185\u5bb9\u76f8\u5173\u7684\u7c7b\u522b\u2026\u2026 | \u52a0\u62ff\u5927\u7687\u5bb6\u94f6\u884c\uff1a\u5c06Affirm Holdings(AFRM.O)\u76ee\u6807\u4ef7\u4ece175\u7f8e\u5143\u4e0b\u8c03\u81f3127\u7f8e\u5143\u3002 | \u5916\u56fd \u516c\u53f8 |\n| Entity Recognition | English | In the sentences extracted from financial agreements in U.S. SEC filings\u2026\u2026 | There is a default in any agreement to which Borrower or any Guarantor is a party with a third party or parties\u2026\u2026 | Borrower, PER |\n|  | Chinese | \u7ed9\u5b9a\u4e00\u6bb5\u6587\u672cT,\u548c\u6587\u672c\u6240\u5c5e\u7684\u4e8b\u4ef6\u7c7b\u578bS,\u4ece\u6587\u672cT\u4e2d\u62bd\u53d6\u6307\u5b9a\u4e8b\u4ef6\u7c7b\u578bS\u7684\u4e8b\u4ef6\u4e3b\u4f53\u2026\u2026 | \u6587\u672c: \u5929\u9f99\u65b0\u6750\u5173\u8054\u62c5\u4fdd\u4e8b\u9879\u672a\u53ca\u65f6\u62ab\u9732\u88ab\u76d1\u7ba1\u4f73\u58eb\u79d1\u6280(300193)\u80a1\u4e1c\u51cf\u6301900\u4e07\u80a1 \u5957\u73b0\u8fd12\u4ebf \u4e8b\u4ef6\u7c7b\u578b: \u4fe1\u6279\u8fdd\u89c4 | \u5929\u9f99\u65b0\u6750 |\n| Relation Extraction | English | What is the relationship between Ivan Glasenberg and Glencore in the context of the input sentence\u2026\u2026 | The persistent oversupply is \"damaging the credibility of the industry,\" Glencore CEO Ivan Glasenberg said in May. | owner_of |\n|  | Chinese | \u7ed9\u5b9a\u53e5\u5b50\u548c\u5176\u4e2d\u7684\u5934\u5c3e\u5b9e\u4f53,\u8981\u6c42\u4f60\u9884\u6d4b\u5934\u5c3e\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\u2026\u2026 | \u5934\u5b9e\u4f53: ISIS \u5c3e\u5b9e\u4f53: \u7f8e\u519b \u53e5\u5b50: \u7f8e\u519b\u5df2\u5bf9ISIS\u53d1\u52a8&lt;N&gt;\u6b21\u7a7a\u88ad\u5916\u8d44\u77f3\u6cb9\u5de8\u5934\u6b32\u64a4\u79bb | unknown |", "caption": "Table 7: Examples of Instruction Construction for Various Financial Language Tasks, Categorized by Task Type and Language", "description": "This table presents examples of how instructions are constructed for various financial language tasks within the Golden Touchstone benchmark.  Each example includes the task type, language (English or Chinese), the instruction given to the language model, the input data provided, and the expected output. This showcases the diversity of tasks and input formats used in the benchmark, and highlights the different complexities and nuances involved in each.", "section": "3. Benchmark Design"}, {"content": "| Task Type | Language | Instruction | Input | Output |\n|---|---|---|---|---|\n| Stock<br>Movement<br>Prediction | English | Please predict the next rise or fall of DJIA Adj based on the next input of the day\u2019s 25 most popular news items\u2026\u2026 | Top1:WikiLeaks demands answers after Google hands staff emails to US government\u2026\u2026 | 1 |\n|  | Chinese | \u5728\u8003\u91cf\u4e86\u516c\u53f8\u7684\u76f8\u5173\u516c\u544a\u4e4b\u540e,\u8bf7\u6839\u636e\u65b0\u95fb\u5bf9\u80a1\u7968\u6570\u636e\u7684\u5f71\u54cd\u5bf9\u8be5\u516c\u53f8\u80a1\u7968\u7684\u8868\u73b0\u8fdb\u884c\u5206\u7c7b\u2026\u2026 | \u516c\u53f8\u8463\u4e8b\u957f\u8f66\u6210\u805a\u627f\u8bfa\u81ea\u672c\u516c\u544a\u65e5\u8d77\u672a\u6765\u516d\u4e2a\u6708\u62df\u589e\u6301\u4ef7\u503c0.5-1.0\u4ebf\u516c\u53f8\u80a1\u4efd\u2026\u2026 | 0 |\n| Multiple<br>Choice | English | Given a text T, and several options, according to the question posed in the text T\u2026\u2026 | The inventory/sales ratio is most likely to be rising\u2026\u2026 | C |\n|  | Chinese | \u7ed9\u5b9a\u4e00\u6bb5\u6587\u672cT,\u548c\u56db\u4e2a\u9009\u9879ABCD,\u6839\u636e\u6587\u672cT\u4e2d\u63d0\u51fa\u7684\u95ee\u9898\u4ece\u56db\u4e2a\u9009\u9879\u4e2d\u9009\u62e9\u5408\u9002\u7684\u591a\u4e2a\u9009\u9879\u4f5c\u4e3a\u7b54\u6848\u2026\u2026 | \u4e0b\u5217\u9009\u9879\u4e2d\u8d23\u4efb\u4e2d\u5fc3\u5224\u65ad\u4e00\u9879\u6210\u672c\u662f\u5426\u53ef\u63a7\u7684\u6761\u4ef6\u6709\uff08 \uff09\u2026\u2026 | A,B,D |\n| Summarization | English | You are given a text that consists of multiple sentences\u2026\u2026 | PORTLAND, Ore., Feb. 17, 2021 /PRNewswire/ \u2013 Allied Market Research published a report, titled,\"Matcha Tea Market By Product Type\u2026\u2026 | Matcha Tea Market to Reach $4.48 Bn, Globally, by 2027 at 7.1%\u2026\u2026 |\n|  | Chinese | \u8bf7\u5bf9\u6839\u636e\u63a5\u4e0b\u6765\u7684\u8f93\u5165\u7684\u4e2d\u6587\u77ed\u65b0\u95fb\u8fdb\u884c\u6458\u8981\u603b\u7ed3,\u8bf7\u76f4\u63a5\u5f00\u59cb\u603b\u7ed3\uff0c\u4e0d\u9700\u8981\u8f93\u51fa\u4efb\u4f55\u89e3\u91ca | \u7f8e\u6e2f\u7535\u8bafAPP 13\u65e5\u8baf\uff0c\u6cd5\u822a\u8377\u822a\u96c6\u56e2\uff08Air France-KLM\uff09\u5df2\u5f00\u59cb\u4e0e\u6ce2\u97f3(BA.N)\u548c\u7a7a\u5ba2\u5c31\u53ef\u80fd\u6210\u4e3a\u8be5\u96c6\u56e2\u6709\u53f2\u4ee5\u6765\u6700\u5927\u7684\u98de\u673a\u8ba2\u5355\u8fdb\u884c\u8c08\u5224\u2026\u2026 | \u6ce2\u97f3\u7a7a\u5ba2\u5c06\u7ade\u4e89\u6cd5\u822a\u8377\u822a\u96c6\u56e2\u53f2\u4e0a\u6700\u5927\u8ba2\u5355 |\n| Question<br>Answering | English | Please answer the given financial question based on the context\u2026\u2026 | on november 18 , 2014 , the company entered into a collateralized reinsurance agreement with kilimanjaro\u2026\u2026 | The answer is:0.26685 |\n|  | Chinese | \u8bf7\u6839\u636e\u4e0b\u9762\u63d0\u51fa\u7684\u4e00\u4e2a\u95ee\u9898\uff0c\u95ee\u9898\u540e\u7684\u6750\u6599\u5185\u4f1a\u6709\u76f8\u5e94\u7684\u7b54\u6848\u2026\u2026 | \u6c5f\u82cf\u91d1\u6c99\u5730\u7406\u4fe1\u606f\u80a1\u4efd\u6709\u9650\u516c\u53f8\u516c\u53f8\u4e0a\u5e02\u4e8b\u4ef6\u5bf9\u5e94\u7684\u8bc1\u5238\u4ee3\u7801\u662f\u4ec0\u4e48\uff1f\u6316\u8d1d\u7f5110\u67089\u65e5\uff0c\u5168\u56fd\u4e2d\u5c0f\u4f01\u4e1a\u80a1\u8f6c\u7cfb\u7edf\u516c\u544a\u663e\u793a\u2026\u2026 | 873361 |", "caption": "Table 8: Comparison of Inference Templates Across Different Models for Dataset Evaluation", "description": "This table compares the input formats or templates used by different large language models (LLMs) when processing data for evaluation on a financial benchmark.  Different LLMs may require different input structures for optimal performance.  The table shows the specific template for each model, highlighting variations in formatting for system prompts, user instructions, and model responses.", "section": "4. Experiments"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.T8.1\">\n<tr class=\"ltx_tr\" id=\"A2.T8.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"A2.T8.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.1.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.1.1.1.1\" style=\"width:86.7pt;\">Model</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"A2.T8.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.1.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.1.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.1.2.1.1.1\">Template</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.2.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.2.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.2.1.1.1.1\">GPT-4o</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.2.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.2.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.2.2.1.1.1\">\"&lt;|im_start|&gt;system{{system_prompt}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.3.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.3.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.3.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.3.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.3.2.1.1.1\">\"&lt;|im_start|&gt;user{{instruction}}{{input}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.4.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.4.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.4.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.4.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.4.2.1.1.1\">\"&lt;|im_start|&gt;assistant\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.5.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.5.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.5.1.1.1.1\">Qwen-2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.5.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.5.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.5.2.1.1.1\">\"&lt;|im_start|&gt;system{{system_prompt}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.6.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.6.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.6.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.6.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.6.2.1.1.1\">\"&lt;|im_start|&gt;user{{instruction}}{{input}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.7.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.7.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.7.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.7.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.7.2.1.1.1\">\"&lt;|im_start|&gt;assistant\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.8.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.8.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.8.1.1.1.1\">Llama-3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.8.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.8.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.8.2.1.1.1\">\"&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.9.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.9.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.9.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.9.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.9.2.1.1.1\">\"{{system_prompt}}&lt;|eot_id|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.10.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.10.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.10.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.10.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.10.2.1.1.1\">\"&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.11.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.11.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.11.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.11.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.11.2.1.1.1\">\"{{instruction}}{{input}}&lt;|eot_id|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.12.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.12.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.12.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.12.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.12.2.1.1.1\">\"&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.13.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.13.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.13.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.13.1.1.1.1\">FinGPT</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.13.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.13.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.13.2.1.1.1\">\"Instruction:{{instruction}}\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.14\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.14.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.14.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.14.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.14.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.14.2.1.1.1\">\"Input{{input}}\\nAnswer:\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.15\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.15.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.15.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.15.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.15.1.1.1.1\">FinMA</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.15.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.15.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.15.2.1.1.1\">\"Human:{{instruction}}{{input}}\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.16\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.16.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.16.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.16.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.16.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.16.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.16.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.16.2.1.1.1\">\"Assistant:\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.17\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.17.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.17.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.17.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.17.1.1.1.1\">CFGPT</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.17.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.17.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.17.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.17.2.1.1.1\">\"{{instruction}}{{input}}\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.18\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.18.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.18.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.18.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.18.1.1.1.1\">DISC-FinLLM</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.18.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.18.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.18.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.18.2.1.1.1\">\"&lt;reserved_102&gt; {{instruction}}{{input}}&lt;reserved_103&gt;\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.19\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.19.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.19.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.19.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text\" id=\"A2.T8.1.19.1.1.1.1\">Touchstone</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.1.19.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.19.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.19.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.19.2.1.1.1\">\"&lt;|im_start|&gt;system{{system_prompt}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.20\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.20.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.20.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.20.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.20.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.20.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.20.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.20.2.1.1.1\">\"&lt;|im_start|&gt;user{{instruction}}{{input}}&lt;|im_end|&gt;\\n\"</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.21\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A2.T8.1.21.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.21.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.21.1.1.1\" style=\"width:86.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A2.T8.1.21.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.21.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.21.2.1.1\" style=\"width:325.2pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"A2.T8.1.21.2.1.1.1\">\"&lt;|im_start|&gt;assistant\\n\"</span></span>\n</span>\n</td>\n</tr>\n</table>", "caption": "Table 9: Detailed Case Study Analysis of Financial Sentiment Analysis on the FiQA-SA dataset, Financial Text Classification on the LendingClub dataset, Financial Entity Extraction on NER dataset, Stock Movement Prediction on DJIA dataset.", "description": "This table presents a detailed analysis of four different financial NLP tasks: financial sentiment analysis using the FiQA-SA dataset; financial text classification using the LendingClub dataset; financial entity extraction using the NER dataset; and stock movement prediction using the DJIA dataset. For each task, it shows example inputs, labels (where applicable), and predictions made by several different large language models (LLMs), including GPT-40, Qwen-2, Llama-3, FinGPT, FinMA, and Touchstone-GPT.  The purpose is to illustrate the strengths and weaknesses of various LLMs on these tasks, highlighting the differences in their performance and ability to handle nuanced financial language.", "section": "4.2 Evaluation Results"}]