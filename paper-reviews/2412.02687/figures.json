[{"figure_path": "https://arxiv.org/html/2412.02687/x1.png", "caption": "Figure 1: \nComparison of various methods, including SNOOPI and alternatives (SwiftBrush, DMD, YOSO, PG-SB), using the PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1 backbone. Each method generates an image with the prompt \u201dVincent van Gogh\u201d (green). PG-SB helps stabilize the training process of image-free distillation, addressing the typical instability in such training. SNOOPI, a combination of PG-SB and the NASA module, enables effective negative prompting (red) even for one and few-step models, allowing for the removal of specific unwanted features and providing enhanced control over image attributes.", "description": "Figure 1 compares the image generation results of several one-step diffusion models, including the proposed SNOOPI model and existing methods like SwiftBrush, DMD, YOSO, and PG-SB.  All models are trained using the PixArt-\u03b1 backbone and prompted with the text \"Vincent van Gogh\". The figure highlights how PG-SB improves training stability in image-free distillation compared to other methods.  Furthermore, it shows SNOOPI's ability to incorporate negative prompts (demonstrated with a red image), effectively removing unwanted features and providing finer control over image generation than models without negative prompt capabilities.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.02687/x2.png", "caption": "Figure 2: \nFID 2K progression throughout training. The default baseline is SwiftBrush for both SDv1.5 and PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1. DMD2Trick indicates the Two Time-scale Update Rule technique [54], which increases the update frequency of the LoRA teacher to 5 times after each student update. These baselines demonstrate notable instability, leading to variability in image quality metrics such as FID. In contrast, our approach, which employs CFG with randomly selected values from a uniform distribution, results in a more stable training process and generates higher-quality samples.", "description": "Figure 2 illustrates the impact of different training approaches on the Fr\u00e9chet Inception Distance (FID) score, a metric measuring the quality of generated images.  The x-axis represents training iterations, while the y-axis represents the FID 2K score.  Three different models (SwiftBrush, SwiftBrush with the 'Two Time-scale Update Rule' modification, and the proposed PG-SB method) are compared for two different diffusion model backbones (SDv1.5 and PixArt-\u03b1). The graph clearly shows that SwiftBrush and its modification exhibit unstable training, leading to significant fluctuations in FID scores. Conversely, the PG-SB approach demonstrates much more stable training, resulting in a consistently lower and more desirable FID score, indicating better image quality.", "section": "4. Proper Guidance - SwiftBrush"}, {"figure_path": "https://arxiv.org/html/2412.02687/x3.png", "caption": "Figure 3: Qualitative comparison of different methods for integrating negative prompts into the generation process using a one-step generator. As shown, simply applying CFG to a one-step generator is equivalent to blending (i.e., adding) two images together, resulting in an unusable output. Alternatively, negating the negative embedding from the positive embedding shows minimal impact on the final image. In contrast, NASA is the first method to successfully steer the generation away from negative attributes in a one-step generator, while also producing high-quality results.", "description": "Figure 3 compares three approaches for using negative prompts in one-step image generation.  Simply applying classifier-free guidance (CFG) directly, as done in multi-step models, results in a visually poor blend of the positive and negative images.  Subtracting the negative embedding from the positive embedding also fails to effectively remove unwanted features.  In contrast, the authors' proposed Negative-Away Steer Attention (NASA) method successfully removes undesired elements while maintaining high-quality image generation, showcasing its effectiveness as the first method able to integrate negative prompts into the one-step generation process.", "section": "5. Negative-Away Steer Attention"}, {"figure_path": "https://arxiv.org/html/2412.02687/x4.png", "caption": "Figure 4: Left: An overview of the Negative-Away Steer Attention (NASA) pipeline. Positive (green) and negative (red) prompts are fed into a text encoder to generate positive and negative text features. The NASA module then processes these features, which adjusts the one-step diffusion model to steer the output image away from the negative features, refining it based on the positive features. Right: The details of the NASA module. It processes queries (\ud835\udc10lsubscript\ud835\udc10\ud835\udc59\\mathbf{Q}_{l}bold_Q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT) in layer l\ud835\udc59litalic_l, note we will omit the subscript l\ud835\udc59litalic_l in subsequent notations to improve readability, with positive (\ud835\udc15+,\ud835\udc0a+superscript\ud835\udc15superscript\ud835\udc0a\\mathbf{V}^{+},\\mathbf{K}^{+}bold_V start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT , bold_K start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT) and negative (\ud835\udc15\u2212,\ud835\udc0a\u2212superscript\ud835\udc15superscript\ud835\udc0a\\mathbf{V}^{-},\\mathbf{K}^{-}bold_V start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT , bold_K start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT) key-value pairs to create positive (\ud835\udc19+superscript\ud835\udc19\\mathbf{Z}^{+}bold_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT) and negative (\ud835\udc19\u2212superscript\ud835\udc19\\mathbf{Z}^{-}bold_Z start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT) attention outputs. The final output (\ud835\udc19NASAsuperscript\ud835\udc19NASA\\mathbf{Z}^{\\text{NASA}}bold_Z start_POSTSUPERSCRIPT NASA end_POSTSUPERSCRIPT) is calculated by subtracting the weighted negative features (\ud835\udc19\u2212superscript\ud835\udc19\\mathbf{Z}^{-}bold_Z start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT) from the positive features (\ud835\udc19+superscript\ud835\udc19\\mathbf{Z}^{+}bold_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT).", "description": "Figure 4 illustrates the Negative-Away Steer Attention (NASA) method.  The left side shows a high-level overview of the process: positive and negative text prompts are input into a text encoder, generating corresponding positive and negative text features.  These features are then fed into the NASA module, which modifies the one-step diffusion model's generation process to avoid the negative features and enhance the positive ones, resulting in a refined output image. The right side details the internal workings of the NASA module at layer 'l'. It shows how positive and negative key-value pairs (K+, V+, K-, V-) interact with queries (Ql) via cross-attention mechanisms to produce positive (Z+) and negative (Z-) attention outputs.  Finally, the weighted negative output (Z-) is subtracted from the positive output (Z+), yielding the final NASA output (ZNASA).", "section": "5. Negative-Away Steer Attention"}, {"figure_path": "https://arxiv.org/html/2412.02687/x5.png", "caption": "Figure 5: Effect of different scale values (0.0 to 1.0) in NASA with SDXL-DMD2 model, illustrating the progressive influence on visual details and composition.", "description": "Figure 5 shows how different scaling factors (0.0 to 1.0) in the NASA module affect image generation using the SDXL-DMD2 model.  The figure demonstrates the progressive impact of the NASA module on visual details and overall composition of the generated images, ranging from a lack of detail and poor composition at 0.0, to a high level of detail and well-composed image at 1.0. Each row shows the results for a single prompt, highlighting the gradual shift in image quality and composition with increasing scale values.", "section": "5. Negative-Away Steer Attention"}, {"figure_path": "https://arxiv.org/html/2412.02687/x6.png", "caption": "Figure 6: Qualitative results of NASA. Each row displays images generated with a positive (green) and negative (red) prompt pair. Models using NASA effectively exclude unwanted features, aligning outputs with desired traits.", "description": "Figure 6 showcases the effectiveness of the Negative-Away Steer Attention (NASA) module in controlling image generation.  Each row presents a pair of prompts: a positive prompt (in green) describing the desired image content, and a negative prompt (in red) specifying features to be excluded.  The images generated by models with and without the NASA module are displayed side-by-side, demonstrating how NASA successfully removes the unwanted attributes specified in the negative prompt while retaining the key elements from the positive prompt. This highlights NASA's ability to precisely control the generated images, aligning outputs more closely with the desired traits specified.", "section": "5. Negative-Away Steer Attention"}, {"figure_path": "https://arxiv.org/html/2412.02687/extracted/6043931/figure/pixart_grid.jpg", "caption": "Figure 7: Additional qualitative images generated by our PG-SB model with the PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1 backbone.", "description": "This figure showcases the visual quality of images generated using the PG-SB model, specifically using the PixArt-\u03b1 backbone.  It presents a diverse array of images demonstrating the model's capability to generate various subjects, styles, and compositions, offering a qualitative assessment of its performance and versatility.", "section": "6. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02687/extracted/6043931/figure/sd15_grid.jpg", "caption": "Figure 8: Additional qualitative images generated by our PG-SB model with the SDv1.5 backbone.", "description": "This figure displays a diverse collection of images generated using the PG-SB (Proper Guidance - SwiftBrush) model, which is a modified version of the SwiftBrush model. The key improvement in PG-SB is the use of a randomized guidance scale for training stability.  These images showcase the model's ability to generate a variety of styles and subjects, demonstrating its versatility and effectiveness in producing high-quality results. All images in this figure were generated using the Stable Diffusion 1.5 model as the backbone for the PG-SB model.", "section": "6. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02687/extracted/6043931/figure/sd21_grid.jpg", "caption": "Figure 9: Additional qualitative images generated by our PG-SB model with the SDv2.1 backbone.", "description": "This figure displays a collection of images generated using the PG-SB model, specifically employing the Stable Diffusion 2.1 (SDv2.1) backbone.  The images showcase the model's capability to produce diverse and high-quality outputs, highlighting the visual style and realism achieved through the PG-SB method. The variety of subjects and artistic styles in the images demonstrates the versatility and effectiveness of the model. Each image serves as a visual example of the model's performance, providing qualitative evidence of its ability to generate detailed, coherent, and visually appealing results.", "section": "Additional Qualitative Results of PG-SB"}]