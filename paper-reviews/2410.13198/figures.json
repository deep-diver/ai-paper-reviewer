[{"figure_path": "2410.13198/figures/figures_1_0.png", "caption": "Figure 1: Comparison of traditional GEC and DARAG. We augment the training dataset with synthetic data generated using our algorithm and named entities retrieved from a datastore to improve in-domain and out-of-domain ASR.", "description": "The figure illustrates the difference between traditional Generative Error Correction and the proposed DARAG method, highlighting the addition of synthetic data and retrieval augmentation for improved ASR performance.", "section": "1 Introduction"}, {"figure_path": "2410.13198/figures/figures_1_1.png", "caption": "Figure 1: Comparison of traditional GEC and DARAG. We augment the training dataset with synthetic data generated using our algorithm and named entities retrieved from a datastore to improve in-domain and out-of-domain ASR.", "description": "The figure compares traditional generative error correction (GEC) with the proposed DARAG method, highlighting the addition of synthetic data and named entity retrieval for improved performance.", "section": "1 Introduction"}, {"figure_path": "2410.13198/figures/figures_5_0.png", "caption": "Figure 2: Illustration of DARAG. \u2460 We generate synthetic data with LLMs and TTS models that are then used to generate hypotheses with diverse errors consistent with the types the ASR model generates on the test set. \u2461 We extract the NEs and store them in a datastore. During training, for every instance, we retrieve the top-k most similar NEs to the best hypothesis and use it to construct an instruction-response pair. Note that in OOD settings we only assume the availability of only a few unsupervised speech samples in the original train set and pseudo-transcripts for prompting are generated using the in-domain ASR model.", "description": "The figure illustrates the DARAG framework, showing how synthetic data is generated and used to augment the training data, and how retrieval augmentation is used to improve named entity correction.", "section": "4 Methodology"}, {"figure_path": "2410.13198/figures/figures_5_1.png", "caption": "Figure 2: Illustration of DARAG. \u2460 We generate synthetic data with LLMs and TTS models that are then used to generate hypotheses with diverse errors consistent with the types the ASR model generates on the test set. \u2461 We extract the NEs and store them in a datastore. During training, for every instance, we retrieve the top-k most similar NEs to the best hypothesis and use it to construct an instruction-response pair. Note that in OOD settings we only assume the availability of only a few unsupervised speech samples in the original train set and pseudo-transcripts for prompting are generated using the in-domain ASR model.", "description": "The figure illustrates the DARAG framework, showing how synthetic data generation and retrieval augmentation are used to improve generative error correction for ASR.", "section": "4 Methodology"}, {"figure_path": "2410.13198/figures/figures_5_2.png", "caption": "Figure 2: Illustration of DARAG. \u2460 We generate synthetic data with LLMs and TTS models that are then used to generate hypotheses with diverse errors consistent with the types the ASR model generates on the test set. \u2461 We extract the NEs and store them in a datastore. During training, for every instance, we retrieve the top-k most similar NEs to the best hypothesis and use it to construct an instruction-response pair. Note that in OOD settings we only assume the availability of only a few unsupervised speech samples in the original train set and pseudo-transcripts for prompting are generated using the in-domain ASR model.", "description": "The figure illustrates the proposed DARAG framework, showing how synthetic data generation and retrieval augmentation improve generative error correction for ASR.", "section": "4 Methodology"}]