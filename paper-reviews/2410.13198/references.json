{"references": [{" publication_date": "2000", "fullname_first_author": "Daniel Jurafsky", "paper_title": "Speech and language processing", "reason": "This foundational textbook provides a comprehensive overview of the field of speech and language processing, including automatic speech recognition (ASR), which is central to the current research. Its importance stems from establishing the fundamental principles and challenges in ASR that motivate the current advancements and innovations.", "section_number": 1}, {" publication_date": "2015", "fullname_first_author": "Jinyu Li", "paper_title": "Robust automatic speech recognition: a bridge to practical applications", "reason": "This paper discusses the challenges and robustness issues faced in real-world ASR, serving as a foundation for the current paper's focus on addressing the challenges of noisy and varied speech data, which is a significant limitation of the traditional GEC approach. It highlights limitations of the traditional methods that inspire the proposed improvements.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Changhan Wang", "paper_title": "VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation", "reason": "This paper introduces a valuable multilingual speech corpus that serves as a benchmark dataset for evaluating the performance of the proposed GEC method. It showcases the significance of multilingual data and its impact on model generalization and performance.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Chen Chen", "paper_title": "Hyporadise: An open baseline for generative speech recognition with large language models", "reason": "This work provides an open-source baseline for generative speech recognition, which helps to contextualize the performance of the proposed DARAG model and facilitates comparisons. It provides the foundation on which the current work builds upon and contrasts its approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "reason": "This research introduces a robust speech recognition model that addresses the noise robustness issues in ASR. This forms the basis for developing the synthetic data augmentation in DARAG, which aims to overcome the limitations of limited diverse training data.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Rao Ma", "paper_title": "N-best T5: Robust ASR error correction using multiple input hypotheses and constrained decoding space", "reason": "This paper demonstrates the value of using multiple input hypotheses in ASR error correction. This motivates the utilization of N-best hypotheses within the DARAG framework to make the system more robust in handling various types of errors.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Chen Chen", "paper_title": "Hyporadise: An open baseline for generative speech recognition with large language models", "reason": "This research explores the potential of generative speech recognition with LLMs, setting the stage for the current paper's focus on utilizing LLMs to generate synthetic data.  The provided baseline allows for a direct comparison.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Sreyan Ghosh", "paper_title": "LipGER: Visually-Conditioned Generative Error Correction for Robust Automatic Speech Recognition", "reason": "This paper develops a novel visually-conditioned generative error correction model, demonstrating the potential of integrating visual cues to improve error correction. It also serves as a motivation to explore integrating relevant entities from the datastore.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Nilaksh Das", "paper_title": "Listen, know and spell: Knowledge-infused subword modeling for improving asr performance of oov named entities", "reason": "This paper focuses on improving ASR performance for out-of-vocabulary (OOV) named entities, directly addressing a crucial aspect of ASR error correction. It motivates the retrieval augmentation method used in DARAG to enhance named entity handling.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Dhanush Bekal", "paper_title": "Remember the context! asr slot error correction through memorization", "reason": "This paper explores ASR slot error correction through memorization techniques, which highlights the memorization aspect of LLMs for enhancing ASR performance and inspires improving GEC.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Benjamin Heinzerling", "paper_title": "Language models as knowledge bases: On entity representations, storage capacity, and paraphrased queries", "reason": "This paper explores language models as knowledge bases, which is relevant to the utilization of LLMs in the proposed method for generating synthetic data. The knowledge base aspect is connected with the retrieval augmentation in DARAG for named entity correction.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Peeyush Singhal", "paper_title": "Domain adaptation: challenges, methods, datasets, and applications", "reason": "This paper reviews the challenges, methods, and datasets related to domain adaptation in ASR. This contextualizes the OOD aspect of the current paper's contributions, highlighting the difficulties in adapting GEC to novel domains and motivating the use of synthetic data generation.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Rao Ma", "paper_title": "Can generative large language models perform asr error correction?", "reason": "This paper directly addresses whether LLMs can be effective for ASR error correction, laying a foundation for the current paper's approach of using LLMs to generate synthetic data.  It addresses the limitations of traditional GEC.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "reason": "This paper introduces the LoRA technique for adapting LLMs. This method is employed in the DARAG approach to fine-tune the LLM for error correction, reducing the computational cost while maintaining performance.  The efficiency improves the scalability of the approach.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Yoach Lacombe", "paper_title": "Parler-TTS", "reason": "This paper introduces the Parler-TTS model, which is used in DARAG to generate synthetic speech data.  The high-fidelity speech generated enables simulating realistic speech patterns and associated errors, which is crucial for training a robust GEC model.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "LLaMa-2-Instruct", "reason": "The LLaMa-2-Instruct model is used for generating synthetic transcripts in DARAG.  The model's ability to generate diverse and relevant transcripts is essential for simulating realistic ASR errors and improving the model's generalization capability.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "N Reimers", "paper_title": "Sentence-BERT: Sentence embeddings using siamese bert-networks", "reason": "Sentence-BERT is used in DARAG's retrieval augmentation mechanism.  The model's ability to generate effective sentence embeddings facilitates efficient retrieval of relevant named entities from the datastore, improving the accuracy of named entity correction.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Patrick Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks", "reason": "This paper introduces the Retrieval-Augmented Generation (RAG) technique, which serves as a foundation for the retrieval-augmented correction component in DARAG. RAG enhances the model's ability to incorporate external knowledge during error correction, leading to more accurate results.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Jiaqi Su", "paper_title": "HiFi-GAN: High-fidelity denoising and dereverberation based on speech deep features in adversarial networks", "reason": "This research introduces HiFi-GAN, a speech enhancement model. This model is used in an ablation study within DARAG, to assess the impact of noise reduction on the system\u2019s overall performance and improve overall robustness.", "section_number": 5}, {" publication_date": "2018", "fullname_first_author": "Shinji Watanabe", "paper_title": "ESPnet: End-to-end speech processing toolkit", "reason": "This paper introduces ESPnet, a widely used open-source toolkit for end-to-end speech processing.  Its use ensures reproducibility and facilitates comparison by providing a standardized platform for model development and evaluation.", "section_number": 5}]}