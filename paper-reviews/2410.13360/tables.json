[{"figure_path": "2410.13360/tables/table_3_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "This table compares different personalization methods for Multimodal LLMs (MLLMs) based on the number of images needed, data requirements, and whether real-time editing is supported.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_7_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for multi-modal large language models (MLLMs) in terms of fine-tuning needs, image requirements, data requirements, and real-time editing support.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_8_0.html", "caption": "Table 3: Quantitative Evaluation on Image Captioning. We report Recall, Precision and F1-score in the table, the best result in each metric is bold and the second is underlined.", "description": "Table 3 quantitatively evaluates the performance of different methods on image captioning task using Recall, Precision and F1-score metrics.", "section": "4.1 Personalized Image Captioning"}, {"figure_path": "2410.13360/tables/table_8_1.html", "caption": "Table 4: Quantitative Evaluation on Question Answering and Visual Recognition. The best result in each setting is bold and the second is underlined. Evaluation results of GPT-4V are also provided as reference. Weighted results are computed as arithmetic means.", "description": "Table 4 quantitatively evaluates the performance of various methods on question answering and visual recognition tasks, highlighting the best performing methods.", "section": "4.2 PERSONALIZED QUESTION ANSWERING"}, {"figure_path": "2410.13360/tables/table_10_0.html", "caption": "Table 5: We evaluate model's performance with perfect retrieval, and test contributions of each dataset component.", "description": "The table shows the ablation study results of RAP-LLaVA model's performance with different settings, including with perfect retrieval, without data augmentation, and without negative samples.", "section": "4.4 ABLATION STUDY"}, {"figure_path": "2410.13360/tables/table_10_1.html", "caption": "Table 6: Evaluation on Multimodal Benchmarks. RAP-LLaVA maintains most knowledge of original LLaVA.", "description": "The table compares the performance of RAP-LLaVA and other methods on two multimodal benchmarks (MMMU and InfoSeek), showing that RAP-LLaVA maintains most of the original LLaVA's knowledge while improving performance on InfoSeek.", "section": "4.4 ABLATION STUDY"}, {"figure_path": "2410.13360/tables/table_15_0.html", "caption": "Table 7: Ablation studies on Question Answering and Visual Recognition. Weighted results are computed as arithmetic means.", "description": "The table presents ablation study results on question answering and visual recognition, showing the impact of data augmentation and negative samples on model performance.", "section": "B ADDITIONAL EVALUATION RESULTS"}, {"figure_path": "2410.13360/tables/table_16_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "Table 1 compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_16_1.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "Table 1 compares different personalization methods for Multimodal LLMs (MLLMs), highlighting RAP's efficiency and flexibility by requiring only one image with a description.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_17_1.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the proposed Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_19_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "This table compares different methods for personalizing Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the proposed Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_20_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for multi-modal large language models, highlighting RAP's efficiency in requiring only one image per concept for personalization.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_21_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting RAP's efficiency in requiring only one image and description for personalization.", "section": "Introduction"}, {"figure_path": "2410.13360/tables/table_22_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting RAP's superior efficiency in requiring only one image and its description for personalization.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_23_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "This table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_24_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "This table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the proposed Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_25_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for Multimodal Large Language Models (MLLMs), highlighting the efficiency and flexibility of the proposed Retrieval Augmented Personalization (RAP) framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_26_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for multi-modal large language models (MLLMs) highlighting the efficiency and flexibility of the proposed RAP framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13360/tables/table_29_0.html", "caption": "Table 1: Comparison of Different Personalization Methods. RAP needs only 1 image with its personalized description, showing outstanding convenience and flexibility in practical applications.", "description": "The table compares different personalization methods for Multimodal Large Language Models (MLLMs) highlighting RAP's efficiency in requiring only one image and its description for personalization.", "section": "1 INTRODUCTION"}]