{"references": [{" publication_date": "2015", "fullname_first_author": "Jascha Sohl-Dickstein", "paper_title": "Deep unsupervised learning using nonequilibrium thermodynamics", "reason": "This paper is foundational to the field of diffusion models, introducing a deep unsupervised learning method using nonequilibrium thermodynamics.  It lays the groundwork for many subsequent advancements in diffusion models, making it a crucial reference for understanding the basis of text-to-image generation techniques.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), which are a core component of many modern diffusion models, including those used for text-to-image generation.  Its contribution significantly advanced the state-of-the-art in generative modeling, providing a foundation for many subsequent research efforts.", "section_number": 2}, {" publication_date": "2021a", "fullname_first_author": "Jiaming Song", "paper_title": "Score-based generative modeling through stochastic differential equations", "reason": "This work presents score-based generative modeling using stochastic differential equations (SDEs). This approach is highly influential in the development of efficient and high-quality diffusion models for image generation and is a key building block for many text-to-image models.", "section_number": 2}, {" publication_date": "2021b", "fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "reason": "This paper proposes denoising diffusion implicit models (DDIMs), offering a more efficient sampling method compared to traditional DDPMs.  This efficiency improvement is critical for practical applications of diffusion models, such as text-to-image generation, where faster sampling is often essential.", "section_number": 2}, {" publication_date": "2014", "fullname_first_author": "Tsung-Yi Lin", "paper_title": "Microsoft coco: Common objects in context", "reason": "The COCO dataset is a widely used benchmark dataset in computer vision, providing a large-scale collection of images with detailed annotations.  Its availability has greatly facilitated the development and evaluation of various computer vision models, including text-to-image models.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP's introduction of contrastive learning for aligning image and text embeddings revolutionized the field of multimodal learning and provided a powerful foundation for many recent advancements in text-to-image generation. Its impact is significant across numerous downstream tasks and models.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "Stable Diffusion's introduction of a latent diffusion model significantly improved the efficiency and quality of image generation, enabling the creation of high-resolution images. This model has become a crucial component of many recent text-to-image generation systems.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "reason": "This paper introduced a significant advancement in text-to-image diffusion models, achieving photorealistic image generation with a much deeper understanding of the textual input. Its high-quality results pushed the boundaries of what is possible with text-to-image generation, serving as a strong benchmark for other models.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "reason": "This research significantly advanced the field of reinforcement learning for language models, enabling the training of models that follow instructions more effectively. This is highly relevant to text-to-image generation where the model needs to accurately follow detailed prompts.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Victor Weixin Liang", "paper_title": "Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning", "reason": "This paper is crucial for understanding the challenges of aligning image and text representations, a central problem in text-to-image generation. The insights into the modality gap provide critical context and motivation for developing more effective methods.", "section_number": 4}, {" publication_date": "2023a", "fullname_first_author": "Junsong Chen", "paper_title": "Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "PixArt-alpha demonstrates significant advancements in the speed and quality of training diffusion models, a highly relevant topic to the work presented in the paper, as they also focused on improving the speed of training and the quality of image generation in relation to long-text inputs.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Yuval Kirstain", "paper_title": "Pick-a-pic: An open dataset of user preferences for text-to-image generation", "reason": "The availability of the Pick-a-pic dataset significantly impacts research in preference learning for text-to-image models. As the dataset provides a benchmark for evaluating the performance of various preference models, the contributions are significant for the advancement of the field.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Xiaoshi Wu", "paper_title": "Human preference score: Better aligning text-to-image models with human preference", "reason": "This paper develops a novel evaluation metric to help better align text-to-image models with human preference and offers a method of improving the alignment of models. This is highly relevant to the core focus of the research, and this metric is used as a benchmark for comparing results.", "section_number": 4}, {" publication_date": "2023b", "fullname_first_author": "Lin Chen", "paper_title": "Sharegpt4v: Improving large multi-modal models with better captions", "reason": "This work directly addresses the challenges of improving caption quality, which is a critical aspect of enhancing long text descriptions for text-to-image models. Therefore, this is highly relevant to the paper's central focus of enhancing long-text alignment.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Anton Razzhigaev", "paper_title": "Kandinsky: an improved text-to-image synthesis with image prior and latent diffusion", "reason": "Kandinsky\u2019s advancements in text-to-image synthesis, using image priors and latent diffusion, are directly comparable to the work presented in the paper. They are both working on enhancing image generation quality in relation to textual inputs, making this a highly relevant reference.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Kevin Clark", "paper_title": "Directly fine-tuning diffusion models on differentiable rewards", "reason": "This paper provides a method for directly fine-tuning diffusion models using differentiable rewards. This technique is directly relevant to the paper's approach of using reward fine-tuning for improving alignment, although this paper introduces several innovations which improved the technique.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Ying Fan", "paper_title": "Reinforcement learning for fine-tuning text-to-image diffusion models", "reason": "This work directly addresses the challenges of fine-tuning diffusion models for better alignment with text, a core aspect of the research presented in the paper.  The techniques used are directly relevant to the method presented.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Xiaoshi Wu", "paper_title": "Deep reward supervisions for tuning text-to-image diffusion models", "reason": "DRTune, introduced in this paper, significantly improves the training speed and efficiency of diffusion models. This efficiency improvement is directly relevant to the paper's aim to improve training speed and quality of image generation in relation to long-text inputs. The technique is used in the experimental setup of the paper.", "section_number": 4}, {" publication_date": "2024a", "fullname_first_author": "Daiqing Li", "paper_title": "Playground v2. 5: Three insights towards enhancing aesthetic quality in text-to-image generation", "reason": "Playground v2.5 provides a valuable comparative baseline model in the evaluation of image generation quality.  The focus on enhancing aesthetic quality is relevant as it is a common human preference which is addressed in the paper's preference decomposition.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Keqiang Sun", "paper_title": "Journeydb: A benchmark for generative image understanding", "reason": "The introduction of the JourneyDB dataset provides a valuable resource for training and evaluating text-to-image models. The dataset\u2019s focus on generative image understanding makes it relevant to the paper's aim to generate high-quality images from long-text descriptions.", "section_number": 5}]}