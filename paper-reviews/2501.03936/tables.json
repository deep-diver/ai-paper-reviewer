[{"content": "| Domain | Document #Chars | Document #Figs | Presentation #Chars | Presentation #Figs | Presentation #Pages |\n|---|---|---|---|---|---| \n| Culture | 12,708 | 2.9 | 6,585 | 12.8 | 14.3 |\n| Education | 12,305 | 5.5 | 3,993 | 12.9 | 13.9 |\n| Science | 16,661 | 4.8 | 5,334 | 24.0 | 18.4 |\n| Society | 13,019 | 7.3 | 3,723 | 9.8 | 12.9 |\n| Tech | 18,315 | 11.4 | 5,325 | 12.9 | 16.8 |", "caption": "Table 1: Statistics of the dataset used in our experiments, detailing the number of characters (\u2018#Chars\u2019) and figures (\u2018#Figs\u2019), as well as the number of pages (\u2018#Pages\u2019).", "description": "This table presents a statistical overview of the Zenodo10K dataset used in the paper's experiments. It provides details on the number of characters, figures, and pages in the presentations and documents included in the dataset, categorized by domain (Culture, Education, Science, Society, Tech).  This information is crucial for understanding the scale and characteristics of the data used to train and evaluate the proposed PPTAgent model.", "section": "4.1 Dataset"}, {"content": "| Setting |  | Existing Metrics |  | PPTEval |  |\n|---|---|---|---|---|---|---|\n| Language Model | Vision Model | SR(%) \u2191 | PPL \u2193 | FID \u2193 | Content \u2191 | Design \u2191 | Coherence \u2191 | Avg. \u2191 |\n|---|---|---|---|---|---|---|---|---|\n| *Baseline* |  |  |  |  |  |  |  |  |\n| GPT-4o<sub>LM</sub> | \u2013 | \u2013 | **110.6** | \u2013 | 2.98 | 2.33 | 3.24 | 2.85 |\n| Qwen2.5<sub>LM</sub> | \u2013 | \u2013 | **122.4** | \u2013 | 2.96 | 2.37 | 3.28 | 2.87 |\n| *PPTAgent* |  |  |  |  |  |  |  |  |\n| GPT-4o<sub>LM</sub> | GPT-4o<sub>VM</sub> | **97.8** | 459.7 | 7.48 | **3.25** | 3.24 | **4.39** | **3.62** |\n| Qwen2-VL<sub>LM</sub> | Qwen2-VL<sub>VM</sub> | 43.0 | 322.3 | **7.32** | 3.13 | **3.34** | 4.07 | 3.51 |\n| Qwen2.5<sub>LM</sub> | Qwen2-VL<sub>VM</sub> | **95.0** | 313.9 | **6.20** | **3.28** | **3.27** | **4.48** | **3.67** |\n| *Ablation* |  |  |  |  |  |  |  |  |\n| PPTAgent |  | **95.0** | 313.9 | **6.20** | **3.28** | 3.27 | **4.48** | **3.67** |\n| *w/o Outline* |  | 91.0 | 2304.3 | **6.94** | 3.24 | **3.30** | 3.36 | 3.30 |\n| *w/o Schema* |  | 78.8 | **164.8** | 7.12 | 3.08 | 3.23 | 4.04 | 3.45 |\n| *w/o Structure* |  | **92.2** | **189.9** | 7.66 | **3.28** | 3.25 | 3.45 | 3.32 |\n| *w/o CodeRender* |  | 74.6 | 231.0 | 7.03 | 3.27 | **3.34** | **4.38** | **3.66** |", "caption": "Table 2: Performance comparison of the baseline, our proposed PPTAgent framework, and its ablation variants. Results are reported using existing metrics\u2014Success Rate (SR), Perplexity (PPL), and FID (Heusel et\u00a0al., 2017)\u2014as well as our proposed PPTPPTEval metrics, which assess Content, Design, Coherence, and their average score.", "description": "This table presents a comprehensive comparison of different presentation generation methods.  It contrasts a baseline approach with the proposed PPTAgent framework and several ablation variants of PPTAgent.  Performance is evaluated using established metrics like Success Rate (SR), Perplexity (PPL), and Fr\u00e9chet Inception Distance (FID), alongside the newly introduced PPT Eval metrics which assess presentation quality across Content, Design, and Coherence. The average score across all metrics is also included, providing a holistic view of each method's effectiveness.", "section": "4 Experiment"}, {"content": "| Corelation | Content | Design | Coherence | Avg. |\n|---|---|---|---|---|\n| **Pearson** | 0.70 | 0.90 | 0.55 | 0.71 |\n| **Spearman** | 0.73 | 0.88 | 0.57 | 0.74 |", "caption": "Table 3: Evaluation results under the configuration of Qwen2-VLLMLM{}_{\\texttt{LM}}start_FLOATSUBSCRIPT LM end_FLOATSUBSCRIPT+Qwen2-VLVMVM{}_{\\texttt{VM}}start_FLOATSUBSCRIPT VM end_FLOATSUBSCRIPT in different domains, using the success rate (SR), PPL, FID and the average PPTEval score across three evaluation dimensions.", "description": "Table 3 presents a performance evaluation of the PPTAgent model using the Qwen2-VLLM and Qwen2-VL configurations.  It shows the success rate (SR), perplexity (PPL), Fr\u00e9chet Inception Distance (FID), and average PPTEval score across content, design, and coherence dimensions for various domains (Culture, Education, Science, Society, Tech). This helps assess the model's effectiveness in different contexts.", "section": "4.4 Result & Analysis"}, {"content": "| Function Name | Description |\n|---|---| \n| `del_span` | Deletes a specific span. |\n| `del_image` | Deletes an image element. |\n| `clone_paragraph` | Creates a duplicate of an existing paragraph. |\n| `replace_span` | Replaces the content of a specific span. |\n| `replace_image` | Replaces an image with a new image. |", "caption": "Table 4: The correlation scores between human ratings and LLM ratings under different dimensions (Coherence, Content, Design). All presented data of similarity exhibit a p-value below 0.05, indicating a statistically significant level of confidence.", "description": "This table presents the correlation analysis results between human evaluation scores and Large Language Model (LLM) scores across three dimensions: Content, Design, and Coherence.  The correlation is measured using both Pearson and Spearman correlation coefficients.  A p-value below 0.05 for all correlations indicates that the relationships between human and LLM judgments are statistically significant, suggesting a high degree of agreement between human raters and the LLM's assessment of presentation quality.", "section": "4.5 Ablation Study"}]