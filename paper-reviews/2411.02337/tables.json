[{"content": "| Models | #Params | Reddit | Gitlab | CMS | Map | OSS | Avg. SR |\n|---|---|---|---|---|---|---|---| \n| *Proprietary LLMs* |  |  |  |  |  |  |  |\n| GPT-4-Turbo | N/A | 10.5 | 16.7 | 14.3 | 36.7 | 13.3 | 17.6 |\n| GPT-4o | N/A | 10.5 | 10.0 | 20.0 | 20.0 | 11.1 | 13.9 |\n| AWM + GPT-4-0613<sup>*</sup> [2024] | N/A | 50.9 | 31.8 | 29.1 | 43.3 | 30.8 | 35.5 |\n| WebPilot + GPT-4o<sup>*</sup> [2024f] | N/A | 65.1 | 39.4 | 24.7 | 33.9 | 36.9 | 37.2 |\n| *Open-sourced LLMs* |  |  |  |  |  |  |  |\n| AutoWebGLM [2024] | 6B | 9.4 | 15.0 | 28.6 | 24.8 | 17.1 | 18.2 |\n| GLM-4-Chat [2024] | 9B | 5.3 | 10.0 | 6.7 | 3.3 | 6.7 | 6.1 |\n| GLM-4 + SFT (BC) | 9B | 47.4 | 13.3 | 31.4 | 23.3 | 13.3 | 22.4 |\n| GLM-4 + Filtered BC | 9B | 52.6 | 10.0 | 31.4 | 26.7 | 20.0 | 24.8 |\n| GLM-4 + AWR [2019] | 9B | 52.6 | 16.7 | 34.3 | 30.0 | 22.2 | 27.9 |\n| GLM-4 + DigiRL [2024] | 9B | 63.2 | 30.0 | 34.3 | 26.7 | 26.7 | 31.5 |\n| GLM-4 + WebRL (ours) | 9B | 57.9 | 50.0 | 48.6 | 36.7 | 37.8 | 43.0 |\n| Llama3.1-Instruct [2024] | 8B | 0.0 | 3.3 | 2.9 | 3.3 | 11.1 | 4.8 |\n| Llama3.1 + SFT (BC) | 8B | 36.8 | 6.7 | 20.0 | 33.3 | 17.8 | 20.6 |\n| Llama3.1 + Filtered BC | 8B | 52.6 | 20.0 | 31.4 | 23.3 | 8.9 | 23.0 |\n| Llama3.1 + AWR [2019] | 8B | 57.9 | 26.7 | 31.4 | 26.7 | 17.8 | 28.5 |\n| Llama3.1 + DigiRL [2024] | 8B | 57.9 | 26.7 | 37.1 | 33.3 | 17.8 | 30.3 |\n| Llama3.1 + WebRL (ours) | 8B | 63.2 | 46.7 | 54.3 | 36.7 | 31.1 | 42.4 |\n| Llama3.1-Instruct [2024] | 70B | 10.5 | 16.7 | 17.1 | 20.0 | 4.4 | 12.7 |\n| Llama3.1 + SFT (BC) | 70B | 52.6 | 20.0 | 20.0 | 26.7 | 13.3 | 23.0 |\n| Llama3.1 + WebRL (ours) | 70B | 78.9 | 50.0 | 54.3 | 40.0 | 44.4 | 49.1 |", "caption": "Table 1: Task success rate (SR) of WebRL and other comparison methods, evaluated on WebArena-Lite\u00a0(Zhou et\u00a0al., 2023a; Liu et\u00a0al., 2024), a human-verified subset of WebArena (* denotes results on full WebArena taken from literature reporting). The best and second-best models are highlighted.", "description": "This table presents a comparison of the task success rate (SR) achieved by different Large Language Models (LLMs) on the WebArena-Lite benchmark.  WebArena-Lite is a human-verified subset of the larger WebArena dataset, focusing on web-based tasks.  The models compared include both open-source LLMs (e.g., Llama-3.1, GLM-4) and proprietary LLMs (e.g., GPT-4-Turbo, GPT-40). The table highlights the significant performance improvements gained by using the WebRL framework to train open-source LLMs for web-based tasks.  Results are broken down by individual website within WebArena-Lite (Reddit, GitLab, CMS, Map, and OSS) and an average SR across all websites.  Models marked with an asterisk (*) used data from the full WebArena dataset.", "section": "3.1 Environments and Baselines"}, {"content": "| [1,\u221e] | [1,1/0.95] | [1/0.95,1/0.5] | [1/0.5,\u221e] |\n|---|---|---|---|\n| 29.1 | 27.9 | 31.5 | 23.0 |", "caption": "Table 2: The impact of perplexity in replay buffer filtering of WebRL.", "description": "This table shows how different perplexity thresholds for filtering data in the replay buffer affect the performance of the WebRL model.  Perplexity is a measure of how surprising or unexpected the data is to the model.  Lower perplexity indicates the data is more familiar to the model, while higher perplexity indicates the data is more unexpected. The table demonstrates the optimal perplexity range for effective model training, highlighting the trade-off between using overly familiar data and overly unexpected data.  Using a narrow range of perplexity values results in the best model performance.", "section": "3.7 ABLATION STUDY"}, {"content": "| Test Dataset (%) | Our ORM (8B) | GPT-4 | Captioner + GPT-4 | GPT-4V |\n|---|---|---|---|---|\n| 80.8 | 71.9 | 72.6 | 71.2 |\n| Rollout (%) | 79.4 | 71.2 | 73.3 | 70.5 |", "caption": "Table 3: Evaluation on output-supervised methods (baselines adopted from\u00a0(Pan et\u00a0al., 2024)). Our ORM, without accessing proprietary GPT-4, performs the best among all.", "description": "This table presents a comparison of the performance of different outcome-supervised reward models on a specific task.  The models being compared include those using proprietary GPT-4 models as well as a new model proposed by the authors (Our ORM).  The key finding is that the authors' model outperforms all others without needing access to the costly GPT-4 APIs, highlighting its efficiency and effectiveness.", "section": "3.8 EVALUATION OF ORM"}, {"content": "| Method | Hyperparameter | Value |\n|---|---|---|\n| SFT | learning rate | 1e-5 |\n|  | lr scheduler type | cosine |\n|  | warmup ratio | 0.1 |\n|  | batch size | 128 |\n|  | training epoch | 1 |\n|  | cutoff length | 16384 |\n| Filtered BC | learning rate | 1e-6 |\n|  | lr scheduler type | constant |\n|  | batch size | 128 |\n|  | training epoch | 1 |\n|  | cutoff length | 16384 |\n|  | filtering threshold | 70th percentile |\n| AWR | actor learning rate | 1e-6 |\n|  | actor lr scheduler type | constant |\n|  | critic learning rate | 1e-6 |\n|  | critic lr scheduler type | constant |\n|  | batch size | 128 |\n|  | discount factor | 0.9 |\n|  | actor training epoch | 1 |\n|  | critic training epoch | 1 |\n| DigiRL | actor learning rate | 1e-6 |\n|  | actor lr scheduler type | constant |\n|  | critic learning rate | 1e-6 |\n|  | critic lr scheduler type | constant |\n|  | instruction value function lr | 1e-6 |\n|  | instruction value function lr scheduler type | constant |\n|  | batch size | 128 |\n|  | discount factor | 0.9 |\n|  | actor training epoch | 1 |\n|  | critic training epoch | 1 |\n|  | instruction value function epoch | 1 |\n|  | rollout temperature | 1 |\n|  | replay buffer size | 100000 |\n| WebRL | actor learning rate | 1e-6 |\n|  | actor lr scheduler type | constant |\n|  | critic learning rate | 1e-6 |\n|  | critic lr scheduler type | constant |\n|  | batch size | 128 |\n|  | discount factor | 0.9 |\n|  | actor training epoch | 1 |\n|  | critic training epoch | 1 |\n|  | rollout temperature | 1 |", "caption": "Table 4: The hyperparameters we employ in WebRL and baselines.", "description": "This table details the hyperparameter settings used for training the WebRL model and several baseline models.  It lists the specific hyperparameters (e.g., learning rate, scheduler type, batch size, etc.) and their corresponding values for each of the training methods: Supervised Fine-Tuning (SFT), Filtered Behavior Cloning (Filtered BC), Advantage Weighted Regression (AWR), DigiRL, and WebRL. This information allows for comparison of the training procedures used to generate the results and analysis of their impact on model performance.", "section": "3.1 Environments and Baselines"}, {"content": "| Hyperparameter | Value |\n|---|---| \n| learning rate | 5e-6 |\n| lr scheduler type | cosine |\n| warmup ratio | 0.1 |\n| batch size | 128 |\n| training epoch | 4 |\n| cutoff length | 16384 |", "caption": "Table 5: The hyperparameters we employ to train the ORM.", "description": "This table details the hyperparameters used during the training of the Outcome-Supervised Reward Model (ORM).  The ORM is a crucial component of the WEBRL framework, responsible for evaluating the success or failure of an agent's actions in completing web-based tasks.  The hyperparameters shown influence various aspects of the training process, such as the learning rate, optimizer, batch size, and the number of training epochs.", "section": "2.1 Reinforcement Learning for LLMs in Online Web Environments"}]