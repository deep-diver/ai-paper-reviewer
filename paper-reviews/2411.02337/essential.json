{"importance": "This paper is crucial for researchers working with LLMs and web agents. It **bridges the gap between open and proprietary LLMs** for web-based tasks, opening avenues for more accessible and powerful autonomous systems.  Its **novel self-evolving curriculum** and adaptive learning strategies offer significant improvements to the current state-of-the-art and **inspire future work in online reinforcement learning**. ", "summary": "WEBRL: A self-evolving online curriculum reinforcement learning framework empowers open LLMs to excel as high-performing web agents, surpassing proprietary models.", "takeaways": ["WEBRL trains effective web agents using open-source LLMs, overcoming limitations of expensive proprietary APIs.", "A self-evolving curriculum and robust reward model enhance agent training and performance.", "WEBRL significantly outperforms existing methods on WebArena-Lite benchmark, showcasing the effectiveness of online curriculum reinforcement learning."], "tldr": "Current LLM web agents heavily rely on costly proprietary APIs, while open LLMs lack decision-making capabilities. This paper introduces WEBRL, a novel framework addressing this issue by training high-performing web agents using open LLMs.  WEBRL tackles challenges like limited training tasks and sparse feedback through a self-evolving curriculum that generates new tasks from failed attempts, a robust reward model, and adaptive learning strategies. \nWEBRL successfully transforms open Llama-3.1 and GLM-4 models into proficient web agents.  Its performance surpasses proprietary LLMs like GPT-4-Turbo and achieves state-of-the-art results on the WebArena-Lite benchmark. This work demonstrates WEBRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, making autonomous web interactions more accessible and powerful.", "affiliation": "Tsinghua University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}}