{"references": [{"fullname_first_author": "Kiyoharu Aizawa", "paper_title": "Building a manga dataset \"manga109\" with annotations for multimedia applications", "publication_date": "2020-01-01", "reason": "This paper introduces Manga109, a benchmark dataset for manga understanding, which is used for comparison in this paper's experiments."}, {"fullname_first_author": "Jinbin Bai", "paper_title": "Meissonic: Revitalizing masked generative transformers for efficient high-resolution text-to-image synthesis", "publication_date": "2024-10-01", "reason": "This paper proposes Meissonic, a novel approach to text-to-image generation that improves efficiency and high-resolution capabilities, which is relevant to the methods explored in this paper."}, {"fullname_first_author": "Tsu-Jui Fu", "paper_title": "Guiding instruction-based image editing via multimodal large language models", "publication_date": "2023-01-01", "reason": "This paper explores using multimodal large language models for image editing, a technique that this paper adapts for customized manga generation."}, {"fullname_first_author": "Yuying Ge", "paper_title": "Seed-X: Multimodal models with unified multi-granularity comprehension and generation", "publication_date": "2024-04-01", "reason": "This paper introduces Seed-X, a multimodal large language model which this paper uses as a foundation for its multi-modal approach to manga generation."}, {"fullname_first_author": "Chang Liu", "paper_title": "Intelligent grimm-open-ended visual storytelling via latent diffusion models", "publication_date": "2024-01-01", "reason": "This paper addresses open-ended visual storytelling using diffusion models, a task related to the customized manga generation addressed in this paper."}]}