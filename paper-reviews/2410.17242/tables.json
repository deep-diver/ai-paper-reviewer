[{"figure_path": "2410.17242/tables/table_7_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "Table 1 quantitatively compares the performance of the proposed LVSM model against various baselines on object-level and scene-level view synthesis tasks, reporting PSNR, SSIM, and LPIPS metrics for different resolutions.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_9_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "Table 1 quantitatively compares the performance of LVSM against state-of-the-art methods on object-level and scene-level novel view synthesis tasks, using PSNR, SSIM, and LPIPS metrics.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_9_1.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "Table 1 quantitatively compares the performance of the proposed LVSM model against existing state-of-the-art methods on object-level and scene-level view synthesis tasks, reporting PSNR, SSIM, and LPIPS metrics for different resolutions.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/tables/table_17_0.html", "caption": "Table 1: Quantitative comparisons on object-level (left) and scene-level (right) view synthesis. For the object-level comparison, we matched the baseline settings with GS-LRM (Zhang et al., 2024) in both input and rendering under both resolution of 256 (Res-256) and resolution of 512 (Res-512). For the scene-level comparison, we use the same validation dataset used by pixelSplat (Charatan et al., 2024), which has 256 resolution.", "description": "Table 1 quantitatively compares the performance of the proposed LVSM model against several baseline methods on object-level and scene-level novel view synthesis tasks, reporting PSNR, SSIM, and LPIPS metrics.", "section": "4.3 EVALUATION AGAINST BASELINES"}]