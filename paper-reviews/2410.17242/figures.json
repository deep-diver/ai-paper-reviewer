[{"figure_path": "2410.17242/figures/figures_2_0.png", "caption": "Figure 1: LVSM supports feed-forward novel view synthesis from sparse posed image inputs (even from a single view) on both objects and scenes. LVSM achieves significant quality improvements compared with the previous SOTA method, i.e., GS-LRM (Zhang et al., 2024). (Please zoom in for more details.)", "description": "Figure 1 shows example results of novel view synthesis on both object and scene level using LVSM, comparing it with the previous state-of-the-art method.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17242/figures/figures_4_0.png", "caption": "Figure 2: LVSM model architecture. LVSM first patchifies the posed input images into tokens. The target view to be synthesized is represented by its Pl\u00fccker ray embeddings and is also tokenized. The input view and target tokens are sent to a full transformer-based model to predict the tokens that are used to regress the target view pixels. We study two LVSM transformer architectures, as a Decoder-only architecture (left) and a Encoder-Decoder architecture (right).", "description": "The figure illustrates the two transformer-based architectures of the Large View Synthesis Model (LVSM): a decoder-only architecture and an encoder-decoder architecture, both designed for novel view synthesis from sparse image inputs.", "section": "3.1 OVERVIEW"}, {"figure_path": "2410.17242/figures/figures_7_0.png", "caption": "Figure 3: Object-level visual comparison at 512 resolution. Given 4 sparse input posed images (leftmost column), we compare our high-res object-level novel-view rendering results with two baselines: Instant3D\u2019s Triplane-LRM (Li et al., 2023) and GS-LRM (Res-512) (Zhang et al., 2024) . Both our Encoder-Decoder and Decoder-Only models exhibit fewer floaters (first example) and fewer blurry artifacts (second example), compared to the baselines. Our Decoder-Only model effectively handles complex geometry, including small holes (third example) and thin structures (fourth example). Additionally, it preserves the details of high-frequency texture (last example).", "description": "Figure 3 shows a qualitative comparison of object-level novel view synthesis results from four different methods at 512 resolution, highlighting the superior performance of the proposed LVSM in handling complex geometries and high-frequency textures.", "section": "4.3 EVALUATION AGAINST BASELINES"}, {"figure_path": "2410.17242/figures/figures_8_0.png", "caption": "Figure 4: Scene-level visual comparison. We evaluate our encoder-decoder and decoder-only models on scene-level view synthesis, comparing them against the prior leading baseline methods, namely pixelSplat (Charatan et al., 2024), MVSplat (Chen et al., 2024), and GS-LRM (Zhang et al., 2024). Our methods exhibit fewer texture and geometric artifacts, generate more accurate and realistic specular reflections, and are closer to the ground truth images.", "description": "Figure 4 shows a qualitative comparison of scene-level view synthesis results between the proposed LVSM and several baseline methods, highlighting the improved quality and realism of LVSM.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.17242/figures/figures_16_0.png", "caption": "Figure 3: Object-level visual comparison at 512 resolution. Given 4 sparse input posed images (leftmost column), we compare our high-res object-level novel-view rendering results with two baselines: Instant3D\u2019s Triplane-LRM (Li et al., 2023) and GS-LRM (Res-512) (Zhang et al., 2024) . Both our Encoder-Decoder and Decoder-Only models exhibit fewer floaters (first example) and fewer blurry artifacts (second example), compared to the baselines. Our Decoder-Only model effectively handles complex geometry, including small holes (third example) and thin structures (fourth example). Additionally, it preserves the details of high-frequency texture (last example).", "description": "Figure 3 shows a comparison of object-level novel view rendering results from the proposed LVSM model against two baseline methods, highlighting the superior performance of LVSM in terms of fewer artifacts and better handling of complex geometries.", "section": "4.3 EVALUATION AGAINST BASELINES"}]