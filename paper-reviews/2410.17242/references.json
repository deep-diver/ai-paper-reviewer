{"references": [{" publication_date": "2020", "fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "reason": "This paper introduced NeRFs, a groundbreaking technique that revolutionized novel view synthesis by representing scenes as neural radiance fields.  It's foundational to many subsequent works in the field, including those focusing on improving NeRF's efficiency, generalization, and robustness, and directly influenced the design choices and motivation of the current work.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Jonathan T. Barron", "paper_title": "Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields", "reason": "This paper significantly improved the visual quality of NeRFs by addressing the problem of aliasing, a common issue in previous rendering methods. Its introduction of multiscale representations is crucial for achieving high-fidelity results and directly addresses a key limitation of earlier NeRF implementations. The proposed method's impact on the quality of generated novel views is considerable and it is directly relevant to the current paper's effort to enhance image quality.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Jonathan T. Barron", "paper_title": "Zip-nerf: Anti-aliased grid-based neural radiance fields", "reason": "This work further advanced NeRF technology by proposing an anti-aliased grid-based representation. It's important because grid-based NeRFs offer enhanced efficiency compared to their continuous counterparts, leading to faster rendering times and greater scalability. The concepts explored in Zip-NeRF are relevant to the present work, which also seeks to achieve increased efficiency and scalability.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Alex Yu", "paper_title": "PixelNeRF: Neural radiance fields from one or few images", "reason": "This paper introduced PixelNeRF, which showed that high-quality novel view synthesis can be performed with a single image. The significance lies in its ability to reduce the reliance on multiple images, a factor often limiting scalability and practicality in real-world applications. The paper's innovative approach is highly relevant to the present work, which focuses on achieving quality with a limited number of views.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Anpei Chen", "paper_title": "Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo", "reason": "This paper addressed the limitations of prior NeRF approaches by introducing a generalizable method for radiance field reconstruction from multi-view stereo inputs.  Its ability to handle sparse and noisy data improves flexibility and robustness, features the present work also strives to improve on. MvsNeRF's impact lies in its ability to reconstruct scenes efficiently from limited input views, thereby enabling wider applicability in diverse scenarios.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Qianqian Wang", "paper_title": "IBRNet: Learning multi-view image-based rendering", "reason": "IBRNet is a significant contribution to the field of image-based rendering (IBR), which has been heavily used as a method to generate novel views.  This paper significantly improved the performance of IBR by integrating learning-based methods, making it more robust and adaptable to various scenarios. The work directly addresses the issues of limited view extrapolation and sparse input problems, paving the way for efficient and scalable novel view synthesis.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Thomas M\u00fcller", "paper_title": "Instant neural graphics primitives with a multiresolution hash encoding", "reason": "This work introduced a significant improvement in the efficiency and scalability of NeRFs.  The proposed method uses a multiresolution hash encoding to drastically reduce memory footprint and rendering time compared to previous techniques, making it feasible to utilize these methods in real-time and resource-constrained environments. This improvement is highly relevant to the present paper's goal of achieving fast and efficient view synthesis.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Qiangeng Xu", "paper_title": "Point-NeRF: Point-based neural radiance fields", "reason": "Point-NeRF is a notable advancement in NeRFs by utilizing point-based representations instead of the traditional volumetric grids. This reduces memory consumption and improves efficiency while maintaining high visual fidelity, factors crucial for the scalability and practical use in real-world applications.  The approach aligns with the present study's interest in achieving efficient and scalable novel view synthesis.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Mehdi SM Sajjadi", "paper_title": "Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations", "reason": "This paper significantly advanced the field by introducing a geometry-free novel view synthesis approach that leverages transformer networks. This work directly addresses the challenges of traditional methods that rely on 3D priors and complex rendering equations, making it highly relevant to the current study's focus on minimizing 3D inductive biases for improved generalization and scalability.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "reason": "This paper presented 3D Gaussian splatting, a technique that improves the efficiency of radiance field rendering significantly.  The efficiency gains are due to the use of sparse representations and optimized rendering methods. This makes it crucial for real-time applications and highly relevant to the work presented here, which aims to achieve scalable and efficient novel view synthesis.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jonathan T. Barron", "paper_title": "Zip-nerf: Anti-aliased grid-based neural radiance fields", "reason": "This paper further advanced NeRF technology by proposing an anti-aliased grid-based representation. It's important because grid-based NeRFs offer enhanced efficiency compared to their continuous counterparts, leading to faster rendering times and greater scalability. The concepts explored in Zip-NeRF are relevant to the present work, which also seeks to achieve increased efficiency and scalability.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiahao Li", "paper_title": "Instant3D: Fast text-to-3D with sparse-view generation and large reconstruction model", "reason": "This work is significant because it introduces a fast and efficient method for text-to-3D generation, using sparse view inputs and a large reconstruction model. It's highly relevant to the present paper's work on novel view synthesis from sparse inputs because it deals with similar input constraints and addresses similar scalability and generalization challenges. Instant3D's efficiency in handling limited views is a key point of similarity and relevance to the current work.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "David Charatan", "paper_title": "pixelsplat: 3D gaussian splats from image pairs for scalable generalizable 3D reconstruction", "reason": "This paper introduced pixelsplat, which is an efficient and scalable method for generating 3D models from image pairs.  It's significant due to its efficiency in handling limited views and its generalizability across various scenes.  These factors align directly with the goals of the present work, which focuses on improving efficiency and generalizability in novel view synthesis from sparse views.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yicong Hong", "paper_title": "LRM: Large reconstruction model for single image to 3D", "reason": "This paper introduced the Large Reconstruction Model (LRM), a transformer-based approach that achieved state-of-the-art results in single image to 3D reconstruction.  The use of transformers is a key similarity to the presented method. It is important for the context of large transformer models as an alternative to 3D inductive biases, which is a key concept in this work.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kai Zhang", "paper_title": "GS-LRM: Large reconstruction model for 3D gaussian splatting", "reason": "GS-LRM is a significant recent work in novel view synthesis.  This paper combined the strengths of Gaussian splatting and large reconstruction models, significantly improving both quality and scalability.  The proposed method's improvements in efficiency and quality serve as a strong baseline and a direct comparison point for the new method described in the current paper.", "section_number": 4}, {" publication_date": "2016", "fullname_first_author": "Justin Johnson", "paper_title": "Perceptual losses for real-time style transfer and super-resolution", "reason": "This paper is highly relevant to the present work due to its introduction of perceptual loss, a crucial component of the loss function used to train the proposed LVSM. Perceptual loss is essential for generating images that are both visually realistic and high-quality, ensuring that generated images maintain the perceptual characteristics of real-world images. This is a key reason why the proposed LVSM provides high-quality images.", "section_number": 3}, {" publication_date": "2014", "fullname_first_author": "Diederik P Kingma", "paper_title": "Adam: A method for stochastic optimization", "reason": "This paper introduced the Adam optimizer, a widely used optimization algorithm in deep learning that is particularly effective for training deep neural networks, and highly relevant to the training of the transformer-based LVSM.  Adam's effectiveness in handling large datasets and complex models makes it a standard choice for training state-of-the-art models, including the one presented here.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Tri Dao", "paper_title": "Flashattention-2: Faster attention with better parallelism and work partitioning", "reason": "This paper significantly improves the efficiency of the attention mechanism used in transformers. By enhancing parallelism and optimizing work partitioning, Flashattention-2 accelerates training and inference, making it critical for large-scale models like the LVSM. The use of Flashattention-2 allows for the proposed LVSM to be trained on a larger dataset, improving both performance and scalability, and is therefore critical to the work presented here.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Alex Henry", "paper_title": "Query-key normalization for transformers", "reason": "This paper introduces query-key normalization (QK-Norm), a technique used to improve the stability of transformer-based models during training.  The use of QK-Norm is especially crucial for training large-scale models such as the one proposed in this work due to its ability to mitigate gradient explosion problems.", "section_number": 4}]}