{"references": [{" publication_date": "2020", "fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "reason": "This is a foundational paper in the field of Neural Radiance Fields (NeRFs), introducing a novel approach to novel view synthesis that uses neural networks to represent a scene's radiance field.  It has spurred a large amount of follow-up work and significantly impacted the field.  The paper's introduction of the concept of NeRFs and their ability to generate high-quality novel views from sparse input images is highly influential to this paper's approach.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Jonathan Barron", "paper_title": "Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields", "reason": "This paper builds upon the original NeRF paper, addressing the issue of anti-aliasing by introducing a multiscale representation of the radiance field.  This is important because it improves the visual quality of NeRF-generated images, a key concern addressed in this paper as well.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Alex Yu", "paper_title": "PixelNeRF: Neural radiance fields from one or few images", "reason": "This work is important for its focus on generating novel views from sparse inputs, which is a key challenge addressed by this paper.  It demonstrates the potential of NeRFs to work with limited data, aligning with this paper's approach of using sparse-view inputs.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Thomas M\u00fcller", "paper_title": "Instant neural graphics primitives with a multiresolution hash encoding", "reason": "This paper introduces an efficient method for representing 3D scenes using neural networks, addressing the computational demands of NeRFs.  This relates to the current paper's goal of creating a scalable novel view synthesis approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "reason": "This paper is important for its efficient approach to radiance field rendering, improving the speed of NeRF-based methods.  It contributes to this paper's focus on a computationally efficient novel view synthesis method.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Yicong Hong", "paper_title": "Lrm: Large reconstruction model for single image to 3d", "reason": "This paper focuses on large reconstruction models (LRMs) that utilize transformers for novel view synthesis, a related area of research that informs the work in this paper.  The large-scale nature of LRMs and their use of transformers informs the current paper's architectural choices.", "section_number": 1}, {" publication_date": "1996", "fullname_first_author": "Paul Debevec", "paper_title": "Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach", "reason": "This work is significant for its early exploration of hybrid geometry- and image-based approaches to view synthesis. It's a foundational paper in the field showing the integration of geometry and image data which influenced later approaches towards novel view synthesis.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "reason": "This is a cornerstone paper in the development of NeRFs, providing a fundamental framework for representing 3D scenes using neural networks.  Its impact on the field and its approach are central to the discussion of this paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Jonathan Barron", "paper_title": "Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields", "reason": "This paper is a significant advancement on the initial NeRF paper, improving the rendering quality by addressing the problem of anti-aliasing.  Improving image quality is also a major focus of this paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Alex Yu", "paper_title": "PixelNeRF: Neural radiance fields from one or few images", "reason": "This paper addresses the challenge of novel view synthesis from sparse inputs, a major focus of this paper. The ability to generate high-quality novel views from limited input is a significant achievement.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Thomas M\u00fcller", "paper_title": "Instant neural graphics primitives with a multiresolution hash encoding", "reason": "This paper significantly improves the efficiency of neural radiance field rendering, which is important in the context of this paper's focus on scalability and computational efficiency.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "reason": "This work focuses on real-time rendering using a novel representation that improves both the speed and quality of rendering, which is a significant contribution to the field and directly relevant to the efficiency focus of the current paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Qianqian Wang", "paper_title": "IBRNet: Learning multi-view image-based rendering", "reason": "This paper demonstrates a learning-based approach to image-based rendering, which provides a relevant alternative to traditional methods and to NeRF based methods. The use of learning-based techniques is also an important aspect of the current work.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Anpei Chen", "paper_title": "MVSNeRF: Fast generalizable radiance field reconstruction from multi-view stereo", "reason": "This work is important for its ability to reconstruct 3D scenes from multi-view images. This capability relates to the current paper's approach, and the ability to handle a large number of input views is considered important.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Mehdi Sajjadi", "paper_title": "Scene Representation Transformer: Geometry-free novel view synthesis through set-latent scene representations", "reason": "This paper demonstrates an approach to novel view synthesis without relying on explicit 3D representations, which is directly related to this paper's goal of reducing reliance on 3D inductive biases.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "David Charatan", "paper_title": "pixelsplat: 3D gaussian splats from image pairs for scalable generalizable 3D reconstruction", "reason": "This is an important recent work in the field, demonstrating state-of-the-art results using Gaussian splatting. Its performance and approach are compared to in the current work.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Anpei Chen", "paper_title": "MVSplat: Efficient 3D Gaussian splatting from sparse multi-view images", "reason": "This paper improves on Gaussian splatting, which is a related technique, specifically addressing the challenge of working with sparse data.  Improving efficiency while utilizing limited data is a key aspect of this paper.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yicong Hong", "paper_title": "Lrm: Large reconstruction model for single image to 3d", "reason": "This work is highly relevant because of its focus on large reconstruction models (LRMs) that leverage transformers to achieve novel view synthesis.  The use of transformers and the goal of minimal 3D inductive biases are directly relevant.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kai Zhang", "paper_title": "Gs-lrm: Large reconstruction model for 3d gaussian splatting", "reason": "This work builds upon the progress made by LRMs, improving the efficiency and scalability of novel view synthesis using Gaussian splatting.  This is a direct comparison point in the current paper's evaluation.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiahao Li", "paper_title": "Instant3D: Fast text-to-3d with sparse-view generation and large reconstruction model", "reason": "This work focuses on efficient 3D reconstruction from sparse views, which is directly relevant to this paper's objectives.  The use of sparse inputs and the overall reconstruction methodology are highly relevant.", "section_number": 2}]}