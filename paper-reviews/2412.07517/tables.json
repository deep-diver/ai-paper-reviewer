[{"content": "| Methods | Add-it | RF-Solver | RF-Inv. | Ours |\n|---|---|---|---|---| \n| Steps | 30 | 15 | 28 | 8 |\n| NFE | 60 | 60 | 56 | 18 |\n| Aux. Model | \u2713 | w/o | w/o | w/o |\n| Local Error | \\(O(\u0394t^2)\\) | \\(O(\u0394t^3)\\) | \\(O(\u0394t^2)\\) | \\(O(\u0394t^3)\\) |", "caption": "Table 1: Comparison of recent training-free inversion and editing methods based on FLUX, including inversion/denoising steps, NFEs (Number of Function Evaluations) for both inversion and editing, local truncation error orders for solving ODE, and the need for a pre-trained auxiliary model for editing. Our approach offers a simple yet effective solution to address the challenges.", "description": "This table compares training-free inversion and editing methods using FLUX, a ReFlow-based model. It considers factors like the number of steps, function evaluations (NFEs), error order of the ODE solver, and the need for a pre-trained auxiliary model. The comparison highlights the efficiency and effectiveness of the proposed 'FireFlow' method.", "section": "Method"}, {"content": "|                                                                    |\n| :------------------------------------------------------------------ |\n| Tewel et\u00a0al.\u00a0(2024) for Add-it, Wang et\u00a0al.\u00a0(2024) for RF-Solver, Rout et\u00a0al.\u00a0(2024) for RF-Inv. |", "caption": "Table 2: Quantitive results on Text-to-Image Generation.", "description": "This table compares three different Rectified Flow models using image generation metrics. The metrics include the number of function evaluations, Fr\u00e9chet Inception Distance (FID), and CLIP Score. It appears in the paper to show that the proposed model can generate high-quality images with few function evaluations.", "section": "5. Experiment"}, {"content": "| Methods | FLUX-dev | RF-Solver | Ours |\n|---|---|---|---| \n| Steps | 20 | 10 | 10 |\n| NFE (\u2193) | 20 | 20 | 11 |\n| FID (\u2193) | 26.77 | 25.93 | **25.16** |\n| CLIP Score (\u2191) | **31.44** | 31.35 | 31.42 |\n| ODE Solver | 1st-order | 2nd-order | 2nd-order |", "caption": "Table 3: Quantitative results for inversion and reconstruction using the FLUX-dev model (excluding the DDIM baseline). NFE includes both inversion and reconstruction function evaluations. Steps or computational costs are kept comparable across comparisons. Reconstruction is performed without leveraging latent features from the inversion process.", "description": "This table presents quantitative results for image inversion and reconstruction using the FLUX-dev model, comparing different methods based on varying steps and NFE (Number of Function Evaluations). Metrics used for evaluation include LPIPS, SSIM, and PSNR.  The table showcases the effectiveness of FireFlow. It demonstrates that the FireFlow can outperform baseline models in reconstruction quality while using fewer steps, hence offering a better speed and computation efficiency.", "section": "5.3. Inversion and Reconstruction"}, {"content": "|         | Steps | NFE\u2193 | LPIPS\u2193 | SSIM\u2191 | PSNR\u2191 |\n| :------ | :---: | :---: | :----: | :---: | :---: |\n| DDIM-Inv. |   50  |  100  | 0.2342 | 0.5872 | 19.72 |\n| RF-Solver |   30  |  120  | 0.2926 | 0.7078 | 20.05 |\n| ReFlow-Inv. |   30  |   60  | 0.5044 | 0.5632 | 16.57 |\n| Ours     |   30  |   62  | **0.1579** | **0.8160** | **23.87** |\n| RF-Solver |    5  |   20  | 0.5010 | 0.5232 | 14.72 |\n| ReFlow-Inv. |    9  |   18  | 0.8145 | 0.3828 | 15.29 |\n| Ours     |    8  |   18  | **0.4111** | **0.5945** | **16.01** |", "caption": "Table 4: Compare our approach with other editing methods on PIE-Bench.", "description": "Comparison of our approach with state-of-the-art image editing methods on PIE-Bench dataset, evaluating structure preservation, background preservation, CLIP similarity, inference steps, and number of function evaluations (NFE).", "section": "5.4. Inversion-based Semantic Image Editing"}, {"content": "| Method | Model | Structure \u2193 | Background Preservation | CLIP Similarity \u2191 | Steps | NFE \u2193 |\n|---|---|---|---|---|---|---| \n| **Prompt2Prompt** (Hertz et\u00a0al., 2022) | Diffusion | 0.0694 | PSNR \u2191: 17.87 <br> SSIM \u2191: 0.7114 | Whole: 25.01 <br> Edited: 22.44 | 50 | 100 |\n| **Pix2Pix-Zero** (Parmar et\u00a0al., 2023) | Diffusion | 0.0617 | PSNR \u2191: 20.44 <br> SSIM \u2191: 0.7467 | Whole: 22.80 <br> Edited: 20.54 | 50 | 100 |\n| **MasaCtrl** (Cao et\u00a0al., 2023) | Diffusion | 0.0284 | PSNR \u2191: 22.17 <br> SSIM \u2191: 0.7967 | Whole: 23.96 <br> Edited: 21.16 | 50 | 100 |\n| **PnP** (Tumanyan et\u00a0al., 2023b) | Diffusion | 0.0282 | PSNR \u2191: 22.28 <br> SSIM \u2191: 0.7905 | Whole: 25.41 <br> Edited: 22.55 | 50 | 100 |\n| **PnP-Inv.** (Ju et\u00a0al., 2024) | Diffusion | **0.0243** | PSNR \u2191: 22.46 <br> SSIM \u2191: 0.7968 | Whole: 25.41 <br> Edited: 22.62 | 50 | 100 |\n| **RF-Inversion** (Rout et\u00a0al., 2024) | ReFlow | 0.0406 | PSNR \u2191: 20.82 <br> SSIM \u2191: 0.7192 | Whole: 25.20 <br> Edited: 22.11 | 28 | 56 |\n| **RF-Solver** (Wang et\u00a0al., 2024) | ReFlow | 0.0311 | PSNR \u2191: 22.90 <br> SSIM \u2191: 0.8190 | Whole: **26.00** <br> Edited: **22.88** | 15 | 60 |\n| Ours | ReFlow | 0.0283 | PSNR \u2191: **23.28** <br> SSIM \u2191: **0.8282** | Whole: 25.98 <br> Edited: **22.94** | 15 | 32 |\n| Ours | ReFlow | **0.0271** | PSNR \u2191: **23.03** <br> SSIM \u2191: **0.8249** | Whole: **26.02** <br> Edited: 22.81 | **8** | **18** |", "caption": "Table 5: Per-image inference time for ReFlow inversion-based editing measured on an RTX 3090. The baseline is a vanilla ReFlow model utilizing 28 steps for both inversion and denoising.", "description": "This table presents the per-image inference time for different ReFlow inversion-based editing methods, including Vanilla ReFlow, RF-Inversion, RF-Solver, and the proposed method (Ours), measured on an RTX 3090.  The baseline is Vanilla ReFlow with 28 steps for both inversion and denoising. The table compares these methods at two different image resolutions (512x512 and 1024x1024) and shows the speedup achieved by each method compared to the baseline.", "section": "5.3. Inversion and Reconstruction"}, {"content": "|  | Resolution | Time Cost | Speedup | \n|---|---|---|---| \n| Vanilla ReFlow | 512x512 | 23.76s | 1.0x | \n| RF-Inversion | 512x512 | 23.36s | 1.02x | \n| RF-Solver | 512x512 | 25.31s | 0.94x | \n| Ours | 512x512 | **7.70s** | **3.09x** | \n| Vanilla ReFlow | 1024x1024 | 72.10s | 1.0x | \n| RF-Inversion | 1024x1024 | 71.35s | 1.01x | \n| RF-Solver | 1024x1024 | 78.80s | 0.92x | \n| Ours | 1024x1024 | **24.52s** | **2.94x** |", "caption": "Table 6: Comparison on different editing methods. Results on PIE Bench are reported. Guidance terms indicate the guidance ratio settings used in the FLUX model during the denoising process.", "description": "This table presents a comparison of various image editing methods evaluated on the PIE Bench dataset.  The methods differ in their guidance ratio settings within the FLUX model during the denoising phase of image generation.  Specifically, it examines the impact of adding query (Q), key (K), and value (V) features from the inversion process to the self-attention mechanism during the denoising process. The table reports metrics for structure preservation, background preservation, and CLIP similarity, alongside the number of steps and NFEs (Number of Function Evaluations) used during the editing process. This allows for a comparison of the editing performance and computational cost of the different guidance strategies.", "section": "5.4 Inversion-based Semantic Image Editing"}]