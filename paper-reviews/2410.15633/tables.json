[{"figure_path": "2410.15633/tables/table_6_1.html", "caption": "Table 2: Results (%) on LongBench in Limited Short Instruction Data Settings.", "description": "This table presents the performance of different models on the LongBench benchmark when trained with a limited amount of short instruction data, comparing various data selection methods.", "section": "4.2 IMPACT OF GATEAU"}, {"figure_path": "2410.15633/tables/table_7_1.html", "caption": "Table 4: Results (%) on MT-Bench in both Real-world and Limited Short Instruction Data Settings.", "description": "Table 4 presents the performance results of different models on the MT-Bench benchmark, categorized by real-world and limited short instruction data settings.", "section": "4.2 IMPACT OF GATEAU"}, {"figure_path": "2410.15633/tables/table_9_0.html", "caption": "Table 5: Results (%) of ablation study and scalability test.", "description": "Table 5 presents the ablation study and scalability test results, showing the impact of removing components from GATEAU and the performance of GATEAU on different sizes of LLMs.", "section": "4.2 IMPACT OF GATEAU"}, {"figure_path": "2410.15633/tables/table_17_0.html", "caption": "Table 1: Results (%) on LongBench in Real-world Settings. We use the ID to represent the dataset in LongBench, e.g., 1-1 is the ID of NarrativeQA dataset. More details can be found in Appendix C.2.", "description": "Table 1 presents the quantitative results of the LongBench benchmark in real-world settings, comparing different data selection methods and their impact on model performance across various tasks.", "section": "4.1 EXPERIMENTAL SETUP"}, {"figure_path": "2410.15633/tables/table_18_0.html", "caption": "Table 7: Detailed results (%) of MT-Bench.", "description": "Table 7 presents a detailed breakdown of the MT-Bench results, showing the performance of various models across different tasks and settings.", "section": "4.2 IMPACT OF GATEAU"}, {"figure_path": "2410.15633/tables/table_21_0.html", "caption": "Table 8: Further exploration of Homologous Model's Guidance.", "description": "Table 8 presents the ablation study of the Homologous Model's Guidance by removing extended context windows, normalization, and comparing it with non-homologous models and perplexity guidance, evaluating performance on LongBench, LongBench-Chat, and MT-Bench in both real-world and limited short instruction data settings.", "section": "4.2 IMPACT OF GATEAU"}]