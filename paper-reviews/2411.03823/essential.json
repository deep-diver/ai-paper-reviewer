{"importance": "This paper is crucial because **data contamination significantly impacts the reliability of multimodal large language model (MLLM) benchmarks** and model evaluations. The proposed MM-Detect framework directly addresses this critical issue, offering a novel approach to detect contamination in MLLMs. This work enhances the trustworthiness of MLLM research and opens avenues for improving model training and evaluation methods.  The findings are highly relevant to researchers working on MLLMs, model evaluation, and data quality assurance.  It encourages more rigorous evaluation practices and better data management strategies within the field.", "summary": "MM-Detect: a novel framework detects contamination in multimodal LLMs, enhancing benchmark reliability by identifying training set leakage and improving performance evaluations.", "takeaways": ["MM-Detect framework effectively identifies varying degrees of contamination in MLLMs.", "Training and test data leakage significantly impacts MLLM performance.", "Contamination can originate from both pre-training and fine-tuning phases of LLMs, affecting multiple phases of development."], "tldr": "Multimodal LLMs (MLLMs) show impressive performance but suffer from data contamination during training, affecting benchmark reliability and fair comparisons.  Existing detection methods for single-modal LLMs are ineffective for MLLMs due to their multiple training phases and different modalities.  This poses challenges in assessing the true performance of MLLMs and hinders progress in the field.\nThe paper introduces MM-Detect, a novel framework designed to detect contamination in MLLMs. It uses two innovative methods (Option Order Sensitivity Test and Slot Guessing for Perturbation Captions) to detect different types of contamination. MM-Detect is evaluated on various MLLMs across several datasets, showcasing its effectiveness in identifying contamination from various sources (pre-training, fine-tuning, and test data). The research reveals that contamination significantly enhances model performance on test sets. Furthermore, MM-Detect reveals potential contamination sources beyond multimodal training, originating from the pre-training phase of the LLMs.", "affiliation": "Chinese University of Hong Kong, Shenzhen", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}}