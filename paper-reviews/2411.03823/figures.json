[{"figure_path": "https://arxiv.org/html/2411.03823/x1.png", "caption": "Figure 1: A description of Multimodal Data Contamination (left) and the overview of proposed MM-Detect framework (right).", "description": "The figure is composed of two parts. The left part illustrates the concept of multimodal data contamination in large language models (LLMs). It shows how contamination can originate from two sources: unimodal contamination (pure text pre-training data) and cross-modal contamination (multimodal post-training data). Both sources can lead to contamination accumulation, affecting the performance and fairness of the MLLMs. The right part provides an overview of the proposed MM-Detect framework, which is designed to detect such contamination.  The framework consists of two main steps: generation of perturbed datasets using two novel methods (Option Order Sensitivity Test and Slot Guessing for Perturbation Captions), and detection of contamination using atomic metrics.  Different components are visually represented, including the input (VQA benchmark samples), data perturbation methods, the MLLM under testing, and the output (results evaluated using atomic metrics).", "section": "3 MM-DETECT"}, {"figure_path": "https://arxiv.org/html/2411.03823/extracted/5974597/figs/shuffle.png", "caption": "Figure 2: An example of Option Order Sensitivity Test applied to a contaminated model.", "description": "This figure illustrates the Option Order Sensitivity Test, a method used to detect contamination in models.  It shows two versions of a multiple-choice question.  The first shows the original order of options, and the second shows the options in a shuffled order.  A contaminated model, having memorized the correct answer's position in the original order, will likely produce a different answer when the order is shuffled. This difference highlights potential data contamination.", "section": "3.1 Option Order Sensitivity Test"}, {"figure_path": "https://arxiv.org/html/2411.03823/extracted/5974597/figs/cs-guessing.png", "caption": "Figure 3: An example of Slot Guessing for Perturbation Caption.", "description": "This figure illustrates the Slot Guessing for Perturbation Caption method used in the MM-Detect framework.  It shows an example where a caption describing an image is back-translated (e.g., from English to Chinese and back to English), and then key words are masked. The model is then tested to see if it can predict the masked words. The ability of the model to predict the masked words in the original caption, but not in the back-translated version, suggests that the model may have memorized the original caption during training, indicating potential data contamination.", "section": "3 MM-DETECT"}, {"figure_path": "https://arxiv.org/html/2411.03823/x2.png", "caption": "Figure 4: MM-Detect captures the increasing contamination levels of models on ScienceQA (test set) and reflects them in the atomic metrics.", "description": "Figure 4 illustrates the sensitivity of the MM-Detect framework to varying degrees of data contamination.  Three versions of the LLaVA-1.5-7B model were trained, each with a different level of contamination from the ScienceQA test set (10%, 50%, and 100%).  The graph shows how the correct rate (CR) and perturbed correct rate (PCR) change with the increasing contamination levels.  The difference between CR and PCR (\u0394), a key metric in MM-Detect, also decreases as contamination increases. This demonstrates that MM-Detect effectively captures the extent of data contamination and reflects this contamination in its atomic metrics. The figure provides visual evidence supporting the claim that MM-Detect is not just a binary contamination detector but can also quantify the degree of contamination.", "section": "5.2 MM-DETECT IS SENSITIVE TO CONTAMINATION DEGREES"}]