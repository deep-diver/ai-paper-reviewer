{"references": [{"fullname_first_author": "Marah Abdin", "paper_title": "Phi-3 technical report: A highly capable language model locally on your phone", "publication_date": "2024-04-15", "reason": "This paper is foundational to ShowUI's architecture because it introduces a highly capable language model that can operate locally on a phone, mirroring ShowUI's goal of efficient processing on devices."}, {"fullname_first_author": "Kanzhi Cheng", "paper_title": "Seeclick: Harnessing gui grounding for advanced visual gui agents", "publication_date": "2024-01-10", "reason": "This paper directly addresses the challenge of GUI visual grounding, a core problem ShowUI also tackles, making it a highly relevant comparative study."}, {"fullname_first_author": "Boyu Gou", "paper_title": "Navigating the digital world as humans do: Universal visual grounding for gui agents", "publication_date": "2024-10-05", "reason": "This paper offers a state-of-the-art approach to GUI visual grounding, which serves as a benchmark and comparison for ShowUI's performance."}, {"fullname_first_author": "Wentong Chen", "paper_title": "GUICourse: From general vision language models to versatile GUI agents", "publication_date": "2024-06-11", "reason": "This paper explores the transition from general vision-language models to specialized GUI agents, which is the same transition ShowUI makes, making it a key comparative work."}, {"fullname_first_author": "Peng Wang", "paper_title": "Qwen2-VL: Enhancing vision-language model's perception of the world at any resolution", "publication_date": "2024-01-01", "reason": "ShowUI is built upon this vision-language model, Qwen2-VL, making it the most direct foundational model that underpins ShowUI's capabilities."}]}