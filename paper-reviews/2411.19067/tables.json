[{"content": "| Method | Image Encoder | Text Encoder | RefCOCO val | RefCOCO testA | RefCOCO testB | RefCOCO+ val | RefCOCO+ testA | RefCOCO+ testB | RefCOCOg val | RefCOCOg test | \n|---|---|---|---|---|---|---|---|---|---|---| \n| *Standard: Training on the training split of each dataset.* |  |  |  |  |  |  |  |  |  |  | \n| **mIoU** |  |  |  |  |  |  |  |  |  |  | \n| CRIS [49] | RN101 | CLIP | 70.47 | 73.18 | 66.10 | 62.27 | 68.08 | 53.68 | 59.87 | 60.36 | \n| ETRIS [54] | RN101 | CLIP | 71.06 | 74.11 | 66.66 | 62.23 | 68.51 | 52.79 | 60.28 | 60.42 | \n| RefTR [25] | RN101 | BERT | 74.34 | 76.77 | 70.87 | 66.75 | 70.58 | 59.40 | 66.63 | 67.39 | \n| LAVT [56] | Swin-B | BERT | 74.46 | 76.89 | 70.94 | 65.81 | 70.97 | 59.23 | 63.34 | 63.62 | \n| CGFormer [46] | Swin-B | BERT | 76.93 | 78.70 | 73.32 | 68.56 | 73.76 | 61.72 | 67.57 | 67.83 | \n| MaskRIS | Swin-B | BERT | **78.35** | **80.24** | **76.06** | **71.68** | **76.73** | **64.50** | **69.31** | **69.42** | \n| **oIoU** |  |  |  |  |  |  |  |  |  |  | \n| LAVT [56] | Swin-B | BERT | 72.73 | 75.82 | 68.79 | 62.14 | 68.38 | 55.10 | 61.24 | 62.09 | \n| CGFormer [46] | Swin-B | BERT | 74.75 | 77.30 | 70.64 | 64.54 | 71.00 | 57.14 | 64.68 | 65.09 | \n| LQMFormer [44] | Swin-B | BERT | 74.16 | 76.82 | 71.04 | 65.91 | 71.84 | 57.59 | 64.73 | 66.04 | \n| NeMo [10] | Swin-B | BERT | 74.48 | 76.32 | 71.51 | 62.86 | 69.92 | 55.56 | 64.40 | 64.80 | \n| ReMamber [55] | Mamba-B | CLIP | 74.54 | 76.74 | 70.89 | 65.00 | 70.78 | 57.53 | 63.90 | 64.00 | \n| CARIS<sup>\u2020</sup> [33] | Swin-B | BERT | 74.67 | 77.63 | 71.71 | 66.17 | 71.70 | 57.46 | 64.66 | 65.45 | \n| MaskRIS | Swin-B | BERT | **76.49** | **78.96** | **73.96** | **67.54** | **74.46** | **59.39** | **65.55** | **66.50** | \n| *Combined: Training on the combination of three datasets.* |  |  |  |  |  |  |  |  |  |  | \n| **oIoU** |  |  |  |  |  |  |  |  |  |  | \n| PolyFormer [31] | Swin-B | BERT | 74.82 | 76.64 | 71.06 | 67.64 | 72.89 | 59.33 | 67.76 | 69.05 | \n| CARIS<sup>\u2020</sup> [33] | Swin-B | BERT | 76.63 | 79.40 | 73.52 | 68.03 | 73.70 | 60.41 | 67.95 | 69.75 | \n| MaskRIS | Swin-B | BERT | **78.71** | **80.64** | **75.10** | **70.26** | **75.15** | **62.83** | **69.12** | **71.09** |", "caption": "Table 1: Comparison with state-of-the-art methods on three benchmark datasets. \u2020\u2020\\dagger\u2020 denotes the reproduced results across all experiments.", "description": "This table presents a comparison of the MaskRIS model's performance against other state-of-the-art Referring Image Segmentation (RIS) models on three benchmark datasets: RefCOCO, RefCOCO+, and RefCOCOg.  The comparison uses several metrics to evaluate performance, including mean Intersection over Union (mIoU), overall Intersection over Union (oIoU), and precision at various thresholds (P@X).  The table shows the performance of each model broken down by the image and text encoders used and indicates whether the results were reproduced by the authors (denoted by \u2020\u2020).", "section": "4.2 Main Results"}, {"content": "| Method | Image Encoder | Text Encoder | RefCOCO val | RefCOCO testA | RefCOCO testB |\n|---|---|---|---|---|---| \n| *Weakly-supervised approach* |  |  |  |  |  |\n| **mIoU** |  |  |  |  |  |\n| TRIS [30] | RN50 | CLIP | 31.17 | 32.43 | 29.56 |\n| TRIS [30] + MaskRIS | RN50 | CLIP | 32.60 (+1.43) | 34.26 (+1.83) | 30.32 (+0.76) |\n| SaG [20] | ViT-S/16 | BERT | 37.21 | 36.60 | 39.41 |\n| SaG [20] + MaskRIS | ViT-S/16 | BERT | 38.85 (+1.64) | 37.70 (+1.1) | 40.20 (+0.79) |\n| *Fully-supervised approach* |  |  |  |  |  |\n| **mIoU** |  |  |  |  |  |\n| CRIS [49] | RN50 | CLIP | 69.52 | 72.72 | 64.70 |\n| CRIS [49] + MaskRIS | RN50 | CLIP | 70.73 (+1.21) | 74.06 (+1.34) | 66.82 (+2.12) |\n| ETRIS [54] | R101 | CLIP | 71.06 | 74.11 | 66.66 |\n| ETRIS [54] + MaskRIS | R101 | CLIP | 72.39 (+1.33) | 74.99 (+0.88) | 68.55 (+1.89) |\n| **oIoU** |  |  |  |  |  |\n| LAVT [56] | Swin-B | BERT | 72.73 | 75.82 | 68.79 |\n| LAVT [56] + MaskRIS | Swin-B | BERT | 73.79 (+1.06) | 76.57 (+0.75) | 70.31 (+1.52) |\n| CARIS\u2020 [33] | Swin-B | BERT | 74.67 | 77.63 | 71.71 |\n| CARIS [33] + MaskRIS | Swin-B | BERT | 76.49 (+1.82) | 78.96 (+1.33) | 73.96 (+2.25) |", "caption": "Table 2: Compatibility of MaskRIS with various RIS methods. MaskRIS consistently enhances existing methods in both fully supervised and weakly supervised settings.", "description": "This table demonstrates the versatility and effectiveness of MaskRIS by showcasing its compatibility with various existing Referring Image Segmentation (RIS) methods.  It compares the performance of several state-of-the-art RIS models, both fully supervised and weakly supervised, with and without the MaskRIS augmentation strategy. The results clearly indicate that MaskRIS consistently improves the performance of all tested models, highlighting its ability to enhance various RIS approaches.", "section": "4.2 Main Results"}, {"content": "| IM | TM | DCL | P@0.5 | P@0.7 | P@0.9 | oIoU |\n|---|---|---|---|---|---|---| \n| \u2718 | \u2718 | \u2718 | 87.73 | 80.20 | 39.60 | 74.67 |\n| \u2714 | \u2718 | \u2718 | 87.76 | 80.52 | 38.73 | 75.31 |\n| \u2718 | \u2714 | \u2718 | 87.72 | 80.45 | 39.26 | 75.32 |\n| \u2714 | \u2714 | \u2718 | 88.00 | 81.35 | 40.11 | 75.71 |\n| \u2714 | \u2718 | \u2714 | 88.60 | 81.86 | 41.08 | 76.02 |\n| \u2718 | \u2714 | \u2714 | 88.34 | 81.19 | 39.24 | 75.76 |\n| \u2714 | \u2714 | \u2714 | **88.62** | **81.95** | **41.19** | **76.49** |", "caption": "Table 3: Impact of each component of MaskRIS on the RefCOCO validation set, where IM (TM) refers to image (text) masking.", "description": "This table presents the ablation study results evaluating the impact of each component of the MaskRIS model on the RefCOCO validation set.  It shows the performance (measured by mean Intersection over Union or mIoU) when using only image masking (IM), only text masking (TM), both image and text masking together, and finally, the full MaskRIS model (including the Distortion-aware Contextual Learning or DCL).  The results demonstrate the individual and combined contributions of each component to the overall performance improvement.", "section": "4.3 Ablation Study"}, {"content": "| IM ratio | TM ratio | $p_m$ | $p_r$ | $p_u$ | oIoU |\n|---|---|---|---|---|---| \n| - | 0.15 | 0.8 | 0.1 | 0.1 | 75.76 |\n| - | 0.15 | 0.8 | 0.2 | 0 | 75.43 |\n| - | 0.15 | 0.5 | 0.5 | 0 | 75.70 |\n| - | 0.50 | 0.5 | 0.5 | 0 | 74.88 |\n| - | 0.75 | 0.5 | 0.5 | 0 | 74.14 |\n| 0.25 | 0.15 | 0.8 | 0.1 | 0.1 | 76.07 |\n| 0.50 | 0.15 | 0.8 | 0.1 | 0.1 | 76.43 |\n| 0.75 | 0.15 | 0.8 | 0.1 | 0.1 | **76.49** |", "caption": "Table 4: Impact of the masking ratio on the RefCOCO validation set. When a word wisubscript\ud835\udc64\ud835\udc56w_{i}italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is selected based on the masking ratio, it has a pmsubscript\ud835\udc5d\ud835\udc5ap_{m}italic_p start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT probability of being masked with a [MASK] token, a prsubscript\ud835\udc5d\ud835\udc5fp_{r}italic_p start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT probability of being replaced with a random word from the vocabulary, and a pusubscript\ud835\udc5d\ud835\udc62p_{u}italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT probability of remaining unchanged.", "description": "This table details the effects of varying the masking ratio during model training on the RefCOCO validation dataset.  The masking ratio determines the likelihood of a word being masked (replaced with [MASK]), replaced with a random word, or remaining unchanged. The table shows how different combinations of these probabilities affect the overall model performance (measured by oIoU).", "section": "4.3. Ablation Study"}, {"content": "|                   | Patch-wise | Grid-wise [11] | Block-wise [2] | Cutout [8] |\n|-----------------|-------------|-----------------|----------------|------------|\n| oIoU             | **76.49**   | 76.14           | 75.90           | 76.07      |", "caption": "Table A: Impact of mask sampling strategy. The performance (oIoU) is evaluated across various mask sampling strategies on the RefCOCO validation set.", "description": "This table presents a comparison of different image masking strategies used for data augmentation in referring image segmentation.  The strategies compared include patch-wise, grid-wise, block-wise, and cutout methods.  The performance metric used is the overall Intersection over Union (oIoU) score, calculated on the RefCOCO validation set. The table helps to determine the effectiveness of each masking strategy in improving model robustness and generalization ability.  The results show how each method affects the final oIoU score.", "section": "A Ablation Study"}, {"content": "| Method | Epoch | val | testA | testB |\n|---|---|---|---|---|\n| CARIS<sup>\u2020</sup> [33] | 50 | 74.67 | 77.63 | 71.71 |\n| CARIS<sup>\u2020</sup> [33] | 100 | 74.80 | 77.38 | 70.63 |\n| MaskRIS | 25 | 75.87 | 77.99 | 73.51 |\n| MaskRIS | 50 | **76.49** | **78.96** | **73.96** |", "caption": "Table B: Comparison of computational cost. All results (oIoU) are evaluated on the RefCOCO dataset. MaskRIS outperforms CARIS even with half of the training epochs.", "description": "This table compares the computational cost and performance of the MaskRIS and CARIS models on the RefCOCO dataset.  The results show that MaskRIS achieves better performance (measured by mean Intersection over Union, or oIoU) even when trained with half the number of epochs compared to CARIS.  This highlights MaskRIS's efficiency in terms of both computational resources and training time.", "section": "A. Ablation Study"}, {"content": "| ps | 8 | 16 | 32 | 64 | 112 |\n|---|---|---|---|---|---| \n| oIoU | **76.58** | 76.49 | 76.49 | 76.47 | 76.01 |", "caption": "Table C: Impact of patch size on image masking. The performance (oIoU) is evaluated across different patch sizes on the RefCOCO validation set. ps denotes the patch size.", "description": "This table investigates the effect of varying the patch size during image masking on the performance of the MaskRIS model.  The experiment is conducted on the RefCOCO validation set. The metric used to evaluate performance is the overall intersection over union (oIoU). The table displays the oIoU scores obtained using different patch sizes (ps). This allows for an analysis of how the patch size impacts the model's ability to handle masked regions in images and ultimately affects the overall accuracy of referring image segmentation.", "section": "A Ablation Study"}, {"content": "| \u03bb | 0.1 | 0.25 | 0.5 | 0.75 | 1.0 |\n|---|---|---|---|---|---| \n| oIoU | 75.48 | **76.62** | 76.49 | 76.16 | 74.67 |", "caption": "Table D: Impact of \u03bb\ud835\udf06\\lambdaitalic_\u03bb on the DCL procedure. The performance (oIoU) is evaluated across various \u03bb\ud835\udf06\\lambdaitalic_\u03bb on the RefCOCO validation set.", "description": "This table presents the ablation study results on the impact of the hyperparameter lambda (\u03bb) within the Distortion-aware Contextual Learning (DCL) framework of the MaskRIS model.  Different values of \u03bb are tested, ranging from 0.1 to 1.0.  Each value represents a different weighting between the distillation loss (Ldist) and the cross-entropy loss (Lce) during training. The primary metric used to evaluate the performance is the overall Intersection over Union (oIoU) calculated on the RefCOCO validation set. The goal is to determine the optimal value of \u03bb that balances the contribution of both losses for improved model performance and robustness.", "section": "A.4 Impact of Hyperparameters"}]