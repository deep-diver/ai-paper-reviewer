{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-31", "reason": "This paper introduces Flamingo, a visual language model that is highly relevant to the task of referring image segmentation, achieving state-of-the-art results on several benchmarks."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-06-01", "reason": "This paper introduces the Masked Autoencoder (MAE) framework, which inspired the masking strategies used in the proposed method, significantly improving the model's performance and robustness."}, {"fullname_first_author": "Sun-Ao Liu", "paper_title": "CARIS: Context-aware referring image segmentation", "publication_date": "2023-12-31", "reason": "This paper presents CARIS, a strong baseline model for referring image segmentation, which serves as a foundation for the proposed method, demonstrating significant improvements in performance."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2018-12-31", "reason": "This paper introduces BERT, a powerful language model widely used in many vision-language tasks, providing strong text representations used in this paper's approach."}, {"fullname_first_author": "Ze Liu", "paper_title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "publication_date": "2021-10-01", "reason": "This paper introduces Swin Transformer, a highly effective image encoder used as the backbone for the proposed method, improving its performance on various image segmentation benchmarks."}]}