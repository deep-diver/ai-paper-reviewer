{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of diffusion models, introducing the core denoising diffusion process that underpins many modern image generation techniques."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-12-01", "reason": "This paper significantly improved the resolution and efficiency of diffusion models, making them practical for high-quality image generation."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial element for connecting image and text data, enabling multimodal applications and improved control in generative models."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-10-01", "reason": "ControlNet, presented in this paper, is a highly influential method that directly addresses image conditioning by adding control signals, a critical advancement for controllable generation."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "This paper introduces Diffusion Transformers (DiT), a novel architecture that combines the strengths of diffusion models and transformers for superior image generation quality, forming the basis of the model used in the current paper."}]}