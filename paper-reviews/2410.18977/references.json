{"references": [{" publication_date": "2022b", "fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "reason": "This paper is foundational for the field, introducing a novel approach to human motion generation using diffusion models.  Its influence is evident in many of the other papers cited, making it a key piece of the overall research landscape. The innovative use of diffusion models for motion generation has significantly advanced the state-of-the-art.", "section_number": 2}, {" publication_date": "2022a", "fullname_first_author": "Guy Tevet", "paper_title": "Motionclip: Exposing human motion generation to clip space", "reason": "This work is highly relevant because it directly addresses the problem of generating high-quality human motions from text descriptions.  By leveraging CLIP, it provides a bridge between visual and textual representations, crucial for understanding text-driven motion generation.  Its methodology has likely influenced other papers in the text-driven motion generation field.", "section_number": 2}, {" publication_date": "2024b", "fullname_first_author": "Chuan Guo", "paper_title": "Momask: Generative masked modeling of 3d human motions", "reason": "This paper tackles the challenge of generating diverse and realistic human motions by introducing a novel masked modeling approach. The idea of using masking for motion generation has likely influenced other research in the area, making this a significant contribution to the state-of-the-art.", "section_number": 2}, {" publication_date": "2023a", "fullname_first_author": "Jiaman Li", "paper_title": "Masked motion completion for human motion prediction", "reason": "This paper deals with the critical problem of completing missing parts of motion sequences. This is a crucial issue in many real-world scenarios, where human motion data may be incomplete or noisy.  The techniques developed could be used in conjunction with other motion generation methods to improve overall performance.", "section_number": 2}, {" publication_date": "2024a", "fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "reason": "This paper focuses on generating realistic human motions from text descriptions, a key challenge in the field.  It emphasizes the diversity and naturalness of the generated motions, a crucial aspect often overlooked in purely quantitative evaluations. This work is highly relevant to the current research, which strives to achieve similar goals.", "section_number": 2}, {" publication_date": "2024b", "fullname_first_author": "Chuan Guo", "paper_title": "Tm2t: Stochastic and tokenized modeling for the reciprocal generation of 3d human motions and texts", "reason": "This paper addresses the important issue of reciprocal text and motion generation. The capability to generate both text from motion and motion from text is crucial for establishing a strong understanding of the interrelationship between text and motion, which is directly related to the goal of this research on motion editing. The techniques presented may have significantly influenced other approaches.", "section_number": 2}, {" publication_date": "2022b", "fullname_first_author": "Chuan Guo", "paper_title": "Tm2t: Stochastic and tokenized modeling for the reciprocal generation of 3d human motions and texts", "reason": "This paper is highly relevant as it addresses the crucial problem of generating realistic human motions from text descriptions, a task that is directly related to the goal of improving motion editing. The techniques developed in this work for text and motion correspondence likely influenced the current research on motion editing, making this work highly significant.", "section_number": 2}, {" publication_date": "2023b", "fullname_first_author": "Jianrong Zhang", "paper_title": "RemoDiffuse: Retrieval-augmented motion diffusion model", "reason": "This work shows significant advancement in motion generation by incorporating retrieval mechanisms, significantly improving the quality and diversity of the output.  It represents a notable step forward in the field, and its techniques could be adapted or integrated with the current research on motion editing.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Wenxun Dai", "paper_title": "Motionlcm: Real-time controllable motion generation via latent consistency model", "reason": "This paper is highly relevant due to its focus on real-time controllable motion generation, which is a practical application of motion editing. The techniques used for real-time control are very relevant to the current research, which aims to achieve similar interactive capabilities.", "section_number": 2}, {" publication_date": "2024a", "fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "reason": "This paper is highly relevant to the current work because of its focus on generating high-quality and diverse 3D human motions directly from text.  The techniques employed for achieving high diversity are highly relevant to the current research on motion editing, which aims for similar results.", "section_number": 2}, {" publication_date": "2022b", "fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "reason": "This work is highly influential as it introduces the use of diffusion models for human motion generation, a very novel approach at the time.  It laid the foundation for much of the later work in this area, including the current research, which also leverages diffusion models.", "section_number": 2}, {" publication_date": "2023b", "fullname_first_author": "Jianrong Zhang", "paper_title": "Motiondiffuse: Text-driven human motion generation with diffusion model", "reason": "This paper is relevant due to its use of diffusion models for text-driven human motion generation, a method widely used in recent research.  The techniques for diffusion-based generation could be adapted and applied to the problem of motion editing.", "section_number": 2}, {" publication_date": "2023a", "fullname_first_author": "Jianrong Zhang", "paper_title": "Generating human motion from textual descriptions with discrete representations", "reason": "This paper shows a key advancement in using discrete representations for motion generation, directly impacting the quality and efficiency of the model.  The techniques presented may have influenced other research in the text-driven motion generation and editing field.", "section_number": 2}, {" publication_date": "2020a", "fullname_first_author": "Kfir Aberman", "paper_title": "Skeleton-aware networks for deep motion retargeting", "reason": "This paper is relevant because of its focus on motion retargeting, a sub-problem of motion editing.  The use of skeleton-aware networks for retargeting is a key advancement that could have influenced the current work on improving motion editing techniques. The techniques presented are very relevant to the goal of improving motion editing.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Hyemin Ahn", "paper_title": "Text2action: Generative adversarial synthesis from language to action", "reason": "This early work is important as it addresses the fundamental problem of translating textual descriptions into actions.  It laid the ground work for much of the later research in text-driven human motion generation, which is very relevant to the current research on improving motion editing.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Xiao Lin", "paper_title": "Human motion modeling using dvgans", "reason": "This is highly relevant because of its early adoption of generative adversarial networks (GANs) for human motion modeling. GANs have been influential in many motion generation works, therefore understanding the contribution and limitations of this early application of GANs to this problem is important.", "section_number": 2}, {" publication_date": "2015", "fullname_first_author": "Olaf Ronneberger", "paper_title": "U-net: Convolutional networks for biomedical image segmentation", "reason": "This paper is extremely important as the architecture of U-Net is used as the basis of the MotionCLR architecture. U-Net is a very successful architecture in many computer vision applications, so this paper contributes greatly to the understanding and success of the current work.", "section_number": 3}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This work introduced the transformer architecture, which has become ubiquitous in many areas of natural language processing and computer vision and is directly used in MotionCLR. It is a foundational paper in deep learning and its influence is undeniable in the current research.", "section_number": 3}, {" publication_date": "2022b", "fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "reason": "This is a highly important paper as it presents the first diffusion-based model for human motion generation. This work introduces several novel techniques and the model has been highly influential in many later works. The work is directly used in this work, forming its basis.", "section_number": 3}]}