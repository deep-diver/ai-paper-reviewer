[{"figure_path": "2410.18977/tables/table_7_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a quantitative comparison of MotionCLR against several state-of-the-art methods for text-driven human motion generation on the HumanML3D dataset.  The table evaluates the methods across multiple metrics: Top 1, Top 2, and Top 3 R-Precision (higher is better, indicating better text-motion matching), FID (Fr\u00e9chet Inception Distance; lower is better, indicating higher motion quality), MM-Dist (Multi-Modal Distance; lower is better, representing lower discrepancy between the generated and real motion), and Multi-Modality (higher is better, denoting higher motion diversity).  MotionCLR demonstrates competitive performance across most metrics, particularly excelling in R-Precision (text-motion alignment), suggesting a strong ability to generate motions faithfully representing the input text. The table also includes results for MotionCLR using two different sampling methods (DDIM and DPM-solver), showing consistent performance.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_10_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a comparison of MotionCLR's performance against several state-of-the-art methods on the HumanML3D dataset.  The table evaluates the models based on three key metrics: Motion Quality (measured by Fr\u00e9chet Inception Distance or FID, lower is better), Motion Diversity (assessed using MultiModality, higher is better), and Text-Motion Matching (evaluated using Recall at Precision@k or R-Precision, higher is better).  Results are shown for Top 1, Top 2, and Top 3 ranks, reflecting the models' ability to generate accurate and diverse motions that match the textual descriptions.  The table also includes results for MotionCLR using two different sampling methods (DDIM and DPM-solver), indicated by the asterisk (*).  Overall, the table demonstrates MotionCLR's competitive performance in generating high-quality and diverse human motions while achieving strong text-motion alignment.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_14_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a quantitative comparison of MotionCLR against several state-of-the-art methods on the HumanML3D dataset.  The comparison uses four metrics: Top-1, Top-2, and Top-3 R-Precision (higher is better, indicating better text-motion matching), FID (Fr\u00e9chet Inception Distance; lower is better, indicating higher visual fidelity), MM-Dist (Multi-Modality Distance; lower is better, representing more diverse motion generation), and Multi-Modality (higher is better, indicating more diverse motion generation).  The table shows MotionCLR's performance with both DDIM and DPM-solver sampling methods, highlighting its competitive performance in motion generation quality and diversity, and superior text-motion matching.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_21_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a comparison of MotionCLR's performance against several state-of-the-art methods on the HumanML3D dataset.  The table evaluates model performance across multiple metrics, including Top 1, Top 2, and Top 3 R-Precision (measuring the accuracy of top motion predictions), FID (Fr\u00e9chet Inception Distance, a measure of generated motion quality), MM-Dist (Multi-Modal Distance, quantifying the diversity of generated motions), and Multi-Modality (another diversity metric).  MotionCLR is shown to perform comparably to or better than existing methods on most of these metrics, demonstrating its effectiveness in both generating high-quality and diverse motions.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_22_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a quantitative comparison of the MotionCLR model against several state-of-the-art methods on the HumanML3D dataset.  The comparison focuses on several metrics: Top 1, Top 2, and Top 3 R-Precision (higher is better), reflecting the model's accuracy in motion generation; Fr\u00e9chet Inception Distance (FID) (lower is better), measuring the quality of generated motions; and Multi-Modality (higher is better) and MM-Dist (lower is better) scores, evaluating the diversity and distance of generated motions from real motions, respectively.  The table includes results for MotionCLR using two different sampling methods, DDIM and DPM-solver, indicated by an asterisk.  The results show MotionCLR achieves competitive performance compared to existing methods, particularly demonstrating higher text-motion alignment and improved diversity.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_22_1.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a comparison of MotionCLR's performance against several state-of-the-art methods on the HumanML3D dataset.  The table evaluates the models based on metrics assessing motion quality (FID), motion diversity (Multi-Modality), and text-motion matching (R-Precision).  Results are shown for Top 1, Top 2, and Top 3 precision, indicating the rank of the generated motion's similarity to ground truth.  FID measures the distance between the generated motion distribution and the real motion distribution, with lower values indicating better fidelity.  Multi-Modality assesses the diversity of the generated motions for a given text prompt, with higher values reflecting greater diversity. R-Precision quantifies the text-motion matching accuracy. MotionCLR's results are presented for both DDIM sampling and DPM-solver sampling techniques, showcasing the model's performance under different sampling strategies.", "section": "5 Experiments"}, {"figure_path": "2410.18977/tables/table_23_0.md", "caption": "Table 1: Comparison with different methods on the HumanML3D dataset. The \"*\" notation denotes the DDIM sampling inference design choice and the other is the DPM-solver sampling choice.", "description": "Table 1 presents a comparison of MotionCLR's performance against several state-of-the-art methods on the HumanML3D dataset.  The table uses several metrics to assess the methods including Top 1, Top 2, and Top 3 R-Precision (higher is better), measuring the accuracy of the top predictions.  FID (Fr\u00e9chet Inception Distance) is included (lower is better), which evaluates the quality of generated motion distribution.  MM-Dist (Multi-Modality Distance) and Multi-Modality are also included (higher is better), reflecting motion diversity. The table shows MotionCLR achieving comparable performance with state-of-the-art methods on generation quality (FID) and diversity (MultiModality), and outperforming them on R-Precision (text-motion matching).  The table also indicates that using different sampling methods (DDIM vs. DPM-solver) doesn't drastically affect the results.", "section": "5 Experiments"}]