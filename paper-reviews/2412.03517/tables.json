[{"content": "| Model | Views | Easy PSNR\u2191 | Easy SSIM\u2191 | Easy LPIPS\u2193 | Easy DISTS\u2193 | Medium PSNR\u2191 | Medium SSIM\u2191 | Medium LPIPS\u2193 | Medium DISTS\u2193 | Hard PSNR\u2191 | Hard SSIM\u2191 | Hard LPIPS\u2193 | Hard DISTS\u2193 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n| MotionCtrl [36] | 1 | 15.0741 | 0.6071 | 0.3616 | 0.0999 | 12.0674 | 0.5667 | 0.5439 | 0.1584 | 11.6381 | 0.5276 | 0.5762 | 0.1633 |\n| CameraCtrl [9] | 1 | 13.6082 | 0.5050 | 0.4234 | 0.1458 | 11.9639 | 0.4934 | 0.5217 | 0.1957 | 11.7599 | 0.4716 | 0.5478 | 0.2021 |\n| DUSt3R [34] | 1 | 13.9443 | 0.5582 | 0.3914 | 0.1565 | 11.4854 | 0.4520 | 0.5570 | 0.2294 | 10.9003 | 0.4029 | 0.6089 | 0.2495 |\n|  | 2 | 17.4837 | 0.6148 | 0.3582 | 0.1503 | 13.3077 | 0.4886 | 0.5434 | 0.2126 | 11.5381 | 0.4003 | 0.6407 | 0.2551 |\n|  | 3 | 17.2341 | 0.6097 | 0.3585 | 0.1504 | 13.2212 | 0.4978 | 0.5287 | 0.2056 | 11.9211 | 0.4387 | 0.5942 | 0.2313 |\n|  | 4 | 17.3545 | 0.6193 | 0.3541 | 0.1481 | 14.6845 | 0.5534 | 0.4892 | 0.1870 | 14.2381 | 0.5280 | 0.5295 | 0.1917 |\n| ViewCrafter [43] | 1 | 17.3750 | 0.6670 | 0.2849 | 0.1221 | 13.6015 | 0.6016 | 0.4315 | 0.1762 | 14.0781 | 0.5894 | 0.4293 | 0.1676 |\n|  | 2 | 18.8906 | 0.6685 | 0.3079 | 0.1334 | 14.2891 | 0.5947 | 0.4478 | 0.1761 | 13.5859 | 0.5537 | 0.5100 | 0.1925 |\n|  | 3 | 18.4531 | 0.6548 | 0.3024 | 0.1294 | 14.1172 | 0.5913 | 0.4401 | 0.1717 | 13.7031 | 0.5620 | 0.4867 | 0.1784 |\n|  | 4 | 18.4844 | 0.6553 | 0.3068 | 0.1346 | 14.7421 | 0.6011 | 0.4230 | 0.1672 | 15.1875 | 0.5874 | 0.4327 | 0.1638 |\n| NVComposer (Ours) | 1 | 18.7227 | 0.7215 | 0.2354 | 0.0996 | 15.3101 | 0.6056 | 0.3445 | 0.1516 | 15.2115 | 0.6408 | 0.4048 | 0.1462 |\n|  | 2 | 20.7395 | 0.7681 | 0.1781 | 0.0793 | 16.9100 | 0.6445 | 0.2742 | 0.1198 | 15.3461 | 0.6638 | 0.3789 | 0.1384 |\n|  | 3 | 21.5278 | 0.7981 | 0.1522 | 0.0716 | 17.7071 | 0.7418 | 0.2759 | 0.1097 | 15.3825 | 0.6822 | 0.3699 | 0.1324 |\n|  | 4 | 22.5519 | 0.8226 | 0.1188 | 0.0537 | 19.5346 | 0.7847 | 0.2030 | 0.0851 | 17.8181 | 0.7359 | 0.2644 | 0.0988 |", "caption": "Table 1: NVS evaluation with varying numbers of input views on RealEstate10K\u00a0[47] for controllable video models MotionCtrl\u00a0[36] and CameraCtrl\u00a0[9], reconstructive model DUSt3R\u00a0[34], and generative models ViewCrafter\u00a0[43] and NVComposer. \u03b8targetsubscript\ud835\udf03target\\theta_{\\text{target}}italic_\u03b8 start_POSTSUBSCRIPT target end_POSTSUBSCRIPT denotes the rotation angle between the anchor view and the furthest target view, while \u03b8condsubscript\ud835\udf03cond\\theta_{\\text{cond}}italic_\u03b8 start_POSTSUBSCRIPT cond end_POSTSUBSCRIPT indicates the angle between the anchor view and the furthest conditional view (when multiple conditions are used).", "description": "This table presents a quantitative comparison of different novel view synthesis (NVS) methods on the RealEstate10K dataset.  It evaluates the performance of several models, including controllable video generation models (MotionCtrl and CameraCtrl), a reconstructive model (DUSt3R), and generative models (ViewCrafter and NVComposer). The evaluation considers varying numbers of input views, categorizing scene difficulty based on the angular distance between views. Metrics include PSNR, SSIM, LPIPS, and DISTS, providing a comprehensive assessment of the generated novel views' quality across different difficulty levels and varying numbers of input views.  The table highlights the impact of the number of input views on the performance of each method and helps understand the strengths and weaknesses of each approach in generating realistic novel views.", "section": "4.2. Results"}, {"content": "| Model | Views | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | DISTS \u2193 |\n|---|---|---|---|---|---| \n| MotionCtrl [36] | 1 | 13.4003 | 0.5539 | 0.4004 | 0.1396 |\n| CameraCtrl [9] | 1 | 12.2995 | 0.4692 | 0.4337 | 0.1829 |\n| DUSt3R [34] | 1 | 11.7650 | 0.4652 | 0.4900 | 0.2295 |\n|  | 2 | 14.6660 | 0.5158 | 0.4531 | 0.2104 |\n|  | 3 | 13.9156 | 0.5010 | 0.4699 | 0.2127 |\n|  | 4 | 14.8716 | 0.5193 | 0.4478 | 0.2072 |\n| ViewCrafter [43] | 1 | 15.5625 | 0.4932 | 0.4122 | 0.2125 |\n|  | 2 | 15.6875 | 0.4775 | 0.4417 | 0.2212 |\n|  | 3 | 14.8593 | 0.4670 | 0.4617 | 0.2273 |\n|  | 4 | 15.0625 | 0.4712 | 0.4549 | 0.2301 |\n| NVComposer (Ours) | 1 | 15.3101 | 0.6056 | 0.3445 | 0.1516 |\n|  | 2 | 16.9100 | 0.6445 | 0.2742 | 0.1198 |\n|  | 3 | 17.3115 | 0.6687 | 0.2558 | 0.1122 |\n|  | 4 | 17.9248 | 0.6958 | 0.2277 | 0.1023 |", "caption": "Table 2: NVS evaluation on DL3DV\u00a0[18]. When more unposed input views are provided, our model consistently reports higher performance.", "description": "Table 2 presents a quantitative evaluation of novel view synthesis (NVS) performance using the DL3DV dataset.  The table compares the performance of the proposed NVComposer model against several baseline methods (MotionCtrl, CameraCtrl, DUSt3R, and ViewCrafter).  The key metric is PSNR (higher is better), which measures the quality of the generated views relative to ground truth. The results are shown for different numbers of unposed input views (1, 2, 3, 4), demonstrating the impact of using multiple input views on the quality of the synthesized novel views.  As the number of input views increases, NVComposer consistently shows improvements in PSNR, indicating its ability to leverage additional information effectively.", "section": "4.2. Results"}, {"content": "| Method | FID\u2193 | FVD\u2193 | KVD\u2193 |\n|---|---|---|---|\n| MotionCtrl [36] | 60.83 | 509.96 | 14.26 |\n| CameraCtrl [9] | 52.33 | 561.97 | 24.38 |\n| ViewCrafter [43] | 46.08 | 485.11 | 13.06 |\n| NVComposer (Ours) | 46.19 | 425.44 | 8.04 |", "caption": "Table 3: Distribution evaluation on generated views of MotionCtrl\u00a0[36], CameraCtrl\u00a0[9], ViewCrafter\u00a0[43], and our NVComposer using FID\u00a0[10], FVD\u00a0[31], and KVD\u00a0[31] metrics.", "description": "This table presents a quantitative comparison of the quality of generated video sequences by four different methods: MotionCtrl, CameraCtrl, ViewCrafter, and NVComposer.  The evaluation is performed using three metrics: Fr\u00e9chet Inception Distance (FID), Fr\u00e9chet Video Distance (FVD), and Kernel Video Distance (KVD).  Lower FID, FVD, and KVD scores indicate higher similarity between the generated videos and real-world videos, suggesting improved generation quality.", "section": "4.2. Results"}, {"content": "| Model | Views | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 |\n|---|---|---|---|---|\n| SV3D [32] | 1 | 13.8861 | 0.8130 | 0.2731 |\n| NVComposer (Ours) | 1 | 16.3764 | 0.8218 | 0.2286 |\n|  | 2 | 17.1507 | 0.8268 | 0.2067 |\n|  | 4 | 17.7234 | 0.8352 | 0.1889 |", "caption": "Table 4: Generative NVS results on the Objaverse\u00a0[4] test set. When only a single conditional view is provided, NVComposer achieves performance comparable to SV3D\u00a0[32]. As more random unposed condition views are added, NVComposer \u2019s performance improves significantly.", "description": "Table 4 presents a comparison of novel view synthesis (NVS) performance on the Objaverse dataset [4], specifically focusing on the impact of the number of input views.  The results demonstrate that NVComposer, even with a single input view, achieves comparable performance to the state-of-the-art method SV3D [32].  Importantly, the table shows a significant improvement in NVComposer's performance as more unposed and randomly selected input views are added. This highlights the effectiveness of NVComposer in leveraging multiple views to enhance the quality of the synthesized novel views.", "section": "4.2.2. Generative NVS in Objects"}, {"content": "| Dual-Stream | PSNR\u2191 | SSIM\u2191 | LPIPS\u2193 |\n|---|---|---|---|\n| w/ | 17.0510 | 0.7501 | 0.1353 |\n| w/o | 14.6857 | 0.7458 | 0.2095 |", "caption": "Table 5: Ablation experiments on dual-stream diffusion on Objaverse\u00a0[4]. We train the two models (initialized from the same checkpoint) for one epoch on a small subset of Objaverse. The model without dual-stream only generates images instead of the image-pose bundles.", "description": "This table presents the ablation study results focusing on the impact of the dual-stream diffusion model in NVComposer.  Two models were trained for one epoch on a subset of the Objaverse dataset. One model incorporated the dual-stream architecture, while the other did not. Both models were initialized from the same checkpoint. The key difference is that the model without the dual-stream generates only images, while the model with dual-stream generates both images and their associated pose information (image-pose bundles). The table compares the performance of these two models using metrics such as PSNR, SSIM, and LPIPS.", "section": "4. Experiments"}, {"content": "| Alignment | PSNR\u2191 | SSIM\u2191 | LPIPS\u2193 | DISTS\u2193 |\n|---|---|---|---|---|\n| w/o | 14.7218 | 0.6291 | 0.3799 | 0.1494 |\n| w/ | 15.6568 | 0.6440 | 0.3284 | 0.1340 |", "caption": "Table 6: Ablation experiments on the geometry-aware feature alignment (Alignment in table). We initialize two models with and without the alignment mechanism from a same checkpoint, and train the two models for an epoch, then evaluate them on RealEstate10K\u00a0[47].", "description": "This table presents the results of an ablation study comparing two models trained on the RealEstate10K dataset.  Both models started from the same checkpoint, but one incorporated the geometry-aware feature alignment mechanism, while the other did not.  The models were trained for a single epoch, after which their performance on several metrics (PSNR, SSIM, LPIPS, and DISTS) was evaluated and compared to determine the effectiveness of the geometry-aware feature alignment in improving novel view synthesis.", "section": "4.3 Analysis"}, {"content": "| Subset | Method | $\\Delta\\hat{R}\\downarrow$ | $\\Delta\\hat{T}\\downarrow$ |\n|---|---|---|---| \n| Easy | DUSt3R [34] | 9.6968 | 0.5757 |\n|  | NVComposer (Ours) | 2.7225 | 0.0257 |\n| Hard | DUSt3R [34] | 58.3987 | 0.7603 |\n|  | NVComposer (Ours) | 5.8566 | 0.0263 |", "caption": "Table 7: Comparison with pose estimation accuracy on two spare condition images in our RealEstate10K\u00a0[47] test sets. Our NVComposer implicitly predicts camera poses by generating ray embeddings of condition views while generating target views.", "description": "This table compares the accuracy of camera pose estimation between NVComposer and the DUSt3R method.  The evaluation is performed on a subset of the RealEstate10K dataset, using two sparsely sampled condition images.  Accuracy is measured in terms of the average angular rotation and translation differences between estimated and ground truth poses. NVComposer implicitly estimates poses by generating ray embeddings of the condition views during novel view synthesis, while DUSt3R uses explicit methods.  The results show that NVComposer outperforms DUSt3R, especially in challenging scenarios with small overlap between views.", "section": "4.3. Analysis"}]