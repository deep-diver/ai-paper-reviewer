[{"figure_path": "https://arxiv.org/html/2503.06674/x2.png", "caption": "Figure 1:  User Study Time! Which one do you think is better? Some images are generated by Pixart-\u03b1\ud835\udefc\\alphaitalic_\u03b1 (50 NFE). Some images are generated by TDM (4 NFE), distilling from Pixart-\u03b1\ud835\udefc\\alphaitalic_\u03b1 in a data-free way with merely 500 training iterations and 2 A800 hours. All images are generated from the same initial noise. We put the location of generated images by TDM in footnote333TDM (left to right):\nbottom, bottom, top, bottom, top..", "description": "This figure presents a user study comparing image generation quality between Pixart-\u03b1 and TDM.  Five pairs of images are shown, each pair depicting the same subject generated by both models. Pixart-\u03b1, a high-quality model, used 50 NFE (number of forward Euler steps) for generation, while TDM, a distilled model from Pixart-\u03b1, used only 4 NFE.  TDM achieved its results via data-free distillation with 500 training iterations and 2 A800 hours. The caption indicates which image in each pair was generated by TDM.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.06674/x3.png", "caption": "Figure 2:  The comparison between Four-step generated images by TDM under different training iterations and pre-trained diffusion models with 25 steps and 5.5 CFG. It can be seen that the ultra-fast convergence of our method, without sacrificing the sample quality.", "description": "This figure compares images generated by the Trajectory Distribution Matching (TDM) method after different numbers of training iterations with those from a pre-trained diffusion model.  The pre-trained model uses 25 sampling steps and a classifier-free guidance (CFG) scale of 5.5.  TDM, in contrast, generates images with only 4 sampling steps. The figure demonstrates that TDM achieves high-quality image generation very quickly, even with a significantly reduced number of sampling steps.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/x4.png", "caption": "Figure 3: Additional Samples by TDM with 4-step generation on SDXL backbone.", "description": "This figure showcases additional examples of images generated using the Trajectory Distribution Matching (TDM) method.  Specifically, it demonstrates the model's performance with 4-step generation using the SDXL (Stable Diffusion XL) model as the backbone. The images exemplify the high quality and diversity achievable with the TDM method, even with a significantly reduced number of sampling steps compared to traditional methods.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/x5.png", "caption": "Figure 4: Trajectory Distribution Matching. An illustration of training 2-step generator by TDM in a data-free way.", "description": "This figure illustrates the data-free training process of a two-step generator using the Trajectory Distribution Matching (TDM) method.  It shows how the TDM framework aligns the student model's trajectory with that of the teacher model at the distribution level, enabling efficient knowledge transfer without needing real data for training. The process involves using a novel data-free score distillation objective and a sampling-steps-aware objective.  The figure depicts the forward diffusion process, backward deterministic sampling, the generator, the computation of the real score and fake score, and the use of importance sampling to optimize the training process.  This data-free approach is key to TDM's efficiency and effectiveness.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/x6.png", "caption": "Figure 5: Qualitative comparisons of TDM against most competing methods on SDXL. All images are generated by the same initial noise.", "description": "This figure displays a qualitative comparison of image generation results from different diffusion models, all starting from the same initial noise.  The models compared include SDXL (a baseline with 50 noise-removing steps), LCM (4 steps), TCD (4 steps), Lighting (4 steps), Hyper (4 steps), DMD2 (4 steps), and TDM (the authors' model, also with 4 steps). The comparison showcases various image prompts and highlights the visual differences in the quality and details of the generated images across the different models.  The goal is to visually demonstrate the performance of the authors' TDM model against existing state-of-the-art methods, emphasizing its ability to produce high-quality images with a significantly reduced number of sampling steps.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.06674/x7.png", "caption": "Figure 6: The user study about the comparison between our method and the most competing methods.", "description": "This figure presents the results of a user study comparing the image quality of images generated by the proposed Trajectory Distribution Matching (TDM) method against several state-of-the-art competing methods. The user study was conducted by showing participants pairs of images and asking which one is better based on overall image quality and how well it aligns with the provided prompt.  The figure visually displays the percentage of times each method was chosen as better by the participants, offering a direct comparison of user preference for image quality generated by different methods.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.06674/x8.png", "caption": "Figure 7: The visualization of ODE trajectory with clean samples at different timesteps. It is clear that our method suffers less from the CFG artifact and has better visual quality. The prompt is \u201cA dog reading a book\u201d. See Appendix\u00a0H for more visualizations.", "description": "Figure 7 visualizes the intermediate clean samples generated during the denoising process of a diffusion model, illustrating the model's trajectory across different timesteps.  The figure compares the trajectory generated by the proposed Trajectory Distribution Matching (TDM) method with that of a standard diffusion model.  The comparison highlights that TDM produces cleaner samples with less of the CFG (classifier-free guidance) artifact, resulting in better visual quality. The input prompt for generating these images was \u201cA dog reading a book.\u201d Additional visualizations are available in Appendix H of the paper.", "section": "4.1 Main Results"}, {"figure_path": "https://arxiv.org/html/2503.06674/x9.png", "caption": "Figure 8: 4 step generation from LCM and our method initialized by LCM. Our method can recover LCM from poor deterministic sampling via merely 100 training iterations.", "description": "This figure compares the image generation results of LCM (Latent Consistency Model) and the proposed TDM (Trajectory Distribution Matching) method, both initialized using LCM.  The left two columns show the results from LCM using stochastic and deterministic sampling, respectively.  Stochastic sampling shows better results but is computationally expensive. Deterministic sampling in LCM produces poor quality images.  The right two columns show the results obtained using TDM after 100 training iterations. TDM achieves significantly improved image quality comparable to that of LCM with stochastic sampling, demonstrating its ability to recover high-quality results from a poorly performing deterministic sampling baseline within very few training iterations.", "section": "4.1 Main Results"}, {"figure_path": "https://arxiv.org/html/2503.06674/x10.png", "caption": "Figure 9: Comparison to DMD2 under LoRA fine-tuning.", "description": "This figure shows a comparison of the performance of TDM and DMD2 when fine-tuned using LoRA.  It compares training time (in hours) and FID (Fr\u00e9chet Inception Distance) scores, a metric assessing the quality of generated images. The graph illustrates that TDM achieves comparable FID scores to DMD2 but in a significantly shorter training time.", "section": "4.3. Ablation Study"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_dmd2.jpg", "caption": "Figure 10: Visual samples of varying the condition steps and sampling steps. The prompt is \u201cA corgi with sunglasses, traveling in the sea\u201d\u201d", "description": "This figure shows the results of varying both the number of conditioning steps and the number of sampling steps used to generate images with the text prompt, \u201cA corgi with sunglasses, traveling in the sea.\u201d  It demonstrates the flexibility of the proposed model (TDM-unify) and its ability to adapt to different numbers of steps while maintaining image quality. Each row represents a different number of sampling steps, while each column represents a different number of conditioning steps. This illustrates how TDM-unify can generate images with consistent results under different settings.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_naive.jpg", "caption": "(a)", "description": "This figure shows a comparison of images generated by different methods under various training iterations.  The goal is to illustrate the rapid convergence of the proposed Trajectory Distribution Matching (TDM) method, which achieves high-quality image generation even with very few training iterations. The images are generated from the same initial noise, allowing for a direct comparison of image quality and showing how TDM quickly approaches the quality of a fully-trained teacher model with minimal training time and resources.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_our.jpg", "caption": "(b)", "description": "This figure shows a comparison of generated images by different methods, including the proposed TDM method and several baselines, under different training iterations.  The images are generated from the same initial noise to highlight the differences in sample quality and convergence speed. The objective is to visualize how the proposed method (TDM) quickly achieves high-quality samples with only a small number of training iterations, outperforming other methods even with far fewer steps in the sampling process.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/match_ablation.jpg", "caption": "(c)", "description": "The figure shows qualitative comparisons of four-step generation images by TDM against several competing methods on the SDXL backbone. All images are generated from the same initial noise. The results demonstrate TDM's superior performance in terms of image quality and adherence to the prompt.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/match_our.jpg", "caption": "Figure 11: Comparison on Mode Cover in 4-step generation based on SD-v1.5. It is clear that our method has better mode cover and image quality. The prompt is \u201cA cute dinosaur, cartoon style\u201d", "description": "This figure compares the mode coverage and image quality of 4-step generation using different methods based on the Stable Diffusion v1.5 model. The prompt used is \u201cA cute dinosaur, cartoon style\u201d. The results show that the proposed Trajectory Distribution Matching (TDM) method outperforms other methods, achieving both better mode coverage (representing the diversity of generated images) and improved image quality.", "section": "4.1 Main Results"}, {"figure_path": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/user_demo.jpg", "caption": "(a)", "description": "This figure shows a comparison of images generated by different methods under various numbers of function evaluations (NFEs). The goal is to demonstrate the impact of the proposed method (TDM) on accelerating diffusion models, particularly in generating high-quality images with only a few steps.  The images generated using 50 NFEs serve as a baseline for quality comparison.  The remaining images, produced with 4 NFEs by different methods, illustrate the trade-off between speed and quality. The methods compared include LCM, TCD, Lightning, Hyper, and DMD2.  The figure showcases the superior quality achieved by TDM even with a significantly reduced number of NFEs.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2503.06674/x11.png", "caption": "(b)", "description": "This figure shows the comparison between four-step generated images by the proposed Trajectory Distribution Matching (TDM) method under different training iterations and pre-trained diffusion models with 25 steps and 5.5 CFG.  It demonstrates the fast convergence of the method without sacrificing image quality.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.06674/x12.png", "caption": "Figure 12: \nComparison on the compatibility with deterministic samplers in the 4-step generation on SD-v1.5.\nIt is clear that our method (matching noisy samples) has better visual quality.", "description": "This figure compares the results of two different approaches for 4-step image generation using the Stable Diffusion v1.5 model.  One approach matches clean samples, while the other matches noisy samples. The image shows that matching noisy samples (the authors' method) produces significantly higher quality images. This demonstrates the superiority of the authors' technique when using deterministic samplers in few-step generation.", "section": "F.2. Additional Ablation"}, {"figure_path": "https://arxiv.org/html/2503.06674/x13.png", "caption": "Figure 13: An example of the evaluation question for our user study.", "description": "This figure shows an example question used in the user study to compare image quality and image-text alignment.  Two images generated by different methods are shown side-by-side. Users were asked to select the image with better quality and alignment to the prompt. This provides a human-centric evaluation of the generated images from different methods, supplementing machine-based metrics.", "section": "G. User Study Details"}]