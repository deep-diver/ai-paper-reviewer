[{"figure_path": "2410.13370/figures/figures_1_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_3_0.png", "caption": "Figure 2: Major challenges in component-controllable personalization. (a) Semantic pollution: (i) Undesired visual elements may inadvertently disturb the personalized concept. (ii) A simple mask-out strategy is ineffective and causes unintended compositions, whereas (iii) our DM-Deg effectively suppresses unwanted visual semantics, preventing such pollution. (b) Semantic imbalance: (i) Simultaneously learning the concept and component can lead to imbalance, resulting in concept or component distortion (here we present a case for the former). (ii) Our DS-Bal ensures balanced learning, enhancing personalization performance.", "description": "Figure 2 illustrates the two main challenges in component-controllable personalization: semantic pollution, where unwanted visual elements corrupt the concept; and semantic imbalance, where disproportionate learning of the concept and component occurs.", "section": "2 RELATED WORKS"}, {"figure_path": "2410.13370/figures/figures_3_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization in text-to-image diffusion models, showing how to modify specific components of visual concepts using reference images and the effectiveness of MagicTailor in achieving this.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_4_0.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "The figure illustrates the pipeline of MagicTailor, a framework that enables component-controllable personalization for text-to-image diffusion models by using dynamic masked degradation and dual-stream balancing.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_5_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, highlighting the differences between standard personalization and the novel component-controllable personalization proposed in the paper, and shows example outputs of the proposed method.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_6_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization using text-to-image diffusion models, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_6_1.png", "caption": "Figure 5: Visualization of the learning process. (a) The vanilla learning paradigm lapses into overemphasizing the easier one. (b) DS-Bal effectively balances the learning of the concept and component.", "description": "Figure 5 visualizes how the dual-stream balancing (DS-Bal) technique in MagicTailor effectively addresses semantic imbalance in component-controllable personalization, contrasting it with the unbalanced learning of a vanilla approach.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_7_0.png", "caption": "Figure 6: Qualitative comparisons. We present images generated by MagicTailor and the compared methods for various domains. MagicTailor generally achieves promising text alignment, strong identity fidelity, and high generation quality. More results are provided in Appendix D.", "description": "Figure 6 shows a qualitative comparison of images generated by MagicTailor and other state-of-the-art methods across various domains, highlighting MagicTailor's superior performance in text alignment, identity fidelity, and image quality.", "section": "4 Experiments"}, {"figure_path": "2410.13370/figures/figures_9_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showing how to modify specific visual components using reference images, and provides example images generated by MagicTailor.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_9_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concepts of personalization and component-controllable personalization in text-to-image diffusion models, and showcases example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_9_2.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization, showing how text-to-image diffusion models can learn and modify visual concepts with example images generated by MagicTailor.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_10_0.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "This figure illustrates the MagicTailor pipeline, which fine-tunes a text-to-image diffusion model to learn concepts and components from reference images, addressing semantic pollution and imbalance.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_10_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization, component-controllable personalization, and example images generated by the proposed MagicTailor framework.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_10_2.png", "caption": "Figure 9: Enhancing other generative tools. MagicTailor can conveniently collaborate with a variety of generative tools that focus on other tasks, equipping them with an additional ability to control the concept's component in their pipelines.", "description": "The figure shows how MagicTailor can be used to enhance other generative tools by adding the ability to control a concept's component.", "section": "Further Applications"}, {"figure_path": "2410.13370/figures/figures_10_3.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "This figure illustrates the pipeline of MagicTailor, a novel framework that enables component-controllable personalization for text-to-image diffusion models, highlighting its key techniques: Dynamic Masked Degradation and Dual-Stream Balancing.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_10_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showcasing examples generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_10_6.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor, highlighting its effectiveness in adapting T2I diffusion models for component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_10_7.png", "caption": "Figure 4: Motivation of dynamic intensity. (a) Fixed intensity (ad = 0.5 here) could cause noisy generated images. (b) Our dynamic intensity helps to mitigate noise memorization.", "description": "Figure 4 shows the comparison of using fixed and dynamic intensity in the DM-Deg, illustrating how dynamic intensity mitigates noise memorization during training.", "section": "3.2 Dynamic Masked Degradation"}, {"figure_path": "2410.13370/figures/figures_17_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "This figure illustrates the concept of personalization and component-controllable personalization, showing how text-to-image diffusion models can modify specific components of a visual concept and provides example images generated by the proposed MagicTailor framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_17_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showing how to modify specific components of a visual concept and examples of images generated by MagicTailor.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_17_2.png", "caption": "Figure 2: Major challenges in component-controllable personalization. (a) Semantic pollution: (i) Undesired visual elements may inadvertently disturb the personalized concept. (ii) A simple mask-out strategy is ineffective and causes unintended compositions, whereas (iii) our DM-Deg effectively suppresses unwanted visual semantics, preventing such pollution. (b) Semantic imbalance: (i) Simultaneously learning the concept and component can lead to imbalance, resulting in concept or component distortion (here we present a case for the former). (ii) Our DS-Bal ensures balanced learning, enhancing personalization performance.", "description": "The figure illustrates the two main challenges in component-controllable personalization: semantic pollution and semantic imbalance, showing how the proposed methods, DM-Deg and DS-Bal, address these issues.", "section": "2 RELATED WORKS"}, {"figure_path": "2410.13370/figures/figures_17_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_17_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showcasing examples of image generation using the proposed MagicTailor framework.", "section": "ABSTRACT"}, {"figure_path": "2410.13370/figures/figures_17_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization in text-to-image diffusion models, showing how MagicTailor modifies a specific visual concept component using reference images.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated using the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor to showcase its effectiveness in adapting T2I diffusion models for component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_2.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the tasks of personalization and component-controllable personalization, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor, highlighting the effectiveness of the proposed framework for adapting T2I diffusion models.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_18_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates personalization, component-controllable personalization, and example images generated by MagicTailor, highlighting the differences between standard personalization and the proposed component-controllable approach.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by MagicTailor.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_19_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization tasks, showing how text-to-image diffusion models can learn and modify specific visual concepts using reference images, and provides example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_2.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing how MagicTailor modifies a specific component of a visual concept.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization in text-to-image diffusion models, showing examples of generated images using the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates personalization, component-controllable personalization, and example images generated by the proposed MagicTailor framework for text-to-image diffusion models.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_6.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the personalization and component-controllable personalization tasks, and shows example images generated by the proposed MagicTailor.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_7.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showcasing component-controllable personalization as a new task and example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_8.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the personalization and component-controllable personalization tasks, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_9.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and examples of images generated by MagicTailor, highlighting its effectiveness in component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_20_0.png", "caption": "Figure 6: Qualitative comparisons. We present images generated by MagicTailor and the compared methods for various domains. MagicTailor generally achieves promising text alignment, strong identity fidelity, and high generation quality. More results are provided in Appendix D.", "description": "Figure 6 shows a qualitative comparison of images generated by MagicTailor and other state-of-the-art methods across different domains, highlighting MagicTailor's superior performance in terms of text alignment, identity preservation, and image quality.", "section": "4 Experiments"}]