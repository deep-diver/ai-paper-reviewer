[{"figure_path": "2410.13370/figures/figures_1_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_3_0.png", "caption": "Figure 2: Major challenges in component-controllable personalization. (a) Semantic pollution: (i) Undesired visual elements may inadvertently disturb the personalized concept. (ii) A simple mask-out strategy is ineffective and causes unintended compositions, whereas (iii) our DM-Deg effectively suppresses unwanted visual semantics, preventing such pollution. (b) Semantic imbalance: (i) Simultaneously learning the concept and component can lead to imbalance, resulting in concept or component distortion (here we present a case for the former). (ii) Our DS-Bal ensures balanced learning, enhancing personalization performance.", "description": "Figure 2 illustrates the two main challenges in component-controllable personalization: semantic pollution and semantic imbalance, showcasing how the proposed DM-Deg and DS-Bal methods address these issues.", "section": "2 RELATED WORKS"}, {"figure_path": "2410.13370/figures/figures_3_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization tasks, and provides example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_4_0.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "The figure illustrates the MagicTailor pipeline, which uses reference images to fine-tune a text-to-image diffusion model, incorporating DM-Deg and DS-Bal to address semantic pollution and imbalance.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_5_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "This figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, along with example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_6_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization in text-to-image diffusion models, showing how MagicTailor modifies a visual concept's specific component.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_6_1.png", "caption": "Figure 5: Visualization of the learning process. (a) The vanilla learning paradigm lapses into overemphasizing the easier one. (b) DS-Bal effectively balances the learning of the concept and component.", "description": "Figure 5 visualizes how the Dual-Stream Balancing (DS-Bal) method effectively balances the learning of visual semantics for both concept and component, resolving the semantic imbalance issue.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_7_0.png", "caption": "Figure 6: Qualitative comparisons. We present images generated by MagicTailor and the compared methods for various domains. MagicTailor generally achieves promising text alignment, strong identity fidelity, and high generation quality. More results are provided in Appendix D.", "description": "Figure 6 shows a qualitative comparison of images generated by MagicTailor and other state-of-the-art methods across various domains, highlighting MagicTailor's superior performance in text alignment, identity preservation, and overall image quality.", "section": "4 Experiments"}, {"figure_path": "2410.13370/figures/figures_9_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showcasing how MagicTailor modifies a specific component of a visual concept during the process.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_9_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the task of personalization, component-controllable personalization, and example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_9_2.png", "caption": "Figure 6: Qualitative comparisons. We present images generated by MagicTailor and the compared methods for various domains. MagicTailor generally achieves promising text alignment, strong identity fidelity, and high generation quality. More results are provided in Appendix D.", "description": "Figure 6 shows a qualitative comparison of images generated by MagicTailor and other state-of-the-art methods across various domains, highlighting MagicTailor's superior text alignment, identity preservation, and image quality.", "section": "4 Experiments"}, {"figure_path": "2410.13370/figures/figures_10_0.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "The figure illustrates the pipeline of MagicTailor, a framework that adapts T2I diffusion models for component-controllable personalization, highlighting its key techniques: Dynamic Masked Degradation (DM-Deg) and Dual-Stream Balancing (DS-Bal).", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_10_2.png", "caption": "Figure 9: Enhancing other generative tools. MagicTailor can conveniently collaborate with a variety of generative tools that focus on other tasks, equipping them with an additional ability to control the concept's component in their pipelines.", "description": "The figure shows how MagicTailor can be integrated with other generative tools like ControlNet, CSGO, and InstantMesh to enhance their capabilities by adding component-controllable personalization.", "section": "4.5 FURTHER APPLICATIONS"}, {"figure_path": "2410.13370/figures/figures_10_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization and component-controllable personalization, showing how text-to-image diffusion models can learn and reproduce visual concepts, modify specific components, and generate example images using the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_10_6.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the personalization and component-controllable personalization tasks, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_17_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization, and provides example images generated by MagicTailor, highlighting the target concept and component.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_17_1.png", "caption": "Figure 8: (a) Decoupled generation. MagicTailor can also separately generate the target concept and component, enriching prospective combinations. (b) Controlling multiple components. MagicTailor shows the potential to handle more than one component, highlighting its effectiveness.", "description": "Figure 8 demonstrates MagicTailor's ability to generate concepts and components separately and to control multiple components simultaneously.", "section": "4.4 Ablation Studies"}, {"figure_path": "2410.13370/figures/figures_17_2.png", "caption": "Figure 4: Motivation of dynamic intensity. (a) Fixed intensity (ad = 0.5 here) could cause noisy generated images. (b) Our dynamic intensity helps to mitigate noise memorization.", "description": "The figure illustrates the benefit of using dynamic intensity in the DM-Deg process to mitigate noise memorization during image generation.", "section": "3.2 Dynamic Masked Degradation"}, {"figure_path": "2410.13370/figures/figures_17_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing how MagicTailor modifies a specific component of a visual concept during personalization.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_17_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor to showcase its effectiveness in adapting text-to-image diffusion models for component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_17_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models and introduces a new task, component-controllable personalization, showing examples of images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by the MagicTailor model, highlighting its effectiveness in component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the tasks of personalization and component-controllable personalization in text-to-image diffusion models and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_2.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concepts of personalization and component-controllable personalization in text-to-image diffusion models, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor, highlighting its effectiveness in adapting T2I diffusion models for component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by MagicTailor to demonstrate its effectiveness in adapting T2I diffusion models for component-controllable personalization.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_18_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization in text-to-image diffusion models, showing how to modify a specific component of a visual concept using reference images, and provides example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_0.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing example images generated by the proposed MagicTailor framework.", "section": "ABSTRACT"}, {"figure_path": "2410.13370/figures/figures_19_1.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization, component-controllable personalization, and example images generated by the proposed MagicTailor framework.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_19_2.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_3.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showing how to modify specific components of a visual concept using reference images and the results generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_4.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_5.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates the concept of personalization in text-to-image diffusion models, showing how to modify specific components of a visual concept during personalization using the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_6.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization in text-to-image diffusion models, and shows example images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_19_7.png", "caption": "Figure 3: Pipeline overview of MagicTailor. Using reference images as the inputs, MagicTailor fine-tunes a T2I diffusion model to learn both the target concept and component, enabling the generation of images that seamlessly integrate the component into the concept. Two key techniques, Dynamic Masked Degradation (DM-Deg, see Section 3.2) and Dual-Stream Balancing (DS-Bal, see Section 3.3), address the challenges of semantic pollution and semantic imbalance, respectively. For clarity, only one image per concept/component is presented and the warm-up stage is not depicted.", "description": "The figure illustrates the MagicTailor pipeline, which fine-tunes a text-to-image diffusion model to learn and integrate a target concept and its component using Dynamic Masked Degradation and Dual-Stream Balancing to address semantic pollution and imbalance.", "section": "3 Methodology"}, {"figure_path": "2410.13370/figures/figures_19_8.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "Figure 1 illustrates personalization and component-controllable personalization in text-to-image diffusion models, including examples of images generated by MagicTailor.", "section": "INTRODUCTION"}, {"figure_path": "2410.13370/figures/figures_19_9.png", "caption": "Figure 1: (a) Illustration of personalization, demonstrating how text-to-image (T2I) diffusion models can learn and reproduce a visual concept from given reference images. (b) Illustration of component-controllable personalization, depicting a newly formulated task that aims to modify a specific component of a visual concept during personalization. (c) Example images generated by MagicTailor, showcasing the effectiveness of the proposed MagicTailor, a novel framework that adapts T2I diffusion models for component-controllable personalization. For clarity, the red and blue circles are used to highlight the target concept and component, respectively.", "description": "The figure illustrates the concept of personalization and component-controllable personalization in text-to-image diffusion models, showing examples of images generated by the proposed MagicTailor framework.", "section": "Introduction"}, {"figure_path": "2410.13370/figures/figures_20_0.png", "caption": "Figure 14: More qualitative comparisons. We present images generated by our MagicTailor and SOTA methods of personalization for various domains including characters, animation, buildings, objects, and animals. MagicTailor generally achieves promising text alignment, strong identity fidelity, and high generation quality.", "description": "Figure 14 presents a qualitative comparison of image generation results from MagicTailor and other state-of-the-art methods across various domains, showcasing MagicTailor's superior performance in terms of text alignment, identity preservation, and overall image quality.", "section": "4 Experiments"}]