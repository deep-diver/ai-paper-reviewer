[{"figure_path": "https://arxiv.org/html/2412.09405/x1.png", "caption": "Figure 1: In discriminative models (left), resolution reduction increases training and inference efficiency, but significantly degrades accuracy. Replacing resolution reduction with WaLLoC leads to significantly higher accuracy, while providing the same degree of acceleration. For signal enhancement (right), WaLLoC provides better quality when scaling to high resolutions compared to directly operating on image pixels or audio samples.", "description": "The figure demonstrates a comparison of model performance using resolution reduction versus WaLLoC for both discriminative and generative tasks.  The left side shows that in discriminative models, reducing resolution improves training and inference speed but drastically reduces accuracy.  Using WaLLoC maintains the speed gains of reduced resolution but significantly improves accuracy, essentially achieving higher effective resolution for the same computational cost. The right side illustrates that in signal enhancement tasks (image colorization and audio source separation), WaLLoC achieves better quality at higher resolutions compared to standard methods.", "section": "4 Evaluation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x2.png", "caption": "Figure 2: Comparison of our proposed method (WaLLoC) with other autoencoder designs for RGB Images (Cheng2020\u00a0[11], Stable Diffusion 3\u00a0[12]) and stereo audio (EnCodec\u00a0[13], Stable Audio\u00a0[9]). Additional metrics are reported in Tables 1 and 2.", "description": "Figure 2 is a 3D visualization comparing WaLLoC's performance to other autoencoder methods (Cheng2020, Stable Diffusion 3, EnCodec, Stable Audio) across key metrics for both RGB images and stereo audio.  Each point represents a different method, and the three axes show dimensionality reduction, compression ratio, and distortion.  WaLLoC outperforms other methods across multiple metrics, showing better trade-offs between compression ratio and distortion. Tables 1 and 2 provide additional quantitative details.", "section": "3 Proposed Method: Design and Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x3.png", "caption": "Figure 3: WaLLoC\u2019s encode-decode pipeline. The entropy bottleneck and entropy coding steps are only required to achieve high compression ratios for storage and transmission. For compressed-domain learning where dimensionality reduction is the primary goal, these steps can be skipped to reduce overhead and completely eliminate CPU-GPU transfers.", "description": "WaLLoC's encode-decode pipeline consists of eight stages.  The input signal undergoes wavelet packet analysis (WPT) to decompose it into frequency subbands, reducing redundancy. A learnable analysis transform then projects this data to a lower-dimensional latent representation.  A companding function and an entropy bottleneck (added noise during training) further enhance the compression ratio. Entropy coding can be applied for storage and transmission. The decoder reverses these steps, performing inverse entropy coding, decompanding, a learnable synthesis transform, and finally inverse wavelet packet synthesis (IWPT) to reconstruct the output. Importantly, for compressed-domain learning, the entropy bottleneck and coding stages are optional, improving efficiency by eliminating CPU-GPU transfers.", "section": "3 Proposed Method: Design and Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x4.png", "caption": "Figure 4: Example of forward and inverse WPT with J=2\ud835\udc3d2J=2italic_J = 2 levels.\nEach level applies filters L_\u2062AsubscriptL_A\\text{L}_{\\_}{\\text{A}}L start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT A and H_\u2062AsubscriptH_A\\text{H}_{\\_}{\\text{A}}H start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT A independently to each of the signal channels, followed by downsampling by a factor of two (\u21932)\u2193absent2\\left(\\downarrow 2\\right)( \u2193 2 ). An inverse level consists of upsampling (\u21912)\u2191absent2\\left(\\uparrow 2\\right)( \u2191 2 ) followed by L_\u2062SsubscriptL_S\\text{L}_{\\_}{\\text{S}}L start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT S and H_\u2062SsubscriptH_S\\text{H}_{\\_}{\\text{S}}H start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT S, then summing the two channels. The full WPT X\u223csuperscriptXsimilar-to\\stackrel{{\\scriptstyle\\sim}}{{\\smash{\\textbf{X}}\\rule{0.0pt}{4.73611pt}}}start_RELOP SUPERSCRIPTOP start_ARG bold_X end_ARG start_ARG \u223c end_ARG end_RELOP of consists of J\ud835\udc3dJitalic_J levels.", "description": "This figure illustrates the forward and inverse wavelet packet transform (WPT) with two levels (J=2).  Each level involves applying high-pass (HA) and low-pass (LA) filters independently to each signal channel. After filtering, a downsampling operation reduces the signal's spatial or temporal resolution by a factor of two. The inverse process is depicted, starting with upsampling and applying low-pass (LS) and high-pass (HS) filters, followed by summation of the resultant two channels to reconstruct the original signal. The figure shows that the full WPT of a signal comprises J levels of this process.", "section": "3.4 WaLLoC Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x5.png", "caption": "Figure 5: Cheng et al. 2020 [11]", "description": "Figure 5 shows a comparison of image reconstruction quality between the method proposed by Cheng et al. in 2020 and the method used in Stable Diffusion 3.  The image shows a photograph of a coffee shop at night. The top image displays the reconstruction using the method from Cheng et al. [11]. The bottom image displays the result from Stable Diffusion 3 [12], illustrating the visual differences in quality achieved by the two methods. This visual comparison helps to demonstrate one aspect of the performance and capabilities of different image compression approaches.", "section": "4.1 Compression trade-off analysis"}, {"figure_path": "https://arxiv.org/html/2412.09405/x6.png", "caption": "Figure 6: Stable Diffusion 3 VAE [12]", "description": "The figure shows an image of the Monkey Nest Coffee shop reconstructed using the Stable Diffusion 3 VAE.  This illustrates the output quality of a generative autoencoder approach to image compression. The image shows some level of detail loss and artifacts, commonly seen in lossy compression techniques where image details are sacrificed to reduce the file size. The level of quality is relatively good considering the high compression ratio achieved by VAEs, but not as detailed as the original image. This visualization supports the discussion in the paper of how different image compression methods affect the quality and detail of compressed images and the impact on compressed-domain learning. ", "section": "3 Proposed Method: Design and Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x7.png", "caption": "Figure 7: WaLLoC 4\u00d7\\times\u00d7", "description": "This figure shows the result of compressing an image using WaLLoC with a compression ratio of 4x.  It visually compares the reconstructed image to the original, demonstrating the effectiveness of WaLLoC in maintaining image quality at a reduced bitrate.", "section": "4.1 Compression trade-off analysis"}, {"figure_path": "https://arxiv.org/html/2412.09405/x8.png", "caption": "Figure 8: WaLLoC 16\u00d7\\times\u00d7", "description": "This figure shows the result of applying WaLLOC with a compression ratio of 16x to an image.  WaLLOC, or Wavelet Learned Lossy Compression, is a neural codec architecture designed for efficient and high-quality compression, particularly suited for compressed-domain learning. The figure likely demonstrates the visual quality of the compressed image compared to the original (not shown) or other compression methods.  The details preserved in the image after 16x compression highlight the efficacy of WaLLOC in reducing dimensionality while maintaining high fidelity.", "section": "3.4 WaLLoC Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x9.png", "caption": "Figure 9: Stereo reconstruction of an audio segment from the MUSDB test set.", "description": "This figure displays the stereo reconstruction of an audio segment from the MUSDB test set, comparing the original uncompressed audio with the reconstructions generated by different compression methods: EnCodec, WaLLOC at 5x compression, Stable Audio, and WaLLOC at 20x compression.  Each method's reconstruction is shown as separate waveforms for each stereo channel (Ch.1 and Ch.2), allowing for a visual comparison of the fidelity and accuracy of each compression algorithm in preserving the original audio signal.", "section": "4.1 Compression trade-off analysis"}, {"figure_path": "https://arxiv.org/html/2412.09405/x10.png", "caption": "Figure 10: Result of using the C_\u2062z=12subscript\ud835\udc36_z12C_{\\_}{\\textbf{z}}=12italic_C start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT z = 12 RGB codec (WaLLoC 16\u00d7\\times\u00d7) to decode a 12\u00d73\u00d73123312\\times 3\\times 312 \u00d7 3 \u00d7 3 latent with all elements equal to zero except except for channel i\ud835\udc56iitalic_i, which is set to [0000310000]matrix0000310000\\begin{bmatrix}0&0&0\\\\\n0&31&0\\\\\n0&0&0\\end{bmatrix}[ start_ARG start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 31 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ].", "description": "This figure visualizes the result of decoding a 12x3x3 latent tensor using the WaLLoC 16x RGB codec.  The latent tensor is mostly zeros except for a single channel, where a value of 31 is inserted in the middle element. The image shows the reconstructed images from this latent data, highlighting how the codec interprets and reconstructs the image information based on this specific input. It demonstrates the effect of a single non-zero channel on the output, showing the model's behavior when processing sparse or low-information latent representations.", "section": "3.4 WaLLoC Implementation"}, {"figure_path": "https://arxiv.org/html/2412.09405/x11.png", "caption": "Figure 11: Result of using the C_\u2062z=48subscript\ud835\udc36_z48C_{\\_}{\\textbf{z}}=48italic_C start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT z = 48 RGB codec (WaLLoC 4\u00d7\\times\u00d7) to decode a 48\u00d73\u00d73483348\\times 3\\times 348 \u00d7 3 \u00d7 3 latent with all elements equal to zero except except for channel i\ud835\udc56iitalic_i, which is set to [0000310000]matrix0000310000\\begin{bmatrix}0&0&0\\\\\n0&31&0\\\\\n0&0&0\\end{bmatrix}[ start_ARG start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 31 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ].", "description": "This figure visualizes the effect of activating individual latent channels in the WaLLoC 4x RGB codec's 48-dimensional latent space.  A 48x3x3 latent representation (a tensor with dimensions 48, 3, and 3) was created where all values were set to zero except for a single channel. This channel was set to a 3x3 matrix with a single non-zero value of 31 in the center. The figure then shows the corresponding image reconstruction for each of the 48 channels. This demonstrates the individual channel's contribution to the overall image reconstruction, illustrating WaLLoC's ability to handle high-dimensional latent spaces effectively.", "section": "3.4 WaLLoC Implementation"}]