[{"figure_path": "https://arxiv.org/html/2501.02423/x1.png", "caption": "Figure 1: The fitting results of the scaling law in Eq. (7) deriving from Kumar et\u00a0al. (2024), which have large bias in E1M1 case. In the three sub-figures on the left, middle and right, the sizes of the data points are approximately proportional to D\ud835\udc37Ditalic_D, E\ud835\udc38Eitalic_E, and M\ud835\udc40Mitalic_M respectively.", "description": "This figure compares the predictions of Kumar et al.'s (2024) scaling law (Equation 7 in the paper) against actual experimental results for various data sizes (D), exponent bits (E), and mantissa bits (M) during floating-point quantization training.  The three subplots show these comparisons, with point sizes in each plot visually representing the magnitude of D, E, and M respectively.  The results show that the scaling law significantly deviates from the observed experimental results particularly when both exponent and mantissa bits are small (E1M1), highlighting the limitations of using this model for this scenario. The plot demonstrates the inaccuracies of Kumar et al.'s scaling law in predicting the loss for floating-point quantization training.", "section": "3. Setup and Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2501.02423/x2.png", "caption": "(a) Chinchilla basic scaling law.", "description": "The figure shows the comparison of the Chinchilla scaling law with the actual LLM training losses using BF16 precision.  The plot visualizes the alignment of predicted losses against empirical losses for various model sizes, demonstrating the accuracy of the Chinchilla scaling law in predicting LLM performance under BF16 precision.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x3.png", "caption": "(b) OpenAI basic scaling law.", "description": "This figure shows the comparison of the OpenAI scaling law with the empirical training loss for various model sizes. The plot illustrates the predicted loss versus the actual training loss observed during experiments. This visualization helps assess the accuracy of the OpenAI scaling law in predicting model performance in the context of the paper's research.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x4.png", "caption": "Figure 2: The fitting performance of classical scaling laws. The size of the data point is proportional to D\ud835\udc37Ditalic_D.", "description": "This figure compares the performance of two established scaling laws \u2013 the Chinchilla scaling law and the OpenAI scaling law \u2013 against actual results obtained from LLM training.  Both laws attempt to predict training loss (L) based on model size (N) and dataset size (D). The plot visually represents the comparison, showing how well each law predicts the observed training losses. The size of each data point corresponds to the dataset size (D). This visualization helps assess the accuracy of the classical scaling laws in predicting LLM training behavior and informs the development of a more precise, precision-aware scaling law.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x5.png", "caption": "Figure 3: Quantization Targets. We select P2, P4, and P6 as our quantization targets for the following exploration of scaling laws.", "description": "This figure illustrates the six different quantization targets considered in the paper: P1 to P6.  Each target represents a specific input tensor to the GEMM (General Matrix Multiplication) operations within the Transformer architecture. These GEMMs are involved in the forward and backward passes of the model during training. The paper explores the impact of quantizing each of these tensors individually on the overall model's performance.  The authors ultimately choose to focus on quantizing P2, P4, and P6 in subsequent experiments due to their findings regarding the impact on model accuracy.", "section": "3.4 Quantization Targets"}, {"figure_path": "https://arxiv.org/html/2501.02423/x6.png", "caption": "Figure 4: Results of loss gaps with different quantization targets.", "description": "The bar chart visualizes the performance loss differences when applying various quantization strategies to different components of the transformer model (inputs to GEMM computation).  It shows that quantizing input embeddings during backward propagation (P5) leads to significant performance degradation, while quantizing other inputs, especially P2, P4, or P6 alone, yields near-optimal results.  Quantizing multiple targets together may not always provide additional benefit. The chart highlights the impact of choosing specific inputs for quantization on model performance.", "section": "3.4 Quantization Targets"}, {"figure_path": "https://arxiv.org/html/2501.02423/x7.png", "caption": "Figure 5: The correlations between \u03b3\ud835\udefe\\gammaitalic_\u03b3,\u03b9\ud835\udf04\\iotaitalic_\u03b9 in Eq. (12) and N\ud835\udc41Nitalic_N,D\ud835\udc37Ditalic_D. \u03b3\ud835\udefe\\gammaitalic_\u03b3,\u03b9\ud835\udf04\\iotaitalic_\u03b9 could be viewed as functions of N\ud835\udc41Nitalic_N,D\ud835\udc37Ditalic_D. Data point size is proportional to D\ud835\udc37Ditalic_D.", "description": "Figure 5 shows the relationship between the hyperparameters \u03b3 and \u03b9 (from the exponent scaling law equation 12) and the model size (N) and data size (D).  The plots illustrate that \u03b3 and \u03b9 are not constant values but rather functions of N and D, indicating that their influence on model performance depends on the model and data size.  The size of each data point in the plot is proportional to the data size (D), providing a visual representation of the relative data sizes used in the experiments.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x8.png", "caption": "Figure 6: The fitting results of our Exponent-related scaling law. Data point size is proportional to D\ud835\udc37Ditalic_D.", "description": "This figure displays the results of fitting the exponent-related scaling law.  The graph shows the relationship between predicted and actual loss values for various LLMs trained under different low-precision settings.  The size of the data points is directly proportional to the amount of training data used in each experiment (D).  This visualization helps assess the accuracy of the proposed Exponent-related scaling law in predicting LLM performance. The graph provides a visual representation of the efficacy of the scaling law to model the effect of the exponent in floating point quantized training on LLM performance.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x9.png", "caption": "Figure 7: The fitting results of our Mantissa-related scaling law. Data point size is proportional to D\ud835\udc37Ditalic_D.", "description": "This figure displays the results of the Mantissa-related scaling law, a part of the study on scaling laws for floating-point quantization training of LLMs.  The plot shows the correlation between predicted and actual loss values for different Mantissa configurations. The sizes of the data points in the graph are proportional to the size of the training dataset (D), providing a visual representation of the dataset's influence on the Mantissa scaling law's accuracy.", "section": "3.5.2. MANTISSA"}, {"figure_path": "https://arxiv.org/html/2501.02423/x10.png", "caption": "Figure 8: The fitting results of the joint Exponent & Mantissa scaling law: Data point sizes in left, middle, and right sub-figures are proportional to D\ud835\udc37Ditalic_D, M\ud835\udc40Mitalic_M, and E\ud835\udc38Eitalic_E, respectively.", "description": "This figure displays the results of the joint exponent and mantissa scaling law. It shows how well the model's predicted loss matches the actual loss across different combinations of exponent bits (E), mantissa bits (M), data size (D), and other parameters.  The size of the data points in the subfigures visually represents the relative contribution of D, M, and E respectively to the overall scaling law, allowing for a better visualization of their individual impacts on the model's performance.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x11.png", "caption": "Figure 9: The correlations between \u03ba\ud835\udf05\\kappaitalic_\u03ba,\u03c8\ud835\udf13\\psiitalic_\u03c8 in Eq. (19) and N\ud835\udc41Nitalic_N,D\ud835\udc37Ditalic_D. \u03ba\ud835\udf05\\kappaitalic_\u03ba,\u03c8\ud835\udf13\\psiitalic_\u03c8 could be viewed as functions of N\ud835\udc41Nitalic_N,D\ud835\udc37Ditalic_D. The data points are scaled proportionally to the value of D\ud835\udc37Ditalic_D.", "description": "Figure 9 visualizes the relationship between the hyperparameters \u03ba and \u03c8 (from the logarithmic scaling law in Equation 19) and the model size (N) and dataset size (D).  The plots show that \u03ba and \u03c8 exhibit clear correlations with N and D, suggesting that the impact of block size on model performance is dependent on the model and dataset scales.  The size of the data points in the figure is scaled proportionally to the dataset size (D), providing a visual representation of data size's influence on the correlations.", "section": "3.6 Block Size of Scaling Factor"}, {"figure_path": "https://arxiv.org/html/2501.02423/x12.png", "caption": "Figure 10: Our scaling law precisely forecasts validation loss for diverse block sizes. Data point sizes are directly proportional to D\ud835\udc37Ditalic_D and B\ud835\udc35Bitalic_B in the respective left and right sub-figures.", "description": "Figure 10 shows the results of experiments on the impact of block size (B) on the validation loss of LLMs. The scaling law proposed in this work accurately predicts the validation loss for different block sizes (B) and data sizes (D).  The left sub-figure shows the correlation between the predicted and actual loss for different data sizes. The right sub-figure emphasizes the relationship between block size (B) and validation loss, showing how accurately the proposed scaling law captures this relationship.  In both sub-figures, the size of the data points is directly proportional to the size of the dataset (D) and block size (B), respectively.", "section": "3. Setup and Scaling Laws"}, {"figure_path": "https://arxiv.org/html/2501.02423/x13.png", "caption": "Figure 11: The fitting results of the channel-wise scaling law. The size of the data point is proportional to D\ud835\udc37Ditalic_D.", "description": "This figure shows the fitting results of the channel-wise scaling law. The x-axis represents the actual loss, and the y-axis represents the predicted loss according to the channel-wise scaling law. Each data point corresponds to a specific model trained with a particular combination of model size (N), data size (D), exponent (E), mantissa (M), and block size of scaling factors (B). The size of the data point is proportional to the data size (D). The plot visually demonstrates how well the channel-wise scaling law predicts the loss compared to the actual results. This figure helps assess the accuracy and applicability of the channel-wise scaling law for estimating the performance of low-precision LLMs in training.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x14.png", "caption": "Figure 12: The correlations between log2\u2061Bsubscript2\ud835\udc35\\log_{2}Broman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_B and ND\ud835\udc41\ud835\udc37\\frac{N}{D}divide start_ARG italic_N end_ARG start_ARG italic_D end_ARG. The size of the data point is proportional to D\ud835\udc37Ditalic_D.", "description": "Figure 12 shows the relationship between the block size of scaling factors (B) and the ratio of model size (N) to data size (D).  Specifically, it plots log\u2082B against log\u2081\u2080(N/D), illustrating how the choice of block size impacts the scaling behavior as model and dataset sizes vary.  The size of each point in the graph corresponds to the dataset size (D), making larger datasets more visually prominent.", "section": "3.6 Block Size of Scaling Factor"}, {"figure_path": "https://arxiv.org/html/2501.02423/x15.png", "caption": "Figure 13: The fitting results of the tensor-wise scaling law. The size of the data point is proportional to D\ud835\udc37Ditalic_D.", "description": "Figure 13 presents the results obtained by fitting the tensor-wise scaling law.  This scaling law models the relationship between the training loss of a large language model (LLM) and key parameters, specifically the data size, model size, and block size of scaling factors. The figure visually displays the agreement between the predicted loss values (from the scaling law) and the actual losses observed during experiments using the tensor-wise scaling strategy. The size of each data point in the figure is directly proportional to the data size (D), providing a visual representation of how the data size relates to model performance under the tensor-wise scaling approach.  This allows for a visual assessment of the accuracy of the tensor-wise scaling law.", "section": "3.6 Block Size of Scaling Factor"}, {"figure_path": "https://arxiv.org/html/2501.02423/x16.png", "caption": "Figure 14: The fitting results of our scaling law for floating-point quantization training. Data point size is proportional to D\ud835\udc37Ditalic_D. The star points (1.2B models) are our validation.", "description": "Figure 14 shows the results of the proposed scaling law for low-precision floating-point training.  The plot compares predicted loss values from the scaling law against actual measured losses across a range of training configurations. Each point represents a different training setup. Point size is proportional to the training dataset size (D). The star points show model validation using 1.2 billion parameter models which are not part of the training data used to generate the scaling law.", "section": "3.3 Basic Scaling Law Form"}, {"figure_path": "https://arxiv.org/html/2501.02423/x17.png", "caption": "Figure 15: The optimal float layouts of different bit widths.", "description": "This figure visualizes the optimal allocation of exponent and mantissa bits for various floating-point precisions (4, 8, and 16 bits).  It shows how the optimal bit distribution changes as the total number of bits in the floating-point representation increases.  The optimal layout is determined by minimizing the loss of information due to quantization, as derived from the proposed scaling law in the paper.", "section": "4.2 Implication-1: Optimal Float Layout Analysis"}, {"figure_path": "https://arxiv.org/html/2501.02423/x18.png", "caption": "Figure 16: Variation of loss with data size under different floating-point quantization settings.", "description": "This figure shows how the training loss changes with respect to the size of the training dataset for different floating-point quantization configurations.  The x-axis represents the dataset size (D), and the y-axis represents the training loss (L).  Multiple lines are presented, each corresponding to a different combination of exponent (E) and mantissa (M) bits in the floating-point format.  This illustrates how the optimal amount of training data might vary depending on the chosen quantization precision.", "section": "3.5 Exponent and Mantissa"}, {"figure_path": "https://arxiv.org/html/2501.02423/x19.png", "caption": "Figure 17: Under the constraint of computing the budget with block size (B\ud835\udc35Bitalic_B) set to 128, and based on the results of our experimental data fitting, the optimal precision (P\ud835\udc43Pitalic_P) values for different data sizes (D\ud835\udc37Ditalic_D) can be deduced. As depicted, across a substantially broad range of data sizes from 0.1T to 100T, the optimal precision value consistently falls within the range of 4 to 8 bits.", "description": "This figure shows the relationship between optimal precision and data size under a fixed computational budget.  The experiment was conducted with a block size (B) of 128.  The results demonstrate that across a wide range of data sizes (0.1T to 100T), the optimal precision consistently falls between 4 and 8 bits. This suggests that a moderate precision is generally optimal, even with very large datasets.", "section": "4.4 Implication-3: Compute-Optimality with Fixed Configurations"}, {"figure_path": "https://arxiv.org/html/2501.02423/x20.png", "caption": "Figure 18: The optimal cost-performance ratio precision as a function of the total compute budget, illustrating the relationship between precision (P\ud835\udc43Pitalic_P) and computational budget (C\ud835\udc36Citalic_C) when the block size (B\ud835\udc35Bitalic_B) is set to 128 and k=6/16\ud835\udc58616k=6/16italic_k = 6 / 16.", "description": "Figure 18 shows the relationship between the optimal precision (number of bits used for computation) and the total computational cost.  The optimal precision is determined by balancing the trade-off between achieving high accuracy and minimizing the computational resources. As the computational budget increases, the optimal precision increases but eventually plateaus. This is because with a larger budget, the model can afford higher precision without significantly sacrificing performance. This figure highlights that there is a sweet spot for computational cost and precision. It is generated by setting the block size (B) to 128 and k to 6/16 in the equation derived by the authors.", "section": "4.4. Implication-3: Compute-Optimality with Fixed Configurations"}]