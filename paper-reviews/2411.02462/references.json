{"references": [{"fullname_first_author": "M. Tufano", "paper_title": "Unit test case generation with transformers and focal context", "publication_date": "2021-XX-XX", "reason": "This paper introduces ATHENATEST, a tool for automated unit test generation, which is a central topic of the current research paper."}, {"fullname_first_author": "M. L. Siddiq", "paper_title": "Using large language models to generate junit tests: An empirical study", "publication_date": "2024-XX-XX", "reason": "This paper evaluates the effectiveness of LLMs in automated unit test generation, providing a direct comparison point for the current research."}, {"fullname_first_author": "Z. Yuan", "paper_title": "No more manual tests? Evaluating and improving chatgpt for unit test generation", "publication_date": "2023-XX-XX", "reason": "This paper explores the use of ChatGPT for unit test generation, a prominent LLM that is also referenced in this current study"}, {"fullname_first_author": "M. Sch\u00e4fer", "paper_title": "An empirical evaluation of using large language models for automated unit test generation", "publication_date": "2023-XX-XX", "reason": "This study performs a large-scale empirical evaluation of LLMs for unit test generation, providing valuable insights that influence the direction of the current paper."}, {"fullname_first_author": "S. Ayupov", "paper_title": "Parameter-efficient fine-tuning of transformers for source code", "publication_date": "2022-12-XX", "reason": "This paper investigates parameter-efficient fine-tuning (PEFT) methods for source code, which are crucial for the cost-effective approach adopted in the current research"}]}