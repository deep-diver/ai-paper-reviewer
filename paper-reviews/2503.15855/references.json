{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "NeRF is fundamental in 3D scene representation using neural radiance fields, influencing many subsequent 3D generative models."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "This paper introduces 3D Gaussian Splatting, a method for real-time rendering that preserves high-fidelity details, making it a popular choice in recent 3D generation approaches."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper is one of the pivotal developments in diffusion models, which has gained prominence in high-fidelity generation across various modalities, influencing 3D generative models as well."}, {"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2023-01-01", "reason": "DreamFusion leverages score distillation sampling with 2D diffusion models to generate 3D content, being a prominent text-to-3D generation method."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces the T5 model, utilized in video generation to extract text embeddings, being a crucial component of text-conditioned generative approaches."}]}