[{"figure_path": "https://arxiv.org/html/2501.09484/x1.png", "caption": "Figure 1. Using the same patient records and doctor model, our patient simulator (shown on the right in the figure) is compared to the baseline patient simulator (prompt engineering on GPT-4o, shown on the left in the figure). Online consultation dialogues are divided into inquiry and diagnosis stages, with D representing the doctor and P representing the patient in the figure. Based on the predefined set of dialogue strategies outlined in this paper, the dialogue strategies output by our model are highlighted in purple. The output from our patient simulator may contain emotions or proactive questions, marked in green. In contrast, the baseline tends to provide more comprehensive symptoms in the first round, with additional symptoms and resulting significant differences highlighted in red. These dimensions illustrate that our model better approximates a real patient.", "description": "This figure compares two patient simulators used in online medical consultations: a baseline simulator (using prompt engineering on GPT-4) and a new patient simulator developed by the authors. Both simulators engage with the same doctor model and patient records. The consultation is divided into two stages: inquiry and diagnosis.  The authors' model's dialogue strategies are highlighted in purple, while expressions of emotion or proactive questions are shown in green.  In contrast, the baseline model outputs are highlighted in red to emphasize the more extensive symptom information provided in the initial round compared to a typical patient. This visual comparison demonstrates that the authors' simulator more accurately reflects the behavior of a real patient during an online consultation.", "section": "2 Patient Simulator"}, {"figure_path": "https://arxiv.org/html/2501.09484/x2.png", "caption": "Figure 2. Prompts for synthesizing patient simulator training dialogues.", "description": "This figure displays the system prompts used for synthesizing training dialogues for the patient simulator.  The prompts guide the generation of realistic doctor-patient conversations, providing examples of patient records and dialogue strategy flows for the system to follow. This ensures the simulated dialogues accurately reflect real-world interactions, making the patient simulator more effective in training doctor models.", "section": "2 Patient Simulator"}, {"figure_path": "https://arxiv.org/html/2501.09484/x3.png", "caption": "Figure 3. The system prompt of our patient simulator.", "description": "This figure shows the system prompt used to instruct the patient simulator. The prompt instructs the model to act as a patient providing information to a doctor.  The prompt includes a placeholder for the patient's personal medical records, which are dynamically inserted during each simulation. The key idea is that this prompt is designed to elicit realistic patient responses by providing a clear role and context.", "section": "2 Patient Simulator"}, {"figure_path": "https://arxiv.org/html/2501.09484/x4.png", "caption": "Figure 4. Workflow for assessing diagnostic accuracy in conversations using LLMs.", "description": "This figure illustrates the workflow used to evaluate the diagnostic accuracy of large language models (LLMs) in conversations.  It starts with patient records, which are used in a simulated doctor-patient dialogue.  The dialogue is then assessed by extracting the diagnosed disease. The extracted diagnosis is then compared to the ground truth diagnosis (the actual disease) and a score is generated representing the accuracy of the LLM's diagnostic abilities.  This workflow helps to quantify the performance of the LLMs in a realistic conversational setting.", "section": "3 Relationship Between Inquiry and Diagnosis: Impact on Diagnostic Accuracy"}, {"figure_path": "https://arxiv.org/html/2501.09484/x5.png", "caption": "Figure 5. Patients consistently use our patient simulator, and doctors initially employ different models to interact with the simulator for fixed n rounds (x-axis, n values are 1, 2, 3, 4, 5) to generate inquiry records. These records are then diagnosed using different doctor models, and the diagnostic accuracy (y-axis) is calculated.", "description": "This figure displays the diagnostic accuracy achieved when using different doctor models to diagnose inquiry records generated through interactions with various inquiry models and the patient simulator.  The x-axis represents the number of inquiry rounds (n=1,2,3,4,5), simulating the length of the doctor-patient conversation. The y-axis shows the resulting diagnostic accuracy.  The consistent use of the patient simulator ensures consistent patient responses across all tests, isolating the impact of the different inquiry and diagnosis models on accuracy. Each subplot represents a different doctor model used for diagnosis.", "section": "3 Relationship Between Inquiry and Diagnosis: Impact on Diagnostic Accuracy"}, {"figure_path": "https://arxiv.org/html/2501.09484/x6.png", "caption": "Figure 6. Examples of four types of inquiry with D representing the doctor and P representing the patient in the figure.", "description": "This figure illustrates examples of the four types of inquiries used in online medical consultations.  The four types are: Chief Complaint Inquiry (doctor asks about the patient's main concern), Specification of Known Symptoms (doctor seeks details about symptoms already mentioned), Inquiry about Accompanying Symptoms (doctor inquires about related symptoms), and Gathering Family or Medical History (doctor asks about family medical history).  Each type is shown with a short doctor-patient dialogue exchange to exemplify the interaction.", "section": "4 Inquiry Differences Among Models"}, {"figure_path": "https://arxiv.org/html/2501.09484/x7.png", "caption": "Figure 7. The comparison focuses on the distribution of four inquiry types across GPT-4o, GPT-4o-mini, and Claude-3-5-sonnet as inquiry models, segmented by inquiry rounds. The x-axis represents the inquiry models, while the y-axis indicates the proportion of the four inquiry types.", "description": "Figure 7 presents a comparison of the distribution of four inquiry types across three different language models (GPT-40, GPT-40-mini, and Claude-3-5-sonnet) used for generating inquiries in a simulated medical consultation.  The models' inquiries are categorized into four types: Chief Complaint Inquiry, Specification of Known Symptoms, Inquiry about Accompanying Symptoms, and Gathering Family or Medical History.  The figure displays this distribution for each model across different numbers of inquiry rounds (turns in the conversation), providing a visual representation of how the models approach the inquiry process in terms of the types of questions asked and the relative frequency of those types. The x-axis identifies the language model, and the y-axis shows the percentage of each inquiry type.", "section": "4 Inquiry Differences Among Models"}, {"figure_path": "https://arxiv.org/html/2501.09484/x8.png", "caption": "Figure 8. Inquiry Type Annotation Prompt", "description": "Figure 8 details the prompt used to annotate the type of inquiries made in doctor-patient dialogues.  The prompt instructs annotators to mark whether a doctor's response contains inquiries about main symptoms, details of already-mentioned symptoms, accompanying symptoms, or family/medical history.  It also asks for marking whether the doctor provides medical diagnoses or advice. Specific instructions and output formatting guidelines are also included to ensure consistent annotation.", "section": "4 Inquiry Differences Among Models"}]