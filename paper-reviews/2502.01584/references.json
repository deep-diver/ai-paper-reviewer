{"references": [{"fullname_first_author": "Fran\u00e7ois Chollet", "paper_title": "On the Measure of Intelligence", "publication_date": "2019-11-01", "reason": "This paper introduces the ARC-AGI benchmark, a widely cited standard in AI reasoning and abstraction, establishing a baseline for evaluating AI progress in these areas and influencing the design of subsequent benchmarks."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training Verifiers to Solve Math Word Problems", "publication_date": "2021-11-01", "reason": "This paper presents the GSM8K benchmark, a significant contribution to evaluating mathematical reasoning capabilities of language models, frequently used as a comparison point in subsequent research."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "publication_date": "2025-01-01", "reason": "This paper introduces DeepSeek R1, a state-of-the-art reasoning model that is directly compared against in the current paper\u2019s experiments, highlighting its capabilities and limitations compared to other models."}, {"fullname_first_author": "Google", "paper_title": "Gemini 2.0 Flash Thinking Experimental", "publication_date": "2024-12-01", "reason": "This paper introduces Google\u2019s Gemini 2.0 Flash Thinking model, another key model in the current paper's experimental evaluation, offering a direct comparison for analysis of different reasoning approaches."}, {"fullname_first_author": "David Rein", "paper_title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "publication_date": "2024-08-01", "reason": "This paper introduces the GPQA benchmark, focusing on challenging domain-specific questions, useful as a contrasting benchmark for evaluating reasoning models in different knowledge domains, highlighting limitations in specialized vs general knowledge."}]}