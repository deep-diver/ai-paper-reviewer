{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a foundational vision-language model that significantly influenced the development of the BIOMEDICA model and its evaluation strategies."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging Properties in Self-Supervised Vision Transformers", "publication_date": "2021-01-01", "reason": "DINOv2, a self-supervised vision transformer model presented in this paper, is used for feature extraction in the BIOMEDICA dataset creation pipeline."}, {"fullname_first_author": "Karan Desai", "paper_title": "RedCaps: Web-Curated Image-Text Data Created by the People, for the People", "publication_date": "2021-01-01", "reason": "This work discusses the creation of large-scale datasets using web-based resources, which is relevant to the BIOMEDICA project's approach of leveraging publicly accessible biomedical literature."}, {"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This report details GPT-4, a large language model which informs the methodology of BIOMEDICA for creating and using vision-language models."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An Open Large-Scale Dataset for Training Next-Generation Image-Text Models", "publication_date": "2022-12-01", "reason": "This paper introduces LAION-5B, a massive dataset used for training large vision-language models, which is referenced for comparison and contextualization within the BIOMEDICA project."}]}