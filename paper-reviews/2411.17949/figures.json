[{"figure_path": "https://arxiv.org/html/2411.17949/x1.png", "caption": "Figure 1: Grid test for instance control. (a) We structure the region positions and instance captions into a single plain caption, then prompt DALL-E 3 to generate a nine-grid image. (b) We apply ROICtrl to generate a nine-grid image based on instance captions.", "description": "This figure compares the instance control capabilities of DALL-E 3 and ROICtrl.  Panel (a) shows the results of prompting DALL-E 3 with a single caption that attempts to describe nine different image regions and their contents. The limitations of relying solely on natural language for precise positional and attribute control are evident in the resulting image. Panel (b) demonstrates the superior performance of ROICtrl in generating the same nine-grid image.  ROICtrl leverages regional instance control, where each instance is specified by a bounding box paired with a free-form caption, enabling significantly more accurate and detailed control over the composition of the generated image.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2411.17949/x2.png", "caption": "Figure 2: Applications of ROICtrl. A trained ROICtrl adapter can extend existing diffusion models (a) and their community-finetuned versions (b) to multi-instance generation. Additionally, it can collaborate with spatial-based add-ons (c) and embedding-based add-ons (d, e) to offer fine-grained control over spatial or identity information. ROICtrl can also be applied to continuous generation settings (f). Due to legal considerations, we do not display customized results involving human identity.", "description": "Figure 2 showcases the versatility of ROICtrl in various visual generation scenarios.  Panel (a) demonstrates ROICtrl's ability to enhance standard and community-modified diffusion models to generate images with multiple instances, unlike typical methods that struggle with this complexity.  Building on this, panels (b) through (e) illustrate ROICtrl's seamless integration with other popular add-ons.  Specifically, (b) shows its compatibility with different community models, (c) demonstrates its functionality when paired with spatial-based add-ons to fine-tune spatial aspects of generation, while (d) and (e) highlight its performance with embedding-based add-ons for more precise control over instance identities. Finally, (f) showcases ROICtrl's ability to perform continuous generation, where the model iteratively refines and extends existing images.  Note that human identity images have been excluded due to ethical considerations.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2411.17949/x3.png", "caption": "Figure 3: Illustration of different ROI injection designs. \u230a\u22c5\u2309delimited-\u230a\u2309\u22c5\\lfloor\\cdot\\rceil\u230a \u22c5 \u2309 denotes coordinate quantization to the nearest integer.", "description": "Figure 3 illustrates three different approaches for injecting Region of Interest (ROI) information into a visual generation model.  (a) shows ROI injection via embedding, where bounding box coordinates and instance captions are combined into embeddings and fed into a self-attention mechanism. This method is implicit and may suffer from attribute leakage. (b) demonstrates ROI injection with an attention mask, where an attention mask isolates each ROI during caption injection, improving alignment but adding computational overhead.  (c) presents the authors' proposed method using ROI-Align and ROI-Unpool.  ROI-Align extracts ROI features, while ROI-Unpool enables precise, efficient reconstruction of the ROIs on the high-resolution feature map.  The notation \u230a\u22c5\u2309 indicates that coordinates are quantized to the nearest integer in (a) and (b), highlighting a potential source of error.", "section": "2. Related Work"}, {"figure_path": "https://arxiv.org/html/2411.17949/x4.png", "caption": "Figure 4: Illustration of ROI-Unpool. The dashed grid represents the spatial features, while the solid grid represents the ROI features. Similar to ROI-Align\u00a0[17], ROI-Unpool avoids coordinate quantization during computation.", "description": "Figure 4 illustrates the ROI-Unpool operation, a key component of the ROICtrl model.  It highlights the difference between spatial features (represented by a dashed grid) and ROI features (represented by a solid grid).  The figure shows how ROI-Unpool, similar to ROI-Align, avoids coordinate quantization during computation, thus ensuring accurate and efficient manipulation of regions of interest within high-resolution feature maps for visual generation. This is crucial because it avoids the loss of information and computational inefficiencies associated with directly applying operations to lower-resolution feature maps.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2411.17949/x5.png", "caption": "Figure 5: Detailed structure of ROICtrl. In parallel with the pretrained global caption injection, we introduce an additional instance caption injection. The global attention output and instance attention output are then fused using learnable blending.", "description": "ROICtrl's architecture is shown, detailing how it integrates with pre-trained diffusion models.  It consists of two parallel paths: one for global caption processing (pretrained) and another for instance caption processing (newly added).  Both paths utilize cross-attention mechanisms to generate attention maps (global and instance-specific). A learnable attention blending module then combines these attention maps to produce a final output that incorporates both global and instance-level information for refined image generation. The instance-specific pathway also incorporates ROI-Align and ROI-Unpool operations for precise spatial control over individual instances.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2411.17949/x6.png", "caption": "Figure 6: Qualitative comparison on ROICtrl-Bench. Track 1 and 2 examine template-based instance caption, while track 3 and 4 evaluate free-form instance caption. [ID] denotes in-distribution caption derived from real dataset, and [OOD] denotes out-of-distribution caption generated by GPT-4\u00a0[1].", "description": "Figure 6 presents a qualitative comparison of the ROICtrl model's performance against other state-of-the-art instance control methods on the ROICtrl-Bench benchmark. The benchmark consists of four tracks. Tracks 1 and 2 evaluate the models' ability to handle template-based instance captions (where captions follow a specific format), while tracks 3 and 4 assess their performance with free-form instance captions (where captions are less structured and more natural).  In-distribution (ID) captions are those taken directly from the real dataset, whereas out-of-distribution (OOD) captions were generated using GPT-4, representing a more challenging scenario for the models. The figure showcases example image generations from each model and track, highlighting their strengths and weaknesses in handling various types of instance captions.", "section": "3.4 Application"}, {"figure_path": "https://arxiv.org/html/2411.17949/x7.png", "caption": "Figure 7: Ablation study comparing ROICtrl and embedding-based injection (GLIGEN*). ROICtrl achieves faster convergence, improved spatial and regional text alignment, and flexible inference aspect ratios.", "description": "Figure 7 presents an ablation study comparing the performance of ROICtrl against a baseline method, GLIGEN*, which uses embedding-based injection.  The study evaluates several key aspects of model performance, including convergence speed, the accuracy of spatial alignment (how well the generated image matches the specified locations), and the accuracy of regional text alignment (how well the generated image matches the textual descriptions within different regions).  Further, the figure shows that ROICtrl maintains robust performance across various aspect ratios during inference. This demonstrates ROICtrl's improved efficiency, precision, and adaptability compared to the GLIGEN* baseline.", "section": "4.4 Ablation Study"}, {"figure_path": "https://arxiv.org/html/2411.17949/x8.png", "caption": "Figure 8: Effect of global attention regularization \u2112r\u2062e\u2062gsubscript\u2112\ud835\udc5f\ud835\udc52\ud835\udc54\\mathcal{L}_{reg}caligraphic_L start_POSTSUBSCRIPT italic_r italic_e italic_g end_POSTSUBSCRIPT. Adding \u2112r\u2062e\u2062gsubscript\u2112\ud835\udc5f\ud835\udc52\ud835\udc54\\mathcal{L}_{reg}caligraphic_L start_POSTSUBSCRIPT italic_r italic_e italic_g end_POSTSUBSCRIPT reduces the weight of the global attention output within the ROI, leading to improved regional text alignment.", "description": "This figure shows the effect of adding a regularization term,  \u2112r\u2062e\u2062gsubscript\u2112\ud835\udc5f\ud835\udc52\ud835\udc54\n\\mathcal{L}_{reg} , to the loss function during training. This term reduces the impact of the global attention output within the Region of Interest (ROI), thereby sharpening the focus on the instance-specific information contained within the ROI.  The improved regional text alignment is visually shown with two example image generation outputs, one without and one with the regularization term.", "section": "3.3 ROICtrl"}, {"figure_path": "https://arxiv.org/html/2411.17949/x9.png", "caption": "Figure 9: Comparison of regional and global coordinate conditioning. Regional coordinate conditioning leads to repetition issues when the inference size is doubled relative to the training size.", "description": "This figure compares the effects of using regional versus global coordinate conditioning in a diffusion model for image generation.  The experiment shows that when the inference image size is doubled compared to the training size, using regional coordinates leads to repeated instances in the generated image. This highlights the advantage of using global coordinates for better generalization to different image sizes.", "section": "4.4.3 Key Design Choices of ROICtrl"}, {"figure_path": "https://arxiv.org/html/2411.17949/x10.png", "caption": "Figure 10: Limitation of ROICtrl. ROICtrl prioritizes the use of instance captions to solve attribute binding but performs unstably when instance boxes with similar captions are heavily overlapped.", "description": "ROICtrl tends to prioritize using instance captions to resolve attribute binding issues. However, when multiple instance boxes have similar captions and significant overlap, ROICtrl's performance becomes unstable and inconsistent, as it struggles to accurately generate the intended visual details for each instance.", "section": "Limitation Analysis"}, {"figure_path": "https://arxiv.org/html/2411.17949/x11.png", "caption": "(a) Qualitative comparison of ROICtrl and previous methods on small-sized ROIs in Instdiff-Bench\u00a0[40]. (Zoom in for details.)", "description": "This figure compares ROICtrl's performance against other methods (GLIGEN, Instance Diffusion, MIGC) on small-sized Regions of Interest (ROIs) using the InstDiff-Bench benchmark.  The goal is to assess how well each method handles the challenges of generating and controlling very small objects within an image, which are often harder to manage than larger ones.  The visual comparison shows the quality and accuracy of generated images for each method. Zooming in on the images is recommended for a clearer evaluation.", "section": "Qualitative Comparison"}, {"figure_path": "https://arxiv.org/html/2411.17949/x12.png", "caption": "(b) Qualitative comparison of ROICtrl and previous methods on out-of-distribution instance captions in Instdiff-Bench\u00a0[40].", "description": "This figure from section 6 (Detailed Evaluation Settings) compares the performance of ROICtrl against previous methods (GLIGEN, Instance Diffusion, and MIGC) on the InstDiff-Bench benchmark. The comparison focuses on the generation of images based on out-of-distribution (OOD) instance captions.  Out-of-distribution captions means the model is given descriptions it hasn't seen during training, testing its ability to generalize. The figure visually demonstrates the quality of generated images for each method, showcasing the differences in terms of accuracy and proper representation of attributes based on provided OOD captions.  Each row represents a different model. Each column shows results for the same test prompt, allowing a visual comparison of how well each model handles the out-of-distribution description.", "section": "6. Detailed Evaluation Settings"}, {"figure_path": "https://arxiv.org/html/2411.17949/x13.png", "caption": "(c) Qualitative comparison of ROICtrl and previous methods on out-of-distribution instance captions in MIG-Bench\u00a0[48].", "description": "This figure compares the performance of ROICtrl against existing methods (GLIGEN, Instance Diffusion, and MIGC) on the MIG-Bench benchmark.  Specifically, it focuses on the scenario where the models are given out-of-distribution instance captions; meaning, captions describing instances not seen during the model's training. The images generated by each method illustrate their ability to accurately depict the objects and attributes specified in these unseen captions, highlighting the differences in their capacity for precise instance control and handling of novel descriptions.", "section": "Qualitative Comparison"}]