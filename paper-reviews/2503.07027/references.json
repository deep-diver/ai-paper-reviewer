{"references": [{"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023", "reason": "This paper introduced ControlNet, a pivotal method for adding spatial control to text-to-image diffusion models, and is important because this paper builds on it."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022", "reason": "This paper introduced Latent Diffusion Models (LDM), a breakthrough in diffusion models that enabled high-resolution image synthesis, influencing the course of this paper."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023", "reason": "This paper introduced Diffusion Transformer (DiT) which is the architecture that EasyControl aims to improve, making it essential to this paper."}, {"fullname_first_author": "Hu Ye", "paper_title": "IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models", "publication_date": "2023", "reason": "This paper introduced IP-Adapter which is a method based on adapters for text-to-image diffusion models that this paper compares to, and also uses IP-Adapter as part of the multi-condition methods in the experimental section."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This paper introduced CLIP, a model that this paper uses to evaluate text consistency, and is considered fundamental in text-to-image generation."}]}