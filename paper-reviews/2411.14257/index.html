<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models &#183; AI Paper Reviews by AI</title>
<meta name=title content="Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models &#183; AI Paper Reviews by AI"><meta name=description content="LLMs' hallucinations stem from entity recognition:  SAEs reveal model 'self-knowledge', causally affecting whether it hallucinates or refuses to answer. This mechanism is even repurposed by chat finet..."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ ETH Zurich,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models"><meta property="og:description" content="LLMs‚Äô hallucinations stem from entity recognition:  SAEs reveal model ‚Äòself-knowledge‚Äô, causally affecting whether it hallucinates or refuses to answer. This mechanism is even repurposed by chat finet‚Ä¶"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-11-21T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-21T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ ETH Zurich"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/cover.png"><meta name=twitter:title content="Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models"><meta name=twitter:description content="LLMs‚Äô hallucinations stem from entity recognition:  SAEs reveal model ‚Äòself-knowledge‚Äô, causally affecting whether it hallucinates or refuses to answer. This mechanism is even repurposed by chat finet‚Ä¶"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models","headline":"Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models","abstract":"LLMs\u0026rsquo; hallucinations stem from entity recognition:  SAEs reveal model \u0026lsquo;self-knowledge\u0026rsquo;, causally affecting whether it hallucinates or refuses to answer. This mechanism is even repurposed by chat finet\u0026hellip;","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2411.14257\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2024","dateCreated":"2024-11-21T00:00:00\u002b00:00","datePublished":"2024-11-21T00:00:00\u002b00:00","dateModified":"2024-11-21T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ ETH Zurich"],"mainEntityOfPage":"true","wordCount":"5261"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2411.14257/cover_hu17529780177257700197.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2411.14257/>Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-21T00:00:00+00:00>21 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span>5261 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">25 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2411.14257/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2411.14257/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-eth-zurich/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ ETH Zurich</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#hallucination-mechanisms>Hallucination Mechanisms</a></li><li><a href=#sparse-autoencoders>Sparse Autoencoders</a></li><li><a href=#causal-effect-of-latents>Causal Effect of Latents</a></li><li><a href=#attention-head-analysis>Attention Head Analysis</a></li><li><a href=#uncertainty-modeling>Uncertainty Modeling</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#hallucination-mechanisms>Hallucination Mechanisms</a></li><li><a href=#sparse-autoencoders>Sparse Autoencoders</a></li><li><a href=#causal-effect-of-latents>Causal Effect of Latents</a></li><li><a href=#attention-head-analysis>Attention Head Analysis</a></li><li><a href=#uncertainty-modeling>Uncertainty Modeling</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2411.14257</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Javier Ferrando et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-11-22</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2411.14257 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2411.14257 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/do-i-know-this-entity-knowledge-awareness-and target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2411.14257/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large language models (LLMs) often generate incorrect information, a phenomenon known as &lsquo;hallucination.&rsquo; This paper investigates the underlying mechanisms of these hallucinations. Existing research has focused on understanding how LLMs recall facts, but less attention has been given to why they hallucinate or refuse to answer. This inability to reliably handle unknown information significantly limits their real-world applicability.</p><p>This research uses sparse autoencoders to analyze LLM internal representations. The study finds that a key aspect of hallucination involves the model&rsquo;s ability to recognize whether it possesses information about a given entity. The researchers demonstrate that these internal representations, reflecting the model&rsquo;s &lsquo;self-knowledge&rsquo;, directly influence whether it hallucinates or refuses to answer. Crucially, they show a causal relationship, proving these &lsquo;self-knowledge&rsquo; directions can be manipulated to control the model&rsquo;s responses. These findings offer significant insights into the underlying mechanisms of LLMs and open new avenues for enhancing their reliability.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-69611b7abaa772895b5df5c9f724a5c7></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-69611b7abaa772895b5df5c9f724a5c7",{strings:[" Large language models' (LLMs) hallucinations are partly caused by their ability to recognize entities they know and don't know. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-d329a6b7c08976a878f25b00a933f7e0></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-d329a6b7c08976a878f25b00a933f7e0",{strings:[" Sparse autoencoders (SAEs) help uncover internal representations within LLMs that reveal the model's 'self-knowledge' about the entities. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-6279c5ee5b49592bd57bd6153506b447></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-6279c5ee5b49592bd57bd6153506b447",{strings:[" The discovered 'self-knowledge' directions causally influence LLM behavior, specifically in their refusal to answer or hallucination of facts. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial because <strong>it addresses the widespread problem of hallucinations in large language models (LLMs)</strong>. By offering a mechanistic understanding of how and why LLMs hallucinate, it <strong>paves the way for developing more reliable and trustworthy AI systems</strong>. The findings on knowledge awareness and its causal link to hallucination offer new avenues for improving LLM design and interpretability. This is highly relevant to current trends in AI safety and the ongoing pursuit of responsible AI development. Furthermore, the introduction of sparse autoencoders as an interpretability tool opens up exciting possibilities for future research in this area.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x1.png alt></figure></p><blockquote><p>üîº The figure displays a scatter plot showing the activation frequencies of Sparse Autoencoder (SAE) latents on known and unknown entities. The x-axis represents the activation frequency for known entities, and the y-axis represents the activation frequency for unknown entities. Each point represents a latent, with its position indicating its tendency to activate for known vs. unknown entities. Latents clustered near the x-axis primarily activate on known entities, while those near the y-axis activate on unknown entities. The plot demonstrates that specific latents strongly correlate with the model&rsquo;s knowledge of the entity. The right panel illustrates the causal effect of manipulating these latents: increasing the &lsquo;known entity&rsquo; latent when querying about a fictitious athlete increases the likelihood of the model hallucinating information.</p><details><summary>read the caption</summary>Figure 1: We identify SAE latents in the final token of the entity residual stream (i.e. hidden state) that almost exclusively activate on either unknown or known entities (scatter plot on the left). Modulating the activation values of these latents, e.g. increasing the known entity latent when asking a question about a made-up athlete increases the tendency to hallucinate.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Known Entity Latent Activations</th><th>Unknown Entity Latent Activations</th></tr></thead><tbody><tr><td>Michael <span style=background-color:#82be82>Jordan</span></td><td>Michael <span style=background-color:#ffb4b4>Jo</span><span style=background-color:#ff8c8c>ordan</span></td></tr><tr><td>When was the player <span style=background-color:#aae6aa>LeBron</span> <span style=background-color:#d6f5d6>James</span> born?</td><td>When was the player Wilson <span style=background-color:#ff8c8c>Brown</span> born?</td></tr><tr><td>He was born in the city of <span style=background-color:#d6f5d6>San Francisco</span></td><td>He was born in the city of <span style=background-color:#ffb4b4>Anthon</span></td></tr><tr><td>I just watched the movie 12 <span style=background-color:#aae6aa>Angry</span> <span style=background-color:#aae6aa>Men</span></td><td>I just watched the movie 20 <span style=background-color:#ffb4b4>Angry</span> <span style=background-color:#ffb4b4>Men</span></td></tr><tr><td>The <span style=background-color:#82be82>Beatles</span> song ‚ÄòYellow <span style=background-color:#aae6aa>Submarine</span><span style=background-color:#d6f5d6>‚Äò</span></td><td>The Beatles song ‚Äò<span style=background-color:#ff8c8c>Turquoise</span> <span style=background-color:#ffb4b4>Submarine</span><span style=background-color:#ffb4b4>‚Äô</span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents pairs of sparse autoencoder latent activations. Each pair shows one activation vector that strongly responds to known entities (i.e., entities for which the model has factual information stored) and another activation vector that strongly responds to unknown entities (entities the model lacks information on). The left column displays examples of known entities (a player, a movie, a song, and a city), and the right column displays similar examples for unknown entities where some components are slightly altered, creating fictitious entities that the model is unfamiliar with. The consistent activation pattern across diverse entity types (movies, cities, songs, and players) suggests the latents&rsquo; reliability in distinguishing between known and unknown entities.</p><details><summary>read the caption</summary>Table 1: Pair of sparse autoencoder latents that activate on known (left) and unknown entities (right) respectively. They fire consistently across entity types (movies, cities, songs, and players).</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Hallucination Mechanisms<div id=hallucination-mechanisms class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hallucination-mechanisms aria-label=Anchor>#</a></span></h4><p>Understanding the mechanisms behind large language model (LLM) hallucinations is crucial for improving their reliability. While LLMs demonstrate impressive capabilities, their propensity for generating factually incorrect or nonsensical information, known as hallucinations, significantly limits their real-world applications. Research into hallucination mechanisms suggests that these are multifaceted, stemming from various sources like <strong>flawed training data</strong>, <strong>inconsistent information retrieval</strong>, and limitations in the models&rsquo; <strong>ability to assess the confidence of their own predictions</strong>. <strong>A key factor appears to be the model&rsquo;s recognition of entities</strong>: the ability to identify and recall facts about specific entities. If the model encounters an entity it has no information about, it&rsquo;s more prone to hallucination, possibly trying to synthesize information based on patterns learned during training rather than admitting its lack of knowledge. Further investigation into how LLMs internally represent and process information, as well as the development of better methods for assessing model uncertainty, are vital for addressing this critical issue and improving the reliability and trustworthiness of LLMs.</p><h4 class="relative group">Sparse Autoencoders<div id=sparse-autoencoders class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sparse-autoencoders aria-label=Anchor>#</a></span></h4><p>The section on Sparse Autoencoders (SAEs) highlights their crucial role as an <strong>interpretability tool</strong> in the paper. SAEs help uncover <strong>meaningful directions</strong> within the complex representation space of large language models (LLMs), essentially revealing the model&rsquo;s internal logic. <strong>Sparse coding</strong> is key here, allowing the identification of significant features (directions) that explain model behavior, like the crucial distinction between recognizing a known entity versus an unknown one. This is particularly important in understanding LLM hallucinations. The use of SAEs moves beyond simple correlation analysis, offering insights into <strong>causal relationships</strong>. The ability to steer the model&rsquo;s responses by manipulating these discovered directions showcases the <strong>interpretability and control</strong> afforded by the SAE technique. In essence, SAEs provide a mechanistic lens, not just a descriptive one, for probing the inner workings of LLMs, especially regarding knowledge awareness and hallucination.</p><h4 class="relative group">Causal Effect of Latents<div id=causal-effect-of-latents class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#causal-effect-of-latents aria-label=Anchor>#</a></span></h4><p>The heading &lsquo;Causal Effect of Latents&rsquo; suggests an investigation into whether manipulating latent variables within a model directly influences its output. This is a crucial aspect of interpretability research because it moves beyond mere correlation to demonstrate causation. The study likely involves interventions, where specific latent activations are altered and the resulting changes in model behavior are carefully measured. A key finding would be <strong>evidence supporting a causal link</strong>, showing that specific changes in latent states reliably lead to predictable changes in the model&rsquo;s responses. This is important because it can help <strong>identify critical components</strong> in the model&rsquo;s decision-making process and potentially inform methods for controlling or improving model behavior. The strength of this causal effect (how much altering a latent impacts the output) would also be a significant finding. Furthermore, the analysis would likely address the <strong>generalizability of the causal effects</strong>, determining whether findings on specific latent variables translate to others or different input types. Ultimately, establishing a causal effect of latents offers strong support for mechanistic understanding of the model.</p><h4 class="relative group">Attention Head Analysis<div id=attention-head-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#attention-head-analysis aria-label=Anchor>#</a></span></h4><p>An attention head analysis within a research paper on large language models (LLMs) would likely involve investigating the inner workings of the attention mechanism. This would probably focus on how attention weights are assigned to different parts of the input sequence, and how these weights influence the model&rsquo;s output. A key aspect would be to analyze <strong>how attention heads specialize in processing specific types of information</strong>, such as factual knowledge versus emotional sentiment, or different grammatical roles within a sentence. The analysis might also examine <strong>the interaction between different attention heads</strong>, exploring whether they complement each other, or compete for resources. Furthermore, a comparative analysis of attention heads across different layers of the model could reveal insights into how information is processed and integrated throughout the network. By understanding attention head behavior, researchers aim to gain a <strong>deeper mechanistic understanding of LLMs</strong>, addressing concerns about transparency and robustness. Ultimately, this analysis could lead to improvements in LLM design and the development of more interpretable and trustworthy models.</p><h4 class="relative group">Uncertainty Modeling<div id=uncertainty-modeling class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#uncertainty-modeling aria-label=Anchor>#</a></span></h4><p>Uncertainty modeling in large language models (LLMs) is crucial for reliable performance, especially when dealing with situations where the model lacks complete knowledge. A robust uncertainty model would allow the LLM to <strong>express its level of confidence</strong> in its predictions, making it less prone to generating inaccurate or misleading information. This is particularly relevant for tasks requiring factual accuracy and avoiding hallucinations. Several approaches to uncertainty modeling exist, ranging from <strong>probabilistic methods</strong> to those that leverage internal model representations to identify regions of the latent space indicative of uncertainty. The integration of such models could improve trustworthiness and limit harmful consequences arising from overconfident yet inaccurate outputs. Furthermore, understanding how uncertainty is internally represented within an LLM is critical for <strong>developing effective strategies</strong> for reducing unreliable responses, potentially by adjusting training data or finetuning techniques to reward more cautious responses in situations of ambiguity or limited information. This area of research opens new avenues for improving LLM safety and usability.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x6.png alt></figure></p><blockquote><p>üîº This figure displays the performance of top 5 latent variables across different layers of a neural network model. The left panel shows the separation scores for known entities, while the right shows the scores for unknown entities. The separation score measures how well each latent distinguishes between known and unknown entities. Higher scores indicate better discrimination. Error bars represent the range of scores across different entity types. The red line (&lsquo;MaxMin&rsquo;) represents the minimum separation score across all entity types for the best-performing latent in each layer. This helps visualize the generalizability of each latent across different entity types - a higher MaxMin implies broader applicability. The overall trend shows that middle layers of the network achieve the best performance in distinguishing between known and unknown entities.</p><details><summary>read the caption</summary>Figure 2: Layerwise evolution of the Top 5 latents in Gemma 2 2B SAEs, as measured by their known (left) and unknown (right) latent separation scores (sknownsuperscriptùë†knowns^{\text{known}}italic_s start_POSTSUPERSCRIPT known end_POSTSUPERSCRIPT and sunknownsuperscriptùë†unknowns^{\text{unknown}}italic_s start_POSTSUPERSCRIPT unknown end_POSTSUPERSCRIPT). Error bars show maximum and minimum scores. MaxMin (red line) refers to the minimum separation score across entities of the best latent. This represents how entity-agnostic is the most general latent per layer. In both cases, the middle layers provide the best-performing latents.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x7.png alt></figure></p><blockquote><p>üîº Figure 3 demonstrates the causal effect of entity recognition directions on knowledge refusal. The left panel shows the refusal rates for different entity types across various model configurations. The original model&rsquo;s refusal rate is compared against models steered using known and unknown entity latents. An orthogonalized model (where the influence of the unknown entity latent is removed) is also included as a control. The results demonstrate a notable increase in refusal rate when the model is steered with the unknown entity latent and a decrease in refusal when steered with the known entity latent. This suggests that the model&rsquo;s knowledge of an entity directly impacts its tendency to answer questions about it. The right panel illustrates an example of steering the model with the unknown entity latent to cause a refusal to answer a question about a well-known basketball player, thus providing concrete support for the findings in the left panel.</p><details><summary>read the caption</summary>Figure 3: Left: Number of times Gemma 2 2B refuses to answer in 100 queries about unknown entities. We examine the unmodified original model, the model steered with the known entity latent and unknown entity latent, and the model with the unknown entity latent projected out of its weights (referred to as Orthogonalized model). Steering with (10) random latents are shown for comparison. Right:¬†This example illustrates the effect of steering with the unknown entity recognition latent (same as in¬†Table¬†1). The steering induces the model to refuse to answer about a well-known basketball player.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x10.png alt></figure></p><blockquote><p>üîº This figure demonstrates the effect of entity recognition (known vs. unknown) on the attention mechanism of a language model. Parts (a) and (b) show the results of activation patching, a technique where activations from a &lsquo;clean&rsquo; forward pass (with a known entity) are inserted into a corrupted forward pass (with an unknown entity). The logit difference (the difference between the probabilities of correct and incorrect predictions) is then measured. Part (c) shows that attention paid to the last token of the entity is higher for known entities in attribute-extraction heads. Parts (d), (e), and (f) show how manipulating (steering) the activations of the last token with the known entity latent (e), the unknown entity latent (d), or a random vector (f) impacts attention scores on the entity, thus demonstrating the causal effect of entity recognition on the attention mechanism.</p><details><summary>read the caption</summary>Figure 4: (a,b) Activation patching on the residual streams and the output of attention heads in the last position (song entities). We patch clean (from known entities prompts) representations into a corrupted forward pass (from unknown entities prompts) and measure the logit difference recovered. (c) Attention paid from the last position to the last token of the entity is greater when faced with a known entity in attribute-extraction heads. (d,e,f) Effect on attention scores, as in (c), after steering the last token of the entity with the unknown entity latent (d), known entity latent (e), and a random vector with same norm (f).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/extracted/6015840/images/gemma-2-9b_feature_activation_frequencies_player.png alt></figure></p><blockquote><p>üîº This figure displays the results of an experiment that investigates how steering with entity recognition latents affects a language model&rsquo;s response to questions about its knowledge. The model is presented with a question asking for certainty about its knowledge of a specific entity (e.g., &lsquo;Are you sure you know the player LeBron James?&rsquo;). The left panel shows the change in the logit difference between &lsquo;yes&rsquo; and &rsquo;no&rsquo; responses when steering with the <em>unknown</em> entity latent. The right panel shows the same, but using the <em>known</em> entity latent. The results illustrate the causal effect of these latents on the model&rsquo;s confidence and its ability to express uncertainty or confidently assert knowledge about entities.</p><details><summary>read the caption</summary>Figure 5: Logit difference between ‚ÄúYes‚Äù and ‚ÄúNo‚Äù predictions on the question ‚ÄúAre you sure you know the {entity_type} {entity_name}? Answer yes or no.‚Äù after steering with unknown (left) and known (right) entity recognition latents.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x13.png alt></figure></p><blockquote><p>üîº This figure visualizes the activation patterns of a specific latent variable, termed the &lsquo;unknown&rsquo; latent, within the Gemma 2B IT language model. The left panel displays box plots illustrating the activation values of this latent for both correct and incorrect model responses. This allows for a comparison of how strongly this latent is activated when the model produces a correct answer versus an incorrect answer. The right panel presents the top 10 tokens that exhibited the greatest increase in logit (probability) scores due to the influence of this &lsquo;unknown&rsquo; latent. This highlights the words or concepts the model strongly associates with uncertainty or situations where the model is less confident in its generated response.</p><details><summary>read the caption</summary>Figure 6: Left: Activation values of the Gemma 2B IT ‚Äòunknown‚Äô latent on correct and incorrect responses. Right: Top 10 tokens with the highest logit increases by the ‚Äòunknown‚Äô latent influence.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x14.png alt></figure></p><blockquote><p>üîº This figure illustrates the process of determining whether an entity is considered &lsquo;known&rsquo; or &lsquo;unknown&rsquo; by the language model. The process starts with a set of entities. For each entity, the model is queried about a collection of its attributes. The model&rsquo;s accuracy in answering these queries is then assessed. A threshold (œÑ) is set; if the number of correct answers exceeds this threshold, the entity is classified as &lsquo;known&rsquo;, otherwise it&rsquo;s marked as &lsquo;unknown&rsquo;. This threshold is set to 1 in this paper.</p><details><summary>read the caption</summary>Figure 7: Pipeline for classifying entities as known or unknown. Each entity ei‚àà‚Ñ∞subscriptùëíùëñ‚Ñ∞{e_{i}\in\mathcal{E}}italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà caligraphic_E is evaluated by querying the language model about a set of attributes ùíú‚Å¢(ei)ùíúsubscriptùëíùëñ\mathcal{A}(e_{i})caligraphic_A ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Classification as known or unknown is based on the accuracy of the model‚Äôs responses. In this work we set the threshold œÑ=1ùúè1\tau=1italic_œÑ = 1.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x15.png alt></figure></p><blockquote><p>üîº This figure shows a scatter plot visualizing the activation frequencies of sparse autoencoder (SAE) latents in the Gemma 2 9B model. Each point represents an SAE latent, with its x-coordinate indicating the activation frequency for known player entities and its y-coordinate indicating the activation frequency for unknown player entities. The plot helps to identify latents that are highly selective for either known or unknown entities, providing insights into the model&rsquo;s ability to distinguish between entities it possesses knowledge about and those it doesn&rsquo;t.</p><details><summary>read the caption</summary>Figure 8: Activation frequencies of Gemma 2 9B SAE latents on known and unknown Prompts, in player entity type.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/extracted/6015840/images/patching_results_gemma_2_2b.png alt></figure></p><blockquote><p>üîº This figure displays the performance of top 5 latent variables (directions in the representation space) across different layers of a Gemma 2 9B model. The performance is measured by the separation score between &lsquo;known&rsquo; and &lsquo;unknown&rsquo; entities. The left panel shows the separation scores for known entities, while the right panel displays the separation scores for unknown entities. The error bars represent the range of minimum and maximum scores observed across different entities. The &lsquo;MaxMin&rsquo; line (in red) shows the minimum separation score among all entities for the best-performing latent in each layer, indicating the most general latent that performs well on various entities. The plot demonstrates that the middle layers generally have the latents that best distinguish between known and unknown entities.</p><details><summary>read the caption</summary>Figure 9: Gemma 2 9B layerwise evolution of the Top 5 latents, as measured by their known (left) and unknown (right) latent separation scores (sknownsuperscriptùë†knowns^{\text{known}}italic_s start_POSTSUPERSCRIPT known end_POSTSUPERSCRIPT and sunknownsuperscriptùë†unknowns^{\text{unknown}}italic_s start_POSTSUPERSCRIPT unknown end_POSTSUPERSCRIPT). Error bars show maximum and minimum scores. MaxMin (red line) refers to the minimum separation score across entities of the best latent. This represents how entity-agnostic is the most general latent per layer. In both cases, middle layers provide the best-performing latents.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/extracted/6015840/images/patching_results_gemma_2_9b.png alt></figure></p><blockquote><p>üîº This figure displays the norm of the residual streams for the final token of an entity across various layers in different Gemma models. It helps visualize how the magnitude of the residual signal changes as the model processes the entity representation. By comparing the norms across different models (Gemma 2 2B, Gemma 2 2B IT, Gemma 2 9B, and Gemma 2 9B IT), we can gain insights into differences in the complexity of entity processing between the different models and whether fine-tuning affects this complexity.</p><details><summary>read the caption</summary>Figure 10: Norm of the residual streams of the last token of the entity across layers of the different Gemma models.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/extracted/6015840/images/rnd_latent_attn_original_vs_steered_entity_types_coeff_100from_known_entity_last_20,3_18,5.png alt></figure></p><blockquote><p>üîº Figure 11 demonstrates the causal effect of entity recognition latents on knowledge refusal. The left panel shows the refusal rate of Gemma 2 9B when answering 100 queries about unknown entities. Four bars represent the unmodified model, the model steered using the known entity latent, the model steered using the unknown entity latent, and an orthogonalized model (where the influence of the unknown entity latent has been removed). For comparison, the effects of steering with 10 randomly selected latents are also shown. The right panel illustrates a specific example: steering with the unknown entity latent causes the model to refuse to answer a question about a well-known basketball player, highlighting the latent&rsquo;s ability to control the model&rsquo;s knowledge refusal behavior.</p><details><summary>read the caption</summary>Figure 11: Left: Number of times Gemma 2 9B refuses to answer in 100 queries about unknown entities. We examine the unmodified original model, the model steered with the known entity latent and unknown entity latent, and the model with the unknown entity latent projected out of its weights (referred to as Orthogonalized model). Steering with 10 random latents are shown for comparison. Right:¬†This example illustrates the effect of steering with the unknown entity recognition latent. The steering induces the model to refuse to answer about a well-known basketball player.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x30.png alt></figure></p><blockquote><p>üîº This figure illustrates the activation patching method used in the paper. Activation patching involves taking activations from a &lsquo;clean&rsquo; forward pass (using a prompt with a known entity, in this case LeBron James) and injecting them into a corrupted forward pass (using a prompt with an unknown entity, Wilson Brown). This allows the researchers to isolate and analyze the effects of specific parts of the model&rsquo;s representation on downstream processing and ultimately its prediction. The figure visually depicts how the clean activations replace the corresponding part of the activations of the unknown entity run at a specific point in the model.</p><details><summary>read the caption</summary>Figure 12: Activation Patching done over the residual stream.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.14257/x31.png alt></figure></p><blockquote><p>üîº This figure displays the results of activation patching experiments conducted on the Gemma 2 2B language model. Activation patching is a technique used to understand the inner workings of a model by selectively replacing activations of a certain part of the model with activations from another part of the model, and comparing the results. The experiments were performed on three different entity types: movies (top), players (middle), and cities (bottom). Each panel shows two sub-plots. The left sub-plot presents the results of applying activation patching to the residual streams (the values that a model computes internally and uses as input for subsequent computations), while the right sub-plot shows the results of applying the patching to the last-token position attention heads. The heatmaps within the plots represent the logit differences between the results obtained by using the activation from a &lsquo;known&rsquo; entity and that from an &lsquo;unknown&rsquo; entity. Darker colors signify a more substantial difference. The goal is to reveal how the model processes information about different entities and how this process might vary based on whether or not the model has previously encountered information on a particular entity.</p><details><summary>read the caption</summary>Figure 13: Gemma 2 2B activation patching results on movies (top), players (middle) and cities (bottom).</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>&lsquo;Unknown&rsquo; Latent Activations</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>‚ÄúApparently one or two people were shooting or shooting at each other for reasons unknown when eight people were struck by the gunfire‚Äù</td><td></td><td></td><td></td><td></td></tr><tr><td>‚Ä¶and the Red Cross all responded to the fire. The cause of the fire remains under investigation.</td><td></td><td></td><td></td><td></td></tr><tr><td>The Witcher Card Game will have another round of beta tests this spring (platforms TBA)</td><td></td><td></td><td></td><td></td></tr><tr><td>His condition was not disclosed, but police said he was described as stable.</td><td></td><td></td><td></td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table displays examples of text that strongly activate the &lsquo;unknown&rsquo; latent within the Gemma 2B IT model. These examples, sourced from Neuropedia, highlight the types of statements or situations that the model identifies as uncertain or lacking sufficient information. The activation of this latent suggests a potential internal mechanism within the model that helps it identify ambiguity or uncertainty in the input text.</p><details><summary>read the caption</summary>Table 2: Activations of the Gemma 2B IT ‚Äòunknown‚Äô latent on the maximally activating examples provided by Neuropedia¬†(Lin & Bloom, 2024).</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Entity Type</th><th>Number of entities</th><th>Attributes</th></tr></thead><tbody><tr><td>Player</td><td>7487</td><td>Birthplace, birthdate, teams played</td></tr><tr><td>Movie</td><td>10895</td><td>Director, screenwriter, release date, genre, duration, cast</td></tr><tr><td>City</td><td>7904</td><td>Country, population, elevation, coordinates</td></tr><tr><td>Song</td><td>8448</td><td>Artist, album, publication year, genre</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the different entity types used in the study, the number of entities of each type, and the attributes associated with each entity type. These entities and their attributes were extracted from Wikidata, a large knowledge base, for use in evaluating the model&rsquo;s knowledge and reasoning abilities.</p><details><summary>read the caption</summary>Table 3: Entity types and attributes extracted from Wikidata.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Known Entity Latent Activations</th><th>Unknown Entity Latent Activations</th></tr></thead><tbody><tr><td>Many people use <span class=ltx_text style=background-color:#cdfbcd>Twitter</span> to share their thoughts.</td><td>Many people use Twitter to share their thoughts.</td></tr><tr><td><span class=ltx_text style=background-color:#82f582>L‚ÄôOr√©al</span> <span class=ltx_text style=background-color:#dafcda>is</span> <span class=ltx_text style=background-color:#e5fde5>a</span> large cosmetics and beauty company.</td><td>L‚ÄôOr√©al is a large cosmetics and beauty company.</td></tr><tr><td>The <span class=ltx_text style=background-color:#9ef79e>Mona Lisa</span> is displayed in the <span class=ltx_text style=background-color:#c9fbc9>Louvre</span> museum.</td><td>The Mona Lisa is displayed in the Louvre museum.</td></tr><tr><td>Many people use <span class=ltx_text style=background-color:#94f694>Snapchat</span> for sharing photos and short videos.</td><td>Many people use Snapchat for sharing photos and short videos.</td></tr><tr><td>The Ac<span class=ltx_text style=background-color:#b7f9b7>ropolis</span> is an ancient citadel in <span class=ltx_text style=background-color:#bbfabb>Athens</span>.</td><td>The Acropolis is an ancient citadel in Athens.</td></tr><tr><td>The <span class=ltx_text style=background-color:#b6f9b6>Galapagos</span> <span class=ltx_text style=background-color:#e1fde1>Islands</span> are known for their unique wildlife.</td><td>The Galapagos Islands are known for their unique wildlife.</td></tr><tr><td>Many people use <span class=ltx_text style=background-color:#a3f8a3>Dropbox</span> for cloud storage.</td><td>Many people use Dropbox for cloud storage.</td></tr><tr><td>The <span class=ltx_text style=background-color:#dafcda>pyramids</span> of <span class=ltx_text style=background-color:#c2fac2>Giza</span> were built by ancient <span class=ltx_text style=background-color:#dcfcdc>Egyptians</span>.</td><td>The pyramids of Giza were built by ancient Egyptians.</td></tr><tr><td><span class=ltx_text style=background-color:#e2fde2>Walmart</span> <span class=ltx_text style=background-color:#bdfabd>is</span> the world<span class=ltx_text style=background-color:#d3fcd3>‚Äôs</span> largest company by revenue.</td><td>Walmart is the world‚Äôs largest company by revenue.</td></tr><tr><td><span class=ltx_text style=background-color:#82f582>FedEx</span> <span class=ltx_text style=background-color:#d5fcd5>is</span> <span class=ltx_text style=background-color:#eefeee>a</span> multinational delivery services company.</td><td>FedEx is a multinational delivery services company.</td></tr><tr><td>Many people use <span class=ltx_text style=background-color:#bcfabc>Instagram</span> to share photos.</td><td>Many people use Instagram to share photos.</td></tr><tr><td>The Neuschwans<span class=ltx_text style=background-color:#b6f9b6>tein</span> Castle inspired Disney‚Äôs Sleeping <span class=ltx_text style=background-color:#bffabf>Beauty</span> <span class=ltx_text style=background-color:#e9fde9>Castle</span>.</td><td>The Neuschwanstein Castle inspired Disney‚Äôs Sleeping Beauty Castle.</td></tr><tr><td>The theory of gravity was developed by Isaac <span class=ltx_text style=background-color:#e2fde2>Newton</span>.</td><td>The theory of gravity was developed by Isaac Newton.</td></tr><tr><td>Sony <span class=ltx_text style=background-color:#cefbce>is</span> known for its electronics and entertainment products.</td><td>Sony is known for its electronics and entertainment products.</td></tr><tr><td>Many people use <span class=ltx_text style=background-color:#aef9ae>Skype</span> for voice and video calls.</td><td>Many people use Skype for voice and video calls.</td></tr><tr><td>The Sistine <span class=ltx_text style=background-color:#c8fbc8>Chapel</span> is famous for its frescoes by <span class=ltx_text style=background-color:#ccfbcc>Michelangelo</span>.</td><td>The Sistine Chapel is famous for its frescoes by Michelangelo.</td></tr><tr><td>The <span class=ltx_text style=background-color:#d3fcd3>Andes</span> are the longest continental mountain range in the world.</td><td>The Andes are the longest continental mountain range in the world.</td></tr><tr><td>The theory of evolution was proposed by Charles <span class=ltx_text style=background-color:#bffabf>Darwin</span>.</td><td>The theory of evolution was proposed by Charles Darwin.</td></tr><tr><td>Many people use <span class=ltx_text style=background-color:#c1fac1>Shopify</span> for e-commerce platforms.</td><td>Many people use Shopify for e-commerce platforms.</td></tr><tr><td><span class=ltx_text style=background-color:#ddfcdd>Honda</span> <span class=ltx_text style=background-color:#b2f9b2>is</span> known for <span class=ltx_text style=background-color:#ebfdeb>its</span> motorcycles and automobiles.</td><td>Honda is known for its motorcycles and automobiles.</td></tr></tbody></table></table></figure><blockquote><p>üîº This table displays example activations of two Gemma 2 2B sparse autoencoder latents. One latent consistently activates when the model processes information about known entities (e.g., LeBron James, Yellow Submarine). The other latent activates when processing information about entities the model doesn&rsquo;t recognize or have factual knowledge about. The examples demonstrate that these latents reliably distinguish between known and unknown entities across various types such as movies, songs, cities, and players, highlighting the model&rsquo;s capacity for recognizing its own knowledge limitations.</p><details><summary>read the caption</summary>Table 4: Activations of Gemma 2 2B entity recognition latents on LLM generated data.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Known Entity Latent Activations</th><th>Unknown Entity Latent Activations</th></tr></thead><tbody><tr><td>Druids commune with nature in the sacred grove of Elthalas.</td><td>Druids commune with nature in the sacred grove of Elthalas.</td></tr><tr><td>Adventurers seek the lost treasure of King Zephyrion.</td><td>Adventurers seek the lost treasure of King Zephyrion.</td></tr><tr><td>The Thaumaturge‚Äôs Guild specializes in Aether manipulation.</td><td>The Thaumaturge‚Äôs Guild specializes in Aether manipulation.</td></tr><tr><td>The Vorpal Blade was forged by the legendary Jabberwock.</td><td>The Vorpal Blade was forged by the legendary Jabberwock.</td></tr><tr><td>The Hivemind of Xarzith threatens galactic peace.</td><td>The Hivemind of Xarzith threatens galactic peace.</td></tr><tr><td>Travelers must appease the Stormcaller to cross the Tempest Sea.</td><td>Travelers must appease the Stormcaller to cross the Tempest Sea.</td></tr><tr><td>Archaeologists unearthed artifacts from the Zanthar civilization.</td><td>Archaeologists unearthed artifacts from the Zanthar civilization.</td></tr><tr><td>Sailors fear the treacherous waters of the Myroskian Sea.</td><td>Sailors fear the treacherous waters of the Myroskian Sea.</td></tr><tr><td>Scientists studied the unique properties of Quixium alloy.</td><td>Scientists studied the unique properties of Quixium alloy.</td></tr><tr><td>The Glibberthorn plant is known for its healing properties.</td><td>The Glibberthorn plant is known for its healing properties.</td></tr><tr><td>The Voidwalker emerged from the Abyssal Rift.</td><td>The Voidwalker emerged from the Abyssal Rift.</td></tr><tr><td>Alchemists seek to create the legendary Philosopher‚Äôs Stone.</td><td>Alchemists seek to create the legendary Philosopher‚Äôs Stone.</td></tr><tr><td>Pilgrims seek enlightenment at the Temple of Ethereal Wisdom.</td><td>Pilgrims seek enlightenment at the Temple of Ethereal Wisdom.</td></tr><tr><td>Pilots navigate through the treacherous Astral Maelstrom.</td><td>Pilots navigate through the treacherous Astral Maelstrom.</td></tr><tr><td>Merchants trade rare gems in the bazaars of Khalindor.</td><td>Merchants trade rare gems in the bazaars of Khalindor.</td></tr><tr><td>Scholars study ancient texts at the University of Arcanum.</td><td>Scholars study ancient texts at the University of Arcanum.</td></tr><tr><td>The Vexnor device revolutionized quantum computing.</td><td>The Vexnor device revolutionized quantum computing.</td></tr><tr><td>The Whispering Woods are guarded by the Sylvani.</td><td>The Whispering Woods are guarded by the Sylvani.</td></tr><tr><td>The Ethereal Conclave governs the realm of spirits.</td><td>The Ethereal Conclave governs the realm of spirits.</td></tr><tr><td>The Quantum Forge harnesses the power of Nullstone.</td><td>The Quantum Forge harnesses the power of Nullstone.</td></tr></tbody></table></table></figure><blockquote><p>üîº This table showcases the activation patterns of two distinct latent variables within the Gemma 2 2B language model. These variables, identified using sparse autoencoders, are specifically sensitive to whether the model possesses factual knowledge about an entity. The &lsquo;Known Entity Latent Activations&rsquo; column illustrates the latent&rsquo;s activation when presented with entities for which the model has stored factual information. Conversely, the &lsquo;Unknown Entity Latent Activations&rsquo; column displays the latent&rsquo;s activation when encountering entities unfamiliar to the model. Each row presents an example prompt, demonstrating how the latents respond to various types of entities and the information the model has about them. This highlights the ability of sparse autoencoders to identify and isolate interpretable features related to a language model&rsquo;s knowledge awareness.</p><details><summary>read the caption</summary>Table 5: Activations of Gemma 2 2B entity recognition latents on LLM generated data.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Question: Where was born the player Leo Barnhorst?</th><th></th></tr></thead><tbody><tr><td><strong>Œ±</strong></td><td><strong>Generation</strong></td></tr><tr><td>0</td><td>Leo Barnhorst was born in <strong>Berlin, Germany</strong></td></tr><tr><td>100</td><td>Leo Barnhorst was born in <strong>Germany</strong></td></tr><tr><td>200</td><td>I do not have access to real-time information, including personal details like birthplaces</td></tr><tr><td>300</td><td>I do not have access to real-time information, including personal details like birthplaces</td></tr><tr><td>400</td><td>I couldn‚Äôt find any information about a player named Leo Barnhorst</td></tr><tr><td>500</td><td>I believe you‚Äôre asking about <strong>Leo Barnhorst</strong>, a professional soccer player</td></tr><tr><td>600</td><td>I‚Äôm unable to provide specific details about the birthplace of a player named Leo Barnhorst</td></tr><tr><td>700</td><td>?</td></tr></tbody></table><p>Please provide me with the correct spelling of the player‚Äôs name |
| 800 | r</p><p>I believe you‚Äôre asking about <span class="ltx_text ltx_font_bold">Leo Barnhart</span>, a professional soccer player |
| 900 | r</p><p>I believe you‚Äôre asking about <strong>Leo Barnhart</strong>, a professional soccer player |
| 1000 | r</p><p>I believe you‚Äôre asking about <strong>Leo Barnhart</strong>, a professional soccer player |
| 1100 | Associate the player Leo Barnhart with the sport of <span class="ltx_text ltx_font_bold">baseball</span> |
| 1200 | discriminator: I‚Äôm sorry, but I don‚Äôt have access to real-time information, including personal details like birthplaces |</p></table></figure><blockquote><p>üîº This table shows how different steering coefficient values (Œ±) in Equation 4 affect the model&rsquo;s response when asked about the birthplace of a fictional player, Leo Barnhorst, who is not in the model&rsquo;s knowledge base. As Œ± increases, the response shifts from hallucinating a birthplace to refusing to answer, indicating the impact of steering on the balance between factual accuracy and hallucination.</p><details><summary>read the caption</summary>Table 6: Gemma 2 2B IT responses to ‚ÄòWhere was born the player Leo Barnhorst?‚Äô at different steering coefficient values, Œ±ùõº\alphaitalic_Œ± in Equation¬†4. Leo Barnhorst is unknown for Gemma 2 2B.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Head</th><th>Entity</th><th></th><th>Extracted Attributes</th></tr></thead><tbody><tr><td>L18H5</td><td>Kawhi Leonard</td><td></td><td>Clippers, Niagara, Raptors,</td></tr><tr><td></td><td>Detmold</td><td></td><td>Westfalen, Lancaster, Volkswagen</td></tr><tr><td></td><td>Boombastic</td><td></td><td>Jamaican, Reggae, Jamaica, Caribbean</td></tr><tr><td>L20H3</td><td>Kawhi Leonard</td><td></td><td>NBA, basketball, Clippers, Basketball</td></tr><tr><td></td><td>Detmold</td><td></td><td>Germans, German, Germany, Westfalen</td></tr><tr><td></td><td>Boombastic</td><td></td><td>reggae, Reggae, Jamaican, music, song</td></tr></tbody></table></table></figure><blockquote><p>üîº This table displays examples of the top tokens (words or sub-word units) generated by two specific attribute extraction heads (L18H5 and L20H3) within the Gemma 2 2B language model. These heads are responsible for extracting relevant attributes from an entity&rsquo;s context. Each row shows an example entity (e.g., Kawhi Leonard, Detmold, Boombastic) and the associated attributes predicted by the corresponding head. This illustrates the types of attributes these heads focus on and how they relate to the given entities. The diversity of entities and attributes helps demonstrate the range of tasks these heads perform within the larger model.</p><details><summary>read the caption</summary>Table 7: Examples from the top tokens promoted by the attribute extraction heads L18H5 and L20H3 in Gemma 2 2B.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-7377dc9dc350fda9c8b4e483fb301033 class=gallery><img src=https://ai-paper-reviewer.com/2411.14257/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.14257/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/&amp;title=Do%20I%20Know%20This%20Entity?%20Knowledge%20Awareness%20and%20Hallucinations%20in%20Language%20Models" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/&amp;text=Do%20I%20Know%20This%20Entity?%20Knowledge%20Awareness%20and%20Hallucinations%20in%20Language%20Models" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14257/&amp;subject=Do%20I%20Know%20This%20Entity?%20Knowledge%20Awareness%20and%20Hallucinations%20in%20Language%20Models" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2411.14257/index.md",oid_likes="likes_paper-reviews/2411.14257/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2411.14522/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A Comprehensive Multimodal Dataset Towards General Medical AI</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-21T00:00:00+00:00>21 November 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2411.15131/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">WildLMa: Long Horizon Loco-Manipulation in the Wild</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-22T00:00:00+00:00>22 November 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>