[{"figure_path": "https://arxiv.org/html/2411.14257/x1.png", "caption": "Figure 1: We identify SAE latents in the final token of the entity residual stream (i.e. hidden state) that almost exclusively activate on either unknown or known entities (scatter plot on the left). Modulating the activation values of these latents, e.g. increasing the known entity latent when asking a question about a made-up athlete increases the tendency to hallucinate.", "description": "The figure displays a scatter plot showing the activation frequencies of Sparse Autoencoder (SAE) latents on known and unknown entities.  The x-axis represents the activation frequency for known entities, and the y-axis represents the activation frequency for unknown entities. Each point represents a latent, with its position indicating its tendency to activate for known vs. unknown entities.  Latents clustered near the x-axis primarily activate on known entities, while those near the y-axis activate on unknown entities.  The plot demonstrates that specific latents strongly correlate with the model's knowledge of the entity.  The right panel illustrates the causal effect of manipulating these latents: increasing the 'known entity' latent when querying about a fictitious athlete increases the likelihood of the model hallucinating information. ", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2411.14257/x6.png", "caption": "Figure 2: Layerwise evolution of the Top 5 latents in Gemma 2 2B SAEs, as measured by their known (left) and unknown (right) latent separation scores (sknownsuperscript\ud835\udc60knowns^{\\text{known}}italic_s start_POSTSUPERSCRIPT known end_POSTSUPERSCRIPT and sunknownsuperscript\ud835\udc60unknowns^{\\text{unknown}}italic_s start_POSTSUPERSCRIPT unknown end_POSTSUPERSCRIPT). Error bars show maximum and minimum scores. MaxMin (red line) refers to the minimum separation score across entities of the best latent. This represents how entity-agnostic is the most general latent per layer. In both cases, the middle layers provide the best-performing latents.", "description": "This figure displays the performance of top 5 latent variables across different layers of a neural network model.  The left panel shows the separation scores for known entities, while the right shows the scores for unknown entities.  The separation score measures how well each latent distinguishes between known and unknown entities. Higher scores indicate better discrimination. Error bars represent the range of scores across different entity types. The red line ('MaxMin') represents the minimum separation score across all entity types for the best-performing latent in each layer. This helps visualize the generalizability of each latent across different entity types - a higher MaxMin implies broader applicability. The overall trend shows that middle layers of the network achieve the best performance in distinguishing between known and unknown entities.", "section": "Sparse Autoencoders Uncover Entity Recognition Directions"}, {"figure_path": "https://arxiv.org/html/2411.14257/x7.png", "caption": "Figure 3: Left: Number of times Gemma 2 2B refuses to answer in 100 queries about unknown entities. We examine the unmodified original model, the model steered with the known entity latent and unknown entity latent, and the model with the unknown entity latent projected out of its weights (referred to as Orthogonalized model). Steering with (10) random latents are shown for comparison. Right:\u00a0This example illustrates the effect of steering with the unknown entity recognition latent (same as in\u00a0Table\u00a01). The steering induces the model to refuse to answer about a well-known basketball player.", "description": "Figure 3 demonstrates the causal effect of entity recognition directions on knowledge refusal. The left panel shows the refusal rates for different entity types across various model configurations. The original model's refusal rate is compared against models steered using known and unknown entity latents.  An orthogonalized model (where the influence of the unknown entity latent is removed) is also included as a control.  The results demonstrate a notable increase in refusal rate when the model is steered with the unknown entity latent and a decrease in refusal when steered with the known entity latent. This suggests that the model's knowledge of an entity directly impacts its tendency to answer questions about it. The right panel illustrates an example of steering the model with the unknown entity latent to cause a refusal to answer a question about a well-known basketball player, thus providing concrete support for the findings in the left panel.", "section": "5 ENTITY RECOGNITION DIRECTIONS CAUSALLY AFFECT KNOWLEDGE REFUSAL"}, {"figure_path": "https://arxiv.org/html/2411.14257/x10.png", "caption": "Figure 4: (a,b) Activation patching on the residual streams and the output of attention heads in the last position (song entities). We patch clean (from known entities prompts) representations into a corrupted forward pass (from unknown entities prompts) and measure the logit difference recovered. (c) Attention paid from the last position to the last token of the entity is greater when faced with a known entity in attribute-extraction heads. (d,e,f) Effect on attention scores, as in (c), after steering the last token of the entity with the unknown entity latent (d), known entity latent (e), and a random vector with same norm (f).", "description": "This figure demonstrates the effect of entity recognition (known vs. unknown) on the attention mechanism of a language model.  Parts (a) and (b) show the results of activation patching, a technique where activations from a 'clean' forward pass (with a known entity) are inserted into a corrupted forward pass (with an unknown entity).  The logit difference (the difference between the probabilities of correct and incorrect predictions) is then measured. Part (c) shows that attention paid to the last token of the entity is higher for known entities in attribute-extraction heads. Parts (d), (e), and (f) show how manipulating (steering) the activations of the last token with the known entity latent (e), the unknown entity latent (d), or a random vector (f) impacts attention scores on the entity, thus demonstrating the causal effect of entity recognition on the attention mechanism.", "section": "Mechanistic Analysis"}, {"figure_path": "https://arxiv.org/html/2411.14257/extracted/6015840/images/gemma-2-9b_feature_activation_frequencies_player.png", "caption": "Figure 5: Logit difference between \u201cYes\u201d and \u201cNo\u201d predictions on the question \u201cAre you sure you know the {entity_type} {entity_name}? Answer yes or no.\u201d after steering with unknown (left) and known (right) entity recognition latents.", "description": "This figure displays the results of an experiment that investigates how steering with entity recognition latents affects a language model's response to questions about its knowledge.  The model is presented with a question asking for certainty about its knowledge of a specific entity (e.g., \"Are you sure you know the player LeBron James?\").  The left panel shows the change in the logit difference between \"yes\" and \"no\" responses when steering with the *unknown* entity latent.  The right panel shows the same, but using the *known* entity latent. The results illustrate the causal effect of these latents on the model's confidence and its ability to express uncertainty or confidently assert knowledge about entities.", "section": "Entity Recognition Directions Causally Affect Knowledge Refusal"}, {"figure_path": "https://arxiv.org/html/2411.14257/x13.png", "caption": "Figure 6: Left: Activation values of the Gemma 2B IT \u2018unknown\u2019 latent on correct and incorrect responses. Right: Top 10 tokens with the highest logit increases by the \u2018unknown\u2019 latent influence.", "description": "This figure visualizes the activation patterns of a specific latent variable, termed the 'unknown' latent, within the Gemma 2B IT language model.  The left panel displays box plots illustrating the activation values of this latent for both correct and incorrect model responses.  This allows for a comparison of how strongly this latent is activated when the model produces a correct answer versus an incorrect answer. The right panel presents the top 10 tokens that exhibited the greatest increase in logit (probability) scores due to the influence of this 'unknown' latent. This highlights the words or concepts the model strongly associates with uncertainty or situations where the model is less confident in its generated response.", "section": "Uncertainty Directions"}, {"figure_path": "https://arxiv.org/html/2411.14257/x14.png", "caption": "Figure 7: Pipeline for classifying entities as known or unknown. Each entity ei\u2208\u2130subscript\ud835\udc52\ud835\udc56\u2130{e_{i}\\in\\mathcal{E}}italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 caligraphic_E is evaluated by querying the language model about a set of attributes \ud835\udc9c\u2062(ei)\ud835\udc9csubscript\ud835\udc52\ud835\udc56\\mathcal{A}(e_{i})caligraphic_A ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Classification as known or unknown is based on the accuracy of the model\u2019s responses. In this work we set the threshold \u03c4=1\ud835\udf0f1\\tau=1italic_\u03c4 = 1.", "description": "This figure illustrates the process of determining whether an entity is considered 'known' or 'unknown' by the language model.  The process starts with a set of entities. For each entity, the model is queried about a collection of its attributes.  The model's accuracy in answering these queries is then assessed. A threshold (\u03c4) is set; if the number of correct answers exceeds this threshold, the entity is classified as 'known', otherwise it's marked as 'unknown'.  This threshold is set to 1 in this paper. ", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2411.14257/x15.png", "caption": "Figure 8: Activation frequencies of Gemma 2 9B SAE latents on known and unknown Prompts, in player entity type.", "description": "This figure shows a scatter plot visualizing the activation frequencies of sparse autoencoder (SAE) latents in the Gemma 2 9B model. Each point represents an SAE latent, with its x-coordinate indicating the activation frequency for known player entities and its y-coordinate indicating the activation frequency for unknown player entities.  The plot helps to identify latents that are highly selective for either known or unknown entities, providing insights into the model's ability to distinguish between entities it possesses knowledge about and those it doesn't.", "section": "4 Sparse Autoencoders uncover entity recognition directions"}, {"figure_path": "https://arxiv.org/html/2411.14257/extracted/6015840/images/patching_results_gemma_2_2b.png", "caption": "Figure 9: Gemma 2 9B layerwise evolution of the Top 5 latents, as measured by their known (left) and unknown (right) latent separation scores (sknownsuperscript\ud835\udc60knowns^{\\text{known}}italic_s start_POSTSUPERSCRIPT known end_POSTSUPERSCRIPT and sunknownsuperscript\ud835\udc60unknowns^{\\text{unknown}}italic_s start_POSTSUPERSCRIPT unknown end_POSTSUPERSCRIPT). Error bars show maximum and minimum scores. MaxMin (red line) refers to the minimum separation score across entities of the best latent. This represents how entity-agnostic is the most general latent per layer. In both cases, middle layers provide the best-performing latents.", "description": "This figure displays the performance of top 5 latent variables (directions in the representation space) across different layers of a Gemma 2 9B model.  The performance is measured by the separation score between 'known' and 'unknown' entities.  The left panel shows the separation scores for known entities, while the right panel displays the separation scores for unknown entities.  The error bars represent the range of minimum and maximum scores observed across different entities. The 'MaxMin' line (in red) shows the minimum separation score among all entities for the best-performing latent in each layer, indicating the most general latent that performs well on various entities. The plot demonstrates that the middle layers generally have the latents that best distinguish between known and unknown entities.", "section": "Sparse Autoencoders Uncover Entity Recognition Directions"}, {"figure_path": "https://arxiv.org/html/2411.14257/extracted/6015840/images/patching_results_gemma_2_9b.png", "caption": "Figure 10: Norm of the residual streams of the last token of the entity across layers of the different Gemma models.", "description": "This figure displays the norm of the residual streams for the final token of an entity across various layers in different Gemma models.  It helps visualize how the magnitude of the residual signal changes as the model processes the entity representation. By comparing the norms across different models (Gemma 2 2B, Gemma 2 2B IT, Gemma 2 9B, and Gemma 2 9B IT), we can gain insights into differences in the complexity of entity processing between the different models and whether fine-tuning affects this complexity.", "section": "Norm Residual Streams"}, {"figure_path": "https://arxiv.org/html/2411.14257/extracted/6015840/images/rnd_latent_attn_original_vs_steered_entity_types_coeff_100from_known_entity_last_20,3_18,5.png", "caption": "Figure 11: Left: Number of times Gemma 2 9B refuses to answer in 100 queries about unknown entities. We examine the unmodified original model, the model steered with the known entity latent and unknown entity latent, and the model with the unknown entity latent projected out of its weights (referred to as Orthogonalized model). Steering with 10 random latents are shown for comparison. Right:\u00a0This example illustrates the effect of steering with the unknown entity recognition latent. The steering induces the model to refuse to answer about a well-known basketball player.", "description": "Figure 11 demonstrates the causal effect of entity recognition latents on knowledge refusal.  The left panel shows the refusal rate of Gemma 2 9B when answering 100 queries about unknown entities. Four bars represent the unmodified model, the model steered using the known entity latent, the model steered using the unknown entity latent, and an orthogonalized model (where the influence of the unknown entity latent has been removed). For comparison, the effects of steering with 10 randomly selected latents are also shown.  The right panel illustrates a specific example:  steering with the unknown entity latent causes the model to refuse to answer a question about a well-known basketball player, highlighting the latent's ability to control the model's knowledge refusal behavior.", "section": "5 ENTITY RECOGNITION DIRECTIONS CAUSALLY AFFECT KNOWLEDGE REFUSAL"}, {"figure_path": "https://arxiv.org/html/2411.14257/x30.png", "caption": "Figure 12: Activation Patching done over the residual stream.", "description": "This figure illustrates the activation patching method used in the paper.  Activation patching involves taking activations from a 'clean' forward pass (using a prompt with a known entity, in this case LeBron James) and injecting them into a corrupted forward pass (using a prompt with an unknown entity, Wilson Brown). This allows the researchers to isolate and analyze the effects of specific parts of the model's representation on downstream processing and ultimately its prediction. The figure visually depicts how the clean activations replace the corresponding part of the activations of the unknown entity run at a specific point in the model.", "section": "6 Mechanistic Analysis"}, {"figure_path": "https://arxiv.org/html/2411.14257/x31.png", "caption": "Figure 13: Gemma 2 2B activation patching results on movies (top), players (middle) and cities (bottom).", "description": "This figure displays the results of activation patching experiments conducted on the Gemma 2 2B language model. Activation patching is a technique used to understand the inner workings of a model by selectively replacing activations of a certain part of the model with activations from another part of the model, and comparing the results.  The experiments were performed on three different entity types: movies (top), players (middle), and cities (bottom).  Each panel shows two sub-plots. The left sub-plot presents the results of applying activation patching to the residual streams (the values that a model computes internally and uses as input for subsequent computations), while the right sub-plot shows the results of applying the patching to the last-token position attention heads. The heatmaps within the plots represent the logit differences between the results obtained by using the activation from a 'known' entity and that from an 'unknown' entity. Darker colors signify a more substantial difference.  The goal is to reveal how the model processes information about different entities and how this process might vary based on whether or not the model has previously encountered information on a particular entity.", "section": "6 Mechanistic Analysis"}]