[{"content": "| Known Entity Latent Activations | Unknown Entity Latent Activations |\n|---|---| \n| Michael <span style=\"background-color:#82BE82;\">Jordan</span> | Michael <span style=\"background-color:#FFB4B4;\">Jo</span><span style=\"background-color:#FF8C8C;\">ordan</span> |\n| When was the player <span style=\"background-color:#AAE6AA;\">LeBron</span> <span style=\"background-color:#D6F5D6;\">James</span> born? | When was the player Wilson <span style=\"background-color:#FF8C8C;\">Brown</span> born? |\n| He was born in the city of <span style=\"background-color:#D6F5D6;\">San Francisco</span> | He was born in the city of <span style=\"background-color:#FFB4B4;\">Anthon</span> |\n| I just watched the movie 12 <span style=\"background-color:#AAE6AA;\">Angry</span> <span style=\"background-color:#AAE6AA;\">Men</span> | I just watched the movie 20 <span style=\"background-color:#FFB4B4;\">Angry</span> <span style=\"background-color:#FFB4B4;\">Men</span> |\n| The <span style=\"background-color:#82BE82;\">Beatles</span> song \u2018Yellow <span style=\"background-color:#AAE6AA;\">Submarine</span><span style=\"background-color:#D6F5D6;\">\u2018</span> | The Beatles song \u2018<span style=\"background-color:#FF8C8C;\">Turquoise</span> <span style=\"background-color:#FFB4B4;\">Submarine</span><span style=\"background-color:#FFB4B4;\">\u2019</span> |", "caption": "Table 1: Pair of sparse autoencoder latents that activate on known (left) and unknown entities (right) respectively. They fire consistently across entity types (movies, cities, songs, and players).", "description": "This table presents pairs of sparse autoencoder latent activations. Each pair shows one activation vector that strongly responds to known entities (i.e., entities for which the model has factual information stored) and another activation vector that strongly responds to unknown entities (entities the model lacks information on).  The left column displays examples of known entities (a player, a movie, a song, and a city), and the right column displays similar examples for unknown entities where some components are slightly altered, creating fictitious entities that the model is unfamiliar with.  The consistent activation pattern across diverse entity types (movies, cities, songs, and players) suggests the latents' reliability in distinguishing between known and unknown entities.", "section": "1 INTRODUCTION"}, {"content": "| 'Unknown' Latent Activations |\n|---|---|---|---|---|\n| \u201cApparently one or two people were shooting or shooting at each other for reasons unknown when eight people were struck by the gunfire\u201d |\n| \u2026and the Red Cross all responded to the fire. The cause of the fire remains under investigation. |\n| The Witcher Card Game will have another round of beta tests this spring (platforms TBA) |\n| His condition was not disclosed, but police said he was described as stable. |", "caption": "Table 2: Activations of the Gemma 2B IT \u2018unknown\u2019 latent on the maximally activating examples provided by Neuropedia\u00a0(Lin & Bloom, 2024).", "description": "This table displays examples of text that strongly activate the 'unknown' latent within the Gemma 2B IT model.  These examples, sourced from Neuropedia, highlight the types of statements or situations that the model identifies as uncertain or lacking sufficient information.  The activation of this latent suggests a potential internal mechanism within the model that helps it identify ambiguity or uncertainty in the input text.", "section": "7 UNCERTAINTY DIRECTIONS"}, {"content": "| Entity Type | Number of entities | Attributes |\n|---|---|---|\n| Player | 7487 | Birthplace, birthdate, teams played |\n| Movie | 10895 | Director, screenwriter, release date, genre, duration, cast |\n| City | 7904 | Country, population, elevation, coordinates |\n| Song | 8448 | Artist, album, publication year, genre |", "caption": "Table 3: Entity types and attributes extracted from Wikidata.", "description": "This table lists the different entity types used in the study, the number of entities of each type, and the attributes associated with each entity type.  These entities and their attributes were extracted from Wikidata, a large knowledge base, for use in evaluating the model's knowledge and reasoning abilities.", "section": "Methodology"}, {"content": "| Known Entity Latent Activations | Unknown Entity Latent Activations |\n|---|---| \n| Many people use <span class=\"ltx_text\" style=\"background-color:#CDFBCD;\">Twitter</span> to share their thoughts. | Many people use Twitter to share their thoughts. |\n| <span class=\"ltx_text\" style=\"background-color:#82F582;\">L\u2019Or\u00e9al</span> <span class=\"ltx_text\" style=\"background-color:#DAFCDA;\">is</span> <span class=\"ltx_text\" style=\"background-color:#E5FDE5;\">a</span> large cosmetics and beauty company. | L\u2019Or\u00e9al is a large cosmetics and beauty company. |\n| The <span class=\"ltx_text\" style=\"background-color:#9EF79E;\">Mona Lisa</span> is displayed in the <span class=\"ltx_text\" style=\"background-color:#C9FBC9;\">Louvre</span> museum. | The Mona Lisa is displayed in the Louvre museum. |\n| Many people use <span class=\"ltx_text\" style=\"background-color:#94F694;\">Snapchat</span> for sharing photos and short videos. | Many people use Snapchat for sharing photos and short videos. |\n| The Ac<span class=\"ltx_text\" style=\"background-color:#B7F9B7;\">ropolis</span> is an ancient citadel in <span class=\"ltx_text\" style=\"background-color:#BBFABB;\">Athens</span>. | The Acropolis is an ancient citadel in Athens. |\n| The <span class=\"ltx_text\" style=\"background-color:#B6F9B6;\">Galapagos</span> <span class=\"ltx_text\" style=\"background-color:#E1FDE1;\">Islands</span> are known for their unique wildlife. | The Galapagos Islands are known for their unique wildlife. |\n| Many people use <span class=\"ltx_text\" style=\"background-color:#A3F8A3;\">Dropbox</span> for cloud storage. | Many people use Dropbox for cloud storage. |\n| The <span class=\"ltx_text\" style=\"background-color:#DAFCDA;\">pyramids</span> of <span class=\"ltx_text\" style=\"background-color:#C2FAC2;\">Giza</span> were built by ancient <span class=\"ltx_text\" style=\"background-color:#DCFCDC;\">Egyptians</span>. | The pyramids of Giza were built by ancient Egyptians. |\n| <span class=\"ltx_text\" style=\"background-color:#E2FDE2;\">Walmart</span> <span class=\"ltx_text\" style=\"background-color:#BDFABD;\">is</span> the world<span class=\"ltx_text\" style=\"background-color:#D3FCD3;\">\u2019s</span> largest company by revenue. | Walmart is the world\u2019s largest company by revenue. |\n| <span class=\"ltx_text\" style=\"background-color:#82F582;\">FedEx</span> <span class=\"ltx_text\" style=\"background-color:#D5FCD5;\">is</span> <span class=\"ltx_text\" style=\"background-color:#EEFEEE;\">a</span> multinational delivery services company. | FedEx is a multinational delivery services company. |\n| Many people use <span class=\"ltx_text\" style=\"background-color:#BCFABC;\">Instagram</span> to share photos. | Many people use Instagram to share photos. |\n| The Neuschwans<span class=\"ltx_text\" style=\"background-color:#B6F9B6;\">tein</span> Castle inspired Disney\u2019s Sleeping <span class=\"ltx_text\" style=\"background-color:#BFFABF;\">Beauty</span> <span class=\"ltx_text\" style=\"background-color:#E9FDE9;\">Castle</span>. | The Neuschwanstein Castle inspired Disney\u2019s Sleeping Beauty Castle. |\n| The theory of gravity was developed by Isaac <span class=\"ltx_text\" style=\"background-color:#E2FDE2;\">Newton</span>. | The theory of gravity was developed by Isaac Newton. |\n| Sony <span class=\"ltx_text\" style=\"background-color:#CEFBCE;\">is</span> known for its electronics and entertainment products. | Sony is known for its electronics and entertainment products. |\n| Many people use <span class=\"ltx_text\" style=\"background-color:#AEF9AE;\">Skype</span> for voice and video calls. | Many people use Skype for voice and video calls. |\n| The Sistine <span class=\"ltx_text\" style=\"background-color:#C8FBC8;\">Chapel</span> is famous for its frescoes by <span class=\"ltx_text\" style=\"background-color:#CCFBCC;\">Michelangelo</span>. | The Sistine Chapel is famous for its frescoes by Michelangelo. |\n| The <span class=\"ltx_text\" style=\"background-color:#D3FCD3;\">Andes</span> are the longest continental mountain range in the world. | The Andes are the longest continental mountain range in the world. |\n| The theory of evolution was proposed by Charles <span class=\"ltx_text\" style=\"background-color:#BFFABF;\">Darwin</span>. | The theory of evolution was proposed by Charles Darwin. |\n| Many people use <span class=\"ltx_text\" style=\"background-color:#C1FAC1;\">Shopify</span> for e-commerce platforms. | Many people use Shopify for e-commerce platforms. |\n| <span class=\"ltx_text\" style=\"background-color:#DDFCDD;\">Honda</span> <span class=\"ltx_text\" style=\"background-color:#B2F9B2;\">is</span> known for <span class=\"ltx_text\" style=\"background-color:#EBFDEB;\">its</span> motorcycles and automobiles. | Honda is known for its motorcycles and automobiles. |", "caption": "Table 4: Activations of Gemma 2 2B entity recognition latents on LLM generated data.", "description": "This table displays example activations of two Gemma 2 2B sparse autoencoder latents.  One latent consistently activates when the model processes information about known entities (e.g., LeBron James, Yellow Submarine). The other latent activates when processing information about entities the model doesn't recognize or have factual knowledge about.  The examples demonstrate that these latents reliably distinguish between known and unknown entities across various types such as movies, songs, cities, and players, highlighting the model's capacity for recognizing its own knowledge limitations.", "section": "Entity Recognition Latents on Diverse Entities"}, {"content": "| Known Entity Latent Activations | Unknown Entity Latent Activations |\n|---|---| \n| Druids commune with nature in the sacred grove of Elthalas. | Druids commune with nature in the sacred grove of Elthalas. |\n| Adventurers seek the lost treasure of King Zephyrion. | Adventurers seek the lost treasure of King Zephyrion. |\n| The Thaumaturge\u2019s Guild specializes in Aether manipulation. | The Thaumaturge\u2019s Guild specializes in Aether manipulation. |\n| The Vorpal Blade was forged by the legendary Jabberwock. | The Vorpal Blade was forged by the legendary Jabberwock. |\n| The Hivemind of Xarzith threatens galactic peace. | The Hivemind of Xarzith threatens galactic peace. |\n| Travelers must appease the Stormcaller to cross the Tempest Sea. | Travelers must appease the Stormcaller to cross the Tempest Sea. |\n| Archaeologists unearthed artifacts from the Zanthar civilization. | Archaeologists unearthed artifacts from the Zanthar civilization. |\n| Sailors fear the treacherous waters of the Myroskian Sea. | Sailors fear the treacherous waters of the Myroskian Sea. |\n| Scientists studied the unique properties of Quixium alloy. | Scientists studied the unique properties of Quixium alloy. |\n| The Glibberthorn plant is known for its healing properties. | The Glibberthorn plant is known for its healing properties. |\n| The Voidwalker emerged from the Abyssal Rift. | The Voidwalker emerged from the Abyssal Rift. |\n| Alchemists seek to create the legendary Philosopher\u2019s Stone. | Alchemists seek to create the legendary Philosopher\u2019s Stone. |\n| Pilgrims seek enlightenment at the Temple of Ethereal Wisdom. | Pilgrims seek enlightenment at the Temple of Ethereal Wisdom. |\n| Pilots navigate through the treacherous Astral Maelstrom. | Pilots navigate through the treacherous Astral Maelstrom. |\n| Merchants trade rare gems in the bazaars of Khalindor. | Merchants trade rare gems in the bazaars of Khalindor. |\n| Scholars study ancient texts at the University of Arcanum. | Scholars study ancient texts at the University of Arcanum. |\n| The Vexnor device revolutionized quantum computing. | The Vexnor device revolutionized quantum computing. |\n| The Whispering Woods are guarded by the Sylvani. | The Whispering Woods are guarded by the Sylvani. |\n| The Ethereal Conclave governs the realm of spirits. | The Ethereal Conclave governs the realm of spirits. |\n| The Quantum Forge harnesses the power of Nullstone. | The Quantum Forge harnesses the power of Nullstone. |", "caption": "Table 5: Activations of Gemma 2 2B entity recognition latents on LLM generated data.", "description": "This table showcases the activation patterns of two distinct latent variables within the Gemma 2 2B language model. These variables, identified using sparse autoencoders, are specifically sensitive to whether the model possesses factual knowledge about an entity.  The 'Known Entity Latent Activations' column illustrates the latent's activation when presented with entities for which the model has stored factual information. Conversely, the 'Unknown Entity Latent Activations' column displays the latent's activation when encountering entities unfamiliar to the model.  Each row presents an example prompt, demonstrating how the latents respond to various types of entities and the information the model has about them. This highlights the ability of sparse autoencoders to identify and isolate interpretable features related to a language model's knowledge awareness.", "section": "Entity Recognition Directions Causally Affect Knowledge Refusal"}, {"content": "| Question: Where was born the player Leo Barnhorst? ||\n|---|---| \n| **\u03b1** | **Generation** |\n| 0 | Leo Barnhorst was born in **Berlin, Germany** | \n| 100 | Leo Barnhorst was born in **Germany** | \n| 200 | I do not have access to real-time information, including personal details like birthplaces | \n| 300 | I do not have access to real-time information, including personal details like birthplaces | \n| 400 | I couldn\u2019t find any information about a player named Leo Barnhorst | \n| 500 | I believe you\u2019re asking about **Leo Barnhorst**, a professional soccer player | \n| 600 | I\u2019m unable to provide specific details about the birthplace of a player named Leo Barnhorst | \n| 700 | ?\n\nPlease provide me with the correct spelling of the player\u2019s name | \n| 800 | r\n\nI believe you\u2019re asking about <span class=\"ltx_text ltx_font_bold\">Leo Barnhart</span>, a professional soccer player | \n| 900 | r\n\nI believe you\u2019re asking about **Leo Barnhart**, a professional soccer player | \n| 1000 | r\n\nI believe you\u2019re asking about **Leo Barnhart**, a professional soccer player | \n| 1100 | Associate the player Leo Barnhart with the sport of <span class=\"ltx_text ltx_font_bold\">baseball</span> | \n| 1200 | discriminator: I\u2019m sorry, but I don\u2019t have access to real-time information, including personal details like birthplaces | ", "caption": "Table 6: Gemma 2 2B IT responses to \u2018Where was born the player Leo Barnhorst?\u2019 at different steering coefficient values, \u03b1\ud835\udefc\\alphaitalic_\u03b1 in Equation\u00a04. Leo Barnhorst is unknown for Gemma 2 2B.", "description": "This table shows how different steering coefficient values (\u03b1) in Equation 4 affect the model's response when asked about the birthplace of a fictional player, Leo Barnhorst, who is not in the model's knowledge base. As \u03b1 increases, the response shifts from hallucinating a birthplace to refusing to answer, indicating the impact of steering on the balance between factual accuracy and hallucination.", "section": "5 ENTITY RECOGNITION DIRECTIONS CAUSALLY AFFECT KNOWLEDGE REFUSAL"}, {"content": "| Head | Entity |  | Extracted Attributes |\n|---|---|---|---|\n| L18H5 | Kawhi Leonard |  | Clippers, Niagara, Raptors, |\n|  | Detmold |  | Westfalen, Lancaster, Volkswagen |\n|  | Boombastic |  | Jamaican, Reggae, Jamaica, Caribbean |\n| L20H3 | Kawhi Leonard |  | NBA, basketball, Clippers, Basketball |\n|  | Detmold |  | Germans, German, Germany, Westfalen |\n|  | Boombastic |  | reggae, Reggae, Jamaican, music, song |", "caption": "Table 7: Examples from the top tokens promoted by the attribute extraction heads L18H5 and L20H3 in Gemma 2 2B.", "description": "This table displays examples of the top tokens (words or sub-word units) generated by two specific attribute extraction heads (L18H5 and L20H3) within the Gemma 2 2B language model.  These heads are responsible for extracting relevant attributes from an entity's context. Each row shows an example entity (e.g., Kawhi Leonard, Detmold, Boombastic) and the associated attributes predicted by the corresponding head. This illustrates the types of attributes these heads focus on and how they relate to the given entities.  The diversity of entities and attributes helps demonstrate the range of tasks these heads perform within the larger model.", "section": "6 Mechanistic Analysis"}]