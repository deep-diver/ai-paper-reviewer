[{"Alex": "Hey everyone, and welcome to the podcast! Today, we're diving into the wild world of molecules \u2013 specifically, how to generate them using AI. Forget Frankenstein, think AI-kenstein! We're talking about a groundbreaking paper that's mixing language models with 3D diffusion to conjure up new molecules. It's called 'NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation,' and I\u2019m here with Jamie to break it down.", "Jamie": "AI-kenstein? I love it! So, Alex, molecules from AI, huh? Sounds like something straight out of science fiction. Before we get too deep, can you give us the basic gist? What problem is this paper trying to solve?"}, {"Alex": "Absolutely! The core challenge is generating valid and stable 3D molecules using computers. This is super important for drug discovery and materials design. Think of it like this: we need new LEGO bricks to build better drugs and materials, but there are trillions of possibilities. AI can help us sift through them, but it has to make sure the bricks actually fit together \u2013 that\u2019s the \u2018validity\u2019 and \u2018stability\u2019 part.", "Jamie": "Okay, so it\u2019s about finding the right LEGO bricks that don't break apart when you build something. Got it. What's wrong with how we're doing it now?"}, {"Alex": "Well, current methods, especially those using 3D diffusion models, are great at modeling the continuous 3D shapes of molecules, but they often fail to create structures that are chemically valid \u2013 basically, molecules that can actually exist in the real world. They sometimes spit out these molecular monstrosities that violate the basic rules of chemistry. It's like designing a bridge that defies the laws of physics.", "Jamie": "Yikes, molecular monstrosities aren't exactly what we're aiming for! So, what's their solution in this paper?"}, {"Alex": "Their solution, NExT-Mol, is a clever combination of two approaches. First, they use a 1D language model, kind of like those used for writing text, but trained on molecule sequences. These language models are great at ensuring validity. Then, they use a 3D diffusion model to predict the 3D structure based on the 1D sequence. It's like having a master architect (the language model) design the blueprint, and then a skilled builder (the diffusion model) constructs the 3D building.", "Jamie": "Hmm, interesting. So, they\u2019re using a language model to ensure the molecule is \u2018grammatically correct,\u2019 and then a diffusion model to make it look right in 3D?"}, {"Alex": "Exactly! The language model they use is called MoLlama \u2013 a play on the LLaMA language model \u2013 and it\u2019s been pre-trained on a massive dataset of 1.8 billion molecular sequences. This pre-training allows MoLlama to learn the fundamental patterns and rules of molecular structure, ensuring the generated molecules are chemically sound. They then refine everything further with some tricks we can talk about.", "Jamie": "A molecular Llama! I see what they did there. So, what are those tricks?"}, {"Alex": "One of the key things they did was scale up the size of the language model. Larger language models generally perform better, but also they improve on the 3D diffusion model's architecture by using something called Relational Multi-Head Self-Attention which extends the transformer to consider atomic interactions in the molecule better. Finally, they apply transfer learning between the 1D sequences and 3D conformers. Think of it like refining the building techniques using the architect's blueprints.", "Jamie": "Wait, transfer learning? Isn't that when you teach an AI something on one task and then use that knowledge to help it with a different task? How does that work here?"}, {"Alex": "Spot on! Because there's a lot more data available on 1D molecule sequences than there is on accurate 3D conformers, they use the 1D data to pre-train MoLlama. This gives MoLlama a solid understanding of molecular structures. Then, they 'transfer' that knowledge to the 3D diffusion model, helping it to predict more accurate and stable 3D structures. It's a bit like teaching someone the basic principles of engineering before having them design a specific type of bridge.", "Jamie": "That makes sense. So, they\u2019re leveraging the abundance of 1D data to boost the performance of the 3D model. Clever! What kind of results did they see?"}, {"Alex": "The results were impressive! NExT-Mol achieved a 26% relative improvement in something called 3D FCD \u2013 a measure of how well the generated molecules match the distribution of real molecules \u2013 on a benchmark dataset called GEOM-DRUGS. They also saw a 13% average relative gain for conditional 3D generation on another dataset, QM9-2014. This means NExT-Mol is not only generating valid molecules, but it\u2019s also generating molecules that are similar to those found in the real world and that match certain properties.", "Jamie": "Wow, a 26% improvement is pretty significant! So, it\u2019s not just creating valid molecules, it\u2019s creating *useful* molecules. What are the implications of these findings?"}, {"Alex": "The implications are huge! This could significantly accelerate drug discovery and materials design. By generating valid and stable 3D molecules with desired properties, we can potentially identify new drug candidates and materials much faster and more efficiently. Think of it as dramatically speeding up the R&D process for everything from life-saving medications to more sustainable materials.", "Jamie": "So, fewer molecular monstrosities, more life-saving drugs! That's a future I can get behind. But what are the limitations? Is this the end of the road for molecule generation?"}, {"Alex": "Not at all! There's still plenty of room for improvement. As the paper says, one limitation is the generalization to unseen scaffolds \u2013 basically, molecular frameworks that the AI hasn't encountered before. Another is exploring different ways to guide the diffusion process, perhaps incorporating even more chemical knowledge. And of course, scaling up the model and exploring even larger datasets are always on the horizon.", "Jamie": "So, better generalization, more informed guidance, and bigger models. Sounds like a solid roadmap for future research. Alex, this has been fascinating! Thanks for breaking down this complex paper for us."}, {"Alex": "And that's where they improve on other research! One area for them to improve on is the generalization to unseen scaffolds - which are basically, molecular frameworks that the AI hasn't encountered before, this will be a big step to bring this tech closer to industrial deployment. There is a big roadmap they've set out for other research.", "Jamie": "So, better generalization, more informed guidance, and bigger models. Sounds like a solid roadmap for future research. Alex, this has been fascinating! Thanks for breaking down this complex paper for us."}, {"Alex": "My pleasure, Jamie! It's exciting stuff, and it just shows how AI is transforming the way we approach molecule design.", "Jamie": "Yeah definitely! What are the main types of datasets used to check it?"}, {"Alex": "Right! So they used GEOM-DRUGS which is pharmaceutically relevant and largest, GEOM-QM9 and QM9-2014. These are all the industry standard when it comes to de novo 3D molecule generation and have good benchmarks set and ready to beat!", "Jamie": "That makes sense - keeping up with the standards I see! How were the comparisons done for 3D shapes? What metric was used?"}, {"Alex": "That is a great question! They mainly focus on something called FCD, or Frechet ChemNet Distance, which measures distribution similarity between molecules based on some math. It is kind of like finding the distance between point clouds. There are also some bond angle and bond length metrics they use to have a good understanding of this!", "Jamie": "Cool! What are the main changes you think that they brought to the table - new stuff that wasn't there before?"}, {"Alex": "That is also a great question! So the key things that they're doing are scaling up 1D molecular LMs - training a larger one to have better representation. Also, they're leveraging transfer learning to use the 1D molecule information in downstream tasks. And also, their 3D diffusion model incorporates the full molecular graph information for the denoising, so it has all the details to generate.", "Jamie": "What kind of computing resources did it take to do all these things?"}, {"Alex": "Haha definitely some money! For pretraining the MoLlama LM is did take 555K global steps, processing 145 billion tokens on some top-end NVIDIA A100s, and also the computing for each task separately!", "Jamie": "Did they do a study on the effects of randomized SELFIES? Did that help improve things?"}, {"Alex": "Yes! Great pickup. So, the cool thing about molecules is that you can traverse their graphs in multiple orders, and the AI should be able to know that, and that it's ok. It is similar to how you can put the words in a sentence into different orders and still have similar meaning. Interestingly, it improves the novelty of the generated samples!", "Jamie": "Interesting! Were there specific data augmentation techniques?"}, {"Alex": "They did a form of randomized SELFIES augmentation, so they traverse the molecule graph in random orders. The key intuition is that atoms in the molecule are inherently unordered, and therefore the LM should generate equal likelihoods of traversing in equal likelihood.", "Jamie": "Yeah, that's a good point. Did it turn out to be like that or no?"}, {"Alex": "Well, it was better to have fixed canonical representations vs randomized representations. The issue is, as with all AI, it's about bridging that gap between two different things (aka 1D MoLlama and 3D DMT). ", "Jamie": "Cool, good to know all these things before reading it for myself. What is your final takeaway for someone trying to design molecules, who has just listened to this conversation?"}, {"Alex": "The main takeaway is that this paper, NExT-Mol, demonstrates a powerful new approach to generating 3D molecules using AI. By combining the strengths of language models and diffusion models, they've achieved significant improvements in validity, stability, and diversity. This has the potential to dramatically accelerate drug discovery and materials design, paving the way for new innovations in medicine and beyond. We are going to see many more advancements along these lines in the coming few years!", "Jamie": "Thanks Alex, that was really illuminating!"}]