{"references": [{"fullname_first_author": "J. Li", "paper_title": "BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-01-01", "reason": "This paper is important because it introduces BLIP, a method for unified vision-language understanding and generation that is used as a baseline in the current paper."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper presents CLIP which is used as the text and image encoders in this paper."}, {"fullname_first_author": "A. Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture, used for sequential data processing."}, {"fullname_first_author": "K. He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-01-01", "reason": "This paper introduces ResNet, a convolutional neural network used for image recognition, providing a simple vision encoder to allow improvements beyond the traditional ResNet50."}, {"fullname_first_author": "W. Zhang", "paper_title": "Blind image quality assessment using a deep bilinear convolutional neural network", "publication_date": "2018-01-01", "reason": "This paper introduces DBCNN, a deep learning-based method for blind image quality assessment, providing baseline performance for comparison, although results reveal is simple and fast but not competitive due to a lack of quality-related feature extraction ability."}]}