<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>KV Shifting Attention Enhances Language Modeling &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="KV Shifting Attention Enhances Language Modeling &#183; HF Daily Paper Reviews by AI"><meta name=description content="KV Shifting Attention: A novel attention mechanism significantly enhances language modeling by simplifying induction heads, leading to improved performance and faster convergence, even in large-scale ..."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ Baichuan Inc.,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="KV Shifting Attention Enhances Language Modeling"><meta property="og:description" content="KV Shifting Attention: A novel attention mechanism significantly enhances language modeling by simplifying induction heads, leading to improved performance and faster convergence, even in large-scale ‚Ä¶"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-29T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ Baichuan Inc."><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/cover.png"><meta name=twitter:title content="KV Shifting Attention Enhances Language Modeling"><meta name=twitter:description content="KV Shifting Attention: A novel attention mechanism significantly enhances language modeling by simplifying induction heads, leading to improved performance and faster convergence, even in large-scale ‚Ä¶"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"KV Shifting Attention Enhances Language Modeling","headline":"KV Shifting Attention Enhances Language Modeling","abstract":"KV Shifting Attention: A novel attention mechanism significantly enhances language modeling by simplifying induction heads, leading to improved performance and faster convergence, even in large-scale \u0026hellip;","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2411.19574\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2024","dateCreated":"2024-11-29T00:00:00\u002b00:00","datePublished":"2024-11-29T00:00:00\u002b00:00","dateModified":"2024-11-29T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ Baichuan Inc."],"mainEntityOfPage":"true","wordCount":"5293"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-03-03/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-03</p></a><a href=/ai-paper-reviewer/2025-03-04/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-04</p></a><a href=/ai-paper-reviewer/2025-03-05/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-05</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-03/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-03</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-04/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-04</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-05/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-05</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2411.19574/cover_hu3714180036543906812.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2411.19574/>KV Shifting Attention Enhances Language Modeling</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">KV Shifting Attention Enhances Language Modeling</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span>5293 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">25 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2411.19574/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2411.19574/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-baichuan-inc./","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Baichuan Inc.</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#kv-shifting-attention>KV Shifting Attention</a></li><li><a href=#induction-head-analysis>Induction Head Analysis</a></li><li><a href=#model-scaling-effects>Model Scaling Effects</a></li><li><a href=#empirical-validation>Empirical Validation</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#kv-shifting-attention>KV Shifting Attention</a></li><li><a href=#induction-head-analysis>Induction Head Analysis</a></li><li><a href=#model-scaling-effects>Model Scaling Effects</a></li><li><a href=#empirical-validation>Empirical Validation</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2411.19574</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Mingyu Xu et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-12-06</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2411.19574 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2411.19574 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/kv-shifting-attention-enhances-language target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2411.19574/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large language models (LLMs) rely heavily on induction heads for their in-context learning capabilities. However, implementing efficient induction heads requires significant computational resources, often necessitating deep and wide transformer architectures. This paper tackles this challenge by introducing a new method called KV shifting attention.</p><p>KV shifting attention elegantly simplifies the induction process by decoupling keys and values in the attention mechanism. This innovative approach significantly reduces the depth and width requirements for induction heads, enabling even single-layer transformers to perform induction tasks effectively. The researchers demonstrate the effectiveness of their method through theoretical analysis and empirical evaluation on various models. Their findings indicate that KV shifting attention achieves comparable or superior performance to multi-layer transformers, offering a more efficient and faster training process for LLMs.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-5613c1e26255520c2b599f269a7eebd7></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-5613c1e26255520c2b599f269a7eebd7",{strings:[" KV shifting attention, a novel attention mechanism, simplifies induction heads and reduces the depth and width requirements of transformers. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-903c6014bc46d95f511715ca582f6ac8></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-903c6014bc46d95f511715ca582f6ac8",{strings:[" The proposed method demonstrates superior performance compared to conventional multi-layer transformers in language modeling across diverse scales. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-75284484cf9dcaa376fdf619bb2f5591></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-75284484cf9dcaa376fdf619bb2f5591",{strings:[" Theoretical analysis and experimental results show that KV shifting attention accelerates learning ability for induction heads and benefits language modeling. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is important because it introduces a novel attention mechanism, <strong>KV shifting attention</strong>, that improves language modeling by reducing the computational demands of induction heads. This has significant implications for the development of more efficient and effective large language models. It provides theoretical analysis, experimental validation, and opens up new avenues for research in transformer architecture optimization. The findings are relevant to current trends in efficient and effective LLMs, especially with implications for resource constrained settings.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/induction.png alt></figure></p><blockquote><p>üîº The figure shows how the accuracy of induction varies among different models with different depths (number of layers). The training step size is the only parameter that changes. The KV shifting attention (1-layer) achieves comparable performance to the vanilla model with 2 layers, and both significantly outperform the vanilla model with only 1 layer, demonstrating the effectiveness of KV shifting attention in reducing the depth requirement for induction head learning.</p><details><summary>read the caption</summary>(a) Various depth</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameters</th><th>1.5B</th><th>2.9B</th><th>6.7B</th><th>13B</th><th>19B</th></tr></thead><tbody><tr><td>Hidden size</td><td>2,048</td><td>2,560</td><td>4,096</td><td>5,120</td><td>6,144</td></tr><tr><td>Layers</td><td>28</td><td>32</td><td>32</td><td>40</td><td>48</td></tr><tr><td>Head Number</td><td>16</td><td>20</td><td>32</td><td>40</td><td>48</td></tr><tr><td>KV Number</td><td>16</td><td>4</td><td>32</td><td>40</td><td>4</td></tr><tr><td>FFN size</td><td>5,504</td><td>8,704</td><td>11,008</td><td>13,824</td><td>16,384</td></tr><tr><td>Max Length</td><td>2,048</td><td>4,096</td><td>2,048</td><td>2,048</td><td>12,288</td></tr><tr><td>Total Tokens</td><td>10B</td><td>500B</td><td>10B</td><td>10B</td><td>200B</td></tr><tr><td>Vocab size</td><td>36,000</td><td>48,000</td><td>36,000</td><td>36,000</td><td>48,000</td></tr></tbody></table></table></figure><blockquote><p>üîº This table details the architecture and hyperparameters of the language models used in the experiments. It shows the different sizes of the models (1.5B, 2.9B, 6.7B, 13B, and 19B parameters), their key architectural components (hidden size, number of layers, number of heads, and feed-forward network size), and training parameters (maximum sequence length, vocabulary size, and other relevant training settings).</p><details><summary>read the caption</summary>Table 1: Model Configuration.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">KV Shifting Attention<div id=kv-shifting-attention class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#kv-shifting-attention aria-label=Anchor>#</a></span></h4><p>The proposed &ldquo;KV Shifting Attention&rdquo; mechanism offers a novel approach to enhancing language models by modifying the attention mechanism. <strong>Instead of the standard approach where query, key, and value vectors are independently computed, this method decouples keys and values, enabling a more flexible and efficient induction process.</strong> This decoupling is achieved by shifting the key and value vectors relative to the query vector, allowing the model to capture information from surrounding tokens more effectively. This is particularly beneficial for learning induction heads, which are essential components in a language model&rsquo;s capacity for in-context learning, reducing the need for deeper and wider transformer architectures. The theoretical analysis demonstrates how <strong>KV Shifting Attention reduces the depth and width requirements for effective induction head learning</strong>, leading to more efficient model training and improved performance, even in large-scale pre-trained models. Experimental results further support the efficacy of this approach, showing <strong>comparable or superior performance compared to conventional multi-layer transformers across diverse model sizes</strong>. The inherent bias towards learning induction heads contributes to more efficient and effective language modeling.</p><h4 class="relative group">Induction Head Analysis<div id=induction-head-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#induction-head-analysis aria-label=Anchor>#</a></span></h4><p>An in-depth analysis of induction heads in transformer-based language models would explore their crucial role in <strong>in-context learning (ICL)</strong>. It would delve into the mechanisms by which induction heads identify and leverage repeating patterns within input sequences, enabling the model to perform tasks like multi-step reasoning and complex inference. The analysis should investigate the <strong>structural requirements</strong> of induction heads, including depth (number of layers) and width (number of attention heads), and discuss the trade-offs between these factors and model performance. A critical part of the analysis would involve studying the <strong>learning dynamics</strong> of induction heads, examining how they acquire and represent inductive knowledge during training. This would include analyzing the influence of various architectural choices and training strategies on the effectiveness of induction head learning. Finally, a comprehensive analysis would assess the <strong>limitations</strong> of current induction head mechanisms, exploring their potential failure modes and areas for future research, for instance, how their performance is affected by input sequence length and complexity.</p><h4 class="relative group">Model Scaling Effects<div id=model-scaling-effects class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#model-scaling-effects aria-label=Anchor>#</a></span></h4><p>Model scaling effects in large language models (LLMs) are a complex interplay of various factors. Increasing model size (parameters) generally leads to improved performance on a wide range of tasks, a phenomenon often described by scaling laws. However, <strong>this improvement isn&rsquo;t linear</strong>, and diminishing returns are observed beyond certain scales. <strong>Computational costs increase dramatically</strong> with model size, posing significant challenges. Furthermore, <strong>data requirements also scale</strong>, necessitating massive datasets for effective training of larger models. Beyond raw size, architectural choices and training techniques influence scaling behavior. <strong>Efficient architectures</strong> mitigate computational costs, while innovative training methods (e.g., Mixture of Experts) enhance scalability. <strong>Generalization ability</strong> is another key consideration; larger models often exhibit better generalization, but this depends on data quality and diversity. Therefore, studying model scaling effects requires a nuanced understanding of the trade-offs between performance gains, computational resources, data needs, architecture, and generalization capabilities. <strong>Optimal scaling strategies</strong> involve carefully considering these factors to achieve the desired balance of performance and efficiency.</p><h4 class="relative group">Empirical Validation<div id=empirical-validation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#empirical-validation aria-label=Anchor>#</a></span></h4><p>An Empirical Validation section in a research paper would rigorously test the proposed KV Shifting Attention mechanism. This would involve designing experiments to compare its performance against existing methods across various aspects. <strong>Key metrics</strong> would include accuracy on language modeling benchmarks (like GLUE or SuperGLUE), training speed, and parameter efficiency. Different model sizes (small, medium, large) should be tested. The choice of datasets is crucial; experiments should cover diverse domains and styles to check for robustness. <strong>Control experiments</strong> are needed to isolate the impact of KV Shifting, for instance, comparing it to standard multi-layer transformers with similar complexity. Results should be presented with statistical significance and error bars to highlight any reliable improvements. <strong>Qualitative analysis</strong> can add additional insights by analyzing attention patterns in the KV Shifting model to see if it learns induction heads more effectively. Finally, <strong>limitations</strong> of the empirical study should be clearly stated, for example, potential biases in data selection or constraints in computational resources. Thorough validation establishes confidence in the proposed method&rsquo;s practical value.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>Future research directions stemming from this paper on KV shifting attention for enhanced language modeling could explore several promising avenues. <strong>One key area is a deeper investigation into the theoretical underpinnings of KV shifting, potentially leading to a more rigorous mathematical framework for understanding its effectiveness.</strong> This could involve extending the analysis beyond the toy models and focusing on the behavior in large-scale language models. Furthermore, <strong>research should delve into the interaction between KV shifting and other architectural components</strong>, such as different attention mechanisms, normalization layers, or positional encodings. This would provide a more comprehensive understanding of how KV shifting affects overall model performance. Another significant area for future work involves <strong>evaluating the generalizability of KV shifting to diverse language modeling tasks beyond those explored in the paper</strong>. This includes testing its efficacy in multilingual, cross-lingual, and low-resource settings. Finally, <strong>exploring the interplay between KV shifting and the training process itself warrants further study</strong>. For instance, research could investigate optimal hyperparameter settings and training schedules tailored to KV-shifted models and analyze the impact on convergence speed and generalization. These future research directions would solidify the understanding of KV shifting and pave the way for more impactful advances in language modeling.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/presure_test.png alt></figure></p><blockquote><p>üîº The figure shows how the accuracy of induction varies with different hidden sizes. There are two layers in the vanilla model and one layer in the KV shifting attention model; therefore, the vanilla model has twice the number of parameters. The results demonstrate that KV shifting attention achieves comparable accuracy to the two-layer vanilla model, even with a smaller width (fewer parameters), highlighting its efficiency in learning induction heads.</p><details><summary>read the caption</summary>(b) Various width</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/ot0.png alt></figure></p><blockquote><p>üîº This figure compares the performance of standard multi-layer transformers (Vanilla) and the proposed KV shifting attention mechanism in learning induction heads. The left panel shows how accuracy in an induction task changes as the training progresses for one-layer and two-layer Vanilla models, and a one-layer KV shifting model. Note that the one-layer KV shifting model has the same number of parameters as the one-layer Vanilla model, while the two-layer Vanilla model has twice as many parameters. The right panel shows accuracy as a function of the hidden layer size. Again, the one-layer KV shifting model is compared to one-layer and two-layer Vanilla models. The results demonstrate that KV shifting attention improves induction learning, even when comparing models with the same number of parameters.</p><details><summary>read the caption</summary>Figure 1: On the left, as the training step size increases, the accuracy of induction varies among different models. In this setting, the only difference between Vanilla and KV shifting attention is the calculation of key and value. The total parameters of Vanilla and KV shifting attention with one layers is the same. And the parameters of Vanilla with 2 layers is twice. On the right is the induction accuracy with different hidden size. There are two layers in Vanilla model, and one layer in KV shifting attention, which means Vanilla model has two times parameters than KV shifting attention.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/ot10.png alt></figure></p><blockquote><p>üîº This figure shows contour lines and gradient descent directions of the loss function L for a simplified model used to analyze induction heads. The loss function is simplified by treating O(T) as a constant and setting Œ±2 = 1 - Œ±1 and Œ≤2 = 1 - Œ≤1. The plot shows how the contour lines and gradient directions change as O(T) increases from 0 to 10 to 100. When O(T) is small, the gradient descent is non-monotonic, but as O(T) increases, it becomes more consistent and it becomes easier for the model to learn induction heads as indicated by the gradient moving toward the point (Œ±1, Œ≤1) = (0,1), representing an ideal induction head.</p><details><summary>read the caption</summary>(a) O‚Å¢(T)=0ùëÇùëá0O(T)=0italic_O ( italic_T ) = 0</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/ot100.png alt></figure></p><blockquote><p>üîº This figure visualizes the contour lines and gradient descent direction of the loss function L in relation to the variables Œ±‚ÇÅ and Œ≤‚ÇÅ. The loss function represents the optimization objective during the training of the KV shifting attention mechanism. The contour lines show the level sets of the loss function, where points on the same line have the same loss value. The gradient descent vectors indicate the direction of steepest descent, which guides the training process to minimize the loss function. The parameter O(T) reflects the complexity of the task and controls how sparse the contour lines are (more sparse for larger O(T)). The figure shows three cases (O(T) = 0, O(T) = 10, O(T) = 100) with different densities of contour lines, illustrating the effect of task complexity on the optimization landscape.</p><details><summary>read the caption</summary>(b) O‚Å¢(T)=10ùëÇùëá10O(T)=10italic_O ( italic_T ) = 10</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/4layers.png alt></figure></p><blockquote><p>üîº This figure shows contour lines and gradient descent directions for the loss function L when O(T) is set to 100. The contour lines represent the values of L, and the arrows indicate the direction of gradient descent. The gradient descent is an optimization process used to find the minimum value of the loss function. The sparseness of the contour lines indicates a slower convergence speed of the optimization algorithm. This visualization is used to illustrate the impact of the O(T) term on the model&rsquo;s ability to learn induction heads.</p><details><summary>read the caption</summary>(c) O‚Å¢(T)=100ùëÇùëá100O(T)=100italic_O ( italic_T ) = 100</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/2layers.png alt></figure></p><blockquote><p>üîº This figure visualizes the contour lines and gradient descent directions of the loss function (L) involved in learning induction heads using KV shifting attention. The analysis simplifies the complex loss function by treating O(T) (a term related to sequence length) as a constant. The plot focuses on the relationship between two learnable parameters, Œ±1 and Œ≤1, while Œ±2 and Œ≤2 are defined as 1-Œ±1 and 1-Œ≤1 respectively. The point (Œ±1, Œ≤1) = (0, 1) represents the ideal state of learning perfect induction heads. The contour lines show how quickly the loss function changes with respect to these parameters. The gradient descent directions indicate the direction the parameters are likely to move during training in order to minimize the loss, thus illustrating how effectively the KV shifting attention method facilitates the training process towards the ideal (0,1) state. Different subplots show the effect of varying the complexity of the training data, represented by O(T).</p><details><summary>read the caption</summary>Figure 2: Contour lines and gradient decent derection of LùêøLitalic_L. We simplified O‚Å¢(T)ùëÇùëáO(T)italic_O ( italic_T ) as a constant, and Œ±2=1‚àíŒ±1subscriptùõº21subscriptùõº1\alpha_{2}=1-\alpha_{1}italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 - italic_Œ± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and Œ≤2=1‚àíŒ≤1subscriptùõΩ21subscriptùõΩ1\beta_{2}=1-\beta_{1}italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 - italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Induction heads means (Œ±1,Œ≤1)=(0,1)subscriptùõº1subscriptùõΩ101(\alpha_{1},\beta_{1})=(0,1)( italic_Œ± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = ( 0 , 1 ).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/1layers.png alt></figure></p><blockquote><p>üîº This figure shows the accuracy of learning 3-gram text using models of different sizes. The experiment includes three models: a 50M parameter model with 4 layers, a 0.4M parameter model with 2 layers, and a 0.8K parameter model with 1 layer. The x-axis represents the number of training epochs, and the y-axis represents the accuracy of predicting the third token in a sequence given the first two tokens. The purpose is to compare the performance of standard transformers (Vanilla) against KV shifting attention in learning n-grams. The results show that KV shifting attention does not significantly improve or hinder the ability to learn 3-grams compared to standard transformers across different model sizes.</p><details><summary>read the caption</summary>(a) 50M</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/loss_curve.png alt></figure></p><blockquote><p>üîº This figure displays the accuracy of induction head learning across different model sizes and training steps. The experiment uses a simplified setting, focusing only on the ability to learn induction heads. The smaller model (0.4M parameters) is compared to a larger model (50M parameters), showing the influence of model size on induction head learning ability, measured by the accuracy of predicting subsequent tokens given a repeating pattern of preceding tokens. The graph demonstrates how well each model learns to identify and utilize these repeating patterns to make accurate predictions. The x-axis represents the number of training steps, while the y-axis indicates the accuracy of the induction head mechanism.</p><details><summary>read the caption</summary>(b) 0.4M</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/19b.png alt></figure></p><blockquote><p>üîº This figure shows the accuracy of learning 3-gram text using a model with 0.8K parameters. It compares the performance of a standard transformer (Vanilla) against the KV shifting attention model. The x-axis represents the training epochs, and the y-axis represents the accuracy. This experiment is designed to evaluate the models&rsquo; ability to learn n-grams, a fundamental aspect of language modeling. The results show how the accuracy of learning 3-grams changes over time for both models.</p><details><summary>read the caption</summary>(c) 0.8K</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/seed.png alt></figure></p><blockquote><p>üîº This figure compares the accuracy of learning 3-gram text across models with varying numbers of parameters and layers. The experiment demonstrates that even a single-layer model with a small number of parameters (0.8K) can achieve a relatively high accuracy. A model with 0.4M parameters and 2 layers performs better, and the largest model with 50M parameters and 4 layers achieves the highest accuracy. This highlights that more parameters and layers generally improve performance for this specific task. However, the single-layer model&rsquo;s performance is still noteworthy given its parameter efficiency.</p><details><summary>read the caption</summary>Figure 3: Accuracy of learning 3-gram text using models of different sizes. In this experiments, there are 50M parameters model with 4 layers, 0.4M parameters model with 2 layers, 0.8K parameters model with 1 layer.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/lr.png alt></figure></p><blockquote><p>üîº The training loss curves for the 2.9B parameter model are plotted, comparing the vanilla model with KV shifting attention. The x-axis represents the number of training tokens (in billions), and the y-axis shows the training loss. The plot illustrates the convergence speed and overall loss values of both models during training, highlighting the difference in their performance.</p><details><summary>read the caption</summary>(a) 2.9B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/lr1e-2.png alt></figure></p><blockquote><p>üîº The figure shows the training loss curve for the 19B parameter model. The model was trained using 200B tokens. The blue line represents the training loss for the vanilla model, while the orange line represents the training loss for the model using KV shifting attention. The graph indicates that the model with KV shifting attention converges faster and achieves a lower final loss compared to the vanilla model. This demonstrates the efficacy of KV shifting attention in enhancing training efficiency and improving model performance.</p><details><summary>read the caption</summary>(b) 19B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/1d4b.png alt></figure></p><blockquote><p>üîº This figure displays the training loss curves for two large language models: one with 2.9 billion parameters trained on 500 billion tokens and another with 19 billion parameters trained on 200 billion tokens. The curves show the decrease in training loss over the course of training, illustrating the models&rsquo; learning progress. Comparing the two curves allows for assessing the impact of model size and training data volume on the learning process.</p><details><summary>read the caption</summary>Figure 4: Training loss curve. We train 2.9B model with 500B tokens, and 19B models with 200B tokens.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/7b.png alt></figure></p><blockquote><p>üîº This figure displays the training loss curves for a 1.5B parameter model across five different random seeds. Each curve represents a separate training run with different random initialization and data sampling. The purpose is to demonstrate the robustness of KV shifting attention compared to vanilla attention, showing that KV shifting attention consistently achieves lower training loss even under varied conditions.</p><details><summary>read the caption</summary>(a) Various Seeds</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/14b.png alt></figure></p><blockquote><p>üîº This figure shows the training loss curves for a 1.5B parameter model with different learning rates (LR). It compares the performance of the vanilla attention mechanism against the KV shifting attention mechanism across various learning rates. The goal is to assess the robustness and stability of each approach under different optimization settings, demonstrating how the KV shifting attention mechanism generally maintains stability even when the vanilla attention mechanism diverges (e.g., at LR=1e-2).</p><details><summary>read the caption</summary>(b) Various LR</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/scaling_law.png alt></figure></p><blockquote><p>üîº This figure displays the training loss curves for a 1.5B parameter model using different learning rates. Specifically, it shows the impact of a 1e-2 learning rate on the training loss of both Vanilla attention and KV shifting attention. Note that the y-axis represents training loss and x-axis represents training steps. The plot helps illustrate the robustness and stability of KV shifting attention, particularly its resilience to higher learning rates, as compared to the Vanilla attention mechanism.</p><details><summary>read the caption</summary>(c) LR=1e-2</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/1d4b40b.png alt></figure></p><blockquote><p>üîº This figure displays the training loss curves for a 1.5B parameter language model under various conditions. Specifically, it illustrates how the training loss changes with the number of training steps across multiple runs using different random seeds for model initialization, and also shows how the loss varies when using different learning rates (LR). This allows for an assessment of the model&rsquo;s robustness and stability during training across different random initializations and hyperparameter settings. The different lines represent separate training runs with different random seeds or learning rates.</p><details><summary>read the caption</summary>Figure 5: Training loss of 1.5B parameters model among random seeds and learning rate (LR).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/gate.png alt></figure></p><blockquote><p>üîº Training loss curve for the 1.5B parameter model. The plot shows the training loss over time (steps) for both a vanilla transformer and one utilizing KV shifting attention. It illustrates the relative convergence speed and loss values of each model, providing insight into the effect of KV shifting attention on training efficiency. Note the difference in scale between the vanilla and KV shifting models.</p><details><summary>read the caption</summary>(a) 1.5B Parameters</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/aba_new.png alt></figure></p><blockquote><p>üîº The figure shows the training loss curves for a 6.7B parameter language model. The graph plots training loss against the number of training steps. Two lines are displayed, one for a model using standard attention and another for a model using KV shifting attention. This visualization allows comparison of the training loss reduction efficiency for both attention mechanisms.</p><details><summary>read the caption</summary>(b) 6.7B Parameters</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/p3_new.png alt></figure></p><blockquote><p>üîº This figure shows the training loss curve for the 13B parameter model. The loss is plotted against the number of training steps. This plot is part of an experiment comparing the performance of a model using the KV shifting attention mechanism to a vanilla transformer model of the same size. This particular plot shows how the loss function changes over training for the larger model, giving insight into the convergence speed and overall performance of the KV-shifting attention.</p><details><summary>read the caption</summary>(c) 13B Parameters</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/hop_vanilla.png alt></figure></p><blockquote><p>üîº Figure 6 presents a comparison of training loss curves for transformer language models of varying sizes (1.5B, 6.7B, and 13B parameters). All models were trained on the same amount of data (10 billion tokens). However, the batch size varied across models. The 1.5B and 6.7B parameter models used a batch size of 0.5 million tokens while the 13B parameter model used a batch size of 1 million tokens. This difference in batch size resulted in the 13B model completing approximately half the number of training steps compared to the other two models. The graphs illustrate the training loss over these steps, allowing for a comparison of training efficiency and convergence across model sizes.</p><details><summary>read the caption</summary>Figure 6: Training loss comparison between different size. All models are trained on 10B tokens. The batch size for 1.5B and 6.7B model is 0.5M, for 13B is 1M, so the total steps of 13B model is half of others.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/hop_vanilla_ori.png alt></figure></p><blockquote><p>üîº This figure presents the scaling law for both vanilla attention and KV shifting attention. The x-axis represents the number of parameters (log scale), and the y-axis represents the validation loss (log scale). The plot shows how validation loss decreases as model size increases, illustrating the relationship between model scale and performance for the two different attention mechanisms. This allows comparison of the efficiency with which each attention mechanism utilizes increased model size to improve performance.</p><details><summary>read the caption</summary>(a) Scaling law</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/hop_kv.png alt></figure></p><blockquote><p>üîº The figure shows the training loss curves for a 1.5 billion parameter language model. Specifically, it compares the training loss of a model using standard attention (&lsquo;Vanilla&rsquo;) versus a model using KV shifting attention. The plot shows the loss decreasing over training steps, with KV shifting attention demonstrating faster convergence and a lower final loss compared to the standard model. This illustrates the improved efficiency and effectiveness of the KV shifting attention mechanism for language model training.</p><details><summary>read the caption</summary>(b) 1.5B Parameters</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/qkvshifting.png alt></figure></p><blockquote><p>üîº Figure 7 displays the validation loss for models of various sizes trained on 10 billion tokens. The left panel (a) shows a scaling law where the x-axis represents the total number of parameters (excluding embedding parameters) and the y-axis represents the validation loss achieved at the final checkpoint of training. The right panel (b) shows the training loss curve for the 1.5B parameter model, specifically focusing on the model&rsquo;s performance as the training progressed towards 30B tokens. This highlights how the validation loss remains relatively stable for KV shifting attention, even with a large increase in training data, unlike the vanilla attention model.</p><details><summary>read the caption</summary>Figure 7: Validation loss across different size and training tokens. For scaling law, while others in this paper means the total parameters. models are trained on 10B tokens and calculate the final checkpoint‚Äôs validation loss.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/mmlu.png alt></figure></p><blockquote><p>üîº This figure displays the training loss curves for different variations of the KV shifting attention mechanism on a 1.5B parameter model trained with 10B tokens. The variations include the baseline Vanilla attention, KV shifting attention with a gate mechanism (KV shifting Gate), KV shifting attention restricted to values between 0 and 1 (KV shifting 0 to 1), and standard KV shifting attention. The purpose is to investigate the impact of these modifications on the model&rsquo;s learning process and performance.</p><details><summary>read the caption</summary>(a) Variant</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.19574/extracted/6047733/image/cmmlu.png alt></figure></p><blockquote><p>üîº This ablation study investigates the impact of removing key and value shifting components from the KV shifting attention mechanism. The figure compares the training loss curves of the full KV shifting attention model against versions where either the key shifting or value shifting, or both, are removed. This allows for assessment of the relative contribution of each component to the model&rsquo;s overall performance and learning ability. Specifically, it shows the impact on the model&rsquo;s capacity to learn the induction heads mechanism that are central to the paper&rsquo;s focus on improving language modeling. The relative differences in training loss among these variants illustrate the importance of both key and value shifting for achieving the model&rsquo;s improved performance.</p><details><summary>read the caption</summary>(b) Ablation</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Tokens</th><th>lambada</th><th>winogrande</th><th>hellaswag</th><th>Arc-E</th><th>Arc-C</th><th>cmmlu</th><th>mmlu</th><th>math</th><th>average</th></tr></thead><tbody><tr><td>Vanilla - 2.9B</td><td>340B</td><td>52.92</td><td>52.09</td><td>42.70</td><td>27.45</td><td>25.97</td><td>28.51</td><td>29.43</td><td>0.80</td><td>32.48</td></tr><tr><td></td><td>420B</td><td>52.80</td><td>54.85</td><td>43.68</td><td>28.96</td><td>26.02</td><td>34.77</td><td>30.34</td><td>1.20</td><td>34.08</td></tr><tr><td></td><td>500B</td><td>51.66</td><td>54.06</td><td>44.49</td><td>27.90</td><td>38.22</td><td>37.26</td><td>1.80</td><td>36.45</td><td></td></tr><tr><td>KV Shiting - 2.9B</td><td>340B</td><td>55.44</td><td>53.91</td><td>42.87</td><td>36.74</td><td>30.04</td><td>34.51</td><td>36.20</td><td>2.00</td><td>36.46</td></tr><tr><td></td><td>420B</td><td>51.91</td><td>54.78</td><td>43.83</td><td>31.91</td><td>37.24</td><td>34.30</td><td>1.80</td><td>36.55</td><td></td></tr><tr><td></td><td>500B</td><td>54.51</td><td>44.52</td><td>39.02</td><td>30.89</td><td>40.78</td><td>40.88</td><td>2.60</td><td>38.57</td><td></td></tr><tr><td>Vanilla - 19B</td><td>160B</td><td>59.93</td><td>48.22</td><td>48.25</td><td>30.34</td><td>24.56</td><td>39.12</td><td>39.22</td><td>1.80</td><td>36.43</td></tr><tr><td></td><td>180B</td><td>58.80</td><td>48.07</td><td>47.78</td><td>31.28</td><td>25.99</td><td>40.80</td><td>39.34</td><td>2.60</td><td>36.83</td></tr><tr><td></td><td>200B</td><td>60.88</td><td>49.01</td><td>47.36</td><td>33.25</td><td>42.92</td><td>42.68</td><td>2.60</td><td>38.06</td><td></td></tr><tr><td>KV shifting - 19B</td><td>160B</td><td>61.93</td><td>48.46</td><td>48.28</td><td>31.25</td><td>25.06</td><td>42.10</td><td>42.87</td><td>2.00</td><td>37.74</td></tr><tr><td></td><td>180B</td><td>60.20</td><td>47.67</td><td>48.16</td><td>32.45</td><td>43.38</td><td>40.49</td><td>3.00</td><td>37.74</td><td></td></tr><tr><td></td><td>200B</td><td>62.35</td><td>48.38</td><td>48.42</td><td>33.28</td><td>29.32</td><td>42.40</td><td>43.29</td><td>3.20</td><td>38.83</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of experiments comparing the performance of language models with and without KV shifting attention. Two model sizes were trained (2.9B and 19B parameters) with different training token counts (500B for 2.9B and 200B for 19B). The table shows the performance of these models on several benchmark datasets (Lambada, Winogrande, HellaSwag, ARC-easy, ARC-Challenge, CMMLU, MMLU, and Math), reporting accuracy scores for each.</p><details><summary>read the caption</summary>Table 2: Main results. We trained four models on 2.9B and 19B parameters respectively, with the 2.9B model having a total training token count of 500B and the 19B model having a total training token count of 200B. ARC-E is short for ARC-easy, and ARC-C if short for ARC-Challenge.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Benchmark</th><th>Vanilla</th><th></th><th></th><th>KV shifting</th><th></th><th></th></tr></thead><tbody><tr><td></td><td>Cloze</td><td>Zero</td><td>Few</td><td>Cloze</td><td>Zero</td><td>Few</td></tr><tr><td>MMLU</td><td>30.41</td><td>33.14</td><td>37.26</td><td>32.17</td><td>37.13</td><td>40.88</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparison of the performance of the vanilla attention mechanism and the proposed KV shifting attention mechanism on a 2.9B parameter language model trained with 500B tokens. The comparison uses three different evaluation metrics: cloze (zero-shot), zero-shot, and few-shot, showing the model&rsquo;s performance on various aspects of language understanding. The results highlight the relative performance improvements achieved by using KV shifting attention across multiple evaluation criteria.</p><details><summary>read the caption</summary>Table 3: We compare vanilla and KV shifting at 2.9B model with 500B training tokens by using different evaluation metric.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th></th><th>Œ±‚ÇÅ > Œ±‚ÇÇ</th><th>Œ±‚ÇÅ ‚â§ Œ±‚ÇÇ</th></tr></thead><tbody><tr><td>Œ≤‚ÇÅ > Œ≤‚ÇÇ</td><td>50</td><td>17</td></tr><tr><td>Œ≤‚ÇÅ ‚â§ Œ≤‚ÇÇ</td><td>9</td><td>52</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents an analysis of the learnable parameters Œ±‚ÇÅ and Œ≤‚ÇÅ within the KV shifting attention mechanism of a 2.9B parameter language model trained on 500B tokens. Specifically, it counts how many times the inequalities Œ±‚ÇÅ ‚â§ Œ±‚ÇÇ and Œ≤‚ÇÅ ‚â§ Œ≤‚ÇÇ hold true across the 128 KV pairs in the model. This analysis helps to understand the learned relationships between these parameters and their impact on the model&rsquo;s behavior.</p><details><summary>read the caption</summary>Table 4: We calculate the number of whether Œ±1‚â§Œ±2subscriptùõº1subscriptùõº2\alpha_{1}\leq\alpha_{2}italic_Œ± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ‚â§ italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and Œ≤1‚â§Œ≤2subscriptùõΩ1subscriptùõΩ2\beta_{1}\leq\beta_{2}italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ‚â§ italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in each KV pair in 2.9B model with 500B token, the total numbers is 128.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A3.T5.5><thead class=ltx_thead><tr class=ltx_tr id=A3.T5.5.6.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" id=A3.T5.5.6.1.1>predict tokens</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=A3.T5.5.6.1.2>logit</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A3.T5.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id=A3.T5.1.1.2>i - 1</th><td class="ltx_td ltx_align_center ltx_border_t" id=A3.T5.1.1.1><math alttext="(\beta_{1}+\beta_{2}e^{\alpha_{2}})/S" class="ltx_Math" display="inline" id="A3.T5.1.1.1.m1.1"><semantics id="A3.T5.1.1.1.m1.1a"><mrow id="A3.T5.1.1.1.m1.1.1" xref="A3.T5.1.1.1.m1.1.1.cmml"><mrow id="A3.T5.1.1.1.m1.1.1.1.1" xref="A3.T5.1.1.1.m1.1.1.1.1.1.cmml"><mo id="A3.T5.1.1.1.m1.1.1.1.1.2" stretchy="false" xref="A3.T5.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A3.T5.1.1.1.m1.1.1.1.1.1" xref="A3.T5.1.1.1.m1.1.1.1.1.1.cmml"><msub id="A3.T5.1.1.1.m1.1.1.1.1.1.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2.cmml"><mi id="A3.T5.1.1.1.m1.1.1.1.1.1.2.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2.2.cmml">Œ≤</mi><mn id="A3.T5.1.1.1.m1.1.1.1.1.1.2.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A3.T5.1.1.1.m1.1.1.1.1.1.1" xref="A3.T5.1.1.1.m1.1.1.1.1.1.1.cmml">+</mo><mrow id="A3.T5.1.1.1.m1.1.1.1.1.1.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.cmml"><msub id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.cmml"><mi id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.2.cmml">Œ≤</mi><mn id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.3.cmml">2</mn></msub><mo id="A3.T5.1.1.1.m1.1.1.1.1.1.3.1" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.1.cmml">‚Å¢</mo><msup id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.cmml"><mi id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.2.cmml">e</mi><msub id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.cmml"><mi id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.2" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.2.cmml">Œ±</mi><mn id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.3" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.3.cmml">2</mn></msub></msup></mrow></mrow><mo id="A3.T5.1.1.1.m1.1.1.1.1.3" stretchy="false" xref="A3.T5.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A3.T5.1.1.1.m1.1.1.2" xref="A3.T5.1.1.1.m1.1.1.2.cmml">/</mo><mi id="A3.T5.1.1.1.m1.1.1.3" xref="A3.T5.1.1.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T5.1.1.1.m1.1b"><apply id="A3.T5.1.1.1.m1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1"><divide id="A3.T5.1.1.1.m1.1.1.2.cmml" xref="A3.T5.1.1.1.m1.1.1.2"></divide><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1"><plus id="A3.T5.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.1"></plus><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.T5.1.1.1.m1.1.1.1.1.1.2.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="A3.T5.1.1.1.m1.1.1.1.1.1.2.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2.2">ùõΩ</ci><cn id="A3.T5.1.1.1.m1.1.1.1.1.1.2.3.cmml" type="integer" xref="A3.T5.1.1.1.m1.1.1.1.1.1.2.3">1</cn></apply><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3"><times id="A3.T5.1.1.1.m1.1.1.1.1.1.3.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.1"></times><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.2">ùõΩ</ci><cn id="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.3.cmml" type="integer" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.2.3">2</cn></apply><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3">superscript</csymbol><ci id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.2">ùëí</ci><apply id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.2">ùõº</ci><cn id="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="A3.T5.1.1.1.m1.1.1.1.1.1.3.3.3.3">2</cn></apply></apply></apply></apply><ci id="A3.T5.1.1.1.m1.1.1.3.cmml" xref="A3.T5.1.1.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.1.1.1.m1.1c">(\beta_{1}+\beta_{2}e^{\alpha_{2}})/S</annotation><annotation encoding="application/x-llamapun" id="A3.T5.1.1.1.m1.1d">( italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) / italic_S</annotation></semantics></math></td></tr><tr class=ltx_tr id=A3.T5.2.2><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id=A3.T5.2.2.2>i</th><td class="ltx_td ltx_align_center" id=A3.T5.2.2.1><math alttext="(2\beta_{1}e^{\alpha_{1}}+\beta_{2}e^{\alpha_{2}})/S" class="ltx_Math" display="inline" id="A3.T5.2.2.1.m1.1"><semantics id="A3.T5.2.2.1.m1.1a"><mrow id="A3.T5.2.2.1.m1.1.1" xref="A3.T5.2.2.1.m1.1.1.cmml"><mrow id="A3.T5.2.2.1.m1.1.1.1.1" xref="A3.T5.2.2.1.m1.1.1.1.1.1.cmml"><mo id="A3.T5.2.2.1.m1.1.1.1.1.2" stretchy="false" xref="A3.T5.2.2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A3.T5.2.2.1.m1.1.1.1.1.1" xref="A3.T5.2.2.1.m1.1.1.1.1.1.cmml"><mrow id="A3.T5.2.2.1.m1.1.1.1.1.1.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.cmml"><mn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.2.cmml">2</mn><mo id="A3.T5.2.2.1.m1.1.1.1.1.1.2.1" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.1.cmml">‚Å¢</mo><msub id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.2.cmml">Œ≤</mi><mn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.3.cmml">1</mn></msub><mo id="A3.T5.2.2.1.m1.1.1.1.1.1.2.1a" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.1.cmml">‚Å¢</mo><msup id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.2.cmml">e</mi><msub id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.2.cmml">Œ±</mi><mn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.3.cmml">1</mn></msub></msup></mrow><mo id="A3.T5.2.2.1.m1.1.1.1.1.1.1" xref="A3.T5.2.2.1.m1.1.1.1.1.1.1.cmml">+</mo><mrow id="A3.T5.2.2.1.m1.1.1.1.1.1.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.cmml"><msub id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.2.cmml">Œ≤</mi><mn id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.3.cmml">2</mn></msub><mo id="A3.T5.2.2.1.m1.1.1.1.1.1.3.1" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.1.cmml">‚Å¢</mo><msup id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.2.cmml">e</mi><msub id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.cmml"><mi id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.2" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.2.cmml">Œ±</mi><mn id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.3" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.3.cmml">2</mn></msub></msup></mrow></mrow><mo id="A3.T5.2.2.1.m1.1.1.1.1.3" stretchy="false" xref="A3.T5.2.2.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A3.T5.2.2.1.m1.1.1.2" xref="A3.T5.2.2.1.m1.1.1.2.cmml">/</mo><mi id="A3.T5.2.2.1.m1.1.1.3" xref="A3.T5.2.2.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T5.2.2.1.m1.1b"><apply id="A3.T5.2.2.1.m1.1.1.cmml" xref="A3.T5.2.2.1.m1.1.1"><divide id="A3.T5.2.2.1.m1.1.1.2.cmml" xref="A3.T5.2.2.1.m1.1.1.2"></divide><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1"><plus id="A3.T5.2.2.1.m1.1.1.1.1.1.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.1"></plus><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2"><times id="A3.T5.2.2.1.m1.1.1.1.1.1.2.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.1"></times><cn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.2.cmml" type="integer" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.2">2</cn><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3">subscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.2">ùõΩ</ci><cn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.3.3">1</cn></apply><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4">superscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.2">ùëí</ci><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3">subscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.2">ùõº</ci><cn id="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.3.cmml" type="integer" xref="A3.T5.2.2.1.m1.1.1.1.1.1.2.4.3.3">1</cn></apply></apply></apply><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.3.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3"><times id="A3.T5.2.2.1.m1.1.1.1.1.1.3.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.1"></times><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.2">ùõΩ</ci><cn id="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.3.cmml" type="integer" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.2.3">2</cn></apply><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3">superscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.2">ùëí</ci><apply id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.2">ùõº</ci><cn id="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="A3.T5.2.2.1.m1.1.1.1.1.1.3.3.3.3">2</cn></apply></apply></apply></apply><ci id="A3.T5.2.2.1.m1.1.1.3.cmml" xref="A3.T5.2.2.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.2.2.1.m1.1c">(2\beta_{1}e^{\alpha_{1}}+\beta_{2}e^{\alpha_{2}})/S</annotation><annotation encoding="application/x-llamapun" id="A3.T5.2.2.1.m1.1d">( 2 italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) / italic_S</annotation></semantics></math></td></tr><tr class=ltx_tr id=A3.T5.3.3><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id=A3.T5.3.3.2>i+1</th><td class="ltx_td ltx_align_center" id=A3.T5.3.3.1><math alttext="(\beta_{1}e^{\alpha_{2}}+\beta_{2})/S" class="ltx_Math" display="inline" id="A3.T5.3.3.1.m1.1"><semantics id="A3.T5.3.3.1.m1.1a"><mrow id="A3.T5.3.3.1.m1.1.1" xref="A3.T5.3.3.1.m1.1.1.cmml"><mrow id="A3.T5.3.3.1.m1.1.1.1.1" xref="A3.T5.3.3.1.m1.1.1.1.1.1.cmml"><mo id="A3.T5.3.3.1.m1.1.1.1.1.2" stretchy="false" xref="A3.T5.3.3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A3.T5.3.3.1.m1.1.1.1.1.1" xref="A3.T5.3.3.1.m1.1.1.1.1.1.cmml"><mrow id="A3.T5.3.3.1.m1.1.1.1.1.1.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.cmml"><msub id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.cmml"><mi id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.2.cmml">Œ≤</mi><mn id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo id="A3.T5.3.3.1.m1.1.1.1.1.1.2.1" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.1.cmml">‚Å¢</mo><msup id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.cmml"><mi id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.2.cmml">e</mi><msub id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.cmml"><mi id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.2.cmml">Œ±</mi><mn id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.3.cmml">2</mn></msub></msup></mrow><mo id="A3.T5.3.3.1.m1.1.1.1.1.1.1" xref="A3.T5.3.3.1.m1.1.1.1.1.1.1.cmml">+</mo><msub id="A3.T5.3.3.1.m1.1.1.1.1.1.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3.cmml"><mi id="A3.T5.3.3.1.m1.1.1.1.1.1.3.2" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3.2.cmml">Œ≤</mi><mn id="A3.T5.3.3.1.m1.1.1.1.1.1.3.3" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3.3.cmml">2</mn></msub></mrow><mo id="A3.T5.3.3.1.m1.1.1.1.1.3" stretchy="false" xref="A3.T5.3.3.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A3.T5.3.3.1.m1.1.1.2" xref="A3.T5.3.3.1.m1.1.1.2.cmml">/</mo><mi id="A3.T5.3.3.1.m1.1.1.3" xref="A3.T5.3.3.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T5.3.3.1.m1.1b"><apply id="A3.T5.3.3.1.m1.1.1.cmml" xref="A3.T5.3.3.1.m1.1.1"><divide id="A3.T5.3.3.1.m1.1.1.2.cmml" xref="A3.T5.3.3.1.m1.1.1.2"></divide><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1"><plus id="A3.T5.3.3.1.m1.1.1.1.1.1.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.1"></plus><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2"><times id="A3.T5.3.3.1.m1.1.1.1.1.1.2.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.1"></times><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2">subscript</csymbol><ci id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.2">ùõΩ</ci><cn id="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.3.cmml" type="integer" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.2.3">1</cn></apply><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3">superscript</csymbol><ci id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.2">ùëí</ci><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.2">ùõº</ci><cn id="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.3.cmml" type="integer" xref="A3.T5.3.3.1.m1.1.1.1.1.1.2.3.3.3">2</cn></apply></apply></apply><apply id="A3.T5.3.3.1.m1.1.1.1.1.1.3.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A3.T5.3.3.1.m1.1.1.1.1.1.3.1.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="A3.T5.3.3.1.m1.1.1.1.1.1.3.2.cmml" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3.2">ùõΩ</ci><cn id="A3.T5.3.3.1.m1.1.1.1.1.1.3.3.cmml" type="integer" xref="A3.T5.3.3.1.m1.1.1.1.1.1.3.3">2</cn></apply></apply><ci id="A3.T5.3.3.1.m1.1.1.3.cmml" xref="A3.T5.3.3.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.3.3.1.m1.1c">(\beta_{1}e^{\alpha_{2}}+\beta_{2})/S</annotation><annotation encoding="application/x-llamapun" id="A3.T5.3.3.1.m1.1d">( italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) / italic_S</annotation></semantics></math></td></tr><tr class=ltx_tr id=A3.T5.4.4><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id=A3.T5.4.4.2>T</th><td class="ltx_td ltx_align_center" id=A3.T5.4.4.1><math alttext="(\beta_{1}+\beta_{2}e^{\alpha_{2}})/S" class="ltx_Math" display="inline" id="A3.T5.4.4.1.m1.1"><semantics id="A3.T5.4.4.1.m1.1a"><mrow id="A3.T5.4.4.1.m1.1.1" xref="A3.T5.4.4.1.m1.1.1.cmml"><mrow id="A3.T5.4.4.1.m1.1.1.1.1" xref="A3.T5.4.4.1.m1.1.1.1.1.1.cmml"><mo id="A3.T5.4.4.1.m1.1.1.1.1.2" stretchy="false" xref="A3.T5.4.4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A3.T5.4.4.1.m1.1.1.1.1.1" xref="A3.T5.4.4.1.m1.1.1.1.1.1.cmml"><msub id="A3.T5.4.4.1.m1.1.1.1.1.1.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2.cmml"><mi id="A3.T5.4.4.1.m1.1.1.1.1.1.2.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2.2.cmml">Œ≤</mi><mn id="A3.T5.4.4.1.m1.1.1.1.1.1.2.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A3.T5.4.4.1.m1.1.1.1.1.1.1" xref="A3.T5.4.4.1.m1.1.1.1.1.1.1.cmml">+</mo><mrow id="A3.T5.4.4.1.m1.1.1.1.1.1.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.cmml"><msub id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.cmml"><mi id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.2.cmml">Œ≤</mi><mn id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.3.cmml">2</mn></msub><mo id="A3.T5.4.4.1.m1.1.1.1.1.1.3.1" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.1.cmml">‚Å¢</mo><msup id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.cmml"><mi id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.2.cmml">e</mi><msub id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.cmml"><mi id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.2" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.2.cmml">Œ±</mi><mn id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.3" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.3.cmml">2</mn></msub></msup></mrow></mrow><mo id="A3.T5.4.4.1.m1.1.1.1.1.3" stretchy="false" xref="A3.T5.4.4.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A3.T5.4.4.1.m1.1.1.2" xref="A3.T5.4.4.1.m1.1.1.2.cmml">/</mo><mi id="A3.T5.4.4.1.m1.1.1.3" xref="A3.T5.4.4.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T5.4.4.1.m1.1b"><apply id="A3.T5.4.4.1.m1.1.1.cmml" xref="A3.T5.4.4.1.m1.1.1"><divide id="A3.T5.4.4.1.m1.1.1.2.cmml" xref="A3.T5.4.4.1.m1.1.1.2"></divide><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1"><plus id="A3.T5.4.4.1.m1.1.1.1.1.1.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.1"></plus><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.T5.4.4.1.m1.1.1.1.1.1.2.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="A3.T5.4.4.1.m1.1.1.1.1.1.2.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2.2">ùõΩ</ci><cn id="A3.T5.4.4.1.m1.1.1.1.1.1.2.3.cmml" type="integer" xref="A3.T5.4.4.1.m1.1.1.1.1.1.2.3">1</cn></apply><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.3.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3"><times id="A3.T5.4.4.1.m1.1.1.1.1.1.3.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.1"></times><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.2">ùõΩ</ci><cn id="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.3.cmml" type="integer" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.2.3">2</cn></apply><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3">superscript</csymbol><ci id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.2">ùëí</ci><apply id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.2">ùõº</ci><cn id="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="A3.T5.4.4.1.m1.1.1.1.1.1.3.3.3.3">2</cn></apply></apply></apply></apply><ci id="A3.T5.4.4.1.m1.1.1.3.cmml" xref="A3.T5.4.4.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.4.4.1.m1.1c">(\beta_{1}+\beta_{2}e^{\alpha_{2}})/S</annotation><annotation encoding="application/x-llamapun" id="A3.T5.4.4.1.m1.1d">( italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) / italic_S</annotation></semantics></math></td></tr><tr class=ltx_tr id=A3.T5.5.5><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id=A3.T5.5.5.2>other else</th><td class="ltx_td ltx_align_center ltx_border_b" id=A3.T5.5.5.1>(<math alttext="\beta_{1}+\beta_{2})/S" class="ltx_math_unparsed" display="inline" id="A3.T5.5.5.1.m1.1"><semantics id="A3.T5.5.5.1.m1.1a"><mrow id="A3.T5.5.5.1.m1.1b"><msub id="A3.T5.5.5.1.m1.1.1"><mi id="A3.T5.5.5.1.m1.1.1.2">Œ≤</mi><mn id="A3.T5.5.5.1.m1.1.1.3">1</mn></msub><mo id="A3.T5.5.5.1.m1.1.2">+</mo><msub id="A3.T5.5.5.1.m1.1.3"><mi id="A3.T5.5.5.1.m1.1.3.2">Œ≤</mi><mn id="A3.T5.5.5.1.m1.1.3.3">2</mn></msub><mo id="A3.T5.5.5.1.m1.1.4" stretchy="false">)</mo><mo id="A3.T5.5.5.1.m1.1.5">/</mo><mi id="A3.T5.5.5.1.m1.1.6">S</mi></mrow><annotation encoding="application/x-tex" id="A3.T5.5.5.1.m1.1c">\beta_{1}+\beta_{2})/S</annotation><annotation encoding="application/x-llamapun" id="A3.T5.5.5.1.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) / italic_S</annotation></semantics></math></td></tr></tbody></table></table></figure><blockquote><p>üîº This table summarizes the logit calculations for predicting different tokens in a simplified model, where the dimensionality (d) approaches infinity. It shows how the logits for predicting the (i-1)th, ith, (i+1)th, and other tokens depend on the learnable parameters Œ±1, Œ±2, Œ≤1, Œ≤2 and the normalization factor S. The factor S incorporates exponential functions of Œ±1 and Œ±2, indicating how much influence these parameters have on the logits, and also includes a term O(T), which represents an order-of-magnitude factor related to the sequence length (T). This simplified view is used in the theoretical analysis of the learning process, and not necessarily representative of the full model.</p><details><summary>read the caption</summary>Table 5: Logits summary, when dùëëditalic_d tend to ‚àû\infty‚àû, where S=2‚Å¢eŒ±1+eŒ±2+O‚Å¢(T)ùëÜ2superscriptùëísubscriptùõº1superscriptùëísubscriptùõº2ùëÇùëáS=2e^{\alpha_{1}}+e^{\alpha_{2}}+O(T)italic_S = 2 italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + italic_e start_POSTSUPERSCRIPT italic_Œ± start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + italic_O ( italic_T )</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameters</th><th>1.5B</th><th>2.9B</th><th>6.7B</th><th>13B</th><th>19B</th></tr></thead><tbody><tr><td>Hidden size</td><td>2,048</td><td>2,560</td><td>4,096</td><td>5,120</td><td>6,144</td></tr><tr><td>Layers</td><td>28</td><td>32</td><td>32</td><td>40</td><td>48</td></tr><tr><td>Head Number</td><td>16</td><td>20</td><td>32</td><td>40</td><td>48</td></tr><tr><td>KV Number</td><td>16</td><td>4</td><td>32</td><td>40</td><td>4</td></tr><tr><td>FFN size</td><td>5,504</td><td>8,704</td><td>11,008</td><td>13,824</td><td>16,384</td></tr><tr><td>Max Length</td><td>2,048</td><td>4,096</td><td>2048</td><td>2,048</td><td>12,288</td></tr><tr><td>Total Tokens</td><td>10B</td><td>500B</td><td>10B</td><td>10B</td><td>200B</td></tr><tr><td>Vocab size</td><td>36,000</td><td>48,000</td><td>36,000</td><td>36,000</td><td>48,000</td></tr><tr><td>GPU</td><td>A100-80G</td><td>H800-80G</td><td>A100-80G</td><td>A100-80G</td><td>A800-80G</td></tr><tr><td>GPU numbers</td><td>64</td><td>512</td><td>64</td><td>128</td><td>240</td></tr><tr><td>Context length</td><td>2,048</td><td>4,096</td><td>2,048</td><td>2,048</td><td>12,288</td></tr><tr><td>Batch size per GPU</td><td>8</td><td>8</td><td>8</td><td>8</td><td>1</td></tr><tr><td>Learning Rate</td><td>2e-4</td><td>8e-4</td><td>2e-4</td><td>2e-4</td><td>2e-4</td></tr><tr><td>Learning Rate shedule</td><td>constant</td><td>constant</td><td>constant</td><td>constant</td><td>constant</td></tr><tr><td>Warm-up steps</td><td>1,000</td><td>600</td><td>1,000</td><td>1,000</td><td>3,000</td></tr><tr><td>Optimizer</td><td>Adam with Œ±‚ÇÅ=0.9, Œ±‚ÇÇ=0.95, weight decay=0.1</td><td>Adam with Œ±‚ÇÅ=0.9, Œ±‚ÇÇ=0.95, weight decay=0.1</td><td>Adam with Œ±‚ÇÅ=0.9, Œ±‚ÇÇ=0.95, weight decay=0.1</td><td>Adam with Œ±‚ÇÅ=0.9, Œ±‚ÇÇ=0.95, weight decay=0.1</td><td>Adam with Œ±‚ÇÅ=0.9, Œ±‚ÇÇ=0.95, weight decay=0.1</td></tr><tr><td>RoPE‚Äôs Base</td><td>100,000</td><td>100,000</td><td>100,000</td><td>100,000</td><td>100,000</td></tr></tbody></table></table></figure><blockquote><p>üîº This table details the configurations used for training various large language models (LLMs) with different parameter sizes (1.5B, 2.9B, 6.7B, 13B, and 19B). It includes specifications such as hidden size, number of layers, number of heads, feedforward network size, maximum sequence length, vocabulary size, training tokens, GPU type and number, batch size, learning rate, optimizer, and the ROPE (Rotary Position Embedding) base value. The settings reflect choices made for both smaller-scale experiments and for large-scale production-level models.</p><details><summary>read the caption</summary>Table 6: Configuration.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model</th><th>Tr12-Te15</th><th>Tr21-Te24</th></tr></thead><tbody><tr><td>Vanilla</td><td>0.8154</td><td>0.8711</td></tr><tr><td>KV Shifting</td><td>0.8909</td><td>0.9062</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of experiments conducted on the iGSM dataset to evaluate the performance of Vanilla and KV Shifting attention models on grade-school math problems. The experiments are designed to assess the models&rsquo; ability to solve math problems with varying complexities. &lsquo;Tr X - Te Y&rsquo; indicates that the model was trained on problems with a maximum of X operations and tested on problems with Y operations. The results show the accuracy achieved by each model under these different training and testing conditions, highlighting the impact of the KV Shifting attention mechanism on problem-solving capabilities.</p><details><summary>read the caption</summary>Table 7: Experiments on iGSM. Tr X - Te Y means train with the numbers of operation no greater than X and test with the numbers of operation as Y.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-ad7952ecf41156e8b1e3740c8ec0768e class=gallery><img src=https://ai-paper-reviewer.com/2411.19574/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.19574/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/&amp;title=KV%20Shifting%20Attention%20Enhances%20Language%20Modeling" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/&amp;text=KV%20Shifting%20Attention%20Enhances%20Language%20Modeling" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19574/&amp;subject=KV%20Shifting%20Attention%20Enhances%20Language%20Modeling" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2411.19574/index.md",oid_likes="likes_paper-reviews/2411.19574/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2411.19638/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">LLM Teacher-Student Framework for Text Classification With No Manually Annotated Data: A Case Study in IPTC News Topic Classification</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2411.19799/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-29T00:00:00+00:00>29 November 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>