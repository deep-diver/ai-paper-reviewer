[{"figure_path": "2410.12109/figures/figures_1_1.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a sample video sequence from the OCTAV dataset, illustrating annotations highlighting key moments with audio and visual event timings.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_5_0.png", "caption": "Figure 2: Overview of the OMCAT pipeline. Video frames are processed through a frozen visual encoder, while audio frames are encoded using a frozen audio encoder. Extracted features are fine-tuned through adaptor layers across all three stages. The LLM remains frozen in Stage 1 and is fine-tuned in Stages 2 and 3. The purple blocks represent time alignment modules, with only one of them activated during training. \u2220 in bottom right denotes the rotation angle.", "description": "The figure illustrates the architecture of the OMCAT model, showing how video and audio features are processed and aligned with text prompts using adaptor layers and time alignment modules before being fed into a large language model to generate a response.", "section": "4 THE OMCAT APPROACH"}, {"figure_path": "2410.12109/figures/figures_10_0.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure illustrates a video sequence from the OCTAV dataset, showing annotations highlighting key moments with audio and visual events' timing.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_19_0.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a sample video sequence from the OCTAV dataset, highlighting key moments with audio and visual annotations.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_19_1.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure illustrates a video sequence from the OCTAV dataset, showing annotations that highlight key moments and the timing of audio and visual events.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_19_2.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a video sequence from the OCTAV dataset with annotations highlighting key moments, including the timing of audio and visual events.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_19_3.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure illustrates a video sequence from the OCTAV dataset, showing annotations that highlight key moments and the timing of audio and visual events.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_19_4.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a sample video sequence from the OCTAV dataset, illustrating how annotations highlight key moments with audio and visual events and their timing.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_20_0.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a sample video sequence from the OCTAV dataset, illustrating annotations highlighting key moments, including audio and visual event timings.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.12109/figures/figures_20_1.png", "caption": "Figure 1: Illustration of a video sequence from our proposed OCTAV dataset. The annotations highlight key moments, including the timing of the audio and visual events.", "description": "The figure shows a video sequence from the OCTAV dataset with annotations highlighting key moments, including the timing of audio and visual events.", "section": "1 INTRODUCTION"}]