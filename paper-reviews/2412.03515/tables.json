[{"content": "| Model | CD \u2193 | JSD \u2193 | Times (s) \u2193 |\n|---|---|---|---|\n| LMSCNet<sup>\u2020</sup> [26] | 0.641 | 0.431 | 0.40 |\n| LODE<sup>\u2020</sup> [14] | 1.029 | 0.451 | 1.76 |\n| MID<sup>\u2020</sup> [34] | 0.503 | 0.470 | 6.42 |\n| PVD [51] | 1.256 | 0.498 | - |\n| LiDiff<sup>\u2020</sup> [24] | 0.434 | 0.444 | 30.38 |\n| LiDiff (Refined)<sup>\u2020</sup> [24] | 0.375 | 0.416 | 30.55 |\n| ScoreLiDAR | 0.406 | 0.425 | 5.16 |\n| ScoreLiDAR (Refined) | 0.342 | 0.399 | 5.37 |", "caption": "Table 1: The completion performance on SemanticKITTI dataset. Colors denote the 1st, 2nd, and 3rd best-performing model. \u201c\u2020\u2020{\\dagger}\u2020\u201d indicates that the sampling time is estimated based on the official code and the provided checkpoints.", "description": "This table presents a quantitative comparison of different 3D LiDAR scene completion models on the SemanticKITTI dataset.  The models are evaluated using two metrics: Chamfer Distance (CD), measuring the geometric difference between the completed scene and the ground truth, and Jensen-Shannon Divergence (JSD), assessing the similarity of probability distributions of point clouds. Lower values for both metrics indicate better completion quality. The table also reports the completion time for each model.  Note that the time for some models is an estimate based on publicly available code and checkpoints rather than direct runtime measurement.", "section": "5.1 Scene completion"}, {"content": "| Model | CD \u2193 | JSD \u2193 | Times (s) \u2193 |\n|---|---|---|---|\n| LMSCNet [26] | 0.979 | 0.496 | - |\n| LODE [14] | 1.565 | 0.483 | - |\n| MID [34] | 0.637 | 0.476 | - |\n| LiDiff \u2020 [24] | 0.564 | 0.459 | 29.18 |\n| LiDiff (Refined) \u2020 [24] | 0.517 | 0.446 | 29.43 |\n| ScoreLiDAR | 0.472 | 0.444 | 4.98 |\n| ScoreLiDAR (Refined) | 0.452 | 0.437 | 5.14 |", "caption": "Table 2: The completion performance on the KITTI-360 dataset.\nThe meaning of notations is the same as those in Tab.\u00a01.", "description": "This table presents a quantitative evaluation of different methods for 3D LiDAR scene completion on the KITTI-360 dataset.  It shows the Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD) scores achieved by various models. Lower CD and JSD values indicate better scene completion quality.  The results allow for a comparison of the accuracy and fidelity of different approaches to reconstructing a complete 3D LiDAR scene from sparse input data.", "section": "5. Experiment"}, {"content": "| Model | SemanticKITTI CD \u2193 | SemanticKITTI JSD \u2193 | KITTI360 CD \u2193 | KITTI360 JSD \u2193 |\n|---|---|---|---|---|\n| ScoreLiDAR (Refined) | 0.342 | 0.399 | 0.452 | 0.437 |\n| w/o Structural Loss | 0.419 | 0.430 | 0.549 | 0.445 |", "caption": "Table 3: Ablation study of the structural loss.", "description": "This table presents an ablation study to evaluate the impact of the proposed structural loss on the performance of the ScoreLiDAR model.  It compares the results of ScoreLiDAR with and without the structural loss, showing the improvements in terms of Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD) on both the SemanticKITTI and KITTI360 datasets.  Lower CD and JSD values indicate better scene completion quality.", "section": "4.2 Structural loss"}, {"content": "| Model | CD \u2193 | JSD \u2193 | Time (s) \u2193 |\n|---|---|---|---|\n| LiDiff (50 steps) [24] | 0.434 | 0.444 | 30.38 |\n| LiDiff (50 steps Refined) [24] | 0.375 | 0.416 | 30.55 |\n| LiDiff (8 steps) [24] | 0.447 | 0.432 | 5.69 |\n| LiDiff (8 steps Refined) [24] | 0.411 | 0.406 | 5.92 |\n| ScoreLiDAR (8 Steps Refined) | 0.342 | 0.399 | 5.37 |\n| ScoreLiDAR (4 Steps Refined) | 0.326 | 0.386 | 3.23 |\n| ScoreLiDAR (2 Steps Refined) | 0.403 | 0.379 | 1.85 |\n| ScoreLiDAR (1 Steps Refined) | 0.548 | 0.384 | 1.10 |", "caption": "Table 4: Ablation study of different sampling steps on the SemanticKITTI dataset.", "description": "This table presents the results of an ablation study conducted to analyze the effect of varying the number of sampling steps in the ScoreLiDAR model on the SemanticKITTI dataset.  The study measures the performance of the model with different numbers of sampling steps (1, 2, 4, and 8 steps), and also includes results for a refined version of the model. The metrics used to evaluate performance are Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD), which both measure the difference between the completed point clouds produced by the model and the ground truth point clouds. Lower values of CD and JSD indicate better completion quality.", "section": "5.2 Ablation study"}, {"content": "| Model | SemanticKITTI CD \u2193 | SemanticKITTI JSD \u2193 | KITTI360 CD \u2193 | KITTI360 JSD \u2193 |\n|---|---|---|---|---|\n| ScoreLiDAR | 0.342 | 0.399 | 0.452 | 0.437 |\n| w/o Point-wise loss | 0.351 | 0.414 | 0.485 | 0.486 |\n| w/o Scene-wise loss | 0.367 | 0.422 | 0.477 | 0.451 |\n| w/o Structural Loss | 0.419 | 0.430 | 0.549 | 0.445 |", "caption": "Table 5: Ablation study of the scene-wise and point-wise loss. The metrics refer to the performance with refinement. Colors denote the 1st, 2nd, and 3rd best-performing model.", "description": "This table presents an ablation study evaluating the impact of the scene-wise and point-wise loss components within the ScoreLiDAR model.  The results show the model's performance (using Chamfer Distance and Jensen-Shannon Divergence metrics) on the SemanticKITTI and KITTI360 datasets, both with and without these loss components, as well as the overall model. The refinement process was applied to all results.  Color-coding highlights the top three performing configurations based on the combined metrics.", "section": "4.2. Structural loss"}, {"content": "| ScoreLiDAR | SemanticKITTI |  | KITTI360 |  | \n|---|---|---|---|---| \n|  | CD \u2193 | JSD \u2193 | CD \u2193 | JSD \u2193 | \n| $\n\\lambda_{scene}=0.5,\\lambda_{point}=0.01$ | 0.342 | 0.399 | 0.452 | 0.437 | \n| $\n\\lambda_{scene}=0.05,\\lambda_{point}=0.01$ | 0.354 | 0.409 | 0.494 | 0.457 | \n| $\n\\lambda_{scene}=0.5,\\lambda_{point}=0.1$ | 0.358 | 0.419 | 0.539 | 0.474 | ", "caption": "Table 6: Ablation study of the different weights of the scene-wise and point-wise loss. The first row refers to the default configuration of the ScoreLiDAR. The metrics refer to the performance with refinement.", "description": "This table presents an ablation study analyzing the impact of varying the weights assigned to the scene-wise and point-wise loss components within the ScoreLiDAR model.  The first row shows the performance using the default weights.  Subsequent rows illustrate the effect of adjusting these weights, demonstrating the sensitivity of the model to different weighting schemes.  All results presented include post-processing refinement steps applied to the generated output. The metrics presented are Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD), lower values indicating better performance.", "section": "4.3. Optimization procedure"}, {"content": "| Model | SemanticKITTI CD \u2193 | SemanticKITTI JSD \u2193 | KITTI360 CD \u2193 | KITTI360 JSD \u2193 |\n|---|---|---|---|---|\n| LiDiff (Refined) | 0.375 | 0.416 | 0.517 | 0.446 |\n| w/ Structural loss | 0.399 | 0.426 | 0.535 | 0.450 |", "caption": "Table 7: Ablation study of training LiDiff\u00a0[24] with structural loss.", "description": "This table presents the results of an ablation study evaluating the impact of adding a structural loss to the LiDiff model for 3D LiDAR scene completion.  It compares the performance of the original LiDiff model (without structural loss) to a version trained with the addition of the structural loss.  The comparison uses Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD) as metrics on the SemanticKITTI and KITTI360 datasets to assess the quality of the 3D scene completion.", "section": "5.2 Ablation study"}, {"content": "| ScoreLiDAR | SemanticKITTI |  | KITTI360 |  |\n|---|---|---|---|---|\n|  | CD \u2193 | JSD \u2193 | CD \u2193 | JSD \u2193 |\n| n=1/30 | 0.342 | 0.399 | 0.452 | 0.437 |\n| n=1/60 | 0.346 | 0.409 | 0.452 | 0.471 |", "caption": "Table 8: Ablation study of different key points number. The first row refers to the default configuration of the ScoreLiDAR. The metrics refer to the performance with refinement.", "description": "This table presents an ablation study on the impact of varying the number of key points used in the ScoreLiDAR model.  The study investigates how the selection of different numbers of key points affects the model's performance after refinement. The first row shows the results using the default configuration of the ScoreLiDAR model, while subsequent rows show the performance with reduced numbers of key points.  The metrics used to evaluate performance are Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD), both lower values indicating improved accuracy and fidelity compared to the ground truth.", "section": "5.2. Ablation study"}, {"content": "| Model | CD \u2193 | JSD \u2193 | Time (s) \u2193 |\n|---|---|---|---|\n| LiDiff (50 steps) [24] | 0.564 | 0.549 | 29.18 |\n| LiDiff (50 steps Refined) [24] | 0.517 | 0.446 | 29.43 |\n| LiDiff (8 steps) [24] | 0.619 | 0.471 | 5.46 |\n| LiDiff (8 steps Refined) [24] | 0.550 | 0.462 | 5.77 |\n| ScoreLiDAR (8 Steps) | 0.452 | 0.437 | 5.14 |\n| ScoreLiDAR (4 Steps) | 0.482 | 0.461 | 3.16 |\n| ScoreLiDAR (2 Steps) | 0.525 | 0.457 | 1.69 |\n| ScoreLiDAR (1 Steps) | 0.750 | 0.478 | 1.03 |", "caption": "Table 9: Ablation study of different sampling steps on the KITTI-360 dataset. The\nmetrics of ScoreLiDAR refer to the performance with refinement.", "description": "This table presents an ablation study analyzing the effect of varying the number of sampling steps on the performance of the ScoreLiDAR model for 3D LiDAR scene completion on the KITTI-360 dataset.  It compares the performance of ScoreLiDAR using different numbers of sampling steps (8, 4, 2, and 1) against the baseline LiDiff model with 50 sampling steps. Both the baseline LiDiff model and the ScoreLiDAR models' performance are measured with and without refinement, showing the impact of refinement on the results.  The metrics used for comparison are Chamfer Distance (CD) and Jensen-Shannon Divergence (JSD), lower values indicating better scene completion quality. The 'Time (s)' column displays the time taken for scene completion.  The results show the trade-off between completion speed and accuracy at various sampling steps.", "section": "5.2. Ablation study"}, {"content": "| Model | User preference \u2191 | \n|---|---| \n| LiDiff [24] | 35% | \n| ScoreLiDAR | 65% | ", "caption": "Table 10: Results of user study. Our ScoreLiDAR outperforms the existing SOTA model.", "description": "A user study was conducted to compare the scene completion quality of ScoreLiDAR and the state-of-the-art (SOTA) LiDiff model. Thirty pairs of completed scenes were generated using both methods for the same 30 input LiDAR scans. Seven volunteers evaluated each pair and selected the one that was more similar to the corresponding ground truth scene. ScoreLiDAR received a 65% user preference over LiDiff, demonstrating its superior performance in producing realistic and accurate scene completions.", "section": "5. Experiment"}, {"content": "| Model | SemanticKITTI (IoU) % \u2191 | 0.5m | 0.2m | 0.1m |\n|---|---|---|---|---|\n| LMSCNet [26] | 32.23 | 23.05 | 3.48 |\n| LODE [14] | 43.56 | 47.88 | 6.06 |\n| MID [34] | 45.02 | 41.01 | 16.98 |\n| PVD [51] | 21.20 | 7.96 | 1.44 |\n| LiDiff [24] | 42.49 | 33.12 | 11.02 |\n| LiDiff (Refined) [24] | 40.71 | 38.92 | 24.75 |\n| ScoreLiDAR | 38.43 | 25.75 | 8.34 |\n| ScoreLiDAR (Refined) | 37.33 | 29.57 | 15.63 |", "caption": "Table 11: The IoU evaluation results on the SemanticKITTI dataset.", "description": "This table presents the Intersection over Union (IoU) scores achieved by different models on the SemanticKITTI dataset.  IoU is a common metric for evaluating the accuracy of semantic segmentation, measuring the overlap between the predicted segmentation and the ground truth. The results are shown for three different voxel resolutions (0.5m, 0.2m, and 0.1m), representing different levels of detail.  Higher IoU values indicate better performance.", "section": "5. Experiments"}, {"content": "| Model | KITTI-360 (IoU) % \u2191 |  |  |  | \n|---|---|---|---|---|\n|  | 0.5m | 0.2m | 0.1m |  | \n| LMSCNet [26] | 25.46 | 16.35 | 2.99 |  | \n| LODE [14] | 42.08 | 42.63 | 5.85 |  | \n| MID [34] | 44.11 | 36.38 | 15.84 |  | \n| LiDiff [24] | 42.22 | 32.25 | 10.80 |  | \n| LiDiff (Refined) [24] | 40.82 | 36.08 | 21.34 |  | \n| ScoreLiDAR | 36.82 | 25.49 | 9.70 |  | \n| ScoreLiDAR (Refined) | 33.29 | 28.60 | 15.95 |  | ", "caption": "Table 12: The IoU evaluation results on the KITTI-360 dataset.", "description": "This table presents the Intersection over Union (IoU) scores for different 3D LiDAR scene completion models on the KITTI-360 dataset.  IoU is a metric measuring the overlap between the predicted scene and ground truth at various voxel resolutions (0.5m, 0.2m, and 0.1m). Higher IoU values indicate better completion accuracy.  The models compared include LMSCNet, LODE, MID, PVD, LiDiff (with and without refinement), and ScoreLiDAR (with and without refinement). The table shows how well each model performs at these different resolutions, allowing for a comparison of completion quality and detail.", "section": "5. Experiment"}]