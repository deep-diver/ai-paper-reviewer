[{"content": "| Type | Model | FID \u2193 | IS \u2191 | Pre \u2191 | Rec \u2191 | #Para | #Step | Time |\n|---|---|---|---|---|---|---|---|---|\n| GAN\u2020 | StyleGan-XL (Sauer et al., 2022) | 2.30 | 265.1 | 0.78 | 0.53 | 166M | 1 | 0.3 |\n| Diff.\u2020 | ADM (Dhariwal & Nichol, 2021) | 10.94 | 101.0 | 0.69 | 0.63 | 554M | 250 | 168 |\n| Diff.\u2020 | LDM-4-G (Rombach et al., 2022) | 3.60 | 247.7 | - | - | 400M | 250 | - |\n| Diff.\u2020 | DiT-L/2 (Peebles & Xie, 2023) | 5.02 | 167.2 | 0.75 | 0.57 | 458M | 250 | 31 |\n| Diff.\u2020 | L-DiT-7B (Peebles & Xie, 2023) | 2.28 | 316.2 | 0.83 | 0.58 | 7.0B | 250 | >45 |\n| Mask.\u2020 | MaskGIT (Chang et al., 2022) | 6.18 | 182.1 | 0.80 | 0.51 | 227M | 8 | 0.5 |\n| AR\u2020 | VQVAE-2\u2020 (Razavi et al., 2019) | 31.11 | ~45 | 0.36 | 0.57 | 13.5B | 5120 | - |\n| AR\u2020 | VQGAN\u2020 (Esser et al., 2021) | 18.65 | 80.4 | 0.78 | 0.26 | 227M | 256 | 19 |\n| AR | VQGAN (Esser et al., 2021) | 15.78 | 74.3 | - | - | 1.4B | 256 | 24 |\n| AR | ViTVQ (Yu et al., 2021) | 4.17 | 175.1 | - | - | 1.7B | 1024 | >24 |\n| AR | RQTran. (Lee et al., 2022) | 7.55 | 134.0 | - | - | 3.8B | 68 | 21 |\n| AR | VAR-d16 (Tian et al., 2024) | 4.19 | 230.2 | 0.84 | 0.48 | 310M | 10 | 0.133 |\n| AR | VAR-d20 (Tian et al., 2024) | 3.35 | 301.4 | 0.84 | 0.51 | 600M | 10 | - |\n| AR | VAR-d24 (Tian et al., 2024) | 2.51 | 312.2 | 0.82 | 0.53 | 1.03B | 10 | - |\n| AR | LlamaGen-B (Sun et al., 2024) | 5.42 | 193.5 | 0.83 | 0.44 | 111M | 256 | - |\n| AR | LlamaGen-L (Sun et al., 2024) | 4.11 | 283.5 | 0.85 | 0.48 | 343M | 256 | 5.01 |\n| Baseline | VAR-_skip-1_ | 9.52 | 178.9 | 0.68 | 0.54 | 310M | 9 | 0.113 |\n| Baseline | VAR-_skip-2_ | 40.09 | 56.8 | 0.46 | 0.50 | 310M | 8 | 0.098 |\n| Baseline | VAR-_onestep*_ | 157.5 | - | - | - | 1 | - | - |\n| Baseline | LlamaGen-_skip-106_ | 19.14 | 80.39 | 0.42 | 0.43 | 343M | 150 | 2.94 |\n| Baseline | LlamaGen-_skip-156_ | 80.72 | 12.13 | 0.17 | 0.20 | 343M | 100 | 1.95 |\n| Baseline | LlamaGen-_onestep*_ | 220.2 | - | - | - | 1 | - | - |\n| Ours | VAR-d16-DD | 9.94 | 193.6 | 0.80 | 0.37 | 327M | 1 | 0.021 (6.3\u00d7) |\n| Ours | VAR-d16-DD | 7.82 | 197.0 | 0.80 | 0.41 | 327M | 2 | 0.036 (3.7\u00d7) |\n| Ours | VAR-d20-DD | 9.55 | 197.2 | 0.78 | 0.38 | 635M | 1 | - |\n| Ours | VAR-d20-DD | 7.33 | 204.5 | 0.82 | 0.40 | 635M | 2 | - |\n| Ours | VAR-d24-DD | 8.92 | 202.8 | 0.78 | 0.39 | 1.09B | 1 | - |\n| Ours | VAR-d24-DD | 6.95 | 222.5 | 0.83 | 0.43 | 1.09B | 2 | - |\n| Ours | LlamaGen-B-DD | 15.50 | 135.4 | 0.76 | 0.26 | 98.3M | 1 | - |\n| Ours | LlamaGen-B-DD | 11.17 | 154.8 | 0.80 | 0.31 | 98.3M | 2 | - |\n| Ours | LlamaGen-L-DD | 11.35 | 193.6 | 0.81 | 0.30 | 326M | 1 | 0.023 (217.8\u00d7) |\n| Ours | LlamaGen-L-DD | 7.58 | 237.5 | 0.84 | 0.37 | 326M | 2 | 0.043 (116.5\u00d7) |", "caption": "Table 1: \nGenerative performance on class-conditional ImageNet-256. \u201c#Step\u201d indicates the number of model inference to generate one image. \u201cTime\u201d is the wall-time of generating one image in the steady state. Results with \u2020 are taken from the VAR paper (Tian et\u00a0al., 2024).", "description": "Table 1 presents a comparison of various image generation models on the ImageNet-256 dataset, focusing on the trade-off between generation quality and speed.  The table includes several state-of-the-art autoregressive (AR) models along with the proposed Distilled Decoding (DD) method and several baselines. For each model, the table shows the Fr\u00e9chet Inception Distance (FID) score, which measures the quality of the generated images; the Inception Score (IS) and Precision (Prec) scores, which are other metrics for image quality; the Recall score (Rec); the number of parameters (#Para) in the model; the number of steps required to generate an image (#Step); and the wall-clock time to generate one image (Time). The results show that the DD approach is able to significantly reduce generation time while maintaining reasonable image quality compared to the baseline and pre-trained models. Results marked with \u2020 are taken directly from the cited VAR paper.", "section": "5 Experiments"}, {"content": "| Type | Model | FID\u2193 | IS\u2191 | Pre\u2191 | Rec\u2191 | #Para | #Step | Time |\n|---|---|---|---|---|---|---|---|---|\n| AR | VAR (Tian et al., 2024) | 4.19 | 230.2 | 0.84 | 0.48 | 310M | 10 | 0.133 |\n| AR | LlamaGen (Sun et al., 2024) | 4.11 | 283.5 | 0.865 | 0.48 | 343M | 256 | 5.01 |\n| Ours | VAR-pre-trained-1-6 | 5.03 | 242.8 | 0.84 | 0.45 | 327M | 6 | 0.090 (1.5\u00d7) |\n| Ours | VAR-pre-trained-4-6 | 5.47 | 230.5 | 0.84 | 0.43 | 327M | 4 | 0.062 (2.1\u00d7) |\n| Ours | VAR-pre-trained-5-6 | 6.54 | 210.8 | 0.83 | 0.42 | 327M | 3 | 0.045 (2.6\u00d7) |\n| Ours | LlamaGen-pre-trained-1-81 | 5.71 | 238.6 | 0.83 | 0.43 | 326M | 81 | 1.725 (2.9\u00d7) |\n| Ours | LlamaGen-pre-trained-41-81 | 6.20 | 233.8 | 0.83 | 0.41 | 326M | 42 | 0.880 (5.7\u00d7) |\n| Ours | LlamaGen-pre-trained-61-81 | 6.76 | 231.4 | 0.83 | 0.40 | 326M | 22 | 0.447 (11.2\u00d7) |", "caption": "Table 2: Generation quality of involving the pre-trained AR model when sampling. The notation pre-trained-n-m means that the pre-trained AR model is used to re-generate the n\ud835\udc5bnitalic_n-th to m\u22121\ud835\udc5a1m-1italic_m - 1-th tokens in the sequence generated by the first step of DD.", "description": "Table 2 presents a detailed comparison of image generation quality when incorporating the pre-trained autoregressive (AR) model into the sampling process.  It contrasts the performance of using only the distilled decoding (DD) model versus various combinations where a portion of the token sequence generated by the first DD step is replaced using the pre-trained AR model.  The notation 'pre-trained-n-m' indicates that tokens n through m-1 in the sequence were re-generated with the pre-trained AR model. This allows for investigating the trade-off between generation speed and image quality by adjusting how many tokens are replaced with the pre-trained model's output. The table shows FID, IS, Precision, Recall, number of parameters, number of steps, and generation time for each configuration.", "section": "5.3 Generation Involving the Pre-trained Models"}, {"content": "| Type | Model | FID | #Param | #Step | Time |\n|---|---|---|---|---|---| \n| AR | LlamaGen | 25.70 | 775M | 256 | 7.90 |\n| Ours | LlamaGen-DD | 36.09 | 756M | 1 | 0.052 (151.9x) |\n| Ours | LlamaGen-DD | 28.95 | 756M | 2 | 0.085 (92.9x) |", "caption": "Table 3: Generation results of DD on text-to-image task.", "description": "This table presents the results of the Distilled Decoding (DD) method on a text-to-image generation task.  It shows the Fr\u00e9chet Inception Distance (FID), the number of parameters, the number of generation steps, and the generation time for different models.  The results are compared to those of the original LlamaGen model, demonstrating the performance gains achieved by DD in terms of speed while maintaining comparable image quality.  The table specifically focuses on a text-to-image task.", "section": "5. Experiments"}]