[{"figure_path": "2410.18076/tables/table_16_0.html", "caption": "Table 2: VAE training details.", "description": "This table shows the hyperparameters used for training the variational autoencoder (VAE) in the SUPE algorithm.", "section": "Pretraining with trajectory VAE"}, {"figure_path": "2410.18076/tables/table_17_0.html", "caption": "Table 3: Hyperparameters for the online RL agent following RLPD (Ball et al., 2023)/ExPLORe (Li et al., 2024). For Diffusion BC + JSRL on AntMaze, we use an initial entropy temperature of 1.0 because it works much better than 0.05. We use a 4\u00d7 larger RND coefficient in skill-based methods such that the reward bonus we get for each step in the skill horizon stays roughly proportional to the non-skill-based methods.", "description": "Table 3 lists the hyperparameters used for training the online reinforcement learning agent in the SUPE method, including those for different environments and skill-based methods.", "section": "Practical implementation details"}]