{"references": [{"fullname_first_author": "Haoxin Chen", "paper_title": "VideoCrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-01-01", "reason": "This paper introduces VideoCrafter2, a significant advancement in video diffusion models that addresses data limitations for generating high-quality videos, which is relevant to the current work's focus on improving video generation through better captions."}, {"fullname_first_author": "Lin Chen", "paper_title": "ShareGPT4Video: Improving video understanding and generation with better captions.", "publication_date": "2024-06-01", "reason": "ShareGPT4Video is a key reference as it directly relates to the core problem addressed in this work, i.e., improving video understanding and generation through enhanced video captioning."}, {"fullname_first_author": "Xuan Ju", "paper_title": "MiraData: A large-scale video dataset with long durations and structured captions.", "publication_date": "2024-07-01", "reason": "MiraData is a crucial reference because it introduces a large-scale video dataset with structured captions, a key aspect that this work builds upon and compares against for instance-aware captioning."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision.", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, which is fundamental to the methods used in this work for evaluating the similarity between generated videos and text descriptions due to its ability to learn transferable visual models from natural language."}, {"fullname_first_author": "Zhuoyi Yang", "paper_title": "CogVideoX: Text-to-video diffusion models with an expert transformer.", "publication_date": "2024-08-01", "reason": "CogVideoX serves as a core baseline for video generation in this work and its latent diffusion model architecture is relevant to the instance-level detail and motion consistency improvements proposed by the authors."}]}