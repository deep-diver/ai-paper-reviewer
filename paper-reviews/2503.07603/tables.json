[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S2.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.1\" style=\"background-color:#D9D9D9;\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.1.1.1.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.1.1.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.1.1.1.1\">Model</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.1.1.2.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.1.1.2.1.1\" style=\"width:62.6pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.2.1.1.1\">Text-Only Pre-training</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.1.1.3.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.1.1.3.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.3.1.1.1\">Image-Text Pre-training</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.1.1.4.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.1.1.4.1.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.4.1.1.1\">Multitask Fine-Tuning</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.2.1\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.2.1.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.2.1.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.2.1.1.1.1.1\">BLIP3\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Xue et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib48\" title=\"\">2024</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.2.1.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.2.1.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(Phi3-mini)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.2.1.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.2.1.3.1.1\" style=\"width:142.3pt;\">Re-warmup\n<br class=\"ltx_break\"/>Caption and interleaved text-image data; no pure text</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.1.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.2.1.4.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.2.1.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.3.2\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.3.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.3.2.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.3.2.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.3.2.1.1.1.1\">Flamingo\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Alayrac et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib2\" title=\"\">2022</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.3.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.3.2.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.3.2.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(closed model)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.3.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.3.2.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.3.2.3.1.1\" style=\"width:142.3pt;\">Re-warmup\n<br class=\"ltx_break\"/>Caption and interleaved text-image data; no pure text</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.3.2.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.3.2.4.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.3.2.4.1.1\" style=\"width:56.9pt;\">(Skipped)</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.3\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.4.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.4.3.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.4.3.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.4.3.1.1.1.1\">IDEFICS\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Lauren\u00e7on et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib27\" title=\"\">2024</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.4.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.4.3.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.4.3.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(Mistral-7B-v0.1)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.4.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.4.3.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.4.3.3.1.1\" style=\"width:142.3pt;\">Re-warmup\n<br class=\"ltx_break\"/>Interleaved text-image data; no pure text</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.4.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.4.3.4.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.4.3.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5.4\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.5.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.5.4.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.5.4.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.5.4.1.1.1.1\">MM1\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(McKinzie et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib37\" title=\"\">2024</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.5.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.5.4.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.5.4.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(closed model)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.5.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.5.4.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.5.4.3.1.1\" style=\"width:142.3pt;\">Re-warmup\n<br class=\"ltx_break\"/>Various image-text ratios (100::0, 91::9, 86::14, 66::33)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.5.4.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.5.4.4.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.5.4.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.6.5\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.6.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.6.5.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.6.5.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.6.5.1.1.1.1\">DeepSeek-VL / DeepSeek-VL2\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Lu et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib36\" title=\"\">2024</a>; Wu et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib47\" title=\"\">2024b</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.6.5.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.6.5.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.6.5.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(DeepSeek)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.6.5.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.6.5.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.6.5.3.1.1\" style=\"width:142.3pt;\">Two-stage (re-warmup then re-warmup) \n<br class=\"ltx_break\"/>Multitask; 30::70 image-text ratio</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.6.5.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.6.5.4.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.6.5.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.7.6\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.7.6.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.7.6.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.7.6.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.7.6.1.1.1.1\">Qwen-VL\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib6\" title=\"\">2023</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.7.6.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.7.6.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.7.6.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(Qwen)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.7.6.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.7.6.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.7.6.3.1.1\" style=\"width:142.3pt;\">Two-stage (re-warmup then re-warmup)\n<br class=\"ltx_break\"/>Caption then multitask; no pure text</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.7.6.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.7.6.4.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.7.6.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.7\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.8.7.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.8.7.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.8.7.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.8.7.1.1.1.1\">PaliGemma\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Beyer et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib9\" title=\"\">2024</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.8.7.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.8.7.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.8.7.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(Gemma)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.8.7.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.8.7.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.8.7.3.1.1\" style=\"width:142.3pt;\">Two-stage (re-warmup then continue LR schedule)\n<br class=\"ltx_break\"/>Multitask; no pure text</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.8.7.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.8.7.4.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.8.7.4.1.1\" style=\"width:56.9pt;\">Continued LR schedule</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.8\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.9.8.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.9.8.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.9.8.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.9.8.1.1.1.1\">Janus / Janus Pro\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Wu et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib46\" title=\"\">2024a</a>; Chen et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib12\" title=\"\">2025</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.9.8.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.9.8.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.9.8.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(DeepSeek-LLM)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.9.8.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.9.8.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.9.8.3.1.1\" style=\"width:142.3pt;\">Two-stage (re-warmup then re-warmup)\n<br class=\"ltx_break\"/>Multitask; no pure text, followed by 30::70 image-text ratio</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.9.8.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.9.8.4.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.9.8.4.1.1\" style=\"width:56.9pt;\">No warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.10.9\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"S2.T1.1.10.9.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.10.9.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.10.9.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.10.9.1.1.1.1\">Prismatic\n<br class=\"ltx_break\"/></span>\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Karamcheti et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2503.07603v1#bib.bib24\" title=\"\">2024</a>)</cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.10.9.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.10.9.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.10.9.2.1.1\" style=\"width:62.6pt;\">Fully pre-trained\n<br class=\"ltx_break\"/>(LLaMA)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.10.9.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.10.9.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.10.9.3.1.1\" style=\"width:142.3pt;\">No image-text pre-training.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S2.T1.1.10.9.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.10.9.4.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.10.9.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.11.10\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r\" id=\"S2.T1.1.11.10.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.11.10.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.11.10.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.11.10.1.1.1.1\">Ours</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"S2.T1.1.11.10.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.11.10.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.11.10.2.1.1\" style=\"width:62.6pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.11.10.2.1.1.1\">Partially</span> pre-trained\n<br class=\"ltx_break\"/>(OpenLM)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"S2.T1.1.11.10.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.11.10.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.11.10.3.1.1\" style=\"width:142.3pt;\">Continued LR schedule\n<br class=\"ltx_break\"/>Various image-text ratios</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"S2.T1.1.11.10.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.11.10.4.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"S2.T1.1.11.10.4.1.1\" style=\"width:56.9pt;\">Re-warmup</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: The conventional approach to VLM training first fully trains a language model on text-only data, and adds images in a second or third stage of training. In this work, we instead introduce image data earlier in pre-training. To do this efficiently, we resume a language model during the course of its pre-training at various stages (e.g., 20% of the way through training) and introduce images midway through training.", "description": "This table compares different approaches to Vision-Language Model (VLM) training.  Traditional methods (shown in the table) first fully train a language model using only text data, then add image data in a later stage (fine-tuning). The authors' approach, however, introduces image data earlier in the pre-training process.  To maintain efficiency, this involves resuming a pre-trained language model at various points (e.g., 20%, 80%) and then incorporating the image data. The table lists several existing VLMs, detailing their pre-training and fine-tuning methods to highlight the differences with the proposed method.", "section": "2.1 TRAINING PROCEDURE"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T2.19\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T2.17.5\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.13.1.1\"><math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.13.1.1.m1.1\"><semantics id=\"A1.T2.13.1.1.m1.1a\"><mi id=\"A1.T2.13.1.1.m1.1.1\" xref=\"A1.T2.13.1.1.m1.1.1.cmml\">N</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.13.1.1.m1.1b\"><ci id=\"A1.T2.13.1.1.m1.1.1.cmml\" xref=\"A1.T2.13.1.1.m1.1.1\">\ud835\udc41</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.13.1.1.m1.1c\">N</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.13.1.1.m1.1d\">italic_N</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.14.2.2\"><math alttext=\"n_{\\text{layers}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.14.2.2.m1.1\"><semantics id=\"A1.T2.14.2.2.m1.1a\"><msub id=\"A1.T2.14.2.2.m1.1.1\" xref=\"A1.T2.14.2.2.m1.1.1.cmml\"><mi id=\"A1.T2.14.2.2.m1.1.1.2\" xref=\"A1.T2.14.2.2.m1.1.1.2.cmml\">n</mi><mtext id=\"A1.T2.14.2.2.m1.1.1.3\" xref=\"A1.T2.14.2.2.m1.1.1.3a.cmml\">layers</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.14.2.2.m1.1b\"><apply id=\"A1.T2.14.2.2.m1.1.1.cmml\" xref=\"A1.T2.14.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A1.T2.14.2.2.m1.1.1.1.cmml\" xref=\"A1.T2.14.2.2.m1.1.1\">subscript</csymbol><ci id=\"A1.T2.14.2.2.m1.1.1.2.cmml\" xref=\"A1.T2.14.2.2.m1.1.1.2\">\ud835\udc5b</ci><ci id=\"A1.T2.14.2.2.m1.1.1.3a.cmml\" xref=\"A1.T2.14.2.2.m1.1.1.3\"><mtext id=\"A1.T2.14.2.2.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"A1.T2.14.2.2.m1.1.1.3\">layers</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.14.2.2.m1.1c\">n_{\\text{layers}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.14.2.2.m1.1d\">italic_n start_POSTSUBSCRIPT layers end_POSTSUBSCRIPT</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.15.3.3\"><math alttext=\"n_{\\text{heads}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.15.3.3.m1.1\"><semantics id=\"A1.T2.15.3.3.m1.1a\"><msub id=\"A1.T2.15.3.3.m1.1.1\" xref=\"A1.T2.15.3.3.m1.1.1.cmml\"><mi id=\"A1.T2.15.3.3.m1.1.1.2\" xref=\"A1.T2.15.3.3.m1.1.1.2.cmml\">n</mi><mtext id=\"A1.T2.15.3.3.m1.1.1.3\" xref=\"A1.T2.15.3.3.m1.1.1.3a.cmml\">heads</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.15.3.3.m1.1b\"><apply id=\"A1.T2.15.3.3.m1.1.1.cmml\" xref=\"A1.T2.15.3.3.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A1.T2.15.3.3.m1.1.1.1.cmml\" xref=\"A1.T2.15.3.3.m1.1.1\">subscript</csymbol><ci id=\"A1.T2.15.3.3.m1.1.1.2.cmml\" xref=\"A1.T2.15.3.3.m1.1.1.2\">\ud835\udc5b</ci><ci id=\"A1.T2.15.3.3.m1.1.1.3a.cmml\" xref=\"A1.T2.15.3.3.m1.1.1.3\"><mtext id=\"A1.T2.15.3.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"A1.T2.15.3.3.m1.1.1.3\">heads</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.15.3.3.m1.1c\">n_{\\text{heads}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.15.3.3.m1.1d\">italic_n start_POSTSUBSCRIPT heads end_POSTSUBSCRIPT</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.16.4.4\"><math alttext=\"d_{\\text{model}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.16.4.4.m1.1\"><semantics id=\"A1.T2.16.4.4.m1.1a\"><msub id=\"A1.T2.16.4.4.m1.1.1\" xref=\"A1.T2.16.4.4.m1.1.1.cmml\"><mi id=\"A1.T2.16.4.4.m1.1.1.2\" xref=\"A1.T2.16.4.4.m1.1.1.2.cmml\">d</mi><mtext id=\"A1.T2.16.4.4.m1.1.1.3\" xref=\"A1.T2.16.4.4.m1.1.1.3a.cmml\">model</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.16.4.4.m1.1b\"><apply id=\"A1.T2.16.4.4.m1.1.1.cmml\" xref=\"A1.T2.16.4.4.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A1.T2.16.4.4.m1.1.1.1.cmml\" xref=\"A1.T2.16.4.4.m1.1.1\">subscript</csymbol><ci id=\"A1.T2.16.4.4.m1.1.1.2.cmml\" xref=\"A1.T2.16.4.4.m1.1.1.2\">\ud835\udc51</ci><ci id=\"A1.T2.16.4.4.m1.1.1.3a.cmml\" xref=\"A1.T2.16.4.4.m1.1.1.3\"><mtext id=\"A1.T2.16.4.4.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"A1.T2.16.4.4.m1.1.1.3\">model</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.16.4.4.m1.1c\">d_{\\text{model}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.16.4.4.m1.1d\">italic_d start_POSTSUBSCRIPT model end_POSTSUBSCRIPT</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.5\"><math alttext=\"d_{\\text{head}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.17.5.5.m1.1\"><semantics id=\"A1.T2.17.5.5.m1.1a\"><msub id=\"A1.T2.17.5.5.m1.1.1\" xref=\"A1.T2.17.5.5.m1.1.1.cmml\"><mi id=\"A1.T2.17.5.5.m1.1.1.2\" xref=\"A1.T2.17.5.5.m1.1.1.2.cmml\">d</mi><mtext id=\"A1.T2.17.5.5.m1.1.1.3\" xref=\"A1.T2.17.5.5.m1.1.1.3a.cmml\">head</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.17.5.5.m1.1b\"><apply id=\"A1.T2.17.5.5.m1.1.1.cmml\" xref=\"A1.T2.17.5.5.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A1.T2.17.5.5.m1.1.1.1.cmml\" xref=\"A1.T2.17.5.5.m1.1.1\">subscript</csymbol><ci id=\"A1.T2.17.5.5.m1.1.1.2.cmml\" xref=\"A1.T2.17.5.5.m1.1.1.2\">\ud835\udc51</ci><ci id=\"A1.T2.17.5.5.m1.1.1.3a.cmml\" xref=\"A1.T2.17.5.5.m1.1.1.3\"><mtext id=\"A1.T2.17.5.5.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"A1.T2.17.5.5.m1.1.1.3\">head</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.17.5.5.m1.1c\">d_{\\text{head}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.17.5.5.m1.1d\">italic_d start_POSTSUBSCRIPT head end_POSTSUBSCRIPT</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.6\">Warmup</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.7\">Learning rate</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.8\">Batch size</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.9\">Training tokens</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T2.17.5.10\">A100 hours</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T2.18.6\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A1.T2.18.6.2\">79M</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.3\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.4\">4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.5\">512</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.6\">128</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.7\">400</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.1\">3<math alttext=\"e\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.18.6.1.m1.1\"><semantics id=\"A1.T2.18.6.1.m1.1a\"><mi id=\"A1.T2.18.6.1.m1.1.1\" xref=\"A1.T2.18.6.1.m1.1.1.cmml\">e</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.18.6.1.m1.1b\"><ci id=\"A1.T2.18.6.1.m1.1.1.cmml\" xref=\"A1.T2.18.6.1.m1.1.1\">\ud835\udc52</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.18.6.1.m1.1c\">e</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.18.6.1.m1.1d\">italic_e</annotation></semantics></math>-3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.8\">512</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.9\">237B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T2.18.6.10\">1.2k</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T2.19.7\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"A1.T2.19.7.2\">1.4B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.3\">24</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.4\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.5\">2,048</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.6\">128</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.7\">5000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.1\">1<math alttext=\"e\" class=\"ltx_Math\" display=\"inline\" id=\"A1.T2.19.7.1.m1.1\"><semantics id=\"A1.T2.19.7.1.m1.1a\"><mi id=\"A1.T2.19.7.1.m1.1.1\" xref=\"A1.T2.19.7.1.m1.1.1.cmml\">e</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.19.7.1.m1.1b\"><ci id=\"A1.T2.19.7.1.m1.1.1.cmml\" xref=\"A1.T2.19.7.1.m1.1.1\">\ud835\udc52</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.19.7.1.m1.1c\">e</annotation><annotation encoding=\"application/x-llamapun\" id=\"A1.T2.19.7.1.m1.1d\">italic_e</annotation></semantics></math>-2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.8\">256</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.9\">4.3T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T2.19.7.10\">106k</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: The two models and set of hyperparameters used in our experiments. Models have number of parameters N\ud835\udc41Nitalic_N, with number of layers nlayerssubscript\ud835\udc5blayersn_{\\text{layers}}italic_n start_POSTSUBSCRIPT layers end_POSTSUBSCRIPT, number of attention heads nheadssubscript\ud835\udc5bheadsn_{\\text{heads}}italic_n start_POSTSUBSCRIPT heads end_POSTSUBSCRIPT, model width dmodelsubscript\ud835\udc51modeld_{\\text{model}}italic_d start_POSTSUBSCRIPT model end_POSTSUBSCRIPT, and width per attention head dheadsubscript\ud835\udc51headd_{\\text{head}}italic_d start_POSTSUBSCRIPT head end_POSTSUBSCRIPT. Batch sizes are global and in units of sequences. Each sequence has 2,048 tokens.\nA100 GPU hours are at M=150\ud835\udc40150M=150italic_M = 150.\nFor the 1.4B scale, a batch size of 256 performs slightly better than 512.", "description": "This table details the hyperparameters used for training two different sized language models: a 79M parameter model and a 1.4B parameter model.  It lists the number of layers, attention heads, model width, and width per attention head for each model.  It also specifies the batch size (in sequences of 2048 tokens), the training token count, the learning rate, the warmup setting, and the approximate A100 GPU hours utilized for training at a scaling factor (M) of 150.  Importantly, the table notes that for the larger 1.4B parameter model, a batch size of 256 sequences produced slightly better results than a batch size of 512.", "section": "2.1 Training Procedure"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A8.T3.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A8.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.1.1.1.1.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A8.T3.1.1.1.1.1.1.1\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.1.1.2.1.1\" style=\"width:113.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A8.T3.1.1.1.2.1.1.1\">Model 1</span> (with image data in pre-training)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.1.1.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.1.1.3.1.1\" style=\"width:113.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A8.T3.1.1.1.3.1.1.1\">Model 2</span> (no image data in pre-training)</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A8.T3.1.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.2.2.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.2.2.1.1.1\" style=\"width:56.9pt;\">VQAv2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A8.T3.1.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.2.2.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.2.2.2.1.1\" style=\"width:113.8pt;\">76.39</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A8.T3.1.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.2.2.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.2.2.3.1.1\" style=\"width:113.8pt;\">74.69</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.3.3.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.3.3.1.1.1\" style=\"width:56.9pt;\">GQA</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.3.3.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.3.3.2.1.1\" style=\"width:113.8pt;\">61.08</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.3.3.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.3.3.3.1.1\" style=\"width:113.8pt;\">60.6</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.4.4.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.4.4.1.1.1\" style=\"width:56.9pt;\">VizWiz</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.4.4.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.4.4.2.1.1\" style=\"width:113.8pt;\">10.88</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.4.4.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.4.4.3.1.1\" style=\"width:113.8pt;\">11.69</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.5.5.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.5.5.1.1.1\" style=\"width:56.9pt;\">TextVQA</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.5.5.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.5.5.2.1.1\" style=\"width:113.8pt;\">0.46828</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.5.5.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.5.5.3.1.1\" style=\"width:113.8pt;\">0.41624</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.6.6.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.6.6.1.1.1\" style=\"width:56.9pt;\">RefCOCO</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.6.6.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.6.6.2.1.1\" style=\"width:113.8pt;\">0.64168</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.6.6.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.6.6.3.1.1\" style=\"width:113.8pt;\">0.58889</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.7.7.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.7.7.1.1.1\" style=\"width:56.9pt;\">OCID</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.7.7.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.7.7.2.1.1\" style=\"width:113.8pt;\">0.46107</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.7.7.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.7.7.3.1.1\" style=\"width:113.8pt;\">0.39696</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A8.T3.1.8.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.8.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.8.8.1.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.8.8.1.1.1\" style=\"width:56.9pt;\">POPE</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A8.T3.1.8.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.8.8.2.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.8.8.2.1.1\" style=\"width:113.8pt;\">0.87478</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A8.T3.1.8.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A8.T3.1.8.8.3.1\">\n<span class=\"ltx_p\" id=\"A8.T3.1.8.8.3.1.1\" style=\"width:113.8pt;\">0.87113</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: Performance of 7B models on various vision-language tasks. We see that model 1 (with images in pre-training) generally outperforms model 2 (no images in pre-training). This supports the findings that we observed in the smaller scale experiments.", "description": "Table 3 presents the performance comparison of two 7B parameter models on various vision-language tasks.  Model 1 incorporates image data during its pre-training phase, while Model 2 does not.  The results show that Model 1, which includes images in pre-training, generally outperforms Model 2 on these tasks. This observation supports the findings from experiments conducted using smaller model sizes, suggesting that the beneficial impact of incorporating image data during pre-training is consistent across different model scales.", "section": "3.3 THE IMPACT OF ADDING IMAGES WHEN TRAINING FROM SCRATCH"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A9.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A9.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A9.T4.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.1.1.1.1\">Checkpoint</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A9.T4.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.1.1.2.1\">Frozen?</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A9.T4.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.1.1.3.1\">Text-Image Ratio</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"A9.T4.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.1.1.4.1\">VQA-v2 score</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A9.T4.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A9.T4.1.2.1.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A9.T4.1.2.1.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A9.T4.1.2.1.3\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A9.T4.1.2.1.4\">58.71</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A9.T4.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.3.2.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.3.2.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.3.2.3\">30%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A9.T4.1.3.2.4\">60.22</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A9.T4.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.4.3.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.4.3.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.4.3.3\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A9.T4.1.4.3.4\">60.85</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A9.T4.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A9.T4.1.5.4.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A9.T4.1.5.4.2\">no</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A9.T4.1.5.4.3\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A9.T4.1.5.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.5.4.4.1\">68.55</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A9.T4.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.6.5.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.6.5.2\">no</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.6.5.3\">30%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A9.T4.1.6.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.6.5.4.1\">69.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A9.T4.1.7.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.7.6.1\">80%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.7.6.2\">no</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A9.T4.1.7.6.3\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A9.T4.1.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A9.T4.1.7.6.4.1\">71.0</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: All results are taken with the mix of DataComp-DR caption data and DCLM text data and fine-tuned on 3 epochs. Across multiple settings, the unfrozen models perform worse in general.", "description": "This table presents ablation study results comparing the performance of vision-language models with frozen versus unfrozen image encoders.  The models were trained using a mix of DataComp-DR caption data and DCLM text data, followed by three epochs of fine-tuning.  The results demonstrate that across various settings and training configurations, models with frozen image encoders consistently outperformed those with unfrozen encoders.", "section": "J.1 EFFECT OF IMAGE DATASET"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A10.T6.fig1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A10.T6.fig1.1.1.1\" style=\"background-color:#D9D9D9;\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.1.1.1.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.1.1.1.1.1\" style=\"width:59.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.1.1.1.1.1.1\">Dataset Mix</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.1.1.2.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.1.1.2.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.1.1.2.1.1.1\">Vision Stable Score</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.1.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.1.1.3.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.1.1.3.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.1.1.3.1.1.1\">Text Stable Score</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A10.T6.fig1.1.2.1\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.2.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.2.1.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.2.1.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.2.1.1.1.1.1\">DataComp</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.2.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.2.1.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.2.1.2.1.1\" style=\"width:42.7pt;\">0.4603</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A10.T6.fig1.1.2.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.2.1.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.2.1.3.1.1\" style=\"width:42.7pt;\">0.1168</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A10.T6.fig1.1.3.2\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A10.T6.fig1.1.3.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.3.2.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.3.2.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.3.2.1.1.1.1\">DataComp-DR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig1.1.3.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.3.2.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.3.2.2.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.3.2.2.1.1.1\">0.4607</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig1.1.3.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.3.2.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.3.2.3.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.3.2.3.1.1.1\">0.1503</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A10.T6.fig1.1.4.3\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A10.T6.fig1.1.4.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.4.3.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.4.3.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.4.3.1.1.1.1\">CC12M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig1.1.4.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.4.3.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.4.3.2.1.1\" style=\"width:42.7pt;\">0.4556</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig1.1.4.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.4.3.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.4.3.3.1.1\" style=\"width:42.7pt;\">0.1298</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A10.T6.fig1.1.5.4\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r\" id=\"A10.T6.fig1.1.5.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.5.4.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.5.4.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig1.1.5.4.1.1.1.1\">ShutterStock</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"A10.T6.fig1.1.5.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.5.4.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.5.4.2.1.1\" style=\"width:42.7pt;\">0.4518</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"A10.T6.fig1.1.5.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig1.1.5.4.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig1.1.5.4.3.1.1\" style=\"width:42.7pt;\">0.1310</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 7: All models above were trained from a 20% checkpoint on a mix of DataComp-DR caption data and DCLM text data.", "description": "This table presents the results of experiments using different random seeds and image ratios during the image-text pre-training phase.  The models were all initialized from a 20% checkpoint of a text-only pre-trained model and further trained using a mixture of DataComp-DR caption data and DCLM text data. The table shows how VQA-v2 scores vary across different random seeds (7 and 365) and image ratios (1%, 5%, 10%) with different numbers of fine-tuning epochs (1 and 2).  This illustrates the impact of these factors on model performance.", "section": "2.1.2 IMAGE-TEXT PRE-TRAINING"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A10.T6.fig2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A10.T6.fig2.1.1.1\" style=\"background-color:#D9D9D9;\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.1.1.1.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.1.1.1.1.1\" style=\"width:59.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.1.1.1.1.1.1\">Image Encoder</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.1.1.2.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.1.1.2.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.1.1.2.1.1.1\">Vision Stable Score</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.1.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.1.1.3.1\" style=\"background-color:#D9D9D9;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.1.1.3.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.1.1.3.1.1.1\">Text Stable Score</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A10.T6.fig2.1.2.1\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.2.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.2.1.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.2.1.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.2.1.1.1.1.1\">SigLIP</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.2.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.2.1.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.2.1.2.1.1\" style=\"width:42.7pt;\">0.4607</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"A10.T6.fig2.1.2.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.2.1.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.2.1.3.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.2.1.3.1.1.1\">0.1503</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A10.T6.fig2.1.3.2\" style=\"background-color:#ECECEC;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A10.T6.fig2.1.3.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.3.2.1.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.3.2.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.3.2.1.1.1.1\">SigLIP + DINO</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig2.1.3.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.3.2.2.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.3.2.2.1.1\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.3.2.2.1.1.1\">0.4696</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A10.T6.fig2.1.3.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.3.2.3.1\" style=\"background-color:#ECECEC;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.3.2.3.1.1\" style=\"width:42.7pt;\">0.1347</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A10.T6.fig2.1.4.3\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r\" id=\"A10.T6.fig2.1.4.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.4.3.1.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.4.3.1.1.1\" style=\"width:59.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A10.T6.fig2.1.4.3.1.1.1.1\">Patch \n<br class=\"ltx_break\"/>Projection</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"A10.T6.fig2.1.4.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.4.3.2.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.4.3.2.1.1\" style=\"width:42.7pt;\">0.1564</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" id=\"A10.T6.fig2.1.4.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A10.T6.fig2.1.4.3.3.1\" style=\"background-color:#FFFFFF;\">\n<span class=\"ltx_p\" id=\"A10.T6.fig2.1.4.3.3.1.1\" style=\"width:42.7pt;\">0.1503</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 8: Benchmark results at different stages of the training process. \"Ours\" is our model trained with 10% image captioning and 90% text before 4 epochs of LLaVA fine-tuning.", "description": "Table 8 presents a comprehensive comparison of benchmark results across various stages of the model training process. It includes results from models trained with different ratios of text and image data, highlighting the impact of incorporating visual information at various stages.  The 'Ours' column specifically showcases the performance of the model trained using the authors' proposed method: 90% text and 10% image caption data in pre-training, followed by four epochs of LLaVA fine-tuning. This allows for a direct comparison of the authors' approach against the baseline and other training variations.", "section": "3 Results"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A11.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A11.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A11.T7.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A11.T7.1.1.1.1.1\">Random Seed</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A11.T7.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A11.T7.1.1.1.2.1\">Image Ratio</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"A11.T7.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A11.T7.1.1.1.3.1\">FT epochs</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"A11.T7.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A11.T7.1.1.1.4.1\">VQA-v2 score</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A11.T7.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A11.T7.1.2.1.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A11.T7.1.2.1.2\">1%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A11.T7.1.2.1.3\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A11.T7.1.2.1.4\">73.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.3.2.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.3.2.2\">1%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.3.2.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.3.2.4\">75.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.4.3.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.4.3.2\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.4.3.3\">1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.4.3.4\">75.36</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.5.4.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.5.4.2\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.5.4.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.5.4.4\">76.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.6.5.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.6.5.2\">10%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.6.5.3\">1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.6.5.4\">75.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.7.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.7.6.1\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.7.6.2\">10%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.7.6.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.7.6.4\">76.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.8.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A11.T7.1.8.7.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A11.T7.1.8.7.2\">1%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A11.T7.1.8.7.3\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A11.T7.1.8.7.4\">74.46</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.9.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.9.8.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.9.8.2\">1%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.9.8.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.9.8.4\">75.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.10.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.10.9.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.10.9.2\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.10.9.3\">1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.10.9.4\">75.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.11.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.11.10.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.11.10.2\">5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.11.10.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.11.10.4\">76.47</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.12.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.12.11.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.12.11.2\">10%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.12.11.3\">1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.12.11.4\">75.55</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A11.T7.1.13.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.13.12.1\">365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.13.12.2\">10%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A11.T7.1.13.12.3\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A11.T7.1.13.12.4\">76.58</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 9: Comparison of evaluation metrics between our model, Prismatic 7B, and PaliGemma 3B. \"Ours\" is our model trained with 10% image captioning and 90% text before 4 epochs of LLaVA fine-tuning.", "description": "Table 9 presents a comparison of the performance of three different Vision-Language Models (VLMs) on a set of benchmark tasks.  The models compared are: the authors' model (trained using a specific recipe described in the paper), Prismatic 7B, and PaliGemma 3B. The authors' model was trained with 10% image caption data and 90% text data, followed by 4 epochs of fine-tuning using the LLaVA dataset. The table shows the performance of these models on several vision and text benchmarks, providing a quantitative comparison of their capabilities.", "section": "N COMPARISON WITH PRIOR SOTA MODELS"}]