{"references": [{"fullname_first_author": "Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper describes improvements that make instruction tuning possible, which is an important component of all of the training pipelines tested in the paper."}, {"fullname_first_author": "Gadre", "paper_title": "Datacomp: In search of the next generation of multimodal datasets", "publication_date": "2024-01-01", "reason": "The work helps source the training data, enabling the model to be exposed to a wide variety of images."}, {"fullname_first_author": "Beyer", "paper_title": "Paligemma: A versatile 3b vlm for transfer", "publication_date": "2024-01-01", "reason": "This paper introduces a strong, and relatively efficient vision-language model with transfer capabilites, which can be leveraged when incorporating images in the pre-training stage."}, {"fullname_first_author": "Hoffmann", "paper_title": "Training compute-optimal large language models", "publication_date": "2022-01-01", "reason": "This papers describes the Chinchilla scaling laws that suggest that the amount of training data should scale linearly with the number of parameters, a theory this paper evaluates."}, {"fullname_first_author": "Karamcheti", "paper_title": "Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models", "publication_date": "2024-02-01", "reason": "The VLMs and codebase for this work provide a foundation for evaluating the vision-language performance of this paper's approach."}]}