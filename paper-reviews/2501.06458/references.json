{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper is foundational for understanding the capabilities of large language models (LLMs) and their potential for few-shot learning, which is directly relevant to the inference-time scaling explored in the current work."}, {"fullname_first_author": "Hanjie Chen", "paper_title": "Benchmarking large language models on answering and explaining challenging medical questions", "publication_date": "2024-00-00", "reason": "This paper provides the benchmarks (JAMA, Medbullets, and MedQA) used in evaluating the performance of LLMs for medical reasoning, forming the empirical foundation of the current study."}, {"fullname_first_author": "Zhen Huang", "paper_title": "O1 replication journey-part 2: Surpassing ol-preview through simple distillation, big progress or bitter lesson?", "publication_date": "2024-00-00", "reason": "This paper represents the previous work by the same research group, providing context for the current study's investigation of inference-time scaling in medical reasoning, part 3 of the O1 replication journey."}, {"fullname_first_author": "Yiwei Qin", "paper_title": "O1 replication journey: A strategic progress report - part 1", "publication_date": "2024-00-00", "reason": "This paper, also part of the series, introduces the O1 replication journey project and establishes the conceptual foundation for the inference-time scaling approach used in the current study."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-00-00", "reason": "This paper introduces the chain-of-thought prompting technique, which is a key method used in the current study for eliciting detailed reasoning processes from the LLMs, thereby enhancing the quality of inference-time outputs."}]}