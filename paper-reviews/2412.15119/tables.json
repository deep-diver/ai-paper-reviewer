[{"content": "| Model | Params | Layers | Hidden | Heads |\n|---|---|---|---|---|\n| PAR-L | 343M | 24 | 1024 | 16 |\n| PAR-XL | 775M | 36 | 1280 | 20 |\n| PAR-XXL | 1.4B | 48 | 1536 | 24 |\n| PAR-3B | 3.1B | 24 | 3200 | 32 |", "caption": "Table 1: Model sizes and architecture configurations of PAR. The configurations are following previous works\u00a0[36, 51, 32, 47].", "description": "This table presents the different model sizes used in the experiments, along with their corresponding architectural configurations.  It shows the number of parameters, the number of layers, the hidden dimension, and the number of attention heads for each model variant (PAR-L, PAR-XL, PAR-XXL, PAR-3B). The architectures build upon prior work, as indicated by the citations, demonstrating consistency in design choices across related studies.", "section": "3.3 Model Architecture Details"}, {"content": "| Type | Model | #Para. | FID\u2193 | IS\u2191 | Precision\u2191 | Recall\u2191 | Steps | Time(s)\u2193 |\n|---|---|---|---|---|---|---|---|---|\n| GAN | BigGAN [3] | 112M | 6.95 | 224.5 | 0.89 | 0.38 | 1 | - |\n|  | GigaGAN [19] | 569M | 3.45 | 225.5 | 0.84 | 0.61 | 1 | - |\n|  | StyleGan-XL [40] | 166M | 2.30 | 265.1 | 0.78 | 0.53 | 1 | 0.08 |\n| Diffusion | ADM [10] | 554M | 10.94 | 101.0 | 0.69 | 0.63 | 250 | 44.68 |\n|  | CDM [16] | - | 4.88 | 158.7 | - | - | 8100 | - |\n|  | LDM-4 [38] | 400M | 3.60 | 247.7 | - | - | 250 | - |\n|  | DiT-XL/2 [34] | 675M | 2.27 | 278.2 | 0.83 | 0.57 | 250 | 11.97 |\n| Mask | MaskGIT [5] | 227M | 6.18 | 182.1 | 0.80 | 0.51 | 8 | 0.13 |\n| VAR | VAR-d30 [49] | 2B | 1.97 | 334.7 | 0.81 | 0.61 | 10 | 0.27 |\n| MAR | MAR [25] | 943M | 1.55 | 303.7 | 0.81 | 0.62 | 64 | 28.24 |\n| AR | VQGAN [11] | 227M | 18.65 | 80.4 | 0.78 | 0.26 | 256 | 5.05 |\n|  | VQGAN [11] | 1.4B | 15.78 | 74.3 | - | - | 256 | 5.05 |\n|  | VQGAN-re [11] | 1.4B | 5.20 | 280.3 | - | - | 256 | 6.38 |\n|  | ViT-VQGAN [64] | 1.7B | 4.17 | 175.1 | - | - | 1024 | >6.38 |\n|  | ViT-VQGAN-re [64] | 1.7B | 3.04 | 227.4 | - | - | 1024 | >6.38 |\n|  | RQTran. [23] | 3.8B | 7.55 | 134.0 | - | - | 256 | 5.58 |\n|  | RQTran.-re [23] | 3.8B | 3.80 | 323.7 | - | - | 256 | 5.58 |\n|  | LlamaGen-L [47] | 343M | 3.07 | 256.1 | 0.83 | 0.52 | 576 | 12.58 |\n|  | LlamaGen-XL [47] | 775M | 2.62 | 244.1 | 0.80 | 0.57 | 576 | 18.66 |\n|  | LlamaGen-XXL [47] | 1.4B | 2.34 | 253.9 | 0.80 | 0.59 | 576 | 24.91 |\n|  | LlamaGen-3B [47] | 3.1B | 2.18 | 263.3 | 0.81 | 0.58 | 576 | 12.41 |\n| AR | PAR-L-4\u00d7 | 343M | 3.76 | 218.9 | 0.84 | 0.50 | 147 | 3.38 |\n|  | PAR-XL-4\u00d7 | 775M | 2.61 | 259.2 | 0.82 | 0.56 | 147 | 4.94 |\n|  | PAR-XXL-4\u00d7 | 1.4B | 2.35 | 263.2 | 0.82 | 0.57 | 147 | 6.84 |\n|  | PAR-3B-4\u00d7 | 3.1B | 2.29 | 255.5 | 0.82 | 0.58 | 147 | 3.46 |\n|  | PAR-XXL-16\u00d7 | 1.4B | 3.02 | 270.6 | 0.81 | 0.56 | 51 | 2.28 |\n|  | PAR-3B-16\u00d7 | 3.1B | 2.88 | 262.5 | 0.82 | 0.56 | 51 | 1.31 |", "caption": "Table 2: Class-conditional image generation on ImageNet 256\u00d7\\times\u00d7256 benchmark.\n\u201c\u2193\u2193\\downarrow\u2193\u201d or \u201c\u2191\u2191\\uparrow\u2191\u201d indicate lower or higher values are better.\n\u201c-re\u201d means using rejection sampling. PAR-4\u00d7\\times\u00d7 and PAR-16\u00d7\\times\u00d7 means generating 4 and 16 tokens per step in parallel, respectively.", "description": "This table presents a quantitative comparison of various class-conditional image generation models on the ImageNet dataset at a resolution of 256x256 pixels.  The models are evaluated across multiple metrics: Fr\u00e9chet Inception Distance (FID), Inception Score (IS), Precision, Recall, the number of generation steps required, and the generation time. Lower FID scores indicate better image quality, while higher IS scores reflect better image diversity and quality.  Precision and Recall measure how well the generated images match the target classes. The number of steps and generation time provide a measure of the computational efficiency of each model.  The table includes both autoregressive (AR) and non-autoregressive models, showing the performance of the proposed method (PAR) in comparison.  The '-re' suffix denotes models that use rejection sampling, while PAR-4x and PAR-16x represent variations of the proposed parallel generation approach that process 4 and 16 tokens per step, respectively.", "section": "4.2.1. Image Generation"}, {"content": "|               | FID\u2193 | IS\u2191 | steps\u2193 |\n| :-----------: | :-: | :-: | :-: |\n| w/o           | 3.67 | 221.36 | 144 |\n| w             | **2.61** | 259.17 | 147 |", "caption": "Table 3: Comparison of class-conditional video generation methods on UCF-101 benchmark.\nFVD measures generation quality, where lower values (\u2193\u2193\\downarrow\u2193) indicate better performance. PAR-1\u00d7\\times\u00d7 represents our token-by-token baseline, while PAR-4\u00d7\\times\u00d7 and PAR-16\u00d7\\times\u00d7 indicate our parallel generation variants with different speedup ratios, achieving competitive FVD scores with significantly reduced generation steps and wall-clock time.", "description": "This table compares the performance of various class-conditional video generation methods on the UCF-101 benchmark dataset. The Fr\u00e9chet Video Distance (FVD) metric is used to evaluate the quality of the generated videos, with lower FVD scores indicating better video generation quality. The table includes results for several state-of-the-art methods as well as the proposed method (PAR) with three different parallelization levels: PAR-1x (token-by-token baseline), PAR-4x (parallel generation with 4-fold speedup), and PAR-16x (parallel generation with 16-fold speedup).  The table shows the number of parameters, FVD scores, number of steps, and generation time for each method.  The results demonstrate that the proposed PAR method, particularly with higher parallelization levels, achieves competitive video generation quality with significantly reduced generation time and steps.", "section": "4.2.2. Video Generation"}, {"content": "| n | FID\u2193 | IS\u2191 | steps\u2193 |\n|---|---|---|---|\n| 1 | **2.34** | 253.90 | 576 |\n| 4 | 2.35 | 263.24 | 147 |\n| 16 | 3.02 | 270.57 | 51 |", "caption": "(a) Importance of initial sequential token generation. Sequential generation of initial tokens improves FID by 1.06 with negligible step increase.", "description": "This table presents an ablation study analyzing the impact of sequentially generating initial tokens before parallel generation in the proposed parallel autoregressive visual generation method.  The study compares the Fr\u00e9chet Inception Distance (FID), Inception Score (IS), and number of steps required for generation with and without the initial sequential generation phase.  The results demonstrate a significant improvement in FID (a lower FID indicates better image quality) when initial tokens are generated sequentially, highlighting the importance of establishing a strong global structure before parallel processing.", "section": "4.3. Ablation Study"}, {"content": "| attn | FID \u2193 | IS \u2191 | steps \u2193 |\n|---|---|---|---|\n| causal | 3.64 | 228.08 | 147 |\n| full | **2.61** | 259.17 | 147 |", "caption": "(b) Number of parallel predicted tokens (PAR-XXL). n=1 is the token-by-token baseline. n=4 reduces steps by 4\u00d7\\times\u00d7 with similar FID (2.35 vs. 2.34), while n=16 reduces steps by 11.3\u00d7\\times\u00d7 at the cost of 0.67 FID.", "description": "This table presents ablation study results on the effect of varying the number of parallel predicted tokens (n) in the PAR-XXL model.  It compares three settings: n=1 (sequential, token-by-token generation serving as the baseline), n=4 (parallel generation of 4 tokens per step), and n=16 (parallel generation of 16 tokens per step). The results show the impact on FID (Fr\u00e9chet Inception Distance, a measure of image quality), IS (Inception Score), and the number of generation steps required.  The key takeaway is that increasing the degree of parallelism (from n=4 to n=16) significantly reduces the number of steps needed for image generation but comes at a small cost in terms of FID (a slight decrease in image quality).", "section": "4. Experiments"}, {"content": "| order | pattern | FID\u2193 | IS\u2191 | steps\u2193 |\n|---|---|---|---|---|\n| raster | one | 2.62 | 244.08 | 576 |\n| distant | one | 2.64 | 262.72 | 576 |\n| raster | multi | 5.64 | 265.46 | 147 |\n| distant | multi | **2.61** | 259.17 | 147 |", "caption": "(c) Attention pattern between parallel tokens. Full attention allows complete context access from previous parallel groups (vs. causal attention\u2019s limited access), bringing 1.03 FID improvement.", "description": "This table investigates the impact of different attention mechanisms on the model's performance when predicting multiple tokens in parallel.  Specifically, it compares using \"full attention\" (where each parallel token has access to the full context from previous groups of parallel tokens) versus \"causal attention\" (where each parallel token only has access to the context from previous tokens in its own group or earlier groups). The results show that full attention leads to a 1.03 point improvement in FID score, indicating that providing complete contextual information is crucial for maintaining accuracy during parallel generation.", "section": "3.3 Model Architecture Details"}, {"content": "| Params | FID \u2193 | IS \u2191 | steps |\n|---|---|---|---| \n| 343M | 3.76 | 218.92 | 147 |\n| 775M | 2.61 | 259.17 | 147 |\n| 1.4B | 2.35 | 263.24 | 147 |\n| 3.1B | **2.29** | 255.46 | 147 |", "caption": "(d) Comparison of different scan orders under single-token and multi-token prediction. Our region-based distant ordering shows similar performance with raster scan in single-token setting, but significantly outperforms in multi-token prediction (2.61 vs. 5.64 FID).", "description": "This table compares the performance of different token ordering strategies for both single-token and multi-token prediction in autoregressive visual generation.  Two scanning methods are compared: a raster scan (processing tokens sequentially from left-to-right, top-to-bottom) and a region-based distant ordering (the approach proposed by the authors, which prioritizes non-adjacent tokens in parallel prediction to leverage weak dependencies).  The results show that both strategies perform comparably for single-token prediction. However, in multi-token prediction, the proposed region-based distant ordering substantially outperforms the raster scan, demonstrating its effectiveness in handling token dependencies during parallel generation. This is measured by FID (Fr\u00e9chet Inception Distance) score, where a lower score indicates better image quality. The region-based distant ordering achieves a FID of 2.61, while the raster scan results in a significantly worse FID score of 5.64.", "section": "3.1 Token Dependencies and Parallel Generation"}, {"content": "| config | value |\n|---|---| \n| **training hyper-params** |  | \n| --- | --- | \n| optimizer | AdamW [28] | \n| learning rate | 1e-4(L,XL)/2e-4(XXL,3B) | \n| weight decay | 5e-2 | \n| optimizer momentum | (0.9, 0.95) | \n| batch size | 256(L,XL)/ 512(XXL,3B) | \n| learning rate schedule | cosine decay | \n| ending learning rate | 0 | \n| total epochs | 300 | \n| warmup epochs | 15 | \n| precision | bfloat16 | \n| max grad norm | 1.0 | \n| dropout rate | 0.1 | \n| attn dropout rate | 0.1 | \n| class label dropout rate | 0.1 | \n| **sampling hyper-params** |  | \n| --- | --- | \n| temperature | 1.0 | \n| guidance scale | 1.60 (L) / 1.50 (XL) / 1.435 (XXL) / 1.345 (3B) | ", "caption": "(e) Scaling of model size (4\u00d7\\times\u00d7 parallel). Generation quality steadily improves with more parameters, from 343M (FID 3.76) to 3.1B (FID 2.29).", "description": "This table presents ablation study results on the impact of model size on image generation quality when using a parallel generation strategy with 4 parallel tokens per step.  It shows that increasing the model size from 343 million parameters to 3.1 billion parameters leads to a consistent improvement in generation quality, as measured by the Fr\u00e9chet Inception Distance (FID).  The FID score decreases from 3.76 to 2.29, indicating a substantial improvement in the visual realism and quality of the generated images.", "section": "4. Experiments"}, {"content": "| config | value |\n|---|---| \n|  ***training hyper-params*** |  | \n| --- | --- | \n| optimizer | AdamW [28] | \n| learning rate | 1e-4 | \n| weight decay | 5e-2 | \n| optimizer momentum | (0.9, 0.95) | \n| batch size | 256 | \n| learning rate schedule | cosine decay | \n| ending learning rate | 0 | \n| total epochs | 3000 | \n| warmup epochs | 150 | \n| precision | bfloat16 | \n| max grad norm | 1.0 | \n| dropout rate | 0.1 | \n| attn dropout rate | 0.1 | \n| class label dropout rate | 0.1 | \n| ***sampling hyper-params*** |  | \n| --- | --- | \n| temperature | 1.0 | \n| guidance scale | 1.15 | \n| top-k | 8000 | \n|  |  | ", "caption": "Table 4: Ablation studies on image generation model designs.", "description": "This table presents the results of ablation studies conducted to analyze the impact of different design choices on the image generation model.  Specifically, it investigates the importance of sequential initial token generation, the number of parallel predicted tokens, the attention mechanism used between parallel tokens, and the token ordering strategy employed.  The impact of each design choice on the FID (Fr\u00e9chet Inception Distance), IS (Inception Score), and the number of generation steps is quantified and compared.", "section": "4. Experiments"}]