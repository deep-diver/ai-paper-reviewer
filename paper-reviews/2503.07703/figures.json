[{"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/seedream_2.0_pdf/overall_cn_en.png", "caption": "Figure 1: Seedream2.0 demonstrates outstanding performance across all evaluation aspects in both English and Chinese.", "description": "This figure presents a radar chart comparing Seedream 2.0's performance against other leading image generation models (Midjourney v6.1, FLUX1.1 Pro, GPT-40, Ideogram 2.0) across multiple evaluation metrics.  These metrics assess various aspects of image quality, including aesthetics, text accuracy, structural correctness, and prompt following ability. Separate charts are shown for evaluations using English prompts and Chinese prompts, showcasing Seedream 2.0's bilingual capabilities. Seedream 2.0 consistently outperforms or is competitive with the other models in all categories, demonstrating its superior performance in both languages.", "section": "Model Performance"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/teaser_final.png", "caption": "Figure 2: Seedream 2.0 Visualization.", "description": "Figure 2 is a collage of images generated by Seedream 2.0, showcasing the model's capabilities in generating diverse image styles, including illustrations, realistic photos, and culturally-specific scenes. It demonstrates the model's ability to understand and respond to various prompts in both English and Chinese. The collage highlights the wide range of applications Seedream 2.0 can support.", "section": "Data Pre-Processing"}, {"figure_path": "https://arxiv.org/html/2503.07703/x1.png", "caption": "Figure 3: Pre-training data system.", "description": "This figure illustrates the system used for creating the pre-training dataset for Seedream 2.0.  It shows four main components of the dataset: High-Quality Data (data with exceptionally high image quality and rich knowledge content), Distribution Maintenance Data (maintains useful distribution while reducing low-quality data through downsampling and clustering), Knowledge Injection Data (adds data with specific Chinese cultural contexts), and Supplementary Data (addresses areas of model weakness through active learning). The figure depicts the flow of data through these components and illustrates the steps involved in creating a balanced and comprehensive dataset for training.", "section": "2 Data Pre-Processing"}, {"figure_path": "https://arxiv.org/html/2503.07703/x2.png", "caption": "Figure 4: Overview of our knowledge injection process.", "description": "This figure illustrates the process of incorporating external knowledge into the pre-training dataset.  It begins with uncurated data that undergoes deduplication and retrieval steps. The embedding step generates representations of data from a taxonomy, allowing the system to add knowledge-rich pairs to the dataset. Finally, the augmented and curated data is used in the pre-training process.", "section": "2.1 Data Composition"}, {"figure_path": "https://arxiv.org/html/2503.07703/x3.png", "caption": "Figure 5: Overview of our data cleaning process.", "description": "This figure illustrates the multi-stage data cleaning process employed to ensure high quality and relevance of the dataset used in the Seedream 2.0 model training.  The process starts with uncurated data and proceeds through three stages. Stage 1 involves a general quality assessment based on criteria such as image clarity, presence of watermarks or logos, and overall meaningfulness of content.  Images failing to meet the standards are removed. Stage 2 performs detailed quality assessments using methods like feature embedding extraction, deduplication and hierarchical clustering to refine data distribution and eliminate lower-quality samples. Finally, Stage 3 involves captioning and re-captioning images, providing richer descriptions for higher-level data and ensuring consistency.", "section": "2.2 Data Cleaning Process"}, {"figure_path": "https://arxiv.org/html/2503.07703/x4.png", "caption": "Figure 6: Flow diagram of Active Learning Lifecycle.", "description": "The figure illustrates the iterative process of active learning used in the data pre-processing stage. It starts with labeling a small subset of the unlabeled image data.  A classifier is trained using this labeled data. Then, the classifier is used to select the most uncertain or informative samples from the remaining unlabeled data. These selected samples are then labeled by human annotators, adding to the labeled dataset. This cycle of classifier training and sample selection repeats until a satisfactory level of data quality is achieved or a specified number of iterations are completed.", "section": "2.3 Active Learning Engine"}, {"figure_path": "https://arxiv.org/html/2503.07703/x5.png", "caption": "Figure 7: Caption examples in our training data.", "description": "Figure 7 shows several examples of image captions used in the training data for the Seedream 2.0 model.  These examples showcase the different types of captions that were created, including short generic captions that briefly summarize the main content of an image, longer generic captions that provide more detailed and descriptive information, artistic captions that focus on stylistic elements and visual characteristics, textual captions that focus on any text present in the image, and surreal captions that describe the image from a more imaginative and fantastical perspective. The variety in the captions reflects the model's training on diverse descriptions, enhancing the model's ability to generate images with rich and varied textual content.", "section": "2.4 Image Captioning"}, {"figure_path": "https://arxiv.org/html/2503.07703/x6.png", "caption": "Figure 8: Text Rendering: Data Pre-processing Pipeline.", "description": "This figure illustrates the data pre-processing pipeline used for text rendering in the Seedream 2.0 model.  The pipeline begins with an image source and filters out low-quality data.  Then, Optical Character Recognition (OCR) is used to detect and extract text regions, followed by filtering out low-quality text boxes.  A re-captioning model is then used to generate high-quality descriptions for the remaining text regions. Finally, these descriptions are paired with the corresponding images to create a high-quality dataset for training the model's text rendering capabilities.", "section": "2.5 Text Rendering Data"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/pipeline.png", "caption": "Figure 9: Overview of Seedream 2.0 Training and Inference Pipeline.", "description": "This figure illustrates the overall architecture of the Seedream 2.0 model, detailing the training and inference pipelines.  The training pipeline shows the sequential stages: pre-training, continued training (CT), supervised fine-tuning (SFT), and human feedback alignment (RLHF). Each stage utilizes specific data and training strategies to refine the model's capabilities. The inference stage demonstrates how a user prompt is processed, involving prompt engineering and use of a text encoder and a base diffusion model (DIT), before producing the final image output.  The refiner module is also shown, handling post-processing steps to optimize the final image. This comprehensive view highlights the multi-stage approach towards achieving high-quality image generation.", "section": "Model Pre-Training"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/arch.png", "caption": "Figure 10: Overview of Model Architecture.", "description": "Figure 10 presents a detailed overview of the Seedream 2.0 model architecture.  It illustrates the flow of data processing from input image and text to final image generation. Key components highlighted include the Variational Autoencoder (VAE) for image encoding, the Glyph-Aligned ByT5 and LLM for text encoding, the Diffusion Transformer with its MMDiT blocks, and the Scaled ROPE for positional encoding. The figure shows how these components interact to generate high-fidelity images, including the use of AdaLN and modulation techniques within the transformer blocks.  The figure also highlights the character-level text encoding using Glyph-ByT5.", "section": "Model Pre-Training"}, {"figure_path": "https://arxiv.org/html/2503.07703/x7.png", "caption": "Figure 11: Visualization during different post-training stages.", "description": "This figure visualizes the intermediate results of Seedream 2.0 during different post-training stages: Supervised Fine-Tuning (SFT), Human Feedback Alignment (RLHF), Prompt Engineering (PE), and Refiner.  Each row shows the results for a different image prompt, demonstrating how the image quality and adherence to the prompt improves through each training phase.  The prompts are written in both English and Chinese. The progression showcases improvements in aesthetics, detail, and overall coherence of the generated images. ", "section": "Model Post-Training"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/Reward.png", "caption": "Figure 12: The reward curves show that the values across diverse reward models all exhibit a stable and consistent upward trend throughout the alignment process. Some visualization examples reveal that the human feedback alignment stage is crucial.", "description": "This figure displays reward curves for three reward models (Image-Text Alignment, Text Render, and Aesthetics) during the RLHF (Reinforcement Learning from Human Feedback) process.  Each curve shows a consistent upward trend, indicating that the models continuously improve their performance across multiple iterations of training.  The visualization examples below the graphs showcase the impact of the RLHF stage. The images show that the quality of image generation is significantly enhanced through RLHF.", "section": "4.3 Human Feedback Alignment (RLHF)"}, {"figure_path": "https://arxiv.org/html/2503.07703/x8.png", "caption": "Figure 13: PE Visualization. We provide 4 PE prompts for each original prompt.", "description": "This figure visualizes the results of prompt engineering (PE).  For each original prompt used to generate an image, four different rephrased prompts (created by the PE model) are shown, along with the images generated from each. This demonstrates how PE refines prompts to improve image generation quality. The variations in the prompts highlight the model's ability to enhance specificity and detail, leading to better alignment with the desired output.", "section": "4.4 Prompt Engineering (PE)"}, {"figure_path": "https://arxiv.org/html/2503.07703/x9.png", "caption": "Figure 14: Refiner Visualization. Recommend to zoom in for the best visualization.", "description": "This figure visualizes the Refiner model's impact on image resolution and quality.  The Refiner model takes a 512x512 resolution image as input and upscales it to 1024x1024 resolution.  The zoomed-in view showcases improvements in detail, texture, and overall image quality resulting from the Refiner model, particularly with details such as human faces that were previously unclear or blurry.  The enhanced clarity and detail demonstrate the Refiner's ability to produce higher-resolution images without sacrificing visual fidelity.", "section": "4.5 Refiner"}, {"figure_path": "https://arxiv.org/html/2503.07703/x10.png", "caption": "Figure 15: Quantitative ablation of SeedEdit. Left: GPT score v.s. CLIP image similarity. Right: GPT score v.s. AdaFace similarity.", "description": "This figure shows the results of an ablation study on the SeedEdit model, which is an instruction-based image editing model. The left panel shows the relationship between the GPT score (a measure of overall image quality) and the CLIP image similarity score (a measure of how similar the edited image is to the original image, according to the CLIP model).  The right panel shows the relationship between the GPT score and the AdaFace similarity score (a measure of how well the edited image preserves the identity of the human faces). The study shows that both multi-expert data fusion and face-aware loss are important factors that contribute to improve the ability of the model to preserve human facial identity when making edits. ", "section": "Align to Instruction-Based Image Editing"}, {"figure_path": "https://arxiv.org/html/2503.07703/x11.png", "caption": "Figure 16: Qualitative comparison of SeedEdit revision. We show here that current approach significantly enhances ID retention.", "description": "This figure presents a qualitative comparison of the SeedEdit model revisions.  It demonstrates how the improvements (Multi-Expert, FaceLoss/Data Optimization, and Refiner) cumulatively enhance the retention of human facial identity (ID) in edited images. The before-and-after results are displayed for several image editing tasks, illustrating that the updated methods significantly reduce the loss or distortion of facial features during the editing process. The improved ID preservation is a key improvement in the SeedEdit model, critical for numerous applications.", "section": "Align to Instruction-Based Image Editing"}, {"figure_path": "https://arxiv.org/html/2503.07703/x12.png", "caption": "Figure 17: Human Evaluation Results.", "description": "This figure presents the results of human evaluations comparing Seedream 2.0 to other text-to-image models.  Evaluations focus on three key aspects: text-image alignment, structural correctness, and aesthetic quality.  A professional evaluation and an ELO-based score (reflecting public preference) are presented for each model. The graph showcases the comparative performance of each model across these dimensions, highlighting Seedream 2.0's overall superiority.", "section": "7.1 Human Evaluation"}, {"figure_path": "https://arxiv.org/html/2503.07703/x13.png", "caption": "Figure 18: EvalMuse Evaluation Results across fine-grained dimensions.", "description": "This radar chart visualizes the performance of Seedream 2.0 and other leading text-to-image models across various fine-grained aspects as evaluated by EvalMuse.  Each axis represents a specific attribute of image generation quality, such as \"overall\", \"object\", \"activity\", \"attribute\", \"spatial\", \"location\", \"food\", \"animal/human\", \"color\", \"material\", \"counting\", and \"other\".  The further a model's point extends outwards on an axis, the better its performance in that specific dimension.  This allows for a detailed comparison of the strengths and weaknesses of each model across various aspects of image quality, beyond simpler, overall metrics.", "section": "7.2 Automatic Evaluation"}, {"figure_path": "https://arxiv.org/html/2503.07703/x14.png", "caption": "Figure 19: Text Rendering Evaluation.", "description": "This figure presents a comparison of text rendering capabilities between Seedream 2.0 and other state-of-the-art text-to-image models in both English and Chinese.  It displays the availability rate, text accuracy rate, and text hit rate for each model.  The availability rate represents the percentage of successfully rendered images judged as acceptable based on overall text rendering quality and integration with other image content. Text accuracy reflects how accurately the generated text matches the prompt, and the hit rate indicates the proportion of correctly rendered characters.  The results demonstrate Seedream 2.0's superior performance in text rendering, particularly in the more challenging domain of Chinese text.", "section": "7 Model Performance"}, {"figure_path": "https://arxiv.org/html/2503.07703/x15.png", "caption": "Figure 20: Chinese Characteristics Evaluation.", "description": "This figure presents the results of an evaluation assessing Seedream 2.0's ability to generate images reflecting Chinese cultural characteristics.  Two metrics were used:  'Response Score', indicating how accurately the generated images depicted the requested elements from the prompt, and 'Chinese Aesthetics Score', measuring how well the image's aesthetic style aligned with typical Chinese artistic sensibilities.  The figure compares Seedream 2.0's performance to several other models on a set of prompts designed to test the understanding of Chinese cultural nuances.", "section": "7.4 Chinese Characteristics"}, {"figure_path": "https://arxiv.org/html/2503.07703/x16.png", "caption": "Figure 21: Response Rate of Chinese Characteristics across Dimensions.", "description": "This radar chart visualizes the percentage of correctly identified Chinese characteristics across various dimensions in images generated by Seedream 2.0 and other models.  Each dimension represents a specific aspect of Chinese culture (e.g., architecture, food, festivals, etc.). The further a point extends from the center, the higher the percentage of correct identification.  The chart allows for a comparison of Seedream 2.0's performance against competing models, highlighting its strengths and weaknesses in representing different cultural elements.", "section": "7.4 Chinese Characteristics"}, {"figure_path": "https://arxiv.org/html/2503.07703/x17.png", "caption": "Figure 22: Chinese Characteristics Comparisons. Our model demonstrates a more accurate understanding and expression of Chinese elements.", "description": "This figure presents a comparative analysis of how different text-to-image models render images based on prompts related to Chinese cultural elements.  It shows that Seedream 2.0 outperforms other models in accurately capturing and expressing the nuances of these elements, such as clothing, food, and architectural styles. The images visually demonstrate Seedream 2.0's superior understanding and representation of Chinese cultural details.", "section": "7.4 Chinese Characteristics"}, {"figure_path": "https://arxiv.org/html/2503.07703/x18.png", "caption": "Figure 23: Alignment Comparisons. Seedream and Ideogram 2.0 excel in these two prompts, while other models either struggle with imaginative scenarios or misinterpret quantity and position in the prompts below.", "description": "This figure compares the performance of several text-to-image models on two image generation prompts.  The first prompt involves generating an image of a teacup-shaped cloud, while the second requires generating an image of two green boxes on a table and two red balls underneath it. The results reveal that Seedream 2.0 and Ideogram 2.0 perform exceptionally well in correctly generating the objects and their spatial relationships as described in both prompts. In contrast, other models such as Midjourney v6.1, FLUX1.1 Pro, and GPT-40 either struggle to generate images matching the creative and imaginative aspects of the first prompt or misinterpret the number and placement of objects in the second prompt.", "section": "Model Performance"}, {"figure_path": "https://arxiv.org/html/2503.07703/x19.png", "caption": "Figure 24: Structure comparisons. External models encounter issues with the distortion of fingers and limbs under complex movements.", "description": "This figure compares the structural accuracy of different image generation models when depicting complex poses.  It highlights how Seedream 2.0 outperforms other models in maintaining realistic proportions and avoiding distortions in limbs and fingers, particularly in dynamic or challenging poses. The other models struggle to accurately represent the structural integrity of the subject, resulting in unnatural or unrealistic imagery.  This demonstrates the superior structural correctness of Seedream 2.0.", "section": "7 Model Performance"}, {"figure_path": "https://arxiv.org/html/2503.07703/x20.png", "caption": "Figure 25: Aesthetics comparisons. Seedream demonstrates outstanding performance in cinematic scenes and artistic design, while other models show weaker performance in artistic style and texture details.", "description": "Figure 25 presents a comparison of different text-to-image models' performance on generating images with cinematic and artistic styles. The prompt used was complex, incorporating multiple stylistic and thematic elements (e.g., specific photography styles, color schemes, and atmospheric elements).  Seedream 2.0 is shown to produce images closely matching the prompt's specifications, with high-quality textures and detailed rendering of visual elements. In contrast, other models such as Ideogram 2.0, Midjourney v6.1, FLUX1.1 Pro, and GPT-4.0, demonstrate varied degrees of failure to capture the nuanced artistic and cinematic aspects specified in the prompt, resulting in lower-quality images and less accurate stylistic representation.", "section": "7 Model Performance"}, {"figure_path": "https://arxiv.org/html/2503.07703/x21.png", "caption": "Figure 26: Text-Rendering Comparisons. Seedream performs exceptionally well in harmonizing text with content and demonstrates strong typesetting capabilities. Notably, it offers a distinct understanding of scenarios with Chinese characteristics.", "description": "Figure 26 showcases a comparison of text rendering capabilities across different models.  Seedream excels by seamlessly integrating text within the image content, showcasing sophisticated typesetting skills.  This is particularly evident in its handling of scenarios involving Chinese characters and cultural elements, where it displays a superior comprehension and nuanced representation compared to other models.", "section": "7.3 Text Rendering"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/text_example.jpeg", "caption": "Figure 27: Text Rendering by Seedream. Our model presents infinite potential in poster design and artistic creation.", "description": "Figure 27 showcases Seedream's text rendering capabilities in various artistic and design contexts.  It demonstrates the model's ability to seamlessly integrate text into diverse creative scenarios, ranging from simple illustrations and posters to more complex compositions.  The collage presents several examples highlighting the model's flexibility in handling different text styles, fonts, and arrangements while maintaining visual coherence. This illustrates Seedream's potential for applications beyond text-to-image generation, extending its utility to fields like graphic design, advertising, and artistic expression.", "section": "7.4 Chinese Characteristics"}, {"figure_path": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/seedream_2.0_pdf/compress_char_show_case.jpeg", "caption": "Figure 28: Chinese Characteristics by Seedream. Our model presents impressive representation of Chinese aesthetics.", "description": "Figure 28 is a collage showcasing the model's ability to generate images reflecting various aspects of Chinese aesthetics.  It includes a diverse range of subjects, from traditional architecture (such as pagodas) and cultural symbols (like pandas) to depictions of mythical creatures (dragons) and figures from Chinese opera. The image demonstrates the model's capacity for detailed rendering, stylistic variation, and culturally sensitive representation.", "section": "7.5 Visualization"}]