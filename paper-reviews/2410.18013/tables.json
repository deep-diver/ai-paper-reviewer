[{"figure_path": "2410.18013/tables/table_7_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of different models' performance on the GenEval benchmark, highlighting the improvement achieved by RankDPO on several key categories.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_7_1.html", "caption": "Table 2: Quantitative Results on T2I-CompBench. RankDPO provides consistent improvements on all categories for both SDXL and SD3-Medium.", "description": "Table 2 presents a quantitative comparison of the performance of SDXL and SD3-Medium models on the T2I-CompBench benchmark, before and after applying RankDPO, showing consistent improvements across various attributes.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_8_0.html", "caption": "Table 3: Quantitative results on DPG-Bench. DSG (Cho et al., 2024) and VQAScore (Lin et al., 2024) measure prompt following using VQA models while Q-Align (Wu et al., 2024a) measures visual quality using multimodal LLMs.", "description": "Table 3 presents a quantitative comparison of different models' performance on the DPG-Bench benchmark, evaluating both prompt alignment and visual quality.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_8_1.html", "caption": "Table 4: Effect of the preference labelling and data quality on the final model.", "description": "The table presents the effect of different preference labelling methods and data quality on the final model's performance, measured by prompt alignment and visual quality scores.", "section": "4.2 Ablation Analysis"}, {"figure_path": "2410.18013/tables/table_8_2.html", "caption": "Table 3: Quantitative results on DPG-Bench. DSG (Cho et al., 2024) and VQAScore (Lin et al., 2024) measure prompt following using VQA models while Q-Align (Wu et al., 2024a) measures visual quality using multimodal LLMs.", "description": "Table 3 presents a quantitative comparison of different methods on the DPG-Bench benchmark, evaluating prompt alignment and visual quality using various metrics.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_9_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of different models' performance on the GenEval benchmark, highlighting the improvements achieved by RankDPO.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_11_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of the performance of different models on the GenEval benchmark, showing improvements achieved by the proposed RankDPO method.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_15_0.html", "caption": "Table 6: Comparison of T2I-Compbench Dataset with DPG-Bench, including model attributes, training time, and inference time increases.", "description": "Table 6 compares the performance of different models on T2I-Compbench and DPG-Bench datasets, showing model attributes, training time, training data size, and inference time.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_15_1.html", "caption": "Table 7: Comparing features of our proposal against baselines that aim to improve T2I model quality post-training. ELLA* also replaces the CLIP text-encoders with T5-XL text-encoder and a 470M parameter adapter applied at each timestep, thereby increasing the inference cost.", "description": "Table 7 compares the training data size, training time, inference cost, and downstream performance of different preference optimization methods for improving text-to-image models.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_16_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of different models on the GenEval benchmark, showing the improvement achieved by RankDPO on various image generation attributes.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_17_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of different models' performance on the GenEval benchmark, highlighting the improvements achieved by RankDPO.", "section": "4.1 Comparison Results"}, {"figure_path": "2410.18013/tables/table_18_0.html", "caption": "Table 1: Quantitative Results on GenEval. RankDPO improves results on most categories, notably \"two objects\", \"counting\", and \"color attribution\" for SDXL and SD3-Medium.", "description": "Table 1 presents a quantitative comparison of different models' performance on the GenEval benchmark, highlighting the improvements achieved by RankDPO on several key categories.", "section": "4.1 Comparison Results"}]