[{"figure_path": "https://arxiv.org/html/2503.11646/x1.png", "caption": "Figure 1: Comparative Analysis of the Real-Data Collection Loop in Robotic Manipulation. (a) Traditional Approach: A tele-operator executes tasks via fixed linguistic instructions in static visual environments.\n(b) Adversarial Data Collection\u00a0(ADC) Framework: Employs a Two-Humans-in-the-Loop approach, where a secondary operator intervenes to perturb the primary\u2019s execution dynamically when the tele-operator is executing a task.\n(c) ADC Loop: The adversarial operator introduces visual (backgrounds, object positions/poses) and linguistic (task goals) perturbations, shifting environmental context and target objects within a single episode.", "description": "Figure 1 illustrates three approaches to collecting real-world data for robotic imitation learning.  (a) shows the traditional method, where a single human teleoperates the robot to perform a task based on a fixed instruction in a static environment.  (b) introduces the Adversarial Data Collection (ADC) framework which utilizes two humans: one teleoperates the robot, while the other introduces dynamic perturbations during task execution. (c) details the ADC loop, highlighting how the adversarial operator introduces visual and linguistic changes to the environment and instructions, forcing the teleoperator to adapt and creating a much more information-dense demonstration.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2503.11646/x2.png", "caption": "Figure 2: The overview of ADC. During training data collection, we introduce several adversarial perturbations, including dynamic visual perturbations and adaptive linguistic challenges. These perturbations increase information density, expand state space coverage, and provide more complete observations of target objects. The resulting high-quality dataset enables the trained policy model to achieve strong robustness and generalization, outperforming models trained with conventional data collection strategies.", "description": "Figure 2 illustrates the Adversarial Data Collection (ADC) process.  It contrasts traditional data collection methods with ADC's human-in-the-loop approach.  Traditional methods passively record robot actions while ADC actively introduces dynamic visual (e.g., changing object positions, backgrounds) and linguistic (e.g., changing task instructions mid-episode) perturbations to increase data diversity. This process results in a dataset with higher information density, allowing for models trained on fewer samples to achieve better robustness and generalization on unseen tasks compared to models trained using traditional methods. The figure also visually represents how information density, coverage and completeness of observations are improved via ADC.", "section": "III. APPROACH"}, {"figure_path": "https://arxiv.org/html/2503.11646/x3.png", "caption": "Figure 3: Hardware setup used in ADC for both data collection and evaluation experiments. The Aloha robot is employed for conventional robotic policy experiments, which include various visual distractors. The AgiBot G1 robot is utilized for the VLA policy experiments, where different dynamic perturbations are applied.", "description": "This figure shows the hardware setups used in the Adversarial Data Collection (ADC) experiments.  Two robots are shown: the Aloha robot, used for conventional robotic policy experiments with various visual distractors to test robustness, and the AgiBot G1 robot, used for Vision-Language-Action (VLA) policy experiments which involved more complex and dynamic perturbations. This illustrates the different experimental conditions used to compare ADC with traditional methods.", "section": "C. ADC in Conventional Robotic Policy"}, {"figure_path": "https://arxiv.org/html/2503.11646/x4.png", "caption": "Figure 4: Comparison of attention maps when one camera is masked. Models trained with ADC focus more precisely on functional cameras, demonstrating superior attention concentration compared to models trained with traditional data collection pipelines.", "description": "This figure compares attention maps of models trained on data collected using the Adversarial Data Collection (ADC) method versus a traditional method.  Both models have one of their cameras masked. The attention maps show where the model focuses its attention when processing visual input. The ADC-trained model demonstrates a stronger ability to focus on the functional cameras (those that still provide useful information) even with a camera masked, highlighting its superior robustness and attention mechanism. In contrast, the traditionally-trained model shows less precise attention, paying attention to irrelevant features like table edges rather than the target object.", "section": "IV. RESULTS AND ANALYSIS"}, {"figure_path": "https://arxiv.org/html/2503.11646/x5.png", "caption": "Figure 5: Comparison of observation coverage for the task \u201dGrasp the orange.\u201d In the traditional data collection process, the target object (orange) is observed from similar viewpoints, resulting in limited visual diversity. In contrast, ADC introduces dynamic perturbations, allowing the orange to be observed from a wider range of viewpoints. This leads to greater visual variation in the ADC dataset, improving model robustness and generalization.", "description": "Figure 5 compares the visual observation coverage of the \"Grasp the orange\" task between traditional data collection and the proposed Adversarial Data Collection (ADC) method.  Traditional methods yield images of the orange from very similar viewpoints, limiting the diversity of visual data.  In contrast, ADC uses dynamic perturbations to change the orange's position and orientation during the task. This results in a much wider variety of viewpoints being captured in the dataset. This increased visual diversity from ADC is crucial for building more robust and generalizable robotic models. The improved generalization is because the models trained on the varied viewpoints from ADC can better adapt to new or unseen scenarios.", "section": "IV. RESULTS AND ANALYSIS"}, {"figure_path": "https://arxiv.org/html/2503.11646/x6.png", "caption": "Figure 6: Dynamic Human-Robot Interaction (HRI) scenarios. The robot is tasked with grasping the target fruit from the human hand, where the human\u2019s hand may move during the manipulation tasks. Evaluation experiments are conducted across different scenes.", "description": "Figure 6 showcases the dynamic human-robot interaction (HRI) scenarios used to test the robot's ability to grasp a moving object.  A human hand holds the fruit (the target object), and the human moves their hand during the grasping process, making the task significantly more challenging. The experiment was repeated across various scenes to further test the model's robustness.", "section": "IV. RESULTS AND ANALYSIS"}, {"figure_path": "https://arxiv.org/html/2503.11646/x7.png", "caption": "Figure 7: Autonomous Failure Recovery in ADC-Trained Robotic Grasping: Real-time demonstration of failure recovery after empty grasp. Following initial contact loss during peach acquisition, the system autonomously recalibrates grip pose parameters and executes a precision-aligned regrasp to complete the task.", "description": "This figure shows a real-time demonstration of an autonomous failure recovery mechanism in a robot performing a grasping task. The robot initially attempts to grasp a peach but loses contact. It then automatically adjusts its grip parameters, performs a precise regrasp, and successfully completes the task. This demonstrates the robustness and adaptability of the robot's control system, which has been trained using the Adversarial Data Collection (ADC) method.", "section": "IV. RESULTS AND ANALYSIS"}]