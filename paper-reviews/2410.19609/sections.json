[{"page_end_idx": 2, "page_start_idx": 1, "section_number": 1, "section_title": "Introduction", "details": {"details": "This section introduces the challenge of developing autonomous agents for complex real-world tasks like web navigation, highlighting limitations of existing approaches.  Current methods often rely on closed-source models or operate in synthetic environments with clearly defined reward signals, hindering generalization to real-world scenarios. The authors point to the need for multimodal perception and the lack of ground truth in realistic settings.  This necessitates building agents that can iteratively explore, receive feedback, and optimize their performance in the real world.  Open-source frameworks are needed to further this development, allowing for the iterative improvement of multimodal web agents.", "first_cons": "Existing approaches often rely on closed-source models or operate in simplified synthetic environments which prevents generalization to real-world complexities.", "first_pros": "Recent advancements in large language and multimodal models offer the potential to develop agents capable of real-world web navigation. ", "keypoints": ["Challenge: Building autonomous agents for complex real-world web navigation.", "Limitations of current methods: reliance on closed-source models and synthetic environments.", "Need for multimodal perception and iterative improvement in real-world settings.", "Proposed solution: Open-source framework for multimodal web agents via iterative real-world exploration, feedback, and optimization."], "second_cons": "Current open-source efforts focus on text-only agents in synthetic environments, lacking the complexity and nuanced feedback of real-world interaction.", "second_pros": "Open-source multimodal agents offer the possibility of broader accessibility and community-driven improvements, surpassing limitations of proprietary solutions.", "summary": "The paper introduces the challenge of building autonomous agents for complex real-world web navigation and highlights the limitations of existing approaches, emphasizing the need for an open-source framework that enables iterative exploration, feedback, and optimization to overcome these challenges."}}, {"page_end_idx": 3, "page_start_idx": 3, "section_number": 3, "section_title": "Method", "details": {"details": "This section introduces OpenWebVoyager, a novel framework for building multimodal web agents.  It starts with **Imitation Learning (IL)**, where the agent learns from high-quality trajectories generated by a strong multimodal agent (WebVoyager-40).  Then, it iteratively refines the agent's policy through **exploration-feedback-optimization cycles**. In each cycle, the agent explores the web, collects trajectories, and receives feedback from GPT-40, focusing only on successful trajectories for training. This iterative process leads to continuous improvement in agent performance. The framework uses **Idefics2-8b-instruct** as the backbone multimodal model and addresses limitations of previous approaches by utilizing real-world web environments and leveraging GPT-40 for both trajectory generation during IL and quality control during iterative refinement, overcoming challenges posed by undefined reward signals and complex real-world scenarios.  The method introduces difficulty-guided sampling to improve performance on challenging websites.", "first_cons": "Relying heavily on GPT-40 for both imitation learning and iterative feedback might be expensive and limit scalability.", "first_pros": "The iterative optimization framework allows for continuous agent improvement in real-world settings. It leverages GPT-40 effectively and addresses limitations of using text-only agents in synthetic environments.", "keypoints": ["**Imitation Learning (IL)** phase to learn initial web navigation skills.", "**Iterative exploration-feedback-optimization cycles** for continuous improvement.", "Use of **GPT-40** for both trajectory generation and feedback.", "Employing **Idefics2-8b-instruct** as the backbone model.", "Addressing challenges of undefined reward signals and complex real-world scenarios.", "**Difficulty-guided sampling** to handle challenging websites"], "second_cons": "The approach is limited to common web actions (click, type, scroll), excluding more complex interactions.  The dependence on a large language model for feedback might introduce biases and limitations.", "second_pros": "The framework is open-source and allows for the development of multimodal agents capable of performing complex real-world tasks.", "summary": "OpenWebVoyager builds multimodal web agents via iterative real-world exploration, feedback from GPT-40, and policy optimization using Idefics2-8b-instruct, overcoming limitations of previous methods."}}, {"page_end_idx": 5, "page_start_idx": 4, "section_number": 3, "section_title": "Web Task Queries Collection", "details": {"details": "The process of collecting web task queries for both the imitation learning phase and the iterative optimization cycles is detailed.  For the imitation learning phase, **48 popular websites** are selected and **queries are synthesized from multiple perspectives** to ensure diversity and difficulty variation.  For the iterative optimization cycles, a self-instruct method is used to generate **new queries similar but not duplicated from previous cycles**, aiming for continuous improvement and exploration.  The approach emphasizes generating diverse and challenging tasks while utilizing the strengths of existing data sets and methods for data augmentation.", "first_cons": "Reliance on GPT-40 for generating initial and evaluating trajectories introduces a significant cost and dependence on external resources.", "first_pros": "The method focuses on creating a diverse set of queries for the imitation learning phase by selecting popular websites and synthesizing queries from various viewpoints, which helps train a robust and generalizable model.", "keypoints": ["48 popular websites are selected for the imitation learning phase queries.", "Queries are synthesized from multiple perspectives to ensure task diversity and difficulty.", "Self-instruct method used for iterative optimization cycles generates new, non-duplicated queries.", "The process aims for continuous improvement and exploration through diverse, challenging tasks.", "Existing datasets (WebVoyager, Mind2Web) and methods are leveraged to enhance the query set and improve the agent's performance in real-world settings"], "second_cons": "The success of the self-instruct method depends on the quality of the initial queries and the model's ability to generate relevant and diverse follow-up tasks. Potential issues could include query redundancy or bias.", "second_pros": "The iterative optimization cycle facilitates continuous improvement and exploration. The approach is scalable, ensuring the agent consistently faces new challenges that enable ongoing development.", "summary": "This section describes the detailed methodology for collecting web task queries, focusing on diversity, difficulty, and continuous improvement through both initial data collection and iterative query generation using a combination of curated datasets and self-instruction methods."}}, {"page_end_idx": 5, "page_start_idx": 4, "section_number": 3, "section_title": "Imitation Learning", "details": {"details": "The imitation learning phase in OpenWebVoyager focuses on training the agent with trajectories from a strong multimodal agent, WebVoyager-40, which has already successfully completed various web navigation tasks.  This initial training equips the agent with fundamental skills in web navigation before it begins real-world exploration and self-improvement. Trajectories are carefully filtered to include only those which are \"finished and successful\",  thus ensuring high-quality training data.  The model uses Idefics2-8b-instruct, an open-source large multimodal model, handling screenshots and accessibility trees as input, to learn from these successful trajectories.  A key element is the handling of image and accessibility tree data, where the accessibility tree is truncated to manage sequence length while preserving essential context information.  The entire process aims to provide a solid foundation for subsequent exploration phases.", "first_cons": "The reliance on a closed-source model (WebVoyager-40) for generating the initial trajectories might limit the reproducibility and generalizability of the approach.", "first_pros": "Leveraging a pre-trained strong agent's trajectories allows for efficient acquisition of foundational web navigation skills, leading to a faster start for the exploration and improvement phases.", "keypoints": ["Uses trajectories from a pre-trained strong agent (WebVoyager-40) for efficient initial training.", "Focuses on \"finished and successful\" trajectories to ensure high-quality training data.", "Employs Idefics2-8b-instruct, an open-source LMM, for training.", "Handles both image and accessibility tree data, addressing sequence length challenges.", "Provides a solid foundation for the subsequent exploration phases.", "Careful filtering and data handling are key to success"], "second_cons": "The reliance on GPT-40 for trajectory evaluation and filtering might introduce biases or limitations.", "second_pros": "The careful filtering of trajectories helps ensure the quality of the training data, which leads to better performance in later stages.", "summary": "OpenWebVoyager's imitation learning phase efficiently trains the agent using high-quality trajectories from a powerful pre-trained agent, enabling it to quickly acquire essential web navigation skills before embarking on real-world exploration."}}, {"page_end_idx": 5, "page_start_idx": 5, "section_number": 3, "section_title": "Iterative Optimization", "details": {"details": "After the initial imitation learning phase, the agent enters iterative optimization cycles.  Each cycle involves generating new web tasks using self-instruct, the agent explores the web, and GPT-40 provides feedback on the agent's trajectories.  Successful trajectories are retained and used to further refine the agent's policy model (\u03c0\u03b8j). This cycle continues for several iterations, aiming to improve the agent's performance across various datasets.  A difficulty-guided sampling (DGS) strategy is explored to address the uneven performance on different websites.  The DGS strategy involves selectively increasing the number of sampled trajectories for difficult websites during the exploration phase, either using trajectories from GPT-40 or the agent itself.  Experimental results demonstrate a gradual improvement in task success rates across iterations, particularly on websites seen during training. Generalization to unseen websites shows some improvement but remains unstable due to sampling randomness.  The average length of trajectories tends to decrease over iterations as the agent learns to complete tasks more efficiently, while the finish rate remains high, but success rate at the first try remains relatively low, suggesting room for improving the efficiency of the agent's exploration and decision-making.", "first_cons": "Generalization to unseen websites is unstable due to sampling randomness.", "first_pros": "Gradual performance improvement across multiple iterations, particularly on seen websites.", "keypoints": ["Iterative exploration-feedback-optimization refines the agent's policy model.", "Difficulty-guided sampling improves performance on challenging websites.", "Trajectory length decreases as the agent becomes more efficient.", "Generalization to unseen websites shows improvement but remains unstable.", "Finish rate remains high, but initial success rate is low, suggesting room for improvement in exploration and decision-making"], "second_cons": "The average length of trajectories decreases, potentially impacting thorough exploration and leading to hallucinated answers.", "second_pros": "The difficulty-guided sampling strategy effectively addresses uneven performance across websites.", "summary": "The OpenWebVoyager agent iteratively improves its web navigation skills through cycles of exploration, feedback from GPT-40, and model optimization, showing improvement but with limitations in generalization and occasional hallucination."}}, {"page_end_idx": 8, "page_start_idx": 5, "section_number": 4, "section_title": "Experiment", "details": {"details": "The experiment section evaluates the OpenWebVoyager agent's performance across three datasets: WebVoyager, Mind2Web cross-task, and Mind2Web cross-website.  The results show improvement in task success rate across all datasets after each iteration of exploration-feedback-optimization, particularly on the seen datasets (WebVoyager and Mind2Web cross-task). The Mind2Web cross-website dataset, representing unseen websites, shows less dramatic but still positive improvement, highlighting the agent's ability to generalize to some extent.  A difficulty-guided sampling strategy is explored to address the agent's struggle with particularly challenging websites, yielding mixed results.  The average trajectory length decreases across iterations, suggesting the agent becomes more efficient with each cycle, though this might be associated with a rise in hallucinated answers. The experiment also analyzes the frequency of the agent using the 'restart' action.", "first_cons": "Difficulty-guided sampling shows mixed results; improvement on unseen websites is less prominent.", "first_pros": "Consistent performance improvement across iterations on seen websites; some generalization to unseen websites; shorter trajectory length.", "keypoints": ["**Improved performance** across iterations on WebVoyager & Mind2Web cross-task datasets.", "**Generalization ability** demonstrated on Mind2Web cross-website (unseen websites).", "**Difficulty-guided sampling** shows mixed success; more robust strategies needed.", "Decreasing trajectory length indicates efficiency gains, but also may correlate with hallucination increase."], "second_cons": "Decreasing trajectory length may indicate a rise in hallucinated answers, negatively impacting accuracy.", "second_pros": "The experiment utilizes multiple datasets for comprehensive evaluation, examining both seen and unseen websites for performance assessment.", "summary": "OpenWebVoyager demonstrates iterative improvement on web navigation tasks, generalizing to some unseen websites but struggling with difficult ones, suggesting potential improvements through refined sampling strategies."}}, {"page_end_idx": 8, "page_start_idx": 8, "section_number": 4, "section_title": "Main Results", "details": {"details": "Throughout the imitation learning and iterative optimization, four models were trained and evaluated: OpenWebVoyagerIL, OpenWebVoyageriter-1, OpenWebVoyageriter-2, and OpenWebVoyageriter-3.  The results show a general improvement in task success rates on the WebVoyager test set and Mind2Web cross-task test set as optimization progressed.  However, performance on the Mind2Web cross-website (unseen) test set was less stable and showed less improvement, indicating that the agent struggles with unseen websites and sampling randomness. Difficulty-guided sampling (DGS) strategies were explored by adding trajectories, which enhanced performance in some cases but also led to instability.  The average length of trajectories decreased across optimization cycles.  Finally, there was a discussion about the limitations of the agent, including the use of only basic web actions, limited model parameter size, and hallucination issues.", "first_cons": "Performance on the Mind2Web cross-website test set (unseen websites) was less stable and showed less improvement than on seen websites. This suggests that the agent struggles with generalizing to completely new and unseen websites. ", "first_pros": "Generally improved performance on the WebVoyager and Mind2Web cross-task test sets after iterative optimization.  The agent showed increased success rates as it learned and adapted across multiple iterations, demonstrating the effectiveness of the iterative optimization method. ", "keypoints": ["Generally improved performance on seen datasets, but less improvement on unseen datasets.", "Decreasing trajectory lengths over iterations, indicating improved efficiency.", "Exploration of difficulty-guided sampling to address performance inconsistencies.", "Limitations: Basic web actions, model size, and hallucination issues"], "second_cons": "Difficulty-guided sampling strategies, while showing some enhancement, also led to some instability and inconsistent performance improvements across different websites.  The agent's performance wasn't uniformly improved across all websites, indicating a need for more robust generalization.", "second_pros": "The iterative optimization cycle showed a general increase in performance across most datasets, particularly those seen during training.  The method demonstrated improved efficiency in task completion, as indicated by the decreasing average length of trajectories. ", "summary": "Iterative optimization of a multimodal web agent improved performance on seen datasets but showed less consistent gains on unseen data, highlighting challenges with generalization and sampling randomness."}}, {"page_end_idx": 8, "page_start_idx": 8, "section_number": 4, "section_title": "Discussion", "details": {"details": "The average trajectory length decreased during iterative optimization, indicating the agent's increasing efficiency in solving familiar tasks. However, this decrease was accompanied by an increase in hallucination, suggesting a trade-off between efficiency and accuracy.  Difficulty-guided sampling (DGS) improved performance on some websites, but the improvement wasn't stable due to sampling randomness, and adding GPT-40-sampled trajectories yielded better results compared to those from the agent itself.  The use of the search engine also increased during optimization, implying that the search engine is more efficient at solving some problems than navigation alone.", "first_cons": "Increased hallucination with shorter trajectory lengths, leading to inaccurate answers.", "first_pros": "Decreased average trajectory length demonstrates improved efficiency in familiar tasks.", "keypoints": ["Shorter trajectories improve efficiency but increase hallucination.", "Difficulty-guided sampling (DGS) shows mixed results.", "Using search engines becomes more prevalent during optimization.", "Trade-off between efficiency and accuracy needs to be considered."], "second_cons": "Inconsistent improvement with difficulty-guided sampling due to sampling randomness.", "second_pros": "Improved performance with difficulty-guided sampling using GPT-40 sampled trajectories.", "summary": "Iterative optimization improved efficiency, but also increased hallucination, highlighting a trade-off between speed and accuracy; difficulty-guided sampling showed mixed results, with GPT-40-sourced trajectories performing better, and search engine usage increased, indicating a shift in problem-solving strategies."}}, {"page_end_idx": 9, "page_start_idx": 9, "section_number": 5, "section_title": "Limitations", "details": {"details": "The limitations section discusses several constraints of the proposed OpenWebVoyager model.  Firstly, it points out the model's limited action capabilities, encompassing only basic web interactions like clicking, typing, and scrolling. This restricted action space hinders its ability to effectively handle more complex web scenarios.  Secondly, the model's reliance on a relatively smaller language model (8B parameters) impacts its performance, especially on unseen domains or complex tasks. This limitation could result in suboptimal navigation and inefficient query responses. Finally, the over-reliance on accessibility trees for visual understanding instead of direct image processing affects the model's performance, particularly in scenarios demanding fine-grained visual reasoning.  The authors acknowledge these limitations and suggest future improvements, such as expanding the action space, utilizing larger language models, and enhancing image processing capabilities.", "first_cons": "**Limited action capabilities**: Only basic web interactions (clicking, typing, scrolling) are supported, hindering performance on complex scenarios.", "first_pros": "The authors acknowledge the limitations and suggest future improvements.", "keypoints": ["Limited action set (only basic web interactions)", "Smaller language model (8B parameters) restricts performance on unseen domains and complex tasks", "Over-reliance on accessibility trees for visual understanding impacts performance in scenarios requiring fine-grained visual reasoning"], "second_cons": "**Smaller language model**: The use of an 8B parameter model limits the agent's ability to effectively handle unseen web domains and complex tasks, leading to suboptimal navigation and less efficient query responses.", "second_pros": "The limitations section provides valuable insights into the model's current constraints and potential future directions.", "summary": "OpenWebVoyager's limitations include a restricted action set, a smaller language model limiting its capabilities, and over-reliance on accessibility trees for visual understanding, hindering performance on complex tasks and unseen domains."}}, {"page_end_idx": 9, "page_start_idx": 9, "section_number": 6, "section_title": "Ethics Statement", "details": {"details": "The ethics statement emphasizes the responsible conduct of online web navigation experiments.  **Human supervision and GPT-4 monitoring ensured adherence to ethical guidelines, avoiding violations and protecting user privacy.**  Experiments focused on information-seeking tasks, excluding actions involving sensitive personal data or financial transactions. The slow sampling frequency minimized any potential negative impact on the websites.", "first_cons": "The ethical considerations are limited to the specific actions performed during the experiments.", "first_pros": "The research emphasizes the importance of ethical guidelines and responsible practices.", "keypoints": ["Ethical guidelines strictly followed during experiments.", "Human supervision and GPT-4 monitoring ensured responsible conduct.", "Focus on information-seeking tasks, excluding sensitive data.", "Slow sampling frequency minimized website impact."], "second_cons": "The statement does not address potential biases or unintended consequences.", "second_pros": "The research team actively considered and addressed various ethical concerns.", "summary": "The research team prioritized ethical considerations in their online web navigation experiments, implementing measures to ensure responsible conduct, privacy protection, and minimal website disruption."}}]