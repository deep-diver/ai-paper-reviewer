[{"page_end_idx": 1, "page_start_idx": 1, "section_number": 1, "section_title": "Introduction", "details": {"details": "Current open-source approaches for building web agents often utilize text-only agents within synthetic environments, limiting their ability to generalize to complex, real-world scenarios that demand multimodal perception.  These methods also often rely on clearly defined reward signals, which are not always present in real-world tasks.  The existing methods are limited by their reliance on synthetic environments and lack of multimodal capabilities, hindering their ability to effectively interact with and navigate the complexities of real-world websites.  This paper aims to address these limitations by introducing an open-source framework that facilitates the creation of multimodal web agents that can learn from iterative real-world exploration and feedback.", "first_cons": "Existing open-source methods focus on text-only agents in synthetic environments, lacking the complexity and multimodal nature of real-world web navigation.", "first_pros": "The proposed framework uses open-source models, enabling wider accessibility and community contributions.", "keypoints": ["Focuses on multimodal web agents for real-world scenarios.", "Addresses limitations of existing text-only agents in synthetic environments.", "Employs iterative real-world exploration, feedback, and optimization.", "Utilizes an open-source framework for accessibility and collaboration.", "Aims to improve agent performance through iterative cycles of learning and adaptation."], "second_cons": "Real-world environments lack clearly defined reward signals, posing a challenge for agent training.", "second_pros": "The iterative exploration-feedback-optimization cycle allows the agent to continuously adapt and improve performance.", "summary": "This paper addresses limitations of current open-source web agents by proposing a new framework that builds multimodal agents capable of iterative real-world learning through exploration, feedback, and optimization."}}, {"page_end_idx": 4, "page_start_idx": 2, "section_number": 2, "section_title": "Method", "details": {"details": "OpenWebVoyager iteratively optimizes a multimodal web agent using a two-stage process.  First, **imitation learning** trains the agent on successful trajectories from a strong model (WebVoyager-40). Then, an **exploration-feedback-optimization** cycle refines the agent.  The agent explores the web, GPT-40 evaluates trajectories, and successful ones enhance the model.  This cycle repeats for several iterations, progressively improving performance across multiple test sets. The framework uses **Idefics2-8b-instruct** as the backbone model and incorporates **accessibility tree** and **screenshot** information into the observation space, addressing limitations of text-only agents in synthetic environments.", "first_cons": "Relying heavily on GPT-40 for both training and evaluation creates a dependency and cost.", "first_pros": "Leveraging GPT-40's capabilities significantly boosts initial performance and feedback quality.", "keypoints": ["Two-stage process: Imitation Learning followed by iterative exploration, feedback, and optimization.", "Multimodal approach: Uses both visual (screenshots) and textual (accessibility trees) information.", "Open-source: Employs an open-source backbone model (Idefics2-8b-instruct).", "Iterative improvement: Continuously refines the agent's policy through feedback loops.", "Real-world setting: Operates within a real-world web environment, increasing generalizability and applicability"], "second_cons": "The reliance on GPT-40 introduces a cost and potential bottleneck.  The system's success depends on the quality of GPT-40's evaluations and feedback.", "second_pros": "The iterative refinement approach addresses the limitations of training purely on synthetic data. The multimodal design better reflects the complexities of real-world web navigation.", "summary": "OpenWebVoyager is an open-source framework that builds a high-performing multimodal web agent through imitation learning and iterative exploration, feedback, and optimization cycles using GPT-40 for both training and evaluation."}}, {"page_end_idx": 7, "page_start_idx": 4, "section_number": 3, "section_title": "Experiment", "details": {"details": "The experiment section evaluates the performance of OpenWebVoyager across three datasets: WebVoyager, Mind2Web cross-task, and Mind2Web cross-website.  The results show improvements in task success rates across all datasets after each iteration of the exploration-feedback-optimization cycle.  The Mind2Web cross-website dataset, which contains unseen websites, shows less improvement but still indicates some generalization ability.  Additionally, a difficulty-guided sampling strategy is explored to address the instability in performance observed on certain websites.  The average trajectory lengths are analyzed showing that successful trajectories tend to get shorter as the training progresses.", "first_cons": "The improvement on the Mind2Web cross-website dataset (unseen websites) is less prominent than on the other two datasets.", "first_pros": "The model demonstrates improvement in task success rates across all datasets after each exploration-feedback-optimization cycle, showcasing its ability to learn and adapt.", "keypoints": ["**Improved performance** across all datasets after each optimization cycle.", "**Mind2Web cross-website** dataset shows less improvement, highlighting generalization challenges.", "**Difficulty-guided sampling** is explored to mitigate instability in performance.", "Analysis of **average trajectory length** reveals a trend of shortening successful trajectories during training.", "Results suggest a tradeoff between exploration and exploitation"], "second_cons": "Difficulty-guided sampling, while showing some improvement, does not consistently enhance performance across all websites.", "second_pros": "The study provides a comprehensive evaluation across multiple datasets and analyses trajectory lengths, offering insights into the learning process and the model's ability to generalize.", "summary": "OpenWebVoyager shows improved performance on web navigation tasks across various datasets after iterative exploration and optimization, but generalization to unseen websites remains a challenge."}}, {"page_end_idx": 10, "page_start_idx": 8, "section_number": 4, "section_title": "Discussion", "details": {"details": "The model's performance improves across iterations, demonstrating the effectiveness of the iterative optimization approach on seen websites.  However, generalization to unseen websites is unstable due to sampling randomness and the agent's tendency to get stuck during navigation.  The decrease in average trajectory length during later iterations might be due to the agent's increased tendency to hallucinate answers instead of fully navigating, impacting overall success rate.  Strategies like difficulty-guided sampling (DGS) were explored to address the unstable performance on unseen websites, showing some promise but ultimately not fully resolving the issue.  The study shows that the initial finish rates are high, but the success rates are relatively low, suggesting further refinement is needed to balance exploration and accuracy.", "first_cons": "Generalization to unseen websites is unstable due to sampling randomness and the agent getting stuck during navigation.", "first_pros": "The model's performance improves across iterations, demonstrating the effectiveness of iterative optimization on seen websites.", "keypoints": ["Improved performance on seen websites, highlighting iterative optimization's effectiveness.", "Unstable generalization to unseen websites due to sampling randomness and navigation issues.", "Decreased trajectory length in later iterations, possibly due to increased hallucination.", "Difficulty-guided sampling (DGS) explored to address the issue of unstable performance on unseen websites, showing some promise but no complete solution.", "High initial finish rates but low success rates indicating a need to balance exploration and accuracy in future work."], "second_cons": "Decreased trajectory length in later iterations potentially stems from increased hallucination, negatively affecting overall success rate.", "second_pros": "Difficulty-guided sampling (DGS) shows promise in mitigating unstable performance on unseen websites.", "summary": "Iterative optimization improves web agent performance on familiar websites but struggles with generalization to unseen websites due to randomness and hallucination."}}]