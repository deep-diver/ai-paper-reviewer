[{"figure_path": "2410.19609/tables/table_6_0.html", "caption": "Table 1: Task success rate on WebVoyager test set (643 queries). All websites are seen during training. 'IL', 'iter-1', 'iter-2', and 'iter-3' represent agents after IL, 1st, 2nd, and 3rd optimization, respectively. 'dgs' and 'dgs-g' denote difficulty-guided sampling, i.e., sample more trajectories for webs with low sampling accuracy, the former by adding trajectories sampled by the agent itself and the latter by adding trajectories sampled by GPT-40.", "description": "Table 1 presents the task success rates of different agents (trained with various optimization strategies) on the WebVoyager test set, showing the impact of iterative optimization and difficulty-guided sampling.", "section": "4.1 Dataset and Metric"}, {"figure_path": "2410.19609/tables/table_6_1.html", "caption": "Table 2: Task success rate on Mind2Web cross-task and cross-web test set. In cross-task set, the queries from the same websites are seen during training. In cross-website set, the websites are not seen during training but still belong to the Entertainment, Shopping, and Travel Domain.", "description": "Table 2 presents the task success rate on Mind2Web cross-task and cross-web test sets, showing the performance of different agents on unseen tasks and websites.", "section": "4.1 Dataset and Metric"}, {"figure_path": "2410.19609/tables/table_8_0.html", "caption": "Table 3: Details of query set and trajectory set during the exploration-feedback-optimization cycle. The feedback on task success or not is provided by GPT-40. F@1 indicates the finish rate of the first exploration. S@K represents the task success rate within K explorations. Each task will sample the trajectory up to 5 times until it succeeds or fails all 5 times, successful trajectories will be retained to improve our agent.", "description": "Table 3 presents the details of the query sets and trajectories generated during each exploration-feedback-optimization cycle, including the number of queries, trajectories, successful trajectories, and the task success rate at various stages (F@1, S@1-S@5).", "section": "4.3 Main Results"}, {"figure_path": "2410.19609/tables/table_8_1.html", "caption": "Table 4: The average length of trajectories across different optimization cycles on various test sets. 'Finish' and 'Success' indicates that we calculate the average length for finished or successful trajectories, respectively.", "description": "Table 4 presents the average length of trajectories across different optimization cycles on various test sets, distinguishing between finished and successful trajectories.", "section": "4.3 Main Results"}, {"figure_path": "2410.19609/tables/table_8_2.html", "caption": "Table 5: The frequency of the agent using the restart action: Let R denote the number of trajectories with restart, RS the number of successful trajectories with restart, and S the total number of successful trajectories.", "description": "Table 5 shows the frequency of the agent using the restart action during the experiment and the success rate of using this action.", "section": "4.4 Discussion"}, {"figure_path": "2410.19609/tables/table_8_3.html", "caption": "Table 6: Study on whether to use a mixture of data from previous phases in exploration-feedback-optimization cycle (OpenWebVoyageriter-1 \u2192 OpenWebVoyageriter-2).", "description": "Table 6 shows the result of the experiment that compares the performance of using a mixture of data from previous phases in exploration-feedback-optimization cycles versus only using data from the current phase.", "section": "4.3 Main Results"}, {"figure_path": "2410.19609/tables/table_13_0.html", "caption": "Table 1: Task success rate on WebVoyager test set (643 queries). All websites are seen during training. \u2018IL\u2019, \u2018iter-1\u2019, \u2018iter-2\u2019, and \u2018iter-3\u2019 represent agents after IL, 1st, 2nd, and 3rd optimization, respectively. \u2018dgs\u2019 and \u2018dgs-g\u2019 denote difficulty-guided sampling, i.e., sample more trajectories for webs with low sampling accuracy, the former by adding trajectories sampled by the agent itself and the latter by adding trajectories sampled by GPT-40.", "description": "Table 1 presents the task success rate of different agents on the WebVoyager test set, showcasing the performance improvement after iterative optimization and the impact of different sampling strategies.", "section": "4.1 Dataset and Metric"}, {"figure_path": "2410.19609/tables/table_13_1.html", "caption": "Table 8: In the Imitation Learning and exploration-feedback-optimization cycles, a total of 48 websites are selected, including 15 from WebVoyager and 37 from Mind2Web (4 duplicates).", "description": "Table 8 lists the 48 websites used in the imitation learning and exploration-feedback-optimization phases of the OpenWebVoyager model, specifying their domains and subdomains.", "section": "4.2 Experimental Details"}, {"figure_path": "2410.19609/tables/table_14_0.html", "caption": "Table 9: Detailed statistics of the test dataset. Websites from WebVoyager and Mind2Web cross-task have been seen during training, while websites from Mind2Web cross-websites have not been encountered.", "description": "Table 9 presents detailed statistics of the test datasets used in evaluating the performance of the proposed OpenWebVoyager model, including the number of queries, whether the websites were seen during training, and domain and subdomain breakdowns.", "section": "4.1 Dataset and Metric"}]