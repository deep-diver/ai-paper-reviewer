[{"figure_path": "https://arxiv.org/html/2411.14793/x2.png", "caption": "Figure 1: Our method learns style templates from reference images, capturing elements including color schemes, layouts, illumination, and brushstrokes. For each image, we fine-tune diffusion models using the reference image in the red insert box to generate the output. We show a \u2018fluffy baby sloth with a knitted hat trying to figure out a laptop\u2019 in different meme templates: a meme with the words \u2018you just activated my trap card\u2019 (top left), a multi-panel comic layout (bottom left), and a two-panel meme (top middle). On the right side, we display typographies in the styles of a wooden sculpture and a minimal line drawing. We also present a \u2018singing kangaroo drinking beer\u2019 in various artistic styles\u2014flat illustration, crayon drawing, watercolor, and line drawing.", "description": "This figure demonstrates the Style-friendly SNR Sampler's ability to generate images in various artistic styles by fine-tuning diffusion models with reference images.  The top row shows examples of generating a 'fluffy baby sloth with a knitted hat trying to figure out a laptop' in three different meme formats. The bottom row shows a 'singing kangaroo drinking beer' rendered in four distinct artistic styles (flat illustration, crayon, watercolor, and line drawing).  The rightmost column displays the same phrase rendered in two distinct typographic styles (wooden sculpture and minimal line drawing). The red boxes within each image highlight the reference images used for style transfer. This showcases the model's capability to learn and apply diverse style templates from relatively few examples.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.14793/x3.png", "caption": "Figure 2: Fine-tuning capability. While FLUX succeeds in learning objects (a), it struggles to capture styles (b). We enable FLUX to learn styles (c). References are shown in the red insert box.", "description": "This figure demonstrates the ability of different models to learn and apply styles during fine-tuning.  In (a), the FLUX model successfully learns object characteristics, resulting in a correctly generated image of the object in a new context. (b) shows that the same model fails to accurately capture the stylistic elements of the reference image (red box), leading to a generated image that lacks the desired artistic style.  In (c), the authors' proposed method successfully learns and applies the stylistic features of the reference image (red box), highlighting the effectiveness of their approach.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.14793/x4.png", "caption": "Figure 3: Prompt switching during generation. \u03bbtsubscript\ud835\udf06\ud835\udc61\\lambda_{t}italic_\u03bb start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT indicates log-SNR. The style prompts are \u2018minimalist flat round logo\u2019, \u2018sticker\u2019, \u2018detailed pen and ink drawing\u2019, and \u2018abstract rainbow colored flowing smoke wave\u2019. Styles emerge in the initial 10% of denoising steps; therefore, (c) and (d) fail to capture target styles. Here, we use FLUX, with the guidance scale 7 across the whole denoising process.", "description": "This figure demonstrates the impact of incorporating style prompts at different stages of the image generation process using diffusion models.  Four variations are shown: (a) consistently applies the style prompt throughout the generation; (b) applies the style prompt only after the initial 10% of denoising steps, when log-SNR (\u03bb\u209c) values indicate higher noise levels; (c) applies the style prompt only in a range of log-SNR values corresponding to when style features start to emerge; and (d) does not apply the style prompt at all. The experiment uses the FLUX model with a guidance scale of 7. The results show that style information is primarily learned during the initial 10% of denoising, explaining why (c) and (d) fail to accurately generate the target styles. Different style prompts were used to showcase the effect across various stylistic choices.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.14793/x5.png", "caption": "Figure 4: Probability distribution of Log-SNR. Colored region indicates style-emerging noise levels discussed in Sec.\u00a03.1.", "description": "This figure displays the probability distribution of the log-SNR (logarithm of the signal-to-noise ratio) used during the training of diffusion models. The x-axis represents the log-SNR values, and the y-axis represents the probability density. Different colored curves show the distributions for different mean values of log-SNR, while maintaining the standard deviation constant.  The colored region highlights the log-SNR range where stylistic features of generated images are observed to emerge, as discussed in Section 3.1 of the paper.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.14793/x6.png", "caption": "Figure 5: Effect of varying \u03bc\ud835\udf07\\muitalic_\u03bc. Diffusion models start to capture the reference glowing style when \u03bc\ud835\udf07\\muitalic_\u03bc is lower than \u221244-4- 4. The target prompt is \u2018A Christmas tree in glowing style\u2019.", "description": "This figure demonstrates how varying the mean (\u03bc) of the log-SNR distribution during training affects the ability of diffusion models to capture and generate specific styles.  As the mean (\u03bc) decreases (becomes more negative), moving the distribution towards higher noise levels, the model increasingly captures the reference \"glowing\" style in the generated Christmas tree images.  When \u03bc is -4 or higher, the glowing style is not well captured, demonstrating that lower \u03bc values are essential for learning this particular style effectively. The experiment highlights the importance of carefully tuning the log-SNR distribution for optimal style-driven generation.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2411.14793/x7.png", "caption": "(a) Varying \u03bc\ud835\udf07\\muitalic_\u03bc.", "description": "The figure shows the effect of varying the mean (\u00b5) of the log-SNR distribution used during the fine-tuning process of diffusion models. Different values of \u00b5 bias the noise level distribution towards different noise levels. Lower values of \u00b5 focus more on higher noise levels, where stylistic features tend to emerge, resulting in better style capture and generation. The plot shows the DINO similarity scores, a measure of style alignment, for different values of \u00b5 for both FLUX and SD3.5 diffusion models. The results show that lower values of \u00b5 lead to higher DINO similarity scores, indicating better style alignment.", "section": "4. Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x8.png", "caption": "(b) Varying \u03c3\ud835\udf0e\\sigmaitalic_\u03c3.", "description": "This figure shows the results of an ablation study on the standard deviation (\u03c3) of the log-SNR sampling distribution used in the Style-friendly SNR sampler.  It demonstrates how the variation in \u03c3 impacts the DINO similarity score of generated images when compared to images generated using FLUX and SD3.5. Different values of \u03c3 were tested to show how this hyperparameter influences style alignment during fine-tuning.", "section": "4.1. Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x9.png", "caption": "(c) Varying LoRA Rank", "description": "This figure shows the result of an ablation study on the impact of LoRA rank on style learning.  It demonstrates how the model's ability to capture and reproduce stylistic features changes as the dimensionality of the LoRA adapters is varied. This is done by measuring DINO similarity. The x-axis represents different LoRA ranks, while the y-axis shows the DINO similarity score.  The figure helps to determine the optimal LoRA rank for balancing model capacity and stylistic accuracy in style-driven generation.", "section": "4.1 Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x10.png", "caption": "Figure 6: SNR sampler analysis. DINO similarities of varying SNR sampler parameters with FLUX and SD3.5-8B. Dotted lines in (c) indicate results of SD3 sampler\u00a0[8]. Unless specified, we use \u03bc=\u22126\ud835\udf076\\mu=-6italic_\u03bc = - 6, \u03c3=2\ud835\udf0e2\\sigma=2italic_\u03c3 = 2, and rank 32. CLIP scores are shown in Fig.\u00a0S7.", "description": "This figure analyzes the performance of the Style-friendly SNR sampler by varying its parameters (\u03bc, \u03c3, and LoRA rank) and comparing its results with those of the standard SD3 sampler and FLUX. The DINO similarity metric is used to evaluate the style alignment for each configuration. The dotted lines in (c) represent the results obtained using the SD3 sampler as a baseline. Unless specified, the Style-friendly sampler was configured with \u03bc = -6, \u03c3 = 2, and a LoRA rank of 32. The figure also references Figure S7 for corresponding CLIP scores, providing a more comprehensive analysis of the sampler's effectiveness.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2411.14793/x11.png", "caption": "Figure 7: Qualitative comparison. All samples are generated with the same seed. Please zoom in.", "description": "Figure 7 displays a qualitative comparison of various style-based image generation methods.  Each row represents a different approach (Style-friendly, SD3 sampler, DCO, IP-Adapter, RB-Modulation, and Style-Aligned), and each column depicts a different style prompt applied to the same base image. This allows for visual comparison of how well each method captures the stylistic elements (color schemes, layout, illumination, brushstrokes) from the reference image (shown in the first row). The fact that all samples share the same seed emphasizes the effect of the method itself on style generation rather than randomness.", "section": "4.2. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x12.png", "caption": "Figure 8: Multi-panel and typography. First row demonstrates generating multiple coherent images as a single image. Second row shows customized typography with a unique style.", "description": "Figure 8 showcases the model's ability to generate multiple coherent images within a single image, as demonstrated in the first row.  The example shows a multi-panel comic strip. The second row illustrates the model's capacity for generating customized typography with unique styles, showcasing different font styles and designs.", "section": "4.4. Applications"}, {"figure_path": "https://arxiv.org/html/2411.14793/x13.png", "caption": "Figure S1: Additional samples. Each row shows images generated with the same random seed at a resolution of 1216\u00d7832, using the prompts \u201ca cute city made of sushi in {style prompt} style\u201d and \u201cmischievous ferret with a playful grin squeezes itself into a large glass jar, in {style prompt} style\u201d.", "description": "This figure displays generated images demonstrating the model's ability to adapt to various artistic styles. Two sets of prompts were used: \"a cute city made of sushi in {style prompt} style\" and \"mischievous ferret with a playful grin squeezes itself into a large glass jar, in {style prompt} style\".  Each row showcases images generated from the same random seed but with different style prompts substituted into the bracketed section. This highlights the model's capacity to maintain image consistency while changing its stylistic features based on the input style prompt. The resolution of each image is 1216x832 pixels.", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x14.png", "caption": "Figure S2: Typography. The first column shows reference images. The second and third columns display samples generated at a resolution of 832\u00d71216, and the fourth column presents samples at 704\u00d71408 resolution. The prompts used are \u201cthe words that says \u2018{letters}\u2019 are written in English, in {style prompt} style\u201d, where \u2018{letters}\u2019 represents the words synthesized in the samples.", "description": "This figure demonstrates the model's ability to generate stylized text.  The first column shows example reference images showcasing different artistic styles. The second and third columns present text generated by the model in those styles at a resolution of 832x1216 pixels, while the fourth column shows text generated at 704x1408 pixels. The model was prompted with the phrase:  \"the words that say '{letters}' are written in English, in {style prompt} style\", where '{letters}' represents the specific words to be generated and '{style prompt}' specifies the desired artistic style (e.g., \"minimalist flat round logo\", \"sticker\", \"detailed pen and ink drawing\", \"abstract rainbow colored flowing smoke wave\").", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x15.png", "caption": "Figure S3: Additional qualitative comparison. Our Style-friendly approach successfully captures complex multi-panel styles, generating images that closely resemble the reference. The prompts used are \u201cA fluffy baby sloth with a knitted hat trying to figure out a laptop, close up in {style prompt} style\u201d, \u201cA banana in {style prompt} style\u201d, \u201cA Christmas tree in {style prompt} style\u201d, and \u201cA bench in {style prompt} style\u201d.", "description": "Figure S3 presents a qualitative comparison of different image generation methods on multi-panel comic style images.  The Style-friendly approach is shown to generate images that closely match the reference style, while other methods struggle to replicate the complex style elements. The comparison includes four different image prompts: a close-up of a sloth with a hat using a laptop, a banana, a Christmas tree, and a park bench. Each prompt was applied to various image generation methods, demonstrating the superior performance of the Style-friendly approach in capturing the detailed style elements of a multi-panel comic style.", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x16.png", "caption": "Figure S4: Additional qualitative comparison. Our method effectively captures the multi-panel style, whereas zero-shot methods generate images with different structures or introduce artifacts.", "description": "Figure S4 presents a qualitative comparison of different methods for generating images with a multi-panel comic style.  The reference image shows a multi-panel comic strip.  Our Style-Friendly SNR Sampler successfully generates images that closely match the structure and style of the reference, demonstrating its ability to learn and apply complex stylistic elements.  In contrast, several zero-shot methods (IP-Adapter, RB-Modulation, and Style-Aligned) fail to accurately capture the multi-panel structure. They either produce images with a different number of panels, a different arrangement of panels, or introduce artifacts that detract from the overall visual coherence. This comparison highlights the effectiveness of the Style-Friendly SNR Sampler in learning and applying highly structured styles compared to the shortcomings of zero-shot methods in similar tasks.", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x17.png", "caption": "Figure S5: Varying \u03bc\ud835\udf07\\muitalic_\u03bc on object references. The object names are written at the top of the reference images. Setting \u03bc=0\ud835\udf070\\mu=0italic_\u03bc = 0 (high log-SNR value) leads to failures in color binding and structure when fine-tuning on object references, whereas using the SD3 sampler allows FLUX to fine-tune object references effectively. This unveils why recent diffusion models perform well on object fine-tuning, as their noise level distributions are adjusted toward object-centric generation.", "description": "This figure demonstrates the impact of the mean (\u03bc) parameter in the Style-friendly SNR sampler on the fine-tuning of object references in diffusion models.  When \u03bc is set to 0 (representing a high log-SNR value), the fine-tuning process fails to accurately capture color relationships and structural details within the objects.  In contrast, using the SD3 sampler, which is pre-trained with a specific noise level distribution, allows the FLUX model to successfully fine-tune on the object references. This experiment highlights the importance of carefully considering the noise level distribution during model training, especially when focusing on object-centric characteristics, in contrast to style-centric ones. This difference explains why many current diffusion models successfully fine-tune for object-centric generation tasks.", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x18.png", "caption": "Figure S6: Comparison of fine-tuning the SD3.5-8B. The results with SD3.5-8B are consistent with the qualitative comparison based on FLUX-dev presented in Fig.\u00a07.", "description": "This figure compares the results of fine-tuning the Stable Diffusion 3.5-8B model using three different methods: the Style-friendly SNR sampler (proposed in this paper), the SD3 sampler (a baseline method), and Direct Consistency Optimization (DCO, another baseline method).  Each method was used to generate images based on the same set of reference images and prompts. The images generated using the Style-friendly SNR sampler are shown alongside those generated by the SD3 sampler and DCO to illustrate the differences in style capture and overall image quality. The results shown for SD3.5-8B are consistent with the qualitative comparisons shown in Figure 7 which used the FLUX model.  This visual comparison demonstrates the effectiveness of the Style-friendly SNR sampler in achieving high-fidelity style transfer.", "section": "A. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.14793/x19.png", "caption": "(a) Varying \u03bc\ud835\udf07\\muitalic_\u03bc.", "description": "The figure shows the effect of varying the mean (\u03bc) of the log-SNR distribution on the DINO similarity score. The DINO similarity score measures the style alignment of images generated by diffusion models fine-tuned with different values of \u03bc. The figure shows that as \u03bc increases, the DINO similarity score decreases, indicating that the model's ability to capture the reference style worsens. This suggests that using a lower \u03bc value (\u03bc = -6 or lower) during fine-tuning helps the model to learn the reference style more effectively.  The x-axis represents the \u03bc values and the y-axis represents the DINO similarity scores.", "section": "4.1 Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x20.png", "caption": "(b) Varying \u03c3\ud835\udf0e\\sigmaitalic_\u03c3.", "description": "The figure shows the result of varying the standard deviation (\u03c3) of the log-SNR sampling distribution during the training of diffusion models.  It demonstrates how different standard deviations affect the model's ability to capture and reflect the stylistic aspects of reference images during fine-tuning.  The x-axis represents different values of \u03c3, and the y-axis represents the DINO similarity score.  The plot shows how a balance is needed in \u03c3 for optimal style learning; too small a \u03c3 limits exploration of noise levels, while too large a \u03c3 may lead to instability and thus reduce similarity to the desired styles.", "section": "4.1. Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x21.png", "caption": "(c) Varying LoRA Rank.", "description": "This figure shows the impact of varying the rank of the LoRA (Low-Rank Adaptation) model on the performance of the Style-Friendly SNR sampler for style-driven image generation. It is part of an ablation study assessing the impact of different hyperparameters on the model's ability to capture and reproduce artistic styles from reference images.  The x-axis shows different LoRA ranks, indicating the model's capacity. The y-axis represents a similarity score, such as DINO similarity, measuring the alignment between generated images and reference style images. The plot helps to determine the optimal LoRA rank that balances model capacity with performance.", "section": "4.1. Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x22.png", "caption": "Figure S7: SNR sampler analysis. CLIP-I similarities with FLUX and SD3.5-8B. Dotted lines in (c) indicate the results of SD3 sampler\u00a0[8].", "description": "This figure analyzes the performance of the Style-friendly SNR sampler by varying its parameters (mean (\u00b5), standard deviation (\u03c3), and LoRA rank). It compares the results obtained using the proposed sampler with those from the standard SD3 sampler on two different diffusion models: FLUX and SD3.5-8B.  The CLIP-I (CLIP Image Similarity) metric is used to evaluate style alignment, measuring how similar the generated images are to the reference style images. The plots demonstrate the effect of varying \u00b5, \u03c3, and the LoRA rank on style alignment, showing how the optimal parameters of the Style-friendly SNR sampler lead to improved style capture compared to the standard SD3 sampler.", "section": "4.1. Analysis of Style-Friendly SNR Sampler"}, {"figure_path": "https://arxiv.org/html/2411.14793/x23.png", "caption": "Figure S8: Prompt switching during generation. The generated images still reflect the intended styles even without style descriptions in most of the denoising process, indicating that stylistic features emerge mainly at the early denoising steps.", "description": "This figure demonstrates the importance of early-stage style conditioning in diffusion models. Four variations of a prompt were used during image generation: 1) style prompt present throughout the process, 2) style prompt present only in the latter steps, 3) style prompt present only in the very early steps, and 4) no style prompt.  The results show that stylistic features emerge during the early denoising stages (high noise levels).  Therefore, omitting style descriptions during only the initial steps is sufficient to prevent styles from being properly incorporated, while adding the prompt only to the later stages still results in the style being included, albeit possibly less prominently.", "section": "A.3. Additional Observations"}]