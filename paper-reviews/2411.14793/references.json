{"references": [{"fullname_first_author": "Diederik P Kingma", "paper_title": "Variational diffusion models", "publication_date": "2021-12-01", "reason": "This paper introduces variational diffusion models, a foundational framework for many modern diffusion models used in image generation, making it highly influential to the field."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat GANs on image synthesis", "publication_date": "2021-12-01", "reason": "This paper demonstrates the superior performance of diffusion models over GANs in image synthesis, marking a significant advancement in the field and prompting increased research into diffusion models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-07-01", "reason": "This paper introduces latent diffusion models which significantly improve the efficiency and scalability of diffusion models for generating high-resolution images, becoming highly influential in the field."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper presents a highly efficient and effective architecture for high-resolution image generation using rectified flow transformers, improving image quality and providing a benchmark for future research."}, {"fullname_first_author": "Kihyuk Sohn", "paper_title": "Styledrop: Text-to-image synthesis of any style", "publication_date": "2024-01-01", "reason": "This paper introduces a method to enable the generation of images with user-specified styles through fine-tuning, significantly improving the ability of text-to-image models to generate images with personalized artistic styles."}]}