[{"figure_path": "https://arxiv.org/html/2411.15466/x2.png", "caption": "Figure 1: Given a single reference image, our Diptych Prompting performs zero-shot subject-driven text-to-image generation through diptych inpainting. Building on the (a) diptych generation capability of FLUX\u00a0[21], we extend it to diptych inpainting with a separate module, resulting in (b) versatility across various tasks including subject-driven text-to-image generation, stylized image generation, and subject-driven image editing.", "description": "This figure demonstrates the Diptych Prompting method, a novel zero-shot approach for subject-driven text-to-image generation.  It uses a single reference image as input and leverages the diptych generation capability of the FLUX model [21]. Diptych Prompting extends FLUX by incorporating a separate inpainting module, allowing it to generate diptychs (two-paneled images) where the left panel contains the reference image and the right panel is generated via text-conditioned inpainting. This approach addresses limitations of traditional methods by accurately capturing the subject's visual characteristics and semantic content while preventing unwanted content leakage. Panel (a) shows the diptych generation process, while panel (b) highlights the method's versatility for various image generation tasks, including subject-driven generation, stylized generation, and subject-driven editing.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.15466/x3.png", "caption": "Figure 2: Diptych Generation Comparisons. We generate the diptych images with various TTI models from the following diptych text: \u201cA diptych with two side-by-side images of same cat. On the left, a photo of a cat in front of Eiffel Tower. On the right, replicate this cat exactly but as a photo of a cat in the jungle\u201d.", "description": "This figure compares the diptych generation capabilities of several text-to-image (TTI) models.  A diptych is a two-paneled image. The models were all given the same prompt: to create a diptych showing the same cat in two different settings. The left panel should depict a cat in front of the Eiffel Tower, and the right panel should show the same cat in a jungle. The figure visually demonstrates how each model interprets and executes the prompt, showcasing differences in image quality, cat likeness, and background rendering.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2411.15466/x4.png", "caption": "Figure 3: (a) Overall Diptych Prompting Framework. Given the incomplete diptych Idiptychsubscript\ud835\udc3cdiptychI_{\\text{diptych}}italic_I start_POSTSUBSCRIPT diptych end_POSTSUBSCRIPT, text prompt Tdiptychsubscript\ud835\udc47diptychT_{\\text{diptych}}italic_T start_POSTSUBSCRIPT diptych end_POSTSUBSCRIPT describing the diptych, and the binary mask Mdiptychsubscript\ud835\udc40diptychM_{\\text{diptych}}italic_M start_POSTSUBSCRIPT diptych end_POSTSUBSCRIPT specifying the right panel as the inpainting target, FLUX with ControlNet module performs text-conditioned inpainting on the right panel while referencing the subject in the left panel. (b) Reference Attention Enhancement. To capture the granular details of the subject in left panel, we enhance the reference attention, an attention weight between the query of the right panel and the key of the left panel.", "description": "Figure 3 illustrates the Diptych Prompting framework.  Panel (a) shows the process: an incomplete diptych image (left panel is a reference image, right panel is blank), a text prompt describing the desired final image, and a binary mask designating the right panel for inpainting are fed into FLUX (a large-scale text-to-image model) with a ControlNet module.  This setup performs text-conditioned inpainting on the right panel, using the left panel's reference image for context. Panel (b) details the 'Reference Attention Enhancement' technique, which increases the attention weight between the right panel's query and the left panel's key, sharpening focus on the reference subject for more accurate inpainting.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.15466/x5.png", "caption": "Figure 4: Background Removal Effects. Simple diptych inpainting exhibits content leakage from the reference image, including background, pose, and location. We mitigate this unwanted leakage through background removal by Gsegsubscript\ud835\udc3asegG_{\\text{seg}}italic_G start_POSTSUBSCRIPT seg end_POSTSUBSCRIPT.", "description": "Figure 4 demonstrates the importance of background removal in diptych inpainting.  Without background removal, simple diptych inpainting methods tend to copy elements from the reference image into the generated image, including the background, subject pose, and the subject's location. This is undesirable, as the goal is to generate a new image of the subject in a specified context without unwanted elements from the reference image interfering with the generated context. The background removal technique, denoted as Gseg, effectively addresses this issue by isolating the subject from its background before inpainting, ensuring that the generated image only incorporates the intended subject and its contextual elements from the text prompt.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.15466/x6.png", "caption": "Figure 5: Qualitative Comparisons. Please zoom in for a more detailed view and better comparison.", "description": "This figure presents a qualitative comparison of different zero-shot subject-driven image generation methods.  The first column shows the reference image, then subsequent columns show the results produced by BLIP Diffusion, A-Eclipse, IP-Adapter, MS-Diffusion, and the authors' proposed method, Diptych Prompting.  Each row represents a different prompt, illustrating the models' ability to accurately generate images of a specific subject within the context described by the text prompt.  The results demonstrate the superior performance of Diptych Prompting in generating visually accurate and contextually relevant images compared to existing methods.", "section": "4.2. Baseline Comparisons"}, {"figure_path": "https://arxiv.org/html/2411.15466/x7.png", "caption": "Figure 6: Qualitative Comparisons of Stylized Image Generation. Using a style image as a reference, Diptych Prompting generates stylized images.", "description": "This figure demonstrates the capability of Diptych Prompting to generate stylized images.  It shows several examples where a style image (like a watercolor painting, cartoon illustration, or crayon drawing) is used as a reference to guide the generation of a new image of a different subject, inheriting the stylistic characteristics of the reference image. The results highlight Diptych Prompting's ability to adapt and apply various styles effectively in a zero-shot setting.", "section": "4.4 Applications"}, {"figure_path": "https://arxiv.org/html/2411.15466/x8.png", "caption": "Figure 7: Subject-Driven Image Editing. Diptych Prompting extends to subject-driven image editing by placing the target image on the right panel and masking only the area to be edited.", "description": "Diptych Prompting is extended to subject-driven image editing by placing the target image on the right panel of a diptych and masking only the area to be edited.  The left panel contains a reference subject image. The model then performs text-conditioned inpainting, using the reference subject to guide the editing process and seamlessly integrate the subject into the modified area of the target image.", "section": "4.4 Applications"}, {"figure_path": "https://arxiv.org/html/2411.15466/x9.png", "caption": "Figure A1: DreamBooth Comparisons. Quantitative comparisons to DreamBooth-LoRA with various rank values.", "description": "Figure A1 presents a quantitative comparison of the performance of Diptych Prompting against DreamBooth-LoRA, a fine-tuning based approach, across various LoRA rank values.  The results are visualized using three metrics from DreamBench: DINO, CLIP-I, and CLIP-T. Each metric assesses a different aspect of the generated images, providing a comprehensive evaluation of the models' ability to capture subject and context in zero-shot image generation.", "section": "B.2. Comparison with Fine-Tuning-Based Method"}, {"figure_path": "https://arxiv.org/html/2411.15466/x10.png", "caption": "Figure A2: Subject-Driven Text-to-Image Generation. More samples of subject-driven text-to-image generation using Diptych Prompting.", "description": "Figure A2 presents additional examples showcasing the capabilities of Diptych Prompting for subject-driven text-to-image generation.  It demonstrates the model's ability to accurately incorporate a reference subject into diverse contexts specified by text prompts. Each row shows a reference image, followed by three generated images illustrating variations in the background and composition while maintaining consistent subject representation.", "section": "B.3. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.15466/x11.png", "caption": "Figure A3: Subject-Driven Text-to-Image Generation. More samples of subject-driven text-to-image generation using Diptych Prompting..", "description": "Figure A3 presents additional examples showcasing the capabilities of Diptych Prompting for subject-driven text-to-image generation.  It displays multiple sets of images. Each set includes a reference image of a subject (e.g., a bowl of berries, a rubber duck, a cat) on the left, and three variations of generated images on the right. These variations depict the subject in different contexts as described by accompanying text prompts, demonstrating the model's ability to accurately place the subject within various scenes while maintaining visual fidelity.", "section": "B.3. Additional Results"}, {"figure_path": "https://arxiv.org/html/2411.15466/x12.png", "caption": "Figure A4: \ud835\udc6esegsubscript\ud835\udc6eseg\\bm{G_{\\text{seg}}}bold_italic_G start_POSTSUBSCRIPT seg end_POSTSUBSCRIPT Ablation. Qualitative comparisons with and without the background removal process.", "description": "This figure shows a qualitative comparison of the results obtained with and without background removal during the image generation process. The background removal process, denoted as Gseg, aims to isolate the subject from its surroundings, preventing content leakage from the reference image (left panel) into the generated image (right panel).  The top row shows examples with a golden retriever, while the bottom row displays examples with a red frog. Each column represents a different generated image, illustrating how the absence of background removal leads to less focused and sometimes undesirable results compared to those generated with the background removal technique.", "section": "Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2411.15466/x13.png", "caption": "Figure A5: \ud835\udf40\ud835\udf40\\bm{\\lambda}bold_italic_\u03bb Ablation. Qualitative transitions according to the varying \u03bb\ud835\udf06\\lambdaitalic_\u03bb values. we control the \u03bb\ud835\udf06\\lambdaitalic_\u03bb from 1.01.01.01.0 (without reference attention enhancement) to 1.51.51.51.5. For a detailed view, please zoom in.", "description": "This ablation study shows how changing the reference attention enhancement parameter (lambda, \u03bb) affects the generated images in the Diptych Prompting method.  The experiment varies \u03bb from 1.0 (no enhancement) to 1.5, showcasing the impact on image detail and subject alignment. The images are presented in a before-and-after style, enabling a visual comparison of how different \u03bb values influence the results of the text-to-image generation process.", "section": "4.3. Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2411.15466/x14.png", "caption": "Figure A6: Stylized Image Generation. More samples of stylized image generation using Diptych Prompting.", "description": "Figure A6 presents diverse examples showcasing the versatility of Diptych Prompting in generating stylized images.  The figure demonstrates how, by providing a style reference image alongside a textual description, the method can accurately replicate various artistic styles, ranging from watercolor paintings and 3D renders to cartoon illustrations and even specific artistic styles (such as a 'kid crayon drawing style').  Each row displays the style reference image followed by several examples of images synthesized using Diptych Prompting in that style, highlighting the precise and effective manner in which it captures and applies the specified styles.", "section": "4.4 Applications"}]