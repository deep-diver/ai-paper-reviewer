[{"figure_path": "https://arxiv.org/html/2503.16397/x1.png", "caption": "Figure 1: \nSpectral analysis of SDXL (Left) and SD3.5 (Right) VAE latents (128\u00d7128128128128{\\times}128128 \u00d7 128) for different diffusion timesteps.\nVertical lines mark frequency boundaries for lower resolutions; frequencies to the right are not present at lower scale latents.\nNoise masks high frequencies, suggesting that latent DMs can operate at lower latent resolutions for high noise levels.", "description": "This figure displays the spectral analysis of SDXL and SD3.5 VAE latent spaces. The spectral density is shown for different diffusion timesteps. Vertical lines represent the frequency boundaries for lower resolution latent spaces (e.g., 16x16, 32x32, 96x96). Frequencies beyond these lines are not present at lower resolutions. The figure demonstrates that high frequencies are masked by noise at high noise levels. This observation supports the idea that latent diffusion models can efficiently operate at lower resolutions during the early stages of the diffusion process (i.e. at high noise levels).", "section": "3. Latent space spectral analysis"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/method_training.jpg", "caption": "Figure 2: \nSwD training step.\ni) Sample training images and the pair of scales [sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, si+1subscript\ud835\udc60\ud835\udc561s_{i+1}italic_s start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT] from the scale schedule.\nii) The images are downscaled to the sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and si+1subscript\ud835\udc60\ud835\udc561s_{i+1}italic_s start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT scales.\niii) The lower resolution version is upscaled and noised according to the forward diffusion process at the timestep tisubscript\ud835\udc61\ud835\udc56t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\niv) Given the noised images, the model G\ud835\udc3aGitalic_G predicts clean images at the target scale si+1subscript\ud835\udc60\ud835\udc561s_{i+1}italic_s start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT.\nv) Distribution matching loss is calculated between predicted and target images.", "description": "The figure illustrates the training process of the Scale-wise Distillation (SWD) method.  It's a five-step process: 1) Select a training image and a pair of scales (s<sub>i</sub> and s<sub>i+1</sub>) from a predefined scale schedule. 2) Downscale the image to both s<sub>i</sub> and s<sub>i+1</sub> resolutions. 3) Upscale the lower-resolution (s<sub>i</sub>) image and add noise according to the forward diffusion process at timestep t<sub>i</sub>.  4) The model G predicts a clean image at the target scale s<sub>i+1</sub>. 5) Finally, calculate the distribution matching loss between the model's prediction and the original, target image at scale s<sub>i+1</sub>. This loss guides the training of model G to accurately predict images at higher resolutions by progressively upscaling and denoising.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/method_overview.jpg", "caption": "Figure 3: \nSwD sampling.\nStarting from noise at the low scale s1subscript\ud835\udc601s_{1}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, the model gradually increases resolution via multistep stochastic sampling.\nAt each step, the previous prediction at the scale si\u22121subscript\ud835\udc60\ud835\udc561s_{i-1}italic_s start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is upscaled and noised according to the  timestep schedule, tisubscript\ud835\udc61\ud835\udc56t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\nThen, the generator predicts a clean image at the current scale sisubscript\ud835\udc60\ud835\udc56s_{i}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.", "description": "This figure illustrates the SWD (Scale-wise Distillation) sampling process.  It starts with pure Gaussian noise at a low initial resolution (s1).  The model then iteratively refines this noisy image through multiple steps. In each step, the model upscales the previous prediction to a higher resolution (si) and adds noise according to a predefined timestep schedule (ti). This noisy image is then fed to the generator, which outputs a progressively cleaner, higher-resolution prediction at each step, until the final, high-resolution image is produced.  The process mimics a coarse-to-fine approach, starting with low-frequency details at lower resolutions and gradually adding high-frequency details at each step.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/exps_crops.jpg", "caption": "Figure 4: \nSD3.5 generates cropped images at low-resolutions (256\u00d7256256256256{\\times}256256 \u00d7 256), while SDXL does not produce meaningful images at all.\nSwD is able to perform successful distillation for such cases and corrects these limitations.", "description": "This figure demonstrates the impact of using a scale-wise distillation method (SwD) compared to training at full resolution.  At a lower resolution (256x256), SD3.5, a diffusion model, produces cropped images lacking detail.  SDXL, another diffusion model, fails to generate coherent images at this resolution. However, SwD successfully distills these models, generating more complete and higher quality images. This highlights the SwD's ability to correct the limitations found in models trained at higher resolutions for lower-resolution tasks. ", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/x2.png", "caption": "Figure 5: \nSide-by-side comparison between scale-wise and full-scale settings.\nThe numbers indicate the sampling steps.", "description": "This figure presents a visual comparison of image generation results using scale-wise and full-scale methods for different numbers of sampling steps.  It helps to illustrate the effectiveness of the scale-wise approach, which progressively increases the image resolution during generation, in comparison to the traditional full-scale method. The images generated by both methods across varying numbers of steps are presented side-by-side for comparison. The number of steps used for generation is indicated below each set of images, enabling a direct visual analysis of how image quality changes with the number of steps and the chosen method.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/exps_full_vs_scale_imgs.jpg", "caption": "Figure 6: Few examples of image generations for scale-wise and full-scale approaches. SwD outperforms the 2222-step configuration.", "description": "Figure 6 presents a comparison of image generation results between the scale-wise distillation method (SWD) and the full-scale method.  It showcases several example prompts and their corresponding generated images. The images highlight the improved quality and detail achieved by SWD, especially when compared to the full-scale method with only two steps. The scale-wise approach produces more coherent and detailed images, demonstrating its superiority over the faster but less accurate full-scale approach.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/x3.png", "caption": "Figure 7: \nSide-by-side comparisons of SwD and baseline models.", "description": "This figure presents a side-by-side comparison of the generated images from SwD and several baseline models, across four key aspects: text relevance, image aesthetics, image complexity, and defects.  For each metric, the figure shows bar graphs representing the human evaluation scores for SwD and the baselines, enabling a visual comparison of their relative performance in these criteria. This allows for a quick assessment of SwD's strengths and weaknesses when compared to state-of-the-art methods.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/exps_cherry.jpg", "caption": "Figure 8: Qualitative comparison of SwD against the state-of-the-art baselines.", "description": "Figure 8 presents a qualitative comparison of image generation results between the proposed Scale-wise Distillation (SwD) method and several state-of-the-art baselines.  Four example image prompts are shown, with each showing the output of SwD and the outputs of the baselines. This allows for a visual comparison of the image quality, detail, and overall fidelity across different methods, highlighting the strengths and weaknesses of each in terms of generating high-quality, detailed images.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/x4.png", "caption": "(a) Scale-wise against full-scale.", "description": "This figure shows a comparison of the scale-wise approach against the full-scale approach.  Specifically, it presents a visual comparison of the results obtained by using the scale-wise method (progressively increasing the resolution at each sampling step) versus the full-resolution method.  The comparison allows assessment of the tradeoffs between computational efficiency and image quality using the two approaches.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/x5.png", "caption": "(b) SwD against its teacher (SD3.5 Large) and SD3.5 Large Turbo.", "description": "This figure presents a comparison of the performance of SwD against its teacher model (SD3.5 Large) and a state-of-the-art, fast text-to-image diffusion model (SD3.5 Large Turbo).  The comparison is conducted using human evaluation across multiple criteria, namely image aesthetics, text relevance, image complexity, and defects.  The results visualize the relative strengths and weaknesses of SwD concerning these aspects compared to existing models, illustrating how well SwD manages to preserve or improve upon its teacher's performance while offering a significant speedup.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_large.jpg", "caption": "Figure 9: Side-by-Side comparisons for SD3.5 Large. The numbers indicate the sampling steps.", "description": "This figure shows a comparison of the image quality generated by different models: the full-resolution SD3.5 Large model and its scale-wise distilled counterparts with 4 and 6 sampling steps.  The images generated from each model are presented side-by-side, allowing for visual comparison of the image quality and detail.  The results are further assessed using human evaluations on various aspects like text relevance, image aesthetics, complexity, and presence of defects. This comparison helps to demonstrate the effectiveness of the scale-wise distillation method.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_full_vs_scale_imgs.jpg", "caption": "Figure 10: Visual examples for the SD3.5 Large models.", "description": "This figure showcases visual examples generated by SD3.5 Large models, highlighting the diverse range of image styles and subject matters achievable using the model.  The examples illustrate the model's capacity to create a variety of images given different prompts.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_cherry.jpg", "caption": "Figure 11: Qualitative examples of image generations for scale-wise and\nfull scale approaches for different generation steps.", "description": "This figure showcases several image generation examples using both scale-wise and full-scale approaches with varying generation steps (2, 4, and 6 steps).  Each row represents a different text prompt, and the images within each row demonstrate the results from different methods and step counts. This allows for a visual comparison of the image quality and detail achieved by each approach. The purpose is to highlight the qualitative differences between the scale-wise distillation technique and a more traditional full-scale approach with different numbers of sampling steps, demonstrating the capabilities of the proposed method in producing high-quality images with fewer steps.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_aesthetics.jpg", "caption": "Figure 12: Qualitative comparisons against the baselines.", "description": "This figure shows a qualitative comparison of image generation results from various models, including the proposed Scale-wise Distillation of Diffusion Models (SWD) and several state-of-the-art baselines (SD3.5, SDXL, DMD-SDXL, and Switti).  For each model, several image examples are displayed for the same text prompt, allowing for a visual comparison of image quality, detail, realism, and adherence to the prompt.  This side-by-side comparison helps highlight the strengths and weaknesses of SWD compared to other methods.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_defects.jpg", "caption": "Figure 13: Human evaluation interface for aesthetics.", "description": "This figure shows the user interface used for human evaluation of image aesthetics.  Assessors are presented with pairs of images and asked to compare them based on several criteria, including brightness and contrast, color quality, glow, visibility of main objects, background and environment, and level of detail in the images.  A multiple choice format allows assessors to indicate which image is better or if they are comparable in quality for a given criterion.  The final rating is a consolidated judgment across all the criteria.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_relevance.jpg", "caption": "Figure 14: Human evaluation interface for defects.", "description": "This figure displays the interface used by assessors in the human evaluation study. Assessors are presented with a pair of images and asked to evaluate the presence of defects. The interface guides assessors through specific types of defects such as those in composition, watermarks, or extra objects.  Assessors rate images based on the severity of these defects and provide a final decision for each image pair.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.16397/extracted/6297350/images/app_complexity.jpg", "caption": "Figure 15: Human evaluation interface for relevance.", "description": "This figure shows the interface used by human evaluators to assess the relevance of generated images to the given text prompt.  The evaluators are presented with a pair of images and asked to judge which image is more relevant to the prompt, considering aspects like the main objects and secondary objects depicted. They also assess the impact of any extra objects present in the image and provide a final verdict indicating which image demonstrates better relevance.", "section": "5. Experiments"}]