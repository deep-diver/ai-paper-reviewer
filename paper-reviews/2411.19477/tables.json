[{"content": "| Download | Code | \n|---|---| \n| <a download=\"\" href=\"data:text/plain;base64,JSBTeXN0ZW0gcHJvbXB0CllvdXIgdGFzayBpcyB0byBhbnN3ZXIgdGhlIHF1ZXN0aW9uIHByb3ZpZGVkIGJ5IHRoZSB1c2VyIHZpYSBzdGVwLWJ5LXN0ZXAgcmVhc29uaW5nLgoKJSBVc2VyIHByb21wdAojIFF1ZXN0aW9uCntxdWVzdGlvbn0KCiMgT3V0cHV0IEZvcm1hdApgYGAKPHJlYXNvbj55b3VyIHN0ZXAtYnktc3RlcCByZWFzb25pbmcgcHJvZGVzczwvcmVhc29uPgo8YW5zd2VyPmZpbmFsIGFuc3dlcjogKipUaGUgYW5zd2VyIGlzIFtYXQoqPC9hbnN3ZXI+CmBgYAo=\" >\u2b07</a> | ```% System prompt\nYour task is to answer the question provided by the user via step-by-step reasoning.\n\n% User prompt\n# Question\n{question}\n\n# Output Format\n```\n<reason>your step-by-step reasoning proecss</reason>\n<answer>final answer: **The answer is [X]**</answer>\n```|", "caption": "Table 1: The adopted prompt template for generating a candidate solution.", "description": "This table presents the prompt template used to instruct the large language model (LLM) to generate candidate solutions for a given problem.  The template includes placeholders for the system's instructions, the user's question, and the expected output format, which requires the LLM to provide both a step-by-step reasoning process and the final answer.", "section": "2 A two-stage algorithm"}, {"content": "| Download | System prompt                                                                                                                                                                                                                              |\n|---|---|---|\n| <a download=\"\" href=\"data:text/plain;base64,JSBTeXN0ZW0gcHJvbXB0CllvdSBhcmUgYSBmYWlyIEp1ZGdlLiBHaXZlbiBhIHF1ZXN0aW9uIGFuZCB0d28gY2FuZGlkYXRlIHNvbHV0aW9ucywgeW91ciB0YXNrIGlzIHRvIGZpZ3VyZSBvdXQgd2hpY2ggc29sdXRpb24gaXMgYmV0dGVyLiBZb3VyIGp1ZGdtZW50IHNob3VsZCBiZSB1bmJpYXNlZCwgd2l0aG91dCBmYXZvcmluZyBlaXRoZXIgU29sdXRpb24gMSBvciAyLgoKJSBVc2VyIHByb21wdAotLS0tIFFVRVNUSU9OIC0tLS0Ke3F1ZXN0aW9ufQoKLS0tLSBTb2x1dGlvbiAxIC0tLS0Ke3NvbHV0aW9uIDF9CgotLS0tIFNvbHV0aW9uIDIgLS0tLQp7c29sdXRpb24gMn0KCi0tLS0gT1VUUFVUIEZPUk1BVCAtLS0tCmBgYAo8Y29tcGFyZT5jb21wYXJlIGJvdGggY2FuZGlkYXRlIHNvbHV0aW9ucyBzdGVwLWJ5LXN0ZXAgdGhvcm91Z2hseSwgYW5kIGRvdWJsZSBjaGVjayBpZiB0aGVyZSBhcmUgbWlzdGFrZXMgaW4gZWl0aGVyIHNvbHV0aW9uPC9jb21wYXJlPgo8d2lubmVyPlNvbHV0aW9uIDEgb3IgU29sdXRpb24gMjwvd2lubmVyPgpgYGAK\">\u2b07</a> | % System prompt\nYou are a fair Judge. Given a question and two candidate solutions, your task is to figure out which solution is better. Your judgment should be unbiased, without favoring either Solution 1 or 2.\n% User prompt\n\u2014- QUESTION \u2014-\n{question}\n\u2014- Solution 1 \u2014-\n{solution 1}\n\u2014- Solution 2 \u2014-\n{solution 2}\n\u2014- OUTPUT FORMAT \u2014-\n\u201c\u2018\n<compare>compare both candidate solutions step-by-step thoroughly, and double check if there are mistakes in either solution</compare>\n<winner>Solution 1 or Solution 2</winner>\n\u201c\u2018                                                                                                                                                                                                                                    |", "caption": "Table 2: The adopted prompt template for pairwise comparison.", "description": "This table presents the prompt template used for pairwise comparison in the knockout stage of the two-stage algorithm.  The prompt instructs the LLM to act as a judge, evaluating two candidate solutions to a given question and selecting the better one based on unbiased, thorough step-by-step comparison and error checking.", "section": "2 A two-stage algorithm"}, {"content": "|| Question | Solution |\n|---|---|---|\n| In a 2 pole lap winding dc machine , the resistance of one conductor is 2\u03a9 and total number of conductors is 100. Find the total resistance | A) 50\u03a9 \nB) 1\u03a9 \nC) 25\u03a9 \nD) 200\u03a9 \nE) 10\u03a9 \nF) 100\u03a9 \nG) 500\u03a9 \nH) 150\u03a9 \nI) 75\u03a9 \nJ) 20\u03a9 |", "caption": "Table 3: Case study: the LLM is capable of conducting pairwise comparison for a question where pgensubscript\ud835\udc5dgenp_{\\text{gen}}italic_p start_POSTSUBSCRIPT gen end_POSTSUBSCRIPT is small and the majority of the initial candidate solutions are incorrect. This question is sampled from the validation set for the \u201cengineering\u201d category of MMLU-Pro.", "description": "This table presents a case study demonstrating the capability of a large language model (LLM) to perform pairwise comparisons even when the probability of generating a correct solution (p_gen) is low and most initial solutions are incorrect.  The example problem, sourced from the MMLU-Pro \"engineering\" category's validation set, showcases the LLM's ability to identify the superior solution between two flawed options through comparison and reasoning, thereby highlighting its capacity for improved performance with increased computation, even under challenging circumstances.", "section": "3 Experiments"}]