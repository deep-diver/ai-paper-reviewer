{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-Thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the Chain-of-Thought prompting technique, a crucial concept for improving LLM reasoning, directly influencing the methodology of the current research."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2024-12-01", "reason": "This paper introduces Direct Preference Optimization (DPO), a key algorithm used in the current research for enhancing model alignment and reasoning quality."}, {"fullname_first_author": "Haotian Liu", "paper_title": "LLaVA-NeXT: Improved reasoning, OCR, and world knowledge", "publication_date": "2024-11-21", "reason": "As the base model for the experiments, LLaVA-NeXT is a highly relevant and impactful reference, demonstrating the baseline performance and context of the current research."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "publication_date": "2023-12-01", "reason": "This paper introduces the Qwen-VL model, a strong LLM used for answer filtering and reasoning path scoring, which is crucial in the multi-agent system of the current research."}, {"fullname_first_author": "Yuan Liu", "paper_title": "MMBench: Is your multi-modal model an all-around player?", "publication_date": "2023-07-01", "reason": "This paper introduces MMBench, a benchmark used for evaluating the performance of the proposed method, thus directly contributing to the experimental validation and comparative analysis."}]}