{"references": [{"fullname_first_author": "Carbune, V.", "paper_title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs", "publication_date": "2024-03-12", "reason": "This paper is highly relevant due to its focus on chart-based reasoning and the use of LLMs for visual language tasks, which directly relates to the core topic and methodology of the main paper."}, {"fullname_first_author": "Han, Y.", "paper_title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation", "publication_date": "2023-11-16", "reason": "The creation of synthetic chart datasets using LLMs is a key aspect of the main paper; therefore, this paper is very important as it describes a similar approach."}, {"fullname_first_author": "Kim, G.", "paper_title": "OCR-Free Document Understanding Transformer", "publication_date": "2022-00-00", "reason": "The main paper uses the Donut model, and this paper introduced the Donut model architecture and training process, which are crucial for understanding the core model used in the main paper."}, {"fullname_first_author": "Lee, K.", "paper_title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding", "publication_date": "2023-00-00", "reason": "The main paper also uses the Pix2Struct model as a comparison model, making this paper fundamentally important for understanding the experimental design and context of the study."}, {"fullname_first_author": "Masry, A.", "paper_title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning", "publication_date": "2022-00-00", "reason": "This paper introduces a benchmark dataset, ChartQA, which is used in the main paper's evaluation. It is therefore important for understanding the context and evaluating the model's performance."}]}