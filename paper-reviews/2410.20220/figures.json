[{"figure_path": "2410.20220/figures/figures_1_0.png", "caption": "Fig. 1: Overview: This survey paper discusses a large variety of state-of-the-art Neural Field methods that enable robotics applications in pose estimation, manipulation, navigation, physics, and autonomous driving. Images adapted from [1-12].", "description": "Figure 1 provides an overview of the various robotics applications enabled by Neural Fields, showcasing examples of pose estimation, manipulation, navigation, physics simulation, and autonomous driving.", "section": "I. INTRODUCTION"}, {"figure_path": "2410.20220/figures/figures_3_0.png", "caption": "Fig. 3: Timeline of Neural Fields in Robotics paper showing key papers over the years divided into 5 major application areas.", "description": "The figure presents a timeline showcasing key neural fields papers in robotics, categorized by application area (pose estimation, manipulation, navigation, physics, and autonomous driving).", "section": "III. NEURAL FIELDS FOR ROBOTICS"}, {"figure_path": "2410.20220/figures/figures_4_0.png", "caption": "Fig. 4: Neural Field Representations: Section II discusses four core Neural Field representations - Occupancy Networks [42], Signed Distance Fields [23], Neural Radiance Fields [22], and 3D Gaussian Splatting [49].", "description": "Figure 4 illustrates four core neural field representations: Occupancy Networks, Signed Distance Fields, Neural Radiance Fields, and 3D Gaussian Splatting.", "section": "II. FORMULATION OF NEURAL FIELDS"}, {"figure_path": "2410.20220/figures/figures_4_1.png", "caption": "Fig. 4: Neural Field Representations: Section II discusses four core Neural Field representations - Occupancy Networks [42], Signed Distance Fields [23], Neural Radiance Fields [22], and 3D Gaussian Splatting [49].", "description": "Figure 4 illustrates four core neural field representations: Occupancy Networks, Signed Distance Fields, Neural Radiance Fields, and 3D Gaussian Splatting, showcasing their distinct characteristics.", "section": "II. FORMULATION OF NEURAL FIELDS"}, {"figure_path": "2410.20220/figures/figures_4_2.png", "caption": "Fig. 4: Neural Field Representations: Section II discusses four core Neural Field representations - Occupancy Networks [42], Signed Distance Fields [23], Neural Radiance Fields [22], and 3D Gaussian Splatting [49].", "description": "Figure 4 illustrates four core neural field representations: Occupancy Networks, Signed Distance Fields, Neural Radiance Fields, and 3D Gaussian Splatting.", "section": "II. FORMULATION OF NEURAL FIELDS"}, {"figure_path": "2410.20220/figures/figures_5_0.png", "caption": "Fig. 5: Taxonomy of selected key Neural Fields papers in five major robotics application areas.", "description": "The figure presents a taxonomy of key neural fields papers in robotics, categorized into five major application areas: pose estimation, manipulation, navigation, physics, and autonomous driving.", "section": "III. NEURAL FIELDS FOR ROBOTICS"}, {"figure_path": "2410.20220/figures/figures_6_0.png", "caption": "Fig. 6: Mapping and tracking results from SplaTam [121].", "description": "Figure 6 shows the mapping and tracking results of SplaTAM, a system that uses 3D Gaussian Splatting for simultaneous localization and mapping (SLAM).", "section": "III. NEURAL FIELDS FOR ROBOTICS"}, {"figure_path": "2410.20220/figures/figures_6_1.png", "caption": "Fig. 7: Network architecture of Nice-SLAM [118].", "description": "The figure illustrates the network architecture of NICE-SLAM, a method employing implicit representations for simultaneous localization and mapping.", "section": "III. NEURAL FIELDS FOR ROBOTICS\nA. Neural Fields for Pose Estimation\n1) Camera Pose Estimation"}, {"figure_path": "2410.20220/figures/figures_7_0.png", "caption": "Fig. 9: NeRF-Det's [57] 3D detection pipeline using NeRFs.", "description": "The figure illustrates the 3D object detection pipeline of NeRF-Det, showcasing its workflow from video stream input to 3D object detection and novel view rendering using Neural Radiance Fields.", "section": "III. NEURAL FIELDS FOR ROBOTICS\nA. Neural Fields for Pose Estimation"}, {"figure_path": "2410.20220/figures/figures_9_0.png", "caption": "Fig. 10: Distilled feature fields [4] distill foundation model features into a feature field along with modeling a NeRF.", "description": "Figure 10 shows the pipeline of Distilled feature fields, which distills foundation model features into a feature field and models a NeRF for language-guided manipulation.", "section": "III. NEURAL FIELDS FOR ROBOTICS"}, {"figure_path": "2410.20220/figures/figures_10_0.png", "caption": "Fig. 12: Generalizable grasping with sparse multi-view images using GraspNeRF [68].", "description": "The figure illustrates the GraspNeRF method, showing fast generalizable NeRF construction from sparse multi-view images, followed by material-agnostic grasp detection and robotic grasping in a real-world scenario.", "section": "III. NEURAL FIELDS FOR ROBOTICS\nB. Neural Fields for Robotic Manipulation"}, {"figure_path": "2410.20220/figures/figures_10_1.png", "caption": "Fig. 13: AutoNeRF generates 3D models of a scene by training NeRFs from data collected by autonomous agents.", "description": "The figure illustrates how AutoNeRF uses autonomously collected data from an exploring agent to train NeRFs and generate 3D scene models.", "section": "C. Neural Fields for Navigation"}, {"figure_path": "2410.20220/figures/figures_11_0.png", "caption": "Fig. 1: Overview: This survey paper discusses a large variety of state-of-the-art Neural Field methods that enable robotics applications in pose estimation, manipulation, navigation, physics, and autonomous driving. Images adapted from [1-12].", "description": "The figure shows an overview of the applications of Neural Fields in robotics, including pose estimation, manipulation, navigation, physics, and autonomous driving.", "section": "I. INTRODUCTION"}, {"figure_path": "2410.20220/figures/figures_11_1.png", "caption": "Fig. 15: Clip-Fields's [85] semantic representation enables 3D spatial memory for mobile robots.", "description": "The figure illustrates Clip-Fields, which uses a semantic representation to enable 3D spatial memory for mobile robots, allowing for language-guided object retrieval.", "section": "C. Neural Fields for Navigation"}, {"figure_path": "2410.20220/figures/figures_12_0.png", "caption": "Fig. 16: Differentiable Robot rendering pipeline [10].", "description": "The figure illustrates the differentiable robot rendering pipeline, showing the process from forward kinematics to appearance deformation.", "section": "III. NEURAL FIELDS FOR ROBOTICS"}, {"figure_path": "2410.20220/figures/figures_12_1.png", "caption": "Fig. 17: An overview of the different materials model-based NFs are able to simulate [89].", "description": "The figure showcases the simulation results of various material models using different neural field methods.", "section": "III-D. Neural Fields for Physics"}, {"figure_path": "2410.20220/figures/figures_13_0.png", "caption": "Fig. 18. The compositional pipeline for Street Gaussians [213].", "description": "The figure illustrates the compositional pipeline used in Street Gaussians for creating high-quality large-scale scene reconstructions in autonomous driving, combining geometry, dynamic appearance, and background models.", "section": "E. Neural Fields in Autonomous Driving"}, {"figure_path": "2410.20220/figures/figures_14_0.png", "caption": "Fig. 19: Photorealistic editing results from UniSim [92].", "description": "The figure shows a comparison of an original driving scenario and a modified scenario where a new truck has been added, illustrating UniSim's ability for photorealistic editing and closed-loop simulation for safety-critical scenarios.", "section": "E. Neural Fields in Autonomous Driving"}, {"figure_path": "2410.20220/figures/figures_14_1.png", "caption": "Fig. 20: An overview of Neural Groundplans approach. [94]", "description": "The figure illustrates the Neural Groundplans approach, showing its pipeline from input camera features to static and dynamic ground plan generation.", "section": "E. Neural Fields in Autonomous Driving"}]