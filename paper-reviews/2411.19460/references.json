{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of large language models (LLMs), introducing the concept of few-shot learning, which is central to the Video-Ma\u00b2mba model's approach."}, {"fullname_first_author": "Albert Gu", "paper_title": "Transformers are ssms: Generalized models and efficient algorithms through structured state space duality", "publication_date": "2024-05-21", "reason": "This paper introduces the Mamba architecture, which is the core of Video-Ma\u00b2mba, offering linear time and space complexity, a significant improvement over traditional transformers."}, {"fullname_first_author": "Tianqi Chen", "paper_title": "Training deep nets with sublinear memory cost", "publication_date": "2016-04-20", "reason": "This paper introduces gradient checkpointing, a crucial technique for managing memory usage in training deep learning models, which is extended by Video-Ma\u00b2mba's multi-axis approach."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper presents the CLIP model, a foundation for cross-modal learning that is used by Video-Ma\u00b2mba for vision encoding and alignment with language models."}, {"fullname_first_author": "Junho Kim", "paper_title": "Salova: Segment-augmented long video assistant for targeted retrieval and routing in long-form video analysis", "publication_date": "2024-11-29", "reason": "This paper introduces the dataset and training approach used in Video-Ma\u00b2mba, which is central to its ability to handle extended video content effectively."}]}