[{"figure_path": "https://arxiv.org/html/2501.02832/extracted/6113005/MAMBA-ASR.drawio_V1.png", "caption": "Figure 1: Architecture diagram (original) of the Samba-ASR model, illustrating the key components including the Mamba encoder, which processes raw audio features using Mamba blocks, and the Mamba decoder along with the Mamba-Cross-Connection bridge, which generates transcriptions by integrating audio context with text representations. The model\u2019s design focuses on efficient long-range dependency capture for accurate automatic speech recognition.", "description": "Figure 1 provides a detailed illustration of the Samba-ASR model's architecture. It showcases the model's key components: the Mamba encoder, responsible for processing raw audio input using Mamba blocks to extract relevant features; the Mamba decoder, which takes the processed audio features and generates text transcriptions; and a crucial Mamba-Cross-Connection bridge facilitating the integration of audio context with text representations for accurate and efficient transcription.  The architecture is designed to efficiently handle long-range dependencies in audio and text sequences for high-accuracy automatic speech recognition.", "section": "4 Samba-ASR: Architecture"}, {"figure_path": "https://arxiv.org/html/2501.02832/extracted/6113005/EpochvsLoss.png", "caption": "Figure 2: This graph shows the correlation of training and validation loss across epochs, with both losses steadily decreasing and converging around the 72nd epoch.", "description": "The figure shows two lines representing training loss and validation loss across training epochs. Both curves steadily decrease, indicating successful model training and a low risk of overfitting.  The convergence of both curves around epoch 72 suggests that the model has learned the training data effectively and its performance is generalizing well to unseen data. This visual representation supports the claim that the model training process is stable and effective.", "section": "7 Evaluation and Results"}, {"figure_path": "https://arxiv.org/html/2501.02832/extracted/6113005/EpochvsWER.png", "caption": "Figure 3: This graph demonstrates a significant reduction in Word Error Rate (WER) throughout the training process, indicating improved model performance and accuracy.", "description": "The graph in Figure 3 visually represents the Word Error Rate (WER) throughout the model's training.  The WER, a key metric in evaluating speech recognition models, shows a significant decrease as the training progresses. This downward trend illustrates the model's improvement in accuracy and performance during training.  The steady decline indicates the effectiveness of the training process and the model's ability to learn from the training data. The x-axis represents the training epochs and the y-axis represents the WER. A lower WER suggests better speech recognition performance.", "section": "7 Evaluation and Results"}]