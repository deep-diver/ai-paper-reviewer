{"references": [{"fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2023-07-04", "reason": "This reference is important as it builds upon text-to-image diffusion models, which are fundamental to the current advancements in video generation, and the current paper enhances those models for better animation."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This work is significant as it explores scaling latent video diffusion models to larger datasets, which enables generation of more realistic videos, and this is directly related to the advancements being discussed in the present paper."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-01-01", "reason": "This paper is important because it investigates video generation models and their ability to act as world simulators, contributing to the broader understanding and advancements in the field."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper is highly relevant as it discusses diffusion models with transformers, which is the underlying model architecture for many advanced video generation techniques, including the approach in the current paper."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the transformer architecture and the attention mechanism, foundational concepts for the video diffusion models discussed in the current study."}]}