[{"figure_path": "2410.13785/figures/figures_1_0.png", "caption": "Figure 1: Illustration of the effects of alignment considering the contrasting patterns. \u03c0ref denotes the distribution of the reference model under pattern i. \u03c0dpoi denotes the overall distribution of the model after DPO alignment on pattern i.", "description": "The figure illustrates how aligning models on limited contrasting patterns may not improve overall distribution, while diversifying patterns leads to more comprehensive gains.", "section": "1 Introduction"}, {"figure_path": "2410.13785/figures/figures_3_0.png", "caption": "Figure 2: The workflow of PopAlign. PopAlign involves three kinds of contrasting strategies: (1) Prompt Contrast such as Prefix Contrast, Demon Contrast (i.e., Demonstration Contrast, and Elicitive Contrast), (2) Model Contrast such as NParam (number of parameters) Contrast and Leaderboard Contrast, as well as (3) Pipeline Contrast such as Refinement Contrast. By mixing the preference data synthesized with diverse contrasting strategies and conducting DPO alignment training on it, we can easily align the LLM without either human annotation or reward labeling.", "description": "The figure illustrates the workflow of PopAlign, a framework that integrates six contrasting strategies across three levels (prompt, model, pipeline) to synthesize preference data for LLM alignment.", "section": "2 PopAlign"}]