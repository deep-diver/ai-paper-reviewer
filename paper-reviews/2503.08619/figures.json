[{"figure_path": "https://arxiv.org/html/2503.08619/x2.png", "caption": "Figure 1: Overview of LightGen\u2019s capabilities in image generation, zero-shot inpainting, and resource usage. (First Row) Images generated at multiple resolutions (512\u00d7512512512512\\times 512512 \u00d7 512 and 1024\u00d71024102410241024\\times 10241024 \u00d7 1024) illustrate the scalability of LightGen. (Second Row) Zero-shot inpainting results showcasing LightGen\u2019s inherent editing ability. (Third Row) LightGen\u2019s resource consumption with drastically reduced dataset size, model parameters, and GPU hours compared to state-of-the-art models, demonstrates significant cost reductions without sacrificing performance.", "description": "Figure 1 demonstrates LightGen's capabilities in image generation, zero-shot inpainting, and efficient resource utilization. The first row showcases images generated at 512x512 and 1024x1024 resolutions, highlighting LightGen's scalability. The second row presents zero-shot inpainting results, demonstrating its ability to seamlessly edit images. The third row compares LightGen's resource consumption (dataset size, model parameters, and GPU hours) against state-of-the-art models.  LightGen achieves comparable performance with significantly reduced resource requirements, showcasing its efficiency and cost-effectiveness.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.08619/extracted/6271669/fig/figure3.png", "caption": "Figure 2: Overview of LightGen efficient pretraining. (a) Training: Images are encoded into tokens via a pre-trained tokenizer, while text embeddings from a T5 encoder are refined by a trainable aligner. A masked autoencoder uses text tokens as queries/values and image tokens as keys for cross-attention, followed by refinement with a Diffusion MLP (D-MLP). (b) Inference: Tokens are predicted and iteratively refined over N\ud835\udc41Nitalic_N steps, then decoded by the image tokenizer to generate final images.", "description": "This figure illustrates the LightGen model's training and inference pipelines.  (a) Training:  The process begins by encoding images into tokens using a pre-trained tokenizer. Simultaneously, text embeddings are generated from a T5 encoder and refined using a trainable aligner to ensure alignment with the image content. A masked autoencoder then processes these text and image tokens, utilizing a cross-attention mechanism where text tokens serve as queries and values, and image tokens as keys. This cross-attention step helps to integrate textual context into the image generation process. Finally, a Diffusion Multi-Layer Perceptron (D-MLP) refines the generated tokens further. (b) Inference:  The inference pipeline takes as input a text prompt, which is processed as in the training stage. The model then iteratively predicts and refines tokens over N steps, with each step leveraging the previously generated tokens to progressively improve the image's quality. After the refinement stage, the tokens are decoded using the image tokenizer to produce the final generated image.", "section": "4. LightGen Pipeline"}, {"figure_path": "https://arxiv.org/html/2503.08619/x3.png", "caption": "Figure 3: Illustrate of DPO Post-processing of LightGen.", "description": "This figure illustrates the Direct Preference Optimization (DPO) post-processing stage in LightGen.  DPO aims to refine the quality of images generated by LightGen by minimizing the difference between the generated image and a high-quality reference image. The process involves adding noise to both the generated and reference images, then using a learned preference model to guide the refinement of the generated image towards the reference image.  The steps show the iterative process of adding noise, applying the MAR model, and then calculating the DPO loss to guide the optimization.  This process enhances image fidelity and positional accuracy, particularly addressing limitations inherent in synthetic data.", "section": "4.2. Post-processing"}, {"figure_path": "https://arxiv.org/html/2503.08619/extracted/6271669/fig/figure5.png", "caption": "Figure 4: Visualization Results. Sample outputs generated using LightGen, showcasing high-quality images at multiple resolutions (256\u00d7256256256256\\times 256256 \u00d7 256, 512\u00d7512512512512\\times 512512 \u00d7 512, 1024\u00d71024102410241024\\times 10241024 \u00d7 1024) and across diverse styles (realistic, animated, virtual, etc.), which demonstrate the versatility and scalability of our approach.", "description": "Figure 4 presents sample images generated by the LightGen model, demonstrating its ability to produce high-quality outputs across various resolutions (256x256, 512x512, and 1024x1024 pixels) and artistic styles (realistic, animated, and virtual).  The diverse examples showcase the model's versatility and scalability in handling different image generation tasks.", "section": "5. Main Results"}, {"figure_path": "https://arxiv.org/html/2503.08619/x4.png", "caption": "Figure 5: Image inpainting demonstrations.", "description": "This figure showcases the inpainting capabilities of the LightGen model.  It demonstrates the model's ability to seamlessly fill in missing or damaged regions of an image while maintaining the overall context and style.  Multiple examples are shown to illustrate the versatility of the model in handling various types of images and levels of damage.", "section": "5. Main Results"}, {"figure_path": "https://arxiv.org/html/2503.08619/x5.png", "caption": "Figure 6: Ablation studies. (a) Pre-train in different data scales, we find it achieves the limitation when pre-train in \ud835\udcaa\u2062(1\u2062M)\ud835\udcaa1\ud835\udc40\\mathcal{O}(1M)caligraphic_O ( 1 italic_M ) data scale. (b) demonstrate different iteration results.", "description": "Figure 6 presents the results of ablation studies conducted to analyze the impact of dataset size and training iterations on LightGen's performance.  Panel (a) shows the effect of varying the size of the pre-training dataset.  It demonstrates that model performance plateaus when the pre-training dataset reaches approximately 1 million images, suggesting that increasing data size beyond this point yields diminishing returns.  Panel (b) illustrates how different numbers of training iterations affect the model's performance. The results indicate the training efficiency of the model.", "section": "5. Experiment"}]