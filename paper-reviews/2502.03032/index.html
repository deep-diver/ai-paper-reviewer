<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Analyze Feature Flow to Enhance Interpretation and Steering in Language Models &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="Analyze Feature Flow to Enhance Interpretation and Steering in Language Models &#183; HF Daily Paper Reviews by AI"><meta name=description content="Researchers unveil a data-free method to visualize and control feature flow in LLMs, enhancing interpretability and enabling targeted model steering."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ T-Tech,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="Analyze Feature Flow to Enhance Interpretation and Steering in Language Models"><meta property="og:description" content="Researchers unveil a data-free method to visualize and control feature flow in LLMs, enhancing interpretability and enabling targeted model steering."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-02-05T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-05T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ T-Tech"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/cover.png"><meta name=twitter:title content="Analyze Feature Flow to Enhance Interpretation and Steering in Language Models"><meta name=twitter:description content="Researchers unveil a data-free method to visualize and control feature flow in LLMs, enhancing interpretability and enabling targeted model steering."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Analyze Feature Flow to Enhance Interpretation and Steering in Language Models","headline":"Analyze Feature Flow to Enhance Interpretation and Steering in Language Models","abstract":"Researchers unveil a data-free method to visualize and control feature flow in LLMs, enhancing interpretability and enabling targeted model steering.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2502.03032\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-02-05T00:00:00\u002b00:00","datePublished":"2025-02-05T00:00:00\u002b00:00","dateModified":"2025-02-05T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ T-Tech"],"mainEntityOfPage":"true","wordCount":"5882"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About This Project">About</p></a><a href=/ai-paper-reviewer/2025-02-12/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-12s>2025-02-12</p></a><a href=/ai-paper-reviewer/2025-02-13/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-13s>2025-02-13</p></a><a href=/ai-paper-reviewer/2025-02-14/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=2025-02-14s>2025-02-14</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Paper Reviews by AI">Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About This Project">About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-12/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-12s>2025-02-12</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-13/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-13s>2025-02-13</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-14/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=2025-02-14s>2025-02-14</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Paper Reviews by AI">Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2502.03032/cover_hu_4ccbfe7338f34c41.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2502.03032/>Analyze Feature Flow to Enhance Interpretation and Steering in Language Models</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Analyze Feature Flow to Enhance Interpretation and Steering in Language Models</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-02-05T00:00:00+00:00>5 February 2025</time><span class="px-2 text-primary-500">&#183;</span><span>5882 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">28 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2502.03032/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2502.03032/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-t-tech/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ T-Tech</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu_97e7d424fadd1c26.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#cross-layer-feature-flow>Cross-Layer Feature Flow</a></li><li><a href=#multi-layer-steering>Multi-Layer Steering</a></li><li><a href=#sae-feature-matching>SAE Feature Matching</a></li><li><a href=#linear-feature-circuits>Linear Feature Circuits</a></li><li><a href=#model-interpretability>Model Interpretability</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#cross-layer-feature-flow>Cross-Layer Feature Flow</a></li><li><a href=#multi-layer-steering>Multi-Layer Steering</a></li><li><a href=#sae-feature-matching>SAE Feature Matching</a></li><li><a href=#linear-feature-circuits>Linear Feature Circuits</a></li><li><a href=#model-interpretability>Model Interpretability</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2502.03032</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Daniil Laptev et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-02-07</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2502.03032 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2502.03032 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2502.03032/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large language models (LLMs) are powerful but opaque. Understanding how semantic information is processed within them is crucial for enhancing their interpretability and control. Existing methods often struggle with the complexity of multi-layer interactions, limiting our ability to analyze and influence feature development. This research tackles this issue by focusing on the dynamics of features across multiple layers.</p><p>The proposed approach utilizes sparse autoencoders (SAEs) to track features across different layers of the LLM, creating &ldquo;flow graphs.&rdquo; These graphs visually represent how features originate, evolve, and eventually disappear. The researchers demonstrate how manipulating these features through the flow graphs allows for direct and targeted control over the LLM&rsquo;s output, such as amplifying or suppressing specific themes in text generation. This technique significantly improves our capacity to understand and control LLMs&rsquo; behavior.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-40e97cff54afe411346c32993d766f83></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-40e97cff54afe411346c32993d766f83",{strings:[" A novel data-free approach maps feature evolution across LLM layers, providing insights into model computations. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-a49bc669872d7ef806ed86fa3a9ec77a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-a49bc669872d7ef806ed86fa3a9ec77a",{strings:[" Cross-layer feature maps allow for direct model steering by amplifying or suppressing specific features. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-b61d57027379f1c05c6954e24cf6faa3></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-b61d57027379f1c05c6954e24cf6faa3",{strings:[" The method clarifies how features develop through forward passes and offers transparent manipulation of LLMs. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial because <strong>it introduces a novel data-free approach to understand and manipulate the inner workings of large language models (LLMs)</strong>. This is a significant step towards making LLMs more interpretable, controllable, and reliable, which addresses a key challenge in the field and opens doors for safer and more effective AI systems. The proposed methods offer unique insights into feature evolution, enabling more precise control over model behavior and facilitating the discovery of computational circuits. This will be highly impactful for researchers aiming to improve model transparency and address issues like bias and toxicity.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x1.png alt></figure></p><blockquote><p>üîº This figure illustrates the method for inner-layer feature matching. It shows how a feature (represented by its embedding vector) from one layer of a language model is compared to features from other layers and modules (MLP, Attention, Residual Stream) using cosine similarity to find its source. The figure shows that features are identified on the layer outputs, and each feature embedding is compared against all feature embeddings in the MLP and attention blocks of that layer, and also against features from the previous layer&rsquo;s residual stream. The comparisons determine which modules and preceding layers most influenced the identified feature.</p><details><summary>read the caption</summary>Figure 1: Schematic illustration of inner-layer matching. We select a feature with index iùëñiitalic_i on the SAE trained at the layer output. Its embedding ùêüùêü\mathbf{f}bold_f, which is the iùëñiitalic_ith column of this SAE‚Äôs decoder weight, is compared to every column of other SAEs on the same layer (after the MLP and attention blocks, as well as with the SAE on the residual stream before some layer). These comparisons indicate the feature‚Äôs source. See Section 3.3 for more details.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A2.T1.1><thead class=ltx_thead><tr class=ltx_tr id=A2.T1.1.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=A2.T1.1.1.1.1>Feature index</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A2.T1.1.1.1.2>Interpretation from Neuronpedia</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A2.T1.1.2.1><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id=A2.T1.1.2.1.1>3/res/9811</th><td class="ltx_td ltx_align_left ltx_border_t" id=A2.T1.1.2.1.2>terms related to gravity and its influences</td></tr><tr class=ltx_tr id=A2.T1.1.3.2><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.3.2.1>18/res/14053</th><td class="ltx_td ltx_align_left" id=A2.T1.1.3.2.2>terms related to theoretical frameworks and conceptual models</td></tr><tr class=ltx_tr id=A2.T1.1.4.3><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.4.3.1>18/res/1336</th><td class="ltx_td ltx_align_left" id=A2.T1.1.4.3.2>references to Dark Matter and astronomical phenomena</td></tr><tr class=ltx_tr id=A2.T1.1.5.4><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.5.4.1>20/res/4506</th><td class="ltx_td ltx_align_left" id=A2.T1.1.5.4.2>terms related to physical laws and scientific principles</td></tr><tr class=ltx_tr id=A2.T1.1.6.5><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.6.5.1>21/res/13226</th><td class="ltx_td ltx_align_left" id=A2.T1.1.6.5.2>references to quantum concepts and theories</td></tr><tr class=ltx_tr id=A2.T1.1.7.6><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.7.6.1>22/res/9002</th><td class="ltx_td ltx_align_left" id=A2.T1.1.7.6.2>terms related to models and their specifications,</td></tr><tr class=ltx_tr id=A2.T1.1.8.7><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.8.7.1>22/res/15105</th><td class="ltx_td ltx_align_left" id=A2.T1.1.8.7.2>terms related to force and energy dynamics</td></tr><tr class=ltx_tr id=A2.T1.1.9.8><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.9.8.1>23/res/4086</th><td class="ltx_td ltx_align_left" id=A2.T1.1.9.8.2>terms related to forces and dynamics in physical systems</td></tr><tr class=ltx_tr id=A2.T1.1.10.9><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A2.T1.1.10.9.1>24/res/7017</th><td class="ltx_td ltx_align_left" id=A2.T1.1.10.9.2>terms related to electromagnetic interactions and properties</td></tr><tr class=ltx_tr id=A2.T1.1.11.10><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id=A2.T1.1.11.10.1>24/res/14548</th><td class="ltx_td ltx_align_left ltx_border_bb" id=A2.T1.1.11.10.2>terms and references related to particle physics and standard model parameters</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the features initially selected for the deactivation experiment targeting the theme of &lsquo;Scientific concepts and entities&rsquo;. Each row represents a feature, identified by its layer, module (residual, MLP, or attention), and index within that module. The &lsquo;Interpretation&rsquo; column provides a brief description of the semantic meaning of each feature according to the Neuronpedia, a tool for interpreting neural network activations. These features were chosen as they were associated with the &lsquo;Scientific concepts and entities&rsquo; theme according to Neuronpedia. The experiment involved deactivating these features in order to investigate their effect on the model&rsquo;s text generation, helping to understand causal relations between model features and their semantic effect.</p><details><summary>read the caption</summary>Table 1: Features initially chosen for deactivation of ‚ÄúScientific concepts and entities‚Äù theme.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Cross-Layer Feature Flow<div id=cross-layer-feature-flow class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#cross-layer-feature-flow aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;Cross-Layer Feature Flow&rsquo; in the context of analyzing large language models (LLMs) offers a powerful approach to understanding how features evolve and interact throughout the network&rsquo;s layers. It moves beyond the limitations of single-layer analysis by tracking the lifespan of features, revealing how they originate, transform, and even vanish as they propagate through different modules like MLPs and attention mechanisms. <strong>This cross-layer perspective provides crucial mechanistic insights</strong>, revealing not only how features develop but also highlighting the formation of computational circuits, pathways where features influence each other across layers. <strong>The ability to map feature evolution using a data-free technique like cosine similarity between sparse autoencoder (SAE) features</strong>, greatly enhances interpretability. Furthermore, understanding the flow graph opens the door to direct model steering, enabling targeted thematic control by amplifying or suppressing specific features across multiple layers. This facilitates more precise, transparent manipulation of LLMs, leading to improved control over the model&rsquo;s behavior and increased understanding of its inner workings. Overall, <strong>the study of Cross-Layer Feature Flow offers a significant advance in causal interpretability and control of LLMs.</strong></p><h4 class="relative group">Multi-Layer Steering<div id=multi-layer-steering class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#multi-layer-steering aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Multi-Layer Steering&rdquo; in the context of large language models (LLMs) presents a significant advancement in controlling model behavior. Instead of manipulating features within a single layer, this approach leverages a <strong>causal, cross-layer interpretability framework</strong> to trace the evolution of features across multiple layers. This allows for more precise control by either <strong>amplifying or suppressing specific features</strong>, enabling targeted thematic control in text generation. By identifying interconnected features across layers, this approach provides a better understanding of how model computations unfold and enhances the effectiveness of steering interventions. <strong>Multi-layer steering is superior to single-layer steering</strong> as it accounts for the complex interplay between features and their propagation across the neural network&rsquo;s depth. Furthermore, it offers the potential for <strong>discovering computational circuits</strong>, identifying interconnected pathways in the model. This framework moves beyond simple feature manipulation to provide a more nuanced and effective means to guide the model&rsquo;s behavior, making LLMs significantly more transparent and controllable.</p><h4 class="relative group">SAE Feature Matching<div id=sae-feature-matching class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#sae-feature-matching aria-label=Anchor>#</a></span></h4><p>SAE (Sparse Autoencoder) feature matching is a crucial technique for analyzing the flow of interpretable features across layers in large language models. It leverages the <strong>sparse representations</strong> learned by SAEs to identify corresponding features across different layers and modules, thus revealing how these features evolve and interact throughout the model&rsquo;s computation. The core idea is to use a similarity metric (e.g., cosine similarity) between the decoder weights of SAEs trained at different layers to find matching features. This allows for the construction of cross-layer feature flow graphs that provide insights into the model&rsquo;s internal mechanisms. This approach is <strong>data-free</strong>, meaning it doesn&rsquo;t require any additional training data beyond what was used to train the original model and SAEs, making it computationally efficient. Effective SAE feature matching is vital for enhancing model interpretability, enabling a deeper understanding of model behavior, and facilitating targeted model steering. <strong>Challenges</strong> in this process may involve choosing appropriate similarity metrics, handling feature sparsity, and addressing potentially noisy matches due to model complexity. The success of SAE feature matching hinges upon the quality of the trained SAEs; the degree of feature disentanglement impacts the clarity and reliability of identified matches.</p><h4 class="relative group">Linear Feature Circuits<div id=linear-feature-circuits class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#linear-feature-circuits aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Linear Feature Circuits&rdquo; in large language models (LLMs) suggests that <strong>model computations can be decomposed into smaller, interconnected subnetworks</strong>. These circuits, characterized by linear transformations of features, represent specific operations or semantic processing steps. Understanding these circuits is crucial for <strong>enhancing interpretability</strong>, as it allows us to trace the flow of information and how features evolve throughout the model&rsquo;s layers. <strong>Identifying linear feature circuits</strong> can also greatly improve <strong>model steering</strong>, providing more granular control over LLM output. This method would allow researchers to modify the behavior of the model by selectively activating or suppressing specific features within these circuits. Further research into this area would reveal potential <strong>mechanistic insights</strong> into how LLMs process information, leading to advancements in the development of more efficient, controllable, and interpretable AI systems.</p><h4 class="relative group">Model Interpretability<div id=model-interpretability class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#model-interpretability aria-label=Anchor>#</a></span></h4><p>Model interpretability is a crucial aspect of research, particularly in the context of large language models (LLMs). <strong>Understanding how LLMs arrive at their outputs</strong> is vital for building trust, identifying biases, and improving model performance. This research explores interpretability by mapping features through the model&rsquo;s layers using sparse autoencoders (SAEs). <strong>SAEs help isolate interpretable features</strong>, allowing researchers to trace their evolution across multiple layers and various model components (MLP, attention). This cross-layer analysis reveals how features originate, transform, or disappear, providing <strong>fine-grained insights into internal computations</strong>. The research goes beyond simple analysis, demonstrating how understanding feature flow enables direct model steering by amplifying or suppressing specific features to achieve targeted thematic control in text generation. This demonstrates a strong connection between interpretability and <strong>controllability of LLMs</strong>. The data-free approach used, relying on cosine similarity between SAE decoder weights, makes the analysis scalable and widely applicable. Overall, the findings highlight the importance of a causal, multi-layer interpretability framework for both understanding and controlling LLMs. The creation of flow graphs offers a novel way to visualize this feature evolution, opening new avenues for research and development of more explainable and controllable AI systems.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x2.png alt></figure></p><blockquote><p>üîº This figure shows a flow graph that visualizes how a specific feature (index 14548) in the 24th residual layer of a large language model evolves across different layers and modules. The graph illustrates the feature&rsquo;s origin, its propagation through the model&rsquo;s architecture (MLP, attention, residual streams), and how it transforms or interacts with other features. Nodes represent features identified by sparse autoencoders (SAEs), and edges indicate relationships between features across layers. This visualization is used in the deactivation experiments (Section 5.2) to understand the causal relationships between features and their effect on downstream model behavior. More details are provided in Appendix E.</p><details><summary>read the caption</summary>Figure 2: An illustration of the resulting flow graph, which we also use in the deactivation experiment (section 5.2). As a starting point, we select the feature on the 24th-layer residual with index 14548. For a detailed explanation of this graph, see Appendix E.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x3.png alt></figure></p><blockquote><p>üîº This figure displays the results of an experiment comparing cosine similarity between a target feature and its predecessors (features from the previous layer, MLP, and attention modules) with their simultaneous activation. The data shows distinct patterns of simultaneous activation for different groups of features. Specifically, features grouped as &lsquo;From MLP&rsquo; show high similarity to MLP predecessors and low similarity to residual stream predecessors, indicating that these features are primarily processed by the MLP module. In contrast, features in the &lsquo;From RES&rsquo; group exhibit the opposite pattern, suggesting that these features originate from and are primarily propagated through the residual stream. This analysis demonstrates that cosine similarity between a feature and its predecessors serves as a strong indicator of their relationship (i.e., shared semantic and mechanistic properties). The experiment involved sampling 350 features per layer, highlighting the large-scale nature of the analysis and its relevance to understanding the complex computational behavior within a large language model.</p><details><summary>read the caption</summary>Figure 3: Example of cosine similarity vs. simultaneous activation with a predecessor (350 features were sampled per layer). ‚ÄúFrom MLP‚Äù and ‚ÄúFrom RES‚Äù groups are notably different: high s(M)superscriptùë†ùëÄs^{(M)}italic_s start_POSTSUPERSCRIPT ( italic_M ) end_POSTSUPERSCRIPT and low s(R)superscriptùë†ùëÖs^{(R)}italic_s start_POSTSUPERSCRIPT ( italic_R ) end_POSTSUPERSCRIPT suggest simultaneous activation with an MLP-module match. Cosine similarity serves as a good proxy for shared semantic and mechanistic properties.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x4.png alt></figure></p><blockquote><p>üîº This figure displays the results of a statistical analysis comparing the similarity scores of different groups of features based on their activation patterns in different modules (MLP, Attention, Residual) of a transformer layer. The analysis determines whether the similarity scores between feature groups are statistically significantly different. The groups are categorized by whether a specific module is active (A) or inactive (I) in both groups (AB, IB) or only one group (AO). The figure visualizes the percentage of statistically significant differences (p&lt;0.001) for each module, revealing the relationships between feature activation and similarity scores. For instance, it shows that for MLP, there is an 87% probability that two feature groups will have statistically different s(R) scores when MLP is active in both groups.</p><details><summary>read the caption</summary>Figure 4: Percentage of statistically significant differences between groups for each module‚Äôs similarity scores. AO means module PùëÉPitalic_P is active in only one group, AB means active in both, and IB means inactive in both. For MLP, two groups differ in s(R)superscriptùë†ùëÖs^{(R)}italic_s start_POSTSUPERSCRIPT ( italic_R ) end_POSTSUPERSCRIPT only 87% of the time when MLP is active in both groups.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x5.png alt></figure></p><blockquote><p>üîº This figure visualizes the distribution of feature groups across different layers of the Gemma 2-2B language model. Each group represents how features originate: from a previous layer&rsquo;s residual stream, from the MLP (Multi-Layer Perceptron) module, from the attention module, or from a combination of these sources. The percentages in the chart illustrate the proportion of features in each category at each layer. This provides insights into the dynamic process of feature emergence and transformation as information flows through the model&rsquo;s layers.</p><details><summary>read the caption</summary>Figure 5: Percentages of each group at each layer of Gemma¬†2‚Äâ2B, illustrating how feature formation proceeds in the model.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x6.png alt></figure></p><blockquote><p>üîº This figure compares different methods for deactivating features in a language model to analyze causal relationships. The x-axis represents different groups of features, categorized by which predecessor features were deactivated before evaluating the impact on the target feature. The y-axis shows the percentage of successful deactivations for each group. The &lsquo;random&rsquo; approach serves as a baseline, randomly choosing a predecessor to deactivate. The other methods, such as &rsquo;top-1&rsquo;, select the most similar predecessor based on cosine similarity. The results demonstrate that the &rsquo;top-1&rsquo; method significantly outperforms the &lsquo;random&rsquo; method, suggesting that selecting the most similar predecessor is a more effective strategy for revealing causal links between features.</p><details><summary>read the caption</summary>Figure 6: Deactivation methods compared. Group labels show which active predecessors were deactivated. The random approach underperforms, suggesting that choosing the top1subscripttop1\operatorname{top}_{1}roman_top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT feature is already meaningful for causal analysis.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x7.png alt></figure></p><blockquote><p>üîº This figure displays the average changes in activation strength for target features when one of their predecessor features is deactivated. The results show that deactivating a single predecessor feature has a more significant impact when that predecessor feature is the only active one. When multiple predecessor features are simultaneously activated, deactivating one of them has a smaller impact on the target feature. This suggests that multiple predecessor features might be part of a larger circuit, such that deactivating just one does not disrupt the overall circuit functionality. The findings indicate that the model&rsquo;s behavior is not solely dependent on single features, but rather groups of features working together in interconnected ways.</p><details><summary>read the caption</summary>Figure 7: Mean activation changes when deactivating one predecessor at a time. Deactivation of some predecessor causes less impact if this predecessor is not activated alone, which leads to the conclusion that combined groups exhibit circuit-like behavior.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x8.png alt></figure></p><blockquote><p>üîº Figure 8 illustrates the impact of the rescaling coefficient (r) on the success rate of deactivating features in a language model. The x-axis represents different values of r, while the y-axis shows the resulting activation change. When r is less than 1 (meaning the features are being suppressed), the activation change demonstrates nonlinear growth. This nonlinearity suggests that even when a direct causal predecessor is deactivated, alternative pathways might still allow the feature to remain active, thus conveying information. The graph also displays the relative loss change, which is calculated as (Lnew - Lold) / Lold and serves as a proxy to assess the impact on the model&rsquo;s forward pass during the deactivation process.</p><details><summary>read the caption</summary>Figure 8: Impact of different rùëüritalic_r values on deactivation success, with rescaling of all available predecessors. When r<1ùëü1r<1italic_r < 1, the activation change grows nonlinearly, indicating alternative causal pathways still convey information. Relative loss change measured as (Lnew‚àíLold)/Loldsubscriptùêønewsubscriptùêøoldsubscriptùêøold(L_{\text{new}}-L_{\text{old}})/L_{\text{old}}( italic_L start_POSTSUBSCRIPT new end_POSTSUBSCRIPT - italic_L start_POSTSUBSCRIPT old end_POSTSUBSCRIPT ) / italic_L start_POSTSUBSCRIPT old end_POSTSUBSCRIPT is a proxy for forward pass impact.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x9.png alt></figure></p><blockquote><p>üîº Figure 9 illustrates an experiment on deactivating the &lsquo;Scientific concepts and entities&rsquo; theme in text generation. The graph displays the impact of different rescaling coefficients (r) applied at various layers of a language model on both the coherence and presence of the target theme in generated text. The dashed black line represents the baseline generation quality without any intervention. Red data points highlight the layer where the deactivation strategy achieves the best results for each value of r. The results show that increasing the rescaling coefficient (r) improves the effectiveness of theme suppression, although the optimal layer for intervention shifts to earlier layers as r increases.</p><details><summary>read the caption</summary>Figure 9: Deactivating the ‚ÄúScientific concepts and entities‚Äù theme. The dashed black line shows the default generation score. Red points mark the best layer for each rùëüritalic_r in the single-layer method. Larger rùëüritalic_r boosts performance but shifts the optimal layer earlier.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x10.png alt></figure></p><blockquote><p>üîº Figure 10 displays the results of an experiment comparing different model steering strategies. The goal was to deactivate a specific theme in text generation. The green line represents a baseline where only the initially identified features related to the theme were deactivated. The orange and blue lines show the results when multiple layers of features were targeted for deactivation (multi-layer interventions). The x-axis likely represents different layers of the model and the y-axis likely shows a performance metric (a combination of metrics that capture the balance between successfully removing the unwanted theme and maintaining text quality). Across different values of the hyperparameter <em>r</em> (presumably controlling the strength of the deactivation), the multi-layer strategies consistently outperformed the single-layer strategy. This suggests that including additional, related features discovered via the flow graph analysis improves the robustness and effectiveness of the deactivation process, reducing sensitivity to the specific value of the hyperparameter.</p><details><summary>read the caption</summary>Figure 10: Comparison of best deactivation scores. The green line indicates deactivation using only the initial feature set. Multi-layer interventions (orange, blue) perform better across different rùëüritalic_r values, suggesting additional discovered features reduce hyperparameter sensitivity.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x11.png alt></figure></p><blockquote><p>üîº This figure displays the results of an experiment on activating specific topics in text generation using a language model. Three different rescaling strategies (detailed in Appendix B) were applied to both single-layer and cumulative steering approaches. The results show that activating multiple similar features effectively amplifies the presence of the target topic in the generated text. However, this improvement in topic presence sometimes comes at the cost of reduced text coherence, indicating a trade-off between targeted topic emphasis and overall text quality.</p><details><summary>read the caption</summary>Figure 11: Activation of specific topics. We compare single-layer steering and cumulative approaches with three rescaling strategies (Appendix¬†B). Activating multiple similar features amplifies a topic‚Äôs presence but may degrade overall text coherence.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x12.png alt></figure></p><blockquote><p>üîº Figure 12 presents a detailed analysis of feature group distribution and score distribution across different layers of a language model. Part (a) shows the percentage of features falling into each of the eight identified groups (based on their predecessor activations) for four different datasets: FineWeb, TinyStories, Python Code, and AutoMathText. This visualization helps to understand how the origin and development of features vary depending on dataset characteristics. Part (b) provides a comparative analysis of score distributions for layers 8 and 18 across these feature groups, showing the distinct patterns of score distribution for each group. The clear separation between these distributions visually validates the proposed approach for identifying feature origins and tracking their evolution across layers.</p><details><summary>read the caption</summary>Figure 12: (a) Percentage of feature groups obtained for each dataset. (b) Distribution of scores for layers 8 and 18. We observe a clear distinction between groups, which additionally indicates the validity of the proposed method.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x13.png alt></figure></p><blockquote><p>üîº This figure shows a matrix representing the probability of features originating from a specific group (e.g., &lsquo;From ATT&rsquo;, &lsquo;From RES&rsquo;, etc.) at one layer, to subsequently appear in another group at a later layer. Each cell (i,j) in the matrix shows the probability of a feature belonging to group &lsquo;i&rsquo; at some layer appearing in group &lsquo;j&rsquo; at a later layer in the model&rsquo;s processing. The rows represent the starting group, while the columns represent the resulting group after propagating through multiple layers. A high value indicates a strong likelihood of transition from the source group to the target group. The high probabilities on the diagonal reflect features that persist through layers. The &lsquo;From Nowhere&rsquo; group represents features that appear without a clear preceding origin.</p><details><summary>read the caption</summary>Figure 13: Probability of group A (row) to appear in group B (column), aggregated over all layers. For example, if we take the ‚ÄúFrom ATT‚Äù group, then with a probability of 0.45, features from this group would appear in the ‚ÄúFrom RES & ATT‚Äù group. High scores for the ‚ÄúFrom nowhere‚Äù group represent its stochasticity.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x14.png alt></figure></p><blockquote><p>üîº This figure displays the results of Mann-Whitney U tests comparing the distributions of similarity scores (cosine similarity between decoder weights) across different groups of features. Each group represents a combination of activated predecessor features (from the previous layer, MLP, or attention). The figure shows the percentage of tests that yielded statistically significant results (p&lt;0.001) for each pair of groups across different layers and datasets. This visualizes which groups of features exhibit distinct similarity score distributions, suggesting differences in their origins and relationship to predecessors.</p><details><summary>read the caption</summary>Figure 14: Percentage of statistically significant differences between groups with respect to a certain score.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x15.png alt></figure></p><blockquote><p>üîº This figure presents a comparison of four different methods for identifying feature predecessors in a language model. Subplot (a) shows the percentage of features assigned to each of the eight possible predecessor groups (e.g., &lsquo;From RES&rsquo;, &lsquo;From MLP & ATT&rsquo;) for each of the four matching methods (random, permutation, top1, top5). The top5 method, which considers the top 5 most similar predecessors, identifies significantly more features belonging to combined groups (e.g., &lsquo;From RES & MLP&rsquo;) than the other methods. Subplot (b) further examines the effects of deactivating a predecessor feature. For each of the eight predecessor groups, it shows the probability of a feature originally belonging to that group transitioning to a different group after deactivation. Each bar represents the percentage of times a feature changes group after deactivation.</p><details><summary>read the caption</summary>Figure 15: (a) Percentage of features per each method. There was a total of 13106 activated features, and for every feature, four matching strategies were applied. We see that top5subscripttop5\operatorname{top}_{5}roman_top start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT method detects many more combined groups than other methods, especially ‚ÄúFrom RES & MLP‚Äù. (b) Probability for a feature from some group Aùê¥Aitalic_A (labeled as the subplot title) to become from group BùêµBitalic_B (shown in legend) after deactivation of some predecessor. Each bar shows the percentage of times the feature falls into a new category.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x16.png alt></figure></p><blockquote><p>üîº This figure presents the results of a model steering experiment. The researchers selected features from specific layers of a language model&rsquo;s flow graph, and then applied four different steering strategies to these features. The experiment aimed to determine the optimal layer for intervention to achieve the best results in terms of the model&rsquo;s ability to generate text aligning with a specific theme. The bar chart displays the best performance attained by each steering strategy across various layers, showing that steering at layers other than layer 12 can sometimes yield better results.</p><details><summary>read the caption</summary>Figure 16: From each flow graph, we select features on a particular layer lùëôlitalic_l and perform steering with the four different strategies. Bars represent the best result for each layer among all scores sùë†sitalic_s. In some cases, steering on a layer other than 12 may improve results.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x17.png alt></figure></p><blockquote><p>üîº This figure visualizes the results of an experiment on model steering, focusing on the theme of &lsquo;Research methodology and experimentation&rsquo;. Part (a) shows the number of features selected for activation across different layers of the model. Vertical lines indicate the initial features selected for this theme. Part (b) presents the results of the model steering process itself, showing the total score achieved (Behavioral score multiplied by Cumulative score) for different steering strategies. The key observation is that while the initial features were not located on layer 5, steering at layer 5 produced the best overall result, suggesting that optimal steering may not always align with the location of initially selected features.</p><details><summary>read the caption</summary>Figure 17: (a) Amount of features selected for activation of ‚ÄúResearch methodology and experimentation‚Äù theme. Vertical lines represent the placement of the initially selected features. (b) Results for steering of selected features. Score is a total metric measured as Behavioral√óCumulativeBehavioralCumulative\text{Behavioral}\times\text{Cumulative}Behavioral √ó Cumulative. We can see that despite none of the initial features being placed on the 5th layer, it gives us the best result.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x18.png alt></figure></p><blockquote><p>üîº Figure 18 compares the distribution of feature groups and their cosine similarity scores between LlamaScope and GemmaScope models. Panel (a) shows that LlamaScope has a much smoother distribution of feature groups compared to GemmaScope (Figure 12), likely due to differences in model architecture, SAE training, or data distribution. Panel (b) demonstrates that LlamaScope exhibits a similar layer-wise pattern of feature group distribution to GemmaScope (Figure 5), suggesting shared underlying properties. Panels (c) and (d) further illustrate these similarities and differences, showing that while LlamaScope&rsquo;s feature groups are less distinct in terms of cosine similarity compared to GemmaScope (Figure 12), the groups are still distinguishable.</p><details><summary>read the caption</summary>Figure 18: (a) Distribution of groups for Llama Scope. We observe a clear distinction from Gemma Scope results (Figure 12) due to a much smoother distribution. This may be a consequence of various factors: the architecture of the models or SAEs, the training procedure, differences in data distribution, etc. (b) Distribution of groups across multiple layers. We observe approximately the same pattern as for Gemma Scope (Figure 5), indicating shared properties between the models. (c) Distribution of scores for different groups. We see that the groups are slightly less distinct from each other compared to the case of Gemma Scope (Figure 12), but they are still present. This is also reflected in (d) the separability of different groups based on their cosine similarity relations.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x19.png alt></figure></p><blockquote><p>üîº This figure visualizes the flow graph for feature 12/res/14455. The graph tracks the evolution of this feature across different layers of the language model, showing how its semantic meaning changes. Chalnev et al. (2024) demonstrated that steering this specific feature led to text generation focused on fashion-related themes. This flow graph confirms this, showing a clear presence of fashion-related semantics in the earlier layers of the model. The nodes in the graph represent features identified by Sparse Autoencoders (SAEs), and edges indicate their connections across layers. The colors likely represent different modules within the language model (e.g., attention, MLP, residual streams). The graph illustrates how the feature&rsquo;s meaning is built upon and transformed through these different model components. Analyzing such a graph allows researchers to better understand the model&rsquo;s inner workings and improve interpretability and steering.</p><details><summary>read the caption</summary>Figure 19: Flow graph for the 12/res/14455 feature. As reported in Chalnev et¬†al. (2024), steering of that feature might produce themes related to fashion, and we clearly observe that our flow graph captures this semantics in the earlier layers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x20.png alt></figure></p><blockquote><p>üîº This figure visualizes the flow of feature 12/res/4230 through the layers of a language model. The feature is initially related to the official aspects of events and agreements, but in the latter half of the model, its semantic meaning shifts strongly towards wedding and marriage ceremonies. This shift reflects the model&rsquo;s association of weddings and marriages with official registration processes, a specific type of interpersonal relationship.</p><details><summary>read the caption</summary>Figure 20: Flow graph for the 12/res/4230 feature. In this case, we observe that the second half of the model is closely related to wedding and marriage ceremonies. We believe that the ‚Äúofficial‚Äù aspect in the interpretation of features in earlier layers is closely related to the fact that wedding ceremonies and marriage are themselves official procedures‚Äîthe registration of a specific type of interpersonal relationship.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x21.png alt></figure></p><blockquote><p>üîº This figure illustrates the concept of using sparse autoencoders (SAEs) to model the transformation of features between consecutive layers in a neural network. Two SAEs, one for layer &rsquo;t&rsquo; and one for layer &rsquo;t+1&rsquo;, are shown. A learned transition matrix &lsquo;T&rsquo; connects the two SAEs, representing the transformation of the feature representations from layer &rsquo;t&rsquo; to layer &rsquo;t+1&rsquo;. This effectively shows how the SAEs can function as a transcoder, mapping features from one layer to the next, revealing the relationships between features across different layers of the network. This is a key element of their proposed multi-layer interpretability framework.</p><details><summary>read the caption</summary>Figure 21: Two SAEs with a learned transition matrix TùëáTitalic_T can be seen as a transcoder from layer tùë°titalic_t to layer t+1ùë°1t+1italic_t + 1.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x22.png alt></figure></p><blockquote><p>üîº Figure 22 presents a comparison of different methods for finding a mapping between features across consecutive layers of a language model, using explained variance as a metric. The methods involve using various permutation variants and cosine similarity between decoder weights. The results show that using cosine similarity between the transpose of the decoder weights from layer 14 and the decoder weights from layer 15, considering only the top-ranked element (I<sub>x>0</sub> top<sub>1</sub> W<sub>dec</sub><sup>(14)‚ä§</sup>W<sub>dec</sub><sup>(15)</sup>), achieves the highest explained variance, indicating its effectiveness in capturing feature correspondences.</p><details><summary>read the caption</summary>Figure 22: Explained variance of the various permutation variants. Cosine similarity between decoders‚Äô vectors (ùêàx>0‚Å¢¬†top¬†1‚Å¢ùëædec(14)‚ä§‚Å¢ùëædec¬†(15)subscriptùêàùë•0subscript¬†top¬†1superscriptsubscriptùëædeclimit-from14topsuperscriptsubscriptùëædec¬†15\mathbf{I}_{x>0}\text{ top }_{1}\boldsymbol{W}_{\text{dec}}^{(14)\top}% \boldsymbol{W}_{\text{dec }}^{(15)}bold_I start_POSTSUBSCRIPT italic_x > 0 end_POSTSUBSCRIPT top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 14 ) ‚ä§ end_POSTSUPERSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 15 ) end_POSTSUPERSCRIPT) performs best. See Appendix F for more details.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.03032/x23.png alt></figure></p><blockquote><p>üîº Figure 23 analyzes the performance of different methods for finding a transition matrix between the feature spaces of consecutive layers in a language model. It compares using the top-k elements of the cosine similarity between decoder weight matrices, with and without folding (a technique to account for varying feature activation scales), and also evaluates the impact of including a bias term. The results show that a simple cosine similarity approach, selecting only the top element, achieves the highest explained variance.</p><details><summary>read the caption</summary>Figure 23: Comparison of various kùëòkitalic_k in topksubscripttopùëò\operatorname{top}_{k}roman_top start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT operator and different weights of the SAE. Cosine similarity (ùêàx>0‚Å¢¬†top¬†1‚Å¢ùëædec(14)‚ä§‚Å¢ùëædec(15)subscriptùêàùë•0subscript¬†top¬†1superscriptsubscriptùëædeclimit-from14topsuperscriptsubscriptùëædec15\mathbf{I}_{x>0}\text{ top }_{1}\boldsymbol{W}_{\text{dec}}^{(14)\top}% \boldsymbol{W}_{\text{dec}}^{(15)}bold_I start_POSTSUBSCRIPT italic_x > 0 end_POSTSUBSCRIPT top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 14 ) ‚ä§ end_POSTSUPERSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 15 ) end_POSTSUPERSCRIPT) performs best. See Appendix F for more details.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A2.T2.1><thead class=ltx_thead><tr class=ltx_tr id=A2.T2.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A2.T2.1.1.1.1>Theme</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A2.T2.1.1.1.2>Feature index</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A2.T2.1.1.1.3>Interpretation</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A2.T2.1.2.1><td class="ltx_td ltx_align_left ltx_border_t" id=A2.T2.1.2.1.1>Anger and frustration</td><td class="ltx_td ltx_align_center ltx_border_t" id=A2.T2.1.2.1.2>12/res/4111</td><td class="ltx_td ltx_align_left ltx_border_t" id=A2.T2.1.2.1.3>expressions of anger and frustration</td></tr><tr class=ltx_tr id=A2.T2.1.3.2><td class="ltx_td ltx_align_left" id=A2.T2.1.3.2.1>Mental health issues</td><td class="ltx_td ltx_align_center" id=A2.T2.1.3.2.2>12/res/16226</td><td class="ltx_td ltx_align_left" id=A2.T2.1.3.2.3>ref. to mental health issues and their connections to other health conditions</td></tr><tr class=ltx_tr id=A2.T2.1.4.3><td class="ltx_td ltx_align_left" id=A2.T2.1.4.3.1>Wedding and marriage</td><td class="ltx_td ltx_align_center" id=A2.T2.1.4.3.2>12/res/4230</td><td class="ltx_td ltx_align_left" id=A2.T2.1.4.3.3>terms related to weddings and marriage ceremonies</td></tr><tr class=ltx_tr id=A2.T2.1.5.4><td class="ltx_td ltx_align_left ltx_border_bb" id=A2.T2.1.5.4.1>Religion and God</td><td class="ltx_td ltx_align_center ltx_border_bb" id=A2.T2.1.5.4.2>12/res/5483</td><td class="ltx_td ltx_align_left ltx_border_bb" id=A2.T2.1.5.4.3>spiritual themes related to faith and divine authority</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the features initially selected for the activation task in the model steering experiment. Each row represents a feature, identified by its layer, module, and index within that module. The &lsquo;Interpretation&rsquo; column provides a brief description of the semantic meaning of that feature, as determined by Neuronpedia.</p><details><summary>read the caption</summary>Table 2: Initial choice of feature for activation task.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A3.T3.1><thead class=ltx_thead><tr class=ltx_tr id=A3.T3.1.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=A3.T3.1.1.1.1>Feature index</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A3.T3.1.1.1.2>Interpretation from Neuronpedia</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A3.T3.1.2.1><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id=A3.T3.1.2.1.1>12/res/6778</th><td class="ltx_td ltx_align_left ltx_border_t" id=A3.T3.1.2.1.2>references to testing and experimentation processes</td></tr><tr class=ltx_tr id=A3.T3.1.3.2><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.3.2.1>16/res/13806</th><td class="ltx_td ltx_align_left" id=A3.T3.1.3.2.2>references to experimental studies and methodologies</td></tr><tr class=ltx_tr id=A3.T3.1.4.3><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.4.3.1>18/res/1056</th><td class="ltx_td ltx_align_left" id=A3.T3.1.4.3.2>references to experiments and experimental protocols</td></tr><tr class=ltx_tr id=A3.T3.1.5.4><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.5.4.1>18/res/7505</th><td class="ltx_td ltx_align_left" id=A3.T3.1.5.4.2>terms and phrases related to research activities and methodologies</td></tr><tr class=ltx_tr id=A3.T3.1.6.5><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.6.5.1>23/res/10746</th><td class="ltx_td ltx_align_left" id=A3.T3.1.6.5.2>terms related to modeling and model-building in scientific contexts</td></tr><tr class=ltx_tr id=A3.T3.1.7.6><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.7.6.1>24/res/11794</th><td class="ltx_td ltx_align_left" id=A3.T3.1.7.6.2>terms and phrases related to scientific reasoning and methodology</td></tr><tr class=ltx_tr id=A3.T3.1.8.7><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.8.7.1>24/res/1027</th><td class="ltx_td ltx_align_left" id=A3.T3.1.8.7.2>concerns related to study validity and bias in research methodologies</td></tr><tr class=ltx_tr id=A3.T3.1.9.8><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.9.8.1>24/res/7391</th><td class="ltx_td ltx_align_left" id=A3.T3.1.9.8.2>phrases related to inquiry and questioning</td></tr><tr class=ltx_tr id=A3.T3.1.10.9><th class="ltx_td ltx_align_center ltx_th ltx_th_row" id=A3.T3.1.10.9.1>24/res/1714</th><td class="ltx_td ltx_align_left" id=A3.T3.1.10.9.2>references to academic studies and their outcomes</td></tr><tr class=ltx_tr id=A3.T3.1.11.10><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id=A3.T3.1.11.10.1>25/res/6821</th><td class="ltx_td ltx_align_left ltx_border_bb" id=A3.T3.1.11.10.2>terms related to experimental methods and results in scientific research</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists features from a sparse autoencoder (SAE) that were selected to activate the &lsquo;Research methodology and experimentation&rsquo; theme in a language model. Each row shows a feature&rsquo;s index (layer, module, index within the layer), and its interpretation as provided by the Neuronpedia tool, which offers explanations of features within the language model. These features were used in a model steering experiment to promote the specified theme.</p><details><summary>read the caption</summary>Table 3: Features initially chosen for activation of ‚ÄúResearch methodology and experimentation‚Äù theme.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A5.T4.3><thead class=ltx_thead><tr class=ltx_tr id=A5.T4.3.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A5.T4.3.1.1.1>Layer</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A5.T4.3.1.1.2>Feature index</th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A5.T4.3.1.1.3>Interpretation</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A5.T4.3.2.1><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.2.1.1 rowspan=2><span class=ltx_text id=A5.T4.3.2.1.1.1>0</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.2.1.2>0/mlp/12987</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.2.1.3>punctuation, particularly quotation marks and dialogue indicators</td></tr><tr class=ltx_tr id=A5.T4.3.3.2><td class="ltx_td ltx_align_center" id=A5.T4.3.3.2.1>0/res/14403</td><td class="ltx_td ltx_align_left" id=A5.T4.3.3.2.2>elements that indicate neglect or care in familial relationships</td></tr><tr class=ltx_tr id=A5.T4.3.4.3><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.4.3.1 rowspan=2><span class=ltx_text id=A5.T4.3.4.3.1.1>1</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.4.3.2>1/mlp/16168</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.4.3.3>mentions of astronomical phenomena and their characteristics</td></tr><tr class=ltx_tr id=A5.T4.3.5.4><td class="ltx_td ltx_align_center" id=A5.T4.3.5.4.1>1/res/13755</td><td class="ltx_td ltx_align_left" id=A5.T4.3.5.4.2>metaphorical language and scientific terminologies related to variables and coefficients</td></tr><tr class=ltx_tr id=A5.T4.3.6.5><td class="ltx_td ltx_border_t" id=A5.T4.3.6.5.1></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.6.5.2>2/res/12939</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.6.5.3>numerical data or metrics related to surveys and observations</td></tr><tr class=ltx_tr id=A5.T4.3.7.6><td class=ltx_td id=A5.T4.3.7.6.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.7.6.2>3/res/16138</td><td class="ltx_td ltx_align_left" id=A5.T4.3.7.6.3>scientific terminology related to study results and causes</td></tr><tr class=ltx_tr id=A5.T4.3.8.7><td class=ltx_td id=A5.T4.3.8.7.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.8.7.2>4/res/11935</td><td class="ltx_td ltx_align_left" id=A5.T4.3.8.7.3>terms related to particle physics and their interactions</td></tr><tr class=ltx_tr id=A5.T4.3.9.8><td class=ltx_td id=A5.T4.3.9.8.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.9.8.2>5/res/14558</td><td class="ltx_td ltx_align_left" id=A5.T4.3.9.8.3>numeric or symbolic representations related to mathematical notation or scientific data</td></tr><tr class=ltx_tr id=A5.T4.3.10.9><td class=ltx_td id=A5.T4.3.10.9.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.10.9.2>6/res/2452</td><td class="ltx_td ltx_align_left" id=A5.T4.3.10.9.3>key terms related to Dark Matter detection and experimental setups</td></tr><tr class=ltx_tr id=A5.T4.3.11.10><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.11.10.1 rowspan=2><span class=ltx_text id=A5.T4.3.11.10.1.1>7</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.11.10.2>7/mlp/6110</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.11.10.3>terms related to datasets and classification in statistical or machine learning contexts</td></tr><tr class=ltx_tr id=A5.T4.3.12.11><td class="ltx_td ltx_align_center" id=A5.T4.3.12.11.1>7/res/16335</td><td class="ltx_td ltx_align_left" id=A5.T4.3.12.11.2>technical terminologies related to particle physics measurements</td></tr><tr class=ltx_tr id=A5.T4.3.13.12><td class="ltx_td ltx_border_t" id=A5.T4.3.13.12.1></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.13.12.2>8/res/9666</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.13.12.3>scientific measurements and data related to particle physics</td></tr><tr class=ltx_tr id=A5.T4.3.14.13><td class=ltx_td id=A5.T4.3.14.13.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.14.13.2>9/res/8318</td><td class="ltx_td ltx_align_left" id=A5.T4.3.14.13.3>references to particle physics concepts and measurements</td></tr><tr class=ltx_tr id=A5.T4.3.15.14><td class=ltx_td id=A5.T4.3.15.14.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.15.14.2>10/res/13754</td><td class="ltx_td ltx_align_left" id=A5.T4.3.15.14.3>technical terms and measurements related to particle physics</td></tr><tr class=ltx_tr id=A5.T4.3.16.15><td class=ltx_td id=A5.T4.3.16.15.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.16.15.2>11/res/7614</td><td class="ltx_td ltx_align_left" id=A5.T4.3.16.15.3>terms related to particle physics and specifically the properties of W and Z bosons</td></tr><tr class=ltx_tr id=A5.T4.3.17.16><td class=ltx_td id=A5.T4.3.17.16.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.17.16.2>12/res/2812</td><td class="ltx_td ltx_align_left" id=A5.T4.3.17.16.3>statistical terms and measurements associated with quark interactions</td></tr><tr class=ltx_tr id=A5.T4.3.18.17><td class=ltx_td id=A5.T4.3.18.17.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.18.17.2>13/res/4955</td><td class="ltx_td ltx_align_left" id=A5.T4.3.18.17.3>terms and concepts related to particle physics experiments and measurements‚Ä¶</td></tr><tr class=ltx_tr id=A5.T4.3.19.18><td class=ltx_td id=A5.T4.3.19.18.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.19.18.2>14/res/5262</td><td class="ltx_td ltx_align_left" id=A5.T4.3.19.18.3>keywords related to particle physics, specifically concerning quarks and their properties</td></tr><tr class=ltx_tr id=A5.T4.3.20.19><td class=ltx_td id=A5.T4.3.20.19.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.20.19.2>15/res/9388</td><td class="ltx_td ltx_align_left" id=A5.T4.3.20.19.3>concepts related to particle physics measurements and events</td></tr><tr class=ltx_tr id=A5.T4.3.21.20><td class=ltx_td id=A5.T4.3.21.20.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.21.20.2>16/res/10649</td><td class="ltx_td ltx_align_left" id=A5.T4.3.21.20.3>complex scientific terms and metrics related to particle physics experiments</td></tr><tr class=ltx_tr id=A5.T4.3.22.21><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.22.21.1 rowspan=2><span class=ltx_text id=A5.T4.3.22.21.1.1>17</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.22.21.2>17/mlp/8454</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.22.21.3>theoretical concepts and key terms related to physics and gauge theories</td></tr><tr class=ltx_tr id=A5.T4.3.23.22><td class="ltx_td ltx_align_center" id=A5.T4.3.23.22.1>17/res/8130</td><td class="ltx_td ltx_align_left" id=A5.T4.3.23.22.2>terms related to gauge bosons and their interactions within the context of particle physics</td></tr><tr class=ltx_tr id=A5.T4.3.24.23><td class="ltx_td ltx_border_t" id=A5.T4.3.24.23.1></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.24.23.2>18/res/11987</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.24.23.3>technical and scientific terminology related to particle physics</td></tr><tr class=ltx_tr id=A5.T4.3.25.24><td class=ltx_td id=A5.T4.3.25.24.1></td><td class="ltx_td ltx_align_center" id=A5.T4.3.25.24.2>19/res/15694</td><td class="ltx_td ltx_align_left" id=A5.T4.3.25.24.3>references to scientific measurements and results related to particle physics‚Ä¶</td></tr><tr class=ltx_tr id=A5.T4.3.26.25><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.26.25.1 rowspan=2><span class=ltx_text id=A5.T4.3.26.25.1.1>20</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.26.25.2>20/mlp/601</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.26.25.3>terms associated with quantum mechanics and transformations</td></tr><tr class=ltx_tr id=A5.T4.3.27.26><td class="ltx_td ltx_align_center" id=A5.T4.3.27.26.1>20/res/12523</td><td class="ltx_td ltx_align_left" id=A5.T4.3.27.26.2>terms and concepts related to particle physics and the Standard Model</td></tr><tr class=ltx_tr id=A5.T4.3.28.27><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.28.27.1 rowspan=2><span class=ltx_text id=A5.T4.3.28.27.1.1>21</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.28.27.2>21/mlp/594</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.28.27.3>technical terminology and classifications related to data or performance metrics</td></tr><tr class=ltx_tr id=A5.T4.3.29.28><td class="ltx_td ltx_align_center" id=A5.T4.3.29.28.1>21/res/14511</td><td class="ltx_td ltx_align_left" id=A5.T4.3.29.28.2>scientific terminology and concepts related to fundamental physics‚Ä¶</td></tr><tr class=ltx_tr id=A5.T4.3.30.29><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.30.29.1 rowspan=2><span class=ltx_text id=A5.T4.3.30.29.1.1>22</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.30.29.2>22/mlp/14728</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.30.29.3>references to gauge symmetries in theoretical physics</td></tr><tr class=ltx_tr id=A5.T4.3.31.30><td class="ltx_td ltx_align_center" id=A5.T4.3.31.30.1>22/res/11460</td><td class="ltx_td ltx_align_left" id=A5.T4.3.31.30.2>terms and concepts related to particle physics and theoretical frameworks</td></tr><tr class=ltx_tr id=A5.T4.3.32.31><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.32.31.1 rowspan=2><span class=ltx_text id=A5.T4.3.32.31.1.1>23</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.32.31.2>23/mlp/6936</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.32.31.3>terms related to theoretical physics and particle interactions</td></tr><tr class=ltx_tr id=A5.T4.3.33.32><td class="ltx_td ltx_align_center" id=A5.T4.3.33.32.1>23/res/9592</td><td class="ltx_td ltx_align_left" id=A5.T4.3.33.32.2>terms related to particle physics and their interactions</td></tr><tr class=ltx_tr id=A5.T4.3.34.33><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.34.33.1 rowspan=2><span class=ltx_text id=A5.T4.3.34.33.1.1>24</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A5.T4.3.34.33.2>24/mlp/11342</td><td class="ltx_td ltx_align_left ltx_border_t" id=A5.T4.3.34.33.3>terms and concepts related to theoretical physics and particle interactions</td></tr><tr class=ltx_tr id=A5.T4.3.35.34><td class="ltx_td ltx_align_center" id=A5.T4.3.35.34.1>24/res/14548</td><td class="ltx_td ltx_align_left" id=A5.T4.3.35.34.2>terms and references related to particle physics and standard model parameters</td></tr><tr class=ltx_tr id=A5.T4.3.36.35><td class="ltx_td ltx_border_bb ltx_border_t" id=A5.T4.3.36.35.1></td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A5.T4.3.36.35.2>25/res/1646</td><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=A5.T4.3.36.35.3>technical terms and measurements related to particle physics and the Standard Model</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a detailed breakdown of a specific feature&rsquo;s evolution (feature index 24/res/14548) across multiple layers of a language model. It shows the layer number, feature index, and an interpretation of the feature&rsquo;s meaning at each layer. MLP features with a cosine similarity score below 0.25 were excluded. This provides insight into how the feature&rsquo;s semantic representation changes as it passes through different model components. The interpretations are based on a tool called Neuronpedia, which helps to interpret the features.</p><details><summary>read the caption</summary>Table 4: Graph built from 24/res/14548 feature with MLP features dropped by threshold t(M)=0.25superscriptùë°ùëÄ0.25t^{(M)}=0.25italic_t start_POSTSUPERSCRIPT ( italic_M ) end_POSTSUPERSCRIPT = 0.25.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-b9ee8ae344f7923ebb41f8fa5bdf34bd class=gallery><img src=https://ai-paper-reviewer.com/2502.03032/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.03032/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/&amp;title=Analyze%20Feature%20Flow%20to%20Enhance%20Interpretation%20and%20Steering%20in%20Language%20Models" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/&amp;text=Analyze%20Feature%20Flow%20to%20Enhance%20Interpretation%20and%20Steering%20in%20Language%20Models" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03032/&amp;subject=Analyze%20Feature%20Flow%20to%20Enhance%20Interpretation%20and%20Steering%20in%20Language%20Models" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2502.03032/index.md",oid_likes="likes_paper-reviews/2502.03032/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2502.04370/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">DreamDPO: Aligning Text-to-3D Generation with Human Preferences via Direct Preference Optimization</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-05T00:00:00+00:00>5 February 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2502.04322/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-06T00:00:00+00:00>6 February 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title=Tags>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>