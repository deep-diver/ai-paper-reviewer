{"references": [{"fullname_first_author": "Bricken", "paper_title": "Towards monosemanticity: Decomposing language models with dictionary learning", "publication_date": "2023-MM-DD", "reason": "This paper introduces the use of Sparse Autoencoders (SAEs) to decompose language models into interpretable features, a core technique used in the present work."}, {"fullname_first_author": "Balagansky", "paper_title": "Mechanistic permutability: Match features across layers", "publication_date": "2024-MM-DD", "reason": "This paper presents a method for tracing feature evolution across multiple layers of language models, which forms the basis for the cross-layer analysis in the current work."}, {"fullname_first_author": "Dunefsky", "paper_title": "Transcoders find interpretable LLM feature circuits", "publication_date": "2024-MM-DD", "reason": "This paper introduces the concept of transcoders for analyzing the computational pathways in LLMs, which is compared and contrasted with the methods of the current study."}, {"fullname_first_author": "Engels", "paper_title": "Not all language model features are linear", "publication_date": "2024-MM-DD", "reason": "This paper discusses the linear representation hypothesis, providing valuable context for interpreting the findings of the present research."}, {"fullname_first_author": "Marks", "paper_title": "Sparse feature circuits: Discovering and editing interpretable causal graphs in language models", "publication_date": "2024-MM-DD", "reason": "This work explores the concept of computational circuits within LLMs, which is relevant to the present study's investigation of feature interactions."}]}