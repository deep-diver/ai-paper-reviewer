{"references": [{"fullname_first_author": "Gonzalo Benegas", "paper_title": "Genomic language models: Opportunities and challenges", "publication_date": "2024-07-26", "reason": "This paper provides a comprehensive overview of genomic language models, highlighting their potential and challenges, which is highly relevant to the current research on METAGENE-1."}, {"fullname_first_author": "Hugo Dalla-Torre", "paper_title": "The nucleotide transformer: Building and evaluating robust foundation models for human genomics", "publication_date": "2023-01-01", "reason": "This work introduces Nucleotide Transformer, a significant advancement in genomic foundation models, setting a benchmark for comparison with METAGENE-1."}, {"fullname_first_author": "Yanrong Ji", "paper_title": "DNABERT: pre-trained bidirectional encoder representations from transformers model for DNA-language in genome", "publication_date": "2021-07-15", "reason": "As one of the earliest and most influential works on genomic language models, DNABERT is a crucial foundation for many subsequent models, including METAGENE-1."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2021-06-21", "reason": "The LoRA technique is a key innovation adopted in METAGENE-1, enabling efficient fine-tuning and making the model more accessible for researchers."}, {"fullname_first_author": "Zhihan Zhou", "paper_title": "DNABERT-2: Efficient foundation model and benchmark for multi-species genome", "publication_date": "2023-06-22", "reason": "This paper introduces DNABERT-2, expanding the scope of genomic language models to multiple species, thus offering a direct comparison and contrast to METAGENE-1's approach."}]}