[{"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/bridge_matching_new.png", "caption": "Figure 1: Outputs of DBMs models distilled by our Inverse Bridge Matching Distillation (IBMD) approach on various image-to-image translation tasks and datasets (\\wasyparagraph5). Teachers use NFE\u2265500absent500\\geq 500\u2265 500 steps, while IBMD distilled models use NFE\u22644absent4\\leq 4\u2264 4.", "description": "This figure showcases the results of the Inverse Bridge Matching Distillation (IBMD) technique on several image-to-image translation tasks.  It presents visual comparisons between the outputs of original diffusion bridge models (DBMs), which required 500 or more steps for inference, and the outputs of DBMs distilled using the IBMD method. The distilled models achieve comparable or even better image quality using only 4 or fewer steps, demonstrating significant improvements in efficiency. The tasks include super-resolution, inpainting, JPEG restoration, and sketch-to-image translation.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/method_new.png", "caption": "Figure 2: Overview of (Conditional) Bridge Matching with x^0subscript^\ud835\udc650\\widehat{x}_{0}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT reparameterization.\nThe process begins by sampling a pair (x0,xT)subscript\ud835\udc650subscript\ud835\udc65\ud835\udc47(x_{0},x_{T})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) from the data coupling p\u2062(x0,xT)\ud835\udc5dsubscript\ud835\udc650subscript\ud835\udc65\ud835\udc47p(x_{0},x_{T})italic_p ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ).\nAn intermediate sample xtsubscript\ud835\udc65\ud835\udc61x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is then drawn from the diffusion bridge q\u2062(xt|x0,xT)\ud835\udc5econditionalsubscript\ud835\udc65\ud835\udc61subscript\ud835\udc650subscript\ud835\udc65\ud835\udc47q(x_{t}|x_{0},x_{T})italic_q ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT )\nat a random time t\u223cU\u2062[0,T]similar-to\ud835\udc61\ud835\udc480\ud835\udc47t\\sim U[0,T]italic_t \u223c italic_U [ 0 , italic_T ]. The model x^0subscript^\ud835\udc650\\widehat{x}_{0}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is trained with an MSE loss\nto reconstruct x0subscript\ud835\udc650x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT from xtsubscript\ud835\udc65\ud835\udc61x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. In the conditional setting (dashed red path),\nx^0subscript^\ud835\udc650\\widehat{x}_{0}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is also conditioned on xTsubscript\ud835\udc65\ud835\udc47x_{T}italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT as an additional input, leveraging information about the terminal state to improve reconstruction.", "description": "Figure 2 illustrates the process of Bridge Matching, a method for constructing a diffusion process between two data distributions.  It shows how an intermediate sample is drawn from a diffusion bridge at a random time point, and the model learns to reconstruct the starting point from this intermediate sample. The figure also illustrates the conditional version, where an additional input is used to improve reconstruction.", "section": "2.1. Bridge Matching"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/i2sb-bicubic-extra_compressed.png", "caption": "Figure 3: Overview of our method Inverse Bridge Matching Distillation (IBMD).\nThe goal is to distill a trained (Conditional) Bridge Matching model into a generator G\u03b8\u2062(z,xT)subscript\ud835\udc3a\ud835\udf03\ud835\udc67subscript\ud835\udc65\ud835\udc47G_{\\theta}(z,x_{T})italic_G start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_z , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ), which learns to produce samples using the corrupted data p\u2062(xT)\ud835\udc5dsubscript\ud835\udc65\ud835\udc47p(x_{T})italic_p ( italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ). Generator G\u03b8\u2062(z,xT)subscript\ud835\udc3a\ud835\udf03\ud835\udc67subscript\ud835\udc65\ud835\udc47G_{\\theta}(z,x_{T})italic_G start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_z , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) defines the coupling p\u03b8\u2062(x0,xT)=p\u03b8\u2062(x0|xT)\u2062p\u2062(xT)subscript\ud835\udc5d\ud835\udf03subscript\ud835\udc650subscript\ud835\udc65\ud835\udc47subscript\ud835\udc5d\ud835\udf03conditionalsubscript\ud835\udc650subscript\ud835\udc65\ud835\udc47\ud835\udc5dsubscript\ud835\udc65\ud835\udc47p_{\\theta}(x_{0},x_{T})=p_{\\theta}(x_{0}|x_{T})p(x_{T})italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) = italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) italic_p ( italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) and we aim to learn the generator in such way that Bridge Matching with p\u03b8\u2062(x0,xT)subscript\ud835\udc5d\ud835\udf03subscript\ud835\udc650subscript\ud835\udc65\ud835\udc47p_{\\theta}(x_{0},x_{T})italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) produces the same (Conditional) Bridge Matching model x^0\u03d5=x^0\u03b8superscriptsubscript^\ud835\udc650italic-\u03d5superscriptsubscript^\ud835\udc650\ud835\udf03\\widehat{x}_{0}^{\\phi}=\\widehat{x}_{0}^{\\theta}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT = over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03b8 end_POSTSUPERSCRIPT. To do so, we learn a bridge model x^0\u03d5superscriptsubscript^\ud835\udc650italic-\u03d5\\widehat{x}_{0}^{\\phi}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT using coupling p\u03b8subscript\ud835\udc5d\ud835\udf03p_{\\theta}italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT in the same way as the teacher model was learned. Then, we use our novel objective given in Theorem\u00a03.2 to update the generator model G\u03b8subscript\ud835\udc3a\ud835\udf03G_{\\theta}italic_G start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT.", "description": "Figure 3 illustrates the Inverse Bridge Matching Distillation (IBMD) method.  The goal is to create a fast, efficient generator that mimics a trained (conditional) Bridge Matching model. This generator, G\u03b8(z, xT), learns to produce samples from corrupted data p(xT).  The key is defining a new coupling, p\u03b8(x0, xT) = p\u03b8(x0|xT)p(xT), using the generator. The method then aims to train the generator such that the Bridge Matching process using this new coupling yields the same output (x0) as the original, slower, teacher model.  This is achieved by training the bridge model with the new coupling p\u03b8(x0, xT) and then using a novel objective function from Theorem 3.2 to refine the generator G\u03b8.", "section": "3. IBMD: Inverse Bridge Matching Distillation"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/i2sb-pool-extra_compressed.png", "caption": "Figure 4: Uncurated samples for IBMD-I2SB distillation of 4x-super-resolution with bicubic kernel on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure displays the results of the Inverse Bridge Matching Distillation (IBMD) method applied to super-resolution.  Specifically, it shows the results of using IBMD to distill a teacher model (trained with 1000 steps) into a student model capable of performing 4x super-resolution with only a single inference step (NFE=1). The images demonstrate examples of input images, outputs from the IBMD-I2SB model (ours), outputs from the teacher model (I2SB), and the ground truth (reference) images. The comparison allows for a visual assessment of the performance of the IBMD method in achieving high-quality super-resolution with significantly reduced computational cost.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/i2sb-jpeg-5-extra_compressed.png", "caption": "Figure 5: Uncurated samples for IBMD-I2SB distillation of 4x-super-resolution with pool kernel on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure showcases the results of Inverse Bridge Matching Distillation (IBMD) applied to a 4x super-resolution task using the I2SB model.  The model is specifically trained with a pool kernel and evaluated on 256x256 ImageNet images. The image shows sets of input images, the results obtained using IBMD with only one forward pass (NFE=1), the results from the original I2SB model with 1000 forward passes (NFE=1000), and the ground truth (reference) images. This comparison highlights the significant speedup and comparable image quality achieved by IBMD compared to the original I2SB model.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/i2sb-jpeg-10-extra_compressed.png", "caption": "Figure 6: Uncurated samples for IBMD-I2SB distillation of Jpeg restoration with QF=5 on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure displays the results of applying Inverse Bridge Matching Distillation (IBMD) to a pre-trained I2SB model for JPEG restoration.  The task is to restore JPEG-compressed images with a quality factor (QF) of 5. The leftmost column shows the original, compressed images. The next three columns present the results of the IBMD model with only one forward pass (NFE=1), the original, pre-trained I2SB model (NFE=1000), and the ground truth (reference) images respectively. This visualization allows for a direct comparison of the restoration quality between the distilled model (IBMD) and the teacher model (I2SB), highlighting the improved efficiency (reduced number of forward diffusion steps) without substantial loss of image quality.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/i2sb-inpaiting-extra_compressed.png", "caption": "Figure 7: Uncurated samples for IBMD-I2SB distillation of Jpeg restoration with QF=10 on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure displays the results of applying Inverse Bridge Matching Distillation (IBMD) to a pre-trained I2SB model (trained on ImageNet 256x256 images).  The task was JPEG restoration with a quality factor (QF) of 10. The figure shows input images, the output of the IBMD model with 1 Noise-Free Expectation (NFE), the output of the original I2SB teacher model (with 1000 NFEs), and a reference image which is the ground truth clean image. This comparison illustrates the effectiveness of IBMD in accelerating inference (1 NFE compared to 1000 NFEs) while maintaining relatively high quality in the generated image. Each row represents a different image.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/new-ddbm-inpaiting-small.png", "caption": "Figure 8: Uncurated samples for IBMD-I2SB distillation trained for inpaiting with NFE=4absent4=4= 4 and inferenced with different inference NFE on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure displays uncurated samples from the Inverse Bridge Matching Distillation (IBMD) method applied to an I2SB (Image-to-Image Schr\u00f6dinger Bridge) model. The model was initially trained for image inpainting using 4 noise free steps (NFE).  The figure presents the results of inference using different numbers of NFEs (1, 2, and 4) to demonstrate the impact of reducing the number of inference steps on image quality.  The results are compared to the original I2SB teacher model (1000 NFEs) and the corresponding reference images.  The goal is to show how IBMD can successfully distill the teacher model while significantly speeding up the inference process.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/ddbm-diode-extra-small.png", "caption": "Figure 9: Uncurated samples for IBMD-DDBM distillation trained for inpaiting with NFE=4absent4=4= 4 and inferenced with different inference NFE on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 images.", "description": "This figure displays the results of inpainting using the IBMD-DDBM (Inverse Bridge Matching Distillation - Denoising Diffusion Bridge Model) method.  The IBMD-DDBM model was initially trained with 4 noise-free encoding steps (NFE).  The figure shows inpainting results for different numbers of inference steps (NFE) during the testing phase (1, 2, and 4 NFEs) alongside the results from the original teacher model (NFE=500) and the ground truth (reference) images. All images are from the ImageNet dataset with a resolution of 256x256 pixels. This visual comparison allows assessment of the trade-off between speed (lower NFE) and quality of inpainting against the teacher and reference images.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/ddbm-diode-extra-test-small.png", "caption": "Figure 10: Uncurated samples from IBMD-DDBM distillation trained on the DIODE-Outdoor dataset (256\u00d7256256256256\\times 256256 \u00d7 256) with NFE=2absent2=2= 2 and NFE=1absent1=1= 1, inferred using the corresponding NFEs on the training set.", "description": "This figure displays the results of the Inverse Bridge Matching Distillation (IBMD) method applied to a Denoising Diffusion Bridge Model (DDBM).  Specifically, it shows uncurated samples generated by IBMD models trained with different numbers of function evaluations (NFEs). Two IBMD models are compared: one trained with 2 NFEs and another with 1 NFE.  These are compared against the corresponding results from the original, teacher DDBM (trained with 500 NFEs) and the reference images.  The images are all from the DIODE-Outdoor dataset (resolution 256x256). The samples generated using the IBMD approach demonstrate the ability of the method to accelerate DDBM inference significantly while maintaining a similar generation quality compared to the teacher model, especially for the model trained with 2 NFEs.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/ddbm-e2h-extra-small.png", "caption": "Figure 11: Uncurated samples from IBMD-DDBM distillation trained on the DIODE-Outdoor dataset (256\u00d7256256256256\\times 256256 \u00d7 256) with NFE=2absent2=2= 2 and NFE=1absent1=1= 1, inferred using the corresponding NFEs on the test set.", "description": "This figure displays uncurated samples generated from the IBMD-DDBM model.  The model was trained on the DIODE-Outdoor dataset, which contains images with a resolution of 256x256 pixels.  Two versions of the model are shown, one trained with 2 Noise-Free Evaluations (NFEs) and another with 1 NFE.  The results demonstrate the model's performance on unseen test data, showcasing its ability to generate realistic and high-quality images from noisy or incomplete inputs, even with a reduced number of NFEs during inference. Each row compares the input image (leftmost column) with the outputs from the 1-NFE and 2-NFE IBMD models, followed by the teacher model and the ground truth reference image.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.01362/extracted/6174617/images/ddbm-e2h-extra-test-small.png", "caption": "Figure 12: Uncurated samples from IBMD-DDBM distillation trained on the Edges \u2192\u2192\\rightarrow\u2192 Handbags dataset (64\u00d764646464\\times 6464 \u00d7 64) with NFE=2absent2=2= 2 and NFE=1absent1=1= 1, inferred using the corresponding NFEs on the training set.", "description": "This figure displays the results of the Inverse Bridge Matching Distillation (IBMD) method applied to the Edges to Handbags dataset. The IBMD technique was trained using the Denoising Diffusion Bridge Model (DDBM).  Two versions of the IBMD model are presented: one trained with 2 Noise Free Ensembles (NFE) and another with 1 NFE.  Samples generated by each IBMD model are shown alongside those generated by the original DDBM teacher model (with 500 NFEs) and the corresponding reference images from the dataset. This comparison showcases the ability of the IBMD method to produce comparable results to a much more computationally expensive model, using far fewer NFEs. The images demonstrate different handbag styles with their corresponding outlines.  The results are from the training set.", "section": "5. Experiments"}]