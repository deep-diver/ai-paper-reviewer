{"references": [{"fullname_first_author": "Omri Avrahami", "paper_title": "Blended diffusion for text-driven editing of natural images", "publication_date": "2022-00-00", "reason": "This paper is foundational to the field of text-driven image editing, introducing a method for effectively blending edits into images using diffusion models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "SDXL: Improving latent diffusion models for high-resolution image synthesis", "publication_date": "2023-07-00", "reason": "As a state-of-the-art high-resolution image synthesis model, this paper significantly improves upon previous models, making it a crucial building block for high-quality image inpainting."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine-tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-00-00", "reason": "This method enables data-efficient adaptation of pre-trained diffusion models, which is fundamental for creating personalized and subject-specific images within the context of image inpainting."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP's capacity for aligning image and text representations is leveraged by the proposed model, making CLIP a highly significant prior work in the context of text-guided image manipulation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces the foundational denoising diffusion probabilistic models (DDPM), which form the basis for many recent advancements in image generation and editing tasks."}]}