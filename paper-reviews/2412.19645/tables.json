[{"content": "| Method | CLIP-T | Face Sim. | CLIP-I | DINO-I | T.Cons. | DD |\n|---|---|---|---|---|---|---|\n| IP-Adapter | 0.2064 | 0.1994 | 0.7772 | 0.6825 | 0.9980 | 0.1025 |\n| IP-Adapter-Plus | 0.2109 | 0.2204 | 0.7784 | 0.6856 | 0.9981 | 0.1000 |\n| IP-Adapter-Faceid | 0.2477 | 0.5610 | 0.5852 | 0.4410 | 0.9945 | 0.1200 |\n| ID-Animator | 0.2236 | 0.3224 | 0.4719 | 0.3872 | 0.9891 | 0.2825 |\n| Photomaker(SDXL) | 0.2627 | 0.3545 | 0.7323 | 0.4579 | 0.9777 | 0.3675 |\n| Ours | 0.2586 | 0.8047 | 0.8285 | 0.7119 | 0.9818 | 0.3725 |", "caption": "Table 1: Comparison with the existing methods for customized human video generation. The best and the second-best results are denoted in bold and underlined, respectively.", "description": "This table presents a comparison of different methods for customized human video generation.  Several metrics are used to evaluate the performance of each method, including CLIP-T (text alignment), Face Similarity (subject fidelity), CLIP-I (image-text similarity assessing subject fidelity), DINO-I (visual similarity measuring subject fidelity), Temporal Consistency (how consistent the subject appearance is over time), and Dynamic Degree (a measure of motion variability). The best and second-best results for each metric are highlighted in bold and underlined, respectively.  This allows for a quantitative comparison of the effectiveness of the different approaches in generating high-fidelity, consistent videos that accurately reflect the input subject and text prompt.", "section": "5. Experiments"}, {"content": "| Method | CLIP-T | CLIP-I | DINO-I | T.Cons. | DD |\n|---|---|---|---|---|---| \n| VideoBooth | 0.266 | 0.7637 | 0.6658 | 0.9564 | 0.5091 |\n| Ous | 0.284 | 0.8071 | 0.7326 | 0.9848 | 0.5132 |", "caption": "Table 2: Comparison with the existing methods for customized object video generation", "description": "This table presents a quantitative comparison of VideoMaker against existing methods for customized object video generation.  It uses several metrics to evaluate both the overall consistency of the generated videos (CLIP-T, Temporal Consistency, Dynamic Degree) and the fidelity of the subject's appearance (CLIP-I, DINO-I).  Higher scores generally indicate better performance.  The results show VideoMaker's superior performance across all metrics.", "section": "5. Experiments"}, {"content": "| PISA | GIRL | W/O Cross | Update Motion | SHP | CLIP-T | Face Sim. | CLIP-I | DINO-I | T.Cons. | DD |\n|---|---|---|---|---|---|---|---|---|---|---|\n| \u2713 |  |  |  |  | 0.2206 | 0.7928 | 0.7966 | 0.6694 | 0.9671 | 0.2725 |\n| \u2713 | \u2713 |  |  |  | 0.2258 | 0.8184 | 0.8484 | 0.7536 | 0.9855 | 0.2750 |\n| \u2713 | \u2713 | \u2713 |  |  | 0.2291 | 0.8454 | 0.8469 | 0.7351 | 0.9747 | 0.2915 |\n| \u2713 | \u2713 | \u2713 | \u2713 |  | 0.2302 | 0.8563 | 0.8674 | 0.7635 | 0.9823 | 0.3575 |\n| \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | 0.2586 | 0.8047 | 0.8285 | 0.7119 | 0.9818 | 0.3725 |", "caption": "Table 3: Quantitative results of each component. \u201cPISA\u201d is our Personalized Injection Self Attention, GIRL is our Guidance Information Recognition Loss, \u201cW/O Cross\u201d refers to whether our reference frame interacts with the text prompt, \u201cUpdate Motion\u201d refers to whether to update the motion block, \u201cSHP\u201d is our subject highlight preprocessing for datasets,", "description": "This table presents an ablation study evaluating the impact of different components in the VideoMaker model on customized human video generation.  It shows quantitative results (CLIP-T, Face Similarity, CLIP-I, DINO-I, Temporal Consistency, and Dynamic Degree) for several model variations.  Each row represents a different configuration, varying the inclusion or exclusion of: Personalized Injection Self-Attention (PISA), Guidance Information Recognition Loss (GIRL), cross-attention between the reference frame and text prompt, updating of motion blocks during training, and subject highlight preprocessing. The results allow for assessing the contribution of each component to overall performance.", "section": "5.4 Ablation Studies"}, {"content": "| Category | Prompt |\n|---|---| \n| Clothing | A person dressed in a crisp white button-up shirt. |\n|  | A person in a sleeveless workout top, displaying an active lifestyle. |\n|  | A person wearing a sequined top that sparkles under the light, ready for a festive occasion. |\n|  | A person wearing a Superman outfit. |\n|  | A person wearing a blue hoodie. |\n| Action | A person holding a book open, reading a book, sitting on a park bench. |\n|  | A person playing an acoustic guitar. |\n|  | A person laughing with their head tilted back, eyes sparkling with mirth. |\n|  | A person is enjoying a cup of coffee in a cozy caf\u00e9. |\n|  | A person watching a laptop, focused on the task at hand. |\n| Accessory | A person wearing a headphones, engaged in a hands-free conversation. |\n|  | A person with a pair of trendy headphones around their neck, a music lover\u2019s staple. |\n|  | A person with a beanie hat and round-framed glasses, portraying a hipster look. |\n|  | A person wearing sunglasses. |\n|  | A person wearing a Christmas hat. |\n| View | A person captured in a close-up, their eyes conveying a depth of emotion. |\n|  | A person framed against the sky, creating an open and airy feel. |\n|  | A person through a rain-streaked window, adding a layer of introspection. |\n|  | A person holding a bottle of red wine. |\n|  | A person riding a horse. |\n| Background | A person is standing in front of the Eiffel Tower. |\n|  | A person with a bustling urban street scene behind them, capturing the energy of the city. |\n|  | A person standing before a backdrop of bookshelves, indicating a love for literature. |\n|  | A person swimming in the pool |\n|  | A person stands in the falling snow scene at the park. |", "caption": "Table 1: Evaluation text prompts for customized human video generation.", "description": "This table lists example text prompts used to generate customized human videos.  The prompts are categorized by different aspects to control the final video's content: Clothing (describing the subject's attire), Action (specifying the subject's activity), Accessory (detailing additional items the subject might have), View (describing the camera angle or setting), and Background (setting the environment where the subject is situated). Each category contains multiple example prompts, demonstrating the variety of instructions that can be given to the model.", "section": "5.1 Experimental Setup"}, {"content": "| Method | CLIP-T | Face Sim. | CLIP-I | DINO-I | T.Cons. | DD |\n|---|---|---|---|---|---|---|\n| IP-Adapter | 0.2347 | 0.1298 | 0.6364 | 0.5178 | 0.9929 | 0.0825 |\n| IP-Adapter-Plus | 0.2140 | 0.2017 | 0.6558 | 0.5488 | 0.9920 | 0.0815 |\n| IP-Adapter-Faceid | 0.2457 | 0.4651 | 0.6401 | 0.4108 | 0.9930 | 0.0950 |\n| ID-Animator | 0.2303 | 0.1294 | 0.4993 | 0.0947 | 0.9999 | 0.2645 |\n| Photomaker* | 0.2803 | 0.2294 | 0.6558 | 0.3209 | 0.9768 | 0.3335 |\n| Ours | 0.2773 | 0.6974 | 0.6882 | 0.5937 | 0.9797 | 0.3590 |", "caption": "Table 2: Comparison with the existing methods for customized human video generation on our non-celebrity dataset. The best and the second-best results are denoted in bold and underlined, respectively. Besides, PhotoMaker\u00a0[38] is base on AnimateDiff\u00a0[25] SDXL version.", "description": "This table compares the performance of VideoMaker against several existing methods for generating customized human videos. The comparison uses a non-celebrity dataset and focuses on customized human video generation.  Metrics include CLIP-T (text alignment), Face Similarity, CLIP-I and DINO-I (subject fidelity), Temporal Consistency, and Dynamic Degree (overall video quality). The best and second-best results for each metric are highlighted. Note that PhotoMaker uses a different base model (AnimateDiff SDXL) compared to the others (AnimateDiff SD1.5).", "section": "5. Experiments"}, {"content": "| Category | Prompt | Category | Prompt |\n|---|---|---|---| \n| bear | A bear walking through a snowy landscape. | car | A car cruising down a scenic coastal highway at sunset. |\n|  | A bear walking in a sunny meadow. |  | A car silently gliding through a quiet residential area. |\n|  | A bear resting in the shade of a large tree. |  | A car smoothly merging onto a highway. |\n|  | A bear walking along a beach. |  | A car driving along a desert road. |\n|  | A bear fishing in a rushing river. |  | A car speeding through a muddy forest trail. |\n|  | A bear running in the forest. |  | A car drifting around a sharp corner on a mountain road. |\n|  | A bear walking along a rocky shoreline. |  | A car navigating through a snow-covered road. |\n|  | A bear drinking from a clear mountain stream. |  | A car driving through a tunnel with bright lights. |\n|  | A bear standing on its hind legs to look around. |  | A car driving through a beach. |\n|  | A bear running on the grass. |  | A car driving through a foggy forest road. |\n| cat | A cat is perched on a bookshelf, silently observing the room below. | dog | A dog is lying on a fluffy rug, its tail curled neatly around its body. |\n|  | A cat is sitting in a cardboard box, perfectly content in its makeshift fortress. |  | A dog is walking on a street. |\n|  | A cat is curled up in a human\u2019s lap, purring softly as it enjoys being petted. |  | A dog is swimming. |\n|  | A cat is circle around a food bowl in a room, patiently waiting for mealtime. |  | A dog is sitting in a window, watching the raindrops race down the glass. |\n|  | A cat is lying on a windowsill, its silhouette framed by the setting sun. |  | A dog is running. |\n|  | A cat is running on the grass. |  | A dog, a golden retriever, is seen bounding joyfully towards the camera. |\n|  | A cat is walking on a street. There are many buildings on both sides of the street. |  | A dog is seen leaping into a sparkling blue lake, creating a splash. |\n|  | A cat is sitting in a window, watching the raindrops race down the glass. |  | A dog is seen in a snowy backyard. |\n|  | A cat is playing with a ball of wool on a child bed. |  | A dog is seen napping on a cozy rug. |\n|  | A cat is playing in the snow, rolling and rolling, snowflakes flying. |  | A dog is seen playing tug-of-war with a rope toy against a small child. |\n| elephant | An elephant walking through the jungle. | horse | A horse walking through a dense forest. |\n|  | An elephant crossing a river. |  | A horse running across a grassy meadow. |\n|  | An elephant walking on the grass. |  | A horse walking along a sandy beach. |\n|  | An elephant walking on a road. |  | A horse running through a shallow stream. |\n|  | An elephant walking along a dirt road. |  | A horse walking on a mountain trail. |\n|  | An elephant playing in a mud pit. |  | A horse running across a desert landscape. |\n|  | An elephant walking through a dense jungle. |  | A horse walking through a quiet village. |\n|  | An elephant walking along a sandy beach. |  | A horse running in an open field. |\n|  | An elephant running through a meadow of wildflowers. |  | A horse walking along a forest path. |\n|  | An elephant running across a desert landscape. |  | A horse running through tall grass. |\n| lion | A lion running along a savannah at dawn. | panda | A panda walking through a bamboo forest. |\n|  | A lion walking through a dense jungle. |  | A panda running on a grassy meadow. |\n|  | A lion running on a snowy plain. |  | A panda running through a field of wildflowers. |\n|  | A lion running along a rocky coastline. |  | A panda walking through a snowy landscape. |\n|  | A lion walking through a field of sunflowers. |  | A panda walking through a city park. |\n|  | A lion running across a grassy hilltop. |  | A panda walking in front of the Eiffel Tower. |\n|  | A lion walking through a grassland. |  | A panda wandering through a dense jungle. |\n|  | A lion running along a riverbank. |  | A panda running along a sandy beach. |\n|  | A lion walking on a savannah during sunrise. |  | A panda exploring a cave. |\n|  | A lion running on a plain. |  | A panda is eating bamboo. |\n| tiger | A tiger running along a savannah at dawn. | tiger | A tiger running across a grassy hilltop. |\n|  | A tiger walking through a dense jungle. |  | A tiger walking through a grassland. |\n|  | A tiger running on a snowy plain. |  | A tiger running along a riverbank. |\n|  | A tiger running along a rocky coastline. |  | A tiger walking on a savannah during sunrise. |\n|  | A tiger walking through a field of sunflowers. |  | A tiger running on a plain. |", "caption": "Table 3: Evaluation text prompts for customized object video generation.", "description": "This table lists example text prompts used to generate customized object videos.  The prompts are categorized by object type (bear, car, cat, dog, elephant, horse, lion, panda, tiger) and each category includes multiple prompts describing various actions, settings, or moods to elicit diverse video outputs.  The goal is to showcase the versatility of the VideoMaker model in generating videos that accurately reflect the specified text descriptions for a wide range of object and situation variations.", "section": "5. Experiments"}]