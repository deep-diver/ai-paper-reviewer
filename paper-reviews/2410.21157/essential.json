{"importance": "This paper is crucial for researchers in code intelligence and software engineering because it introduces a **massively multilingual benchmark** for evaluating code completion models, addressing the limitations of existing benchmarks. It also provides a large-scale **instruction dataset** to further improve the models. This work will significantly advance the field by facilitating more comprehensive and robust evaluations of code LLMs across multiple languages and settings.", "summary": "M2RC-EVAL: A new massively multilingual benchmark for repository-level code completion, featuring fine-grained annotations and a large instruction dataset, enabling better evaluation of code LLMs across 18 languages.", "takeaways": ["M2RC-EVAL, a massively multilingual repository-level code completion benchmark covering 18 programming languages is introduced.", "The benchmark includes two types of fine-grained annotations (bucket-level and semantic-level) to analyze the performance in a fine-grained manner.", "A massively multilingual instruction dataset, M2RC-INSTRUCT, is provided to improve the repository-level code completion abilities of existing code LLMs."], "tldr": "Existing code completion benchmarks usually focus on a limited number of languages and lack fine-grained analysis, hindering the evaluation of code LLMs' abilities across different languages and scenarios.  This significantly limits the advancement of multilingual code intelligence. \nTo address these issues, this paper introduces M2RC-EVAL, a **massively multilingual repository-level code completion benchmark** covering 18 programming languages. It offers fine-grained annotations (bucket-level and semantic-level) for various completion scenarios, allowing for a more detailed performance analysis.  Furthermore, it introduces M2RC-INSTRUCT, a large-scale multilingual instruction dataset, to improve the performance of code LLMs.", "affiliation": "Alibaba Group", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}}