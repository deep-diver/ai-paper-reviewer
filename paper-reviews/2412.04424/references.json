{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-XX-XX", "reason": "This paper introduces CLIP, a widely used foundation model for vision-language tasks, which is heavily compared against in this research."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-XX-XX", "reason": "This paper introduces a high-resolution image generation model, which is relevant to the Florence-VL model's generative vision capabilities."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-XX-XX", "reason": "This paper introduces LLaVA, a significant multimodal large language model that directly inspired the design and training methodology for Florence-VL."}, {"fullname_first_author": "Bin Xiao", "paper_title": "Florence-2: Advancing a unified representation for a variety of vision tasks", "publication_date": "2024-XX-XX", "reason": "This paper details Florence-2, the generative vision foundation model that is core to Florence-VL's architecture and visual feature extraction capabilities."}, {"fullname_first_author": "Shengbang Tong", "paper_title": "Cambrian-1: A fully open, vision-centric exploration of multimodal LLMs", "publication_date": "2024-XX-XX", "reason": "This paper introduces another significant multimodal large language model, Cambrian, which serves as a key comparative baseline for evaluating the performance of Florence-VL."}]}