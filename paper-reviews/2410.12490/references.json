{"references": [{" publication_date": "2020", "fullname_first_author": "Mark Chen", "paper_title": "Generative pretraining from pixels", "reason": "This paper is foundational for image autoregressive models.  It introduced iGPT, a pioneering work showing the potential of applying transformer-based autoregressive models to images, directly inspiring many subsequent efforts in this area.  Its success in image understanding and generation, demonstrated through pre-training on pixels, laid the groundwork for further research into more efficient and effective methods like the one presented in this paper.", "section_number": 5}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper is highly influential due to its introduction of GPT-2, demonstrating the power of large language models and the next-token prediction paradigm. The principles and architecture established in this paper were adapted and extended to the visual domain in several works, including this one, to develop image autoregressive models.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This paper is crucial to this work because it introduced Latent Diffusion Models (LDMs) and demonstrated their effectiveness in generating high-resolution images. The authors of the current paper contrast the success of LDMs with the relative underperformance of autoregressive models in image generation. This contrast is central to the current paper's motivation for improving image autoregressive modeling.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Huiwen Chang", "paper_title": "Maskgit: Masked generative image transformer", "reason": "This paper presents MaskGIT, a masked image modeling (MIM) approach that leverages a masked autoencoder-like framework for high-quality image generation. This work uses it as a benchmark to compare against the proposed image autoregressive model, demonstrating the limitations of current autoregressive models relative to MIMs.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "reason": "This paper is significant because it introduced VQGAN, a vector-quantized generative adversarial network (VQGAN) that uses vector quantization to compress image pixels into a more manageable low-dimensional latent space before generating the image. This technique is a key component of many current latent-based image generation models and forms a basis of comparison for the proposed approach.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Ting Chen", "paper_title": "A simple framework for contrastive learning of visual representations", "reason": "This paper is a cornerstone of self-supervised learning, introducing SimCLR.  The concepts and techniques presented in this paper significantly influenced the design and development of self-supervised learning models, including DINOv2, used in the current work to stabilize the latent space for autoregressive models. The impact of contrastive learning on generating high-quality images is also considered in this work.", "section_number": 5}, {" publication_date": "2020", "fullname_first_author": "Kaiming He", "paper_title": "Momentum contrast for unsupervised visual representation learning", "reason": "This paper introduced MoCo, a highly influential self-supervised learning method for visual representation.  MoCo is referenced because it is also a significant foundation for self-supervised learning and contributed to the development of many SSL models used for this work, similar to the impact of SimCLR.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Keyu Tian", "paper_title": "Visual autoregressive modeling: Scalable image generation via next-scale prediction", "reason": "This paper introduced an autoregressive model that uses a next-scale prediction approach to generate images.  This work is cited because it is closely related to the current work in focusing on autoregressive image generation and aims to improve the efficiency and scalability of the process.  This work also discusses autoregressive models as an alternative to iterative ones.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This work is extremely influential because it showed the power of applying the transformer architecture to images using a patch-based approach.  This has had a profound impact on the field of visual representation learning. The current work uses a similar image-patch based approach but applies the transformer-based architecture to the autoregressive generation task.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Aaron van den Oord", "paper_title": "Neural discrete representation learning", "reason": "This paper introduced VQ-VAE, which is a fundamental model for this work.  VQ-VAE proposed a method to compress images into discrete latent representations through vector quantization, paving the way for subsequent works to efficiently handle large-scale image data and improve image generation performance. The concepts presented in this paper remain critical to many latent-based image generative models.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This paper introduced the Transformer architecture, which is fundamental to this paper. Transformers and the attention mechanism they utilize have revolutionized various NLP tasks and are being increasingly applied to image processing and generation.  The current work utilizes a causal Transformer model for image generation, directly building on the concepts introduced in this highly influential work.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Tianyang Hu", "paper_title": "Complexity matters: Rethinking the latent space for generative modeling", "reason": "This paper is highly relevant because it directly addresses the challenges and complexities in designing optimal latent spaces for generative models.  This work delves into the relationship between reconstruction and generation abilities in latent space, which mirrors the exploration of latent space stability in the present study.  The insights gained from this work directly informed the present work\u2019s focus on optimizing latent space for generative capabilities.", "section_number": 2}, {" publication_date": "2014", "fullname_first_author": "Ian Goodfellow", "paper_title": "Generative adversarial nets", "reason": "This paper introduced GANs, a revolutionary approach to generative modeling.  While not directly used in this work, GANs are a central development in the field of generative models and understanding their impact and limitations provides a context for appreciating the challenges addressed in this paper, especially concerning the generation of high-quality images.", "section_number": 2}, {" publication_date": "2014", "fullname_first_author": "Diederik P Kingma", "paper_title": "Auto-encoding variational bayes", "reason": "This paper introduced VAEs, a fundamental model for the current work.  VAEs provide a way to learn compressed representations of data, enabling the efficient handling of high-dimensional datasets such as images. The work also utilizes variational autoencoders to develop latent-based generative models.  This paper is crucial to understanding the latent-space approaches compared in this paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Tianhong Li", "paper_title": "Mage: Masked generative encoder to unify representation learning and image synthesis", "reason": "This paper introduces MAGE, a Masked Generative Encoder (MAGE) model. The authors of the current work compare their proposed model against this as it is one of the state-of-the-art masked image modeling techniques. It demonstrates that MIM approaches achieve superior performance compared to autoregressive methods.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Doyup Lee", "paper_title": "Autoregressive image generation using residual quantization", "reason": "This paper introduced RQ-Transformer, an autoregressive model that utilizes residual quantization to improve the quality of image generation. This is directly relevant to the current work as it focuses on autoregressive image generation and explores improvements in the tokenization and generation process.  The paper serves as a benchmark for comparison of various image autoregressive models.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "reason": "This work introduced a self-supervised learning approach for training vision transformers, which is highly relevant to this work.  This work explores the use of self-supervised learning models for improving the stability of latent spaces for generative models, influencing the model design and training process of this work.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "reason": "This paper introduced masked autoencoders (MAE) as a self-supervised learning method.  MAE is mentioned due to its influence on the field of self-supervised learning, and the current work employs a self-supervised approach, using DINOv2, for stabilizing the latent space. This highlights the close connection between self-supervised learning advancements and this work\u2019s focus on stable latent spaces.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "reason": "This paper introduced DINOv2, a highly effective self-supervised learning model for image representation. DINOv2 is used in this work to generate a stable latent space for the autoregressive model, demonstrating that self-supervised learning models can provide stable visual features, improving upon the latent space representations from reconstructive autoencoders.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper demonstrated the impressive few-shot learning capabilities of large language models and highlighted the potential of these models for various downstream tasks. This result underscores the effectiveness and efficiency of autoregressive language models, forming the basis of the work's ambition to achieve similar performance in the context of image generation.", "section_number": 1}]}