[{"figure_path": "https://arxiv.org/html/2501.00958/x1.png", "caption": "Figure 1: Previous interleaved datasets, e.g., MMC4 and OBELICS, suffer from limitations like weak text-image relations, low knowledge density, and incoherent image sequences. Our multimodal textbook, sourced from massive tutorial videos, employs coarse-to-fine knowledge extraction and multi-level filtering to create a high-quality, textbook-level dataset. It interleaves video keyframes with tutorial texts (extracted from ASR and OCR), enabling VLMs to acquire rich knowledge through tightly coupled text-image and more coherent logic.", "description": "This figure compares previous interleaved datasets (MMC4 and OBELICS) with the newly introduced multimodal textbook dataset.  It highlights the shortcomings of existing datasets, such as loose image-text relationships, low knowledge density, and a lack of logical coherence in image sequences. In contrast, the multimodal textbook dataset, derived from instructional videos, boasts high-quality data with tightly coupled text-image relationships and a logically structured organization of images and text. The dataset construction process employs a coarse-to-fine knowledge extraction and multi-level filtering approach to ensure high-quality data suitable for Vision-Language Model (VLM) training.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.00958/x2.png", "caption": "Figure 2: An illustration of constructing a multimodal textbook from instructional videos. We first instruct LLMs to construct a knowledge taxonomy, then retrieve and filter videos at metadata level, collecting 159K instructional videos. Then a video-to-textbook pipeline is designed for multi-level knowledge extraction. \u2460 We filter out non-instructional videos using ASR transcripts, retaining 75K high-quality videos. \u2461 We use ASR\u2019s timestamp to segment long videos into short clips, discarding those with misaligned visuals and ASR. \u2462 We detect keyframes from each clip and extract text and symbols by OCR. Our pipeline produces 6.5M keyframes, 259M ASR, and 500M OCR tokens and organizes them into an image-text interleaved textbook.", "description": "This figure illustrates the process of creating a multimodal textbook from instructional videos.  It begins with using LLMs to create a knowledge taxonomy, which is then used to collect and filter 159,000 instructional videos from the internet. A multi-stage pipeline then processes these videos. First, non-instructional videos are removed based on their Automatic Speech Recognition (ASR) transcripts, leaving 75,000 high-quality videos. These videos are then segmented into shorter clips using timestamps from the ASR, removing clips with misaligned visuals and audio. Finally, keyframes are extracted from each clip, and Optical Character Recognition (OCR) is used to extract text and symbols from the keyframes.  The result is a multimodal textbook containing 6.5 million keyframes, 259 million ASR tokens, and 500 million OCR tokens, organized in an image-text interleaved format.", "section": "Curation of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/extracted/6106116/sec/fig/fig3.png", "caption": "Figure 3: We randomly select 20%, 50%, and 100% samples from datasets and shuffle the image order within each sample. These datasets with shuffled images are also used for pretraining. The Accuracy denotes the average of seven benchmarks.", "description": "This figure displays the effect of shuffling image order within samples on the performance of vision-language models (VLMs).  Three different datasets (MMC4-Core-ff, OBELICS, and the authors' Textbook-6.5M) were used. For each dataset, 20%, 50%, and 100% of the samples were randomly selected, and the image order within those samples was shuffled. The resulting datasets with shuffled images were then used for pretraining VLMs. The y-axis shows the average accuracy across seven benchmark tasks.  The x-axis indicates the percentage of samples that underwent image shuffling (0%, 20%, 50%, 100%). The graph visually demonstrates how sensitive each dataset is to changes in image order, offering insights into the influence of image coherence on VLM performance.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.00958/x3.png", "caption": "Figure 4: Top: We plot six subjects along with their corresponding sub-courses. Due to space constraints, we selectively visualized only the courses with the highest proportions. Bottom: We count the knowledge points distribution belongs to each subject and its course", "description": "This figure visualizes the structure of the knowledge taxonomy used in the paper. The top part shows a hierarchical tree diagram of six main subjects (Mathematics, Physics, Chemistry, Earth Science, Engineering, and Computer Science). Each subject branches out into several sub-courses, representing more specific areas of study within the subject. Due to space limitations, only the sub-courses with the highest proportions (most videos) are shown for each subject. The bottom part displays bar charts, one for each subject, showing the distribution of knowledge points across the sub-courses within that subject.  This gives a visual representation of the breadth and depth of the educational content included in the dataset.", "section": "4. Analysis of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x4.png", "caption": "Figure 5: A case presented in our textbook illustrates the water cycle within the domain of earth science.", "description": "This figure shows a visualization of the water cycle.  The image depicts the various stages of the water cycle including evaporation from bodies of water, condensation forming clouds, precipitation in the form of rain, surface runoff, infiltration into the ground, and groundwater flow.  The illustration highlights the interconnectedness of these processes and how water continuously circulates within the Earth's system. This example is presented as part of an earth science lesson within the multimodal textbook.", "section": "3. Curation of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x5.png", "caption": "Figure 6: A case presented in our textbook introducing the principles of mechanics within the domain of physics.", "description": "Figure 6 showcases an example from the textbook illustrating the principles of mechanics in physics.  It presents a step-by-step calculation of acceleration using the formula (v-u)/t, where 'v' is the final velocity, 'u' is the initial velocity, and 't' is the time taken.  The example problem involves an object initially at rest accelerating to a certain velocity, visually depicted with keyframes and corresponding text explanations of the calculations.  Further, it explains the concept of acceleration units and its derivation from velocity and time. The figure demonstrates the use of both visual and textual cues to clarify the physical principle within the context of an instructional video.", "section": "3. Curation of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x6.png", "caption": "Figure 7: A case presented in our textbook introducing the concepts of velocity and acceleration within the context of physics.", "description": "This figure shows an example from the textbook that uses two objects with different masses (10kg and 100kg) to illustrate the concept of inertia. A constant force of 50N is applied to both objects.  The resulting accelerations are calculated using Newton's second law (F=ma), demonstrating how a larger mass leads to a smaller acceleration. It then expands on the concept by comparing the rotational inertia of a thin hoop and a solid disk with the same mass and radius, prompting reflection on how mass distribution affects rotational inertia. This section visually explains the relationship between mass and inertia, in both linear and rotational motion.", "section": "4. Analysis of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x7.png", "caption": "Figure 8: A case presented in our textbook demonstrates how to solve a question about planar geometry in the domain of mathematics.", "description": "Figure 8 presents a step-by-step solution to a planar geometry problem.  The problem involves finding the area of a rectangle inscribed within a semicircle. The solution methodically uses geometric principles, including properties of isosceles right triangles, inscribed angles, and central angles, to determine the dimensions of the rectangle and calculate its area.  The figure is highly visual, using diagrams and annotations to guide the reader through each step of the reasoning process. This showcases how the textbook uses a combination of visual and textual explanations to teach mathematical concepts.", "section": "4. Analysis of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x8.png", "caption": "Figure 9: A case presented in our textbook illustrates the concepts of molecules, atoms, and compounds in the domain of chemistry.", "description": "This figure from the section \"Analysis of Multimodal Textbook\" shows a chemistry lesson explaining the difference between atoms and molecules using examples of helium, hydrogen, and water. It helps to illustrate that atoms are the basic building blocks of matter, while molecules are formed when two or more atoms are chemically bonded.  The figure visually depicts atoms (He, Ne) and molecules (H2, O2, CO2, H2O) clarifying pure substances (elements and compounds) using diagrams and text annotations.", "section": "Analysis of Multimodal Textbook"}, {"figure_path": "https://arxiv.org/html/2501.00958/x9.png", "caption": "Figure 10: A case presented in our textbook introduces a depth-first search algorithm.", "description": "This figure shows a step-by-step visual explanation of the Depth-First Search (DFS) algorithm, a graph traversal algorithm.  The visualization uses a simple graph and highlights the process of visiting nodes, backtracking when reaching dead ends, and ensuring that each node is visited exactly once. The accompanying text explains the choices made during each step of the traversal, illustrating the algorithm's logic and how it systematically explores the graph.  Additionally,  pseudocode for the DFS algorithm is provided, further reinforcing the textual and visual explanation.", "section": "3. Curation of Multimodal Textbook"}]