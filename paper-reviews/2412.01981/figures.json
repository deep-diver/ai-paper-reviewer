[{"figure_path": "https://arxiv.org/html/2412.01981/x1.png", "caption": "Figure 1: The x-axis indicates the FLOPs required to collect the data and train the model,\nand y axis the accuracies of best-of-64 performance.\nThe accuracy is averaged over the best-of-64 accuracies of Mistral-7B-Instruct-v0.2 (Jiang et\u00a0al., 2023), Llama-3.1-8B-Instruct, and Llama-3.1-70B-Instruct (Meta, 2024) on MATH (Hendrycks et\u00a0al., 2021).\nDifferent dots on the same line indicates models trained with the same approach but on different scales of data.\nThe top-left zone is desirable in this figure, as it suggests a model can achieve higher performance with less development overhead.\nOur implicit PRM is much cheaper to train while presenting the best performance under the same budget.", "description": "This figure compares different reward models based on their training cost (FLOPs) and performance (best-of-64 accuracy on the MATH dataset).  The performance is averaged across three different language models: Mistral-7B-Instruct-v0.2, Llama-3.1-8B-Instruct, and Llama-3.1-70B-Instruct. Each point on a line represents a model trained with the same method but with a different amount of training data. The ideal model would be located in the top-left corner, indicating high accuracy with low training cost. The results show that the proposed 'implicit PRM' achieves the best accuracy while having significantly lower training costs compared to other methods.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.01981/x2.png", "caption": "Figure 2: \nOverhead of developing different PRMs, in terms of FLOPs during data collection and training.\nThe X axis indicates the number of responses per instruction which determines the scale of training data, and the Y axis is the number of FLOPs. Our implicit PRM always consumes the least FLOPs compared to baselines, with CE being 38.6\u00d7\\times\u00d7 to 38.8\u00d7\\times\u00d7 more efficient than Math-Shepherd across different dataset scales.", "description": "This figure illustrates the computational cost of training different process reward models (PRMs), comparing the proposed implicit PRM with existing methods. The x-axis represents the number of responses per instruction, which directly impacts the size of the training dataset.  The y-axis displays the total FLOPs (floating-point operations) required for both data collection and model training. The figure demonstrates that the implicit PRM consistently requires significantly fewer FLOPs than other PRMs, highlighting its computational efficiency.  Specifically, the implicit PRM using the cross-entropy (CE) loss function is shown to be 38.6 to 38.8 times more efficient than the Math-Shepherd method, showcasing a substantial reduction in computational resources.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.01981/x3.png", "caption": "Figure 3: Results with majority voting. We present the averaged best-of-N accuracy across three testsets.", "description": "Figure 3 presents the average best-of-N accuracy across three different test sets (Mistral-7B-Instruct-v0.2, Llama-3.1-8B-Instruct, and Llama-3.1-70B-Instruct) when using majority voting.  The bar chart displays the performance improvement obtained by using majority voting to aggregate the scores of multiple model responses that lead to the same answer, compared to not using majority voting.", "section": "5.1 Incorporating Majority Voting"}, {"figure_path": "https://arxiv.org/html/2412.01981/x4.png", "caption": "(a) Implicit PRM (DPO).", "description": "The figure shows the results of scaling up the number of instructions used to train an implicit PRM using the DPO objective.  The x-axis represents the number of candidates considered in the best-of-N sampling, while the y-axis shows the accuracy. Different colored lines represent the performance of the implicit PRM trained on different proportions of the original instruction dataset (25%, 50%, 75%, and 100%). The figure displays the results on three different generation models: Mistral-7B-Inst-v0.2, Llama-3.1-8B-Inst, and Llama-3.1-70B-Inst.  It demonstrates how the performance of the implicit PRM scales with the amount of training data.", "section": "5.2 SCALING UP INSTRUCTIONS AND RESPONSES CAN IMPROVE IMPLICIT PRMS"}, {"figure_path": "https://arxiv.org/html/2412.01981/x5.png", "caption": "(b) Implicit PRM (CE).", "description": "This figure shows the results of scaling the number of responses per instruction when training an Implicit PRM using the cross-entropy (CE) loss.  It presents the best-of-N sampling performance on three different language models (Mistral-7B-Inst-v0.2, Llama-3.1-8B-Inst, Llama-3.1-70B-Inst) across various numbers of responses per instruction (1, 2, 4, 8).  The x-axis represents the number of candidates considered in best-of-N sampling, and the y-axis represents the accuracy.  The figure illustrates how the model's performance improves with more responses per instruction, showcasing the effect of data scaling on the Implicit PRM trained with CE loss.", "section": "5.2 SCALING UP INSTRUCTIONS AND RESPONSES CAN IMPROVE IMPLICIT PRMS"}, {"figure_path": "https://arxiv.org/html/2412.01981/x6.png", "caption": "Figure 4: Scaling instruction numbers. Our implicit PRM\u2019s performance on Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct scales well with the number of instructions, despite the trend is more complex on Llama-3.1-70B-Instruct.", "description": "This figure displays the results of experiments on scaling the number of instructions used to train implicit PRMs.  The x-axis represents the number of candidates considered in the best-of-N sampling process.  The y-axis represents the accuracy achieved.  Three different language models (Mistral-7B-Instruct-v0.2, Llama-3.1-8B-Instruct, and Llama-3.1-70B-Instruct) were used.  The results show that for Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct, the performance of the implicit PRM generally improves as the number of training instructions increases. However, the trend is more complex and less consistent for Llama-3.1-70B-Instruct, highlighting potential differences in how these models benefit from increased training data.", "section": "5.2 SCALING UP INSTRUCTIONS AND RESPONSES CAN IMPROVE IMPLICIT PRMS"}, {"figure_path": "https://arxiv.org/html/2412.01981/x7.png", "caption": "(a) Implicit PRM (DPO).", "description": "The figure shows the result of scaling up the number of instructions for the Implicit PRM using the DPO objective.  It presents the best-of-N sampling performance on three different language models: Mistral-7B-Inst-v0.2, Llama-3.1-8B-Inst, and Llama-3.1-70B-Inst.  The x-axis shows the number of candidates considered in the best-of-N sampling, and the y-axis shows the accuracy. Different colored lines represent different scales of training data (25%, 50%, 75%, and 100% of the instructions). The figure demonstrates the effect of scaling instruction data on the performance of the Implicit PRM with DPO.", "section": "5.2 SCALING UP INSTRUCTIONS AND RESPONSES CAN IMPROVE IMPLICIT PRMS"}]