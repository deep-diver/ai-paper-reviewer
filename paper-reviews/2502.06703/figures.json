[{"figure_path": "https://arxiv.org/html/2502.06703/x1.png", "caption": "Figure 1: Comparison between the performance of smaller LLMs compute-optimal TTS and that of larger LLMs CoT on MATH-500 and AIME24. (a) & (d) Llama-3.2-3B-Instruct surpasses Llama-3.1-405B-Instruct and GPT-4o on MATH-500 and AIME24; (b) & (e) DeepSeek-R1-Distill-1.5B outperforms o1-preview on MATH-500 and AIME24, and surpasses o1-mini on MATH-500; (c) & (f) DeepSeek-R1-Distill-7B beats o1 on MATH-500 and AIME24, and exceeds DeepSeek-R1 on AIME24.", "description": "This figure compares the performance of smaller Language Models (LLMs) using compute-optimal Test-Time Scaling (TTS) against larger LLMs using Chain-of-Thought (CoT) reasoning on the MATH-500 and AIME24 datasets.  It demonstrates that smaller models, when utilizing a compute-optimal TTS strategy, can sometimes surpass significantly larger models in terms of accuracy. Specifically, the figure showcases several examples: Llama-3.2-3B-Instruct outperforming Llama-3.1-405B-Instruct and GPT-4; DeepSeek-R1-Distill-1.5B outperforming o1-preview and o1-mini; and DeepSeek-R1-Distill-7B surpassing both o1 and the larger DeepSeek-R1 model. Each comparison is presented using bar charts illustrating performance on MATH-500 and AIME24.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x2.png", "caption": "Figure 2: Comparison of different external TTS methods.", "description": "This figure compares three external Test-Time Scaling (TTS) methods: Best-of-N, Beam Search, and Diverse Verifier Tree Search. Each method uses a policy model to generate responses and a process reward model (PRM) to score them. Best-of-N generates multiple responses and selects the best one. Beam search explores multiple possible solution paths, keeping the top N most promising ones at each step. Diverse Verifier Tree Search extends beam search by dividing the search process into subtrees, exploring each independently to enhance diversity and potentially handle complex problems more effectively.", "section": "Setup & Preliminaries"}, {"figure_path": "https://arxiv.org/html/2502.06703/x3.png", "caption": "Figure 3: Distribution of Pass@1 accuracy of Qwen2.5-72B-Instruct on MATH-500, divided into five bins.", "description": "This figure shows the distribution of Pass@1 accuracy for the Qwen2.5-72B-Instruct model on the MATH-500 dataset.  The x-axis represents the Pass@1 accuracy, which is divided into five bins or ranges of accuracy. The y-axis represents the percentage of problems in each bin. The figure visually demonstrates the performance of the model across different difficulty levels within the MATH-500 dataset, showing how many problems are solved correctly at different accuracy levels.", "section": "3.2. Absolute Problem Difficulty Criterion is More Effective Than Quantiles"}, {"figure_path": "https://arxiv.org/html/2502.06703/x4.png", "caption": "Figure 4: Performance of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct on MATH-500 with different PRMs and TTS strategies.", "description": "This figure showcases the performance comparison of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct models on the MATH-500 dataset using various process reward models (PRMs) and test-time scaling (TTS) strategies.  Different TTS methods, namely Majority Voting, Best-of-N, Beam Search, and Diverse Verifier Tree Search (DVTS), are applied to each model with different compute budgets. The x-axis likely represents the compute budget, while the y-axis shows the accuracy (Pass@k), illustrating the effect of PRMs and TTS strategies on the model's performance.  The purpose is to demonstrate how various PRMs and TTS techniques impact the performance of the models on the MATH-500 tasks.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x5.png", "caption": "Figure 5: Performance of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct on AIME24 with different PRMs and TTS strategies.", "description": "This figure displays the performance comparison of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct language models on the AIME24 dataset, using different process reward models (PRMs) and test-time scaling (TTS) strategies.  It visually represents how various combinations of models, PRMs, and TTS methods affect the accuracy (Pass@k) of the language models.  The graph likely shows the performance across different compute budgets, highlighting the impact of each PRM and TTS strategy on performance.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x6.png", "caption": "Figure 6: The relationship between TTS performance and process supervision abilities of different PRMs on MATH, where the size of each circle represents the number of parameters of the PRM and the curve represents the fitted function.", "description": "Figure 6 illustrates the correlation between the performance of Test-Time Scaling (TTS) and the process supervision capabilities of various Process Reward Models (PRMs) on the MATH dataset.  The x-axis represents the process supervision ability score of each PRM, while the y-axis shows the corresponding TTS performance. Each data point is a PRM, with the circle's size proportional to the number of parameters in that PRM. The fitted curve visually represents the trend of this relationship. This demonstrates how better process supervision provided by a PRM generally correlates with better TTS results.", "section": "3. Rethinking Compute-Optimal Test-Time Scaling"}, {"figure_path": "https://arxiv.org/html/2502.06703/x7.png", "caption": "Figure 7: TTS performance of policy models with parameters from 0.5B to 72B on MATH-500 with different scaling methods.", "description": "Figure 7 presents the results of applying Test-Time Scaling (TTS) strategies to various language models (LMs) of different sizes, ranging from 0.5B to 72B parameters, and evaluating their performance on the MATH-500 dataset.  The figure displays how different TTS approaches (Best-of-N, Beam Search, and Diverse Verifier Tree Search) impact the accuracy of these models. The results demonstrate the relationship between model size and the optimal TTS strategy for achieving high performance on mathematical reasoning tasks. It shows that optimal TTS methods change depending on the size of the language model.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x8.png", "caption": "Figure 8: TTS performance of three Llama policy models on MATH-500 with three difficulty levels.", "description": "This figure displays the results of applying Test-Time Scaling (TTS) strategies to three different sized Llama language models (1B, 8B, and 72B parameters) on the MATH-500 dataset.  The performance is evaluated across three difficulty levels (easy, medium, hard), each defined by a range of Pass@1 accuracy scores. For each model and difficulty level, the figure shows the Pass@k accuracy achieved by four different TTS methods (Majority Voting, Best-of-N, Beam Search, Diverse Verifier Tree Search) with varying compute budgets (represented by the x-axis).  The plot visually demonstrates how the effectiveness of different TTS methods varies depending on the model size and problem difficulty. It helps to determine the best strategy based on these parameters.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x9.png", "caption": "Figure 9: TTS performance of three Llama policy models on MATH-500 with different difficulty levels.", "description": "Figure 9 presents the results of Test-Time Scaling (TTS) experiments conducted on the MATH-500 dataset using three different Llama language models.  The models vary in size, and the results are broken down by three difficulty levels of problems (easy, medium, hard).  The plot likely shows the accuracy (Pass@k - probably Pass@1) achieved by each model at different computational budgets using several TTS strategies (Majority voting, Best-of-N, Beam Search, Diverse Verifier Tree Search).  This allows for an analysis of how different TTS approaches perform under various computational costs and across problems of varying complexity, especially for smaller language models.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x10.png", "caption": "Figure 10: TTS performance of different policy models on MATH-500 with different PRMs and scaling strategies.", "description": "This figure displays the results of Test-Time Scaling (TTS) experiments conducted on the MATH-500 dataset.  It shows how the performance (Pass@k accuracy) of various Large Language Models (LLMs, the 'policy models') changes when using different Process Reward Models (PRMs) and scaling strategies (such as Best-of-N, Beam Search, and Diverse Verifier Tree Search). The x-axis represents the compute budget (number of steps/tokens), while the y-axis shows the accuracy. Different colors represent different policy models, and each group of bars represents a specific PRM. This visualization helps to understand the impact of different TTS hyperparameters on the performance of various LLMs when applied to a mathematical reasoning task.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x11.png", "caption": "Figure 11: TTS performance of different policy models on AIME24 with different PRMs and scaling strategies.", "description": "Figure 11 presents a comprehensive analysis of Test-Time Scaling (TTS) performance across various Large Language Models (LLMs) on the challenging AIME24 mathematical reasoning dataset. The figure systematically evaluates different policy models (LLMs used for generating solutions), Process Reward Models (PRMs; models used for evaluating solutions), and scaling strategies (methods for allocating compute during inference).  The results reveal the intricate interplay between these components and highlight the dependence of optimal TTS performance on the specific combination of policy model, PRM, and scaling method employed.  This detailed breakdown offers valuable insights into the conditions under which TTS proves most effective for enhancing LLM reasoning capabilities.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x12.png", "caption": "Figure 12: Toy case of beam search with RLHFlow-Mistral-PRM-8B and RLHFlow-Deepseek-PRM-8B.", "description": "This figure presents a toy example to illustrate the beam search process using two different process reward models (PRMs): RLHFlow-Mistral-PRM-8B and RLHFlow-Deepseek-PRM-8B.  The example shows how each PRM assigns scores to intermediate steps during the beam search for a mathematical problem, ultimately leading to different final answers.  This highlights the impact of PRM choice on the reasoning process and the resulting solution. The figure demonstrates the differences in the quality of intermediate steps scored by each PRM and how these differences affect the final outcome of the beam search.", "section": "4. How to Scale Test-Time Compute Optimally?"}, {"figure_path": "https://arxiv.org/html/2502.06703/x13.png", "caption": "Figure 13: TTS case of Over-Criticism.", "description": "This figure showcases an example of 'Over-Criticism' in Test-Time Scaling (TTS).  The model, using the prime factorization method to simplify the square root of 242, produces mathematically correct steps. However, the Process Reward Model (PRM) assigns surprisingly low scores to these correct steps, even though the solution's logic and calculations are sound. This illustrates a scenario where the PRM is overly critical, penalizing correct reasoning, and potentially hindering the overall performance of the TTS strategy. The low scores assigned by the PRM despite the correct steps highlight a potential flaw in the PRM's evaluation criteria, incorrectly discounting accurate work.", "section": "C. Cases"}, {"figure_path": "https://arxiv.org/html/2502.06703/x14.png", "caption": "Figure 14: TTS case of Error Neglect.", "description": "This figure shows a test-time scaling (TTS) example where the model makes a mathematical error but receives a high score from the process reward model (PRM). The problem involves finding the length of a side of a right triangle given the sine of an angle and the length of another side. The model correctly uses the sine formula but makes an error when simplifying the resulting equation, which leads to an incorrect answer, yet the PRM assigns a high score, demonstrating that the PRM has difficulty correctly identifying mathematical errors.", "section": "C. Cases"}, {"figure_path": "https://arxiv.org/html/2502.06703/x15.png", "caption": "Figure 15: TTS case of Error Neglect.", "description": "This figure shows a test-time scaling (TTS) example where the model makes a reasoning error but the process reward model (PRM) fails to assign a low score to it, resulting in an incorrect answer. The problem involves trigonometry, and although the model's solution has a mathematical error (incorrect trigonometric relationship), the PRM does not give a low score.  This highlights the issue of the PRM neglecting errors during the reasoning process, and demonstrates the need for more robust methods for evaluating the quality of intermediate steps in TTS.", "section": "C. Cases"}, {"figure_path": "https://arxiv.org/html/2502.06703/x16.png", "caption": "Figure 16: TTS case of Error Localization Bias.", "description": "This figure showcases a case study within the Test-Time Scaling (TTS) method, highlighting an issue called 'Error Localization Bias'.  The example problem involves finding the intersection point of tangents to a circle. The model's reasoning process is visualized step-by-step, revealing that the reward model (PRM) assigns lower scores to intermediate steps that aren't where the actual mathematical errors occur.  This bias affects the overall accuracy of the TTS method, indicating a misalignment between where the PRM assigns low scores and the location of genuine mistakes in the reasoning. The figure demonstrates how these scoring discrepancies can lead to incorrect solutions even if other parts of the solution are mathematically sound.", "section": "C. Cases"}, {"figure_path": "https://arxiv.org/html/2502.06703/x17.png", "caption": "Figure 17: TTS case of Scoring Bias.", "description": "This figure shows a specific example where the scoring system used in Test-Time Scaling (TTS) exhibits bias, unfairly penalizing correct reasoning steps.  The example involves a word problem about redistributing coins across bags. The model correctly determines the solution and the steps to achieve it.  However, the scoring mechanism gives low scores to several intermediate steps even though those steps are mathematically sound and contribute to the correct final answer. This bias toward certain step lengths or solution formats leads to inaccurate scoring, making the TTS process less reliable and potentially affecting the overall outcome.", "section": "C. Cases"}, {"figure_path": "https://arxiv.org/html/2502.06703/x18.png", "caption": "Figure 18: TTS case of Scoring Bias.", "description": "This figure shows a case where the scoring mechanism of the Test-Time Scaling (TTS) method exhibits bias.  The problem involves redistributing coins among bags, and the model's scoring reflects this bias. The model generates several steps with a higher score despite mathematical errors.   The final answer is correct but the scoring does not accurately reflect the correctness of intermediate reasoning steps.", "section": "C. Cases"}]