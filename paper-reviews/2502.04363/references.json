{"references": [{"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper is foundational to the field of diffusion models and sets the benchmark for image generation, which is crucial for the presented text-to-video generation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion models as a fundamental generative model, which is core to the method used in the referenced paper."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-07-01", "reason": "This paper introduces the T5 model, which is used for text embedding in the studied paper, a critical component of text-to-video generation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper presents a high-resolution image generation method based on diffusion models, which is highly relevant to the video generation task."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper is highly relevant to the current research as it advances the state-of-the-art in diffusion-based video generation and addresses challenges in scaling to larger datasets."}]}