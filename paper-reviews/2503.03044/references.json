{"references": [{"fullname_first_author": "Freitag, Markus", "paper_title": "Experts, errors, and context: A large-scale study of human evaluation for machine translation", "publication_date": "2021-01-01", "reason": "This paper presents a large-scale study of human evaluation for machine translation, emphasizing the role of experts, errors, and context."}, {"fullname_first_author": "NLLB Team", "paper_title": "Scaling neural machine translation to 200 languages", "publication_date": "2024-06-01", "reason": "This paper introduces the NLLB model, which is used in the current study to translate challenging documents and is a widely-used MT model that achieves industry-level performances across 200 languages."}, {"fullname_first_author": "Guerreiro, Nuno M.", "paper_title": "xcomet: Transparent machine translation evaluation through fine-grained error detection", "publication_date": "2024-01-01", "reason": "This paper introduces XCOMET-XXL, which is a multilingual Transformer encoder that is used in the current study for word-level QE."}, {"fullname_first_author": "Kocmi, Tom", "paper_title": "GEMBA-MQM: Detecting translation quality error spans with GPT-4", "publication_date": "2023-01-01", "reason": "This paper introduces GEMBA-MQM, which detects translation quality error spans with GPT-4."}, {"fullname_first_author": "Shenoy, Raksha", "paper_title": "Investigating the helpfulness of word-level quality estimation for post-editing machine translation output", "publication_date": "2021-01-01", "reason": "This paper investigates the effect of synthetic word-level QE highlights for English-German post-editing on Wikipedia data and is very similar to the focus of the current work."}]}