[{"figure_path": "https://arxiv.org/html/2411.09661/x2.png", "caption": "Figure 1: The AdaptiveDecoder. This learned module is added to the standard transformer in order to select decoding hyperparameters. It consists of a new decoder head attached to the last hidden state which assigns probabilities to different hyperparameter choices per token (right) or sequence (left), and the highest probability choice is selected in each case. This allows the LLM to select low temperatures for tokens requiring factual consistency, and higher temperatures for tasks requiring creativity and diversity. For the token level adaptive decoder, a different temperature can be selected for different parts of the response given a single instruction.", "description": "The figure illustrates the Adaptive Decoder module, a learnable layer added to a standard transformer-based language model to dynamically select decoding temperatures.  The Adaptive Decoder consists of a new decoder head that takes the last hidden state as input and outputs a probability distribution over different temperature choices. These choices can be made at either the token or sequence level.  At the token level, the model selects a unique temperature for each generated token, enabling fine-grained control over the output's diversity and accuracy. At the sequence level, a single temperature is chosen for the entire sequence.  This dynamic temperature selection allows the model to generate more factually consistent responses when needed (low temperature) and more creative outputs when appropriate (high temperature).", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.09661/x5.png", "caption": "Figure 2: Latent Preference Optimization (LPO) Training Mechanism. We demonstrate how preference pairs are constructed for training the LPO loss (we show a Sequence-Level AdaptiveDecoder, but the procedure remains the same for Token-Level). Here we have N=2 generated response samples for a single prompt, and the Reward Model (RM) scores Response1 better than Response2. Therefore, we use \u03c4=0.6\ud835\udf0f0.6\\tau=0.6italic_\u03c4 = 0.6 as the chosen temperature, and \u03c4=0.2\ud835\udf0f0.2\\tau=0.2italic_\u03c4 = 0.2 as the rejected temperature, and then apply the loss to prefer the chosen temperature over the rejected one for the given context (prompt).", "description": "This figure illustrates the Latent Preference Optimization (LPO) training process.  Two different responses are generated for the same input prompt using the Adaptive Decoder module. A reward model (RM) evaluates the responses and assigns a higher score to one. The temperature used to generate the higher-scoring response (\u03c4=0.6) is considered the 'chosen' temperature, while the temperature used for the lower-scoring response (\u03c4=0.2) is the 'rejected' temperature. The LPO loss function is then used to train the model to favor the 'chosen' temperature over the 'rejected' temperature for similar inputs.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.09661/x6.png", "caption": "Figure 3: UltraMathStories Results. UltraMathStories is a superset of UltraFeedback, GSM8K, and Stories. The Adaptive Decoding models are trained on all 3 subtasks simultaneously. Winrates are shown as the average winrate across the test sets of the 3 subtasks in UltraMathStories. (left) AdaptiveDecoders\u2062e\u2062qsubscriptAdaptiveDecoder\ud835\udc60\ud835\udc52\ud835\udc5e\\textsc{AdaptiveDecoder}_{seq}AdaptiveDecoder start_POSTSUBSCRIPT italic_s italic_e italic_q end_POSTSUBSCRIPT vs Fixed Temperature Winrates. (right) AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT vs Fixed Temperature Winrates. In both cases, Adaptive Decoding outperforms all fixed temperatures.", "description": "Figure 3 presents the results of experiments conducted on the UltraMathStories dataset, which combines UltraFeedback, GSM8K, and Stories datasets.  Adaptive decoding models (both sequence-level and token-level) were trained on all three subtasks simultaneously. The figure displays win-rates, averaged across the three test sets, comparing the adaptive decoding models to multiple models using fixed decoding temperatures.  The left panel shows the comparison using the sequence-level adaptive decoder, and the right panel illustrates the results for the token-level adaptive decoder.  In both cases, the adaptive decoding approach demonstrates superior performance compared to all fixed temperature baselines.", "section": "4.3. UltraMathStories"}, {"figure_path": "https://arxiv.org/html/2411.09661/x7.png", "caption": "Figure 4: AdaptiveDecoders\u2062e\u2062qsubscriptAdaptiveDecoder\ud835\udc60\ud835\udc52\ud835\udc5e\\textsc{AdaptiveDecoder}_{seq}AdaptiveDecoder start_POSTSUBSCRIPT italic_s italic_e italic_q end_POSTSUBSCRIPT predicted temperature distributions. We show the distribution of predicted temperatures on the test set of each subtask in UltraMathStories. As expected, the model predicts low temperatures for GSM8K, high temperatures for Stories, and temperatures mostly in between for UltraFeedback.", "description": "Figure 4 presents the distributions of predicted temperatures generated by the ADAPTIVEDECODERseq model on three different subtasks within the UltraMathStories dataset: GSM8K (mathematical reasoning), Stories (creative writing), and UltraFeedback (general instructions).  The x-axis represents the temperature values, and the y-axis shows the percentage of samples with a given temperature.  As expected, the model demonstrates task-appropriate temperature selection: lower temperatures are predicted for the GSM8K task (requiring factual accuracy), higher temperatures are used for the Stories task (emphasizing creativity), and intermediate temperatures are prevalent in UltraFeedback (a mix of creative and factual tasks). This visualization highlights the model's ability to adapt its decoding temperature dynamically according to task demands.", "section": "4.3. UltraMathStories"}, {"figure_path": "https://arxiv.org/html/2411.09661/x8.png", "caption": "Figure 5: Constrained Creative Writing (ConstrainedStories) Results. Here we show a quantitative analysis of the AdaptiveDecoder on the constrained creative writing task, ConstrainedStories. (left) AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT winrates vs fixed temperatures.\nThe high fixed temperatures perform worse because they fail to follow the constraint. Fixed greedy decoding works well at following the constraint, but AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT outperforms it by using higher temperatures when possible. (right) Mean temperature predicted by the AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT for the first 50 tokens of each sentence. This plot confirms our hypothesis that the first token of each sentence should be low temperature in order to follow the constraint, and all other tokens should be high temperature in order to write a good story. The average temperature for the first token is \u03c4=0.21\ud835\udf0f0.21\\tau=0.21italic_\u03c4 = 0.21, and the average temperature for all other tokens is \u03c4=0.55\ud835\udf0f0.55\\tau=0.55italic_\u03c4 = 0.55, showing a more greedy decoding for the constraint, and less greedy everywhere else.", "description": "Figure 5 presents a comparative analysis of the Adaptive Decoder's performance on a constrained creative writing task.  The left panel displays win rates for the Adaptive Decoder (token-level) against various fixed temperature settings.  It demonstrates that while fixed greedy decoding excels at constraint adherence, the Adaptive Decoder achieves superior performance by strategically employing higher temperatures whenever feasible. The right panel shows the average predicted temperature across the first 50 tokens of each sentence.  This visualization confirms the hypothesis that lower temperatures are optimal for initial tokens (to maintain constraint compliance), while higher temperatures are preferable for subsequent tokens (to foster narrative creativity). The average temperature for the first token is 0.21, indicating a preference for greedy decoding in this context, whereas the average temperature for subsequent tokens is 0.55, showing a less greedy approach, allowing for more creative output.", "section": "4.4. Constrained Creative Writing (ConstrainedStories)"}, {"figure_path": "https://arxiv.org/html/2411.09661/x9.png", "caption": "Figure 6: AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT predicted temperatures for Constrained Creative Story Writing. We demonstrate an example of AdaptiveDecodert\u2062o\u2062ksubscriptAdaptiveDecoder\ud835\udc61\ud835\udc5c\ud835\udc58\\textsc{AdaptiveDecoder}_{tok}AdaptiveDecoder start_POSTSUBSCRIPT italic_t italic_o italic_k end_POSTSUBSCRIPT predicted temperatures (\u03c4\ud835\udf0f\\tauitalic_\u03c4) on the constrained creative story writing task for the prompt \u201cWrite a creative and coherent story with the following title. You must begin each sentence with a word that starts with \u201cAb\u201d.\\n\\nTitle: The Village of the Blindfolded\u201d. We can see that the model is more greedy (\u03c4\ud835\udf0f\\tauitalic_\u03c4 close to 0.0) when generating the constraint tokens (All sentences must begin with words that start with \u201cAb\u201d), and less greedy (\u03c4\ud835\udf0f\\tauitalic_\u03c4 close to 1.0) on all other tokens.", "description": "Figure 6 presents the AdaptiveDecoder<sub>tok</sub>'s predicted temperature values for a constrained creative story-writing task.  The model is tasked with writing a coherent story, but each sentence must begin with a word starting with \"Ab\". The figure shows the model's temperature selection for each token in the generated text.  Low temperatures (closer to 0.0) indicate greedy decoding, favoring high-probability words, which is necessary for meeting the constraint of starting each sentence with \"Ab\". High temperatures (closer to 1.0) correspond to less greedy decoding, allowing for more diverse and creative word choices. As expected, the model uses low temperatures for the constraint-satisfying tokens at the beginning of each sentence and then higher temperatures for other tokens, demonstrating that it learns to adapt its temperature choices depending on the specific requirements of the task.", "section": "4.4 Constrained Creative Writing (ConstrainedStories)"}, {"figure_path": "https://arxiv.org/html/2411.09661/x10.png", "caption": "Figure 7: AdaptiveDecoders\u2062e\u2062qsubscriptAdaptiveDecoder\ud835\udc60\ud835\udc52\ud835\udc5e\\textsc{AdaptiveDecoder}_{seq}AdaptiveDecoder start_POSTSUBSCRIPT italic_s italic_e italic_q end_POSTSUBSCRIPT Training Preference Distributions. Here we show the percentage of samples in the training set that are chosen or rejected for each of the 6 different temperateure (\u03c4\ud835\udf0f\\tauitalic_\u03c4) values. The LPO loss uses both chosen and rejected responses, and the ratio of chosen to rejected is an important factor for learning the right temperature. A vanilla negative log-likelihood loss only uses the chosen responses, which leads to suboptimal temperature predictions since high temperature values are the most chosen regardless of the task.", "description": "Figure 7 illustrates the training data distribution for the Latent Preference Optimization (LPO) method used to train the ADAPTIVEDECODER model.  It shows, for each of six temperature values (\u03c4), the percentage of training samples that were labeled as 'chosen' (preferred) versus 'rejected' (less preferred) by the reward model.  The ratio of chosen to rejected samples is crucial for the LPO loss function to learn effective temperature selection.  In contrast, a standard negative log-likelihood loss, which only considers chosen samples, would lead to suboptimal temperature choices, as high temperatures tend to be more frequently chosen, irrespective of their actual effectiveness on different tasks.", "section": "3. Method"}]