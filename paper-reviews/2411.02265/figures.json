[{"figure_path": "https://arxiv.org/html/2411.02265/extracted/5974582/figs/syn.png", "caption": "Figure 1: The four-step process of data synthesis in Hunyuan-Large\u2019s pre-training: (1) Instruction generation, (2) Instruction evolution, (3) Response generation, and (4) Response filtering.", "description": "This figure illustrates the four-step data synthesis process used in the pre-training of Hunyuan-Large.  First, instructions are generated using various sources like web pages and books. Second, these instructions are evolved by refining them, expanding low-resource domains, and increasing the difficulty level. Third, responses to these evolved instructions are generated by specialized models.  Finally, the generated instruction-response pairs are filtered to ensure high quality and consistency, removing low-quality or inconsistent data. This process is crucial for creating high-quality and diverse training data for the model.", "section": "2.1 Data and Tokenizer"}, {"figure_path": "https://arxiv.org/html/2411.02265/x1.png", "caption": "(a) Traditional Top-k Routing.", "description": "In traditional top-k routing, tokens are assigned to the top k experts based on their scores.  If an expert exceeds its maximum capacity, the excess tokens are dropped. This can lead to information loss and inefficiency.", "section": "2.2.3 Expert Routing Strategy"}, {"figure_path": "https://arxiv.org/html/2411.02265/x2.png", "caption": "(b) Recycle Routing.", "description": "This figure shows the Recycle Routing strategy used in Hunyuan-Large.  In traditional Top-k routing, tokens from overloaded experts are dropped. However, the Recycle Routing strategy reassigns these tokens to other experts that are not overloaded, preventing loss of information and improving training efficiency.  The illustration compares the traditional approach with the new recycle routing.", "section": "2.2.2 KV Cache Compression"}, {"figure_path": "https://arxiv.org/html/2411.02265/x3.png", "caption": "Figure 2: An illustration of the recycle routing strategy in Hunyuan-Large, where each expert\u2019s maximum capacity is set to 2. Token D, which was initially allocated to the overloaded Expert 1, is reassigned to a randomly selected Expert 4. This approach helps alleviate the potential loss of valuable information. In traditional routing strategies, tokens from overloaded experts would be dropped as shown in (a). However, our strategy involves randomly reassigning these tokens to other experts, as demonstrated in (b), where Token D is routed to Expert 4.", "description": "This figure illustrates the difference between the traditional top-k routing strategy and the novel recycle routing strategy used in Hunyuan-Large.  In the traditional approach (a), when an expert's capacity is reached, excess tokens are dropped, potentially leading to information loss.  The recycle routing strategy (b) addresses this by randomly reassigning tokens initially sent to overloaded experts to other experts that are not at capacity. This ensures no information is lost and maintains efficiency.", "section": "2.2.3 Expert Routing Strategy"}, {"figure_path": "https://arxiv.org/html/2411.02265/x4.png", "caption": "Figure 3: Using quadratic polynomial fitting, we obtain the scaling law of the optimal number of activation parameters under different minimum compute budgets.", "description": "This figure shows the relationship between the optimal number of activated parameters in a Mixture of Experts (MoE) model and the minimum compute budget.  By using quadratic polynomial fitting on data from experiments with varying numbers of activated parameters and training data, the authors derived a scaling law. This law helps guide the choice of the optimal model size based on available computational resources.  The x-axis represents the minimum compute budget (FLOPSmin), and the y-axis represents the optimal number of activated parameters. The curves represent the scaling law at different training loss values, providing insights for effective and efficient model training with limited resources.", "section": "2.3 Pre-Training Recipes"}]