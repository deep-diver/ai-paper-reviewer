[{"figure_path": "2410.13859/tables/table_7_0.html", "caption": "Table 1: Comparison of different \u03b3-MoD configurations on LLaVA-HR. The default setting used in the table is colored in gray. \u201cQ\u201d and \u201cA\u201d refer to question and answer tokens.", "description": "Table 1 compares the performance of various \u03b3-MoD configurations on the LLaVA-HR model across different metrics, including accuracy and the proportion of skipped tokens.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.13859/tables/table_8_0.html", "caption": "Table 2: Ablation study of \u03b3-MoD on LLaVA-HR. \u201cParam\u201d, \u201cAcc.\u201d and \u201cSkip\u201d indicate the parameter, accuracy, and skip ratio, respectively.", "description": "Table 2 shows the ablation study of the proposed \u03b3-MoD on LLaVA-HR model by varying different components of the model and measuring its impact on the performance and efficiency.", "section": "5.3 Experimental Results"}, {"figure_path": "2410.13859/tables/table_8_1.html", "caption": "Table 1: Comparison of different \u03b3-MoD configurations on LLaVA-HR. The default setting used in the table is colored in gray. \u201cQ\u201d and \u201cA\u201d refer to question and answer tokens.", "description": "Table 1 compares the performance of different \u03b3-MoD configurations on the LLaVA-HR model across various metrics, including accuracy and the proportion of skipped tokens.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.13859/tables/table_9_0.html", "caption": "Table 4: Training and inference efficiency of \u03b3-MoD on LLaVA-HR. The inference efficiency is tested on an NVIDIA A100 GPU, which is the average value of GQA, SQA, MMMU, and TextVQA.", "description": "This table shows the training and inference efficiency gains achieved by applying the \u03b3-MoD model to the LLaVA-HR model, showing reductions in training time, memory usage, and computational cost while maintaining similar accuracy.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.13859/tables/table_9_1.html", "caption": "Table 1: Comparison of different \u03b3-MoD configurations on LLaVA-HR. The default setting used in the table is colored in gray. \u201cQ\u201d and \u201cA\u201d refer to question and answer tokens.", "description": "Table 1 compares the performance of different \u03b3-MoD configurations on the LLaVA-HR model across various metrics, including accuracy and token skip rate, for different layer configurations, masked tokens and shared routing.", "section": "5 Experiments"}]