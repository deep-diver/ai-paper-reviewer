[{"figure_path": "2410.13859/figures/figures_4_0.png", "caption": "Figure 2: Illustration of our \u03b3-MoD adaptation on LLaVA-HR. \u03b3-MoD is a plug-and-play approach that can be directly applied in existing MLLMs. After vision-language alignment, \u03b3-MoD can replace most redundant layers with MoD ones via the rank-based redundancy estimation.", "description": "Figure 2 illustrates the \u03b3-MoD adaptation process on the LLaVA-HR model, showing how it replaces redundant layers with MoD layers based on rank estimation.", "section": "3 PRELIMINARIES"}, {"figure_path": "2410.13859/figures/figures_10_4.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how the routing mechanism in \u03b3-MoD selectively skips less important tokens (colored gray) in both image and text data, focusing computation on key elements for improved efficiency.", "section": "5.3.3 Qualitative Analysis"}, {"figure_path": "2410.13859/figures/figures_10_5.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes the routing results of \u03b3-MoD, showing how different tokens are skipped during computation in different MoD layers, with a focus on question, image, and answer tokens.", "section": "5.3.3 Qualitative Analysis"}, {"figure_path": "2410.13859/figures/figures_10_6.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how the proposed \u03b3-MoD model routes tokens in different layers, highlighting the skipped tokens (in gray) and demonstrating how the model focuses on key information for generating answers.", "section": "5.3.3 Qualitative Analysis"}, {"figure_path": "2410.13859/figures/figures_10_7.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "The figure visualizes how the \u03b3-MoD model routes tokens (keeps or skips) in different layers, highlighting the skipped tokens in gray to show the model's focus on relevant information for efficient computation.", "section": "5.3.3 QUALITATIVE ANALYSIS"}, {"figure_path": "2410.13859/figures/figures_10_8.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how the routing mechanism of \u03b3-MoD selectively skips less important tokens (colored gray) in both image and text data across different layers, focusing computation on key elements.", "section": "5.3.3 Qualitative Analysis"}, {"figure_path": "2410.13859/figures/figures_10_9.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how the \u03b3-MoD model routes tokens (keeps or skips) at different layers, illustrating the model's focus on key information and discarding of redundant parts in both image and text data.", "section": "5.3.3 QUALITATIVE ANALYSIS"}, {"figure_path": "2410.13859/figures/figures_10_10.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how the proposed \u03b3-MoD model routes tokens through different layers, highlighting which tokens are skipped and which are processed.", "section": "5.3.3 Qualitative Analysis"}, {"figure_path": "2410.13859/figures/figures_10_12.png", "caption": "Figure 4: Visualization of routing results for different MoD layers. \u201cQ\u201d, \u201cI\u201d and \u201cA\u201d denote the question, image and response, respectively. The skipped tokens in sub-figure (b) are colored in gray.", "description": "Figure 4 visualizes how \u03b3-MoD\u2019s routing mechanism skips less important tokens (colored in gray) in both images and text, focusing computation on key elements for accurate responses.", "section": "5.3.3 Qualitative Analysis"}]