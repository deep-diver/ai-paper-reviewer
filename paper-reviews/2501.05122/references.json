{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-05-14", "reason": "This paper introduced the foundational large language model (LLM) architecture and methodology that underpins much of the current research in LLMs, including the LVLMs discussed in the target paper."}, {"fullname_first_author": "Xi Chen", "paper_title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model", "publication_date": "2022-09-06", "reason": "This paper introduced PaLI, one of the first significant multilingual vision-language models, which directly influenced the approach and design of the LVLMs discussed in the target paper."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual Instruction Tuning", "publication_date": "2023-04-08", "reason": "This paper introduced the Visual Instruction Tuning (VIT) method, a key technique used in training many current LVLMs, including Centurio, and is directly compared against in the target paper."}, {"fullname_first_author": "Ashish V. Thapliyal", "paper_title": "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset", "publication_date": "2022-11-16", "reason": "This paper introduced the Crossmodal-3600 dataset, a benchmark dataset used for evaluating multilingual vision-language models that is directly referenced and compared against in the target paper."}, {"fullname_first_author": "Jonas Pfeiffer", "paper_title": "xGQA: Cross-Lingual Visual Question Answering", "publication_date": "2022-05-22", "reason": "This paper introduced the xGQA dataset, another benchmark dataset used for evaluating multilingual vision-language models which is directly compared to in the target paper."}]}