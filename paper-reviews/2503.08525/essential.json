{"importance": "This work offers vital insights & a practical solution (GTR) to prevent thought collapse in RL-based VLM agents, boosting performance & generalization. It enhances decision-making in complex visual environments, opening doors for smarter, more reliable AI systems.", "summary": "GTR: Prevents thought collapse in RL-based VLM agents by process guidance, enhancing performance in complex visual reasoning tasks.", "takeaways": ["Thought collapse restricts VLM agent reasoning during RL training, causing state-irrelevant & invalid actions.", "Guided Thought Reinforcement (GTR) framework can effectively prevents thought collapse during RL.", "GTR significantly improves performance & generalization of VLM agents across visual environments."], "tldr": "Reinforcement Learning with verifiable outcome rewards (RLVR) has shown promise in scaling up chain-of-thought (CoT) reasoning in large language models (LLMs). However, its effectiveness is less established when training vision-language model (VLM) agents for goal-directed action reasoning in visual settings. Through experiments on card games and embodied tasks, the research identified a bottleneck where RL fails to incentivize CoT reasoning in VLMs. This leads to a \u201cthought collapse,\u201d characterized by a rapid loss of diversity in the agent\u2019s thoughts, state-irrelevant reasoning, and invalid actions. \n\nTo address this, the paper introduces Guided Thought Reinforcement (GTR). GTR utilizes an automated corrector that evaluates and refines the agent's reasoning. This framework trains reasoning and action simultaneously without human labeling. Experiments demonstrate that GTR enhances the performance and generalization of the LLaVA-7b model across visual environments. GTR achieves higher task success rates compared to other models. This shows that combining thought guidance with RL enhances the decision-making potential of VLM agents.", "affiliation": "Tsinghua University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2503.08525/podcast.wav"}