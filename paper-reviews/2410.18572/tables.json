[{"figure_path": "2410.18572/tables/table_7_0.html", "caption": "Table 1: Zero-shot results of Taipan against baseline models.", "description": "Table 1 presents the zero-shot results for three model sizes (190M, 450M, and 1.3B parameters) across various common-sense reasoning and question answering tasks, comparing Taipan against Transformer++, Mamba-2, and Jamba baselines.", "section": "4.2 LANGUAGE MODELING PERFORMANCE"}, {"figure_path": "2410.18572/tables/table_8_0.html", "caption": "Table 1: Zero shot results of Taipan against baseline models.", "description": "Table 1 presents the zero-shot results for models of three sizes: 190M, 450M, and 1.3B parameters, evaluated on various common-sense reasoning and question-answering tasks.", "section": "4.2 LANGUAGE MODELING PERFORMANCE"}]