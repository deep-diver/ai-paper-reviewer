{"references": [{" publication_date": "2021", "fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "reason": "This paper is a foundational technical report of GPT-4, a highly influential large language model.  Its significance to this work is the establishment of the state-of-the-art (SOTA) performance of LLMs on code generation tasks. The paper provides a comprehensive evaluation of GPT-4's capabilities, serving as a benchmark against which other models are compared in this research and impacting the field of LLM code generation.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Jacob Austin", "paper_title": "Program synthesis with large language models", "reason": "This is a seminal work establishing the potential of large language models for program synthesis. Its inclusion is critical because it sets the stage for the current research by demonstrating the early progress and highlighting the potential for LLM applications in code generation tasks, a field that has advanced significantly since the publication of this paper.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Ning Bian", "paper_title": "ChatGPT is a knowledgeable but inexperienced solver", "reason": "This work delves into the limitations of current LLMs, highlighting areas where they lack the expertise and critical thinking skills of human programmers.  Its contribution is in framing the limitations of large language models which necessitates further research toward real world application and code generation.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Egor Bogomolov", "paper_title": "Long code arena: a set of benchmarks for long-context code models", "reason": "This is a significant benchmark dataset used in the field of evaluating code generation capacity of LLMs, especially considering their limitation in context window size. Its importance lies in addressing the limitations of prior benchmarks.  The comparison with this benchmark provides insights into how the current research addresses issues of context and complexity in code generation.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Mark Chen", "paper_title": "Evaluating large language models trained on code", "reason": "This influential work offers a comprehensive evaluation of LLMs trained on code, providing insights into their capabilities and limitations in a specific domain.  Its importance stems from its significant impact on the field, providing an evaluation benchmark against which other LLMs can be measured.  The study's methodology informs the current research on LLMs' performance in code generation tasks.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "X. Du", "paper_title": "Evaluating large language models in class-level code generation", "reason": "This paper presents a benchmark dataset for evaluating LLMs' capabilities in class-level code generation.  Its inclusion is vital because it highlights the progress and challenges in code generation and emphasizes the development of more comprehensive benchmarks that address the complexities of real-world scenarios. The paper's contribution is in providing a benchmark against which the current research can be compared and which aids in understanding the complexities of LLMs' real-world applications.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "reason": "This paper presents a family of powerful language models, including Llama 3, that are used in the current work. Its significance lies in providing a basis for comparing the performance of the different LLMs on the REPOCOD benchmark.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Daya Guo", "paper_title": "Deepseek-coder: When the large language model meets programming", "reason": "This research is significant because it presents a large language model specifically designed for code generation, offering a strong comparison point against existing benchmarks.  Its importance stems from the model's performance being a point of reference in this work, demonstrating the recent advancements in LLMs and their capabilities.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring coding challenge competence with apps", "reason": "This paper offers a novel method for assessing the competence of LLMs in solving coding challenges.  Its significance lies in providing a framework for evaluating the LLMs, which underpins the evaluation approaches in this research.  The comparison to this existing method further validates the results and highlights the limitations of other benchmarks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Soneya Binta Hossain", "paper_title": "A deep dive into large language models for automated bug localization and repair", "reason": "This paper investigates the use of LLMs in the context of automated bug localization and repair. Its importance lies in demonstrating the potential of LLMs in various aspects of software engineering, including bug fixing, beyond code generation, placing the current work in a broader context of LLM applications in software development.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nan Jiang", "paper_title": "Impact of code language models on automated program repair", "reason": "This paper investigates the impact of code language models on automated program repair, highlighting a key application area of LLMs.  Its significance stems from its focus on code repair, closely linked to code generation, and its findings provide further context for understanding the potential of LLMs in software development and their capabilities in solving real-world problems.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiawei Liu", "paper_title": "Is your code generated by chatgpt really correct?", "reason": "This paper delves into the critical aspect of evaluating the correctness of code generated by LLMs, a significant concern when assessing the capabilities of these models for real-world software development. This paper's evaluation method is significant to this study's methodology and results.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Anton Lozhkov", "paper_title": "Starcoder 2 and the stack v2: The next generation", "reason": "This paper introduces a powerful new code generation model, serving as a basis of comparison in the current research. The model is relevant to this work's focus on assessing the capabilities of state-of-the-art models for code generation and thus comparing the proposed model against the presented models adds insights to the study.", "section_number": 2}, {" publication_date": "1976", "fullname_first_author": "T.J. McCabe", "paper_title": "A complexity measure", "reason": "This seminal paper introduces a widely used metric for measuring the cyclomatic complexity of code, a key factor in assessing the complexity of code generation tasks. Its relevance to this research is its role in characterizing and comparing the complexities of the problems in the proposed REPOCOD benchmark against existing benchmarks.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Erik Nijkamp", "paper_title": "Codegen: An open large language model for code with multi-turn program synthesis", "reason": "This work presents an open-source large language model for code generation, providing an important comparative model in the current research.  The model's performance is compared with other models on the REPOCOD benchmark, adding to the comprehensive evaluation and insights into different model architectures and capabilities in code generation.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shuyin Ouyang", "paper_title": "LLM is like a box of chocolates: the non-determinism of chatgpt in code generation", "reason": "This paper explores the non-deterministic nature of LLMs in code generation, revealing the limitations of these models.  The findings contribute to the understanding of the challenges in LLM-based code generation and provide context for interpreting the results from the current study.  The non-deterministic behaviour of LLMs is an important consideration when evaluating their applicability for real-world software development.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Shuo Ren", "paper_title": "Codebleu: a method for automatic evaluation of code synthesis", "reason": "This research introduces CodeBLEU, a metric used in evaluating code generation quality, which is relevant because many prior benchmarks rely on similar metrics for evaluation. Its inclusion is vital as it provides a context and a benchmark to evaluate the methodology of the current research and to understand how it addresses the limitations of similarity-based metrics.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Baptiste Rozi\u00e8re", "paper_title": "Code llama: Open foundation models for code", "reason": "This paper introduces a family of powerful code generation models that are used in the current work.  Its significance lies in providing a basis for comparison of models in the current study and highlights the rapid advancements in LLMs and their applications.", "section_number": 2}, {" publication_date": "2009", "fullname_first_author": "Stephen Robertson", "paper_title": "The probabilistic relevance framework: BM25 and beyond", "reason": "This is a foundational paper on BM25, a widely used ranking function for information retrieval, which is used in the sparse retrieval setting of the current research. Its significance lies in providing the basis for one of the retrieval methods used in the evaluation and thus, its relevance to the study's methodology and results.", "section_number": 5}]}