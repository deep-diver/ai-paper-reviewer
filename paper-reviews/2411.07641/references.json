{"references": [{"fullname_first_author": "Mark Chen", "paper_title": "Evaluating large language models trained on code", "publication_date": "2021-07-01", "reason": "This paper is foundational for understanding the capabilities and limitations of LLMs in code generation, a key area relevant to the current research on reasoning."}, {"fullname_first_author": "Aitor Lewkowycz", "paper_title": "Solving quantitative reasoning problems with language models", "publication_date": "2022-00-00", "reason": "This paper directly addresses the challenge of quantitative reasoning in LLMs, which is the central focus of the current work."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-00-00", "reason": "This paper introduces chain-of-thought prompting, a crucial technique for improving LLM reasoning that is directly relevant to the current research."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024-07-01", "reason": "This paper introduces the LLaMA 3 model, which serves as the foundation for the experimental evaluation in the current work."}, {"fullname_first_author": "Minh Nguyen", "paper_title": "Min p sampling: Balancing creativity and coherence at high temperature", "publication_date": "2024-07-01", "reason": "This paper introduces the min-p sampling method, a key existing sampling technique that is compared and contrasted with the proposed method."}]}