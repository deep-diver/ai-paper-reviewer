Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models