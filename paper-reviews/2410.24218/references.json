{"references": [{"fullname_first_author": "Lili Chen", "paper_title": "Decision Transformer: Reinforcement Learning via Sequence Modeling", "publication_date": "2021-12-01", "reason": "This paper introduces the Decision Transformer (DT) architecture, which is used as the backbone for the proposed Language-Teachable Decision Transformer (LTDT) model in this work."}, {"fullname_first_author": "Mohit Shridhar", "paper_title": "ALFWorld: Aligning Text and Embodied Environments for Interactive Learning", "publication_date": "2021-06-01", "reason": "This paper introduces the ALFWorld environment which is one of the four benchmarks used to evaluate the effectiveness of the proposed methods."}, {"fullname_first_author": "Nils Reimers", "paper_title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks", "publication_date": "2019-11-01", "reason": "This paper introduces Sentence-BERT, which is used for generating language embeddings for language feedback."}, {"fullname_first_author": "Michael Janner", "paper_title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem", "publication_date": "2021-12-01", "reason": "This paper provides a theoretical framework and connections between offline reinforcement learning and sequence modeling problems which helps to position the work in the broader context."}, {"fullname_first_author": "Aviral Kumar", "paper_title": "Conservative Q-Learning for Offline Reinforcement Learning", "publication_date": "2020-12-01", "reason": "This paper introduces Conservative Q-Learning (CQL), a key algorithm in offline reinforcement learning which provides a related method for this work."}]}