{"references": [{"fullname_first_author": "Jiaben Chen", "paper_title": "Sportsslomo: A new benchmark and baselines for human-centric video frame interpolation", "publication_date": "2024-00-00", "reason": "This paper provides a benchmark and baselines for human-centric video frame interpolation, which is directly relevant to the MotionBench benchmark proposed in this paper."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70m: Captioning 70m videos with multiple cross-modality teachers", "publication_date": "2024-00-00", "reason": "This paper introduces a large-scale video captioning dataset (Panda-70M), a valuable resource for video understanding research and directly used in creating MotionBench."}, {"fullname_first_author": "Deepak Gupta", "paper_title": "A dataset for medical instructional video classification and question answering", "publication_date": "2023-00-00", "reason": "This paper provides a dataset (MedVid) focusing on medical instructional videos, contributing diverse video content to MotionBench and enhancing its real-world applicability."}, {"fullname_first_author": "Ridouane Ghermi", "paper_title": "Short film dataset (sfd): A benchmark for story-level video understanding", "publication_date": "2024-00-00", "reason": "This paper offers a benchmark (Short Film Dataset) for evaluating story-level video understanding, providing a comparative analysis of different levels of video understanding granularity relevant to MotionBench's focus on motion-level perception."}, {"fullname_first_author": "Zhe Chen", "paper_title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2023-00-00", "reason": "InternVL is a significant vision-language model that directly relates to MotionBench, as it's a state-of-the-art model that the authors evaluate on MotionBench, demonstrating the capabilities and limitations of existing models in fine-grained motion understanding."}]}