[{"figure_path": "https://arxiv.org/html/2502.16922/x1.png", "caption": "Figure 1: A QA pair from a script error correction task and an instance of the Timeline Ito Game with a \u201cfruit size\u201d theme from CTM.\n333The English translation is presented in App.\u00a0B.2.", "description": "Figure 1 presents two examples from the CTM benchmark. The first is a Question Answering (QA) task focusing on script error correction.  A scenario is presented, and the model must identify historical inaccuracies. The example shown includes a scene featuring Li Bai and Bai Juyi together, along with chili peppers and a Guqin, which is historically incorrect given the timelines of their lives and chili pepper introduction to China. The second example illustrates the Timeline Ito Game. This is a collaborative game where models have to infer the chronological order of historical entities, using a thematic metaphor to aid reasoning. In the example, the theme is \"fruit size,\" and the models have to determine the order of three figures from Chinese history (represented by different fruit sizes) based on their historical timelines.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2502.16922/x2.png", "caption": "Figure 2: Statistic of CTM.", "description": "Figure 2 presents a statistical overview of the Chinese Time Reasoning (CTM) benchmark dataset.  It visually summarizes the distribution of various question types within the dataset and also shows the breakdown of the Timeline Ito Game dataset into different difficulty levels based on the number of entities involved.", "section": "2 CTM Dataset"}, {"figure_path": "https://arxiv.org/html/2502.16922/x3.png", "caption": "Figure 3: Average performance of Ito\u2019s Guessing Game. Detailed results can be found in Appendix\u00a0I.", "description": "This figure displays the average performance across different LLMs in the Timeline Ito Game.  It shows the average accuracy of various LLMs in correctly ordering historical entities based on contextual clues and thematic metaphors.  The game involves multiple steps: describing an entity, inferring its rank based on the theme, and determining its order in the timeline.  The figure provides a summary of the overall performance, while the detailed results for each LLM are available in Appendix I.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2502.16922/x4.png", "caption": "Figure 4: Accuracy across entity inter-dynastic intervals under direct prompting setting.\nThe detailed results are shown in Figure\u00a023, Figure\u00a024 and Figure\u00a025.", "description": "This figure displays the accuracy of various large language models (LLMs) in temporal reasoning tasks, specifically focusing on the ability to correctly identify temporal relationships between entities spanning different Chinese dynasties. The x-axis represents the minimum temporal span (in dynasties) between the entities involved in the task, while the y-axis shows the accuracy of the LLMs' predictions.  The graph illustrates how the difficulty of the task, and thus the model accuracy, changes as the time interval between entities increases.  More detailed breakdowns of this accuracy are presented in Figures 23, 24, and 25.", "section": "3.1 Main Results"}, {"figure_path": "https://arxiv.org/html/2502.16922/x5.png", "caption": "Figure 5: Performance in the close-book and open-book settings. Detailed results can be found in App.\u00a0J.", "description": "This figure compares the performance of different LLMs in temporal reasoning tasks under two settings: close-book (no external knowledge) and open-book (allowing access to external information via search engines).  The x-axis represents the different LLMs evaluated.  The y-axis displays the accuracy achieved.  The bars illustrate the performance difference between the two settings for each LLM, highlighting the impact of access to external information on temporal reasoning capabilities. More detailed results are available in Appendix J.", "section": "3. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.16922/x6.png", "caption": "Figure 6: A JSON-format case for historical figure entity.", "description": "This JSON data represents a structured format for storing information about a historical figure.  It includes fields for the person's name (\"\u5c48\u539f\"), the dynasty they lived in (\"\u5148\u79e6\"), their place of birth, birth and death years, and a list of their writings and associated sentences from their works.  Each work is listed with a title and a specific excerpt. This structured format is used to organize the data in a consistent manner for processing by a computer, allowing for easy data retrieval and analysis.", "section": "2.2 Data Collection"}, {"figure_path": "https://arxiv.org/html/2502.16922/x7.png", "caption": "Figure 7: A JSON-format case for place entity.", "description": "The figure displays a JSON-formatted example representing a place entity within the CTM benchmark dataset.  The JSON structure includes fields such as \"dynasty\" (specifying the Chinese dynasty), \"id\", \"begin\" and \"end\" (for temporal range), \"pre_address\" (the modern equivalent of the location), and \"subordinate_units\" (containing information about administrative divisions within the place during that period). This is a structured way of representing the data for historical places within the dataset, facilitating efficient processing and analysis by machine learning models during evaluation.", "section": "2 CTM Dataset"}, {"figure_path": "https://arxiv.org/html/2502.16922/x8.png", "caption": "Figure 8: A JSON-format case for event entity.", "description": "Figure 8 displays a JSON formatted example representing an event entity from the CTM dataset.  It shows the structure used to represent events in a standardized way, including fields like 'id', 'dynasty' (the historical dynasty in which the event occurred), and 'main_figures' (key individuals involved). This structured format facilitates data processing and analysis for tasks involving temporal reasoning.", "section": "2 CTM Dataset"}]