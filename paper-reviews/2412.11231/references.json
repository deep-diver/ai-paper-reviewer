{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-10", "reason": "This paper introduces InstructGPT, a model trained with human feedback to follow instructions, which establishes the instruction tuning paradigm and is fundamental to the work presented."}, {"fullname_first_author": "Chunting Zhou", "paper_title": "LIMA: Less is more for alignment", "publication_date": "2023-12-10", "reason": "This work investigates the effectiveness of instruction tuning data and shows that a smaller, high-quality dataset can achieve comparable performance to much larger datasets, influencing the data selection strategies in this paper."}, {"fullname_first_author": "Can Xu", "paper_title": "WizardLM: Empowering large pre-trained language models to follow complex instructions", "publication_date": "2024-05-07", "reason": "This paper introduces Evol-Instruct, a method for evolving instructions to be more complex and challenging for LLMs, which is a key instruction data construction method compared in this study."}, {"fullname_first_author": "Guanting Dong", "paper_title": "Self-play with execution feedback: Improving instruction-following capabilities of large language models", "publication_date": "2024-06-27", "reason": "This work presents AutoIF, another key instruction data construction method explored in this study, which utilizes a code feedback mechanism to ensure instruction quality."}, {"fullname_first_author": "Weihao Zeng", "paper_title": "Automatic instruction evolving for large language models", "publication_date": "2024-11-12", "reason": "This paper introduces Auto Evol-Instruct, a method for automatically evolving instructions without human intervention, also explored and compared in this study."}]}