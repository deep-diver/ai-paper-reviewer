[{"content": "| Model | Method | Step | Latency (s) | FID\u2193 |\n|---|---|---|---|---|\n| LlamaGen-L | NTP | 576 | 15.20 | 3.16 |\n| LlamaGen-L | ZipAR-16 | 400 (-30.5%) | 10.38 (-24.7%) | 3.32 |\n| LlamaGen-L | ZipAR-12 | 312 (-45.8%) | 8.38 (-39.2%) | 4.50 |\n| LlamaGen-L | ZipAR-8 | 224 (-61.1%) | 6.56 (-52.4%) | 10.22 |", "caption": "Table 1: Quantitative evaluation on ImageNet 256\u00d7256256256256\\times 256256 \u00d7 256 benchmark. Here, \u201cNTP\u201d denotes the next-token prediction paradigm. \u201cZipAR-n\ud835\udc5bnitalic_n\u201d denotes the ZipAR paradigm with a window size of n\ud835\udc5bnitalic_n. \u201cStep\u201d is the number of model forward passes required to generate an image. The latency is measured with a batch size of 1.", "description": "Table 1 presents a quantitative comparison of the performance of different image generation methods on the ImageNet 256x256 benchmark.  The methods compared are the standard next-token prediction (NTP) approach and variations of the proposed ZipAR method using different window sizes (ZipAR-n, where n represents the window size). For each method, the table shows the number of forward passes ('Step') required to generate a single image, the time taken to generate the image ('Latency'), and the Fr\u00e9chet Inception Distance (FID) score, which is a measure of image quality.  A lower FID score indicates better image quality.  The latency is measured using a batch size of 1.  This table helps demonstrate the efficiency improvements of ZipAR compared to the baseline NTP method.", "section": "4.2 Quantitative Results"}, {"content": "| Model | Method | Step | Latency (s) | CLIP Score \u2191 |\n|---|---|---|---|---|\n| LlamaGen-XL | NTP | 1024 | 33.17 | 0.287 |\n| LlamaGen-XL | ZipAR-16 | 544 (-46.8%) | 17.65 (-46.8%) | **0.287** |\n| LlamaGen-XL | ZipAR-12 | 424 (-58.6%) | 12.91 (-61.0%) | 0.286 |\n| LlamaGen-XL | ZipAR-8 | 304 (-70.3%) | 9.44 (-71.5%) | 0.285 |\n| LlamaGen-XL | ZipAR-4 | **184 (-82.0%)** | **5.51 (-83.3%)** | 0.280 |", "caption": "Table 2: Quantitative evaluation on MS-COCO dataset. Here, \u201cNTP\u201d denotes the next-token prediction paradigm. \u201cZipAR-n\ud835\udc5bnitalic_n\u201d denotes the ZipAR paradigm with a window size of n\ud835\udc5bnitalic_n. \u201cStep\u201d is the number of model forward passes required to generate an image. The latency is measured with a batch size of 1.", "description": "Table 2 presents a quantitative comparison of the performance of the next-token prediction (NTP) method and the proposed ZipAR method on the MS-COCO dataset for image generation.  It shows the number of forward passes ('Step'), generation latency (in seconds), and CLIP score (a metric for image quality) for each method.  Different variations of ZipAR are tested, each using a different window size (n) to determine the number of tokens processed simultaneously. The latency is measured using a batch size of 1, providing a consistent evaluation across methods.", "section": "4.2 Quantitative Results"}]