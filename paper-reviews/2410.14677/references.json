{"references": [{" publication_date": "2023", "fullname_first_author": "Sina Alemohammad", "paper_title": "Self-consuming generative models go mad", "reason": "This paper is crucial because it directly addresses the long-term consequences of training LLMs on AI-generated data, highlighting the potential for a self-consuming cycle that leads to a degradation of model capabilities. This directly supports the paper's central argument about the importance of high-quality data for maintaining LLM performance.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Ebtesam Almazrouei", "paper_title": "The falcon series of open language models", "reason": "As a new large language model, Falcon is important because it is used to generate data in several datasets which the main study will analyze and evaluate. Its properties and quality will be used to evaluate the quality of the datasets.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Guangsheng Bao", "paper_title": "Fast-detectgpt: Efficient zero-shot detection of machine-generated text via conditional probability curvature", "reason": "This paper provides a computationally efficient alternative to the DetectGPT framework, addressing one of the limitations of the original method and offering a valuable tool for large-scale analysis of generated text datasets.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Pengcheng He", "paper_title": "Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing", "reason": "DeBERTa is used as one of the main classifiers for detecting AI-generated text, and this paper describes a significant improvement to this model architecture. Using the improved version results in a more accurate evaluation of the datasets.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Daphne Ippolito", "paper_title": "Automatic detection of generated text is easiest when humans are fooled", "reason": "This research highlights the limitations of current methods in evaluating AI-generated texts. Their findings of human biases in the evaluation of text provides essential insights for improving and generating more robust datasets and methods for the detection of AI-generated text.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Xinlei He", "paper_title": "MGTBench: Benchmarking Machine-Generated Text Detection", "reason": "MGTBench is one of the important datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Hans", "paper_title": "Spotting LLMs with binoculars: Zero-shot detection of machine-generated text", "reason": "Binoculars is used as one of the main classifiers for detecting AI-generated text. This paper presents a novel zero-shot approach for AI-generated text detection, offering a valuable contribution to the field and providing further insights for the comparative analysis of detection methods.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Eric Mitchell", "paper_title": "Detectgpt: zero-shot machine-generated text detection using probability curvature", "reason": "DetectGPT is one of the most important methods used in the study to detect AI-generated content and this paper introduces a novel approach to this method. The original DetectGPT framework is computationally expensive, hence the use of the faster version, which is also described in another citation.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "GPT-2 is used to generate text and as the base model in DetectGPT. This paper is foundational for understanding the capabilities and limitations of large language models, providing important context for evaluating the quality of AI-generated text.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "reason": "T5-Large is used in the Fast-DetectGPT method as the perturbation generator. This paper presents a significant advancement in text-to-text transfer learning, providing valuable context for evaluating the perturbation method used in this study.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Areg Mikael Sarvazyan", "paper_title": "Overview of autextification at iberlef 2023: Detection and attribution of machine-generated text in multiple domains", "reason": "AuTexTification and Iber AuTexTification datasets are important benchmarks for evaluating the performance of AI-generated text detection models and this paper provides an overview of the datasets.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Areg Mikael Sarvazyan", "paper_title": "Overview of iberautextification at iberlef 2024: Detection and attribution of machine-generated text on languages of the iberian peninsula", "reason": "Iber AuTexTification dataset is an important benchmark for evaluating the performance of AI-generated text detection models and this paper provides an overview of the datasets.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Tatiana Shamardina", "paper_title": "Findings of the the ruatd shared task 2022 on artificial text detection in russian", "reason": "RuATD is one of the important datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Zhenpeng Su", "paper_title": "Hc3 plus: A semantic-invariant human chatgpt comparison corpus", "reason": "HC3 is one of the datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Mingjie Sun", "paper_title": "Massive activations in large language models", "reason": "This paper introduces the concept of \"massive activations\" in attention maps, which is used as one of the methods for assessing dataset quality. Understanding these patterns helps in distinguishing between human and machine-generated texts.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Eduard Tulchinskii", "paper_title": "Intrinsic dimension estimation for robust detection of ai-generated texts", "reason": "Topological Time Series is used as one of the methods for evaluating datasets, and this paper introduces the concept and methodology for calculating the intrinsic dimensionality of texts. This method provides a novel way to assess dataset quality by examining text structure and complexity.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Vivek Verma", "paper_title": "Ghostbuster: Detecting text ghostwritten by large language models", "reason": "GhostBuster is one of the important datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Anastasia Voznyuk", "paper_title": "Deep-Pavlov at SemEval-2024 task 8: Leveraging transfer learning for detecting boundaries of machine-generated texts", "reason": "SemEval 2024 Task 8 is one of the important datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Yafu Li", "paper_title": "Mage: Machine-generated text detection in the wild", "reason": "MAGE is one of the datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Yuxia Wang", "paper_title": "M4: Multi-generator, multi-domain, and multilingual black-box machine-generated text detection", "reason": "M4 is one of the datasets used in the study. The paper describing this dataset is important for understanding the characteristics and limitations of the benchmark, providing crucial context for evaluating the results in the paper.", "section_number": 3}]}