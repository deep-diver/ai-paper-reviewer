[{"figure_path": "2410.14677/tables/table_4_0.html", "caption": "Table 1: Statistics of the datasets from the shared tasks.", "description": "The table presents statistics of datasets from shared tasks, including the year, language, number of texts, generated vs. human texts, average length, and median length.", "section": "3 Data"}, {"figure_path": "2410.14677/tables/table_5_0.html", "caption": "Table 2: Statistics of the datasets from the research papers.", "description": "Table 2 presents statistics for datasets from research papers, including the year, language, number of texts, generated vs. human text counts, average length, and median length.", "section": "3 Data"}, {"figure_path": "2410.14677/tables/table_6_0.html", "caption": "Table 3: Classification results with different detectors estimated using F\u2081-score. Binoculars and DetectGPT work only with English texts, thus we could not apply them to datasets with non-English texts.", "description": "Table 3 presents the F1-scores achieved by three different detectors (DeBERTa, Binoculars, and DetectGPT) on various datasets, highlighting their performance on English and multilingual texts.", "section": "4 Approach"}, {"figure_path": "2410.14677/tables/table_7_0.html", "caption": "Table 4: Calculated statistics on texts from chosen datasets. In \"Attention Columns\" we show the mean difference between the highest attention column and the second-placed. The first value is for human texts; the second value is for machine-generated. Some values for KLTTS are underlined, because texts are too short, see Section 7.", "description": "Table 4 presents calculated statistics for several datasets, showing the mean difference in attention columns between human and machine-generated texts, and also includes KL divergence scores measuring the similarity of text distributions after adversarial modifications.", "section": "4 Approach"}, {"figure_path": "2410.14677/tables/table_12_0.html", "caption": "Table 7: Best results from each analysed competition. PAN24 used mean of 5 metrics, such as accuracy, F1 and other to evaluate efficiency of the system.", "description": "Table 7 presents the best results obtained in various AI-generated text detection competitions, indicating the performance of different methods evaluated using various metrics.", "section": "3 Data"}, {"figure_path": "2410.14677/tables/table_12_1.html", "caption": "Table 1: Statistics of the datasets from the shared tasks.", "description": "This table presents statistics of datasets from shared tasks, including the year, language, number of texts, number of human and generated texts, average length, and median length.", "section": "3 Data"}, {"figure_path": "2410.14677/tables/table_13_0.html", "caption": "Table 1: Statistics of the datasets from the shared tasks.", "description": "This table presents statistics of datasets from shared tasks, including the year, language, number of texts, number of generated vs human texts, and average and median length.", "section": "3 Data"}, {"figure_path": "2410.14677/tables/table_15_0.html", "caption": "Table 2: Statistics of the datasets from the research papers.", "description": "This table presents statistics for datasets from research papers, including year, language, number of texts, generated vs. human texts, average length, and median length.", "section": "3 Data"}]