{"importance": "This paper is crucial for researchers in video understanding and large vision language models (LVLMs).  It addresses the **scarcity of high-quality datasets for video reasoning**, introducing a novel dataset, VideoEspresso, that will significantly advance the field. The **proposed Hybrid LVLMs Collaboration framework** also presents a new approach for efficient video reasoning, opening up exciting avenues for future work in improving the capabilities of LVLMs in handling complex video tasks. The **automatic construction of VideoEspresso reduces reliance on costly manual annotations**, facilitating the creation of larger and higher-quality video reasoning datasets.", "summary": "VideoEspresso: A new dataset and Hybrid LVLMs framework boost fine-grained video reasoning!", "takeaways": ["VideoEspresso, a large-scale dataset for fine-grained video reasoning via core frame selection, significantly improves the quality and scalability of VideoQA datasets.", "A novel Hybrid LVLMs Collaboration framework leverages a frame selector and a two-stage fine-tuned LVLM to enhance video reasoning capabilities.", "The proposed method outperforms existing baselines on most tasks in the benchmark evaluation, demonstrating superior video reasoning capabilities."], "tldr": "Current VideoQA datasets suffer from **limited scale and insufficient granularity**, hindering the development of effective video reasoning models.  Existing datasets heavily rely on costly manual annotations and often lack the detail needed for complex reasoning tasks.  Automatic methods exist, but these often create redundant data via frame-by-frame analysis, thus limiting scalability and efficiency.\nThis paper introduces VideoEspresso, a novel, large-scale dataset designed to address these limitations.  It utilizes a **semantic-aware method** to automatically generate high-quality VideoQA pairs.  Furthermore, the paper introduces a novel **Hybrid LVLMs Collaboration framework** that combines a frame selector with a two-stage instruction fine-tuned LVLM to perform efficient and accurate video reasoning.  The framework and dataset are rigorously evaluated against existing methods, showcasing **superior performance** on various video reasoning tasks.", "affiliation": "Beihang University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2411.14794/podcast.wav"}