{"references": [{"fullname_first_author": "Yaniv Leviathan", "paper_title": "Fast inference from transformers via speculative decoding", "publication_date": "2023-07-23", "reason": "This paper introduces the core concept of speculative decoding, a technique this paper builds upon."}, {"fullname_first_author": "Charlie Chen", "paper_title": "Accelerating large language model decoding with speculative sampling", "publication_date": "2023-02-01", "reason": "This paper is a key foundational work in speculative decoding that this paper improves upon."}, {"fullname_first_author": "Cunxiao Du", "paper_title": "Glide with a cape: A low-hassle method to accelerate speculative decoding", "publication_date": "2024-07-21", "reason": "This paper proposes a state-of-the-art method in speculative decoding that this paper directly compares against."}, {"fullname_first_author": "Yuhui Li", "paper_title": "EAGLE-2: faster inference of language models with dynamic draft trees", "publication_date": "2024-06-16", "reason": "This paper is another state-of-the-art method that is compared against in this paper's experiments."}, {"fullname_first_author": "Heming Xia", "paper_title": "Unlocking efficiency in large language model inference: A comprehensive survey of speculative decoding", "publication_date": "2024-08-11", "reason": "This survey paper provides a broad overview of the field and is referenced to give context to this paper's contributions."}]}