[{"figure_path": "https://arxiv.org/html/2502.01441/x1.png", "caption": "Figure 1: Box and Whisker Plot: Impulsive noise comparison between pixel and latent spaces. The right column shows the statistics of TD values at 21 discretization steps. Other discretization steps exhibit same behavior, where impulsive outliers are consistently present regardless of the total discretization steps. The blue boxes represent interquartile ranges of the data, while the green and orange dashed lines indicate inner and outer fences, respectively. Outliers are marked with red dots.", "description": "This figure uses box and whisker plots to compare the distribution of data and temporal difference (TD) values in pixel and latent spaces.  The left side shows the distribution of data values in each space, highlighting the presence of extreme outliers (marked in red) in the latent space. These outliers are much more pronounced in the latent space compared to the pixel space. The right side displays the distribution of TD values (calculated at one point in the training process, specifically timestep 21 of a total of 36). Again, the latent space shows a substantially higher concentration and magnitude of outliers in the TD values. The box and whisker plots clearly show that the range of TD values, the interquartile range, and the presence of extreme values differ greatly between the pixel and latent spaces. This difference helps explain why existing consistency training methods perform poorly in latent space due to the significant impact of these impulsive outliers on the loss function.", "section": "4.1 ANALYSIS OF LATENT SPACE"}, {"figure_path": "https://arxiv.org/html/2502.01441/extracted/6175049/figures/func.png", "caption": "(a) Robust Loss", "description": "The figure illustrates a comparison of three robust loss functions: Pseudo-Huber, Cauchy, and Geman-McClure.  The left subplot (a) shows the loss values plotted against the residual (||x - y||/c), demonstrating how each loss function handles outliers. The right subplot (b) displays the derivatives of these loss functions, highlighting their sensitivity to outliers.  The Pseudo-Huber loss shows linear growth for large residuals, while the Cauchy loss exhibits logarithmic growth, and the Geman-McClure loss approaches a constant value. These differences in behavior indicate varying degrees of robustness to outliers, with the Cauchy loss offering a balance between robustness and sensitivity to informative outliers.", "section": "4.2 CAUCHY LOSS AGAINST IMPULSIVE OUTLIER"}, {"figure_path": "https://arxiv.org/html/2502.01441/extracted/6175049/figures/derivative.png", "caption": "(b) Derivative of Robust Loss", "description": "The plot shows the derivative of three different robust loss functions: Pseudo-Huber, Cauchy, and Geman-McClure.  The x-axis represents the normalized residual (||x-y||/c), and the y-axis represents the derivative of the loss function.  The plot visually compares the sensitivity of each loss function to outliers (large residuals).  The Cauchy loss shows a logarithmic increase with increasing residuals, demonstrating robustness to large outliers. The Pseudo-Huber loss shows a linear increase for larger residuals, while the Geman-McClure loss exhibits a sharp decrease to near zero for large residuals, indicating it will tend to ignore outliers.", "section": "4.2 CAUCHY LOSS AGAINST IMPULSIVE OUTLIER"}, {"figure_path": "https://arxiv.org/html/2502.01441/extracted/6175049/figures/output.png", "caption": "Figure 2: Analysis of robust loss: Pseudo-Huber, Cauchy, and Geman-McClure", "description": "This figure compares three robust loss functions: Pseudo-Huber, Cauchy, and Geman-McClure.  Subfigure (a) shows the loss value as a function of the residual error (||x-y||/c) for each loss function, illustrating their different sensitivities to outliers. The Pseudo-Huber loss behaves linearly for large residuals, while the Cauchy loss increases logarithmically and the Geman-McClure loss plateaus at 1. Subfigure (b) presents the derivative of the loss function for each method, further clarifying the behavior of the loss in relation to the residual error and highlighting their different robustness properties when dealing with outliers.", "section": "4.2 CAUCHY LOSS AGAINST IMPULSIVE OUTLIER"}, {"figure_path": "https://arxiv.org/html/2502.01441/x2.png", "caption": "Figure 3: Each iteration, we use optimal transport to produce the optimal coupling. This helps reduce the variance during training, leading to better performance.", "description": "This figure demonstrates the use of optimal transport (OT) to improve the efficiency and stability of the consistency training process.  Optimal transport is used to find the best mapping (coupling) between the noise and data distributions in each training iteration. This optimal coupling minimizes a cost function, effectively reducing the variance during training. By reducing variance, the training process becomes more stable, and ultimately leads to better model performance (as measured by metrics like FID and recall). The visualization likely shows the transport map, illustrating the flow from the noise distribution to the data distribution, potentially highlighting the improved alignment achieved with the use of OT.", "section": "4.4 OT Matching Reduces the Variance"}, {"figure_path": "https://arxiv.org/html/2502.01441/x3.png", "caption": "Figure 4: Model convergence plot on different c\ud835\udc50citalic_c schedule. (Left) Our proposed c\ud835\udc50citalic_c values. Performance on FID (Middle) and Recall (Right) of our proposed c\ud835\udc50citalic_c in comparison with different choices.", "description": "Figure 4 presents a comprehensive analysis of the impact of different scaling parameter (c) schedules on the performance of a consistency model. The left panel displays the proposed adaptive c schedule, demonstrating how c changes over training iterations. The middle and right panels show FID and recall, respectively, illustrating how various c schedules affect model convergence and performance. By comparing the performance metrics under different schedules (including the proposed adaptive schedule against static values of c), the figure provides insights into the optimal strategy for controlling robustness in the training process.", "section": "4.5 ADAPTIVE C SCHEDULER"}, {"figure_path": "https://arxiv.org/html/2502.01441/x4.png", "caption": "(a) CelebA-HQ", "description": "This figure shows the qualitative results of image generation using the proposed method. Specifically, it presents a grid of images generated for the CelebA-HQ dataset, showcasing the quality and diversity of the generated samples.  The images demonstrate the model's ability to produce realistic and high-resolution facial images, highlighting the effectiveness of the improved training technique.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x5.png", "caption": "(b) LSUN Church", "description": "The figure shows the qualitative results of image generation on the LSUN Church dataset using the proposed latent consistency model with one and two sampling steps.  It visually demonstrates the model's ability to generate high-quality, realistic images of church exteriors, showcasing the improvement achieved by the proposed training technique over the baseline iLCT.  The images are arranged in a grid to allow for easy comparison of the generated samples.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x6.png", "caption": "(c) FFHQ", "description": "The figure shows the results of the proposed training technique on the FFHQ dataset at a resolution of 256 x 256 pixels.  The results are presented in terms of FID and Recall metrics, which are standard evaluation measures for generative models. The table showcases a quantitative comparison with various state-of-the-art diffusion and consistency models, highlighting the superior performance achieved by the proposed approach. Lower FID values indicate better image quality and higher Recall suggests higher diversity of generated samples.", "section": "5.1 Performance of our training technique"}, {"figure_path": "https://arxiv.org/html/2502.01441/x7.png", "caption": "Figure 5: Our qualitative results using 1-NFE at resolution 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure showcases the qualitative results obtained from the proposed model.  Specifically, it presents sample images generated using only one forward diffusion step (1-NFE) at a resolution of 256x256 pixels. The images are visually compared across three different datasets: CelebA-HQ (faces), LSUN Church (church exteriors), and FFHQ (high-resolution faces). This provides a visual demonstration of the model's ability to generate high-quality images with a minimal number of diffusion steps. The improved image quality reflects the model's effectiveness and efficiency.", "section": "5 EXPERIMENT"}, {"figure_path": "https://arxiv.org/html/2502.01441/x8.png", "caption": "(a) CelebA-HQ", "description": "This figure shows a qualitative comparison of images generated by the proposed model and the baseline model.  The subfigure (a) displays images generated for the CelebA-HQ dataset.  The figure demonstrates the improved quality of images generated by the proposed model compared to the baseline.  This highlights the effectiveness of the proposed training techniques.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x9.png", "caption": "(b) LSUN Church", "description": "The figure shows the qualitative results of the proposed method on the LSUN Church dataset.  The images demonstrate the model's ability to generate realistic and high-quality images of church scenes, showcasing architectural details and overall scene composition.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x10.png", "caption": "(c) FFHQ", "description": "This figure displays the quantitative results obtained by the proposed training technique on the FFHQ dataset.  It presents key metrics like FID (Fr\u00e9chet Inception Distance) and Recall, along with the number of function evaluations (NFE), to evaluate the quality of generated images.  The table likely includes comparisons to other state-of-the-art models on the same dataset.", "section": "5.1 Performance of our training technique"}, {"figure_path": "https://arxiv.org/html/2502.01441/x11.png", "caption": "Figure 6: iLCT qualitative results using 1-NFE at resolution 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays the qualitative results obtained from the iLCT model (Improved Latent Consistency Training) when generating images with only one forward diffusion step (1-NFE). The images are generated at a resolution of 256x256 pixels. The purpose is to showcase the quality of images produced by the iLCT model in comparison to other models, highlighting its strengths and weaknesses in terms of image generation quality and diversity.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x12.png", "caption": "Figure 7: One-step samples on CelebA-HQ 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays a grid of images generated using the improved latent consistency training technique.  Each image is a sample produced in a single step (one-step sampling) and represents the model's output after applying the proposed training enhancements. The dataset used to train the model is CelebA-HQ, and the generated images are 256x256 pixels in resolution. This visual showcases the quality and diversity of the generated images, demonstrating the effectiveness of the improved technique.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x13.png", "caption": "Figure 8: Two-step samples on CelebA-HQ 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays the results of generating images using a latent consistency model with two sampling steps. The images are of size 256x256 pixels and belong to the CelebA-HQ dataset, which is known for its high-quality celebrity face images.  The figure demonstrates the model's ability to generate diverse and realistic-looking faces after undergoing a two-step sampling process, highlighting the quality and detail achievable with the proposed method.", "section": "Appendix"}, {"figure_path": "https://arxiv.org/html/2502.01441/x14.png", "caption": "Figure 9: One-step samples on LSUN Church 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays a grid of images generated by a one-step sampling method on the LSUN Church dataset. The images are 256x256 pixels.  The figure serves as a qualitative evaluation of the model's ability to generate realistic and diverse images of church scenes. It is intended to visually demonstrate the quality of the generated images.", "section": "5 Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x15.png", "caption": "Figure 10: Two-step samples on LSUN Church 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays images generated using a latent consistency model trained with the improved techniques presented in the paper.  Specifically, it showcases the results of a two-step sampling process on the LSUN Church dataset. Each image in the grid is an example of a generated church scene, demonstrating the model's ability to generate detailed and varied church architecture. The resolution of each generated image is 256x256 pixels.", "section": "5. Experiment"}, {"figure_path": "https://arxiv.org/html/2502.01441/x16.png", "caption": "Figure 11: One-step samples on FFHQ 256\u00d7256256256256\\times 256256 \u00d7 256", "description": "This figure displays the results of generating images using a one-step sampling method on the FFHQ dataset with a resolution of 256x256 pixels.  The images represent a selection of generated samples and showcase the model's ability to produce realistic-looking high-resolution images of faces.  The quality and diversity of the generated images are indicative of the model's performance.", "section": "5 Experiment"}]