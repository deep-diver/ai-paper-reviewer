<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Lifelong Sequential Knowledge Editing without Model Degradation &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="Lifelong Sequential Knowledge Editing without Model Degradation &#183; HF Daily Paper Reviews by AI"><meta name=description content="ENCORE enables lifelong sequential knowledge editing in LLMs without performance loss, achieving 10,000 edits while maintaining downstream accuracy."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ UC Berkeley,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="Lifelong Sequential Knowledge Editing without Model Degradation"><meta property="og:description" content="ENCORE enables lifelong sequential knowledge editing in LLMs without performance loss, achieving 10,000 edits while maintaining downstream accuracy."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-02-03T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-03T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ UC Berkeley"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/cover.png"><meta name=twitter:title content="Lifelong Sequential Knowledge Editing without Model Degradation"><meta name=twitter:description content="ENCORE enables lifelong sequential knowledge editing in LLMs without performance loss, achieving 10,000 edits while maintaining downstream accuracy."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Lifelong Sequential Knowledge Editing without Model Degradation","headline":"Lifelong Sequential Knowledge Editing without Model Degradation","abstract":"ENCORE enables lifelong sequential knowledge editing in LLMs without performance loss, achieving 10,000 edits while maintaining downstream accuracy.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2502.01636\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-02-03T00:00:00\u002b00:00","datePublished":"2025-02-03T00:00:00\u002b00:00","dateModified":"2025-02-03T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ UC Berkeley"],"mainEntityOfPage":"true","wordCount":"13067"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-02-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-20</p></a><a href=/ai-paper-reviewer/2025-02-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-21</p></a><a href=/ai-paper-reviewer/2025-02-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-24</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-20</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-21</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-24/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-24</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2502.01636/cover_hu13762596824362073102.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2502.01636/>Lifelong Sequential Knowledge Editing without Model Degradation</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Lifelong Sequential Knowledge Editing without Model Degradation</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-02-03T00:00:00+00:00>3 February 2025</time><span class="px-2 text-primary-500">&#183;</span><span>13067 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">62 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2502.01636/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2502.01636/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-uc-berkeley/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ UC Berkeley</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#locate-then-edit-issues>Locate-then-Edit Issues</a></li><li><a href=#encore-framework>ENCORE Framework</a></li><li><a href=#norm-growth-analysis>Norm Growth Analysis</a></li><li><a href=#overfitting-mitigation>Overfitting Mitigation</a></li><li><a href=#future-directions>Future Directions</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#locate-then-edit-issues>Locate-then-Edit Issues</a></li><li><a href=#encore-framework>ENCORE Framework</a></li><li><a href=#norm-growth-analysis>Norm Growth Analysis</a></li><li><a href=#overfitting-mitigation>Overfitting Mitigation</a></li><li><a href=#future-directions>Future Directions</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2502.01636</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Akshat Gupta et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-02-04</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2502.01636 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2502.01636 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2502.01636/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Current methods for adding or updating knowledge in large language models (LLMs) face challenges: <strong>performing many edits leads to a decline in the model&rsquo;s overall performance</strong>. This happens because these methods tend to overfit on new information and create disproportionate growth in the parameters being updated. This issue limits the scalability and practical applicability of these techniques.</p><p>To address these challenges, the researchers introduce ENCORE, a new technique that prevents both overfitting and excessive parameter growth. <strong>ENCORE uses a combination of early stopping criteria (MPES) and a constraint to limit the magnitude of parameter updates</strong>. The results demonstrate that ENCORE successfully performs up to 10,000 sequential edits without significant performance degradation, significantly outperforming existing methods in terms of both accuracy and speed.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-d23db8c5de60c88b5217842603c9303a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-d23db8c5de60c88b5217842603c9303a",{strings:[" Sequential knowledge editing in LLMs suffers from model degradation due to overfitting and disproportionate norm growth. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-a10b1730787b58b8307cc18f9946fef3></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-a10b1730787b58b8307cc18f9946fef3",{strings:[" ENCORE, a novel method combining early stopping and norm constraints, mitigates these issues enabling 10,000+ sequential edits. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-60cee62ba785758b5cb7aa22d5f6de2a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-60cee62ba785758b5cb7aa22d5f6de2a",{strings:[" ENCORE significantly outperforms existing methods in both editing performance and efficiency. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial for researchers in natural language processing and machine learning, especially those working on knowledge editing and large language models. It addresses a critical limitation of current methods‚Äî<strong>model degradation during sequential editing</strong>‚Äîand proposes a novel solution, opening avenues for improved knowledge integration in LLMs. The efficient method and comprehensive analysis are highly valuable to the field.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/main-paper-figures/memit-llama3-weight-norm.png alt></figure></p><blockquote><p>üîº The figure shows the continuous growth of the Frobenius norm of edited MLP matrices in the Llama3-8B model during sequential knowledge editing using the MEMIT method. The x-axis represents the number of edits, and the y-axis represents the Frobenius norm. The figure illustrates how the norm increases disproportionately with each sequential edit, suggesting a potential cause for model degradation.</p><details><summary>read the caption</summary>(a) MEMIT</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=S3.T1.9.9><tr class=ltx_tr id=S3.T1.9.9.10><td class="ltx_td ltx_align_left ltx_border_tt" id=S3.T1.9.9.10.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.1.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id=S3.T1.9.9.10.2><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.2.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S3.T1.9.9.10.3><span class=ltx_text id=S3.T1.9.9.10.3.1></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.3.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.3.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=S3.T1.9.9.10.3.3.1><span class=ltx_tr id=S3.T1.9.9.10.3.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.3.3.1.1.1>Original Fact</span></span>
<span class=ltx_tr id=S3.T1.9.9.10.3.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.3.3.1.2.1>Prob</span></span>
</span></span><span class=ltx_text id=S3.T1.9.9.10.3.4></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.3.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S3.T1.9.9.10.4><span class=ltx_text id=S3.T1.9.9.10.4.1></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.4.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.4.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=S3.T1.9.9.10.4.3.1><span class=ltx_tr id=S3.T1.9.9.10.4.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.4.3.1.1.1>Edited Fact</span></span>
<span class=ltx_tr id=S3.T1.9.9.10.4.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.4.3.1.2.1>Prob w/o MPES</span></span>
</span></span><span class=ltx_text id=S3.T1.9.9.10.4.4></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.4.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id=S3.T1.9.9.10.5><span class=ltx_text id=S3.T1.9.9.10.5.1></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.5.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.5.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=S3.T1.9.9.10.5.3.1><span class=ltx_tr id=S3.T1.9.9.10.5.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.5.3.1.1.1>Edited Fact</span></span>
<span class=ltx_tr id=S3.T1.9.9.10.5.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.5.3.1.2.1>Prob w/ MPES</span></span>
</span></span><span class=ltx_text id=S3.T1.9.9.10.5.4></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.5.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S3.T1.9.9.10.6><span class=ltx_text id=S3.T1.9.9.10.6.1></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.6.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.6.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=S3.T1.9.9.10.6.3.1><span class=ltx_tr id=S3.T1.9.9.10.6.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.6.3.1.1.1>Time Per Edit</span></span>
<span class=ltx_tr id=S3.T1.9.9.10.6.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.6.3.1.2.1>w/o MPES (s)</span></span>
</span></span><span class=ltx_text id=S3.T1.9.9.10.6.4></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.6.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S3.T1.9.9.10.7><span class=ltx_text id=S3.T1.9.9.10.7.1></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.7.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.7.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=S3.T1.9.9.10.7.3.1><span class=ltx_tr id=S3.T1.9.9.10.7.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.7.3.1.1.1>Time Per Edit</span></span>
<span class=ltx_tr id=S3.T1.9.9.10.7.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S3.T1.9.9.10.7.3.1.2.1>w/ MPES (s)</span></span>
</span></span><span class=ltx_text id=S3.T1.9.9.10.7.4></span><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.10.7.5 style=font-size:90%></span></td></tr><tr class=ltx_tr id=S3.T1.1.1.1><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T1.1.1.1.2><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.2.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.1.1.1.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.3.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.1.1.1.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.4.1 style=font-size:90%>0.39</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.1.1.1.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.5.1 style=font-size:90%>0.98</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.1.1.1.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.6.1 style=font-size:90%>0.47</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.1.1.1.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.7.1 style=font-size:90%>1.26</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.1.1.1.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.1.1 style=font-size:90%>0.63 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.1.1.1.1.2 style=font-size:90%> 50%)</span></td></tr><tr class=ltx_tr id=S3.T1.2.2.2><td class=ltx_td id=S3.T1.2.2.2.2></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.2.2.2.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.3.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S3.T1.2.2.2.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.4.1 style=font-size:90%>0.52</span></td><td class="ltx_td ltx_align_center" id=S3.T1.2.2.2.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.5.1 style=font-size:90%>0.92</span></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.2.2.2.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.6.1 style=font-size:90%>0.59</span></td><td class="ltx_td ltx_align_center" id=S3.T1.2.2.2.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.7.1 style=font-size:90%>6.61</span></td><td class="ltx_td ltx_align_center" id=S3.T1.2.2.2.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.1.1 style=font-size:90%>1.86 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.2.2.2.1.m1.1"><semantics id="S3.T1.2.2.2.1.m1.1a"><mo id="S3.T1.2.2.2.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.2.2.2.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.1.m1.1b"><ci id="S3.T1.2.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.2.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.2.2.2.1.2 style=font-size:90%> 71%)</span></td></tr><tr class=ltx_tr id=S3.T1.3.3.3><td class=ltx_td id=S3.T1.3.3.3.2></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.3.3.3.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.3.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S3.T1.3.3.3.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.4.1 style=font-size:90%>0.49</span></td><td class="ltx_td ltx_align_center" id=S3.T1.3.3.3.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.5.1 style=font-size:90%>0.99</span></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.3.3.3.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.6.1 style=font-size:90%>0.61</span></td><td class="ltx_td ltx_align_center" id=S3.T1.3.3.3.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.7.1 style=font-size:90%>7.65</span></td><td class="ltx_td ltx_align_center" id=S3.T1.3.3.3.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.1.1 style=font-size:90%>1.86 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.3.3.3.1.m1.1"><semantics id="S3.T1.3.3.3.1.m1.1a"><mo id="S3.T1.3.3.3.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.3.3.3.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><ci id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.3.3.3.1.2 style=font-size:90%> 76%)</span></td></tr><tr class=ltx_tr id=S3.T1.4.4.4><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T1.4.4.4.2><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.2.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.4.4.4.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.3.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.4.4.4.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.4.1 style=font-size:90%>0.39</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.4.4.4.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.5.1 style=font-size:90%>0.65</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.4.4.4.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.6.1 style=font-size:90%>0.14</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.4.4.4.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.7.1 style=font-size:90%>1.60</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.4.4.4.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.1.1 style=font-size:90%>0.97 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.4.4.4.1.m1.1"><semantics id="S3.T1.4.4.4.1.m1.1a"><mo id="S3.T1.4.4.4.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.4.4.4.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.1.m1.1b"><ci id="S3.T1.4.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.4.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.4.4.4.1.2 style=font-size:90%> 39%)</span></td></tr><tr class=ltx_tr id=S3.T1.5.5.5><td class=ltx_td id=S3.T1.5.5.5.2></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.5.5.5.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.3.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S3.T1.5.5.5.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.4.1 style=font-size:90%>0.52</span></td><td class="ltx_td ltx_align_center" id=S3.T1.5.5.5.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.5.1 style=font-size:90%>0.75</span></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.5.5.5.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.6.1 style=font-size:90%>0.41</span></td><td class="ltx_td ltx_align_center" id=S3.T1.5.5.5.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.7.1 style=font-size:90%>4.84</span></td><td class="ltx_td ltx_align_center" id=S3.T1.5.5.5.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.1.1 style=font-size:90%>2.79 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.5.5.5.1.m1.1"><semantics id="S3.T1.5.5.5.1.m1.1a"><mo id="S3.T1.5.5.5.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.5.5.5.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.1b"><ci id="S3.T1.5.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.5.5.5.1.2 style=font-size:90%> 42%)</span></td></tr><tr class=ltx_tr id=S3.T1.6.6.6><td class=ltx_td id=S3.T1.6.6.6.2></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.6.6.6.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.3.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S3.T1.6.6.6.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.4.1 style=font-size:90%>0.49</span></td><td class="ltx_td ltx_align_center" id=S3.T1.6.6.6.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.5.1 style=font-size:90%>0.77</span></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.6.6.6.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.6.1 style=font-size:90%>0.41</span></td><td class="ltx_td ltx_align_center" id=S3.T1.6.6.6.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.7.1 style=font-size:90%>8.71</span></td><td class="ltx_td ltx_align_center" id=S3.T1.6.6.6.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.1.1 style=font-size:90%>3.31 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.6.6.6.1.m1.1"><semantics id="S3.T1.6.6.6.1.m1.1a"><mo id="S3.T1.6.6.6.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.6.6.6.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.1.m1.1b"><ci id="S3.T1.6.6.6.1.m1.1.1.cmml" xref="S3.T1.6.6.6.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.6.6.6.1.2 style=font-size:90%> 61%)</span></td></tr><tr class=ltx_tr id=S3.T1.7.7.7><td class="ltx_td ltx_align_left ltx_border_t" id=S3.T1.7.7.7.2><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.2.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.7.7.7.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.3.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.7.7.7.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.4.1 style=font-size:90%>0.39</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.7.7.7.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.5.1 style=font-size:90%>0.98</span></td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S3.T1.7.7.7.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.6.1 style=font-size:90%>0.39</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.7.7.7.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.7.1 style=font-size:90%>1.49</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S3.T1.7.7.7.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.1.1 style=font-size:90%>0.83 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.7.7.7.1.m1.1"><semantics id="S3.T1.7.7.7.1.m1.1a"><mo id="S3.T1.7.7.7.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.7.7.7.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><ci id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.7.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.7.7.7.1.2 style=font-size:90%> 44%)</span></td></tr><tr class=ltx_tr id=S3.T1.8.8.8><td class=ltx_td id=S3.T1.8.8.8.2></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.8.8.8.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.3.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S3.T1.8.8.8.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.4.1 style=font-size:90%>0.52</span></td><td class="ltx_td ltx_align_center" id=S3.T1.8.8.8.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.5.1 style=font-size:90%>0.84</span></td><td class="ltx_td ltx_align_center ltx_border_r" id=S3.T1.8.8.8.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.6.1 style=font-size:90%>0.37</span></td><td class="ltx_td ltx_align_center" id=S3.T1.8.8.8.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.7.1 style=font-size:90%>5.89</span></td><td class="ltx_td ltx_align_center" id=S3.T1.8.8.8.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.1.1 style=font-size:90%>2.69 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.8.8.8.1.m1.1"><semantics id="S3.T1.8.8.8.1.m1.1a"><mo id="S3.T1.8.8.8.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.8.8.8.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.1.m1.1b"><ci id="S3.T1.8.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.8.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.8.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.8.8.8.1.2 style=font-size:90%> 54%)</span></td></tr><tr class=ltx_tr id=S3.T1.9.9.9><td class="ltx_td ltx_border_bb" id=S3.T1.9.9.9.2></td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id=S3.T1.9.9.9.3><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.3.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S3.T1.9.9.9.4><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.4.1 style=font-size:90%>0.49</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S3.T1.9.9.9.5><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.5.1 style=font-size:90%>0.75</span></td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id=S3.T1.9.9.9.6><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.6.1 style=font-size:90%>0.33</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S3.T1.9.9.9.7><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.7.1 style=font-size:90%>9.44</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S3.T1.9.9.9.1><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.1.1 style=font-size:90%>3.43 (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.9.9.9.1.m1.1"><semantics id="S3.T1.9.9.9.1.m1.1a"><mo id="S3.T1.9.9.9.1.m1.1.1" mathsize="90%" stretchy="false" xref="S3.T1.9.9.9.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.1b"><ci id="S3.T1.9.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.9.1.m1.1d">‚Üì</annotation></semantics></math><span class="ltx_text ltx_font_smallcaps" id=S3.T1.9.9.9.1.2 style=font-size:90%> 63%)</span></td></tr></table></table></figure><blockquote><p>üîº This table compares the prediction probabilities of facts that have been edited into the model using different knowledge editing methods, against the probabilities of facts that the model already knew from its pretraining. It shows that methods without Most-Probable Early Stopping (MPES) tend to overfit on the edited facts, assigning them unrealistically high probabilities. MPES mitigates this overfitting, resulting in more natural prediction probabilities. The table also demonstrates the significant speed improvements achieved by MPES, showing that it is 39% to 76% faster than other methods.</p><details><summary>read the caption</summary>Table 1: Comparison between prediction probabilities of edited facts versus facts that a model knows through pretraining. MPES results in more natural prediction probabilities while being 39% - 76% faster than other methods.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Locate-then-Edit Issues<div id=locate-then-edit-issues class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#locate-then-edit-issues aria-label=Anchor>#</a></span></h4><p>Locate-then-edit methods, while efficient, present two key issues. First, <strong>overfitting</strong> on edited facts occurs because the optimization process excessively focuses on ensuring correct predictions for those specific facts. This leads to unusually high confidence scores for edited information, potentially at the expense of the model&rsquo;s general performance. Second, there is <strong>disproportionate norm growth</strong> in the edited matrices, meaning the updated weights increase in magnitude much more significantly than other parts of the model. This hidden &ldquo;importance hacking&rdquo; allows outputs from these edited layers to dominate the final model output, potentially hindering the model&rsquo;s ability to incorporate and balance information from other parts of the network. These issues collectively contribute to downstream performance degradation after multiple edits, revealing a limitation in the current approach to knowledge editing.</p><h4 class="relative group">ENCORE Framework<div id=encore-framework class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#encore-framework aria-label=Anchor>#</a></span></h4><p>The ENCORE framework, designed for lifelong sequential knowledge editing, tackles the critical issue of model degradation during extensive edits. <strong>It directly addresses the overfitting and disproportionate norm growth problems</strong> inherent in many locate-then-edit methods. ENCORE achieves this through two key mechanisms: <strong>Most-Probable Early Stopping (MPES)</strong> prevents overfitting by halting gradient descent when the edited facts reach maximum probability, thus improving generalization. <strong>Simultaneously, a Frobenius-norm constraint</strong> controls the growth of edited matrix norms, preventing the dominance of edited layers and ensuring the model retains broader capabilities. This combined approach allows ENCORE to perform significantly more sequential edits (up to 10,000) while maintaining downstream performance and achieving faster edit speeds compared to previous methods. The framework&rsquo;s success hinges on its nuanced understanding of the interplay between overfitting, norm growth, and the inner workings of locate-then-edit methods, offering a powerful solution for robust and scalable knowledge editing in large language models.</p><h4 class="relative group">Norm Growth Analysis<div id=norm-growth-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#norm-growth-analysis aria-label=Anchor>#</a></span></h4><p>Analyzing norm growth in the context of lifelong sequential knowledge editing reveals crucial insights into model behavior. <strong>Disproportionate increases in the Frobenius norm of edited weight matrices</strong> during sequential editing are observed, indicating that these matrices gain undue influence over the model&rsquo;s output. This phenomenon, termed &ldquo;importance hacking,&rdquo; allows the edited layers to override information from other parts of the model, leading to successful edits but potentially harming the model&rsquo;s overall performance on unrelated tasks. <strong>The growth is not random</strong>; it consistently increases with each edit, highlighting a systematic issue within the locate-then-edit methods. This observation suggests a need to constrain the norm growth. By controlling this growth, <strong>we can mitigate overfitting to specific facts and reduce the model&rsquo;s tendency to over-rely on recently edited information.</strong> This approach paves the way for more robust and reliable lifelong sequential knowledge editing without significant performance degradation.</p><h4 class="relative group">Overfitting Mitigation<div id=overfitting-mitigation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#overfitting-mitigation aria-label=Anchor>#</a></span></h4><p>Overfitting is a critical concern in machine learning, especially when dealing with complex models and limited data. In the context of knowledge editing, overfitting manifests as the model becoming overly reliant on the newly added or corrected information, neglecting previously learned knowledge. This can lead to poor generalization and reduced performance on unseen data. <strong>Effective overfitting mitigation strategies are therefore crucial for successful knowledge editing.</strong> Techniques such as early stopping, regularization, and data augmentation can be employed to address this issue. Early stopping prevents the model from training for too long, reducing the risk of overfitting. Regularization techniques, such as adding penalty terms to the loss function, constrain model complexity, discouraging overfitting. Data augmentation increases the diversity of the training dataset, making the model less sensitive to specific characteristics of the limited dataset. <strong>Careful selection and tuning of these techniques are necessary to achieve the best balance between model accuracy and generalization ability</strong> in the context of knowledge editing.</p><h4 class="relative group">Future Directions<div id=future-directions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-directions aria-label=Anchor>#</a></span></h4><p>Future research could explore extending ENCORE&rsquo;s capabilities to handle more complex edits, such as those involving multiple facts or relationships. <strong>Investigating the impact of different norm constraints and early stopping criteria</strong> on both editing performance and downstream task performance would be valuable. A deeper understanding of the theoretical underpinnings of norm growth and its relation to model overfitting is needed, potentially involving analysis of activation patterns and information flow within the model&rsquo;s layers. <strong>Furthermore, exploring the robustness and generalization of ENCORE across diverse model architectures and datasets</strong> is crucial to solidify its potential as a general-purpose knowledge editing framework. Finally, <strong>addressing ethical concerns surrounding knowledge editing</strong> requires careful consideration and investigation of the potential for misuse or unintended consequences.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/main-paper-figures/alphaedit-llama3-weight-norm.png alt></figure></p><blockquote><p>üîº The figure shows the continuous growth of the Frobenius norm of edited multi-layer perceptron (MLP) matrices in the LLama3-8B model during sequential knowledge editing using AlphaEdit. The x-axis represents the number of edits performed, and the y-axis shows the Frobenius norm. Each line represents a different layer within the MLP.</p><details><summary>read the caption</summary>(b) AlphaEdit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/ft-step1.png alt></figure></p><blockquote><p>üîº This figure visualizes the continuous increase in the Frobenius norm of edited multi-layer perceptron (MLP) matrices within the LLaMA3-8B model during sequential knowledge editing. Two subfigures are presented: (a) shows the norm growth for the MEMIT method, and (b) shows the norm growth for the AlphaEdit method. The x-axis represents the number of sequential edits performed, while the y-axis represents the Frobenius norm. The plots illustrate that the norm consistently increases with each sequential edit, regardless of the method used. This observation highlights a potential issue where continuous norm growth might lead to model degradation.</p><details><summary>read the caption</summary>Figure 1: The continuous growth of norm of edited MLP matrices in LLama3-8B during sequential knowledge editing, as a function of number edits.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/ft-step2.png alt></figure></p><blockquote><p>üîº This figure shows the first step in the locate-then-edit knowledge editing method. The goal is to find the optimal activation vector for the second MLP matrix in a Transformer decoder layer. Gradient descent is used to modify the model&rsquo;s weights, which will result in the model producing the correct output (target activation) when provided with a specific input. This step focuses solely on finding the desired activation, without directly updating the model&rsquo;s weights.</p><details><summary>read the caption</summary>(a) Gradient descent step which finds the target activations for the MLP matrix.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-combo-plots/MEMIT_downstream_f1_combined_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the second step in the locate-then-edit knowledge editing method. The first step (not shown in this figure) uses gradient descent to find an ideal activation vector. This vector represents the desired output for a specific fact that is being edited into the model. In this second step, the found activation vector is used as a target. A least squares loss function is applied to update the weights (in red) of the second Multilayer Perceptron (MLP) matrix within a selected layer. The goal is to adjust the MLP weights so the model produces the target activation (and consequently the edited fact) when presented with a related query, while preserving the model&rsquo;s output for other, unrelated inputs.</p><details><summary>read the caption</summary>(b) Target activations are used to update the second MLP matrix (in red).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-combo-plots/AlphaEdit_downstream_f1_combined_mpes.png alt></figure></p><blockquote><p>üîº This figure illustrates the two-step process of locate-then-edit knowledge editing methods. The first step uses gradient descent to find the optimal activation vector for the MLP matrix being edited. The second step updates this weight matrix using a least-squares loss function that aims to retain the outputs for unrelated contexts while producing the target activation for the edited fact.</p><details><summary>read the caption</summary>Figure 2: Presenting locate-then-edit knowledge editing methods as a two-step fine-tuning process.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-combo-plots/EMMET_downstream_f1_combined_mpes.png alt></figure></p><blockquote><p>üîº The figure shows the continuous growth of the Frobenius norm of edited MLP matrices in the Llama-3B model during sequential knowledge editing using the MEMIT method. The x-axis represents the number of edits performed, and the y-axis represents the Frobenius norm. Different lines represent different layers within the model, illustrating how the norm increases with each sequential edit.</p><details><summary>read the caption</summary>(a) MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_alphaedit.png alt></figure></p><blockquote><p>üîº The figure shows the continuous growth of the Frobenius norm of edited multilayer perceptron (MLP) matrices in the LLama-3B model during sequential knowledge editing using the AlphaEdit method. The x-axis represents the number of edits performed, and the y-axis represents the Frobenius norm. Separate lines show the norm growth for different layers of the MLP. The graph illustrates the significant increase in the norm of the edited matrices as more edits are performed, indicating a potential issue with the AlphaEdit method.</p><details><summary>read the caption</summary>(b) AlphaEdit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_memit.png alt></figure></p><blockquote><p>üîº This figure shows the average downstream performance (F1 score) across six tasks (MMLU, NLI, RTE, SST2, MRPC, and CoLA) for the EMMET algorithm over 10,000 sequential edits. It illustrates the model&rsquo;s performance degradation over time, demonstrating the impact of sequential knowledge editing on the overall capabilities of the language model. The x-axis represents the number of edits (in batches of 100), and the y-axis shows the average F1 score across the six tasks. Different colored lines show the performance for different model sizes (Llama2 and Llama3).</p><details><summary>read the caption</summary>(c) EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_baseline_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure displays the average performance across six downstream tasks (detailed in Section 2) for three different knowledge editing methods: MEMIT, AlphaEdit, and EMMET. Each method is tested on two different language models, Llama3-8B and Llama2-7B, with and without the Most-Probable Early Stopping (MPES) technique. The x-axis represents the number of edits performed, and the y-axis shows the F1 score, a common metric for evaluating model performance. The graph illustrates how the MPES technique helps mitigate the performance degradation typically observed with sequential knowledge editing, especially over a larger number of edits. This is shown by a slower decline in the F1 score for methods that utilize MPES.</p><details><summary>read the caption</summary>Figure 3: Average downstream performance measured over 6 tasks (sec 2) for MEMIT, AlphaEdit and EMMET. We see that MPES is able to delay loss of downstream performance for both Llama3-8B and Llama2-7B with additional gains in efficiencey.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_alphaedit_llama3-8b.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of edited MLP matrices in Llama-3-8B during sequential knowledge editing using AlphaEdit. It illustrates the disproportionate growth of the norm in the edited layers (4-8) as the number of edits increases, highlighting a key finding about the inner workings of locate-then-edit methods discussed in the paper.</p><details><summary>read the caption</summary>(a) Alphaedit (Llama3-8B)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_llama3-8b.png alt></figure></p><blockquote><p>üîº The figure shows the continuous growth of the Frobenius norm of edited MLP matrices in the Llama3-8B model during sequential knowledge editing using the MEMIT method. The x-axis represents the number of edits performed, and the y-axis represents the Frobenius norm. The graph displays a clear upward trend for all layers (4-8), indicating that the norm consistently increases as more edits are performed.</p><details><summary>read the caption</summary>(b) MEMIT (Llama3-8B)</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_llama3-8b_combination.png alt></figure></p><blockquote><p>üîº This figure compares the Frobenius norm (a matrix norm) of the edited MLP (Multilayer Perceptron) matrices against the unedited MLP matrices, after 5,000 and 10,000 sequential edits using AlphaEdit and MEMIT methods. It visualizes the disproportionate growth of the norm for the edited layers compared to the rest of the model, highlighting the norm increase over 10 times its original value for MEMIT and twice for AlphaEdit. This disproportionate growth indicates the &lsquo;importance hacking&rsquo; effect described in the paper, where the output from edited layers becomes overly dominant in the model&rsquo;s output.</p><details><summary>read the caption</summary>Figure 4: Comparison between norm of edited MLP matrices and norm of unedited matrices after 5,000 and 10,000 sequential edits.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-combo-plots/MEMIT_downstream_f1_combined_llama2.png alt></figure></p><blockquote><p>üîº This figure shows the proportional contribution of the activation vectors generated from each sub-module of the unedited Llama3-8B model to the overall residual stream. It visualizes the relative influence of different model components (e.g., input, self-attention, MLP layers) on the final model output before any knowledge editing takes place. The proportion of contribution is represented as the average norm ratio for each layer type.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Unedited Llama3-8B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-combo-plots/MEMIT_downstream_f1_combined_llama3.png alt></figure></p><blockquote><p>üîº The figure shows the proportion of the contribution of activation vectors produced from each sub-module to the residual stream for Llama3-8B after applying AlphaEdit. The edited layers are highlighted in red. The figure demonstrates how the influence of the output of edited layers grows dramatically after continuous editing, showing that the edited layers&rsquo; contributions become disproportionately larger compared to other parts of the model.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for Llama3-8B using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_regmemit_encore.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the total activation vector norm that comes from each layer in the Llama-3-8B model after applying 10,000 sequential edits using the MEMIT algorithm. The x-axis represents different layer types (e.g., input embeddings, attention, MLP), and the y-axis shows the proportion of the total norm contributed by each layer type. The figure visually demonstrates the disproportionate contribution of the edited layers (highlighted in red) to the model&rsquo;s output after sequential edits, indicating that these layers have an increased influence compared to other layers. This is a visual representation of the &lsquo;importance hacking&rsquo; phenomenon discussed in the paper.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for Llama3-8B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth-subset/new_weights_norm_encore.png alt></figure></p><blockquote><p>üîº This figure displays the proportion of the total activation vector norm contributed by each layer type in the Llama3-8B model after undergoing 10,000 sequential knowledge edits using the ENCORE method. It visually represents how the influence of different layer types on the final model output changes due to the application of ENCORE. It helps to demonstrate ENCORE&rsquo;s impact on the activation norms and the distribution of influence across the layers of the model.</p><details><summary>read the caption</summary>(d) Average Norm Proportion for Llama3-8B using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_base_gpt2-xl.png alt></figure></p><blockquote><p>üîº This figure visualizes the impact of continuous knowledge editing on the model&rsquo;s internal activation flow. It compares the proportion of each layer&rsquo;s contribution to the residual stream (the cumulative activation signal) before and after editing. Specifically, it highlights how the proportion of activation from the edited layers (shown in red) increases significantly after multiple edits, indicating that the output of the edited layers dominates the model&rsquo;s final output. This illustrates the phenomenon of &lsquo;importance hacking&rsquo;, where the model relies disproportionately on the edited layers to generate the output, potentially compromising its overall performance. The magnitude of increase is shown separately for different editing methods.</p><details><summary>read the caption</summary>Figure 5: The figure shows the proportion of contribution of activations vectors produced from each sub-module to the residual stream. The edited layers are shown in red. We see that the influence of the output of the edited layers grows dramatically after contiuous editing.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_alphaedit_gpt2-xl.png alt></figure></p><blockquote><p>üîº This figure shows the average downstream performance across six tasks (MMLU, NLI, RTE, SST2, MRPC, CoLA) for the Llama 2-7B model over 10,000 sequential edits using different algorithms. It illustrates how the model&rsquo;s performance on these downstream tasks changes as more and more edits are sequentially applied to the model, specifically highlighting the impact of different knowledge editing methods on long-term performance.</p><details><summary>read the caption</summary>(a) Llama2-7B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_emmet_gpt2-xl.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the edited MLP matrices in Llama3-8B during sequential knowledge editing using AlphaEdit. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. The different colored lines represent different numbers of edits (0, 5000, and 10000). The figure demonstrates the significant growth of the norm in the edited layers (layers 4-8) as more edits are performed. This disproportionate norm growth is a key observation in the paper and contributes to the model&rsquo;s performance degradation during lifelong sequential knowledge editing.</p><details><summary>read the caption</summary>(b) Llama3-8B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_gpt2-xl.png alt></figure></p><blockquote><p>üîº This figure displays the average performance across six downstream tasks (MMLU, NLI, RTE, SST2, MRPC, CoLA) for Llama 2-7B and Llama 3-8B language models after undergoing 10,000 sequential knowledge editing operations. It compares the performance of four different methods: a baseline MEMIT approach, MEMIT enhanced with Most-Probable Early Stopping (MPES), MEMIT with a Norm Constraint, and ENCORE (which incorporates both MPES and a norm constraint). The x-axis represents the cumulative number of edits, while the y-axis shows the average F1 score across the six downstream tasks. The graph illustrates how ENCORE maintains consistent downstream performance even after numerous edits, outperforming the other methods, highlighting the effectiveness of the combined techniques of MPES and norm constraint in preventing performance degradation during extensive sequential knowledge editing.</p><details><summary>read the caption</summary>Figure 6: Average downstream performance for during sequential editing with ENCORE compared to baseline of MEMIT and addition of MPES and Norm-Constraint (NC).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_baseline_llama2-7b.png alt></figure></p><blockquote><p>üîº This figure shows a comparison of the Frobenius norm of the edited MLP matrices (layers 4-8) with the unedited MLP matrices in the Llama-3B model after 5,000 and 10,000 sequential edits using AlphaEdit and MEMIT. The plot visually demonstrates the significant increase in the norm of the edited matrices compared to other layers. It highlights the disproportionate growth that occurs with sequential editing, particularly for MEMIT.</p><details><summary>read the caption</summary>(a) Comparison with unedited layers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_alphaedit_llama2-7b.png alt></figure></p><blockquote><p>üîº This figure shows how the Frobenius norm of the edited weight matrices changes as the number of sequential edits increases. It provides a visual representation of the &rsquo;norm growth&rsquo; phenomenon discussed in the paper, where the norm of the edited matrices increases disproportionately with each sequential edit, potentially contributing to model degradation.</p><details><summary>read the caption</summary>(b) Norm growth as function of edits.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_emmet_llama2-7b.png alt></figure></p><blockquote><p>üîº This figure visualizes the growth of the Frobenius norm of edited MLP matrices in the Llama3-8B model during sequential knowledge editing using the ENCORE method. It demonstrates that ENCORE effectively controls the growth of these norms, unlike other methods that show a large disproportionate increase. The left panel displays a comparison of norms across all layers of both unedited and edited models (after 5,000 and 10,000 edits). The right panel shows the growth in the norm of the edited matrices as a function of the number of edits performed. This illustrates ENCORE&rsquo;s ability to maintain reasonable norm levels even after a significant number of edits.</p><details><summary>read the caption</summary>Figure 7: Growth in norm of edited matrices for ENCORE for Llama3-8B.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_llama2-7b.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the total activation vector norm contributed by each layer type (input, self-attention, MLP) in the GPT-2-XL language model <em>before any edits are applied</em>. It provides a baseline to compare against figures showing norm changes after knowledge editing using various methods.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Unedited GPT2-XL</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_baseline_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure is a bar chart showing the proportion of the activation vector norm contributed by different layers in the GPT-2-XL model after applying the AlphaEdit knowledge editing method. The x-axis represents different layer types within the model, and the y-axis represents the average proportion of the activation vector norm for each layer type. It visually demonstrates the relative influence of each layer on the model&rsquo;s overall output, particularly highlighting how AlphaEdit alters the distribution of activation norms across layers.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for GPT2-XL using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_alphaedit_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure displays a bar chart visualizing the average norm proportions by layer type for the GPT-2-XL model when using the EMMET algorithm. The chart shows the relative contribution of different layer types (such as input, self-attention, and MLP layers) to the overall norm of the model&rsquo;s activations. Each bar represents a specific layer type, and the height of the bar indicates its contribution to the average norm. This aids in understanding the impact of various layer types on the model&rsquo;s behavior and performance, particularly when comparing this distribution with similar charts from unedited models or models using different editing algorithms.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for GPT2-XL using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_emmet_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norm from each layer for GPT2-XL after applying the MEMIT algorithm. The x-axis represents the layer types (e.g., input, self-attn, and MLP), and the y-axis represents the average norm proportion for each layer type. The figure helps illustrate the impact of MEMIT on the distribution of activation norms across different layers of the model, highlighting how the norms of specific layers are affected.</p><details><summary>read the caption</summary>(d) Average Norm Proportion for GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure visualizes the growth of activation norms within a GPT2-XL model during sequential knowledge editing. It compares the average norm proportions across different layer types (input, self-attention, MLP) for the unedited model and models edited using AlphaEdit, EMMET, and MEMIT. The plots highlight how the norm distribution shifts after editing, showcasing the disproportionate increase in the norms of the edited layers relative to the other layers in the model.</p><details><summary>read the caption</summary>Figure 8: Activation norm growth for GPT2-XL.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_gpt2-xl.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norm from each layer sub-module in the residual stream for an unedited Llama 2-7B model. The bar chart visually represents the contribution of each layer&rsquo;s sub-module to the overall norm. The x-axis labels represent the various sub-modules within each layer of the model (e.g., input, self-attention, MLP), and the y-axis represents the proportion of the total activation vector norm contributed by each sub-module. This allows for a comparison of the relative importance of different sub-modules in the model&rsquo;s output.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Unedited Llama2-7B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_gpt2-xl_norm.png alt></figure></p><blockquote><p>üîº The figure shows the proportion of the activation vector norm from each sub-module (e.g., input, self-attention, MLP) of Llama2-7B language model to the total norm of the residual stream after applying AlphaEdit knowledge editing method. The x-axis represents the different sub-modules in the layers, while the y-axis indicates the average proportion of the norm of activation vectors produced from each sub-module to the total norm. The figure illustrates how AlphaEdit affects the norm of activation vectors across the layers, particularly focusing on the impact of the editing process on the relative contribution of different sub-modules to the overall output of the model.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for Llama2-7B using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_gpt2-xl_combination.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norms produced from each sub-module of the Llama2-7B model after editing using the EMMET algorithm. The x-axis represents different layer types within the model (e.g., input embeddings, self-attention, MLP), and the y-axis displays the proportion of the total norm contributed by each layer type. This visualization highlights how the contribution of activations from different layers changes due to the editing process. Specifically, this allows for comparison of the relative contributions of different layers before and after edits are applied.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for Llama2-7B using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_llama2-7b.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norms from different layers in Llama-2-7B model after applying the MEMIT knowledge editing method. The x-axis represents different layer types within the model (e.g., input, self-attention, MLP), and the y-axis shows the average norm proportion for each layer type. It visually represents how the norms of activation vectors from each layer contribute to the overall residual stream. The figure helps to illustrate the impact of MEMIT on the distribution of activation norms across different layers of the model.</p><details><summary>read the caption</summary>(d) Average Norm Proportion for Llama2-7B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_llama2-7b_norm.png alt></figure></p><blockquote><p>üîº This figure visualizes the growth of activation norms across different layers of the Llama2-7B model during sequential knowledge editing using four different methods: unedited, AlphaEdit, EMMET, and MEMIT. Each sub-figure shows the average norm proportion for each layer type in the model, highlighting how the norms change after 5,000 and 10,000 sequential edits. The x-axis represents the layer type, and the y-axis represents the average norm proportion. This helps illustrate the disproportionate growth of norms in certain layers following different knowledge editing methods.</p><details><summary>read the caption</summary>Figure 9: Activation norm growth for Llama2-7B.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_llama2-7b_combination.png alt></figure></p><blockquote><p>üîº This figure displays the average proportion of the activation vector norm contributed by each layer type in the unedited Llama3-8B model. It shows the relative contribution of different layer types (e.g., input, self-attention, MLP) to the overall activation norm. The visualization helps to understand the baseline activation norm distribution before any knowledge editing is applied.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Unedited Llama3-8B</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_memit_llama3-8b.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the total activation vector norm that comes from each layer of the Llama3-8B model after 10,000 sequential edits using the AlphaEdit algorithm. The x-axis represents different layer types within the model, while the y-axis represents the proportion of the total norm contributed by that layer type. It visually demonstrates the disproportionate increase in the norm of the activation vectors produced by the layers edited by AlphaEdit, compared to the other layers. This highlights the phenomenon of &lsquo;importance hacking&rsquo;, where edits to the model&rsquo;s weights cause the output of the edited layers to dominate the model&rsquo;s output, potentially at the cost of overall model performance.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for Llama3-8B using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_llama3-8b_norm.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the contribution of activation vectors produced by each sub-module in Llama3-8B to the residual stream after 10,000 sequential edits using the EMMET algorithm. The x-axis represents the different sub-modules in a decoder layer, while the y-axis shows the average norm proportion. The edited layers are highlighted in red, illustrating their increased influence on the final output after the edits.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for Llama3-8B using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/activation-norm-growth/average_norm_ratio_regmemit_llama3-8b_combination.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norm from each sub-module of the Llama3-8B model to the total residual stream norm after 10,000 sequential edits using MEMIT. The x-axis represents different sub-modules within a layer, while the y-axis shows the proportion of their contribution to the total residual stream norm. The red bars highlight the edited layers. This visualization helps understand how the contribution of activations from the edited layers changes compared to unedited layers, illustrating the effect of MEMIT on the model&rsquo;s output.</p><details><summary>read the caption</summary>(d) Average Norm Proportion for Llama3-8B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/emmet-norm-constraint/emmet-llama2-nc-baseline.png alt></figure></p><blockquote><p>üîº This figure visualizes the growth of the Frobenius norm of edited MLP matrices in the Llama3-8B model during sequential knowledge editing using different methods. Four subfigures are presented: (a) shows the unedited Llama3-8B model; (b) shows Llama3-8B after 5,000 sequential edits using AlphaEdit; (c) shows Llama3-8B after 10,000 sequential edits using AlphaEdit; (d) shows Llama3-8B after 5,000 and 10,000 sequential edits using MEMIT. The y-axis represents the Frobenius norm, while the x-axis represents the layer index. The figure demonstrates the disproportionate norm growth in the edited layers compared to the rest of the model, illustrating the &lsquo;importance hacking&rsquo; phenomenon discussed in the paper.</p><details><summary>read the caption</summary>Figure 10: Activation norm growth for Llama3-8B.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/emmet-norm-constraint/emmet-llama2-nc-best-editing.png alt></figure></p><blockquote><p>üîº This figure shows the average proportion of the activation vector norm contributed by different layer types in the GPT-2-XL model when using the MEMIT knowledge editing method. It visualizes the distribution of activation vector norms across various layer types within the model after applying MEMIT. The x-axis likely represents different layer types within the model architecture (e.g., embedding layers, attention layers, feed-forward layers), and the y-axis represents the average proportion of the total activation vector norm contributed by each layer type. This allows for analysis of how different layers in the model contribute to the overall activation norm during the MEMIT process, potentially highlighting whether certain layers are more significantly influenced than others by the edits.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/emmet-norm-constraint/emmet-llama2-nc-best-downstream.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norm contributed by each layer type in the GPT-2-XL model after applying the norm constraint method during sequential knowledge editing. The x-axis represents different layer types within the model, and the y-axis represents the proportion of the total activation vector norm attributed to each layer type. The graph visually displays how the norm constraint method affects the distribution of activation norms across the layers, particularly highlighting the impact on the edited layers.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for GPT2-XL using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_alphaedit.png alt></figure></p><blockquote><p>üîº This figure visualizes the proportion of activation vector norms contributed by different layer types in the GPT2-XL model after applying the ENCORE method. It displays the relative influence of each layer&rsquo;s output on the model&rsquo;s overall output. The use of ENCORE aims to mitigate the disproportionate growth of norms in certain layers, improving model robustness and performance during sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for GPT2-XL using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_emmet.png alt></figure></p><blockquote><p>üîº This figure visualizes the growth of activation vector norms within different layers of the GPT-2-XL language model during sequential knowledge editing. It compares the impact of two methods: using a norm constraint and employing the ENCORE technique. The x-axis represents the layers of the model, while the y-axis shows the average norm of the activation vectors for each layer. By contrasting the norm growth with and without ENCORE, the figure highlights ENCORE&rsquo;s effectiveness in mitigating the disproportionate increase in activation norms observed in certain layers during sequential knowledge updates.</p><details><summary>read the caption</summary>Figure 11: Activation norm growth for GPT2-XL using Norm Constraint and ENCORE.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_memit.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the total activation vector norm contributed by each layer type in the Llama2-7B model after applying the MEMIT knowledge editing method. The x-axis represents different layer types within the model, while the y-axis displays the proportion of the norm. The visualization helps to understand how the norm of activation vectors is distributed across various layer types in the model after applying MEMIT. This distribution of the activation norm across different layer types is crucial for understanding the effectiveness and potential side effects of the knowledge editing method.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Llama2-7B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_memit.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the contribution of activation vectors produced from each sub-module to the residual stream for Llama2-7B after applying the norm constraint method. The x-axis represents different layers in the model, categorized by type (e.g., input, self-attention, MLP). The y-axis displays the average norm proportion. The figure highlights how the norm constraint method affects the distribution of activation norms across different layers, particularly focusing on the impact of the edited layers.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for Llama2-7B using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_regmemit_norm.png alt></figure></p><blockquote><p>üîº This figure is a bar chart showing the proportion of the average activation vector norm from each layer sub-module (input, self-attention, MLP) to the overall residual stream. The chart specifically focuses on the Llama2-7B model after applying the ENCORE method. The x-axis represents the different layer sub-modules, and the y-axis shows the proportion of each sub-module&rsquo;s norm to the total residual stream. The color coding might highlight the layers modified by ENCORE. This visualization helps to understand the impact of ENCORE on the relative contribution of different layers to the model&rsquo;s output.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for Llama2-7B using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/gpt2-xl_regmemit_encore.png alt></figure></p><blockquote><p>üîº This figure compares the growth of activation norms in the Llama2-7B model during sequential knowledge editing using different methods: Norm Constraint and ENCORE. It visualizes the proportion of the total activation norm contributed by each layer of the model, specifically highlighting the edited layers (shown in red) in order to demonstrate how these methods impact the relative influence of different layers in producing the final output. By comparing the norm growth across layers with and without these editing techniques, the figure helps explain how these methods affect the model&rsquo;s behavior during sequential updates.</p><details><summary>read the caption</summary>Figure 12: Activation norm growth for Llama2-7B using Norm Constraint and ENCORE.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_alphaedit.png alt></figure></p><blockquote><p>üîº The figure shows the proportion of the activation vector norm from each sub-module of the Llama3-8B model after 10,000 sequential edits using MEMIT. The x-axis represents different layer types (input, self-attention, MLP), and the y-axis represents the average norm proportion for each layer type. The figure illustrates how the norm of activation vectors produced by the edited layers (in red) increases significantly after continuous editing, demonstrating the importance hacking phenomenon described in the paper.</p><details><summary>read the caption</summary>(a) Average Norm Proportion For Llama3-8B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the proportion of the activation vector norm from each layer of the Llama3-8B model after applying the norm constraint method for sequential knowledge editing. The x-axis represents different types of layers in the model, while the y-axis represents the proportion of the norm. It visually demonstrates the effect of the norm constraint on the distribution of activation norms across different layer types within the model.</p><details><summary>read the caption</summary>(b) Average Norm Proportion for Llama3-8B using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_memit.png alt></figure></p><blockquote><p>üîº This figure is a bar chart showing the proportion of the activation vector norm contributed by different layers of the Llama 3-8B language model when using the ENCORE method for knowledge editing. The x-axis represents the different layers of the model, and the y-axis represents the proportion of the total activation vector norm originating from each layer. It visually demonstrates the impact of ENCORE on the distribution of activation vector norms across model layers during sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Average Norm Proportion for Llama3-8B using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_memit.png alt></figure></p><blockquote><p>üîº This figure compares the growth of activation vector norms across different layers of the Llama3-8B language model under various knowledge editing methods. It displays how the norms change for the unedited model and after applying 5,000 and 10,000 sequential edits using MEMIT, Norm Constraint, and ENCORE. By visualizing the norm proportions for each layer type, the figure reveals the impact of each editing method on the distribution of activation vector norms, highlighting differences in the influence of various layers on the model&rsquo;s output. The figure helps illustrate how ENCORE and the Norm Constraint technique attempts to mitigate the disproportionate norm growth observed in other methods.</p><details><summary>read the caption</summary>Figure 13: Activation norm growth for Llama3-8B using Norm Constraint and ENCORE.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_regmemit_norm.png alt></figure></p><blockquote><p>üîº This figure shows the average downstream performance across six tasks (MMLU, NLI, RTE, SST2, MRPC, and CoLA) for the EMMET baseline model during sequential knowledge editing. The x-axis represents the number of edits performed, while the y-axis displays the F1 score for each task. Different colored lines represent different tasks.</p><details><summary>read the caption</summary>(a) EMMET baseline</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-2-7b_regmemit_encore.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of the model after performing knowledge editing, specifically focusing on the scenario where the best editing score is achieved using a norm constraint. It demonstrates how the model&rsquo;s performance on various downstream tasks changes as more edits are performed, and helps to visualize the trade-off between achieving the best editing scores and maintaining downstream capabilities.</p><details><summary>read the caption</summary>(b) Downstream performance for best editing score with norm constraint.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_alphaedit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of the EMMET model on the Llama2-7B dataset when using a norm constraint during the knowledge editing process. Specifically, it illustrates how the model&rsquo;s performance on several downstream tasks (SST2, NLI, MMLU, COLA, RTE, MRPC) changes as the number of edits increases. This experiment focuses on the best-performing scenario observed, where the norm constraint is tuned to optimize downstream task performance rather than editing performance alone. The goal is to understand the trade-off between improving downstream task performance and applying the norm constraint successfully during editing.</p><details><summary>read the caption</summary>(c) Downstream peformance for best the scenario where we get best downstream performance with norm constraint.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_emmet.png alt></figure></p><blockquote><p>üîº Figure 14 displays the impact of incorporating a norm constraint into the EMMET objective function on downstream and editing performance. The results show that adding the norm constraint does not lead to a noticeable improvement in downstream performance; in fact, it results in a decrease in editing performance. This indicates a trade-off between maintaining downstream performance and improving edit quality when using the norm constraint with the EMMET objective.</p><details><summary>read the caption</summary>Figure 14: Comparison between the effect of adding norm-constrain the EMMET objective. We see no appreciable improvement in downstream performace but incur loss in editing performance.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_memit.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the GPT2-XL model after 5,000 and 10,000 sequential edits using the AlphaEdit algorithm. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. The different colored lines represent the norm for the unedited model and for the model after the specified number of edits. This visualization highlights the disproportionate growth of the norm in the edited layers compared to other layers of the model, a phenomenon discussed in the paper as a contributor to model degradation during sequential knowledge editing.</p><details><summary>read the caption</summary>(a) Norm growth of GPT2-XL using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_memit.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the GPT2-XL model during sequential knowledge editing using the EMMET algorithm. The x-axis represents the layers of the model, while the y-axis shows the Frobenius norm. Different colored lines represent different stages of editing, showing how the norm changes as more edits are sequentially applied to the model.</p><details><summary>read the caption</summary>(b) Norm growth of GPT2-XL using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_regmemit_norm.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the GPT2-XL model during sequential knowledge editing using the MEMIT method. It illustrates the growth of the norm over the layers (x-axis) and the number of edits (different colored lines). This visualization helps to understand the extent of norm increase and its impact on model performance.</p><details><summary>read the caption</summary>(c) Norm growth of GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/norm-growth/llama-3-8b_regmemit_encore.png alt></figure></p><blockquote><p>üîº This figure compares the growth of the Frobenius norm of edited MLP matrices in the GPT2-XL model across different knowledge editing methods. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Each line in the graph corresponds to a different editing method (AlphaEdit, EMMET, MEMIT) and shows the norm of the edited matrices before any edits and after 5000 and 10000 edits. This visualization helps illustrate how different methods affect the norm of the edited parameters during sequential knowledge editing. Note that the scale of the y-axis is not consistent across different plots within Figure 15, so direct comparison across methods should only be done within each sub-plot.</p><details><summary>read the caption</summary>Figure 15: Norm growth of GPT2-XL across different methods</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_alphaedit.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the MLP matrices in the GPT-2-XL model during sequential knowledge editing using the MEMIT method. The x-axis represents the layer number, while the y-axis represents the Frobenius norm. Different colored lines represent different stages of the editing process (e.g., the original unedited model, the model after 5,000 edits, and the model after 10,000 edits). The figure illustrates the significant increase in the norm of the edited matrices as more edits are applied sequentially.</p><details><summary>read the caption</summary>(a) Norm growth of GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_alphaedit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the GPT-2-XL model after sequential knowledge editing using the Norm Constraint method. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Multiple lines are shown, each representing the norm at different stages of sequential editing (e.g., unedited, 5000 edits, 10000 edits). The plot visualizes the impact of the Norm Constraint on the growth of the Frobenius norm during sequential knowledge editing, highlighting whether it effectively mitigates the disproportionate norm increase observed in other methods.</p><details><summary>read the caption</summary>(b) Norm growth of GPT2-XL using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the GPT-2-XL model after 5,000 and 10,000 sequential edits using the ENCORE method. It visually demonstrates the impact of ENCORE on controlling the growth of the norm in the edited layers, showing how ENCORE prevents the disproportionate increase observed in other methods like MEMIT and AlphaEdit. The graph plots the Frobenius norm against the layer number, enabling a comparison between the norms of the unedited and edited model layers. The controlled norm growth, as a result of ENCORE, is a key aspect of preventing model degradation during large-scale sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Norm growth of GPT2-XL using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure compares the Frobenius norms of the weight matrices in the second MLP layer of GPT2-XL&rsquo;s decoder across different editing methods. It illustrates the norm growth over 5,000 and 10,000 edits for three scenarios: using the MEMIT method, applying a norm constraint to MEMIT, and employing ENCORE, the method proposed in the paper. The plot visually demonstrates the effectiveness of the norm constraint and ENCORE in mitigating the disproportionate norm growth observed in MEMIT during sequential knowledge editing.</p><details><summary>read the caption</summary>Figure 16: Norm growth of GPT2-XL using Norm Constraint and ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_memit.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in Llama2-7B language model after applying AlphaEdit. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Multiple lines represent the norms at different numbers of edits (e.g., unedited model, 5000 edits, 10000 edits). It illustrates the disproportionate growth of the norm of the edited matrix during sequential knowledge editing with AlphaEdit, a phenomenon that can lead to model degradation.</p><details><summary>read the caption</summary>(a) Norm growth of Llama2-7B using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_memit_mpes.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the edited MLP matrices in the Llama2-7B model during sequential knowledge editing using the EMMET algorithm. The x-axis represents the layers of the model, and the y-axis represents the Frobenius norm. Different colored lines represent different stages of the editing process (e.g., unedited, 5000 edits, 10000 edits). The plot illustrates the growth in the norm of the weight matrices as more edits are made, showcasing how the weight changes accumulate over time.</p><details><summary>read the caption</summary>(b) Norm growth of Llama2-7B using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_memit_norm.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the edited MLP matrices in the Llama2-7B model during sequential knowledge editing using the MEMIT method. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Different colored lines represent different stages of the editing process (e.g., unedited model, model after 5,000 edits, and model after 10,000 edits). The figure visually demonstrates the disproportionate growth of the norm in the edited layers compared to other layers as the number of edits increases.</p><details><summary>read the caption</summary>(c) Norm growth of Llama2-7B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/gpt2_xl_memit_encore.png alt></figure></p><blockquote><p>üîº This figure compares the growth of the Frobenius norm of edited MLP matrices in the Llama2-7B model across different knowledge editing methods (AlphaEdit, EMMET, MEMIT). It visually demonstrates how the norm of the edited matrices changes as a function of the number of sequential edits performed by each method. This provides insight into the impact of different editing techniques on the model&rsquo;s parameters and can be used to understand the reasons for model degradation.</p><details><summary>read the caption</summary>Figure 17: Norm growth of Llama2-7B across different methods</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl_alphaedit.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the edited MLP matrices in the Llama2-7B model during sequential knowledge editing using the MEMIT method. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Different colored lines represent different stages of the editing process (e.g., the unedited model, the model after 5,000 edits, and the model after 10,000 edits). The figure illustrates the disproportionate growth of the norm in the edited layers as sequential edits are performed.</p><details><summary>read the caption</summary>(a) Norm growth of Llama2-7B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl_alphaedit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the Llama2-7B model during sequential knowledge editing using the Norm Constraint method. The x-axis represents the layer number in the model, and the y-axis represents the Frobenius norm. Multiple lines are shown, each representing the norm at different stages of the editing process (e.g., unedited, after 5000 edits, after 10000 edits). The plot visualizes how the norm of the edited matrices changes as more edits are performed, illustrating the impact of the norm constraint on controlling the growth of the matrix norm. It highlights the effect of the Norm Constraint on mitigating the disproportionate growth in the norm of the edited matrix observed in other methods.</p><details><summary>read the caption</summary>(b) Norm growth of Llama2-7B using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the Llama2-7B model after sequential knowledge editing using ENCORE. It displays the norm values for each layer of the model, illustrating the impact of ENCORE on controlling the growth of norms in the weight matrices during lifelong sequential knowledge editing. Specifically, it contrasts the norm growth with that observed in other methods, highlighting ENCORE&rsquo;s effectiveness in mitigating disproportionate norm increases.</p><details><summary>read the caption</summary>(c) Norm growth of Llama2-7B using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure compares the Frobenius norm of the weight matrices in the Llama-2-7B model&rsquo;s MLP layers before and after sequential knowledge editing with two methods: Norm Constraint and ENCORE. It visualizes how the norms change for each layer after 5,000 and 10,000 edits using both methods, showing the impact of each technique on the model&rsquo;s parameters. The goal is to illustrate the effectiveness of ENCORE and Norm Constraint in controlling norm growth during sequential knowledge editing.</p><details><summary>read the caption</summary>Figure 18: Norm growth of Llama2-7B using Norm Constraint and ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl-memit.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in Llama-3-8B during sequential knowledge editing using the AlphaEdit method. The x-axis represents the different layers of the model, and the y-axis represents the Frobenius norm. The different colored lines show the norm after different numbers of edits (e.g., unedited, 5,000 edits, 10,000 edits). The figure highlights the disproportionate growth in the norm of the edited matrices compared to other layers as the number of edits increases, illustrating a key finding of the paper.</p><details><summary>read the caption</summary>(a) Norm growth of Llama3-8B using Alphaedit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl-memit_mpes.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the edited MLP matrices in the Llama3-8B model after applying the EMMET knowledge editing method. It illustrates the growth of the norm across different layers of the model as a function of the number of edits performed. The x-axis represents the layer number in the model and y-axis represents the Frobenius norm. The plot visualizes how the norm of the edited matrices increases during sequential knowledge editing with EMMET.</p><details><summary>read the caption</summary>(b) Norm growth of Llama3-8B using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl-memit_norm.png alt></figure></p><blockquote><p>üîº The figure shows the Frobenius norm of the MLP weight matrices in the Llama3-8B model&rsquo;s decoder layers after 5,000 and 10,000 sequential edits using the MEMIT method. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. It illustrates the significant increase in the norm of the edited matrices (layers 4-8) compared to the unedited model, highlighting the disproportionate norm growth caused by MEMIT during sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Norm growth of Llama3-8B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/gpt2-xl-memit_encore.png alt></figure></p><blockquote><p>üîº This figure displays the Frobenius norm of the edited MLP matrices in the Llama3-8B model after 5,000 and 10,000 sequential edits using different knowledge editing methods. The x-axis represents the layer number, and the y-axis represents the Frobenius norm. Each line corresponds to a different method (AlphaEdit, MEMIT, and the proposed ENCORE) and shows how the norm of the edited matrices changes with the number of edits. The figure demonstrates the disproportionate growth of the norm in certain methods compared to the unedited model and other layers, highlighting a key observation in the paper.</p><details><summary>read the caption</summary>Figure 19: Norm growth of Llama3-8B across different methods</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_alphaedit.png alt></figure></p><blockquote><p>üîº The figure visualizes the Frobenius norm of the edited MLP matrices in the Llama3-8B model across different layers during sequential knowledge editing using the MEMIT method. The x-axis represents the layer number, while the y-axis shows the Frobenius norm. Different colored lines depict the norm at various stages of the editing process (e.g., unedited model, 5,000 edits, 10,000 edits). This illustrates the disproportionate growth of the norm in specific layers as more edits are performed.</p><details><summary>read the caption</summary>(a) Norm growth of Llama3-8B using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_alphedit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the Llama3-8B model after sequential knowledge editing using the Norm Constraint method. The x-axis represents the different layers of the model, and the y-axis shows the Frobenius norm. The different colored lines represent the norms at different stages of the editing process (e.g., unedited, 5,000 edits, 10,000 edits). This visualization helps illustrate the effectiveness of the Norm Constraint in mitigating the disproportionate growth of norms in the edited layers compared to other methods.</p><details><summary>read the caption</summary>(b) Norm growth of Llama3-8B using Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2-7b_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the Frobenius norm of the edited MLP matrices in the Llama3-8B model after performing sequential knowledge editing using the ENCORE method. It illustrates the growth of the norm in the edited layers (layers 4-8) as a function of the number of edits. The graph helps visualize the impact of ENCORE on controlling the norm growth compared to other methods, highlighting ENCORE&rsquo;s effectiveness in mitigating the disproportionate increase in norm observed in other approaches to sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Norm growth of Llama3-8B using ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure displays a comparison of the Frobenius norm of weight matrices in Llama-3-8B language model&rsquo;s MLP layers after applying different methods: unedited model, model edited with 5,000 edits using AlphaEdit, and 10,000 edits using AlphaEdit. It shows the norm growth of the matrices in the edited layers relative to unedited layers, highlighting the impact of these methods on the model&rsquo;s weights. The disproportionate norm increase is an important observation discussed in the paper.</p><details><summary>read the caption</summary>Figure 20: Norm growth of Llama3-8B using Norm Constraint and ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_memit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model when using AlphaEdit for knowledge editing. The x-axis represents the number of edits performed, and the y-axis shows the F1 score across six different downstream tasks: SST-2, NLI, MMLU, COLA, RTE, and MRPC. The lines represent the performance on each task as the number of edits increases. This illustrates the impact of AlphaEdit on the model&rsquo;s performance on various NLP tasks during sequential knowledge editing.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using AlphaEdit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_memit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT2-XL language model after applying AlphaEdit with Most-Probable Early Stopping (MPES) method for sequential knowledge editing. The downstream performance is evaluated across six tasks: SST2, NLI, MMLU, COLA, RTE, and MRPC. The x-axis represents the number of edits performed (in batches of 100), and the y-axis shows the F1 score achieved on each of these six tasks. The plot helps to analyze how the downstream performance of the model changes with an increasing number of sequential edits, allowing for the assessment of model degradation after applying MPES.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using AlphaEdit with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_memit_norm.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance of GPT-2-XL language model on six different downstream tasks (SST-2, MRPC, NLI, RTE, COLA, MMLU) after applying AlphaEdit and MPES methods with the CounterFact dataset. The x-axis represents the number of edits (in batches of 100) performed, and the y-axis shows the F1 score for each task. The plot helps to visualize how the model&rsquo;s performance on different tasks changes with sequential knowledge editing using the combined approach.</p><details><summary>read the caption</summary>Figure 21: Downstream Performance for GPT2-XL using AlphaEdit and MPES with CounterFact dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama2_7b_memit_encore.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model when using the EMMET algorithm for sequential knowledge editing. The downstream performance is evaluated across six different tasks (SST-2, MRPC, NLI, RTE, COLA, MMLU) and is measured as F1 score. The x-axis represents the number of edits (in batches of 100), and the y-axis represents the F1 score for each task. The lines represent the performance of different tasks during the process of sequential knowledge editing using the EMMET algorithm.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_alphaedit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT2-XL model when using the EMMET algorithm with the Most-Probable Early Stopping (MPES) technique. The downstream performance is evaluated across six different tasks: sentiment analysis (SST2), paraphrase detection (MRPC), natural language inference (NLI, RTE), linguistic acceptability classification (COLA), and massive multitask language understanding (MMLU). The x-axis represents the number of edits (in batches of 100), and the y-axis represents the F1 score for each task. The plot illustrates how the model&rsquo;s performance on these tasks changes as more knowledge edits are sequentially applied using EMMET and MPES.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using EMMET with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_alphaedit_mpes.png alt></figure></p><blockquote><p>üîº This figure displays the results of downstream performance evaluations for the GPT-2-XL model using two different methods: EMMET and EMMET combined with MPES (Most-Probable Early Stopping). The x-axis represents the number of edits performed, and the y-axis shows the F1 score across six different downstream tasks (SST-2, MRPC, NLI, RTE, COLA, and MMLU). The graph allows for a comparison of the performance of the two methods across various downstream tasks and the impact of MPES on maintaining the model&rsquo;s performance across many sequential edits.</p><details><summary>read the caption</summary>Figure 22: Downstream Performance for GPT2-XL using EMMET and MPES with CounterFact dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_emmet.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance of GPT-2-XL language model when using the MEMIT knowledge editing algorithm. The x-axis represents the number of edits performed, and the y-axis shows the F1 score across six different downstream tasks (SST2, MRPC, NLI, RTE, COLA, and MMLU). The graph illustrates how the model&rsquo;s performance on these tasks changes as more edits are sequentially applied. This helps assess whether and to what extent the MEMIT algorithm causes a degradation in the model&rsquo;s overall capabilities after multiple knowledge editing updates.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying MEMIT knowledge editing method with Most Probable Early Stopping (MPES). The x-axis represents the number of edits performed in batches of 100, and the y-axis shows the F1 score across six different downstream tasks: SST-2, MRPC, NLI, RTE, COLA, and MMLU. The plot visualizes how the model&rsquo;s performance on these tasks changes as more knowledge edits are integrated. Different colored lines represent the performance of different downstream tasks, showing their relative robustness to the editing process.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using MEMIT with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_memit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying the MEMIT knowledge editing method with an added norm constraint on the CounterFact dataset. The x-axis represents the number of editing steps performed (where each step involves a batch of edits), while the y-axis shows the F1 score across six different downstream tasks (SST-2, MRPC, NLI, RTE, COLA, and MMLU). The graph illustrates the model&rsquo;s performance on these tasks as the number of editing steps increases. This visualization helps to assess the effect of the norm constraint in maintaining the model&rsquo;s performance after sequential knowledge editing.</p><details><summary>read the caption</summary>(c) Downstream Performance for GPT2-XL using MEMIT with Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_memit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying MEMIT (Memory-efficient in-context editing) and ENCORE (Early stopping and Norm-Constrained Robust knowledge Editing) sequentially. It displays the F1 scores across six different downstream tasks (SST2, NLI, MMLU, COLA, RTE, MRPC) as the number of edits increases. The graph allows for comparison of the model&rsquo;s performance with and without ENCORE, illustrating its effectiveness in maintaining performance during large-scale sequential knowledge editing.</p><details><summary>read the caption</summary>(d) Downstream Performance for GPT2-XL using MEMIT with ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_memit_norm.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance of GPT-2-XL model on the CounterFact dataset after applying four different knowledge editing methods: MEMIT, MEMIT with MPES (Most-Probable Early Stopping), MEMIT with Norm Constraint, and ENCORE. The x-axis represents the number of edits (in batches of 100) performed on the model, while the y-axis shows the F1 score achieved on six different downstream tasks (SST2, MRPC, NLI, RTE, COLA, and MMLU). The plot allows for a comparison of how each method affects the model&rsquo;s performance on various tasks as the number of edits increases, demonstrating the impact of the techniques on model degradation during sequential knowledge editing.</p><details><summary>read the caption</summary>Figure 23: Downstream Performance for GPT2-XL using MEMIT, MPES, Norm Constraint and ENCORE with CounterFact dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama2_memit_encore.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying AlphaEdit knowledge editing method. The x-axis represents the number of edits performed (in batches of 100), and the y-axis shows the F1 score across six different downstream tasks (SST-2, MRPC, NLI, RTE, COLA, and MMLU). The graph displays how the model&rsquo;s performance on these tasks changes as more edits are incorporated. Different colored lines represent different downstream tasks.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using AlphaEdit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3_8b_alphaedit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying AlphaEdit with Most-Probable Early Stopping (MPES) for knowledge editing. The x-axis represents the number of edits performed in batches of 100, up to a maximum of 10000 edits. The y-axis shows the F1 score across six different downstream tasks: SST-2, NLI, MMLU, COLA, RTE, and MRPC. The graph illustrates how the model&rsquo;s performance on these tasks changes as more sequential knowledge edits are applied using the AlphaEdit method enhanced with MPES. This allows for comparison of performance changes as a result of the knowledge editing process.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using AlphaEdit with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3_8b_alphaedit_mpes.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance results for the GPT-2-XL model when using the AlphaEdit algorithm with and without MPES (Most-Probable Early Stopping) on the zsRE dataset. Downstream performance is assessed using several tasks including sentiment analysis, paraphrase detection, natural language inference, and others. The x-axis represents the number of edits performed (in batches of 100), and the y-axis represents the F1 score achieved on each of the downstream tasks. It shows how the addition of MPES affects the performance of AlphaEdit over a sequence of edits.</p><details><summary>read the caption</summary>Figure 24: Downstream Performance for GPT2-XL using AlphaEdit and MPES with zsRE dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3-8b_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model when using the EMMET knowledge editing algorithm. Downstream performance is measured across six different tasks: sentiment analysis (SST2), paraphrase detection (MRPC), natural language inference (NLI, RTE), linguistic acceptability (CoLA), and massive multitask language understanding (MMLU). The x-axis represents the number of edits performed, and the y-axis shows the F1-score for each task. The plot helps to visualize how the model&rsquo;s performance on these downstream tasks changes as more knowledge edits are made using the EMMET method.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3-8b_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying the EMMET algorithm with the addition of Most-Probable Early Stopping (MPES). The x-axis represents the number of edits performed, while the y-axis shows the F1 score across six downstream tasks (SST-2, MRPC, NLI, RTE, COLA, MMLU). The graph illustrates how the model&rsquo;s performance on these tasks changes as more edits are sequentially introduced using the EMMET method, enhanced by MPES to mitigate overfitting.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using EMMET with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3-8b_memit.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance results for the GPT2-XL model when employing the EMMET knowledge editing method, both with and without MPES (Most-Probable Early Stopping). The x-axis represents the number of edits, while the y-axis shows the F1 score across six different downstream tasks (SST2, NLI, MMLU, COLA, RTE, MRPC). It visually demonstrates the impact of MPES on mitigating performance degradation during sequential knowledge editing using EMMET.</p><details><summary>read the caption</summary>Figure 25: Downstream Performance for GPT2-XL using EMMET and MPES with zsRE dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3-8b_memit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying MEMIT (Memory-Efficient Multi-task Learning) method for sequential knowledge editing. The x-axis represents the number of edits (in batches of 100), and the y-axis shows the F1 score across six downstream tasks: SST-2, MRPC, NLI, RTE, COLA, and MMLU. The figure helps visualize how well the model maintains its performance on various tasks after a series of knowledge edits, demonstrating the model&rsquo;s robustness and ability to retain learned knowledge after editing.</p><details><summary>read the caption</summary>(a) Downstream Performance for GPT2-XL using MEMIT</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3_8b_norm.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying MEMIT (Memory-Efficient Multi-task Editing) knowledge editing method with MPES (Most-Probable Early Stopping). The downstream performance is evaluated across multiple tasks and is plotted against the number of edits. It illustrates how the model&rsquo;s performance on various downstream tasks changes as sequential knowledge edits are incorporated using MEMIT with the added MPES optimization. The graph likely shows the F1 scores (a common metric for evaluating model performance) for each task as a function of the number of edits performed.</p><details><summary>read the caption</summary>(b) Downstream Performance for GPT2-XL using MEMIT with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream_mcf/llama3-8b_memit_encore.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model after applying MEMIT algorithm with a norm constraint during sequential knowledge editing. Downstream performance is evaluated across six different tasks, and the x-axis represents the number of edits performed. The y-axis represents the F1 score, which measures the model&rsquo;s accuracy. The figure helps visualize how the addition of a norm constraint to the MEMIT algorithm impacts the model&rsquo;s performance on various downstream tasks after sequential edits.</p><details><summary>read the caption</summary>(c) Downstream Performance for GPT2-XL using MEMIT with Norm Constraint</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_alphaedit.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of GPT-2-XL language model on six different downstream tasks after applying sequential knowledge editing using the MEMIT method with ENCORE. The x-axis represents the number of edits, and the y-axis represents the F1 score for each task. The F1 score measures the model&rsquo;s performance on each task after a specified number of edits. The figure helps to understand how ENCORE affects the performance of the model on various tasks, and how it compares to other methods in the paper.</p><details><summary>read the caption</summary>(d) Downstream Performance for GPT2-XL using MEMIT with ENCORE</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_alphaedit_mpes.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance of GPT-2 XL model on the zsRE dataset after applying four different methods: MEMIT, MEMIT with MPES (early stopping), MEMIT with norm constraint, and ENCORE (which combines MPES and norm constraint). The x-axis represents the number of edits (in batches of 100), and the y-axis represents the F1 score across six different downstream tasks (SST2, MRPC, NLI, RTE, COLA, MMLU). Each line represents the performance of a specific downstream task after applying the mentioned editing method. This visualization helps understand how different methods affect the overall model performance in the long run.</p><details><summary>read the caption</summary>Figure 26: Downstream Performance for GPT2-XL using MEMIT, MPES, Norm Constraint and ENCORE with zsRE dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_emmet.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of Llama 2-7B language model after applying AlphaEdit knowledge editing method. The x-axis represents the number of edits performed on the model, and the y-axis shows the F1 score across six different downstream tasks (SST2, MRPC, NLI, RTE, CoLA, and MMLU). It illustrates how the model&rsquo;s performance on these tasks changes as more edits are applied, providing insights into the impact of AlphaEdit on the model&rsquo;s generalization capabilities.</p><details><summary>read the caption</summary>(a) Downstream Performance for Llama2-7B using AlphaEdit</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_emmet_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of Llama 2-7B language model after applying AlphaEdit with Most-Probable Early Stopping (MPES). The downstream performance is measured across six different tasks: Massive Multitask Language Understanding (MMLU), Natural Language Inference (NLI), Recognizing Textual Entailment (RTE), Sentiment Analysis (SST2), Paraphrase Detection (MRPC), and Linguistic Acceptability (CoLA). The x-axis represents the number of sequential edits performed in batches of 100. The y-axis represents the F1 score, a common metric used to evaluate the model&rsquo;s performance on these downstream tasks. The graph illustrates the effect of AlphaEdit, enhanced by MPES, on the model&rsquo;s ability to maintain performance across multiple tasks during a long sequence of edits.</p><details><summary>read the caption</summary>(b) Downstream Performance for Llama2-7B using AlphaEdit with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_memit.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance of the Llama-2-7B language model when using the AlphaEdit algorithm with and without Most-Probable Early Stopping (MPES) on the CounterFact dataset. The graph showcases the F1 scores across six downstream tasks (SST2, NLI, MMLU, CoLA, RTE, MRPC) as the number of edits increases. It visually represents how the model&rsquo;s performance on these tasks changes over the course of sequential knowledge editing, demonstrating the effects of MPES on mitigating performance degradation.</p><details><summary>read the caption</summary>Figure 27: Downstream Performance for Llama2-7B using AlphaEdit and MPES with CounterFact dataset</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_memit_mpes.png alt></figure></p><blockquote><p>üîº This figure shows the downstream performance of the Llama 2-7B model when using the EMMET algorithm for sequential knowledge editing. It displays the F1 scores across six different downstream tasks (SST2, NLI, MMLU, COLA, RTE, MRPC) as the number of edits increases. The graph allows for visualizing the extent to which model performance degrades (or improves) as the model undergoes a series of knowledge editing operations using the EMMET method.</p><details><summary>read the caption</summary>(a) Downstream Performance for Llama2-7B using EMMET</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/llama3_memit_norm.png alt></figure></p><blockquote><p>üîº The figure shows the downstream performance of Llama 2-7B language model when using the EMMET knowledge editing method along with the Most-Probable Early Stopping (MPES) technique. Downstream performance is evaluated across six distinct tasks: Massive Multitask Language Understanding (MMLU), Natural Language Inference (NLI), Recognizing Textual Entailment (RTE), Sentiment Analysis (SST2), Paraphrase Detection (MRPC), and Linguistic Acceptability (CoLA). The x-axis represents the number of edits (in batches of 100), and the y-axis represents the F1 score achieved on each task. The graph visualizes how the model&rsquo;s performance on these tasks changes as more edits are sequentially applied using the combined EMMET and MPES approach.</p><details><summary>read the caption</summary>(b) Downstream Performance for Llama2-7B using EMMET with MPES</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2502.01636/extracted/6169970/figures/downstream-zsre/new_llama3_encore_zsre.png alt></figure></p><blockquote><p>üîº This figure displays the downstream performance results for the Llama 2-7B language model when employing the EMMET method with and without MPES (Most-Probable Early Stopping). The downstream performance is evaluated across six distinct tasks: SST-2, NLI, MMLU, COLA, RTE, and MRPC, and is presented as F1 scores plotted against the number of edits. The graph helps assess how well the model maintains its performance on general language tasks as it undergoes sequential knowledge editing using the EMMET approach, examining the impact of using MPES to improve performance.</p><details><summary>read the caption</summary>Figure 28: Downstream Performance for Llama2-7B using EMMET and MPES with CounterFact dataset</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=S4.T2.1><tr class=ltx_tr id=S4.T2.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=S4.T2.1.1.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.1.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.2.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.3.1 style=font-size:90%><span class=ltx_text id=S4.T2.1.1.3.1.1></span> <span class=ltx_text id=S4.T2.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=S4.T2.1.1.3.1.2.1><span class=ltx_tr id=S4.T2.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=S4.T2.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S4.T2.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.4.1 style=font-size:90%><span class=ltx_text id=S4.T2.1.1.4.1.1></span> <span class=ltx_text id=S4.T2.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=S4.T2.1.1.4.1.2.1><span class=ltx_tr id=S4.T2.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=S4.T2.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S4.T2.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.5.1 style=font-size:90%><span class=ltx_text id=S4.T2.1.1.5.1.1></span> <span class=ltx_text id=S4.T2.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=S4.T2.1.1.5.1.2.1><span class=ltx_tr id=S4.T2.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=S4.T2.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S4.T2.1.1.5.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.6.1 style=font-size:90%><span class=ltx_text id=S4.T2.1.1.6.1.1></span> <span class=ltx_text id=S4.T2.1.1.6.1.2><span class="ltx_tabular ltx_align_middle" id=S4.T2.1.1.6.1.2.1><span class=ltx_tr id=S4.T2.1.1.6.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.6.1.2.1.1.1>Overall</span></span>
<span class=ltx_tr id=S4.T2.1.1.6.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.6.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S4.T2.1.1.6.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S4.T2.1.1.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.1.7.1 style=font-size:90%><span class=ltx_text id=S4.T2.1.1.7.1.1></span> <span class=ltx_text id=S4.T2.1.1.7.1.2><span class="ltx_tabular ltx_align_middle" id=S4.T2.1.1.7.1.2.1><span class=ltx_tr id=S4.T2.1.1.7.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.7.1.2.1.1.1>Generation</span></span>
<span class=ltx_tr id=S4.T2.1.1.7.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S4.T2.1.1.7.1.2.1.2.1>Entropy</span></span>
</span></span><span class=ltx_text id=S4.T2.1.1.7.1.3></span></span></td></tr><tr class=ltx_tr id=S4.T2.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=S4.T2.1.2.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.1.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.3.1 style=font-size:90%>81.04</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.4.1 style=font-size:90%>64.67</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.5.1 style=font-size:90%>60.95</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.6.1 style=font-size:90%>67.859</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.2.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.2.7.1 style=font-size:90%>442.59</span></td></tr><tr class=ltx_tr id=S4.T2.1.3><td class=ltx_td id=S4.T2.1.3.1></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.3.1 style=font-size:90%>49.68</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.4.1 style=font-size:90%>49.29</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.5.1 style=font-size:90%>51.31</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.6.1 style=font-size:90%>50.078</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.3.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.3.7.1 style=font-size:90%>373.48</span></td></tr><tr class=ltx_tr id=S4.T2.1.4><td class="ltx_td ltx_align_left" id=S4.T2.1.4.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.4.1.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.4.3.1 style=font-size:90%>88.43</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.4.4.1 style=font-size:90%>70.83</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.4.5.1 style=font-size:90%>65.86</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.4.6.1 style=font-size:90%>73.873</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.4.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.4.7.1 style=font-size:90%>542.1</span></td></tr><tr class=ltx_tr id=S4.T2.1.5><td class="ltx_td ltx_align_left" id=S4.T2.1.5.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.5.1.1 style=font-size:90%>+ MPES</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.5.3.1 style=font-size:90%>65.78</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.5.4.1 style=font-size:90%>57.58</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.5.5.1 style=font-size:90%>50.25</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.5.6.1 style=font-size:90%>57.176</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.5.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.5.7.1 style=font-size:90%>560.78</span></td></tr><tr class=ltx_tr id=S4.T2.1.6><td class="ltx_td ltx_align_left ltx_border_t" id=S4.T2.1.6.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.1.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.3.1 style=font-size:90%>61.1</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.4.1 style=font-size:90%>55.86</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.5.1 style=font-size:90%>53.75</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.6.1 style=font-size:90%>56.74</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.6.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.6.7.1 style=font-size:90%>540.92</span></td></tr><tr class=ltx_tr id=S4.T2.1.7><td class=ltx_td id=S4.T2.1.7.1></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.3.1 style=font-size:90%>72.67</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.4.1 style=font-size:90%>63.44</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.5.1 style=font-size:90%>52.9</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.6.1 style=font-size:90%>61.948</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.7.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.7.7.1 style=font-size:90%>465.81</span></td></tr><tr class=ltx_tr id=S4.T2.1.8><td class="ltx_td ltx_align_left" id=S4.T2.1.8.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.8.1.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.8.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.8.3.1 style=font-size:90%>84.15</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.8.4.1 style=font-size:90%>74.94</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.8.5.1 style=font-size:90%>62.87</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.8.6.1 style=font-size:90%>72.933</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.8.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.8.7.1 style=font-size:90%>583.4</span></td></tr><tr class=ltx_tr id=S4.T2.1.9><td class="ltx_td ltx_align_left" id=S4.T2.1.9.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.9.1.1 style=font-size:90%>+ MPES</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.9.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.9.3.1 style=font-size:90%>88.43</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.9.4.1 style=font-size:90%>82.08</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.9.5.1 style=font-size:90%>56.5</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.9.6.1 style=font-size:90%>72.832</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.9.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.9.7.1 style=font-size:90%>565.36</span></td></tr><tr class=ltx_tr id=S4.T2.1.10><td class="ltx_td ltx_align_left ltx_border_t" id=S4.T2.1.10.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.1.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.3.1 style=font-size:90%>94.98</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.4.1 style=font-size:90%>84.05</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.5.1 style=font-size:90%>55.76</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.6.1 style=font-size:90%>74.331</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T2.1.10.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.10.7.1 style=font-size:90%>569.24</span></td></tr><tr class=ltx_tr id=S4.T2.1.11><td class=ltx_td id=S4.T2.1.11.1></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.11.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.3><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.11.3.1 style=font-size:90%>85.03</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.4><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.11.4.1 style=font-size:90%>75.06</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.5><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.11.5.1 style=font-size:90%>49.08</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.6><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.11.6.1 style=font-size:90%>65.995</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.11.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.11.7.1 style=font-size:90%>567.34</span></td></tr><tr class=ltx_tr id=S4.T2.1.12><td class="ltx_td ltx_align_left" id=S4.T2.1.12.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.12.1.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.12.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.12.3.1 style=font-size:90%>96.8</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.12.4.1 style=font-size:90%>88.4</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.12.5.1 style=font-size:90%>58.41</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.12.6.1 style=font-size:90%>77.393</span></td><td class="ltx_td ltx_align_center" id=S4.T2.1.12.7><span class="ltx_text ltx_font_bold" id=S4.T2.1.12.7.1 style=font-size:90%>584.28</span></td></tr><tr class=ltx_tr id=S4.T2.1.13><td class="ltx_td ltx_align_left ltx_border_bb" id=S4.T2.1.13.1><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.13.1.1 style=font-size:90%>+ MPES</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.2><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.13.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.3><span class="ltx_text ltx_font_bold" id=S4.T2.1.13.3.1 style=font-size:90%>92.96</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.4><span class="ltx_text ltx_font_bold" id=S4.T2.1.13.4.1 style=font-size:90%>86.12</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.5><span class="ltx_text ltx_font_bold" id=S4.T2.1.13.5.1 style=font-size:90%>55.74</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.6><span class="ltx_text ltx_font_bold" id=S4.T2.1.13.6.1 style=font-size:90%>74.424</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T2.1.13.7><span class="ltx_text ltx_font_smallcaps" id=S4.T2.1.13.7.1 style=font-size:90%>564.82</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the results of sequential knowledge editing experiments after 10,000 edits using four different methods: MEMIT, MEMIT with MPES, AlphaEdit, and AlphaEdit with MPES. The performance is evaluated across two language models (Llama-2-7B and Llama-3-8B) using five key metrics: Edit Score (ES), Paraphrase Score (PS), Neighborhood Score (NS), Overall Score (S), and Generation Entropy (GE). The table highlights the impact of incorporating MPES (Most-Probable Early Stopping) on the editing performance, demonstrating improvements in various metrics across both models and methods. It showcases the efficacy and robustness of the knowledge editing techniques, particularly when combined with MPES.</p><details><summary>read the caption</summary>Table 2: Sequential knowledge editing performance after 10,000 edits for different algorithms. We see that using MPES improves editing metrics across all algorithms and models.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=S5.T3.1><tr class=ltx_tr id=S5.T3.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=S5.T3.1.1.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.1.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.2.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.3.1 style=font-size:90%><span class=ltx_text id=S5.T3.1.1.3.1.1></span> <span class=ltx_text id=S5.T3.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=S5.T3.1.1.3.1.2.1><span class=ltx_tr id=S5.T3.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=S5.T3.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S5.T3.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.4.1 style=font-size:90%><span class=ltx_text id=S5.T3.1.1.4.1.1></span> <span class=ltx_text id=S5.T3.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=S5.T3.1.1.4.1.2.1><span class=ltx_tr id=S5.T3.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=S5.T3.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S5.T3.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.5.1 style=font-size:90%><span class=ltx_text id=S5.T3.1.1.5.1.1></span> <span class=ltx_text id=S5.T3.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=S5.T3.1.1.5.1.2.1><span class=ltx_tr id=S5.T3.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=S5.T3.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S5.T3.1.1.5.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.6.1 style=font-size:90%><span class=ltx_text id=S5.T3.1.1.6.1.1></span> <span class=ltx_text id=S5.T3.1.1.6.1.2><span class="ltx_tabular ltx_align_middle" id=S5.T3.1.1.6.1.2.1><span class=ltx_tr id=S5.T3.1.1.6.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.6.1.2.1.1.1>Overall</span></span>
<span class=ltx_tr id=S5.T3.1.1.6.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.6.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=S5.T3.1.1.6.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.1.1.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.1.7.1 style=font-size:90%><span class=ltx_text id=S5.T3.1.1.7.1.1></span> <span class=ltx_text id=S5.T3.1.1.7.1.2><span class="ltx_tabular ltx_align_middle" id=S5.T3.1.1.7.1.2.1><span class=ltx_tr id=S5.T3.1.1.7.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.7.1.2.1.1.1>Generation</span></span>
<span class=ltx_tr id=S5.T3.1.1.7.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=S5.T3.1.1.7.1.2.1.2.1>Entropy</span></span>
</span></span><span class=ltx_text id=S5.T3.1.1.7.1.3></span></span></td></tr><tr class=ltx_tr id=S5.T3.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=S5.T3.1.2.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.1.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.3.1 style=font-size:90%>81.04</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.4.1 style=font-size:90%>64.67</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.5.1 style=font-size:90%>60.95</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.6.1 style=font-size:90%>67.859</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.2.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.2.7.1 style=font-size:90%>442.59</span></td></tr><tr class=ltx_tr id=S5.T3.1.3><td class=ltx_td id=S5.T3.1.3.1></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.3.1 style=font-size:90%>49.68</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.4.1 style=font-size:90%>49.29</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.5.1 style=font-size:90%>51.31</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.6.1 style=font-size:90%>50.078</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.3.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.3.7.1 style=font-size:90%>373.48</span></td></tr><tr class=ltx_tr id=S5.T3.1.4><td class="ltx_td ltx_align_left ltx_border_t" id=S5.T3.1.4.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.1.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.3.1 style=font-size:90%>88.43</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.4.1 style=font-size:90%>70.83</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.5.1 style=font-size:90%>65.86</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.6.1 style=font-size:90%>73.873</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.4.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.4.7.1 style=font-size:90%>542.1</span></td></tr><tr class=ltx_tr id=S5.T3.1.5><td class="ltx_td ltx_align_left" id=S5.T3.1.5.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.1.1 style=font-size:90%>+ MPES</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.3.1 style=font-size:90%>65.78</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.4.1 style=font-size:90%>57.58</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.5.1 style=font-size:90%>50.25</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.5.6.1 style=font-size:90%>57.17</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.5.7><span class="ltx_text ltx_font_bold" id=S5.T3.1.5.7.1 style=font-size:90%>560.78</span></td></tr><tr class=ltx_tr id=S5.T3.1.6><td class="ltx_td ltx_align_left ltx_border_t" id=S5.T3.1.6.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.1.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.3.1 style=font-size:90%>90.94</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.4.1 style=font-size:90%>81.31</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.5.1 style=font-size:90%>59.73</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.6.1 style=font-size:90%>74.931</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.6.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.6.7.1 style=font-size:90%>539.58</span></td></tr><tr class=ltx_tr id=S5.T3.1.7><td class="ltx_td ltx_align_left" id=S5.T3.1.7.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.1.1 style=font-size:90%>+ Norm-Const</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.3><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.3.1 style=font-size:90%>85.72</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.4><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.4.1 style=font-size:90%>77.08</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.5><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.5.1 style=font-size:90%>58.45</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.6><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.6.1 style=font-size:90%>71.86</span></td><td class="ltx_td ltx_align_center" id=S5.T3.1.7.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.7.7.1 style=font-size:90%>367.46</span></td></tr><tr class=ltx_tr id=S5.T3.1.8><td class="ltx_td ltx_align_left ltx_border_t" id=S5.T3.1.8.1><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.8.1.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.8.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.3><span class="ltx_text ltx_font_bold" id=S5.T3.1.8.3.1 style=font-size:90%>92.57</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.4><span class="ltx_text ltx_font_bold" id=S5.T3.1.8.4.1 style=font-size:90%>82.64</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.5><span class="ltx_text ltx_font_bold" id=S5.T3.1.8.5.1 style=font-size:90%>60.43</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.6><span class="ltx_text ltx_font_bold" id=S5.T3.1.8.6.1 style=font-size:90%>76.043</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.1.8.7><span class="ltx_text ltx_font_bold" id=S5.T3.1.8.7.1 style=font-size:90%>560.16</span></td></tr><tr class=ltx_tr id=S5.T3.1.9><td class="ltx_td ltx_border_bb" id=S5.T3.1.9.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.2><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.9.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.3><span class="ltx_text ltx_font_bold" id=S5.T3.1.9.3.1 style=font-size:90%>88.77</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.4><span class="ltx_text ltx_font_bold" id=S5.T3.1.9.4.1 style=font-size:90%>78.19</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.5><span class="ltx_text ltx_font_bold" id=S5.T3.1.9.5.1 style=font-size:90%>60.07</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.6><span class="ltx_text ltx_font_bold" id=S5.T3.1.9.6.1 style=font-size:90%>73.707</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.1.9.7><span class="ltx_text ltx_font_smallcaps" id=S5.T3.1.9.7.1 style=font-size:90%>523.61</span></td></tr></table></table></figure><blockquote><p>üîº This table presents a comparison of the editing performance of three knowledge editing methods: the baseline MEMIT approach, MEMIT enhanced with Most-Probable Early Stopping (MPES), and MEMIT further improved with both MPES and a Frobenius norm constraint. The results are shown for Llama2-7B and Llama3-8B language models, highlighting the impact of each modification on editing scores (Edit, Paraphrase, Neighborhood) and overall performance, including generation entropy. This demonstrates the effectiveness of ENCORE (Early stopping and Norm-Constrained Robust knowledge Editing), which combines MPES and the norm constraint, in achieving superior performance compared to the individual improvements and the original MEMIT method.</p><details><summary>read the caption</summary>Table 3: Editing performance of ENCORE when compared to baseline MEMIT and modifications using MPES and Norm Constraint.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A0.T4.1><tr class=ltx_tr id=A0.T4.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A0.T4.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.1.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.3.1 style=font-size:90%><span class=ltx_text id=A0.T4.1.1.3.1.1></span> <span class=ltx_text id=A0.T4.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=A0.T4.1.1.3.1.2.1><span class=ltx_tr id=A0.T4.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=A0.T4.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A0.T4.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.4.1 style=font-size:90%><span class=ltx_text id=A0.T4.1.1.4.1.1></span> <span class=ltx_text id=A0.T4.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A0.T4.1.1.4.1.2.1><span class=ltx_tr id=A0.T4.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=A0.T4.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A0.T4.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.5.1 style=font-size:90%><span class=ltx_text id=A0.T4.1.1.5.1.1></span> <span class=ltx_text id=A0.T4.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=A0.T4.1.1.5.1.2.1><span class=ltx_tr id=A0.T4.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=A0.T4.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A0.T4.1.1.5.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.6.1 style=font-size:90%><span class=ltx_text id=A0.T4.1.1.6.1.1></span> <span class=ltx_text id=A0.T4.1.1.6.1.2><span class="ltx_tabular ltx_align_middle" id=A0.T4.1.1.6.1.2.1><span class=ltx_tr id=A0.T4.1.1.6.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.6.1.2.1.1.1>Overall</span></span>
<span class=ltx_tr id=A0.T4.1.1.6.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.6.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A0.T4.1.1.6.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A0.T4.1.1.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.1.7.1 style=font-size:90%><span class=ltx_text id=A0.T4.1.1.7.1.1></span> <span class=ltx_text id=A0.T4.1.1.7.1.2><span class="ltx_tabular ltx_align_middle" id=A0.T4.1.1.7.1.2.1><span class=ltx_tr id=A0.T4.1.1.7.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.7.1.2.1.1.1>Generation</span></span>
<span class=ltx_tr id=A0.T4.1.1.7.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A0.T4.1.1.7.1.2.1.2.1>Entropy</span></span>
</span></span><span class=ltx_text id=A0.T4.1.1.7.1.3></span></span></td></tr><tr class=ltx_tr id=A0.T4.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A0.T4.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.1.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.2.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.3.1 style=font-size:90%>79.27</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.4.1 style=font-size:90%>67.45</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.5.1 style=font-size:90%>52.39</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.6.1 style=font-size:90%>64.48</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A0.T4.1.2.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.2.7.1 style=font-size:90%>570.24</span></td></tr><tr class=ltx_tr id=A0.T4.1.3><td class=ltx_td id=A0.T4.1.3.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.2.1 style=font-size:90%>EMMET+MPES</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.3.1 style=font-size:90%>95.08</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.4.1 style=font-size:90%>79.47</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.5.1 style=font-size:90%>56.33</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.6.1 style=font-size:90%>73.43</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.3.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.3.7.1 style=font-size:90%>555.39</span></td></tr><tr class=ltx_tr id=A0.T4.1.4><td class=ltx_td id=A0.T4.1.4.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.2.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.3.1 style=font-size:90%>88.58</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.4.1 style=font-size:90%>70.33</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.5.1 style=font-size:90%>56.04</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.6.1 style=font-size:90%>69.2</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.4.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.4.7.1 style=font-size:90%>580.27</span></td></tr><tr class=ltx_tr id=A0.T4.1.5><td class=ltx_td id=A0.T4.1.5.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.2.1 style=font-size:90%>AlphaEdit + MPES</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.3.1 style=font-size:90%>95.52</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.4.1 style=font-size:90%>82.08</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.5.1 style=font-size:90%>60.03</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.6.1 style=font-size:90%>76.32</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.5.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.5.7.1 style=font-size:90%>565.44</span></td></tr><tr class=ltx_tr id=A0.T4.1.6><td class=ltx_td id=A0.T4.1.6.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.2.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.3.1 style=font-size:90%>94.04</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.4.1 style=font-size:90%>79.91</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.5.1 style=font-size:90%>57.9</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.6.1 style=font-size:90%>74.22</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.6.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.6.7.1 style=font-size:90%>517.37</span></td></tr><tr class=ltx_tr id=A0.T4.1.7><td class=ltx_td id=A0.T4.1.7.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.2.1 style=font-size:90%>MEMIT + MPES</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.3.1 style=font-size:90%>91.43</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.4.1 style=font-size:90%>73.68</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.5.1 style=font-size:90%>61.71</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.6.1 style=font-size:90%>73.68</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.7.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.7.7.1 style=font-size:90%>532.47</span></td></tr><tr class=ltx_tr id=A0.T4.1.8><td class=ltx_td id=A0.T4.1.8.1></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.2.1 style=font-size:90%>Norm-Constraint</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.3.1 style=font-size:90%>93.89</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.4.1 style=font-size:90%>80.9</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.5.1 style=font-size:90%>58.0</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.6.1 style=font-size:90%>74.53</span></td><td class="ltx_td ltx_align_center" id=A0.T4.1.8.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.8.7.1 style=font-size:90%>504.68</span></td></tr><tr class=ltx_tr id=A0.T4.1.9><td class="ltx_td ltx_border_bb" id=A0.T4.1.9.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.2.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.3.1 style=font-size:90%>93.21</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.4.1 style=font-size:90%>78.04</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.5><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.5.1 style=font-size:90%>59.95</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.6><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.6.1 style=font-size:90%>74.58</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A0.T4.1.9.7><span class="ltx_text ltx_font_smallcaps" id=A0.T4.1.9.7.1 style=font-size:90%>524.34</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the knowledge editing performance results for the GPT-2-XL model on the CounterFact dataset. It compares several knowledge editing algorithms (EMMET, AlphaEdit, MEMIT, and ENCORE) and evaluates their performance when combined with the Most-Probable Early Stopping (MPES) technique. The performance is assessed using five key metrics: Efficacy Score (ES), Paraphrase Score (PS), Neighborhood Score (NS), Overall Score (S), and Generation Entropy (GE). These metrics provide a comprehensive evaluation of the accuracy, generalization, and fluency of knowledge editing across different algorithms.</p><details><summary>read the caption</summary>Table 4: Knowledge editing performance for GPT2-XL on the CounterFact dataset for different algorithms in combination with MPES.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A4.T5.1><tr class=ltx_tr id=A4.T5.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A4.T5.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.1.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.2.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.3.1 style=font-size:90%><span class=ltx_text id=A4.T5.1.1.3.1.1></span> <span class=ltx_text id=A4.T5.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=A4.T5.1.1.3.1.2.1><span class=ltx_tr id=A4.T5.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=A4.T5.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A4.T5.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.4.1 style=font-size:90%><span class=ltx_text id=A4.T5.1.1.4.1.1></span> <span class=ltx_text id=A4.T5.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A4.T5.1.1.4.1.2.1><span class=ltx_tr id=A4.T5.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=A4.T5.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A4.T5.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.5><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.5.1 style=font-size:90%><span class=ltx_text id=A4.T5.1.1.5.1.1></span> <span class=ltx_text id=A4.T5.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=A4.T5.1.1.5.1.2.1><span class=ltx_tr id=A4.T5.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=A4.T5.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A4.T5.1.1.5.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.6><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.6.1 style=font-size:90%><span class=ltx_text id=A4.T5.1.1.6.1.1></span> <span class=ltx_text id=A4.T5.1.1.6.1.2><span class="ltx_tabular ltx_align_middle" id=A4.T5.1.1.6.1.2.1><span class=ltx_tr id=A4.T5.1.1.6.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.6.1.2.1.1.1>Overall</span></span>
<span class=ltx_tr id=A4.T5.1.1.6.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.6.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A4.T5.1.1.6.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A4.T5.1.1.7><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.1.7.1 style=font-size:90%><span class=ltx_text id=A4.T5.1.1.7.1.1></span> <span class=ltx_text id=A4.T5.1.1.7.1.2><span class="ltx_tabular ltx_align_middle" id=A4.T5.1.1.7.1.2.1><span class=ltx_tr id=A4.T5.1.1.7.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.7.1.2.1.1.1>Generation</span></span>
<span class=ltx_tr id=A4.T5.1.1.7.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A4.T5.1.1.7.1.2.1.2.1>Entropy</span></span>
</span></span><span class=ltx_text id=A4.T5.1.1.7.1.3></span></span></td></tr><tr class=ltx_tr id=A4.T5.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A4.T5.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.1.1 style=font-size:90%>EMMET baseline</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.3.1 style=font-size:90%>93.85</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.4.1 style=font-size:90%>87.32</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.5><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.5.1 style=font-size:90%>58.07</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.6><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.6.1 style=font-size:90%>76.281</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A4.T5.1.2.7><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.2.7.1 style=font-size:90%>579.79</span></td></tr><tr class=ltx_tr id=A4.T5.1.3><td class="ltx_td ltx_align_left" id=A4.T5.1.3.1><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.1.1 style=font-size:90%>EMMET best-editing</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.3.1 style=font-size:90%>94.24</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.4.1 style=font-size:90%>87.2</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.5><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.5.1 style=font-size:90%>54.36</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.6><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.6.1 style=font-size:90%>74.12</span></td><td class="ltx_td ltx_align_center" id=A4.T5.1.3.7><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.3.7.1 style=font-size:90%>566.08</span></td></tr><tr class=ltx_tr id=A4.T5.1.4><td class="ltx_td ltx_align_left ltx_border_bb" id=A4.T5.1.4.1><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.1.1 style=font-size:90%>EMMET best-downstream</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.3.1 style=font-size:90%>90.35</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.4.1 style=font-size:90%>85.97</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.5><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.5.1 style=font-size:90%>53.65</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.6><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.6.1 style=font-size:90%>72.57</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A4.T5.1.4.7><span class="ltx_text ltx_font_smallcaps" id=A4.T5.1.4.7.1 style=font-size:90%>541.16</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the editing performance results for the EMMET algorithm using the Llama2-7B model, specifically focusing on how the inclusion of a norm constraint affects the editing performance. It compares the baseline EMMET performance with two variations that incorporate the norm constraint: one optimized for the best overall editing score and the other optimized for the best downstream performance.</p><details><summary>read the caption</summary>Table 5: Editing performance for EMMET with Llama2-7B with norm constraint.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T6.1.1><tr class=ltx_tr id=A6.T6.1.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T6.1.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T6.1.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.1.3.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T6.1.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.1.1.1 style=font-size:90%><span class=ltx_text id=A6.T6.1.1.1.1.1.2></span> <span class=ltx_text id=A6.T6.1.1.1.1.1.1><span class="ltx_tabular ltx_align_middle" id=A6.T6.1.1.1.1.1.1.1><span class=ltx_tr id=A6.T6.1.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T6.1.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T6.1.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T6.1.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T6.1.1.1.1.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T6.1.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.1.4.1 style=font-size:90%><span class=ltx_text id=A6.T6.1.1.1.4.1.1></span> <span class=ltx_text id=A6.T6.1.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A6.T6.1.1.1.4.1.2.1><span class=ltx_tr id=A6.T6.1.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T6.1.1.1.4.1.2.1.1.1>Probability</span></span>
<span class=ltx_tr id=A6.T6.1.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T6.1.1.1.4.1.2.1.2.1>Cut Off</span></span>
</span></span><span class=ltx_text id=A6.T6.1.1.1.4.1.3></span></span></td><td class="ltx_td ltx_border_tt" id=A6.T6.1.1.1.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T6.1.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.2.1.1 style=font-size:90%>EMMET + MPES</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.2.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.2.3.1 style=font-size:90%>10,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.2.4.1 style=font-size:90%>+1</span></td><td class="ltx_td ltx_border_t" id=A6.T6.1.1.2.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.3><td class=ltx_td id=A6.T6.1.1.3.1></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.3.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.3.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.3.4.1 style=font-size:90%>+0</span></td><td class=ltx_td id=A6.T6.1.1.3.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.4><td class=ltx_td id=A6.T6.1.1.4.1></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.4.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.4.4.1 style=font-size:90%>+0</span></td><td class=ltx_td id=A6.T6.1.1.4.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.5><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T6.1.1.5.1><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.5.1.1 style=font-size:90%>AlphaEdit + MPEs</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.5.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.5.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.5.4.1 style=font-size:90%>+1</span></td><td class="ltx_td ltx_border_t" id=A6.T6.1.1.5.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.6><td class=ltx_td id=A6.T6.1.1.6.1></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.6.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.6.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.6.4.1 style=font-size:90%>+0</span></td><td class=ltx_td id=A6.T6.1.1.6.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.7><td class=ltx_td id=A6.T6.1.1.7.1></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.7.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.7.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.7.4.1 style=font-size:90%>+0</span></td><td class=ltx_td id=A6.T6.1.1.7.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.8><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T6.1.1.8.1><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.8.1.1 style=font-size:90%>MEMIT + MPEs</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.8.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.8.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T6.1.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.8.4.1 style=font-size:90%>+2</span></td><td class="ltx_td ltx_border_t" id=A6.T6.1.1.8.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.9><td class=ltx_td id=A6.T6.1.1.9.1></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.9.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.9.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T6.1.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.9.4.1 style=font-size:90%>+1</span></td><td class=ltx_td id=A6.T6.1.1.9.5></td></tr><tr class=ltx_tr id=A6.T6.1.1.10><td class="ltx_td ltx_border_bb" id=A6.T6.1.1.10.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T6.1.1.10.2><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.10.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T6.1.1.10.3><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.10.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T6.1.1.10.4><span class="ltx_text ltx_font_smallcaps" id=A6.T6.1.1.10.4.1 style=font-size:90%>+2</span></td><td class="ltx_td ltx_border_bb" id=A6.T6.1.1.10.5></td></tr></table></table></figure><blockquote><p>üîº This table presents the hyperparameters used for different knowledge editing algorithms when combined with the Most-Probable Early Stopping (MPES) technique. It shows the specific values of Œªp (lambda p), the probability cutoff parameter, and the model used (GPT2-XL, Llama2-7B, Llama3-8B) for each algorithm (EMMET, AlphaEdit, MEMIT). These settings are crucial for fine-tuning the algorithms&rsquo; performance and controlling for overfitting during the knowledge editing process on the CounterFact dataset.</p><details><summary>read the caption</summary>Table 6: Hyperparameters for different algorithms with MPES on CouterFact dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T7.2.2><tr class=ltx_tr id=A6.T7.2.2.2><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T7.2.2.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.2.3.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T7.2.2.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.2.4.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T7.1.1.1.1><span class=ltx_text id=A6.T7.1.1.1.1.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.1.1.1.1.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.1.1.1.1.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T7.1.1.1.1.1.1><span class=ltx_tr id=A6.T7.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T7.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T7.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T7.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T7.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T7.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T7.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T7.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T7.1.1.1.1.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.1.1.1.1.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T7.2.2.2.2><span class=ltx_text id=A6.T7.2.2.2.2.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.2.2.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.2.2.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T7.2.2.2.2.1.1><span class=ltx_tr id=A6.T7.2.2.2.2.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T7.2.2.2.2.1.1.1.1><math alttext="\lambda_{n}" class="ltx_Math" display="inline" id="A6.T7.2.2.2.2.1.1.1.1.m1.1"><semantics id="A6.T7.2.2.2.2.1.1.1.1.m1.1a"><msub id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.2" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.3" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T7.2.2.2.2.1.1.1.1.m1.1b"><apply id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="A6.T7.2.2.2.2.1.1.1.1.m1.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T7.2.2.2.2.1.1.1.1.m1.1c">\lambda_{n}</annotation><annotation encoding="application/x-llamapun" id="A6.T7.2.2.2.2.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T7.2.2.2.2.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.2.2.5 style=font-size:90%></span></td></tr><tr class=ltx_tr id=A6.T7.2.2.3><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T7.2.2.3.1><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.3.1.1 style=font-size:90%>Norm Constraint</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T7.2.2.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.3.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T7.2.2.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.3.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T7.2.2.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.3.4.1 style=font-size:90%>10</span></td></tr><tr class=ltx_tr id=A6.T7.2.2.4><td class=ltx_td id=A6.T7.2.2.4.1></td><td class="ltx_td ltx_align_center" id=A6.T7.2.2.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T7.2.2.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T7.2.2.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.4.4.1 style=font-size:90%>10</span></td></tr><tr class=ltx_tr id=A6.T7.2.2.5><td class="ltx_td ltx_border_bb" id=A6.T7.2.2.5.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T7.2.2.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T7.2.2.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.5.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T7.2.2.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T7.2.2.5.4.1 style=font-size:90%>20</span></td></tr></table></table></figure><blockquote><p>üîº This table shows the hyperparameters used for the norm constraint method on the CounterFact dataset. It lists the model (GPT2-XL, Llama2-7B, Llama3-8B), the lambda parameter (Œª), and the hyperparameter A for each model. These values were used in the experiments involving the norm constraint technique.</p><details><summary>read the caption</summary>Table 7: Hyperparameters for Norm Constraint on CouterFact dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T8.2.2><tr class=ltx_tr id=A6.T8.2.2.2><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T8.2.2.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.3.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T8.2.2.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.4.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T8.1.1.1.1><span class=ltx_text id=A6.T8.1.1.1.1.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.1.1.1.1.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.1.1.1.1.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T8.1.1.1.1.1.1><span class=ltx_tr id=A6.T8.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T8.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T8.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T8.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T8.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T8.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T8.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T8.1.1.1.1.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.1.1.1.1.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T8.2.2.2.2><span class=ltx_text id=A6.T8.2.2.2.2.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.2.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.2.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T8.2.2.2.2.1.1><span class=ltx_tr id=A6.T8.2.2.2.2.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T8.2.2.2.2.1.1.1.1><math alttext="\lambda_{n}" class="ltx_Math" display="inline" id="A6.T8.2.2.2.2.1.1.1.1.m1.1"><semantics id="A6.T8.2.2.2.2.1.1.1.1.m1.1a"><msub id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.2" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.3" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T8.2.2.2.2.1.1.1.1.m1.1b"><apply id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="A6.T8.2.2.2.2.1.1.1.1.m1.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.2.2.2.2.1.1.1.1.m1.1c">\lambda_{n}</annotation><annotation encoding="application/x-llamapun" id="A6.T8.2.2.2.2.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T8.2.2.2.2.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.2.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T8.2.2.2.5><span class=ltx_text id=A6.T8.2.2.2.5.1></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.5.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.5.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T8.2.2.2.5.3.1><span class=ltx_tr id=A6.T8.2.2.2.5.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T8.2.2.2.5.3.1.1.1>Probability</span></span>
<span class=ltx_tr id=A6.T8.2.2.2.5.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T8.2.2.2.5.3.1.2.1>Cut Off</span></span>
</span></span><span class=ltx_text id=A6.T8.2.2.2.5.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.2.5.5 style=font-size:90%></span></td></tr><tr class=ltx_tr id=A6.T8.2.2.3><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T8.2.2.3.1><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.3.1.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T8.2.2.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.3.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T8.2.2.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.3.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T8.2.2.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.3.4.1 style=font-size:90%>10</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T8.2.2.3.5><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.3.5.1 style=font-size:90%>+3</span></td></tr><tr class=ltx_tr id=A6.T8.2.2.4><td class=ltx_td id=A6.T8.2.2.4.1></td><td class="ltx_td ltx_align_center" id=A6.T8.2.2.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T8.2.2.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T8.2.2.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.4.4.1 style=font-size:90%>10</span></td><td class="ltx_td ltx_align_center" id=A6.T8.2.2.4.5><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.4.5.1 style=font-size:90%>+2</span></td></tr><tr class=ltx_tr id=A6.T8.2.2.5><td class="ltx_td ltx_border_bb" id=A6.T8.2.2.5.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T8.2.2.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T8.2.2.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.5.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T8.2.2.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.5.4.1 style=font-size:90%>20</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T8.2.2.5.5><span class="ltx_text ltx_font_smallcaps" id=A6.T8.2.2.5.5.1 style=font-size:90%>+1</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the optimal hyperparameters for the ENCORE model when fine-tuning on the CounterFact dataset. It lists the model (GPT2-XL, Llama2-7B, Llama3-8B), the lambda parameter (Œª), the hyperparameter for the norm constraint (Œªn), and the probability cutoff used for early stopping. These values were determined empirically to yield optimal performance with the ENCORE method on this dataset.</p><details><summary>read the caption</summary>Table 8: Hyperparameters for ENCORE on CouterFact dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T9.1.1><tr class=ltx_tr id=A6.T9.1.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T9.1.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T9.1.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.1.3.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T9.1.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.1.1.1 style=font-size:90%><span class=ltx_text id=A6.T9.1.1.1.1.1.2></span> <span class=ltx_text id=A6.T9.1.1.1.1.1.1><span class="ltx_tabular ltx_align_middle" id=A6.T9.1.1.1.1.1.1.1><span class=ltx_tr id=A6.T9.1.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T9.1.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T9.1.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T9.1.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T9.1.1.1.1.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T9.1.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.1.4.1 style=font-size:90%><span class=ltx_text id=A6.T9.1.1.1.4.1.1></span> <span class=ltx_text id=A6.T9.1.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A6.T9.1.1.1.4.1.2.1><span class=ltx_tr id=A6.T9.1.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T9.1.1.1.4.1.2.1.1.1>Probability</span></span>
<span class=ltx_tr id=A6.T9.1.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T9.1.1.1.4.1.2.1.2.1>Cut Off</span></span>
</span></span><span class=ltx_text id=A6.T9.1.1.1.4.1.3></span></span></td><td class="ltx_td ltx_border_tt" id=A6.T9.1.1.1.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T9.1.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.2.1.1 style=font-size:90%>EMMET + MPES</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.2.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.2.3.1 style=font-size:90%>10,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.2.4.1 style=font-size:90%>+1</span></td><td class="ltx_td ltx_border_t" id=A6.T9.1.1.2.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.3><td class=ltx_td id=A6.T9.1.1.3.1></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.3.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.3.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.3.4.1 style=font-size:90%>+1</span></td><td class=ltx_td id=A6.T9.1.1.3.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.4><td class=ltx_td id=A6.T9.1.1.4.1></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.4.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.4.4.1 style=font-size:90%>+2</span></td><td class=ltx_td id=A6.T9.1.1.4.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.5><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T9.1.1.5.1><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.5.1.1 style=font-size:90%>AlphaEdit + MPEs</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.5.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.5.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.5.4.1 style=font-size:90%>+1</span></td><td class="ltx_td ltx_border_t" id=A6.T9.1.1.5.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.6><td class=ltx_td id=A6.T9.1.1.6.1></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.6.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.6.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.6.4.1 style=font-size:90%>+1</span></td><td class=ltx_td id=A6.T9.1.1.6.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.7><td class=ltx_td id=A6.T9.1.1.7.1></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.7.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.7.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.7.4.1 style=font-size:90%>+3</span></td><td class=ltx_td id=A6.T9.1.1.7.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.8><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T9.1.1.8.1><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.8.1.1 style=font-size:90%>MEMIT + MPEs</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.8.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.8.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T9.1.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.8.4.1 style=font-size:90%>+5</span></td><td class="ltx_td ltx_border_t" id=A6.T9.1.1.8.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.9><td class=ltx_td id=A6.T9.1.1.9.1></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.9.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.9.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T9.1.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.9.4.1 style=font-size:90%>+1</span></td><td class=ltx_td id=A6.T9.1.1.9.5></td></tr><tr class=ltx_tr id=A6.T9.1.1.10><td class="ltx_td ltx_border_bb" id=A6.T9.1.1.10.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T9.1.1.10.2><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.10.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T9.1.1.10.3><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.10.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T9.1.1.10.4><span class="ltx_text ltx_font_smallcaps" id=A6.T9.1.1.10.4.1 style=font-size:90%>+4</span></td><td class="ltx_td ltx_border_bb" id=A6.T9.1.1.10.5></td></tr></table></table></figure><blockquote><p>üîº This table presents the hyperparameters used for different knowledge editing algorithms when combined with Most-Probable Early Stopping (MPES) on the zsRE dataset. It shows the values of Œªp (lambda p), Œªn (lambda n), and the probability cutoff for each algorithm (EMMET, AlphaEdit, and MEMIT) across three different language models (GPT2-XL, Llama2-7B, and Llama3-8B). These hyperparameters were fine-tuned for optimal performance on the zsRE dataset.</p><details><summary>read the caption</summary>Table 9: Hyperparameters for different algorithms with MPES on zsRE dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T10.2.2><tr class=ltx_tr id=A6.T10.2.2.2><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T10.2.2.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.2.3.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T10.2.2.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.2.4.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T10.1.1.1.1><span class=ltx_text id=A6.T10.1.1.1.1.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.1.1.1.1.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.1.1.1.1.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T10.1.1.1.1.1.1><span class=ltx_tr id=A6.T10.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T10.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T10.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T10.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T10.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T10.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T10.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T10.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T10.1.1.1.1.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.1.1.1.1.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T10.2.2.2.2><span class=ltx_text id=A6.T10.2.2.2.2.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.2.2.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.2.2.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T10.2.2.2.2.1.1><span class=ltx_tr id=A6.T10.2.2.2.2.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T10.2.2.2.2.1.1.1.1><math alttext="\lambda_{n}" class="ltx_Math" display="inline" id="A6.T10.2.2.2.2.1.1.1.1.m1.1"><semantics id="A6.T10.2.2.2.2.1.1.1.1.m1.1a"><msub id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.2" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.3" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T10.2.2.2.2.1.1.1.1.m1.1b"><apply id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="A6.T10.2.2.2.2.1.1.1.1.m1.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T10.2.2.2.2.1.1.1.1.m1.1c">\lambda_{n}</annotation><annotation encoding="application/x-llamapun" id="A6.T10.2.2.2.2.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T10.2.2.2.2.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.2.2.5 style=font-size:90%></span></td></tr><tr class=ltx_tr id=A6.T10.2.2.3><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T10.2.2.3.1><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.3.1.1 style=font-size:90%>Norm Constraint</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T10.2.2.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.3.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T10.2.2.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.3.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T10.2.2.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.3.4.1 style=font-size:90%>40</span></td></tr><tr class=ltx_tr id=A6.T10.2.2.4><td class=ltx_td id=A6.T10.2.2.4.1></td><td class="ltx_td ltx_align_center" id=A6.T10.2.2.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T10.2.2.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T10.2.2.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.4.4.1 style=font-size:90%>10</span></td></tr><tr class=ltx_tr id=A6.T10.2.2.5><td class="ltx_td ltx_border_bb" id=A6.T10.2.2.5.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T10.2.2.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T10.2.2.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.5.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T10.2.2.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T10.2.2.5.4.1 style=font-size:90%>20</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the hyperparameters used for the norm constraint method on the zsRE dataset. It shows the model (GPT2-XL, Llama2-7B, Llama3-8B), the hyperparameter Œª for the norm constraint (40, 10, 20 respectively), and the hyperparameter A which is the Frobenius norm constraint (20000, 15000, 15000 respectively).</p><details><summary>read the caption</summary>Table 10: Hyperparameters for Norm Constraint on zsRE dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A6.T11.2.2><tr class=ltx_tr id=A6.T11.2.2.2><td class="ltx_td ltx_align_left ltx_border_tt" id=A6.T11.2.2.2.3><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.3.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T11.2.2.2.4><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.4.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T11.1.1.1.1><span class=ltx_text id=A6.T11.1.1.1.1.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.1.1.1.1.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.1.1.1.1.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T11.1.1.1.1.1.1><span class=ltx_tr id=A6.T11.1.1.1.1.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T11.1.1.1.1.1.1.1.1><math alttext="\lambda_{p}" class="ltx_Math" display="inline" id="A6.T11.1.1.1.1.1.1.1.1.m1.1"><semantics id="A6.T11.1.1.1.1.1.1.1.1.m1.1a"><msub id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T11.1.1.1.1.1.1.1.1.m1.1b"><apply id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A6.T11.1.1.1.1.1.1.1.1.m1.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T11.1.1.1.1.1.1.1.1.m1.1c">\lambda_{p}</annotation><annotation encoding="application/x-llamapun" id="A6.T11.1.1.1.1.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T11.1.1.1.1.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.1.1.1.1.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T11.2.2.2.2><span class=ltx_text id=A6.T11.2.2.2.2.2></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.2.3 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.2.1 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T11.2.2.2.2.1.1><span class=ltx_tr id=A6.T11.2.2.2.2.1.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T11.2.2.2.2.1.1.1.1><math alttext="\lambda_{n}" class="ltx_Math" display="inline" id="A6.T11.2.2.2.2.1.1.1.1.m1.1"><semantics id="A6.T11.2.2.2.2.1.1.1.1.m1.1a"><msub id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.2" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.2.cmml">Œª</mi><mi id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.3" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A6.T11.2.2.2.2.1.1.1.1.m1.1b"><apply id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.2">ùúÜ</ci><ci id="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="A6.T11.2.2.2.2.1.1.1.1.m1.1.1.3">ùëõ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T11.2.2.2.2.1.1.1.1.m1.1c">\lambda_{n}</annotation><annotation encoding="application/x-llamapun" id="A6.T11.2.2.2.2.1.1.1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></span></span>
</span></span><span class=ltx_text id=A6.T11.2.2.2.2.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.2.5 style=font-size:90%></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A6.T11.2.2.2.5><span class=ltx_text id=A6.T11.2.2.2.5.1></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.5.2 style=font-size:90%> </span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.5.3 style=font-size:90%><span class="ltx_tabular ltx_align_middle" id=A6.T11.2.2.2.5.3.1><span class=ltx_tr id=A6.T11.2.2.2.5.3.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T11.2.2.2.5.3.1.1.1>Probability</span></span>
<span class=ltx_tr id=A6.T11.2.2.2.5.3.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A6.T11.2.2.2.5.3.1.2.1>Cut Off</span></span>
</span></span><span class=ltx_text id=A6.T11.2.2.2.5.4></span><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.2.5.5 style=font-size:90%></span></td></tr><tr class=ltx_tr id=A6.T11.2.2.3><td class="ltx_td ltx_align_left ltx_border_t" id=A6.T11.2.2.3.1><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.3.1.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T11.2.2.3.2><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.3.2.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T11.2.2.3.3><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.3.3.1 style=font-size:90%>20,000</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T11.2.2.3.4><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.3.4.1 style=font-size:90%>40</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A6.T11.2.2.3.5><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.3.5.1 style=font-size:90%>+4</span></td></tr><tr class=ltx_tr id=A6.T11.2.2.4><td class=ltx_td id=A6.T11.2.2.4.1></td><td class="ltx_td ltx_align_center" id=A6.T11.2.2.4.2><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.4.2.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center" id=A6.T11.2.2.4.3><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.4.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center" id=A6.T11.2.2.4.4><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.4.4.1 style=font-size:90%>10</span></td><td class="ltx_td ltx_align_center" id=A6.T11.2.2.4.5><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.4.5.1 style=font-size:90%>+2</span></td></tr><tr class=ltx_tr id=A6.T11.2.2.5><td class="ltx_td ltx_border_bb" id=A6.T11.2.2.5.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T11.2.2.5.2><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.5.2.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T11.2.2.5.3><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.5.3.1 style=font-size:90%>15,000</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T11.2.2.5.4><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.5.4.1 style=font-size:90%>10</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A6.T11.2.2.5.5><span class="ltx_text ltx_font_smallcaps" id=A6.T11.2.2.5.5.1 style=font-size:90%>+3</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the hyperparameters used for the ENCORE model on the zsRE dataset. It details the values of lambda_p (Œªp), lambda_n (Œªn), and the probability cutoff used during the training process. These values were specifically tuned for the ENCORE model and this specific dataset to achieve optimal performance in the knowledge editing task. The table shows hyperparameter settings for GPT2-XL, Llama2-7B, and Llama3-8B models.</p><details><summary>read the caption</summary>Table 11: Hyperparameters for ENCORE on zsRE dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A9.T12.1><tr class=ltx_tr id=A9.T12.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A9.T12.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.1.1.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T12.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T12.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.1.3.1 style=font-size:90%><span class=ltx_text id=A9.T12.1.1.3.1.1></span> <span class=ltx_text id=A9.T12.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T12.1.1.3.1.2.1><span class=ltx_tr id=A9.T12.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=A9.T12.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T12.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T12.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.1.4.1 style=font-size:90%><span class=ltx_text id=A9.T12.1.1.4.1.1></span> <span class=ltx_text id=A9.T12.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T12.1.1.4.1.2.1><span class=ltx_tr id=A9.T12.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=A9.T12.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T12.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T12.1.1.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.1.5.1 style=font-size:90%><span class=ltx_text id=A9.T12.1.1.5.1.1></span> <span class=ltx_text id=A9.T12.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T12.1.1.5.1.2.1><span class=ltx_tr id=A9.T12.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=A9.T12.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T12.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T12.1.1.5.1.3></span></span></td></tr><tr class=ltx_tr id=A9.T12.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A9.T12.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.2.1.1 style=font-size:90%>GPT2-XL</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T12.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.2.2.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T12.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.2.3.1 style=font-size:90%>39.71</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T12.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.2.4.1 style=font-size:90%>27.17</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T12.1.2.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.2.5.1 style=font-size:90%>9.78</span></td></tr><tr class=ltx_tr id=A9.T12.1.3><td class=ltx_td id=A9.T12.1.3.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.3.2.1 style=font-size:90%>EMMET+MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.3.3.1 style=font-size:90%>53.55</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.3.4.1 style=font-size:90%>39.42</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.3.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.3.5.1 style=font-size:90%>16.81</span></td></tr><tr class=ltx_tr id=A9.T12.1.4><td class=ltx_td id=A9.T12.1.4.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.4.2.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.4.3.1 style=font-size:90%>42.1</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.4.4.1 style=font-size:90%>33.61</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.4.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.4.5.1 style=font-size:90%>14.61</span></td></tr><tr class=ltx_tr id=A9.T12.1.5><td class=ltx_td id=A9.T12.1.5.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.5.2.1 style=font-size:90%>AlphaEdit + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.5.3.1 style=font-size:90%>54.99</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.5.4.1 style=font-size:90%>43.18</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.5.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.5.5.1 style=font-size:90%>18.4</span></td></tr><tr class=ltx_tr id=A9.T12.1.6><td class=ltx_td id=A9.T12.1.6.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.6.2.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.6.3.1 style=font-size:90%>74.6</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.6.4.1 style=font-size:90%>61.77</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.6.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.6.5.1 style=font-size:90%>22.4</span></td></tr><tr class=ltx_tr id=A9.T12.1.7><td class=ltx_td id=A9.T12.1.7.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.7.2.1 style=font-size:90%>MEMIT + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.7.3.1 style=font-size:90%>75.09</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.7.4.1 style=font-size:90%>61.58</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.7.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.7.5.1 style=font-size:90%>23.37</span></td></tr><tr class=ltx_tr id=A9.T12.1.8><td class=ltx_td id=A9.T12.1.8.1></td><td class="ltx_td ltx_align_center" id=A9.T12.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.8.2.1 style=font-size:90%>Norm-Constraint</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.8.3.1 style=font-size:90%>74.51</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.8.4.1 style=font-size:90%>61.9</span></td><td class="ltx_td ltx_align_center" id=A9.T12.1.8.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.8.5.1 style=font-size:90%>23.39</span></td></tr><tr class=ltx_tr id=A9.T12.1.9><td class="ltx_td ltx_border_bb" id=A9.T12.1.9.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T12.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.9.2.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T12.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.9.3.1 style=font-size:90%>74.46</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T12.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.9.4.1 style=font-size:90%>61.79</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T12.1.9.5><span class="ltx_text ltx_font_smallcaps" id=A9.T12.1.9.5.1 style=font-size:90%>23.41</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the editing performance of different knowledge editing methods on the GPT2-XL model using the zsRE dataset. It shows the efficacy, paraphrase score, and neighborhood score for each method. These metrics evaluate the success of the edit, the model&rsquo;s ability to generalize to paraphrases of the edited fact, and the impact on related knowledge, respectively.</p><details><summary>read the caption</summary>Table 12: Editing performance for GPT2-XL on zsre dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A9.T13.1><tr class=ltx_tr id=A9.T13.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A9.T13.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.1.1.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T13.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T13.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.1.3.1 style=font-size:90%><span class=ltx_text id=A9.T13.1.1.3.1.1></span> <span class=ltx_text id=A9.T13.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T13.1.1.3.1.2.1><span class=ltx_tr id=A9.T13.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=A9.T13.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T13.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T13.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.1.4.1 style=font-size:90%><span class=ltx_text id=A9.T13.1.1.4.1.1></span> <span class=ltx_text id=A9.T13.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T13.1.1.4.1.2.1><span class=ltx_tr id=A9.T13.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=A9.T13.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T13.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T13.1.1.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.1.5.1 style=font-size:90%><span class=ltx_text id=A9.T13.1.1.5.1.1></span> <span class=ltx_text id=A9.T13.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T13.1.1.5.1.2.1><span class=ltx_tr id=A9.T13.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=A9.T13.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T13.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T13.1.1.5.1.3></span></span></td></tr><tr class=ltx_tr id=A9.T13.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A9.T13.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.2.1.1 style=font-size:90%>Llama2-7B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T13.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.2.2.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T13.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.2.3.1 style=font-size:90%>75.42</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T13.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.2.4.1 style=font-size:90%>69.69</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T13.1.2.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.2.5.1 style=font-size:90%>33.89</span></td></tr><tr class=ltx_tr id=A9.T13.1.3><td class=ltx_td id=A9.T13.1.3.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.3.2.1 style=font-size:90%>EMMET+MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.3.3.1 style=font-size:90%>84.07</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.3.4.1 style=font-size:90%>76.9</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.3.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.3.5.1 style=font-size:90%>41.88</span></td></tr><tr class=ltx_tr id=A9.T13.1.4><td class=ltx_td id=A9.T13.1.4.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.4.2.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.4.3.1 style=font-size:90%>83.77</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.4.4.1 style=font-size:90%>77.12</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.4.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.4.5.1 style=font-size:90%>41.96</span></td></tr><tr class=ltx_tr id=A9.T13.1.5><td class=ltx_td id=A9.T13.1.5.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.5.2.1 style=font-size:90%>AlphaEdit + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.5.3.1 style=font-size:90%>83.8</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.5.4.1 style=font-size:90%>77.64</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.5.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.5.5.1 style=font-size:90%>41.97</span></td></tr><tr class=ltx_tr id=A9.T13.1.6><td class=ltx_td id=A9.T13.1.6.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.6.2.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.6.3.1 style=font-size:90%>79.49</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.6.4.1 style=font-size:90%>74.29</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.6.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.6.5.1 style=font-size:90%>41.8</span></td></tr><tr class=ltx_tr id=A9.T13.1.7><td class=ltx_td id=A9.T13.1.7.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.7.2.1 style=font-size:90%>MEMIT + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.7.3.1 style=font-size:90%>83.01</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.7.4.1 style=font-size:90%>77.45</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.7.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.7.5.1 style=font-size:90%>44.64</span></td></tr><tr class=ltx_tr id=A9.T13.1.8><td class=ltx_td id=A9.T13.1.8.1></td><td class="ltx_td ltx_align_center" id=A9.T13.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.8.2.1 style=font-size:90%>Norm-Constraint</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.8.3.1 style=font-size:90%>88.73</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.8.4.1 style=font-size:90%>84.05</span></td><td class="ltx_td ltx_align_center" id=A9.T13.1.8.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.8.5.1 style=font-size:90%>47.98</span></td></tr><tr class=ltx_tr id=A9.T13.1.9><td class="ltx_td ltx_border_bb" id=A9.T13.1.9.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T13.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.9.2.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T13.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.9.3.1 style=font-size:90%>89.1</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T13.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.9.4.1 style=font-size:90%>84.28</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T13.1.9.5><span class="ltx_text ltx_font_smallcaps" id=A9.T13.1.9.5.1 style=font-size:90%>48.51</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the performance of different knowledge editing methods on the Llama 2-7B model using the zsRE dataset. The metrics evaluated include the Edit Score, Paraphrase Score, and Neighborhood Score, providing a comprehensive assessment of each method&rsquo;s effectiveness in modifying the model&rsquo;s factual knowledge.</p><details><summary>read the caption</summary>Table 13: Editing performance for Llama2-7B on zsre dataset</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A9.T14.1><tr class=ltx_tr id=A9.T14.1.1><td class="ltx_td ltx_align_left ltx_border_tt" id=A9.T14.1.1.1><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.1.1.1 style=font-size:90%>Model</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T14.1.1.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.1.2.1 style=font-size:90%>Method</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T14.1.1.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.1.3.1 style=font-size:90%><span class=ltx_text id=A9.T14.1.1.3.1.1></span> <span class=ltx_text id=A9.T14.1.1.3.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T14.1.1.3.1.2.1><span class=ltx_tr id=A9.T14.1.1.3.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.3.1.2.1.1.1>Edit</span></span>
<span class=ltx_tr id=A9.T14.1.1.3.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.3.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T14.1.1.3.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T14.1.1.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.1.4.1 style=font-size:90%><span class=ltx_text id=A9.T14.1.1.4.1.1></span> <span class=ltx_text id=A9.T14.1.1.4.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T14.1.1.4.1.2.1><span class=ltx_tr id=A9.T14.1.1.4.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.4.1.2.1.1.1>Paraphrase</span></span>
<span class=ltx_tr id=A9.T14.1.1.4.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.4.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T14.1.1.4.1.3></span></span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=A9.T14.1.1.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.1.5.1 style=font-size:90%><span class=ltx_text id=A9.T14.1.1.5.1.1></span> <span class=ltx_text id=A9.T14.1.1.5.1.2><span class="ltx_tabular ltx_align_middle" id=A9.T14.1.1.5.1.2.1><span class=ltx_tr id=A9.T14.1.1.5.1.2.1.1><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.5.1.2.1.1.1>Neighborhood</span></span>
<span class=ltx_tr id=A9.T14.1.1.5.1.2.1.2><span class="ltx_td ltx_nopad_r ltx_align_center" id=A9.T14.1.1.5.1.2.1.2.1>Score</span></span>
</span></span><span class=ltx_text id=A9.T14.1.1.5.1.3></span></span></td></tr><tr class=ltx_tr id=A9.T14.1.2><td class="ltx_td ltx_align_left ltx_border_t" id=A9.T14.1.2.1><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.2.1.1 style=font-size:90%>Llama3-8B</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T14.1.2.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.2.2.1 style=font-size:90%>EMMET</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T14.1.2.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.2.3.1 style=font-size:90%>96.97</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T14.1.2.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.2.4.1 style=font-size:90%>90.96</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=A9.T14.1.2.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.2.5.1 style=font-size:90%>45.26</span></td></tr><tr class=ltx_tr id=A9.T14.1.3><td class=ltx_td id=A9.T14.1.3.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.3.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.3.2.1 style=font-size:90%>EMMET+MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.3.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.3.3.1 style=font-size:90%>96.75</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.3.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.3.4.1 style=font-size:90%>91.31</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.3.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.3.5.1 style=font-size:90%>46.44</span></td></tr><tr class=ltx_tr id=A9.T14.1.4><td class=ltx_td id=A9.T14.1.4.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.4.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.4.2.1 style=font-size:90%>AlphaEdit</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.4.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.4.3.1 style=font-size:90%>89.27</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.4.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.4.4.1 style=font-size:90%>82.19</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.4.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.4.5.1 style=font-size:90%>45.23</span></td></tr><tr class=ltx_tr id=A9.T14.1.5><td class=ltx_td id=A9.T14.1.5.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.5.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.5.2.1 style=font-size:90%>AlphaEdit + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.5.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.5.3.1 style=font-size:90%>93.54</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.5.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.5.4.1 style=font-size:90%>85.93</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.5.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.5.5.1 style=font-size:90%>47.32</span></td></tr><tr class=ltx_tr id=A9.T14.1.6><td class=ltx_td id=A9.T14.1.6.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.6.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.6.2.1 style=font-size:90%>MEMIT</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.6.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.6.3.1 style=font-size:90%>96.45</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.6.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.6.4.1 style=font-size:90%>90.3</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.6.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.6.5.1 style=font-size:90%>48.91</span></td></tr><tr class=ltx_tr id=A9.T14.1.7><td class=ltx_td id=A9.T14.1.7.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.7.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.7.2.1 style=font-size:90%>MEMIT + MPES</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.7.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.7.3.1 style=font-size:90%>96.85</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.7.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.7.4.1 style=font-size:90%>90.76</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.7.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.7.5.1 style=font-size:90%>47.34</span></td></tr><tr class=ltx_tr id=A9.T14.1.8><td class=ltx_td id=A9.T14.1.8.1></td><td class="ltx_td ltx_align_center" id=A9.T14.1.8.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.8.2.1 style=font-size:90%>Norm-Constraint</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.8.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.8.3.1 style=font-size:90%>90.4</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.8.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.8.4.1 style=font-size:90%>84.58</span></td><td class="ltx_td ltx_align_center" id=A9.T14.1.8.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.8.5.1 style=font-size:90%>49.09</span></td></tr><tr class=ltx_tr id=A9.T14.1.9><td class="ltx_td ltx_border_bb" id=A9.T14.1.9.1></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T14.1.9.2><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.9.2.1 style=font-size:90%>ENCORE</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T14.1.9.3><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.9.3.1 style=font-size:90%>93.15</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T14.1.9.4><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.9.4.1 style=font-size:90%>86.19</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=A9.T14.1.9.5><span class="ltx_text ltx_font_smallcaps" id=A9.T14.1.9.5.1 style=font-size:90%>49.81</span></td></tr></table></table></figure><blockquote><p>üîº This table presents the performance of different knowledge editing methods on the Llama3-8B model using the zsRE dataset. It shows the efficacy (EDIT SCORE), generalization (PARAPHRASE SCORE), locality (NEIGHBORHOOD SCORE) and overall performance (OVERALL SCORE) of each method. The methods compared include EMMET, EMMET with MPES, AlphaEdit, AlphaEdit with MPES, MEMIT, MEMIT with MPES, MEMIT with norm constraint, and ENCORE. The scores are presented to allow for comparison and evaluation of the effectiveness of each technique in terms of accuracy, consistency, and potential interference with previously learned knowledge.</p><details><summary>read the caption</summary>Table 14: Editing performance for Llama3-8B on zsre dataset</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-b00d88d36c6d9b6c366ed72de27ebe08 class=gallery><img src=https://ai-paper-reviewer.com/2502.01636/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2502.01636/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/&amp;title=Lifelong%20Sequential%20Knowledge%20Editing%20without%20Model%20Degradation" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/&amp;text=Lifelong%20Sequential%20Knowledge%20Editing%20without%20Model%20Degradation" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01636/&amp;subject=Lifelong%20Sequential%20Knowledge%20Editing%20without%20Model%20Degradation" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2502.01636/index.md",oid_likes="likes_paper-reviews/2502.01636/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2502.01061/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-03T00:00:00+00:00>3 February 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2502.01105/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-02-03T00:00:00+00:00>3 February 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>