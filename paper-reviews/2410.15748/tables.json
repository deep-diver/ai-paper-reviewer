[{"figure_path": "2410.15748/tables/table_5_0.html", "caption": "Table 1: Templates for instructions designed to be executed in a Lean environment. We determine if a theorem is invocable by running the specific instruction.", "description": "This table shows the templates for instructions used to determine if a theorem is invocable within a Lean environment by executing specific instructions.", "section": "3 METHOD"}, {"figure_path": "2410.15748/tables/table_8_0.html", "caption": "Table 2: Number of theorems. Stage one: the number of invocable instructions for all candidate theorems. Stage two: the number of theorems that pass the verification of the Lean theorem prover.", "description": "Table 2 presents the number of theorems at different stages of the data synthesis pipeline, showing the expansion achieved by using each tactic (rw and apply) and their respective conversion ratios.", "section": "4.1 Implementation Details"}, {"figure_path": "2410.15748/tables/table_9_0.html", "caption": "Table 3: Results on Mathlib. tidy: a tactic in Mathlib that uses heuristics to complete a proof. We select the performance of each model solely fine-tuned using Mathlib-train as the main baseline. Mathlib-train + x: the performance of the model pre-trained and fine-tuned on a mixture of Mathlib-train and additional data about x.", "description": "Table 3 presents the results of the experiments on the Mathlib dataset, comparing the performance of different models with and without additional synthetic data.", "section": "4.3 Experimental Results"}, {"figure_path": "2410.15748/tables/table_10_0.html", "caption": "Table 4: Effectiveness of continual pre-training. We grouped the dataset for CPT and SFT by the tactic employed in the additional state-tactic pairs.", "description": "This table shows the effectiveness of continual pre-training on the performance of LLMs across diverse supervised fine-tuning settings, comparing models with and without the pre-training stage.", "section": "4.3.2 EFFECTIVENESS OF CONTINUAL PRETRAINING"}, {"figure_path": "2410.15748/tables/table_10_1.html", "caption": "Table 3: Results on Mathlib. tidy: a tactic in Mathlib that uses heuristics to complete a proof. We select the performance of each model solely fine-tuned using Mathlib-train as the main baseline. Mathlib-train + x: the performance of the model pre-trained and fine-tuned on a mixture of Mathlib-train and additional data about x.", "description": "Table 3 presents the performance comparison of different models on Mathlib benchmark, showing the impact of incorporating synthetic data generated using different tactics.", "section": "4 Experiments"}, {"figure_path": "2410.15748/tables/table_18_0.html", "caption": "Table 2: Number of theorems. Stage one: the number of invocable instructions for all candidate theorems. Stage two: the number of theorems that pass the verification of the Lean theorem prover.", "description": "Table 2 presents the number of theorems at different stages of the data synthesis pipeline, showing a significant increase in the number of theorems after verification.", "section": "4.1 Implementation Details"}, {"figure_path": "2410.15748/tables/table_25_0.html", "caption": "Table 2: Number of theorems. Stage one: the number of invocable instructions for all candidate theorems. Stage two: the number of theorems that pass the verification of the Lean theorem prover.", "description": "Table 2 presents the number of theorems at each stage of the data synthesis pipeline, showing a significant increase in the number of theorems after verification.", "section": "4.1 Implementation Details"}, {"figure_path": "2410.15748/tables/table_26_0.html", "caption": "Table 2: Number of theorems. Stage one: the number of invocable instructions for all candidate theorems. Stage two: the number of theorems that pass the verification of the Lean theorem prover.", "description": "Table 2 presents the number of theorems at different synthesis stages, showing a significant increase after verification by the Lean theorem prover.", "section": "4.1 Implementation Details"}, {"figure_path": "2410.15748/tables/table_28_0.html", "caption": "Table 3: Results on Mathlib. tidy: a tactic in Mathlib that uses heuristics to complete a proof. We select the performance of each model solely fine-tuned using Mathlib-train as the main baseline. Mathlib-train + x: the performance of the model pre-trained and fine-tuned on a mixture of Mathlib-train and additional data about x.", "description": "Table 3 presents the performance comparison of different methods on the Mathlib benchmark, highlighting the impact of using synthetic data for training.", "section": "4.3 Experimental Results"}, {"figure_path": "2410.15748/tables/table_28_1.html", "caption": "Table 3: Results on Mathlib. tidy: a tactic in Mathlib that uses heuristics to complete a proof. We select the performance of each model solely fine-tuned using Mathlib-train as the main baseline. Mathlib-train + x: the performance of the model pre-trained and fine-tuned on a mixture of Mathlib-train and additional data about x.", "description": "Table 3 presents the performance comparison of different LLMs on the Mathlib benchmark, showing the impact of using synthetic data generated by the proposed method.", "section": "4.3 Experimental Results"}]