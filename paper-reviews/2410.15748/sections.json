[{"page_end_idx": 1, "page_start_idx": 1, "section_number": 1, "section_title": "INTRODUCTION", "details": {"details": "The introduction section highlights the challenges and importance of Neural Theorem Proving (NTP).  It begins by noting the increasing trend among mathematicians to verify their work using proof assistants like Lean, emphasizing the complexity of formal proof writing. The section then introduces NTP as a method to automate this process, but points out its current limitations, primarily the scarcity of formal mathematical corpora available for training these neural models, compared to the abundance of general text data. This data scarcity is the central challenge addressed in the paper.  Existing efforts in NTP are mentioned, such as using Large Language Models (LLMs), but these also struggle with the reasoning capabilities needed for theorem proving. The introduction concludes by clearly stating that the core challenge lies in the lack of data and that the paper will address this through a novel method of synthetic data generation.", "first_cons": "The introduction doesn't elaborate on the specific limitations of current LLMs in theorem proving beyond mentioning their 'limitations in reasoning abilities'. A more detailed analysis of the shortcomings of existing methods would strengthen the justification for the proposed approach.", "first_pros": "The introduction effectively establishes the context and motivation for the research. It clearly identifies the core problem (data scarcity in NTP) and highlights the importance of addressing it.", "keypoints": ["The complexity of formal proof writing, motivating the need for automated approaches.", "The scarcity of formal mathematical data for training NTP models is a major bottleneck, with the existing corpora being limited compared to general text data.", "Existing methods, including those employing LLMs, struggle with the advanced reasoning required for theorem proving.", "The paper focuses on addressing the data scarcity problem through a novel framework for data synthesis, a key contribution."], "second_cons": "The introduction lacks a precise definition of 'Neural Theorem Proving' and does not offer any specific examples of existing successful or unsuccessful NTP models. Providing concrete examples would improve clarity and understanding.", "second_pros": "The introduction concisely summarizes the core challenge and the paper's main contribution. It successfully generates interest by highlighting the growing need and potential impact of effective automated theorem proving.", "summary": "This introduction highlights the challenges of writing formal mathematical proofs and introduces Neural Theorem Proving (NTP) as a solution. However, it points out that NTP is hampered by a lack of training data. The paper will introduce Alchemy, a method for synthesizing formal theorems to improve the capabilities of NTP."}}, {"page_end_idx": 3, "page_start_idx": 2, "section_number": 2, "section_title": "RELATED WORK", "details": {"details": "The related work section primarily focuses on reviewing existing research efforts in Neural Theorem Proving (NTP).  It highlights the challenges in NTP, particularly the scarcity of formal mathematical data available for training models. Several approaches are mentioned, including those that leverage large language models (LLMs) for proof generation (Polu & Sutskever, 2020; Polu et al., 2023; Trinh et al., 2024), and others that explore automatic formalization (Xin et al., 2024; Ying et al., 2024) by translating natural language problems into formal statements.  The section also notes the difficulties in manually formalizing theorems and the associated scarcity of data, contrasted with the relative abundance of general text data. The review concludes by comparing the data synthesis approach proposed in the current paper with existing autoformalization techniques, highlighting that the current approach leverages the power of the Lean theorem prover to directly synthesize theorems in the symbolic space which is more scalable and cost-effective than autoformalization.", "first_cons": "The review is somewhat brief and lacks in-depth analysis of the strengths and weaknesses of each individual cited work.", "first_pros": "The section clearly establishes the context and problem setting for the paper, emphasizing the significant challenge of data scarcity in Neural Theorem Proving.", "keypoints": ["Data scarcity is a significant challenge in Neural Theorem Proving (NTP).", "Existing approaches focus on LLMs for proof generation and autoformalization.", "Autoformalization is labor-intensive and cost-prohibitive.", "Data synthesis in symbolic space offers a more direct and scalable approach compared to autoformalization.", "The paper's approach leverages the Lean theorem prover to synthesize theorems directly in symbolic space, contrasting with previous autoformalization-based methods which translate natural language problems into formal statements before proving them.."], "second_cons": "The comparison of the proposed data synthesis approach with existing methods is superficial and does not provide a comprehensive evaluation.", "second_pros": "The comparison between the proposed symbolic theorem synthesis and the autoformalization approach effectively positions the paper's contribution within the existing research landscape.", "summary": "This section reviews existing Neural Theorem Proving (NTP) research, highlighting the problem of data scarcity and describing previous approaches which primarily focus on either using LLMs for proof generation or autoformalization techniques. It positions the current work's novel data synthesis technique\u2014generating theorems in the symbolic space using the Lean prover\u2014as a more scalable and efficient alternative to existing methods which are limited by data scarcity and the cost of manual formalization."}}, {"page_end_idx": 6, "page_start_idx": 4, "section_number": 3, "section_title": "METHOD", "details": {"details": "The core of the method section lies in generating new Lean theorems.  This process begins with identifying \"invocable theorems\" from the Lean Mathlib4 library (initially containing 110,000 theorems). These are existing theorems that can be used to symbolically mutate a candidate theorem.  The core of the process is done by using two Lean tactics, `rw` (rewrite) and `apply`, which are used to symbolically manipulate the candidate theorem's statement (function declaration) and its proof (function body). The `rw` tactic replaces parts of the statement with equivalent expressions.  The `apply` tactic uses an implication to simplify the proof goal.  This generates a new, mutated theorem.  The system then generates the proof for the mutated theorem (a process which leverages the original proof) and verifies the new theorem's correctness using Lean. The entire process aims to augment the Mathlib dataset by a substantial amount, expanding the number of theorems from approximately 110k to 6 million.  The augmented dataset, including the generated state-tactic pairs, is subsequently used to pre-train and fine-tune large language models (LLMs).", "first_cons": "The method heavily relies on the Leandojo tool, which has limitations such as being memory-intensive, not supporting multiprocessing effectively, and requiring data uploading to GitHub. These limitations pose significant challenges to scalability and efficiency.", "first_pros": "The method directly synthesizes theorems in the symbolic space using Lean tactics (rw and apply), thus avoiding intermediate translation steps and enabling cost-effective CPU-based scaling.", "keypoints": ["The method increases the number of theorems in Mathlib by an order of magnitude, from 110k to 6M.", "It uses two Lean tactics, `rw` and `apply`, for symbolic manipulation, creating new theorems and associated proofs.", "The process includes verifying the correctness of each newly synthesized theorem using Lean.", "The augmented dataset is used for continual pretraining and supervised fine-tuning of LLMs."], "second_cons": "The complexity of the algorithm, especially the step of finding invocable theorems, has a time complexity of O(n^2). The construction of the proof for mutated theorems also relies on heuristic rules rather than purely formal methods.", "second_pros": "The generated synthetic data significantly improves LLMs' theorem-proving performance, achieving around a 5% absolute improvement on the Leandojo benchmark and a 2.5% improvement on the miniF2F benchmark.", "summary": "This method section details a novel approach for augmenting theorem-proving datasets by constructing formal theorems through symbolic mutation using Lean's `rw` and `apply` tactics.  The process involves identifying invocable theorems, mutating candidate theorems, generating proofs for the mutated theorems, and verifying their correctness in Lean. This method substantially expands the Lean Mathlib4 dataset, leading to a significant improvement in the performance of large language models (LLMs) for theorem proving tasks."}}, {"page_end_idx": 8, "page_start_idx": 7, "section_number": 4, "section_title": "EXPERIMENTS", "details": {"details": "The experiments section in the paper evaluates the effectiveness of the proposed data synthesis method for improving the performance of Large Language Models (LLMs) in theorem proving.  Two widely-used benchmarks are employed: the held-out test split of Mathlib (in-distribution) and miniF2F (out-of-distribution).  The data synthesis pipeline significantly increased the number of theorems in Mathlib, from 110k to 6M.  The LLMs are continually pre-trained and then fine-tuned using a mixture of human-written and synthetic theorems and state-tactic pairs.  The results show that the synthetic data improve the performance on both benchmarks.  Specifically, a 5% absolute improvement is achieved on the Leandojo benchmark (novel_premises split), and a 2.5% absolute improvement on the miniF2F benchmark.  The analysis of the synthetic data composition and training paradigm provides valuable insights into the development of strong theorem provers.  A detailed analysis of the data synthesis process is provided, including the number of theorems generated for each tactic (rw and apply) and their distribution across various mathematical subjects. The study also examines the effects of continual pre-training and different quantities of synthetic data on the LLM's performance, revealing that continual pre-training before fine-tuning is beneficial.  The effectiveness of different tactics is explored, and a combination of rw and apply tactics yields the best results, outperforming the use of either tactic alone.", "first_cons": "The data synthesis process is computationally expensive, taking several days to complete on large CPU clusters, which may pose a barrier to broader adoption.", "first_pros": "The proposed data synthesis method significantly improves the performance of LLMs in theorem proving, showing a 5% absolute improvement on the Leandojo benchmark's novel premises split and a 2.5% absolute improvement on the miniF2F benchmark.", "keypoints": ["Significant increase in the number of theorems in Mathlib (from 110k to 6M) using the data synthesis pipeline.", "5% absolute performance improvement on the Leandojo benchmark (novel premises split).", "2.5% absolute performance improvement on the miniF2F benchmark.", "Continual pre-training before fine-tuning enhances LLM performance.", "Combination of rw and apply tactics yields the best results, outperforming the use of either tactic alone.", "Comprehensive analysis of synthetic data composition and training paradigms provides valuable insights for developing robust theorem provers."], "second_cons": "The reliance on Leandojo, a specific tool with limitations like memory intensiveness and lack of native support for tracing local Lean repositories, may restrict the generalizability of the method.", "second_pros": "The study uses two established benchmarks, Mathlib and miniF2F, making the results more reliable and comparable to other work in the field.", "summary": "This experiment section evaluates a data synthesis method to boost the performance of LLMs in theorem proving.  Using the Mathlib and miniF2F benchmarks, the results show that the method significantly expands the dataset (110k to 6M theorems) and improves the LLMs' performance by 5% (Leandojo, novel premises) and 2.5% (miniF2F), highlighting the value of synthetic data.  The analysis reveals that continual pre-training and combining the rw and apply tactics are beneficial. However, the computational cost of the data synthesis process remains a limitation."}}]