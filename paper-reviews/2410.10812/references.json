{"references": [{" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is foundational to the field of diffusion models, which are a key point of comparison for the new autoregressive model presented in the paper.  Understanding the strengths and limitations of diffusion models is crucial for evaluating the novel approach proposed here. The impact of diffusion models on image generation is significant, and this paper is highly cited in the field, making it a critical reference for context and comparison.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This is a highly influential paper in the field of diffusion models, establishing a state-of-the-art approach for image synthesis. The paper's method and results are directly relevant to the work presented in this paper, serving as a primary benchmark for comparison.  The high-resolution image generation capabilities of this model are of particular significance as the current paper attempts to achieve comparable quality using an autoregressive approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "This paper proposes DiT-XL/2, a highly efficient diffusion model that serves as a key point of comparison in terms of computational efficiency. The paper demonstrates significant improvements in efficiency, which is a crucial aspect of the current paper's focus on developing a fast autoregressive model.  The results are used directly to compare the performance of autoregressive and diffusion models.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Tianhong Li", "paper_title": "Text-to-image generation with 1-shape block parallel decoding", "reason": "This is a very recent, highly relevant paper to the current work, also focusing on visual generation using an autoregressive approach.  The paper proposes a novel architecture aiming for efficiency, directly addressing a key limitation of previous autoregressive models that this paper aims to improve upon.  Comparing and contrasting both approaches offers valuable insight into the relative merits of different strategies.", "section_number": 1}, {" publication_date": "2017", "fullname_first_author": "Aaron Van Den Oord", "paper_title": "Neural discrete representation learning", "reason": "This paper introduces Vector Quantized Variational Autoencoders (VQVAE), a fundamental technique used in many autoregressive image generation models, including the one presented in this paper. VQ is a cornerstone of many of the techniques explored in this field.  The paper serves to provide a theoretical understanding of the methods used in the current work.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Haotian Tang", "paper_title": "Hybrid Autoregressive Transformer", "reason": "This is the current paper introducing a novel hybrid autoregressive model. The paper presents a detailed architecture, methodology, and analysis of a new method for image generation.  It combines autoregressive and diffusion models and presents the methods, results, and analyses of this approach.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Tianhong Li", "paper_title": "Autoregressive image generation without vector quantization", "reason": "This recent paper presents a novel autoregressive model (VAR) that is used as a baseline for comparison in this paper. The architecture and results of VAR are crucial for understanding the context and advancements achieved in the current work, serving as the starting point for the development and improvements presented in this study.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Dustin Podell", "paper_title": "SDXL: Improving latent diffusion models for high-resolution image synthesis", "reason": "This paper introduces SDXL, a state-of-the-art diffusion model used as a primary benchmark for comparison in terms of image quality.  The high-resolution image generation capabilities of this model are directly relevant as the current paper aims to match or exceed this performance using a different (autoregressive) approach.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Junsong Chen", "paper_title": "PixArt-\u03a3: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "This paper presents PixArt-\u03a3, a state-of-the-art diffusion model used as a key benchmark for comparison.  The results of this model are directly compared to this paper's proposed model for performance evaluation and demonstrate how the proposed approach performs relative to top-performing methods.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Daiqing Li", "paper_title": "Playground v2.5: Three insights towards enhancing aesthetic quality in text-to-image generation", "reason": "This paper presents Playground v2.5, a state-of-the-art diffusion model that serves as a key benchmark.  It's directly compared to the proposed approach for quantitative performance evaluation and demonstrates the relative strengths of the new method compared to existing best practices in visual generation.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "reason": "This paper is a foundational work in using transformers for high-resolution image synthesis.  The techniques and findings presented here are highly relevant to the current work's goal of developing an efficient high-resolution image generation model using autoregressive techniques.  The comparison helps to highlight the improvements achieved using the novel approach.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Junsong Chen", "paper_title": "PixArt-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "This is a recent paper that introduces PixArt-alpha, another state-of-the-art diffusion model used as a benchmark for comparison.  The results of this model help to provide a complete picture of how the performance of the new approach compares to top-performing techniques in image generation.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Minguk Kang", "paper_title": "Scaling up GANs for text-to-image synthesis", "reason": "This recent paper explores using GANs for high-quality text-to-image generation, providing a different approach to the problem being addressed in the main paper.  Including this paper highlights that there is a broader consideration of different model types.  The inclusion helps to provide a more complete context and comparison with existing state-of-the-art techniques.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is fundamental to the field of diffusion models, providing the theoretical foundation and a baseline for comparison of the novel autoregressive approach.  The understanding of diffusion models is critical for evaluating the contributions of the new approach presented in this paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat GANs on image synthesis", "reason": "This influential paper demonstrates the state-of-the-art performance of diffusion models in image generation, providing a strong benchmark for comparison of the proposed autoregressive approach.  The success of diffusion models is of particular relevance as the current paper seeks to achieve comparable performance using a different methodology.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This paper is another highly influential work in the field of diffusion models, showcasing a significant advancement in the quality and resolution of generated images. The paper's results and methodology provide a key benchmark for comparison with the autoregressive approach, illustrating the potential of this method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Junsong Chen", "paper_title": "Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "This paper introduces PixArt-alpha, a highly efficient diffusion model that is relevant to the current paper's focus on efficiency. The paper demonstrates a significant advancement in training speed, which is directly compared against in this paper.  The results help to show how the novel model improves in efficiency and provides a basis for comparison.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Tianhong Li", "paper_title": "Autoregressive image generation without vector quantization", "reason": "This paper is a very recent, highly relevant work, presenting a novel autoregressive model (VAR) that is directly compared to this paper's proposed model. VAR is used as a baseline model in this paper, therefore, understanding VAR is crucial for fully appreciating the contributions made in the current work. It's a close relative of the work described here.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Lijun Yu", "paper_title": "Language model beats diffusion-tokenizer is key to visual generation", "reason": "This very recent paper explores using language models for visual generation, offering a different yet relevant approach to the problem. The paper's findings provide additional context and insights into the relative strengths and weaknesses of different approaches. It provides a comparable approach to the current paper.", "section_number": 3}]}