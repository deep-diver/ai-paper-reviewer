[{"figure_path": "2410.16251/charts/charts_5_0.png", "caption": "Figure 3: Efficacy Scores of Knowledge Editing Methods. The \"overall\" refers to the Efficacy Score (%) on the whole HalluEditBench embracing 9 domains for different methods. The Efficacy Score on each domain is also reported. Efficacy scores (%) are measured by the accuracy on Efficacy Evaluation Question-answer Pairs, where the pre-edit scores of each LLM are ensured 0.", "description": "The chart displays the efficacy scores of different knowledge editing methods across nine domains and three large language models (LLMs).", "section": "3 RESULTS AND ANALYSIS"}, {"figure_path": "2410.16251/charts/charts_6_0.png", "caption": "Figure 4: Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (\"rephrase\"), Yes-or-No Questions with Yes or No as answers (\"yes\" or \"no\"), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to averaged scores over five question types. The figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in Appendix D.1.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across five question types for three LLMs.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_7_0.png", "caption": "Figure 13: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when with N hops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The domains include \u201cbusiness\u201d, \u201centertainment", "description": "The chart displays the Portability scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) and three domains (business, entertainment, event) with varying hop distances.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_8_0.png", "caption": "Figure 3: Efficacy Scores of Knowledge Editing Methods. The \"overall\" refers to the Efficacy Score (%) on the whole HalluEditBench embracing 9 domains for different methods. The Efficacy Score on each domain is also reported. Efficacy scores (%) are measured by the accuracy on Efficacy Evaluation Question-answer Pairs, where the pre-edit scores of each LLM are ensured 0.", "description": "The chart displays the efficacy scores of various knowledge editing methods across different domains and LLMs in correcting real-world hallucinations.", "section": "3 RESULTS AND ANALYSIS"}, {"figure_path": "2410.16251/charts/charts_9_0.png", "caption": "Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions with M turns (M = 1 ~ 10). We regard Efficacy Scores as the Robustness Scores when M is 0. The domains include \"geography\", \"health\", and \"technology\".", "description": "The chart displays the robustness scores of seven knowledge editing methods across three large language models (LLMs) and three domains, showing the accuracy of the methods against distractions in prompts over ten turns.", "section": "3.5 FACET 5: ROBUSTNESS"}, {"figure_path": "2410.16251/charts/charts_22_0.png", "caption": "Figure 4: Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (\"rephrase\"), Yes-or-No Questions with Yes or No as answers (\"yes\" or \"no\"), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to averaged scores over five question types. The figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in Appendix D.1.", "description": "The chart displays the Generalization scores of different knowledge editing methods across various question types for three different LLMs.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_23_0.png", "caption": "Figure 4: Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (\"rephrase\"), Yes-or-No Questions with Yes or No as answers (\"yes\" or \"no\"), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to averaged scores over five question types. The figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in Appendix D.1.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across five question types for three LLMs on the HalluEditBench dataset.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_23_1.png", "caption": "Figure 4: Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (\"rephrase\"), Yes-or-No Questions with Yes or No as answers (\"yes\" or \"no\"), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to averaged scores over five question types. The figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in Appendix D.1.", "description": "The chart displays the Generalization Scores of various knowledge editing methods across five question types for three different LLMs.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_23_2.png", "caption": "Figure 10: Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (\u201crephrase\u201d), two types of Yes-or-No Questions with Yes or No as answers (\u201cyes\u201d or \u201cno\u201d), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to the averaged scores over five types of questions. The domains include \u201centertainment\u201d and \u201cevent\u201d.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) for two domains (entertainment and event), showing the accuracy of each method on various question types.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_23_3.png", "caption": "Figure 4: Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (\"rephrase\"), Yes-or-No Questions with Yes or No as answers (\"yes\" or \"no\"), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to averaged scores over five question types. The figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in Appendix D.1.", "description": "The chart displays the generalization scores of various knowledge editing methods across five different question types, showing their ability to generalize to different question phrasings.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_23_4.png", "caption": "Figure 10: Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (\u201crephrase\u201d), two types of Yes-or-No Questions with Yes or No as answers (\u201cyes\u201d or \u201cno\u201d), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to the averaged scores over five types of questions. The domains include \u201centertainment\u201d and \u201cevent\u201d.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) and two domains (entertainment, event).", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_24_0.png", "caption": "Figure 10: Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (\u201crephrase\u201d), two types of Yes-or-No Questions with Yes or No as answers (\u201cyes\u201d or \u201cno\u201d), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to the averaged scores over five types of questions. The domains include \u201centertainment\u201d and \u201cevent\u201d.", "description": "The chart displays the Generalization scores for different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) and two domains (entertainment, event) using five different question types.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_25_0.png", "caption": "Figure 12: Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (\u201crephrase\u201d), two types of Yes-or-No Questions with Yes or No as answers (\u201cyes\u201d or \u201cno\u201d), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to the averaged scores over five types of questions. The domain is \u201ctechnology\u201d.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) and two domains (geography and health) based on five types of evaluation questions.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_26_0.png", "caption": "Figure 12: Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (\u201crephrase\u201d), two types of Yes-or-No Questions with Yes or No as answers (\u201cyes\u201d or \u201cno\u201d), Multi-Choice Questions (\u201cmc\u201d), Reversed Questions (\u201creversed\u201d). The \u201caverage\u201d refers to the averaged scores over five types of questions. The domain is \u201ctechnology\u201d.", "description": "The chart displays the Generalization Scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) for the \"technology\" domain, broken down by five question types.", "section": "3.2 FACET 2: GENERALIZATION"}, {"figure_path": "2410.16251/charts/charts_27_0.png", "caption": "Figure 13: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when with N hops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The domains include \u201cbusiness\u201d, \u201centertainment", "description": "The chart displays the portability scores of various knowledge editing methods across three large language models (LLMs) and three domains, showing the accuracy of the methods on multi-hop questions.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_28_0.png", "caption": "Figure 13: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when with N hops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The domains include \u201cbusiness\u201d, \u201centertainment\u201d, and \u201cevent\u201d.", "description": "The chart displays the portability scores of different knowledge editing methods across three LLMs and three domains, illustrating their ability to reason across multiple hops of knowledge.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_29_0.png", "caption": "Figure 15: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when with N hops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The domain is \u201cart\u201d.", "description": "The chart displays the portability scores of different knowledge editing methods across various hop distances for Llama2-7B, Llama3-8B, and Mistral-v0.3-7B on the art domain.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_29_1.png", "caption": "Figure 5: Portability Scores of Knowledge Editing Methods. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions with N hops (N = 1 ~ 6). The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The results for more domains are given in Appendix D.2. The \u201coverall\u201d refers to the Portability Score (%) on the whole HalluEditBench embracing 9 domains.", "description": "The chart displays the portability scores of various knowledge editing methods across different hop distances (1-6) for Llama3-8B on the 'art' domain, illustrating the ability of these methods to reason about edited knowledge in downstream tasks.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_29_2.png", "caption": "Figure 15: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when with N hops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions when N is 1. The domain is \u201cart\u201d.", "description": "The chart displays the portability scores of various knowledge editing methods across different hop distances (1-6) for the Mistral-v0.3-7B model on the \u2018art\u2019 domain.", "section": "3.3 FACET 3: PORTABILITY"}, {"figure_path": "2410.16251/charts/charts_30_0.png", "caption": "Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions with M turns (M = 1 ~ 10). We regard Efficacy Scores as the Robustness Scores when M is 0. The domains include \u201cgeography\u201d, \u201chealth\u201d, and \u201ctechnology\u201d.", "description": "The chart displays the robustness scores of seven knowledge editing methods across three large language models (LLMs) and three domains, showing the persistence of edited knowledge under various levels of distraction.", "section": "3.5 FACET 5: ROBUSTNESS"}, {"figure_path": "2410.16251/charts/charts_31_0.png", "caption": "Figure 3: Efficacy Scores of Knowledge Editing Methods. The \"overall\" refers to the Efficacy Score (%) on the whole HalluEditBench embracing 9 domains for different methods. The Efficacy Score on each domain is also reported. Efficacy scores (%) are measured by the accuracy on Efficacy Evaluation Question-answer Pairs, where the pre-edit scores of each LLM are ensured 0.", "description": "The chart displays the efficacy scores of various knowledge editing methods across different domains and LLMs, showing their effectiveness in correcting hallucinations.", "section": "3.1 FACET 1: EFFICACY"}, {"figure_path": "2410.16251/charts/charts_32_0.png", "caption": "Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions with M turns (M = 1 ~ 10). We regard Efficacy Scores as the Robustness Scores when M is 0. The domains include \"geography\", \"health\", and \"technology\".", "description": "The chart displays the robustness scores of various knowledge editing methods across three different LLMs and three domains, showing the percentage of times the LLMs maintained the corrected answers even after being prompted with distracting questions.", "section": "3.5 FACET 5: ROBUSTNESS"}, {"figure_path": "2410.16251/charts/charts_32_1.png", "caption": "Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions with M turns (M = 1 ~ 10). We regard Efficacy Scores as the Robustness Scores when M is 0. The domains include \"geography\", \"health\", and \"technology\".", "description": "The chart displays the robustness scores of different knowledge editing methods across three LLMs and three domains, showing the percentage of \"yes\" responses over ten turns of robustness evaluation questions.", "section": "3.5 FACET 5: ROBUSTNESS"}, {"figure_path": "2410.16251/charts/charts_32_2.png", "caption": "Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions with M turns (M = 1 ~ 10). We regard Efficacy Scores as the Robustness Scores when M is 0. The domains include \"geography\", \"health\", and \"technology\".", "description": "The chart displays the robustness scores of different knowledge editing methods across three LLMs (Llama2-7B, Llama3-8B, Mistral-v0.3-7B) and three domains (geography, health, technology) over ten turns.", "section": "3.5 FACET 5: ROBUSTNESS"}]