[{"figure_path": "2410.16251/tables/table_1_0.md", "caption": "Table 1: Performance measured by Accuracy (%) of Llama2-7B before editing (\u201cPre-edit\u201d) and after applying typical knowledge editing methods (\u201cPost-edit\u201d) on common existing evaluation datasets.", "description": "This table presents the accuracy of Llama2-7B in answering questions before and after applying different knowledge editing methods on three established evaluation datasets: WikiDataRecent, ZsRE, and WikiBio.  The \"Pre-edit\" row shows the baseline accuracy before any editing. Subsequent rows, labeled with the names of specific knowledge editing techniques (ROME, MEMIT, FT-L, FT-M, LoRA), indicate the accuracy achieved after applying each method.  The results highlight the effectiveness of various editing methods in improving accuracy, showcasing the potential of knowledge editing for enhancing LLM performance. Note that the high post-edit accuracy on these datasets may not always reflect the true effectiveness in correcting real-world hallucinations.", "section": "1 INTRODUCTION"}]