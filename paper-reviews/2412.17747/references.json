{"references": [{"fullname_first_author": "J. Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-XX-XX", "reason": "This paper is foundational to the current work, introducing the concept of chain-of-thought prompting, which is a key technique used in the current paper's approach to improve reasoning in LLMs."}, {"fullname_first_author": "T. Kojima", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-XX-XX", "reason": "This paper demonstrates the surprising ability of LLMs to perform zero-shot reasoning, which is directly relevant to the current paper's goal of enhancing LLM reasoning capabilities."}, {"fullname_first_author": "A. Goyal", "paper_title": "Recurrent independent mechanisms", "publication_date": "2021-XX-XX", "reason": "This paper introduces the concept of recurrent independent mechanisms, which provides a framework for improving the efficiency of LLMs by allowing them to allocate compute resources adaptively during generation."}, {"fullname_first_author": "E. Zelikman", "paper_title": "Star: Bootstrapping reasoning with reasoning", "publication_date": "2022-XX-XX", "reason": "This paper explores methods for improving LLM reasoning abilities by bootstrapping the reasoning process, which is closely related to the current paper's approach."}, {"fullname_first_author": "S. Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "publication_date": "2024-XX-XX", "reason": "This paper proposes a novel method for improving LLM reasoning by generating a tree of thoughts, which is a more structured and comprehensive approach than the methods presented in the current paper."}]}