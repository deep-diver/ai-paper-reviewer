{"references": [{" publication_date": "2024", "fullname_first_author": "Antonio Alliegro", "paper_title": "Polydiff: Generating 3d polygonal meshes with diffusion models", "reason": "This paper is highly relevant because it explores the use of diffusion models for generating 3D polygonal meshes, which is a closely related task to the goal of DynamicCity (generating 4D LiDAR scenes).  The techniques and insights from this paper on 3D object generation using diffusion models can potentially be applied or adapted to improve the methods used in DynamicCity.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Sherwin Bahmani", "paper_title": "Tc4d: Trajectory-conditioned text-to-4d generation", "reason": "This paper directly addresses 4D generation, a key focus of DynamicCity.  Its trajectory-conditioned approach is relevant to DynamicCity\u2019s aim of generating dynamic scenes that capture temporal evolution. The techniques used in TC4D's trajectory conditioning could provide valuable insights and possible improvements to DynamicCity\u2019s methods for handling temporal dynamics.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Maxim Berman", "paper_title": "The lov\u00e1sz-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks", "reason": "This paper is crucial because DynamicCity uses a combination of loss functions for training its VAE. The Lov\u00e1sz-softmax loss is specifically chosen for its ability to better handle class imbalance.  Understanding this loss function is essential for reproducing and interpreting DynamicCity\u2019s results.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This work focuses on high-resolution video synthesis using latent diffusion models, which is a related task to the 4D LiDAR scene generation tackled by DynamicCity.  The insights and techniques from this paper, particularly those related to handling high-resolution data and temporal consistency, could be valuable for improving DynamicCity.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Lucas Caccia", "paper_title": "Deep generative modeling of lidar data", "reason": "This is an early but important work on LiDAR scene generation.  It provides a foundational understanding of the challenges and early approaches used in this area, which helps contextualize the advancements made by DynamicCity. This paper\u2019s methods, while older, provide a necessary baseline to evaluate the progress in the field.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Holger Caesar", "paper_title": "nuscenes: A multimodal dataset for autonomous driving", "reason": "DynamicCity uses the nuScenes dataset for evaluation.  Understanding this dataset is crucial to interpreting and comparing DynamicCity's results, and the paper provides the details of the dataset's composition, making it an essential reference for understanding the context of the experiments.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Ang Cao", "paper_title": "Hexplane: A fast representation for dynamic scenes", "reason": "This paper introduces the HexPlane representation, which is a core component of DynamicCity.  HexPlane\u2019s design, efficiency, and suitability for representing dynamic 3D scenes are critical to understanding and evaluating DynamicCity's methodology and results.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Eric R Chan", "paper_title": "Efficient geometry-aware 3d generative adversarial networks", "reason": "This paper is relevant as DynamicCity focuses on generating large-scale 3D scenes, which this paper also addresses.  The techniques used in this paper for generating 3D scenes, especially using geometry-aware methods, provide context and potential alternative approaches that DynamicCity could learn from or compare against.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Christopher Choy", "paper_title": "4d spatio-temporal convnets: Minkowski convolutional neural networks", "reason": "This paper introduces Minkowski Convolutional Neural Networks, a method for processing 4D spatio-temporal data.  Since DynamicCity deals with 4D LiDAR data, understanding Minkowski ConvNets is relevant for comparing and contrasting the approaches DynamicCity uses for processing 4D data.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Tri Dao", "paper_title": "Flashattention: Fast and memory-efficient exact attention with io-awareness", "reason": "DynamicCity uses FlashAttention for faster training and reduced memory usage.  This paper is critical for understanding the implementation details and optimization strategies employed by DynamicCity to enhance the efficiency of its model.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Sara Fridovich-Keil", "paper_title": "K-planes: Explicit radiance fields in space, time, and appearance", "reason": "This paper addresses the related task of representing spatiotemporal data using a structured approach. This is relevant because DynamicCity also uses a structured representation (HexPlane) for efficient handling of 4D LiDAR data. Understanding K-Planes can provide useful insights for comparing and improving DynamicCity's representation methods.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "reason": "DynamicCity uses Classifier-Free Guidance (CFG) for conditional generation.  This paper is fundamental to understanding how CFG works and its impact on the performance of the model.  It is essential for reproducing and understanding DynamicCity's conditional generation capabilities.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Siyuan Huang", "paper_title": "Spatio-temporal self-supervised representation learning for 3d point clouds", "reason": "This work is related to DynamicCity's approach as it deals with spatio-temporal representation learning for 3D point clouds. DynamicCity addresses a similar problem but in the context of 4D LiDAR data. This paper provides a related context and potential comparison points for the techniques used in DynamicCity.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jumin Lee", "paper_title": "Semcity: Semantic scene generation with triplane diffusion", "reason": "SemCity is compared directly against DynamicCity in the experiments.  Understanding SemCity\u2019s methodology is critical for evaluating the relative performance and contributions of DynamicCity. The comparison highlights the advantages of DynamicCity over existing approaches.", "section_number": 5}, {" publication_date": "2023a", "fullname_first_author": "Yuheng Liu", "paper_title": "Pyramid diffusion for fine 3d large scene generation", "reason": "This paper is relevant because it tackles the generation of large-scale 3D scenes using a diffusion model, which is related to DynamicCity's goal of generating large-scale 4D LiDAR scenes.  Understanding its approach and limitations helps in evaluating the novelty and contributions of DynamicCity.", "section_number": 2}, {" publication_date": "2023b", "fullname_first_author": "Zhen Liu", "paper_title": "Meshdiffusion: Score-based generative 3d mesh modeling", "reason": "This paper explores score-based diffusion models for 3D mesh generation, a closely related field to the 4D LiDAR generation addressed by DynamicCity.  The techniques and findings of this paper can offer valuable insights and potential improvements for DynamicCity\u2019s methods for generating and processing 3D structures.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kazuto Nakashima", "paper_title": "Lidar data synthesis with denoising diffusion probabilistic models", "reason": "This paper is highly relevant because it directly tackles LiDAR scene generation using diffusion probabilistic models, which is the core approach used in DynamicCity. The comparison between this method and DynamicCity's approach provides a strong benchmark for evaluating DynamicCity's contribution.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Lucas Nunes", "paper_title": "Scaling diffusion models to real-world 3d lidar scene completion", "reason": "This paper focuses on scaling diffusion models for real-world 3D LiDAR scene completion, a closely related task to DynamicCity\u2019s goal of generating 4D LiDAR scenes.  The challenges and solutions presented in this paper provide important context and potential insights for improving DynamicCity\u2019s scalability and performance.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "DynamicCity uses Diffusion Transformers (DiT) for scene generation. This paper introduces the DiT architecture, which is a fundamental component of DynamicCity.  A deep understanding of DiT is essential for interpreting and analyzing the results of DynamicCity.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This paper is highly influential because it details the technique of high-resolution image synthesis using latent diffusion models, a technique highly relevant to DynamicCity\u2019s approach to generating high-quality 4D LiDAR scenes.  The methods for achieving high-resolution outputs could be adapted or improved upon for DynamicCity.", "section_number": 2}]}