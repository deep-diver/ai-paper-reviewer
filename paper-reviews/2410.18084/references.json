{"references": [{" publication_date": "2024", "fullname_first_author": "Antonio Alliegro", "paper_title": "Polydiff: Generating 3d polygonal meshes with diffusion models", "reason": "This paper is highly relevant due to its focus on diffusion models for 3D object generation, which is a closely related area to LiDAR scene generation.  Understanding advancements in diffusion models for object generation is crucial for informing and advancing techniques in LiDAR scene generation, which shares many technical challenges and opportunities.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Sherwin Bahmani", "paper_title": "Tc4d: Trajectory-conditioned text-to-4d generation", "reason": "This paper directly addresses the challenge of 4D generation, making it highly relevant to the topic of the paper. Its focus on trajectory conditioning is especially significant since it highlights a key application area and provides a point of comparison for the methods proposed in this paper. It is a recent, state-of-the-art approach making it important for comparison.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Maxim Berman", "paper_title": "The lov\u00e1sz-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks", "reason": "This paper introduces a loss function that improves the performance of neural networks, a technique used in the current paper. The method of improving loss is highly relevant for improving the performance of the model.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This paper tackles the problem of high-resolution video synthesis using latent diffusion models, providing insights into how to handle temporal data and high-resolution outputs in generative models.  This is directly applicable to the challenges faced in generating high-quality, long-sequence 4D LiDAR scenes.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Lucas Caccia", "paper_title": "Deep generative modeling of lidar data", "reason": "This paper is significant because it represents an early attempt at LiDAR scene generation.  It highlights the challenges and the early approaches taken which serves as a background to understand the evolution of the field.  Analyzing the shortcomings of early methods is important to fully appreciate the advancement made in this paper.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Holger Caesar", "paper_title": "nuscenes: A multimodal dataset for autonomous driving", "reason": "This paper introduces a widely used dataset for autonomous driving research, namely nuScenes.  The dataset is directly relevant to the current paper because it provides a real-world benchmark for evaluating the performance of 4D LiDAR scene generation models. The use of this dataset allows the model to be benchmarked against real-world data.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Ang Cao", "paper_title": "Hexplane: A fast representation for dynamic scenes", "reason": "This paper is highly relevant since the current paper builds upon the HexPlane representation for dynamic scenes. It introduces a novel representation method, HexPlane, which is adopted and improved in the work for efficient 4D encoding. The use of HexPlane is a key component of the model.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Eric R Chan", "paper_title": "Efficient geometry-aware 3d generative adversarial networks", "reason": "This paper is relevant due to its focus on generating 3D data using GANs, demonstrating methods to work with 3D data efficiently. This is important because LiDAR data is 3D and understanding how to handle 3D data is relevant to the current work. While it doesn't use diffusion models, it deals with challenges in generating realistic 3D structures, thus offering valuable insights.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Christopher Choy", "paper_title": "4d spatio-temporal convnets: Minkowski convolutional neural networks", "reason": "This paper introduces Minkowski Convolutional Neural Networks (MCNNs), a powerful technique for processing spatio-temporal data.  While not directly used in the proposed method, the ideas behind MCNNs and the challenges of spatio-temporal processing are relevant to understanding the complexities addressed in the current work. It is highly relevant to the paper's handling of 4D data.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Sara Fridovich-Keil", "paper_title": "K-planes: Explicit radiance fields in space, time, and appearance", "reason": "This paper introduces K-Planes, another 4D scene representation.  Since the current work uses HexPlanes, understanding other approaches to representing 4D scenes is essential. K-Planes offer an alternative perspective that helps the reader understand the broader landscape of 4D scene representation techniques and appreciate the choices made in the paper.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "reason": "This paper is highly relevant because it introduces Classifier-Free Guidance (CFG), a technique used to enhance the performance of diffusion models by controlling the balance between diversity and accuracy in conditional generation. The use of CFG is crucial to the results and success of the current work.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Siyuan Huang", "paper_title": "Spatio-temporal self-supervised representation learning for 3d point clouds", "reason": "This paper is relevant to the current work because it deals with spatio-temporal representation learning for 3D point clouds, which is an important subproblem in 4D LiDAR scene generation.  Understanding how to effectively represent spatio-temporal information is crucial for developing high-quality 4D models, thus this work is valuable to the overall model.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Jumin Lee", "paper_title": "Semcity: Semantic scene generation with triplane diffusion", "reason": "This paper is highly relevant to the current work due to its focus on LiDAR scene generation using diffusion models.  The paper introduces the \"triplane\" representation, an alternative to the HexPlane used in the proposed approach.   This allows the comparison between approaches and the advantages of using HexPlane in the current work.", "section_number": 2}, {" publication_date": "2023a", "fullname_first_author": "Yuheng Liu", "paper_title": "Pyramid diffusion for fine 3d large scene generation", "reason": "This paper tackles the challenge of generating large-scale 3D scenes using a pyramid diffusion model, which is highly relevant to this paper's approach.  The use of diffusion models for large-scale scenes is directly comparable and allows the study of alternative methods. This is important because it allows the authors to discuss improvements over other models.", "section_number": 2}, {" publication_date": "2023b", "fullname_first_author": "Zhen Liu", "paper_title": "Meshdiffusion: Score-based generative 3d mesh modeling", "reason": "This paper focuses on 3D mesh generation, a closely related area to LiDAR scene generation. Understanding the advancements in 3D mesh generation helps to inform techniques for improving LiDAR generation, especially in terms of geometric detail and realism. The use of score-based models for 3D is also relevant.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kazuto Nakashima", "paper_title": "Lidar data synthesis with denoising diffusion probabilistic models", "reason": "This paper directly addresses the problem of LiDAR scene generation using diffusion models, which is highly relevant to this paper's approach. It provides insights into the use of diffusion models for LiDAR data and offers a point of comparison in terms of methodology and performance. Being recent and state-of-the-art this is important for comparison.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Lucas Nunes", "paper_title": "Scaling diffusion models to real-world 3d lidar scene completion", "reason": "This paper is highly relevant because it focuses on scaling diffusion models for real-world 3D LiDAR scene completion, which is a major challenge in the field.  Understanding how to scale diffusion models for improved performance on realistic scenes informs and validates the work presented in this paper. Scaling is a key consideration and this addresses that.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "reason": "This paper introduces Diffusion Transformers (DiT), the core model used in the current paper for generating HexPlanes. The use of this is fundamental to the approach. Understanding the capabilities and limitations of DiT is crucial for assessing the performance and contributions of the proposed method.  It is a highly relevant foundational paper.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This paper is significant because it introduces a method for high-resolution image synthesis using latent diffusion models.  This work is fundamental to understanding the advancements in diffusion models, which are also used in this paper.  High-resolution generation is a key challenge in LiDAR scene generation, and the techniques in this paper inform the approach.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Uriel Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "reason": "This paper is highly relevant because it focuses on the generation of dynamic video sequences, which is a closely related task to generating dynamic LiDAR scenes.  Understanding techniques for high-quality video generation informs how to handle temporal dependencies and dynamic elements in the LiDAR data.", "section_number": 2}, {" publication_date": "2015", "fullname_first_author": "Karen Simonyan", "paper_title": "Very deep convolutional networks for large-scale image recognition", "reason": "This paper is highly influential in the field of computer vision, and its introduction of very deep convolutional networks has significantly advanced the state-of-the-art in many tasks, including image classification and object detection. These architectures are foundational to many computer vision models, including many of the backbone networks used in LiDAR processing and scene generation. The underlying architectures and principles are highly relevant.", "section_number": 2}]}