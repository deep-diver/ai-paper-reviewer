{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a model that bridges image and text understanding, which is foundational to many text-to-video models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces latent diffusion models, a key technique used in many modern image and video generation models, including the one described in the paper."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces denoising diffusion probabilistic models, a fundamental concept for various generative models, including those used for video generation."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-00-00", "reason": "This paper introduces the T5 text-to-text transformer model, which is used in Mimir and is crucial for text understanding and generation in many AI tasks."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper introduces a state-of-the-art text-to-image model that uses a large language model for text understanding, which is relevant to the approach described in Mimir."}]}