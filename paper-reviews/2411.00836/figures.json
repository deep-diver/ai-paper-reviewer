[{"figure_path": "https://arxiv.org/html/2411.00836/x1.png", "caption": "Figure 1: An example of consistent failures in GPT-4o.\nSeed question 78 in our DynaMath benchmark generates a graph of a shifted absolute value function.\nGPT-4o consistently provides incorrect answers for variant 9 (left) with 90% repetition consistency, while it can successfully answer variant 7 (right) with 100% repetition consistency. We tested 7 other variants involving non-zero shifts of the absolute value function, and in each case, GPT-4o insists incorrectly that the \u201csharp corner\u201d is at x=0\ud835\udc650x=0italic_x = 0, leading to incorrect answers for all 7 variants. More failure examples are in Appendix\u00a0F.", "description": "Figure 1 shows an example where GPT-4 consistently fails to correctly identify the location of a sharp corner in a shifted absolute value function graph.  Variant 9 of seed question 78 consistently produces an incorrect answer from GPT-4 with a repetition consistency of 90%. In contrast, variant 7, with the same function but a different shift, generates correct answers consistently.  Across 7 other similar variants with varying shifts, GPT-4 makes the same error, claiming that the sharp corner is always at x=0, even though the function is shifted.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2411.00836/x2.png", "caption": "Figure 2: The dynamic benchmark generation procedure in DynaMath. A seed question is represented as a program that can generate many concrete questions with different variations. The plots for concrete questions are randomly generated along with the corresponding ground-truth answers. During evaluation, all concrete variants of the seed questions are considered, allowing us to evaluate the worst-case model performance and robustness.", "description": "The figure illustrates the process of generating a dynamic benchmark dataset for evaluating the robustness of vision-language models (VLMs) in mathematical reasoning.  It starts with a seed question, represented as a Python program. This program generates numerous concrete question variants by randomly altering parameters (numerical values, function types, etc.), producing different visual representations (plots, graphs, etc.).  Each variant has a corresponding ground-truth answer. During the evaluation phase, all generated variants of each seed question are used to assess the model's performance, enabling the calculation of both average-case and worst-case accuracy, providing a comprehensive measure of robustness against variations.", "section": "BENCHMARK DESIGN"}, {"figure_path": "https://arxiv.org/html/2411.00836/x6.png", "caption": "Figure 5: Comparing reasoning robustness across different models (top), topics (middle), and variant types (bottom).", "description": "This figure compares the reasoning robustness of various vision-language models (VLMs) across different aspects. The top panel shows the overall reasoning robustness of each model, indicating how consistently each model performs across various question variants. The middle panel breaks down the robustness performance across different math problem topics, showing variations in the models\u2019 abilities across diverse mathematical domains. The bottom panel analyzes the robustness concerning various types of question variations, assessing how sensitive the models are to changes in numerical values, geometric transformations, functional representations, and so on.", "section": "4. EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2411.00836/x7.png", "caption": "Figure 6: Example of the Memorization Phenomenon: the generated variants of seed Question 12 and the corresponding responses from Claude 3.5 Sonnet. The model\u2019s response remains 2\u2062\u03c02\ud835\udf0b2\\pi2 italic_\u03c0 with high probability, regardless of changes in the conditions depicted in the diagram.", "description": "Figure 6 demonstrates the memorization phenomenon observed in Claude 3.5 Sonnet.  Five variants of seed question 12, each with a different visual representation of a periodic function, were generated. Despite the varying inputs, the model consistently predicted the period of the function as 2\u03c0. This indicates that instead of performing actual calculations based on the diagram's details, the model may be relying on memorized patterns or heuristics. The high probability of the model giving the same answer, regardless of visual changes in the input, highlights a significant limitation in its reasoning capability and emphasizes the need for more robust evaluation of vision-language models.", "section": "4.3 QUALITY STUDY"}, {"figure_path": "https://arxiv.org/html/2411.00836/x8.png", "caption": "Figure 7: Error Analysis of Claude-3.5 Sonnet.", "description": "The figure shows a pie chart that breaks down the types of errors made by the Claude-3.5 Sonnet model on the DYNAMATH benchmark.  It visually represents the proportion of errors attributed to five categories: figure reading errors, calculation errors, reasoning errors, knowledge errors, and hallucination errors.  This allows for a quick understanding of the model's failure modes and their relative frequencies.", "section": "4.3 QUALITY STUDY"}, {"figure_path": "https://arxiv.org/html/2411.00836/x36.png", "caption": "Figure 8: Variation types considered in our DynaMath benchmark", "description": "Figure 7 visualizes six distinct variation types incorporated within the DynaMath benchmark. These variations manipulate different aspects of mathematical problems to assess the robustness of Vision-Language Models (VLMs).  The variations include altering numerical values, performing geometric transformations, modifying function types, applying symbolic substitutions, incorporating real-life contexts, and changing graph structures.  Each variation type challenges VLMs' ability to generalize their reasoning processes across diverse problem instances.", "section": "3.1 DATASET COLLECTION"}, {"figure_path": "https://arxiv.org/html/2411.00836/x37.png", "caption": "Figure 9: Example of the generated variants of Question 169 and the corresponding responses from GPT-4o.", "description": "Figure 9 shows six variations of Question 169 from the DynaMath benchmark.  Question 169 asks whether the product of two functions, f(x) and g(x), represented graphically, is even or odd. Each variant displays a slightly altered version of the graphs of f(x) and g(x), testing the model's robustness to changes in visual representation.  The figure also includes the corresponding answers generated by GPT-40 for each variant.  The differences in the answers highlight GPT-40's inconsistency in solving similar problems with minor visual changes.", "section": "3.2 Dataset Statistics"}, {"figure_path": "https://arxiv.org/html/2411.00836/x38.png", "caption": "Figure 10: Example of the generated variants of Question 75 and the corresponding responses from Gemini.", "description": "Figure 10 presents six variations of Question 75 from the DYNAMATH benchmark, each showing different visual representations of two lines. The question asks whether the lines are parallel.  Gemini's responses to each variant are included, demonstrating inconsistencies in its ability to correctly assess parallelism based on these different visual presentations.", "section": "Experimental Results"}]