[{"figure_path": "https://arxiv.org/html/2411.17041/extracted/6019632/Figure/overall.jpg", "caption": "Figure 1: \nRepresentative video results using Free2Guide, a novel framework that enables train-Free, gradient-Free video Guidance leveraging a Large Vision-Language Model. Best viewed with Acrobat Reader. Click each image to play the video clip.", "description": "Figure 1 showcases example video outputs generated using the Free\u00b2Guide framework.  Each row presents a text prompt and compares the videos produced by a baseline method (without Free\u00b2Guide) versus videos generated with Free\u00b2Guide. The Free\u00b2Guide method utilizes a Large Vision-Language Model to guide the video generation process without requiring any additional model training or gradient calculations.  This allows for flexibility and avoids the computational overhead of gradient-based methods.  The improved text alignment and video quality obtained using Free\u00b2Guide are clearly visible in the generated videos.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2411.17041/extracted/6019632/Figure/fig-qualitative.jpg", "caption": "Figure 2: Overall pipeline of Free2Guide, leveraging path integral control to enhance text-video alignment without requiring reward gradient. During the sampling process, Free2Guide generates multiple denoised video samples and evaluate text alignment using non-differentiable Large Vision-Language Models (LVLMs).", "description": "Free\u00b2Guide uses path integral control to improve text-video alignment in diffusion models without needing reward gradients.  The process involves generating multiple denoised video samples at each step of the sampling process.  A Large Vision-Language Model (LVLM), acting as a non-differentiable reward function, evaluates the alignment of each sample with the input text prompt. This feedback guides the sampling process toward generating videos that better match the text description. The figure illustrates this overall pipeline.", "section": "Method: Free\u00b2Guide"}, {"figure_path": "https://arxiv.org/html/2411.17041/extracted/6019632/Figure/additional.jpg", "caption": "Figure 3: Qualitative results of our method. Baseline with LaVie on the left and VideoCrafter2 on the right.", "description": "Figure 3 presents a qualitative comparison of video generation results using different methods.  The left side shows results from the LaVie model, while the right side shows results from the VideoCrafter2 model.  Each row displays a different text prompt used to guide the video generation. Within each row, the first image shows the baseline video generated without any additional guidance. Subsequent images show the results when adding different reward models for guidance, including CLIP, ImageReward, and GPT-40. This allows for a visual comparison of how the different methods affect the alignment of generated videos with the given text descriptions, and the overall quality of the generated videos.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.17041/extracted/6019632/Figure/suppl-comparison.jpg", "caption": "Table 5: Quantitative results on text alignment by sample size.", "description": "This table presents the results of an ablation study on the effect of varying the number of samples used during the sampling process of the Free\u00b2Guide model on text-to-video alignment performance.  The study employed the LaVie model with CLIP reward, varying the number of samples (n) used for Monte Carlo estimation.  The results show an optimal sample size, where increasing the number beyond a certain point does not further improve alignment and may introduce errors.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.17041/extracted/6019632/Figure/suppl-ensemble.jpg", "caption": "Table 6: Quantitative results on text alignment by range of guidance step.", "description": "This table presents the results of an experiment evaluating the impact of the guidance range (the number of steps during the sampling process where guidance is applied) on text alignment in video generation.  It shows how different guidance ranges affect the average text alignment score, comparing results when guidance is applied in various time windows during the sampling process. The goal is to determine the optimal guidance range that balances accurate alignment with overall video quality.  Using too narrow a range might not be sufficient for proper alignment, whereas too wide a range could allow for accumulation of errors during the sampling process, thus negatively impacting the overall video quality.", "section": "5. Experiments"}]