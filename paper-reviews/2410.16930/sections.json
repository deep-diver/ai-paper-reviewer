[{"page_end_idx": 1, "page_start_idx": 1, "section_number": 1, "section_title": "Introduction", "details": {"details": "The introduction establishes the context of research on Large Language Models (LLMs) and their mathematical reasoning capabilities.  It highlights the limited exploration of how mathematical reasoning is encoded within LLM parameters and the potential benefits of identifying these parameters.  Such identification, the authors argue, would allow targeted improvements in mathematical performance without affecting other LLM functionalities and would enhance our understanding of how LLMs represent mathematical knowledge. The introduction then reviews existing literature on parameter importance identification in LLMs, noting that while some methods exist, they are either computationally expensive (using gradient information) or unable to effectively isolate broad concepts like mathematical reasoning, potentially due to entanglement with other skills. The authors posit that this necessitates the development of a new method, which they introduce as the focus of their paper.  The overarching goal is to disentangle math-specific parameters from general language parameters, thereby isolating the capacity for math reasoning within the LLM.", "first_cons": "The introduction's claim of a research gap in isolating math-specific parameters in LLMs might be overstated. While the focus on *disentangling* math-specific parameters from general language parameters is a novel approach,  the claim might overlook other related research that uses different methods to address aspects of this problem.", "first_pros": "The introduction clearly defines the research problem and its significance. It effectively sets the stage for the proposed novel method, highlighting the existing limitations in existing research and the potential implications of successfully addressing the problem.  The motivation for the research is both clearly stated and compelling.", "keypoints": ["Limited research on how math reasoning is encoded within LLMs.", "Potential benefits of isolating math-specific parameters: targeted improvement, better understanding.", "Existing methods for parameter importance identification are either computationally expensive or ineffective for isolating broad skills like math reasoning.", "The need for a new method to effectively isolate math-specific parameters is highlighted."], "second_cons": "The introduction could benefit from a more explicit discussion of the specific challenges involved in identifying and isolating math-specific parameters within LLMs. This would further strengthen the justification for the proposed method.", "second_pros": "The introduction is concise and well-structured, providing a clear and logical flow of information.  It effectively summarizes the current state of research, motivates the need for the proposed method, and clearly outlines the paper's contributions.", "summary": "This paper investigates the under-explored area of isolating mathematical reasoning abilities within Large Language Models (LLMs).  While existing methods for identifying important parameters exist, they are either computationally expensive or insufficiently effective for isolating a broad, complex skill such as mathematical reasoning. This paper introduces a novel method, Math Neurosurgery, that uses only forward passes to identify and isolate these parameters, potentially enabling targeted improvements to mathematical performance in LLMs without negatively impacting other capabilities."}}, {"page_end_idx": 2, "page_start_idx": 2, "section_number": 2, "section_title": "Related Work", "details": {"details": "This section reviews existing literature on skill and knowledge localization within Large Language Models (LLMs).  It highlights a gap in research focusing specifically on math reasoning abilities within LLMs.  Many studies have explored skill localization, but these often use computationally expensive gradient-based methods and don't always successfully isolate abilities like math reasoning, which might be entangled with other skills.  Some works focus on the internal representation of mathematical concepts within LLMs but fall short of identifying specific parameters responsible for mathematical reasoning. The authors point to some studies using forward passes (cheaper computationally) to identify important parameters for a task but these are less successful in isolating domain-specific abilities from other related skills.  In short, this section sets the stage for the novel contributions of the paper by highlighting the lack of prior work effectively isolating math reasoning parameters within LLMs.", "first_cons": "The review of existing work is somewhat superficial.  It doesn't go into depth on the methodologies of other works beyond classifying them as computationally expensive or using forward passes. A more in-depth analysis of the strengths and weaknesses of different methods would have added value.", "first_pros": "The section clearly and effectively identifies a significant gap in the literature. The authors articulate the problem of isolating math reasoning parameters in LLMs, establishing the need for the novel methods proposed in the rest of the paper.", "keypoints": ["Many existing skill localization studies use computationally expensive gradient-based methods", "Few studies specifically target math reasoning in LLMs", "Some studies explore how mathematical concepts are represented internally, but do not pinpoint parameters solely responsible for math reasoning", "Forward pass methods offer computational advantages, but struggle to isolate single skill-related parameters from other related skills"], "second_cons": "The distinction between studies exploring internal representations of mathematical concepts and those aiming to isolate parameters is not always crystal clear.  More distinct categorization and explanation of these two research approaches would make the review clearer.", "second_pros": "The section effectively establishes the context and motivation for the new approach presented in the paper. By clearly outlining the limitations of existing methods, the authors successfully justify the need for their novel solution.", "summary": "This section reviews prior work on skill and knowledge localization in LLMs, noting that while many methods exist, few specifically address and successfully isolate math reasoning abilities in LLMs.  Existing methods often rely on computationally expensive gradient-based techniques or simpler forward-pass methods that struggle to separate math reasoning from other intertwined linguistic abilities.  The authors identify a lack of research effectively isolating math-specific parameters, motivating their proposed novel solution."}}, {"page_end_idx": 3, "page_start_idx": 3, "section_number": 3, "section_title": "Methods", "details": {"details": "MathNeuro, the proposed parameter identification method, leverages forward passes to isolate math-specific parameters within LLMs. It builds upon Wanda, a state-of-the-art pruning method, by using weights and activations to calculate parameter importance but adds a crucial step. MathNeuro removes parameters deemed important for general language tasks, effectively isolating those crucial for mathematical reasoning.  The method evaluates the absolute value of weights times activations for both math and non-math tasks (using datasets like GSM8K and RACE).  It then identifies the top K% parameters for each task, and selects only those highly important for math but not for non-math as math-specific parameters. This process helps to eliminate entanglement with other cognitive abilities. This method is then applied to prune or scale parameters, evaluating impact on GSM8K (math) and RACE/MMLU (non-math) tasks. Results show that pruning the parameters identified by MathNeuro deletes a model\u2019s math reasoning ability without affecting its general language ability; conversely, scaling these parameters can boost the model\u2019s performance on GSM8K by 4-17%, showcasing its effectiveness and efficiency, particularly as it maintains effectiveness even with single-sample parameter importance calculations.", "first_cons": "MathNeuro's reliance on a separate non-math task for comparison could introduce bias or inaccuracies if the chosen non-math task is not sufficiently distinct from mathematical reasoning. The impact on different sized models needs additional investigations.", "first_pros": "MathNeuro demonstrates high data efficiency; most of its effectiveness holds when using a single sample for identifying math-specific parameters, which reduces the computational burden of parameter importance calculation and potentially improves scalability.", "keypoints": ["MathNeuro uses only forward passes, making it computationally efficient for large models.", "It isolates math-specific parameters by removing those important for general language tasks.", "Pruning MathNeuro-identified parameters eliminates a model's math reasoning ability without affecting general language skills.", "Scaling these parameters improves model performance by 4-17% on GSM8K.", "The method remains data efficient; it retains effectiveness when using only a single sample."], "second_cons": "The selection of the top K% parameters is hyperparameter-dependent and its optimal value might need to be determined experimentally for each model architecture and task.", "second_pros": "The approach is rigorously evaluated with five different LLMs ranging in size from 1B to 8B parameters, enhancing its generalizability and robustness.", "summary": "MathNeuro is a novel method that uses forward passes to isolate math-specific parameters in LLMs. It builds on existing work by using weights and activations to calculate parameter importance but further isolates math-specific parameters by removing those important for general language tasks.  Experiments show that pruning MathNeuro-identified parameters eliminates a model's math reasoning ability without harming its general language ability, while scaling those parameters boosts GSM8K performance by 4-17%, and this holds true even with single-sample calculations."}}, {"page_end_idx": 5, "page_start_idx": 4, "section_number": 4, "section_title": "Experiments", "details": {"details": "This section details the experiments conducted to validate the effectiveness of MathNeuro in identifying math-specific parameters within LLMs.  Two main experimental settings are used: pruning and scaling.  In the pruning experiments, parameters identified as important for math reasoning are removed from the model, and the impact on both math and non-math performance is assessed across five different LLMs (ranging from 1B to 8B parameters).  The results show that MathNeuro effectively isolates math-specific parameters, leading to a significant drop in math performance without substantially affecting non-math tasks.  In the scaling experiments, identified math parameters are scaled by a small constant (e.g., 1.1), and the effect on model performance is evaluated.  This experiment reveals performance improvements (4-17% on GSM8K) for various LLMs. The data efficiency of MathNeuro is also demonstrated through single-sample experiments, indicating the method's potential for broader applications.", "first_cons": "The study focuses on a limited number of LLMs and datasets, potentially limiting the generalizability of the findings to other models and tasks.", "first_pros": "The study demonstrates a significant performance improvement on mathematical reasoning tasks after scaling MathNeuro identified parameters (4-17% improvement on GSM8K).", "keypoints": ["MathNeuro effectively isolates math-specific parameters, significantly reducing math performance while minimally impacting non-math tasks.", "Scaling MathNeuro-identified parameters improves math performance by 4-17% on GSM8K across different models.", "MathNeuro is data-efficient, showcasing significant effectiveness even when using a single training sample.", "The method shows consistency in identifying similar subsets of parameters as math-specific across different samples and across different models."], "second_cons": "The selection of a single non-math dataset (RACE and MMLU) might not fully capture the multifaceted nature of general language understanding abilities.", "second_pros": "The experiments show MathNeuro's robustness across diverse LLMs (ranging from 1B to 8B parameters), increasing confidence in its effectiveness.", "summary": "This experiment section validates MathNeuro's ability to isolate math-specific parameters in LLMs. By pruning these parameters, the model's math reasoning ability is effectively removed with minimal impact on non-math skills. Conversely, scaling these parameters improves math performance by 4-17% on GSM8K. These findings highlight MathNeuro's data efficiency and robustness across multiple LLMs."}}]