[{"figure_path": "2410.17241/tables/table_3_0.html", "caption": "TABLE 1\nData statistics for colonoscopy datasets. The columns include: number of images (#IMG) and videos (#VID), classification tag (Cls), bounding box (Bbx), segmentation mask (Seg), text (Tx). The categories not related to colonoscopy, such as stomach and esophagitis, are marked in grey.", "description": "Table 1 presents data statistics for 63 colonoscopy datasets, including the number of images and videos, classification tags, bounding boxes, segmentation masks, and text annotations, categorized by their objectives.", "section": "3 REVISITING COLONOSCOPY DATA"}, {"figure_path": "2410.17241/tables/table_5_0.html", "caption": "TABLE 1\nData statistics for colonoscopy datasets. The columns include: number of images (#IMG) and videos (#VID), classification tag (Cls), bounding\nbox (Bbx), segmentation mask (Seg), text (Tx). The categories not related to colonoscopy, such as stomach and esophagitis, are marked in grey.", "description": "Table 1 presents data statistics for 63 colonoscopy datasets, including the number of images and videos, and the types of annotations available (classification, bounding boxes, segmentation masks, and text).", "section": "3 REVISITING COLONOSCOPY DATA"}, {"figure_path": "2410.17241/tables/table_6_0.html", "caption": "TABLE 1\nData statistics for colonoscopy datasets. The columns include: number of images (#IMG) and videos (#VID), classification tag (Cls), bounding\nbox (Bbx), segmentation mask (Seg), text (Tx). The categories not related to colonoscopy, such as stomach and esophagitis, are marked in grey.", "description": "Table 1 presents data statistics for 63 colonoscopy datasets, including the number of images and videos, classification tags, bounding boxes, segmentation masks, and text annotations.", "section": "3 REVISITING COLONOSCOPY DATA"}, {"figure_path": "2410.17241/tables/table_10_0.html", "caption": "TABLE 6\nDetails of instruction tuning dataset ColonINST. For each task, we provide five templates for human instructions, the data sources used to organise human-machine dialogues, and an example of a human-machine conversation.", "description": "Table 6 presents details of the ColonINST dataset, including instruction templates, data sources, and sample human-machine dialogues for four tasks.", "section": "5.1 Established instruction tuning dataset: ColonINST"}, {"figure_path": "2410.17241/tables/table_12_0.html", "caption": "TABLE 7\nMultimodal benchmark for three conversational tasks. \"LoRA\" refers to fine-tuning using low-rank adaptation [282]. \"EXT\" indicates the use of\npre-trained weights on extra data. We compare the results on the seen samples from the validation set and the unseen samples from the testing\nset of ColonINST. The symbol \u2191 signifies that a higher score reflects better performance.", "description": "Table 7 presents a multimodal benchmark comparing eight popular MLMs on three conversational tasks using ColonINST dataset, evaluating their performance on seen and unseen data samples.", "section": "5.3 Experiments"}, {"figure_path": "2410.17241/tables/table_13_0.html", "caption": "TABLE 8\nDiagnostic studies of three core components in ColonGPT. *: interpolate the position embeddings for higher resolution, specifically from\n224px to 384px. Our default configurations are shaded with a gray background.", "description": "Table 8 presents diagnostic studies of three core components in ColonGPT, showing the impact of different visual encoders, multigranularity multimodal adapters, and fine-tuning strategies on the model's performance across three conversational tasks.", "section": "5.3 Experiments"}]