[{"content": "| Method | Overall | Human-Shape | Animals | Daily-Used | Buildings | Transportations | Plants | Food | Electronics |\n|---|---|---|---|---|---|---|---|---|---| \n| PointCLIP | 5.4 | 3.5 | 4.5 | 6.5 | 5.5 | 3.6 | 8.8 | 12.3 | 5.6 |\n| PointCLIPv2 | 9.5 | 6.8 | 10.0 | 11.3 | 8.4 | 6.5 | 15.8 | 15.3 | 9.9 |\n| SATR | 12.3 | 15.6 | 16.5 | 12.7 | 7.9 | 9.4 | 17.2 | 14.5 | 9.7 |\n| PartSLIP | 24.3 | 39.3 | 41.1 | 19.0 | 13.0 | 17.1 | 31.7 | 17.3 | 18.5 |\n| Ours | **34.7** | **44.4** | **51.6** | **33.6** | **20.7** | **26.6** | **42.6** | **35.1** | **31.1** |", "caption": "Table 1: Zero-shot semantic segmentation on PartObjaverse-Tiny, reported in mIoU (%).", "description": "This table presents the performance of various zero-shot semantic segmentation methods on the PartObjaverse-Tiny dataset.  The performance is measured using the mean Intersection over Union (mIoU) metric, a standard evaluation metric for semantic segmentation, and is broken down by object category within the dataset.  The results show the mIoU for each category for each method, highlighting the relative strengths and weaknesses of each approach in segmenting different types of objects.", "section": "4. Experiments"}, {"content": "| Method | Overall | Human-Shape | Animals | Daily-Used | Buildings | Transportations | Plants | Food | Electronics |\n|---|---|---|---|---|---|---|---|---|---| \n| PartSLIP | 35.2 | 45.0 | 50.1 | 34.4 | 22.5 | 26.3 | 44.6 | 33.4 | 32.0 |\n| SAM3D | 43.6 | 47.2 | 45.0 | 43.1 | 38.6 | 39.4 | 51.1 | 46.8 | 43.8 |\n| Ours | **53.7** | **54.4** | **59.0** | **52.1** | **46.2** | **50.3** | **60.7** | **59.8** | **54.5** |", "caption": "Table 2: Zero-shot class-agnostic part segmentation on PartObjaverse-Tiny, reported in mIoU (%).", "description": "This table presents the performance comparison of different zero-shot semantic part segmentation methods on the PartObjaverse-Tiny dataset.  The dataset is a newly introduced, smaller subset of the larger Objaverse dataset and consists of 200 3D objects with detailed part annotations. The comparison focuses on class-agnostic part segmentation, meaning the methods do not need to identify specific semantic categories of parts, only distinguish between parts within an object. The metric used to evaluate performance is mean Intersection over Union (mIoU), which quantifies the overlap between predicted and ground truth part segmentations.  The results are broken down by object category for a more granular analysis of model performance.", "section": "4. Experiments"}, {"content": "| Method | Overall | Human-Shape | Animals | Daily-Used | Buildings | Transportations | Plants | Food | Electronics |\n|---|---|---|---|---|---|---|---|---|---| \n| PartSLIP | 16.3 | 23.0 | 34.1 | 13.1 | 6.7 | 10.4 | 28.9 | 7.2 | 10.2 |\n| Ours | **30.2** | **36.9** | **43.7** | **29.0** | **19.0** | **21.4** | **38.5** | **39.4** | **27.7** |", "caption": "Table 3: Zero-shot instance segmentation on PartObjaverse-Tiny, reported in mAP50 (%).", "description": "This table presents the results of zero-shot instance segmentation on the PartObjaverse-Tiny dataset.  Zero-shot instance segmentation means the model was not trained on this specific dataset, but rather on a large-scale unlabeled dataset and evaluated its performance on this dataset. The results are reported using the mean Average Precision (mAP) metric at an Intersection over Union (IoU) threshold of 50%.  The mAP50 score measures the average precision of the model's ability to correctly identify and segment individual instances (parts) of objects within the images.  The table breaks down the mAP50 scores across various categories of objects within PartObjaverse-Tiny, allowing for a more granular understanding of model performance across different object types.", "section": "4. Experiments"}, {"content": "| Method | PointCLIPv2 | PartSLIP | ZeroPS | PartDistill | Ours |\n|---|---|---|---|---|---| \n| Overall | 16.1 | 34.4 | 39.3 | 39.9 | **41.2** |", "caption": "Table 4: Zero-shot semantic segmentation on PartNetE\u00a0[25], reported in mIoU (%).", "description": "This table presents the results of zero-shot semantic segmentation on the PartNetE dataset.  Zero-shot refers to the model's ability to perform the task without explicit training on PartNetE. The evaluation metric used is mean Intersection over Union (mIoU), a common measure of accuracy in semantic segmentation. The table compares the performance of several existing methods against the proposed SAMPart3D method.  It shows the overall mIoU across all categories in the dataset and potentially a breakdown of mIoU for individual categories of objects within PartNetE.", "section": "4. Experiments"}, {"content": "| Method | Pre-train Data | Overall | Human-Shape | Animals | Daily-Used | Buildings | Transportations | Plants | Food | Electronics |\n|---|---|---|---|---|---|---|---|---|---|---|\n| w.o. pre. | - | 43.4 | 48.5 | 45.7 | 44.9 | 31.7 | 37.2 | 54.5 | 48.1 | 44.8 |\n| PTv3 | 36k | 46.7 | 50.9 | 48.7 | 47.8 | 38.5 | 43.0 | 51.5 | 52.0 | 47.0 |\n| w.o. skip | 36k | 48.7 | 51.1 | 51.0 | 49.0 | 40.5 | 44.3 | 59.0 | 53.1 | 49.5 |\n| Ours | 36k | 50.5 | 53.3 | 53.4 | 51.1 | 41.6 | 45.5 | 58.7 | 57.2 | 51.8 |\n| Ours | 200k | **53.7** | **54.4** | **59.0** | **52.1** | **46.2** | **50.3** | **60.7** | **59.8** | **54.5** |", "caption": "Table 5: Ablation study on PartObjaverse-Tiny, reported in mIoU (%).", "description": "This ablation study analyzes the impact of different design choices in the SAMPart3D model on the PartObjaverse-Tiny dataset.  Specifically, it evaluates the effects of removing the pre-training step, using the original PTv3 backbone instead of the modified PTv3-object, and omitting the long skip connection. The results, measured in mean Intersection over Union (mIoU), are presented for the overall performance and broken down by object category, providing a detailed assessment of the contribution of each component to the model's accuracy.", "section": "4. Experiments"}, {"content": "| Method | Overall | Human-Shape | Animals | Daily-Used | Buildings | Transportations | Plants | Food | Electronics |\n|---|---|---|---|---|---|---|---|---|---| \n| 0.0 | 49.1 | 52.6 | 54.8 | 45.3 | 42.4 | 47.8 | 55.2 | 42.5 | 49.5 |\n| 0.5 | 48.9 | 51.1 | 53.1 | 47.1 | 41.3 | 46.9 | 58.0 | 50.9 | 48.0 |\n| 1.0 | 39.6 | 35.2 | 43.0 | 42.0 | 37.4 | 34.1 | 41.9 | 50.4 | 43.4 |\n| 1.5 | 31.5 | 26.7 | 31.0 | 34.3 | 20.9 | 24.9 | 34.1 | 52.3 | 35.6 |\n| 2.0 | 24.4 | 21.5 | 24.6 | 30.6 | 22.5 | 15.4 | 30.3 | 48.4 | 24.9 |\n| mixed-scale | **53.7** | **54.4** | **59.0** | **52.1** | **46.2** | **50.3** | **60.7** | **59.8** | **54.5** |", "caption": "Table 6: Zero-shot class-agnostic part segmentation on PartObjaverse-Tiny across different scale values, reported in mIoU (%).", "description": "This table presents the results of zero-shot class-agnostic part segmentation on the PartObjaverse-Tiny dataset.  The performance is evaluated using the mean Intersection over Union (mIoU) metric.  Importantly, it shows how the segmentation performance varies across different scale values (0.0, 0.5, 1.0, 1.5, 2.0) applied during the segmentation process. A 'mixed-scale' row is also included, which likely represents an approach that combines or optimizes across these scales. Results are broken down by object category for a more granular analysis.", "section": "4. Experiments"}]