{"references": [{"fullname_first_author": "Max Bain", "paper_title": "Frozen in time: A joint video and image encoder for end-to-end retrieval", "publication_date": "2021-00-00", "reason": "This paper introduces a novel approach for video and image retrieval that is relevant to the current research on video generation."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-00-00", "reason": "This is a foundational paper in diffusion models, which is the primary method used in this research for video generation."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-00-00", "reason": "This paper explores the use of video generation models for simulating realistic scenarios and is highly relevant to the current work."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Structure and content-guided video synthesis with diffusion models", "publication_date": "2023-00-00", "reason": "This paper advances video synthesis using diffusion models, which directly informs the current research on video generation."}, {"fullname_first_author": "Basile Van Hoorick", "paper_title": "Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis", "publication_date": "2024-00-00", "reason": "This paper proposes a method for generating multi-camera videos using a generative model, which is directly compared against in this research."}]}