[{"figure_path": "https://arxiv.org/html/2411.19527/x1.png", "caption": "Figure 1: Concept of DisCoRD. Discrete quantization methods encode multiple motions into a single quantized representation. While existing methods deterministically decode from this quantized representation, DisCoRD iteratively decodes the discrete latent in a continuous space to recover the inherent continuity and dynamism of motion. To assess the gap between reconstructed and real motion, prior work primarily used FID as the metric. Here, we additionally propose symmetric Jerk Percentage Error (sJPE) to evaluate the differences in naturalness between reconstructed and real motion.", "description": "DisCoRD, unlike traditional methods, uses an iterative decoding process in continuous space to generate motion from discrete latent representations. This approach addresses the limitations of deterministic decoding by recovering the inherent continuity and dynamism of motion.  The figure illustrates this process, highlighting how DisCoRD improves upon existing methods by balancing faithfulness and naturalness.  It also introduces a new evaluation metric, Symmetric Jerk Percentage Error (sJPE), which is used in addition to FID to assess the naturalness of generated motion.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.19527/x2.png", "caption": "Figure 2: An overview of DisCoRD. During the Training stage, we leverage a pretrained quantizer to first obtain discrete representations (tokens) of motion. These tokens are then projected into continuous features \ud835\udc02\ud835\udc02\\mathbf{C}bold_C, which are concatenated with noisy motion \ud835\udc17tsubscript\ud835\udc17\ud835\udc61\\mathbf{X}_{t}bold_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This concatenated feature is used to train a vector field v\ud835\udc63vitalic_v. During the Inference stage, we use a pretrained token prediction model based on the pretrained quantizer to first generate tokens from the given control signal. These generated tokens are then projected into continuous features \ud835\udc02^^\ud835\udc02\\mathbf{\\hat{C}}over^ start_ARG bold_C end_ARG, concatenated with Gaussian noise \ud835\udc170\u223c\ud835\udca9\u2062(0,I)similar-tosubscript\ud835\udc170\ud835\udca90\ud835\udc3c\\mathbf{X}_{0}\\sim\\mathcal{N}(0,I)bold_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u223c caligraphic_N ( 0 , italic_I ), and iteratively decoded through the learned vector field v\u03b8subscript\ud835\udc63\ud835\udf03v_{\\theta}italic_v start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT into motion \ud835\udc17^1subscript^\ud835\udc171\\mathbf{\\hat{X}}_{1}over^ start_ARG bold_X end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.", "description": "DisCoRD's training and inference stages are shown in this figure.  During training, a pretrained quantizer processes motion data to create discrete motion tokens. These tokens are converted to continuous features (C), which are combined with noisy motion data (X<sub>t</sub>) to train a vector field (v). In the inference phase, a token prediction model generates tokens from a control signal.  These tokens are transformed into continuous features (\u0108), combined with Gaussian noise (X<sub>0</sub>), and iteratively refined using the trained vector field (v<sub>\u03b8</sub>) to produce continuous motion data (X\u0302<sub>1</sub>).", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.19527/x3.png", "caption": "Figure 3: sJPE and FID response to gaussian noise. Noise sJPE is very sensitive to small level frame-wise noise than FID, while Static sJPE remains small. Note that FID values are very small.", "description": "This figure demonstrates the sensitivity of the Symmetric Jerk Percentage Error (sJPE) and Fr\u00e9chet Inception Distance (FID) metrics to Gaussian noise in generated motion data.  The left graph shows that Noise sJPE is highly sensitive to small amounts of frame-wise noise, while Static sJPE remains relatively unaffected. This indicates that Noise sJPE is a more effective metric for capturing subtle noise artifacts. The right graph visually compares the generated motions, showcasing the effect of Gaussian noise. It further illustrates how Noise sJPE distinguishes between subtle variations in motion quality more effectively than FID, which is less sensitive to small differences, especially with already low FID scores.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x4.png", "caption": "Figure 4: Under-reconstruction and frame-wise noise. We visualize joint positions (top) and corresponding jerk graphs (bottom). Compared to MoMask, DisCoRD demonstrates lower noise levels (Noise sJPE, blue area) and reduced under-reconstruction (Static sJPE, red area), with under-reconstruction regions in Momask highlighted in green boxes. This results in a lower sJPE for our method, indicating improved naturalness in the reconstructed motion.", "description": "Figure 4 compares the motion reconstruction quality of DisCoRD and MoMask, focusing on under-reconstruction and frame-wise noise. The top row shows the joint positions of the reconstructed motions over time, while the bottom row displays the corresponding jerk values, which represent the rate of change in acceleration.  The figure highlights that MoMask exhibits more pronounced frame-wise noise (blue shaded areas) and under-reconstruction (red shaded areas), indicated by the green boxes.  Conversely, DisCoRD demonstrates significantly reduced frame-wise noise and under-reconstruction, resulting in a lower symmetric Jerk Percentage Error (sJPE) score. This indicates that DisCoRD generates more natural and smoother reconstructed motions compared to MoMask.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x5.png", "caption": "Figure 5: Time spent decoding a batch of token sequences with a batch size of 32. All tests are conducted on the same NVIDIA RTX 4090Ti. Each experiment was repeated 20 times across the entire HumanML3D test set, and the average values were reported.", "description": "This figure shows the time taken to decode a batch of 32 motion token sequences using three different methods: MLD, MoMask, and DisCoRD (the authors' method).  The decoding was performed on the same hardware (NVIDIA RTX 4090Ti GPU) to ensure a fair comparison.  The experiment was repeated 20 times for each method on the complete HumanML3D dataset. The graph displays the average decoding time for each method.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x6.png", "caption": "Figure 6: Qualitative comparisons on the test set of HumanML3D.", "description": "This figure showcases a qualitative comparison of human motion generation results on the HumanML3D dataset.  It visually presents generated motions alongside corresponding text descriptions from various models, highlighting differences in both faithfulness (how accurately the motion matches the text description) and naturalness (how smooth and realistic the motion appears). The comparison enables a visual assessment of the models' strengths and weaknesses in producing high-quality, natural human movement based on textual prompts. ", "section": "4. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2411.19527/x7.png", "caption": "Figure 7: User study results on the HumanML3D dataset. Each bar represents a comparison between two models, with win rates depicted in blue and loss rates in red, evaluated based on naturalness and faithfulness.", "description": "This figure displays the results of a user study comparing the performance of different models on the HumanML3D dataset. Each bar graph represents a head-to-head comparison between two models, showing the percentage of times each model was preferred by users for either faithfulness or naturalness of generated motion.  Blue sections indicate the win rate for a particular model (i.e., the percentage of times that particular model was preferred over the other model in that comparison) while red shows the loss rate.  The user study aimed to evaluate the subjective quality of generated motions in terms of their faithfulness to input text prompts and their naturalness.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x8.png", "caption": "Figure 8: Relationship between fine-grained trajectory and jerk: Frame-wise noise in predicted motions, highlighted in the red box, results in higher jerk values compared to the ground truth, represented by the blue areas. The sum of the blue areas corresponds to Noise sJPE. Conversely, under-reconstruction in predicted motions, highlighted in the green box, leads to lower jerk values compared to the ground truth, represented by the red areas. The sum of the red areas corresponds to Static sJPE.", "description": "Figure 8 visualizes the relationship between fine-grained motion trajectories and jerk, a measure of motion smoothness.  The figure shows how frame-wise noise (in red boxes) leads to higher jerk values in the prediction compared to the ground truth. The cumulative area of this discrepancy is quantified as Noise sJPE. Conversely, under-reconstruction (in green boxes), where the model fails to capture fine details, results in lower jerk values than the ground truth. The cumulative difference here is represented by Static sJPE. Thus, the figure illustrates how these two components of the Symmetric Jerk Percentage Error (sJPE) capture different types of motion imperfections: noise and under-reconstruction.", "section": "C. Additional Analysis on sJPE"}, {"figure_path": "https://arxiv.org/html/2411.19527/x9.png", "caption": "Figure 9: Joint Trajectory and Jerk: Under-Reconstruction in Discrete Methods\nDisCoRD effectively reduces the red area, demonstrating its capability to reconstruct dynamic motion accurately. This improvement is also reflected in the lower sJPE value.", "description": "Figure 9 visualizes the effectiveness of DisCoRD in reconstructing dynamic motion compared to other discrete methods. It presents a detailed analysis of joint trajectories and jerk (the rate of change of acceleration) over time. The figure highlights how DisCoRD minimizes under-reconstruction, a common issue in discrete methods where fine-grained details are lost, as represented by the reduction in the red area. This improvement directly correlates with a lower Symmetric Jerk Percentage Error (sJPE) value, indicating that DisCoRD produces smoother and more natural-looking motions.", "section": "4.2. Quantitative results"}, {"figure_path": "https://arxiv.org/html/2411.19527/x10.png", "caption": "Figure 10: \nJoint Trajectory and Jerk: Frame-Wise Noise in Discrete Methods\nDisCoRD significantly reduces the blue area, indicating its ability to generate smooth motions that closely resemble the ground truth. This improvement is further reflected in the lower sJPE value.", "description": "Figure 10 visualizes the effectiveness of DisCoRD in reducing frame-wise noise during motion generation.  It compares the joint trajectories and jerk (rate of change of acceleration) of motions generated by DisCoRD against those from other discrete methods. The blue areas in the plots represent instances where the predicted jerk exceeds the ground truth jerk, indicating noisy or unnatural motion.  DisCoRD's significantly smaller blue area demonstrates its superior ability to produce smooth, natural motions that closely match the ground truth. This improvement is quantitatively reflected in a lower Symmetric Jerk Percentage Error (sJPE) value.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x11.png", "caption": "Figure 11: Joint Trajectory and Jerk: Both Frame-Wise Noise and Under-Reconstruction in Discrete Methods\nDisCoRD addresses both frame-wise noise and under-reconstruction by simultaneously reducing the blue and red areas. This demonstrates its ability to generate smooth and dynamic motions, closely aligning with the ground truth. This further supported by the lower sJPE values.", "description": "Figure 11 visualizes the effectiveness of DisCoRD in addressing both frame-wise noise and under-reconstruction, common issues in discrete methods. It presents joint trajectory and jerk plots for several methods, including DisCoRD, highlighting how DisCoRD significantly reduces both the blue area (representing noise) and the red area (representing under-reconstruction). This results in smoother, more dynamic, and accurate motions closely matching the ground truth, as confirmed by the lower Symmetric Jerk Percentage Error (sJPE) values.", "section": "4.2. Quantitative results"}, {"figure_path": "https://arxiv.org/html/2411.19527/x12.png", "caption": "Figure 12: Additional qualitative comparisons on the HumanML3D test set. The continuous method, MLD, often fails to perfectly align with the text consistently, while the discrete method, MoMask, exhibits issues such as under-reconstruction, resulting in minimal hand movement, or unnatural leg jitter caused by frame-wise noise.", "description": "Figure 12 presents a qualitative comparison of human motion generation results from three different methods: a continuous method (MLD), a discrete method (MoMask), and the proposed DisCoRD approach.  Each row shows motion generated from the same text prompt.  The continuous method (MLD) produces smooth motions but frequently lacks faithfulness to the textual description. The discrete method (MoMask) suffers from under-reconstruction, which leads to simplified or unnatural movements, especially noticeable in the hands and legs, and frame-wise noise, causing jerky or unnatural motion. The DisCoRD method, in contrast, aims to balance the strengths of both approaches, generating motion that remains faithful to the text description while maintaining smoothness and naturalness. The figure highlights how DisCoRD improves on the shortcomings of the other two methods.", "section": "4.3. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2411.19527/x13.png", "caption": "Figure 13: Additional qualitative results of our method on the HumanML3D test set.", "description": "This figure showcases qualitative comparisons of human motion generation results between DisCoRD and two other methods (MLD and MoMask) on the HumanML3D dataset.  It highlights DisCoRD's ability to generate motions that are both faithful to the textual descriptions and visually natural.  The examples demonstrate that MLD struggles with faithfulness to text descriptions, often resulting in incorrect actions, while MoMask, although more faithful, produces less natural motions with issues such as under-reconstruction and frame-wise noise.  DisCoRD effectively addresses these limitations, generating smoother, more realistic movements that accurately reflect the input text.", "section": "4.3. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2411.19527/x14.png", "caption": "Figure 14: Guidelines for user study in the Main paper: participants were asked to evaluate Faithfulness and Naturalness, excluding hand and facial movements that are not included in HumanML3D.", "description": "This figure shows the guidelines used in the user study. Participants were asked to evaluate the generated motions based on two criteria: faithfulness (how well the motion reflects the given text description) and naturalness (how natural the motion appears, regardless of the text).  Importantly, the instructions specifically excluded evaluating hand and facial movements, as these elements are not consistently present in the HumanML3D dataset used for training and evaluation.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x15.png", "caption": "Figure 15: Guidelines for User Study in the Supplementary: Participants were asked to evaluate Naturalness, excluding hand and facial movements that are not included in HumanML3D.", "description": "This figure details the guidelines provided to participants in a user study conducted as part of supplementary materials for the research paper.  The user study focused on evaluating the naturalness of generated human motions. Importantly, the guidelines explicitly instructed participants to disregard hand and facial movements when assessing naturalness, as these elements were not included in the HumanML3D dataset used for model training and evaluation. This exclusion is crucial because the models being assessed did not generate these features, and including them in the evaluation would introduce bias and unfair comparisons.", "section": "Supplementary Material"}, {"figure_path": "https://arxiv.org/html/2411.19527/x16.png", "caption": "Figure 16: User evaluation interface for the user study in the Main paper: participants were presented with two randomly selected videos and asked to choose the better sample in terms of faithfulness and naturalness.", "description": "In this user study, participants were shown pairs of videos generated using different methods.  For each pair, participants were asked to select which video better demonstrated two key qualities: faithfulness (how accurately the motion reflected the given text description) and naturalness (how smooth and realistic the motion appeared, irrespective of the text prompt).  This figure shows the user interface used for this evaluation.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.19527/x17.png", "caption": "Figure 17: User evaluation interface for the user study in the supplementary: participants were presented with a grid layout containing the GT video and three generated videos. Using the GT video as the upper bound, they were asked to rank the three generated videos in terms of naturalness.", "description": "This figure shows the user interface employed in a supplementary user study.  Participants viewed a grid containing the ground truth (GT) motion video alongside three motion videos generated by different models.  Their task was to rank the three generated videos based on their naturalness, using the GT video as a benchmark for comparison. The ranking scale was ordinal, allowing participants to assign the same rank to multiple videos if the differences in naturalness were indistinguishable.", "section": "Supplementary Material"}]