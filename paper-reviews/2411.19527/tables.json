[{"content": "| Methods | FID \u2193 | MPJPE \u2193 | sJPE \u2193 |\n|---|---|---|---|\n| **HumanML3D** |  |  |  |\n| MLD (cont.) | 0.017 | 14.7 | 0.404 |\n| T2M-GPT | 0.089 \u00b1 .001 | **60.0** | 0.564 |\n| **+DisCoRD(Ours)** | **0.031** \u00b1 .001 | 71.5 | **0.488** |\n| MMM | 0.097 \u00b1 .001 | **46.9** | 0.517 |\n| **+DisCoRD(Ours)** | **0.020** \u00b1 .001 | 56.8 | **0.429** |\n| MoMask | 0.019 \u00b1 001 | **29.5** | 0.512 |\n| **+DisCoRD(Ours)** | **0.011** \u00b1 000 | 33.3 | **0.385** |\n| **KIT-ML** |  |  |  |\n| T2M-GPT | 0.470 \u00b1 .010 | **46.4** | 0.526 |\n| **+DisCoRD(Ours)** | **0.284** \u00b1 .009 | 58.7 | **0.395** |\n| MoMask | 0.113 \u00b1 .001 | 37.5 | 0.384 |\n| **+DisCoRD(Ours)** | **0.103** \u00b1 .002 | **33.0** | **0.359** |", "caption": "Table 1: Quantitative evaluation on the HumanML3D and KIT-ML test sets for reconstruction. DisCoRD serves as a discrete model\u2019s decoder, outperforming MLD in both FID and sJPE, demonstrating its effectiveness in decoding discrete tokens in continuous space.", "description": "Table 1 presents a quantitative comparison of different methods for motion reconstruction using the HumanML3D and KIT-ML datasets.  The metrics used are Fr\u00e9chet Inception Distance (FID), which measures the similarity between the generated and real motion feature distributions, and Mean Per Joint Position Error (MPJPE), which measures the average distance between corresponding joints in the generated and real motions. A novel metric, Symmetric Jerk Percentage Error (sJPE), is also included, assessing the naturalness of the generated motion by evaluating the smoothness of the motion trajectory. The table highlights that DisCoRD, when used as a decoder for discrete motion representations (as opposed to using a continuous method like MLD), achieves superior performance on both FID and sJPE, demonstrating its effectiveness at translating discrete tokens into natural, continuous motions.", "section": "4. Experiments"}, {"content": "|-:|-:|-:|-:|-:|-:|-:|\n| Datasets | Methods | Top 1 | Top 2 | Top 3 | FID \u2193 | MultiModal Dist \u2193 | MultiModality \u2191 |\n|---|---|---|---|---|---|---|---| \n| Human<br>ML3D | MDM [45] | - | - | 0.611<sup>\u00b1.007</sup> | 0.544<sup>\u00b1.044</sup> | 5.566<sup>\u00b1.027</sup> | **2.799<sup>\u00b1.072</sup>** |\n|  | MLD [6] | 0.481<sup>\u00b1.003</sup> | 0.673<sup>\u00b1.003</sup> | 0.772<sup>\u00b1.002</sup> | 0.473<sup>\u00b1.013</sup> | 3.196<sup>\u00b1.010</sup> | <u>2.413<sup>\u00b1.079</sup></u> |\n|  | MotionDiffuse [61] | 0.491<sup>\u00b1.001</sup> | 0.681<sup>\u00b1.001</sup> | 0.782<sup>\u00b1.001</sup> | 0.630<sup>\u00b1.001</sup> | 3.113<sup>\u00b1.001</sup> | 1.553<sup>\u00b1.042</sup> |\n|  | ReMoDiffuse [62] | 0.510<sup>\u00b1.005</sup> | 0.698<sup>\u00b1.006</sup> | 0.795<sup>\u00b1.004</sup> | 0.103<sup>\u00b1.004</sup> | 2.974<sup>\u00b1.016</sup> | 1.795<sup>\u00b1.043</sup> |\n|  | MMM [36] | 0.504<sup>\u00b1.003</sup> | 0.696<sup>\u00b1.003</sup> | 0.794<sup>\u00b1.002</sup> | 0.080<sup>\u00b1.003</sup> | 2.998<sup>\u00b1.007</sup> | 1.164<sup>\u00b1.041</sup> |\n|  | T2M-GPT [60] | 0.491<sup>\u00b1.003</sup> | 0.680<sup>\u00b1.003</sup> | 0.775<sup>\u00b1.002</sup> | 0.116<sup>\u00b1.004</sup> | 3.118<sup>\u00b1.011</sup> | 1.856<sup>\u00b1.011</sup> |\n|  | + DisCoRD (Ours) | 0.476<sup>\u00b1.008</sup> | 0.663<sup>\u00b1.006</sup> | 0.760<sup>\u00b1.007</sup> | 0.095<sup>\u00b1.011</sup> | 3.121<sup>\u00b1.009</sup> | 1.831<sup>\u00b1.048</sup> |\n| KIT-<br>ML | MDM [45] | - | - | 0.396<sup>\u00b1.004</sup> | 0.497<sup>\u00b1.021</sup> | 9.191<sup>\u00b1.022</sup> | 1.907<sup>\u00b1.214</sup> |\n|  | MLD [6] | 0.390<sup>\u00b1.008</sup> | 0.609<sup>\u00b1.008</sup> | 0.734<sup>\u00b1.007</sup> | 0.404<sup>\u00b1.027</sup> | 3.204<sup>\u00b1.027</sup> | **2.192<sup>\u00b1.071</sup>** |\n|  | MotionDiffuse [61] | 0.417<sup>\u00b1.004</sup> | 0.621<sup>\u00b1.004</sup> | 0.739<sup>\u00b1.004</sup> | 1.954<sup>\u00b1.062</sup> | 2.958<sup>\u00b1.005</sup> | 0.730<sup>\u00b1.013</sup> |\n|  | ReMoDiffuse [62] | 0.427<sup>\u00b1.014</sup> | 0.641<sup>\u00b1.004</sup> | 0.765<sup>\u00b1.055</sup> | **0.155<sup>\u00b1.006</sup>** | 2.814<sup>\u00b1.012</sup> | 1.239<sup>\u00b1.028</sup> |\n|  | MMM [36] | 0.404<sup>\u00b1.005</sup> | 0.621<sup>\u00b1.006</sup> | 0.744<sup>\u00b1.005</sup> | 0.316<sup>\u00b1.019</sup> | 2.977<sup>\u00b1.019</sup> | 1.232<sup>\u00b1.026</sup> |\n|  | T2M-GPT [60] | 0.398<sup>\u00b1.007</sup> | 0.606<sup>\u00b1.006</sup> | 0.729<sup>\u00b1.005</sup> | 0.718<sup>\u00b1.038</sup> | 3.076<sup>\u00b1.028</sup> | 1.887<sup>\u00b1.050</sup> |\n|  | + DisCoRD (Ours) | 0.382<sup>\u00b1.007</sup> | 0.590<sup>\u00b1.007</sup> | 0.715<sup>\u00b1.004</sup> | 0.541<sup>\u00b1.038</sup> | 3.260<sup>\u00b1.028</sup> | <u>1.928<sup>\u00b1.059</sup></u> |\n|  | + DisCoRD (Ours) | **0.434<sup>\u00b1.007</sup>** | **0.657<sup>\u00b1.005</sup>** | <u>0.775<sup>\u00b1.004</sup></u> | <u>0.169<sup>\u00b1.010</sup></u> | <u>2.792<sup>\u00b1.015</sup></u> | 1.266<sup>\u00b1.046</sup> |", "caption": "Table 2: Quantitative evaluation on the HumanML3D and KIT-ML test set.\n\u00b1plus-or-minus\\pm\u00b1 indicates a 95% confidence interval. +DisCoRD indicates that the baseline model\u2019s decoder is replaced with DisCoRD. Bold indicates the best result, while underscore refers the second best. DisCoRD improves naturalness, as evidenced by FID scores, while preserving faithfulness, demonstrated by R-Precision and MM Distance.", "description": "Table 2 presents a quantitative comparison of different methods for text-to-motion generation on the HumanML3D and KIT-ML datasets.  The metrics used are Top-K Recall@1, FID (Fr\u00e9chet Inception Distance), Multimodal Distance, and Multimodality.  The plus-or-minus symbol (\u00b1) indicates the 95% confidence interval for each metric's score. Rows with '+DisCoRD' show the performance when the DisCoRD method replaces the original decoder of a baseline model. Bold typeface highlights the best performance for each metric, and underlined text indicates the second-best performance.  The table demonstrates that DisCoRD improves the naturalness of generated motion (lower FID scores), while maintaining its faithfulness to the input text (higher R-Precision and lower Multimodal Distance).", "section": "4. Experiments"}, {"content": "| Methods | sJPE\u2193 | FGD\u2193 |\n|---|---|---|\n| TalkSHOW [58] | 0.284 | 74.88 |\n| + DisCoRD(Ours) | **0.077** | **43.58** |\n| ProbTalk [27] | 0.406 | 5.21 |\n| + DisCoRD(Ours) | **0.349** | **4.83** |", "caption": "Table 3: Quantitative results on co-speech gesture generation. DisCoRD outperforms baseline models on sJPE and FGD.", "description": "This table presents a quantitative comparison of different methods for co-speech gesture generation.  The metrics used are Symmetric Jerk Percentage Error (sJPE), which measures the smoothness and naturalness of the generated motion, and Fr\u00e9chet Gesture Distance (FGD), which assesses the overall similarity between the generated and ground truth gestures. The results show that DisCoRD significantly outperforms other methods in terms of both sJPE and FGD, indicating its superior ability to generate natural and faithful co-speech gestures.", "section": "4. Experiments"}, {"content": "| Methods | sJPE\u2193 | Dist<sub>k</sub>\u2192 | Dist<sub>g</sub>\u2192 |\n|---|---|---|---|\n| TM2D [9] | 0.275 | 8.851 | 4.225 |\n| +DisCoRD(Ours) | 0.261 | 9.830 | 8.519 |", "caption": "Table 4: Quantitative results on music-to-dance generation. DisCoRD outperforms baseline model on sJPE, DistksubscriptDistk\\mathrm{Dist_{k}}roman_Dist start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT and DistgsubscriptDistg\\mathrm{Dist_{g}}roman_Dist start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT.", "description": "Table 4 presents a quantitative comparison of the proposed DisCoRD model against a baseline method for music-to-dance generation. The evaluation metrics used are Symmetric Jerk Percentage Error (sJPE), Dist<sub>k</sub> (kinetic distance), and Dist<sub>g</sub> (geometric distance).  The results demonstrate that DisCoRD achieves superior performance across all three metrics, indicating its effectiveness in generating high-quality, natural dance movements from music.", "section": "4. Experiments"}, {"content": "| Methods | Reconstruction FID \u2193 | Reconstruction MPJPE \u2193 |  | Generation FID \u2193 | Generation MM-Dist \u2193 |\n|---|---|---|---|---|---| \n| MoMask | 0.019 \u00b1 .001 | **29.5** |  | 0.051 \u00b1 .002 | **2.957** \u00b1 .008 |\n| + DisCoRD (Ours) | 0.011 \u00b1 .000 | 33.3 |  | **0.032** \u00b1 .002 | **2.938** \u00b1 .010 |\n| Ours (Upconv) | 0.010 \u00b1 .000 | 31.5 |  | 0.039 \u00b1 .003 | **2.943** \u00b1 .006 |\n| Ours (Repeat & Linear) | 0.011 \u00b1 .001 | 31.8 |  | 0.038 \u00b1 .001 | 2.947 \u00b1 .008 |\n| Ours (w/ Attention) | 0.020 \u00b1 .000 | 32.7 |  | 0.043 \u00b1 .002 | 2.983 \u00b1 .009 |\n| Ours (w/o WM) | **0.008** \u00b1 .000 | 33.4 |  | 0.038 \u00b1 .002 | 2.952 \u00b1 .009 |", "caption": "Table 5: Ablation studies. We perform ablations on the projection, attention, and motion windowing strategies during training on the HumanML3D dataset.\n(WM stands for Windowed Motion.)", "description": "This ablation study investigates the impact of different architectural choices within the DisCoRD model on its performance.  Specifically, it examines the effect of three key components: the projection method used to transform discrete tokens into continuous features, the inclusion of an attention mechanism in the U-Net architecture, and the training strategy using windowed motion sequences (as opposed to full-length sequences).  The results, evaluated on the HumanML3D dataset, quantify the contribution of each component to the model's reconstruction and generation quality, as measured by FID and MPJPE.", "section": "4. Experiments"}, {"content": "| Training Details ||\n|---|---|---|\n| Optimizer |  | AdamW (0.9,0.999) |\n| LR |  | 0.0005 |\n| LR Decay Ratio |  | 0 |\n| LR Scheduler |  | Cosine |\n| Warmup Epochs |  | 20 |\n| Gradient Clipping |  | 1.0 |\n| Weight EMA |  | 0.999 |\n| Flow Loss |  | MSE Loss |\n| Batch Size |  | 768 |\n| Window Size |  | 64 |\n| Steps |  | 481896 |\n| Epochs |  | 200 |\n| Model Details ||\n|---|---|---|\n| Input Channels |  | 512 |\n| Output Channels |  | 263 |\n| Condition Channels |  | 256 |\n| Activation |  | SiLU |\n| Dropout |  | 0 |\n| Width |  | (512, 1024) |\n| # Resnet / Block |  | 2 |\n| # Params |  | 66.9M |", "caption": "Table 6: Implementation details for training the DisCoRD decoder on the HumanML3D dataset using the pretrained Momask quantizer.", "description": "Table 6 details the hyperparameters and settings used to train the DisCoRD decoder.  The DisCoRD decoder was trained using the pretrained Momask quantizer on the HumanML3D dataset.  The table specifies the optimizer used (AdamW), learning rate, learning rate decay ratio, learning rate scheduler, gradient clipping, weight exponential moving average (EMA), flow loss function, batch size, window size, and the number of training steps and epochs.  Architectural details like input and output channels, the activation function used (SiLU), dropout rate, and the number of parameters are also included.", "section": "A. Implementation Details"}, {"content": "## Table 1:  Quantitative Results on HumanML3D and KIT-ML Datasets\n\n| Datasets | Methods | R Precision \u2191 (Top 1) | R Precision \u2191 (Top 2) | R Precision \u2191 (Top 3) | FID \u2193 | MultiModal Dist \u2193 | MultiModality \u2191 |\n|---|---|---|---|---|---|---|---| \n| Human<br>ML3D | MDM [45] | - | - | 0.611 \u00b1 0.007 | 0.544 \u00b1 0.044 | 5.566 \u00b1 0.027 | 2.799 \u00b1 0.072 |\n|  | MLD [6] | 0.481 \u00b1 0.003 | 0.673 \u00b1 0.003 | 0.772 \u00b1 0.002 | 0.473 \u00b1 0.013 | 3.196 \u00b1 0.010 | 2.413 \u00b1 0.079 |\n|  | MotionDiffuse [61] | 0.491 \u00b1 0.001 | 0.681 \u00b1 0.001 | 0.782 \u00b1 0.001 | 0.630 \u00b1 0.001 | 3.113 \u00b1 0.001 | 1.553 \u00b1 0.042 |\n|  | ReMoDiffuse [62] | 0.510 \u00b1 0.005 | 0.698 \u00b1 0.006 | 0.795 \u00b1 0.004 | 0.103 \u00b1 0.004 | 2.974 \u00b1 0.016 | 1.795 \u00b1 0.043 |\n|  | Fg-T2M [51] | 0.492 \u00b1 0.002 | 0.683 \u00b1 0.003 | 0.783 \u00b1 0.024 | 0.243 \u00b1 0.019 | 3.109 \u00b1 0.007 | 1.614 \u00b1 0.049 |\n|  | M2DM [18] | 0.497 \u00b1 0.003 | 0.682 \u00b1 0.002 | 0.763 \u00b1 0.003 | 0.352 \u00b1 0.005 | 3.134 \u00b1 0.010 | 3.587 \u00b1 0.072 |\n|  | M2D2M [7] | - | - | 0.799 \u00b1 0.002 | 0.087 \u00b1 0.004 | 3.018 \u00b1 0.010 | 2.115 \u00b1 0.079 |\n|  | MotionGPT [63] | 0.364 \u00b1 0.005 | 0.533 \u00b1 0.003 | 0.629 \u00b1 0.004 | 0.805 \u00b1 0.002 | 3.914 \u00b1 0.013 | 2.473 \u00b1 0.041 |\n|  | MotionLLM [54] | 0.482 \u00b1 0.004 | 0.672 \u00b1 0.003 | 0.770 \u00b1 0.002 | 0.491 \u00b1 0.019 | 3.138 \u00b1 0.010 | - |\n|  | MotionGPT-2 [52] | 0.496 \u00b1 0.002 | 0.691 \u00b1 0.003 | 0.782 \u00b1 0.004 | 0.191 \u00b1 0.004 | 3.080 \u00b1 0.013 | 2.137 \u00b1 0.022 |\n|  | AttT2M [65] | 0.499 \u00b1 0.003 | 0.690 \u00b1 0.002 | 0.786 \u00b1 0.002 | 0.112 \u00b1 0.006 | 3.038 \u00b1 0.007 | 2.452 \u00b1 0.051 |\n|  | MMM [36] | 0.504 \u00b1 0.003 | 0.696 \u00b1 0.003 | 0.794 \u00b1 0.002 | 0.080 \u00b1 0.003 | 2.998 \u00b1 0.007 | 1.164 \u00b1 0.041 |\n|  | T2M-GPT [60] | 0.491 \u00b1 0.003 | 0.680 \u00b1 0.003 | 0.775 \u00b1 0.002 | 0.116 \u00b1 0.004 | 3.118 \u00b1 0.011 | 1.856 \u00b1 0.011 |\n|  | **+ DisCoRD (Ours)** | 0.476 \u00b1 0.008 | 0.663 \u00b1 0.006 | 0.760 \u00b1 0.007 | 0.095 \u00b1 0.011 | 3.121 \u00b1 0.009 | 1.831 \u00b1 0.048 |\n| KIT-<br>ML | MDM [45] | - | - | 0.396 \u00b1 0.004 | 0.497 \u00b1 0.021 | 9.191 \u00b1 0.022 | 1.907 \u00b1 0.214 |\n|  | MLD [6] | 0.390 \u00b1 0.008 | 0.609 \u00b1 0.008 | 0.734 \u00b1 0.007 | 0.404 \u00b1 0.027 | 3.204 \u00b1 0.027 | 2.192 \u00b1 0.071 |\n|  | MotionDiffuse [61] | 0.417 \u00b1 0.004 | 0.621 \u00b1 0.004 | 0.739 \u00b1 0.004 | 1.954 \u00b1 0.062 | 2.958 \u00b1 0.005 | 0.730 \u00b1 0.013 |\n|  | ReMoDiffuse [62] | 0.427 \u00b1 0.014 | 0.641 \u00b1 0.004 | 0.765 \u00b1 0.055 | **0.155** \u00b1 0.006 | 2.814 \u00b1 0.012 | 1.239 \u00b1 0.028 |\n|  | Fg-T2M [51] | 0.418 \u00b1 0.005 | 0.626 \u00b1 0.004 | 0.745 \u00b1 0.004 | 0.571 \u00b1 0.047 | 3.114 \u00b1 0.015 | 1.019 \u00b1 0.029 |\n|  | M2DM [18] | 0.416 \u00b1 0.004 | 0.628 \u00b1 0.004 | 0.743 \u00b1 0.004 | 0.515 \u00b1 0.029 | 3.015 \u00b1 0.017 | **3.325** \u00b1 0.037 |\n|  | M2D2M [7] | - | - | 0.753 \u00b1 0.006 | 0.378 \u00b1 0.023 | 3.012 \u00b1 0.021 | 2.061 \u00b1 0.067 |\n|  | MotionGPT [63] | 0.340 \u00b1 0.002 | 0.570 \u00b1 0.003 | 0.660 \u00b1 0.004 | 0.868 \u00b1 0.032 | 3.721 \u00b1 0.018 | 2.296 \u00b1 0.022 |\n|  | MotionLLM [54] | 0.409 \u00b1 0.006 | 0.624 \u00b1 0.007 | 0.750 \u00b1 0.005 | 0.781 \u00b1 0.026 | 2.982 \u00b1 0.022 | - |\n|  | MotionGPT-2 [52] | 0.427 \u00b1 0.003 | 0.627 \u00b1 0.002 | 0.764 \u00b1 0.003 | 0.614 \u00b1 0.005 | 3.164 \u00b1 0.013 | 2.357 \u00b1 0.022 |\n|  | **+ DisCoRD (Ours)** | **0.434** \u00b1 0.007 | **0.657** \u00b1 0.005 | **0.781** \u00b1 0.005 | 0.204 \u00b1 0.011 | **2.779** \u00b1 0.022 | **1.928** \u00b1 0.059 |\n", "caption": "Table 7: Additional quantitative evaluation on the HumanML3D and KIT-ML test sets. \u00b1plus-or-minus\\pm\u00b1 indicates a 95% confidence interval. +DisCoRD indicates that the baseline model\u2019s decoder is replaced with our DisCoRD decoder.\nBold indicates the best result, while underscore refers the second best.", "description": "Table 7 presents a detailed quantitative comparison of different methods for text-to-motion generation on the HumanML3D and KIT-ML datasets.  The metrics used include Fr\u00e9chet Inception Distance (FID), which measures the realism of generated motions; R-Precision (Top 1, Top 2, Top 3), which evaluates the accuracy of retrieving the correct motion given a text description; MultiModal Distance (MM-Dist), which assesses how well the generated motions align with their textual descriptions; and MultiModality, which measures the diversity of generated motions.  The table includes results for several baseline methods and then shows the improved performance achieved when replacing the baseline decoder with the DisCoRD decoder.  The plus-or-minus values (\u00b1) indicate the 95% confidence interval around the reported metrics, reflecting the uncertainty in the measurements.  Bold font highlights the best performance for each metric, while underlined font indicates the second-best performance.", "section": "4. Experiments"}, {"content": "| Methods | Diversity \u2191 | BC \u2192 | \n|---|---|---| \n| TalkSHOW [58] | 0.821 | **0.872** | \n| +DisCoRD(Ours) | **0.919** | 0.876 | \n| ProbTalk [27] | 0.259 | 0.795 | \n| +DisCoRD(Ours) | **0.331** | **0.866** | ", "caption": "Table 8: Additional quantitative results on co-speech gesture generation. The results demonstrate that our method performs on par with, or surpasses, the baseline models.", "description": "Table 8 presents a quantitative comparison of DisCoRD against several state-of-the-art methods for co-speech gesture generation.  The metrics used assess both the accuracy of the generated gestures in reflecting the accompanying speech (faithfulness) and the naturalness of the generated movements.  The results show that DisCoRD either matches or exceeds the performance of existing methods across multiple evaluation metrics, indicating its effectiveness and robustness in this specific application.", "section": "4. Experiments"}, {"content": "| Methods | FID<sub>k</sub>\u2193 | FID<sub>g</sub>\u2193 | BAS \u2191 |\n|---|---|---|---|\n| Ground Truth | 17.10 | 10.60 | 0.2374 |\n| TM2D [9] | **19.01** | **20.09** | 0.2049 |\n| +DisCoRD(Ours) | 23.98 | 88.74 | **0.2190** |", "caption": "Table 9: Additional quantitative results on music-to-dance generation. The results demonstrate that, although our method shows performance degradation on FIDksubscriptFIDk\\mathrm{FID_{k}}roman_FID start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT and FIDgsubscriptFIDg\\mathrm{FID_{g}}roman_FID start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT, which are known to be unreliable, it achieves improvement in the Beat Align Score.", "description": "Table 9 presents a quantitative evaluation of music-to-dance generation performance.  It compares the proposed DisCoRD method against a baseline. The metrics used are FIDk (kinetic features), FIDg (geometric features), and Beat Align Score (BAS). While FIDk and FIDg are known to be unreliable, DisCoRD shows an improvement in the BAS, indicating better synchronization between the generated dance and the music.  This suggests that although some aspects of visual fidelity may not show significant improvement, the method still improves the overall alignment of the motion to the music.", "section": "4. Experiments"}]