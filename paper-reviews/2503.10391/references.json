{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is essential because it introduces CLIP, a crucial model for aligning visual and textual information, which many later models built upon."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper introduces a framework for diffusion models with transformers, showing how they can be scaled up to achieve high quality image and video generation."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces T5, a unified text-to-text transformer model, which is used in this paper to bridge the gap between LLM and MLLM."}, {"fullname_first_author": "A Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper is essential because it introduces the Transformer architecture, which is a foundational technology for many modern deep learning models used in image/video generation."}, {"fullname_first_author": "Yang Song", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), which have become a cornerstone of modern generative modeling for images and videos."}]}