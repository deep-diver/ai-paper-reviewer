{"references": [{"fullname_first_author": "A. G. Howard", "paper_title": "Mobilenets: Efficient convolutional neural networks for mobile vision applications", "publication_date": "2017-04-04", "reason": "This paper introduced MobileNets, a foundational architecture for efficient CNNs, which heavily influenced the design of lightweight models in this paper."}, {"fullname_first_author": "M. Sandler", "paper_title": "Mobilenetv2: Inverted residuals and linear bottlenecks", "publication_date": "2018-00-00", "reason": "This paper presented MobileNetV2, significantly improving upon the original MobileNet architecture and introducing inverted residual blocks, which are directly relevant to the proposed iRMB in this paper."}, {"fullname_first_author": "A. Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This work introduced Vision Transformers (ViTs), which are compared against and incorporated in the design of lightweight models in this paper, thus forming a critical component of the research."}, {"fullname_first_author": "Z. Liu", "paper_title": "Swin transformer: Hierarchical vision transformer using shifted windows", "publication_date": "2021-00-00", "reason": "This paper introduced the Swin Transformer architecture, a significant advancement in efficient Transformers; its windowed attention mechanism is compared to and improved upon in this research."}, {"fullname_first_author": "J. Zhang", "paper_title": "Rethinking mobile block for efficient attention-based models", "publication_date": "2023-00-00", "reason": "This paper, a precursor to the current work, introduced EMOv1, providing a baseline for comparison and laying the groundwork for the improvements presented in EMOv2."}]}