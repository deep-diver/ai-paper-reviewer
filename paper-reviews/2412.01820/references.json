{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-31", "reason": "This paper introduces Flamingo, a visual language model that serves as the backbone for the MatchVision model, demonstrating strong adaptability across various downstream tasks."}, {"fullname_first_author": "Gedas Bertasius", "paper_title": "Is space-time attention all you need for video understanding?", "publication_date": "2021-12-31", "reason": "This paper introduces the spatiotemporal attention mechanism, which is integrated into MatchVision to effectively leverage spatiotemporal information in soccer videos."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-12-31", "reason": "This paper introduces the vision transformer architecture, which is used in the MatchVision model for token embedding."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024-12-31", "reason": "This paper introduces the LLaMA-3 model, used in MatchVision to conduct event summarization on textual commentaries."}, {"fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2022-12-31", "reason": "This paper introduces LoRA, a low-rank adaptation technique used for efficient fine-tuning of the LLM decoder in MatchVision for commentary generation."}]}