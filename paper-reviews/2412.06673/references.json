{"references": [{"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A frontier large vision-language model with versatile abilities", "publication_date": "2023-08-12", "reason": "This paper introduces Qwen-VL, a large vision-language model that serves as a foundational model for ILLUME's visual understanding capabilities."}, {"fullname_first_author": "Haotian Liu", "paper_title": "LLaVA-NeXT: Improved reasoning, ocr, and world knowledge", "publication_date": "2024-00-00", "reason": "LLaVA-NeXT is a significant advancement in visual language models used as a baseline for ILLUME and is crucial for its training process."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-00-00", "reason": "This work proposes visual instruction tuning, a technique vital for ILLUME's efficient image-text alignment training."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models which forms the basis for ILLUME's image generation component."}, {"fullname_first_author": "Quan Sun", "paper_title": "Emu: Unified multimodal large language model", "publication_date": "2023-00-00", "reason": "Emu is among the first unified multimodal large language models that greatly influences the development of ILLUME's unified architecture."}]}