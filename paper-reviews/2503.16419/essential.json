{"importance": "This survey is important for researchers because it offers a structured overview of efficient reasoning, highlighting its impact on reducing computational costs and improving responsiveness. It opens avenues for exploration of efficient data and small models.", "summary": "LLMs survey: Model, output, and prompt-based strategies for efficient reasoning, mitigating \"overthinking\" for faster, cheaper, and real-world applications.", "takeaways": ["Efficient reasoning in LLMs can be achieved through model-based, output-based, and prompt-based strategies.", "Reducing reasoning length is key to lowering computational costs and improving the responsiveness of LLMs.", "The survey identifies and categorizes existing research, providing a structured overview of the field and highlighting areas for future work."], "tldr": "Large Language Models (LLMs) show great skills in complex tasks, but their reasoning process can be inefficient, leading to unnecessary computational costs. This is due to \u201coverthinking phenomenon\u201d, where models generate lengthy reasoning steps. To address this, the survey explores the concept of efficient reasoning, which aims to optimize reasoning length while maintaining the model's capabilities. Efficient reasoning seeks practical benefits like reduced costs and improved responsiveness. \n\nThis survey categorizes current approaches to achieving efficient reasoning in LLMs based on the inherent mechanism of LLMs: model-based, reasoning output-based, and input prompts-based strategies. It discusses efficient data for training, explores small language models, and covers evaluation methods. The authors maintain a public repository to track the research. This work aims to provide insights that can guide future research and the development of reasoning-driven applications.", "affiliation": "Rice University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.16419/podcast.wav"}