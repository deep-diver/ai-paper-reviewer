[{"content": "| Method | 3D Generation |  |  |  | 4D Generation |  |  |  |\n|---|---|---|---|---|---|---|---|---|\n|  | Object | Scene | Single View | Multi-View | Object | Scene | Single View | Multi-View |\n|---|---|---|---|---|---|---|---|---|\n| IM-3D | \u2713 | \u2717 | \u2713 | \u2717 | \u2717 | \u2717 | \u2717 | \u2717 |\n| RealmDreamer | \u2717 | \u2713 | \u2713 | \u2717 | \u2717 | \u2717 | \u2717 | \u2717 |\n| ReconFusion | \u2713 | \u2713 | \u2717 | \u2713 | \u2717 | \u2717 | \u2717 | \u2717 |\n| CAT3D | \u2713 | \u2713 | \u2713 | \u2713 | \u2717 | \u2717 | \u2717 | \u2717 |\n| Animate124 | \u2717 | \u2717 | \u2717 | \u2717 | \u2713 | \u2717 | \u2713 | \u2717 |\n| CameraCtrl | \u2717 | \u2717 | \u2717 | \u2717 | \u2717 | \u2713 | \u2713 | \u2717 |\n| SV4D | \u2713 | \u2717 | \u2713 | \u2717 | \u2713 | \u2717 | \u2713 | \u2713 |\n| CamCo | \u2717 | \u2713 | \u2713 | \u2717 | \u2717 | \u2713 | \u2713 | \u2717 |\n| Gen\ud835\udcb3D (Ours) | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |", "caption": "Table 1: Comparison among the settings of previous works.", "description": "This table compares the capabilities of various existing methods for 3D and 4D scene generation.  It shows which methods support generation with object-level detail, scene-level detail, single-view generation, and multi-view generation for both 3D and 4D scenarios.", "section": "1 INTRODUCTION"}, {"content": "| Method | FID \u2193 | FVD \u2193 |\n|---|---|---|\n| MotionCtrl [Wang et al. (2024)](https://arxiv.org/html/2411.02319/bib.bib57) | 118.14 | 1464.08 |\n| CameraCtrl [He et al. (2024)](https://arxiv.org/html/2411.02319/bib.bib13) | 138.64 | 1470.59 |\n| GenXD (Single View) | 101.78 | 1208.93 |\n| GenXD (3 Views) | **55.64** | **490.50** |", "caption": "Table 4: Quantitative comparison of few-view 3D reconstruction on both in-distribution (Re10K) and out-of-distribution (LLFF) datasets.", "description": "This table presents a quantitative comparison of the performance of few-view 3D reconstruction methods on two datasets: Re10K (in-distribution) and LLFF (out-of-distribution).  It shows the PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity) scores for each method on each dataset.  Higher PSNR and SSIM scores indicate better reconstruction quality, while lower LPIPS scores indicate that the reconstructed images are perceptually more similar to the ground truth.  The comparison allows for assessment of how well the methods generalize to unseen data.", "section": "5.3 3D GENERATION"}, {"content": "| Method | Time \u2193 | CLIP-I \u2191 |\n|---|---|---|\n| Zero-1-to-3-V [Liu et al. (2023b)](https://arxiv.org/html/2411.02319/bib.bib27) | 4 hrs | 79.25 |\n| RealFusion-V [Melas-Kyriazi et al. (2023)](https://arxiv.org/html/2411.02319/bib.bib32) | 5 hrs | 80.26 |\n| Animate124 [Zhao et al. (2023)](https://arxiv.org/html/2411.02319/bib.bib65) | 7 hrs | 85.44 |\n| Gen\ud835\udcb3D (Single View) | **4 min** | **90.32** |", "caption": "Table 5: Ablation studies on motion disentangle.", "description": "This table presents the results of ablation studies conducted to evaluate the effectiveness of the motion disentanglement module in the GenXD model.  The ablation studies assess the impact of removing the motion disentanglement component on the model's performance in generating both 3D and 4D scenes, specifically examining metrics like PSNR, SSIM, LPIPS, FID, and FVD across different datasets (Cam-DAVIS and Re10K).  The results help quantify the contribution of the motion disentanglement technique to the overall quality of generated images and videos.", "section": "5.4 Ablation Study"}, {"content": "| Method | Re10K PSNR\u2191 | Re10K SSIM\u2191 | Re10K LPIPS\u2193 | LLFF PSNR\u2191 | LLFF SSIM\u2191 | LLFF LPIPS\u2193 |\n|---|---|---|---|---|---|---|\n| Zip-NeRF [Barron et al. (2023)] | 20.58 | 0.729 | 0.382 | 14.26 | 0.327 | 0.613 |\n| Zip-NeRF + GenXD | **25.40** | **0.858** | **0.223** | **19.39** | **0.556** | **0.423** |\n| 3D-GS [Kerbl et al. (2023)] | 18.84 | 0.714 | 0.286 | 17.35 | 0.489 | 0.335 |\n| 3D-GS + GenXD | **23.13** | **0.808** | **0.202** | **19.43** | **0.554** | **0.312** |", "caption": "Table 6: Quantitative comparison of image-to-3D generation on examples from Wang & Shi (2023).", "description": "This table presents a quantitative comparison of different methods for generating 3D models from a single image.  The comparison is based on examples from the Wang & Shi (2023) paper and uses the CLIP-I (Image-text similarity) metric to evaluate the quality of the generated 3D models.  It shows the model type (3D or 3D&4D), the generation time in minutes, and the CLIP-I score for each method, allowing for a direct comparison of performance across different approaches.", "section": "5.3 3D GENERATION"}, {"content": "| Method | Re10K PSNR \u2191 | Re10K SSIM \u2191 | Re10K LPIPS \u2193 | LLFF PSNR \u2191 | LLFF SSIM \u2191 | LLFF LPIPS \u2193 | Cam-DAVIS FID \u2193 | Cam-DAVIS FVD \u2193 |\n|---|---|---|---|---|---|---|---|---|\n| w.o. Motion Disentangle | 20.75 | 0.635 | 0.362 | 16.89 | 0.397 | 0.560 | 122.73 | 1488.47 |\n| GenXD | 22.96 | 0.774 | 0.341 | 17.94 | 0.463 | 0.546 | 101.78 | 1208.93 |", "caption": "Table 7: Ablation studies on camera conditioning scheme and joint training.", "description": "This table presents the results of ablation experiments conducted to evaluate the impact of different design choices within the GenXD model on its performance. Specifically, it examines the effectiveness of using camera poses as conditions and the effect of jointly training the model on both 3D and 4D data.  The metrics used to assess performance include Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), Fr\u00e9chet Inception Distance (FID), and Kinetic Fr\u00e9chet Inception Distance (K-FID) on the Re10k and LLFF datasets and the Cam-DAVIS benchmark.", "section": "5.4 Ablation Study"}]