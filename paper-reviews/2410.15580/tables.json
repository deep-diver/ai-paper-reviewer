[{"figure_path": "2410.15580/tables/table_5_0.md", "caption": "Inductive and deductive accuracy difference \u0394.", "description": "This table presents the results of an experiment investigating whether Large Language Models (LLMs) leverage partial products in arithmetic learning.  Two LLMs, Gemma-2-2B and Llama-3.1-8B, were fine-tuned on two-digit multiplication tasks using four different calculation methods (Standard, Lattice, Repetitive, Egyptian). The table shows the percentage change in accuracy for two tasks:  'Task \u2192 Partial P.' (accuracy on identifying partial products after fine-tuning on the main multiplication task) and 'Partial P. \u2192 Task' (accuracy on the main multiplication task after fine-tuning on partial product identification).  Positive values indicate improved accuracy, negative values indicate decreased accuracy.  The results reveal that while fine-tuning on the multiplication task improved the models' ability to identify partial products in some cases, fine-tuning on partial products did not improve performance on the main multiplication task, suggesting LLMs may not utilize partial products in arithmetic learning.", "section": "Examining Partial Product in Arithmetic Learning"}, {"figure_path": "2410.15580/tables/table_5_1.md", "caption": "Table 2: Diagnostic sets with four calculation methods.", "description": "This table presents the diagnostic sets used to probe large language models' (LLMs) understanding of partial products in arithmetic.  It lists four different multiplication calculation methods: Standard Multiplication, Repetitive Addition, Lattice Method, and Egyptian Multiplication. For each method, it provides a symbolic representation of the diagnostic set (P),  which consists of specific partial product computations related to the method. These diagnostic sets are used to evaluate whether LLMs utilize partial products during arithmetic learning by assessing their accuracy on these specific computations.", "section": "5.2 Examining Partial Product in Arithmetic Learning"}, {"figure_path": "2410.15580/tables/table_7_0.md", "caption": "Table 3: Label space statistics with different rule perturbations. H(L) represents the entropy of the label space, and |L| is the size of the label space. {C}i=1 represents all positions in output digits.", "description": "This table presents the label space statistics for different rule perturbations applied to addition and multiplication tasks.  For each task (addition with various constant offsets and modulo operations; multiplication with scaling factors and modulo operations), it shows the label space entropy H(L), the cardinality |L| of the label space, and the entropy H(C) of each individual digit position C1 through C5. The table demonstrates how altering the arithmetic rules affects the entropy and size of the output space.", "section": "6.3 Subgroup Complexity: Label Space Matters in the Final Stage"}, {"figure_path": "2410.15580/tables/table_7_1.md", "caption": "Table 4: Test Accuracy difference \u0394 on perturbed addition and multiplication.", "description": "This table presents the accuracy difference (\u0394) in percentage points for addition and multiplication tasks, comparing the model performance after applying different rule perturbations.  The perturbations involve adding constants (1, 15, 115) to the addition operation and multiplying by constants (2, 4, 8) for multiplication.  Additionally, modular arithmetic is used with various moduli (100, 50, 10) for both operations.  The results are shown separately for Gemma-2-2B and Llama-3.1-8B, demonstrating the impact of these rule perturbations on model accuracy.  Positive values indicate improved accuracy after perturbation, while negative values show decreased accuracy.", "section": "6.3 Subgroup Complexity: Label Space Matters in the Final Stage"}, {"figure_path": "2410.15580/tables/table_12_0.md", "caption": "Table 5: Label space statistics with different format perturbations. H(L) represents the entropy of the space, and |L| is the size of the space. {Cj}=1 represents all possible output digits.", "description": "This table presents label space statistics with different format perturbations applied to addition and multiplication tasks.  For each arithmetic operation (addition or multiplication) and format perturbation (natural language, random string, and disturbed digits), the table shows the label space entropy H(L), and the size of the label space |L|.  The format column illustrates the different input formats used, highlighting variations in natural language, random strings and distorted digits. The entropy values (H(L)) reflect the uncertainty or variability in the output space for each condition. The final two columns provide the number of output digits ({Cj}=1) and the total entropy considering all output digits.", "section": "A.2 Format Perturbations in Arithmetic Tasks"}, {"figure_path": "2410.15580/tables/table_12_1.md", "caption": "Table 6: Test Accuracy difference \u0394 on perturbed addition and multiplication.", "description": "This table presents the results of an experiment assessing the robustness of two large language models (LLMs), Gemma-2-2B and Llama-3.1-8B, to various input format perturbations in arithmetic tasks. The experiment used three types of perturbations: Natural Language (NL), Random String (RS), and Disturbed Digits (DD).  For both addition and multiplication tasks, the impact of these perturbations on model accuracy is shown, revealing the LLMs' performance under different input formats while maintaining consistent output labels. The results indicate that the models remain largely unaffected by these perturbations.", "section": "5.2 Examining Partial Product in Arithmetic Learning"}, {"figure_path": "2410.15580/tables/table_13_0.md", "caption": "Table 1: Inductive and deductive accuracy difference \u0394.", "description": "This table presents the results of an experiment investigating whether large language models (LLMs) leverage partial products in arithmetic learning. Two LLMs, Gemma-2-2B and Llama-3.1-8B, were fine-tuned on two-digit multiplication tasks using four different calculation methods: standard multiplication, repetitive addition, the lattice method, and Egyptian multiplication.  The table shows the change in accuracy (\u0394) for each model and method in two scenarios: 1) when the models were initially trained on the multiplication task and then tested on identifying partial products (Task \u2192 Partial Products), and 2) when the models were initially trained on identifying partial products and then tested on the multiplication task (Partial Products \u2192 Task).  Positive values indicate improved accuracy after fine-tuning, while negative values indicate decreased accuracy. The results reveal that while fine-tuning improved the ability to identify partial products (inductive), it did not translate to improved performance on the multiplication task (deductive).", "section": "Examining Partial Product in Arithmetic Learning"}]