[{"figure_path": "2410.15580/tables/table_5_0.html", "caption": "Table 1: Inductive and deductive accuracy difference \u0394.", "description": "This table shows the inductive and deductive accuracy differences in identifying tasks and partial products for two LLMs (Gemma-2-2B and Llama-3.1-8B) across four multiplication calculation methods.", "section": "Examining Partial Product in Arithmetic Learning"}, {"figure_path": "2410.15580/tables/table_5_1.html", "caption": "Table 2: Diagnostic sets with four calculation methods.", "description": "The table presents the diagnostic sets used to probe language models' partial products in four different multiplication calculation methods.", "section": "5.2 Examining Partial Product in Arithmetic Learning"}, {"figure_path": "2410.15580/tables/table_7_0.html", "caption": "Table 3: Label space statistics with different rule perturbations. H(L) represents the entropy of the label space, and |L| is the size of the label space. {C}i=1 represents all positions in output digits.", "description": "Table 3 shows the label space entropy and size for different rule perturbations applied to addition and multiplication tasks, highlighting the impact of rule variations on task complexity.", "section": "6.3 Subgroup Complexity: Label Space Matters in the Final Stage"}, {"figure_path": "2410.15580/tables/table_7_1.html", "caption": "Table 4: Test Accuracy difference \u0394 on perturbed addition and multiplication.", "description": "Table 4 presents the accuracy difference (\u0394) in percentage for addition and multiplication tasks, showing the impact of rule perturbation on the performance of Gemma-2-2B and Llama-3.1-8B language models.", "section": "6.3 Subgroup Complexity: Label Space Matters in the Final Stage"}, {"figure_path": "2410.15580/tables/table_12_1.html", "caption": "Table 6: Test Accuracy difference \u0394 on perturbed addition and multiplication.", "description": "Table 6 presents the accuracy difference (\u0394) in percentage for addition and multiplication tasks with different input format perturbations (Natural Language, Random String, and Disturbed Digits) using Gemma-2-2B and Llama-3.1-8B language models.", "section": "5 Are Large Language Models Implicit Calculators?"}, {"figure_path": "2410.15580/tables/table_13_0.html", "caption": "Table 1: Inductive and deductive accuracy difference \u0394.", "description": "The table presents the changes in accuracy for identifying partial products and solving arithmetic tasks before and after fine-tuning LLMs on different sets of diagnostic tasks, comparing the performance across four multiplication calculation methods.", "section": "Examining Partial Product in Arithmetic Learning"}]