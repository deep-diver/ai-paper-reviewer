[{"figure_path": "2410.13863/charts/charts_4_0.png", "caption": "Figure 2: Autoregressive models with different orders. (a) A raster-order autoregressive model predicts one next token based on the known ones, implemented using a GPT-like transformer with causal attention. (b) A random-order autoregressive model predicts one or multiple tokens simultaneously given a random order, implemented using a BERT-like transformer with bidirectional attention.", "description": "The chart compares and contrasts raster-order and random-order autoregressive models in terms of their token prediction mechanisms and attention strategies.", "section": "4 IMPLEMENTATION"}, {"figure_path": "2410.13863/charts/charts_7_0.png", "caption": "Figure 5: Validation loss scales as a power-law with model size. The validation loss is evaluated on 30K images randomly sampled from the MS-COCO 2014 training set. The x and y axes are in log-scale. The change in y is relatively small for each plot, making the log-scale alike linear-scale.", "description": "The chart displays the scaling behavior of validation loss across four different autoregressive image generation model variants with respect to model size.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_7_1.png", "caption": "Figure 6: Random-order models using continuous tokens (orange) achieve the best performance on evaluation metrics. FID (lower is better) is evaluated on 30K images randomly sampled from the MS-COCO 2014 training set, while the GenEval overall score (higher is better) is assessed using the 553 prompts provided by the official benchmark, with four images generated for each prompt. Among all models, random-order models on continuous tokens consistently show an improvement in evaluation metrics as model size increases and achieve the best FID and GenEval scores.", "description": "The chart displays the scaling behavior of four different autoregressive image generation model variants in terms of FID and GenEval scores, showing that random-order models using continuous tokens perform best.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_8_0.png", "caption": "Figure 7: Validation losses and evaluation performance scale with increasing training steps and computes. We use random-order models with continuous tokens. Results for other autoregressive variants are included in the appendix. The training compute is computed as model GFLOPs \u00d7 batch size \u00d7 training steps \u00d7 3, where the factor of 3 accounts for the backward pass being approximately twice as compute-intensive as the forward pass.", "description": "The chart displays the scaling behavior of validation loss, FID, and GenEval scores as functions of training steps and compute for different model sizes of Fluid, showing consistent improvements in both validation loss and evaluation performance with increased training steps and compute.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_8_1.png", "caption": "Figure 8: Validation loss and evaluation metrics are highly correlated. We use random-order models with continuous tokens. The Pearson correlation coefficients for FID and GenEval scores are 0.917 and -0.931, respectively. We also observe that the linear correlation slightly weakens and becomes less pronounced for the 3.1B model.", "description": "The chart displays the strong correlation between validation loss and FID/GenEval scores for Fluid models of varying sizes, indicating a near-linear relationship.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_15_0.png", "caption": "Figure 5: Validation loss scales as a power-law with model size. The validation loss is evaluated on 30K images randomly sampled from the MS-COCO 2014 training set. The x and y axes are in log-scale. The change in y is relatively small for each plot, making the log-scale alike linear-scale.", "description": "The chart displays the scaling behavior of validation loss across different model sizes, showing a consistent linear relationship in log space.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_15_1.png", "caption": "Figure 5: Validation loss scales as a power-law with model size. The validation loss is evaluated on 30K images randomly sampled from the MS-COCO 2014 training set. The x and y axes are in log-scale. The change in y is relatively small for each plot, making the log-scale alike linear-scale.", "description": "The chart shows that validation loss consistently scales with model size across four autoregressive image generation model variants, exhibiting a linear relationship in log space.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_15_2.png", "caption": "Figure 5: Validation loss scales as a power-law with model size. The validation loss is evaluated on 30K images randomly sampled from the MS-COCO 2014 training set. The x and y axes are in log-scale. The change in y is relatively small for each plot, making the log-scale alike linear-scale.", "description": "The chart displays the scaling behavior of validation loss across four different autoregressive image generation models with varying model sizes.", "section": "5.1 SCALING BEHAVIORS"}, {"figure_path": "2410.13863/charts/charts_16_0.png", "caption": "Figure 13: Validation loss and FID w.r.t. training FLOPs for raster-order models with discrete tokens.", "description": "The chart visualizes the scaling behavior of four autoregressive image generation model variants across different metrics (single object, two objects, counting, colors, position, color attribution) as model size increases.", "section": "5.1 Scaling Behaviors"}]