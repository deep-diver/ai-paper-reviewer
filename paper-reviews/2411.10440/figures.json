[{"figure_path": "https://arxiv.org/html/2411.10440/x1.png", "caption": "Figure 1: Performance of LLaVA-o1\u00a0and other models across six multimodal reasoning benchmarks. Although LLaVA-o1\u00a0is fine-tuned from the Llama-3.2-11B-Vision-Instruct [40] model (which has the lowest average score), it outperforms many larger open-source models and even some closed-source models. Detailed benchmark results are shown in Table\u00a07.", "description": "This figure compares the performance of LLaVA-01 with several other vision-language models (VLMs) across six established multimodal reasoning benchmarks.  Despite being fine-tuned from a smaller, less performant base model (Llama-3.2-11B-Vision-Instruct), LLaVA-01 achieves surprisingly high average scores. Notably, it surpasses numerous larger open-source VLMs and even some closed-source models, highlighting its effectiveness in complex reasoning tasks.  For detailed numerical results, refer to Table 7 in the paper.", "section": "6 Multimodal Reasoning Benchmarks"}, {"figure_path": "https://arxiv.org/html/2411.10440/x2.png", "caption": "Figure 2: Comparison of the base model and LLaVA-o1. As shown, the base model Llama-3.2-11B-Vision-Instruct exhibits obvious flaws in reasoning, with several errors occurring throughout the reasoning process. In contrast, LLaVA-o1\u00a0begins by outlining the problem, interprets relevant information from the image, proceeds with a step-by-step reasoning process, and ultimately reaches a well-supported conclusion.", "description": "This figure showcases a comparison between the reasoning capabilities of two models: Llama-3.2-11B-Vision-Instruct (the base model) and LLaVA-01.  Two example problems are presented, each involving visual reasoning. The base model demonstrates significant flaws and errors in its reasoning process, often producing inaccurate or illogical steps.  In contrast, LLaVA-01 exhibits a systematic and structured approach. It starts by summarizing the problem, then extracts relevant information from the image, meticulously outlines a step-by-step reasoning process, and finally arrives at a logically sound and well-supported conclusion. This highlights LLaVA-01's superior ability to perform systematic and structured reasoning compared to the base model.", "section": "Comparison of the base model and LLaVA-01"}, {"figure_path": "https://arxiv.org/html/2411.10440/x3.png", "caption": "Figure 3: Process flow for generating the LLaVA-o1-100k dataset. We prompt GPT-4o to generate responses in separate stages, and filter its outputs to ensure quality.", "description": "This figure illustrates the process of creating the LLaVA-01-100k dataset.  The process starts with a question and involves four stages: 1. Summary: GPT-40 summarizes the question and outlines the overall approach. 2. Caption: If an image is part of the question, GPT-40 describes the relevant visual elements. 3. Reasoning: GPT-40 outlines a step-by-step logical reasoning process to answer the question. 4. Conclusion: GPT-40 provides the final answer.  The outputs from each stage are then filtered to ensure high quality before being included in the dataset.", "section": "3. Proposed Method"}, {"figure_path": "https://arxiv.org/html/2411.10440/x4.png", "caption": "Figure 4: An illustration of inference approaches. Best-of-N search generates N\ud835\udc41Nitalic_N complete responses and selects the best one among them; Sentence-level Beam Search generates multiple candidate options for each sentence and chooses the best one. In contrast, our Stage-level Beam Search generates candidates for each reasoning stage (e.g., summary, caption, reasoning, and conclusion) and selects the best option at each stage. Best-of-N search operates at a coarse level, while Sentence-level Beam Search is overly granular, and our method achieves an optimal balance and achieves the best performance.", "description": "Figure 4 illustrates three different inference time scaling methods: Best-of-N search, sentence-level beam search, and the proposed stage-level beam search.  Best-of-N search generates multiple complete answers and selects the single best one. This approach is computationally expensive and may not be effective when responses vary widely in quality. Sentence-level beam search generates multiple options for each sentence and chooses the best among them. This approach is quite granular, focusing on small portions of the text and potentially missing important contextual relationships. In contrast, the paper's proposed stage-level beam search generates candidates for each stage of the reasoning process (summary, caption, reasoning, and conclusion) and selects the best option at each stage. By focusing on the broader reasoning structure and checking the quality of each step, it offers a better balance between efficiency and accuracy. The figure highlights that the stage-level approach achieves superior performance compared to the other two methods due to its optimal granularity.", "section": "3.2 Effective Inference Time Scaling using Stage-level Beam Search"}, {"figure_path": "https://arxiv.org/html/2411.10440/x5.png", "caption": "Figure 5: Comparison of LLaVA-o1\u00a0performance with and without stage-level beam search. Our stage-level beam search is effective in selecting better reasoning during model inference.", "description": "The figure showcases a comparison of LLaVA-01's performance on a visual question answering task, both with and without the application of a stage-level beam search.  Two examples of question-answering tasks are presented: one involving a simple counting problem and another involving a physics problem that necessitates a step-by-step reasoning process.  For each problem, the figure displays the base model's answer (Llama-3.2-11B-Vision-Instruct) and LLaVA-01's answer. LLaVA-01's answer shows the model's step-by-step reasoning process through four distinct stages: summarization, captioning, reasoning, and conclusion. The base model's answer is presented as a single step without explicit reasoning, showing its limitations in handling complex reasoning tasks. In contrast, LLaVA-01 demonstrates more robust reasoning by outlining the problem, interpreting relevant information from the image, engaging in structured step-by-step reasoning, and finally, providing well-supported conclusions.  The comparison highlights that the stage-level beam search in LLaVA-01 is crucial for effective inference, enabling more accurate and systematic solutions to complex problems.", "section": "3.2 Effective Inference Time Scaling using Stage-level Beam Search"}]