[{"figure_path": "2410.18860/figures/figures_2_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "The figure illustrates the DeCoRe workflow, showing how contrasting the outputs of a base LLM and a masked LLM, guided by conditional entropy, leads to more accurate predictions by mitigating hallucinations.", "section": "2 DeCoRe: Decoding by Contrasting Retrieval Heads"}, {"figure_path": "2410.18860/figures/figures_8_0.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "Figure 3 shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct with DeCoRe entropy across various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_8_1.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct model using DeCoReEntropy across various faithfulness, factuality and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_8_2.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct with DeCoReentropy on various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_18_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "This figure illustrates the workflow of DeCoRe, showing how it contrasts the outputs of a base LLM and a masked LLM to mitigate hallucinations.", "section": "2 DECORE: DECODING BY CONTRASTING RETRIEVAL HEADS"}, {"figure_path": "2410.18860/figures/figures_20_0.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct with DeCoReentropy on several faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_25_0.png", "caption": "Figure 8: Correlation between the number of masked random heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "Figure 8 shows the correlation between the number of masked random heads and the performance of Llama3-8B-Instruct with DeCoReentropy across various tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_35_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "The figure illustrates the DeCoRe workflow, showing how contrasting the outputs of a base LLM and a masked LLM, guided by conditional entropy, leads to more accurate predictions.", "section": "2 DECORE: DECODING BY CONTRASTING RETRIEVAL HEADS"}]