[{"figure_path": "2410.18860/figures/figures_2_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "The figure illustrates the DeCoRe workflow, showing how contrasting the outputs of a base LLM and a masked LLM, guided by conditional entropy, improves the accuracy of predictions.", "section": "2 DECORE: DECODING BY CONTRASTING RETRIEVAL HEADS"}, {"figure_path": "2410.18860/figures/figures_8_0.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct model using DeCoRe entropy across various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_8_1.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct with DeCoReentropy on various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "3.1 Datasets and Evaluation Metrics"}, {"figure_path": "2410.18860/figures/figures_8_2.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "Figure 3 shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct model using DeCoReentropy on various tasks, showing negative correlations for some tasks and positive correlations for others.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_18_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "The figure illustrates the workflow of DeCoRe, a decoding strategy that contrasts the outputs of a base LLM and a masked LLM to mitigate hallucinations.", "section": "2 DECORE: DECODING BY CONTRASTING RETRIEVAL HEADS"}, {"figure_path": "2410.18860/figures/figures_20_0.png", "caption": "Figure 3: Correlation between the number of masked retrieval heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "The figure shows the correlation between the number of masked retrieval heads and the performance of Llama3-8B-Instruct with DeCoReentropy across various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_25_0.png", "caption": "Figure 8: Correlation between the number of masked random heads and performance of Llama3-8B-Instruct with DeCoReentropy on each task. The correlations are quantified by the Pearson Correlation Coefficient r for each plot. Detailed results are listed in Table 14 and Table 16.", "description": "Figure 8 shows the correlation between the number of masked random heads and the performance of Llama3-8B-Instruct with DeCoReentropy across various faithfulness, factuality, and chain-of-thought reasoning tasks.", "section": "Effect of Retrieval Head Masking on Task Performance of DeCoRe"}, {"figure_path": "2410.18860/figures/figures_35_0.png", "caption": "Figure 1: Overview of the DeCoRe workflow. Given the same input, the base LLM (LLMbase) and the variant with masked retrieval heads (LLMmasked) predict the next token. An uncertainty estimation is applied to the base model's output using conditional entropy: higher conditional entropy increases the contrastive factor (a), penalising predictions that align with the LLMmasked. The final prediction is selected based on weighted contrastive decoding of the outputs from both models, leading to a more grounded response.", "description": "The figure illustrates the DeCoRe workflow, showing how contrasting the outputs of a base LLM and a masked LLM, guided by conditional entropy, leads to more accurate predictions.", "section": "2 DECORE: DECODING BY CONTRASTING RETRIEVAL HEADS"}]