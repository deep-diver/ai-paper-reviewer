[{"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/intro.png", "caption": "Figure 1: Comparison between a baseline agent, manually written knowledge, and Mobile-Agent-V. The baseline agent, lacking operation knowledge, struggles to complete the task, requiring excessive steps and still failing. Manually written knowledge requires documentation and iterative verification. In contrast, Mobile-Agent-V leverages operation videos, requiring only execution and recording, making knowledge injection far more efficient.", "description": "This figure compares three approaches to mobile device automation: a baseline agent without operational knowledge, a manually-written knowledge base, and the proposed Mobile-Agent-V.  The baseline agent fails to complete the task, requiring many steps. Manually creating a knowledge base is time-consuming and requires repeated testing.  Mobile-Agent-V, in contrast, uses video demonstrations for knowledge injection, making the process significantly more efficient. Users simply record a video of the task, and the system learns from it, reducing effort and increasing efficiency.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/framework.png", "caption": "Figure 2: The framework of Mobile-Agent-V.", "description": "The figure illustrates the workflow of Mobile-Agent-V, a framework designed for mobile device automation using video guidance.  It shows how video input (V) is processed through uniform sampling and redundancy removal to create keyframes (F'). A sliding window (Vw) selects a subset of keyframes for the decision agent (Da), which generates actions (Oi) based on the window, video instructions (Iv), device state (Di), user instructions (Iu), and historical operations.  The deep-reflection agent (Ra) refines these actions (ROi), which are then executed on the device, updating its state (Di+1). Finally, the video agent (Va) determines the next window's starting point (Si+1), dynamically adjusting the observation scope as the task progresses.", "section": "3 Mobile-Agent-V"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/CD.png", "caption": "Figure 3: Comparison of video-misaligned instructions and video-aligned instructions. The in-domain means that the video instruction is consistent with the user instruction, and the cross-domain instruction is inconsistent.", "description": "This figure compares the performance of Mobile-Agent-V on two types of instructions: video-aligned and video-misaligned.  Video-aligned instructions refer to scenarios where the instructions given to the user and the demonstrated actions in the video are consistent (in-domain).  Video-misaligned instructions, conversely, represent cases where the instructions and the video demonstration are inconsistent (cross-domain). The figure shows how well Mobile-Agent-V generalizes beyond exact video matches to instructions.  It displays success rate (SR), completion rate (CR), decision accuracy (DA), and step count for basic, normal, and advanced instructions under both aligned and misaligned conditions.", "section": "4.4 Analysis"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/window.png", "caption": "Figure 4: Comparison of different sliding window sizes.", "description": "This figure shows the effect of different sliding window sizes on the performance of Mobile-Agent-V.  The x-axis represents different window sizes, and the y-axis represents the performance metrics including success rate (SR), completion rate (CR), decision accuracy (DA), and step count (Step) for three different instruction types (Basic, Normal, and Advanced). The results indicate that larger window sizes generally improve performance, but beyond a certain point, adding more frames to the window starts to negatively affect the model's performance, highlighting the importance of balancing temporal context in the model.", "section": "4.4.2 Impact of Window Size"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/keyframe.png", "caption": "Figure 5: Comparison of different keyframe quality.", "description": "This figure compares the performance of Mobile-Agent-V using different keyframe extraction methods.  It contrasts the results of using manually selected high-quality keyframes against the automatically generated keyframes produced by the model's uniform sampling and filtering technique.  The goal is to illustrate the impact of keyframe quality on the model's performance, specifically in terms of Success Rate (SR), Completion Rate (CR), Decision Accuracy (DA), and the number of Steps taken to complete a task.  The manual selection method serves as an upper bound of performance.", "section": "4.4.3 Impact of Keyframe Quality"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/DR.png", "caption": "Figure 6: Comparison of w/o DR and w/ DR across different instructions.", "description": "This figure compares the performance of Mobile-Agent-V with and without the deep-reflection (DR) agent across different instruction difficulty levels (Basic, Normal, Advanced).  It displays the success rate (SR), completion rate (CR), decision accuracy (DA), and step count for each condition and difficulty level, illustrating the impact of the DR agent on the overall performance of the model.  The bars visually represent the quantitative differences in these metrics between the two versions of the model.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.17110/extracted/6219047/case.jpg", "caption": "Figure 7: A complete execution case of Mobile-Agent-V. The decision agent initially makes an incorrect action, but the deep-reflection agent verifies the operation video, compares the device state, and corrects the action.", "description": "This figure illustrates a scenario where the decision agent in Mobile-Agent-V initially makes an incorrect action. However, the deep-reflection agent intervenes by verifying the actions against the video instructions and the current device state.  The deep-reflection agent identifies the discrepancy and provides the corrected action. The video agent also dynamically adjusts the sliding window, updating the context for the decision-making process. This example demonstrates the collaborative functionality of Mobile-Agent-V's multi-agent architecture in ensuring accurate and efficient task completion.", "section": "3 Mobile-Agent-V"}]