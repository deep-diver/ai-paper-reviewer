{"references": [{"fullname_first_author": "Pan Lu", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts.", "publication_date": "2023-10-02", "reason": "This paper introduces the MathVista dataset, a key benchmark used for evaluating mathematical reasoning in visual contexts, making it highly relevant."}, {"fullname_first_author": "Chaoqun He", "paper_title": "Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems.", "publication_date": "2024-02-14", "reason": "This paper introduces OlympiadBench, another crucial dataset specifically designed for evaluating performance on Olympiad-level scientific problems, thus making it a crucial benchmark."}, {"fullname_first_author": "Yunzhuo Hao", "paper_title": "Can mllms reason in multimodality? emma: An enhanced multimodal reasoning benchmark.", "publication_date": "2025-01-05", "reason": "This paper introduces EMMA, an enhanced multimodal reasoning benchmark to test models in complex scientific problems, which is one of the three benchmarks used in the main paper."}, {"fullname_first_author": "Lei Wang", "paper_title": "T-sciq: Teaching multimodal chain-of-thought reasoning via large language model signals for science question answering.", "publication_date": "2024-01-01", "reason": "This paper is important because it directly tackles multimodal chain-of-thought reasoning, an approach used by the MAPS framework to improve scientific question answering."}, {"fullname_first_author": "Davide Caffagni", "paper_title": "The revolution of multimodal large language models: a survey.", "publication_date": "2024-02-12", "reason": "This paper provides a survey of multimodal large language models, giving context to the models and techniques used to create the MAPS framework and for comparison in the study."}]}