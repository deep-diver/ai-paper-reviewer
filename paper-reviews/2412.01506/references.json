{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a powerful vision foundation model used for encoding visual features in the proposed SLAT representation, significantly enhancing the model's ability to capture detailed appearance information."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This foundational paper on diffusion models provides the theoretical basis for the rectified flow transformers used in the proposed method, enabling high-quality and efficient 3D asset generation."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper introduces the rectified flow transformer architecture, a key component of the proposed method that allows for efficient and high-quality 3D asset generation across various output formats."}, {"fullname_first_author": "Matt Deitke", "paper_title": "Objaverse: A universe of annotated 3d objects", "publication_date": "2023-06-18", "reason": "This paper introduces the Objaverse dataset, a large-scale 3D asset dataset used for training the proposed model. The dataset's size and diversity are crucial for achieving high-quality 3D asset generation."}, {"fullname_first_author": "Ben Poole", "paper_title": "DreamFusion: Text-to-3D using 2D diffusion", "publication_date": "2023-01-01", "reason": "This pioneering work demonstrates the effectiveness of leveraging pre-trained 2D diffusion models for 3D generation, inspiring the approach of integrating a powerful vision foundation model into the proposed framework."}]}