{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model for vision-language representation learning that the current research builds upon."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "Laion-400M: Open dataset of clip-filtered 400 million image-text pairs", "publication_date": "2021-07-01", "reason": "This paper introduces LAION-400M, a large-scale dataset crucial for training and evaluating vision-language models, which the current research uses as a baseline."}, {"fullname_first_author": "Minwoo Byeon", "paper_title": "COYO-700M: Image-text pair dataset", "publication_date": "2022-07-01", "reason": "This paper provides another large-scale image-text dataset that is used to demonstrate the scalability of the approach presented in the current research."}, {"fullname_first_author": "Hugo Lauren\u00e7on", "paper_title": "OBELICS: An open web-scale filtered dataset of interleaved image-text documents", "publication_date": "2024-07-01", "reason": "This paper introduces OBELICS, a novel dataset of interleaved image-text documents used as the primary data source in the current work."}, {"fullname_first_author": "Kaicheng Yang", "paper_title": "Unicom: Universal and compact representation learning for image retrieval", "publication_date": "2023-07-01", "reason": "This paper presents Unicom, a method for efficient feature quantization that is used in the hierarchical retrieval method of the current research."}]}