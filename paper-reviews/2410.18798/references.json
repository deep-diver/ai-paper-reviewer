{"references": [{" publication_date": "2022", "fullname_first_author": "Ahmed Masry", "paper_title": "ChartQA: A benchmark for question answering about charts with visual and logical reasoning", "reason": "ChartQA is a fundamental benchmark frequently cited throughout the paper, its limitations in visual complexity and reasoning abilities motivating the development of the REACHQA dataset.  The error analysis presented in the introduction directly stems from ChartQA, establishing its importance as the central benchmark for the paper's investigation.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Anthropic", "paper_title": "Introducing claude 3.5 sonnet", "reason": "This paper's mention of Anthropic's work is relevant to the context of advanced multimodal models, providing a point of comparison for current state-of-the-art capabilities in visual and language processing, showing a foundation for the challenges addressed in the presented work.", "section_number": 1}, {" publication_date": "2024a", "fullname_first_author": "OpenAI", "paper_title": "GPT-4o", "reason": "OpenAI's GPT-40 is frequently used as a comparison point throughout the paper, demonstrating its role as a leading multimodal model and standard against which the performance of other models, including those fine-tuned with the proposed REACHQA dataset, are measured.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ahmed Masry", "paper_title": "ChartQA: A benchmark for question answering about charts with visual and logical reasoning", "reason": "ChartQA serves as a primary benchmark, highlighting the need for better visual recognition and reasoning capabilities in MLLMs. Its limitations in visual diversity and reasoning complexity justify the need for the proposed approach in REACHQA.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Shankar Kantharaj", "paper_title": "OpenCQA: Open-ended question answering with charts", "reason": "OpenCQA is mentioned in the context of existing chart-related datasets that share limitations in visual diversity and complexity.  Its inclusion supports the analysis of existing shortcomings and underscores the need for a more advanced dataset like REACHQA.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Meng", "paper_title": "Chartassisstant: A universal chart multimodal language model via chart-to-table pre-training and multitask instruction tuning", "reason": "This paper provides insight into recent attempts to enhance chart processing using LLMs, highlighting the difficulties and suggesting a need for a more effective approach as provided by REACHQA. Its limitations in visual complexity and scalability are also cited in the paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yucheng Han", "paper_title": "Chartllama: A multimodal Ilm for chart understanding and generation", "reason": "ChartLlama's inclusion demonstrates existing efforts to address the limitations of MLLMs in chart understanding.  The comparison helps justify the development of the REACHQA dataset as a better and more efficient method to improve MLLM performance in chart-related tasks.", "section_number": 2}, {" publication_date": "1986", "fullname_first_author": "Michael Zarechnak", "paper_title": "The intermediary language for multilanguage translation", "reason": "This paper introduces the concept of intermediary translation, which inspires the core methodology of the paper\u2014Code-as-Intermediary Translation (CIT).  The analogy to using code as an intermediary language to improve translation is central to the paper's innovation.", "section_number": 2}, {" publication_date": "2007", "fullname_first_author": "Jacqueline L\u00e9on", "paper_title": "From universal languages to intermediary languages in machine translation", "reason": "This reference expands on the concept of intermediary translation, further solidifying the rationale behind the CIT approach proposed in the paper.  It provides additional theoretical support for the use of an intermediary representation (code) to facilitate cross-modal understanding.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yizhong Wang", "paper_title": "Self-instruct: Aligning language models with self-generated instructions", "reason": "Self-Instruct is a key technique used in the creation of the REACHQA dataset.  It's a data synthesis method applied to generate diverse chart-plotting codes, and its mention illustrates the core methodology of REACHQA and its efficiency compared to manual annotation methods.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Can Xu", "paper_title": "Wizardlm: Empowering large pre-trained language models to follow complex instructions", "reason": "Evol-Instruct is another core technique used to synthesize the REACHQA dataset.  The mention of Evol-Instruct highlights the importance of this technique in generating more complex and diverse chart codes, thus enhancing the quality and complexity of the final dataset.", "section_number": 3}, {" publication_date": "2024a", "fullname_first_author": "Ahmed Masry", "paper_title": "Chartinstruct: Instruction tuning for chart comprehension and reasoning", "reason": "The paper shows the dataset created via LLM, that improves performance by instruction tuning. It demonstrates a clear connection with the proposed approach and justification for the choice of LLMs as a cost-effective tool for data synthesis.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Nitesh Methani", "paper_title": "PlotQA: Reasoning over scientific plots", "reason": "PlotQA is included for comparison, highlighting its limited scope and simpler chart types and questions, which contrasts with the broader scope and increased complexity of REACHQA.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Edward J. Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "This paper presents LoRA, a crucial technique used for fine-tuning various models in the paper's experiments. Its inclusion is necessary for understanding the fine-tuning methodology and its relevance to the evaluation of models' performance on the REACHQA dataset.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Takeshi Kojima", "paper_title": "Large language models are zero-shot reasoners", "reason": "The mention of chain-of-thought (CoT) prompting is crucial to understanding the evaluation methodology of the experiments.  CoT prompting is used to elicit reasoning steps from the models, which is fundamental for evaluating their performance on complex chart reasoning tasks.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Lianmin Zheng", "paper_title": "Judging Ilm-as-a-judge with mt-bench and chatbot arena", "reason": "The LLM-as-a-judge method forms the basis of the evaluation process for accuracy assessment.  This paper's inclusion helps to define and justify this methodological choice and to understand its potential limitations and impacts on the results.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Pan Lu", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts", "reason": "MathVista is used as a benchmark for evaluating general multimodal reasoning, highlighting that the improvements achieved by fine-tuning models with REACHQA data are not limited to chart-specific tasks but generalize to broader mathematical reasoning capabilities.", "section_number": 4}, {" publication_date": "2024a", "fullname_first_author": "Ke Wang", "paper_title": "Measuring multimodal mathematical reasoning with math-vision dataset", "reason": "MATH-Vision is another benchmark used to assess general multimodal reasoning, offering additional validation that the improvements from REACHQA extend beyond chart-specific tasks and provide generalized improvements in multimodal reasoning.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Yizhong Wang", "paper_title": "Self-instruct: Aligning language models with self-generated instructions", "reason": "This paper describes Self-Instruct, a key technique used for data synthesis within the REACHQA methodology.  Its inclusion is crucial for understanding the efficiency and scalability of the data generation process and how it contrasts with traditional manual methods.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Xiang Yue", "paper_title": "MMMU-PRO: A more robust multi-discipline multimodal understanding benchmark", "reason": "This paper is crucial in providing a foundation for understanding the importance of evaluating multimodal models across various tasks. The general multimodal benchmarks like MMMU-PRO provide a contrast against the more specialized chart-reasoning benchmarks, allowing a comparison of how performance on specialized tasks transfers to more general multimodal scenarios.", "section_number": 5}]}