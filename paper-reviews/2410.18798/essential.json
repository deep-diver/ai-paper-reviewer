{"reason": "This research introduces Code-as-Intermediary Translation (CIT), a novel method to effectively synthesize training data for multimodal large language models (MLLMs) to enhance visual chart reasoning abilities.  By using code as an intermediary, LLMs can efficiently translate visual chart representations into text, leading to a cost-effective and scalable data creation method. The resulting dataset, REACHQA, significantly improves MLLM performance in both chart-related and general mathematical reasoning tasks.", "summary": "Code-as-Intermediary Translation synthesizes chart Q&A data, boosting MLLM visual reasoning.", "takeaways": ["Code-as-Intermediary Translation (CIT) offers a cost-effective way to create high-quality chart-reasoning datasets.", "The REACHQA dataset significantly improves MLLM performance on chart-related and general mathematical reasoning benchmarks.", "CIT's approach demonstrates the potential of using code as an intermediary to bridge different modalities in MLLM training."], "tldr": "This paper tackles the challenge of training multimodal large language models (MLLMs) to understand and reason with visual charts.  Existing methods for creating training datasets are expensive and time-consuming.  The authors propose a novel method called Code-as-Intermediary Translation (CIT).  CIT uses code as a bridge between the visual chart and the textual representation, allowing LLMs to process and understand cross-modal information more effectively.  They used this approach to synthesize a new dataset, REACHQA, containing 3,000 charts and 20,000 question-answer pairs.  Experiments show that fine-tuning MLLMs on REACHQA significantly improves performance on various chart-related and general mathematical reasoning benchmarks, demonstrating the effectiveness of CIT in improving MLLM visual reasoning abilities."}