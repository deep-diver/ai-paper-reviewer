[{"content": "Model|Backbone|[S]P|[S]I|[L]P|[L]I|AVG|L1|L2|L3|L4|L5|AVG|GPT-3.5*|GPT|59.0|68.5|64.0|73.6|66.3|80.3|68.0|68.6|61.1|53.2|66.2|66.3|GPT-4\u2020|GPT|76.9|83.6|79.3|85.4|81.3|84.7|76.1|71.3|74.5|62.4|73.8|77.6|Vicuna-v1.5-13B\u2020|Llama2|43.1|53.6|46.6|58.0|50.3|71.2|61.3|48.3|38.0|33.1|50.4|50.4|WizardLM-v1.2-13B|Llama2|43.6|54.4|48.4|59.1|51.4|61.3|51.6|43.3|37.5|29.9|44.7|48.1|Conifer<sub>SFT</sub>-13B\u2020|Llama2|42.9|53.0|47.5|57.4|50.2|60.5|53.6|48.4|40.7|31.7|47.0|48.6|Zephyr-beta-7B\u2020|Mistral|32.0|46.8|44.9|58.0|45.4|57.6|51.9|41.9|41.4|31.4|44.8|45.1|Conifer<sub>SFT</sub>-7B\u2020|Mistral|45.8|57.1|50.8|62.0|53.9|54.3|49.5|49.3|40.8|30.5|44.9|49.4|Conifer<sub>DPO</sub>-7B\u2020|Mistral|48.1|59.1|52.3|63.3|55.7|60.3|53.6|48.0|47.1|41.0|50.0|52.9|Llama3 8B|Llama3|25.7|36.8|28.1|35.1|31.4|4.8|8.7|8.8|6.0|9.8|7.6|19.5|Llama3<sub>Crab</sub>|Llama3|39.4|50.2|43.8|54.2|46.9|57.5|44.9|34.9|25.2|20.0|36.5|41.7|Llama3<sub>Crab</sub> + DPO|Llama3|40.3|52.0|47.7|58.9|49.7|64.6|49.0|41.6|35.8|36.8|45.5|47.6|Mistral 7B|Mistral|18.5|30.8|19.6|31.9|25.2|14.3|16.6|8.3|5.8|5.5|10.1|17.7|Mistral<sub>Crab</sub>|Mistral|47.9|57.3|51.6|61.2|54.5|63.9|54.4|40.1|30.4|27.9|43.3|48.9|Mistral<sub>Crab</sub> + DPO|Mistral|49.7|61.5|57.7|68.5|59.3|66.1|53.6|53.4|42.4|31.7|49.4|54.4|", "caption": "Table 1: Experimental results (%) of the LLMs on IFEval and FollowBench. In IFEval, \u201c[S]\u201d and \u201c[L]\u2019 denote strict and loose accuracy, \u201cP\u201d and \u201cI\u201d indicate the prompt and instruction level.\nIn FollowBench, L1 (simplest) to L5 (hardest) denote different difficulty levels.\nWe highlight the highest and second-highest scores of open-source LLMs using bold font and underline. \u2020\u2020\\dagger\u2020 and\n* means the results are from\u00a0Sun et\u00a0al. (2024) and \u00a0He et\u00a0al. (2024).", "description": "Table 1 presents a comprehensive comparison of various Large Language Models (LLMs) on two complex instruction following benchmarks: IFEval and FollowBench.  IFEval results are broken down by strict and loose accuracy, distinguishing between prompt-level and instruction-level evaluations.  FollowBench results show performance across five difficulty levels (L1-L5), representing increasing complexity. The table highlights the top two performing open-source LLMs using bold font and underlines.  Results marked with \u2020 and * indicate data sourced from external studies by Sun et al. (2024) and He et al. (2024), respectively.", "section": "3 Experiments"}, {"content": "| Model | LC WinRate | WinRate |\n|---|---|---|\n| GPT-3.5-turbo-0613\u2020 | 22.4 | 14.1 |\n| GPT-4-0613\u2020 | 30.2 | 15.8 |\n| WizardLM-70B\u2020 | 17.6 | 14.4 |\n| WizardLM-v1.2-13B\u2020 | 14.5 | 12.0 |\n| Vicuna-v1.5-13B\u2020 | 10.5 | 6.7 |\n| Zephyr-beta-7B\u2020 | 13.2 | 11.0 |\n| Conifer<sub>DPO</sub>-7B\u2020 | 17.1 | 11.3 |\n| Mistral<sub>Crab</sub> | 13.3 | 7.9 |\n| Mistral<sub>Crab</sub> + DPO | 18.1 | 17.6 |\n| (vs.) Conifer<sub>DPO</sub> | 60.6 | 63.5 |", "caption": "Table 2: Winning rate (%) of the investigated LLMs on Alpaca-Eval 2.0\u00a0(Li et\u00a0al., 2023b).\n\u201cLC\u201d denotes length-controlled\u00a0(Dubois et\u00a0al., 2024).\n\u2020\u2020\\dagger\u2020 means the results are sourced from the original leaderboard.", "description": "This table presents the winning rates of various Large Language Models (LLMs) on the Alpaca-Eval 2.0 benchmark.  Alpaca-Eval 2.0 assesses the general instruction-following abilities of LLMs. The winning rate indicates the percentage of times a given LLM's response was judged superior to that of another LLM when both responded to the same prompt. The results are categorized by whether or not length constraints were applied to the model's response generation.  A dagger symbol (\u2020) denotes that the results were taken from the original Alpaca-Eval leaderboard, indicating that those specific model results were not generated as part of this paper's experimental setup.", "section": "3.3 Analysis on General Instruction Following"}, {"content": "| Model | IFEval | FollowBench AVG | FollowBench L1-L2 | FollowBench L3-L5 | AVG |\n|---|---|---|---|---|---| \n| Mistral<sub>Crab</sub> | 54.5 | 59.1 | 32.8 | 48.9 |\n| (-) Reverse training | 52.1 | 56.2 | 33.5 | 47.3 |\n| (-) Forward training | 53.9 | 57.1 | 32.1 | 48.0 |\n| (-) In-Context Demons | 53.6 | 55.8 | 30.0 | 47.0 |\n| InstBackT<sub>SFT</sub> | 52.7 | 55.4 | 29.3 | 46.2 |", "caption": "Table 3: Experimental results (%) of the ablation study. In-Context Demons denotes in-context demonstrations.", "description": "This table presents the results of an ablation study analyzing the impact of different components on the performance of the model.  The study investigates three key factors: reverse training, forward training (supervised fine-tuning), and the inclusion of in-context demonstrations.  The model's performance is evaluated on the IFEval and FollowBench datasets, with separate scores for strict and loose accuracy on IFEval, and scores broken down by difficulty level (L1-L5) for FollowBench.  Each row represents a model trained with a specific combination (or absence) of the three factors, allowing for a comparison of their individual and combined effects on the overall effectiveness of the model in following complex instructions.", "section": "3 Experiments"}, {"content": "| Constraint Category | Generator | Weighted |\n|---|---|---|\n| Define Circumstances | LLM | 0.7 |\n| Desired Writing Style | LLM | 0.7 |\n| Semantic Elements | LLM | 0.8 |\n| Morphological Constraints | LLM | 0.8 |\n| Multi-lingual Constraints | LLM | 0.8 |\n| Specific Literary Devices | LLM | 0.8 |\n| Specific Grammatical Structure | LLM | 0.8 |\n| Hierarchical Instructions | LLM | 0.8 |\n| Special Output Format | LLM | 0.8 |\n| Paragraphs Constraints | LLM | 0.7 |\n| Specific Sentence | LLM | 0.7 |\n| Keyword Formatting | LLM | 1.0 |\n| Item Listing Details | LLM | 1.0 |\n| Length Constraint | Python | 0.5 |\n| Words Per Sentence | Python | 0.5 |\n| Sentences Per Paragraph | Python | 0.3 |\n| Characters Per Word | Python | 0.3 |\n| Keyword Constraint | Python | 0.5 |\n| Punctuation Limitation | Python | 0.3 |", "caption": "Table 4: Constraint types defined during the back-translation process. \"Weighted\" indicates the sampling probability of each constraint type during combination.", "description": "This table lists the nineteen types of constraints used in the constraint back-translation process, which are categorized by constraint type and generator (LLM or Python).  The \"Weighted\" column shows the probability of each constraint type being selected during the combination phase where multiple constraints are combined to form a final constraint for an instruction.", "section": "2 Method"}, {"content": "| Instruction | Output |\n|---|---| \n| What is an easy J Perm PLL algorithm that wouldn\u2019t be too complicated for a beginner at speed solving? | One easy J Perm PLL algorithm that is not too complicated for a beginner at speed solving is the following: R\u2019 U R\u2019 U\u2019 J R U\u2019 R\u2019 U\u2019 J\u2019 U2 R U This algorithm only has 10 moves and does not require any complicated finger tricks. Here is a breakdown of the algorithm: 1. R\u2019 U R\u2019 U\u2019 - This is a common setup move for J Perm PLL algorithms. It sets up the J shape in the corner of the cube. 2. J R U\u2019 R\u2019 U\u2019 - This is the J Perm algorithm itself. It swaps the two adjacent edges and the two adjacent corners in the J shape. 3. J\u2019 U2 R U - This is the inverse of the setup move and completes the PLL algorithm. Remember to practice this algorithm slowly at first, and then gradually increase your speed. With enough practice, you should be able to execute this algorithm quickly and efficiently.  |\n| Define Circumstance: What is a simple, 10-move or fewer J Perm PLL algorithm for speed solving that a beginner can learn and execute efficiently, without requiring advanced finger tricks or complex sequences? |  A simple, beginner-friendly Perm PLL algorithm, involving 10 or fewer moves, and avoiding complicated finger tricks is highly desirable for efficient execution in speed solving. The algorithm should be easily learnable and executable.  The focus should be on a clear, concise explanation that avoids overly technical terminology.  The response must use at least 160 words and adhere to specified word and character limits. Each sentence should ideally be under 25 words, and each word should contain at least 15 characters.  The explanation should use a step-by-step approach.  The keywords \u2018complicated finger tricks\u2019, \u2018Perm PLL\u2019, and \u2018Perm PLL algorithm\u2019 should be included.  The response should not contain question marks and should adhere to the specified grammatical structure. The goal is to provide a helpful resource for beginners in speed solving, focusing on the simplicity and ease of use of the algorithm.  This means providing straightforward instructions that are easily understood without being overly verbose.   |\n| Length Constraint: Submit an response that contains at least 160 words. |  The response will include at least 160 words, and will provide detailed instructions for executing a simple Perm PLL algorithm. The response will be carefully crafted to satisfy the specified word count requirement, while remaining clear, concise, and easy to understand for beginners.  This ensures that the instructions are easy to follow, even for those new to speed cubing, making it more accessible and effective for learning and implementation.  The additional word count will be used to provide further explanations and more detailed information about the algorithm, while keeping the sentences short. The focus will be on making the process simpler and easier to understand for beginners in speed solving. This way, the algorithm will be made accessible to newcomers who might have limited previous experience. |\n| Word Per Sentence: Restrict each sentence to 25 words maximum. | Each sentence in the response will adhere to the 25-word limit to ensure clarity and readability.  This approach makes the instructions easier to comprehend for beginners, avoiding overwhelming them with excessively long sentences.  The brief sentences maintain a consistent and easily digestible flow of information throughout the entire explanation. This approach simplifies the learning process and enhances comprehension, leading to faster and more effective learning. This strategy helps to support beginners in mastering the algorithm. |\n| Characters Per Word: Each word in the response must consist of at least 15 characters. | Every word used in the response will include at least fifteen characters.   This constraint ensures more descriptive words, which helps to enhance the overall clarity of the explanation. The additional letters help to minimize ambiguity and add specificity to the instructions, making the process more effective.  This improves the comprehension level and ensures that the algorithm's execution is readily grasped by new users. The use of more extensive vocabulary contributes to the comprehensive nature of the response. |\n| Keyword Constraint: In your reply, include the terms complicated finger tricks, Perm PLL, Perm PLL algorithm to emphasize the critical components and provide clarity. |  The response includes the terms \u2018complicated finger tricks\u2019, \u2018Perm PLL\u2019, and \u2018Perm PLL algorithm\u2019 to highlight essential elements and to provide clarity. The inclusion of these keywords ensures the critical aspects are clearly emphasized.  The targeted use of these keywords enhances both the understanding and accessibility of the provided information, making the response much clearer and more useful for the audience.  The strategic placement of these terms further improves clarity and readability, making the text easier to follow. |\n| Punctuation Limitation: Avoid using question marks in your response. |  The response will not include any question marks.  This adherence to the punctuation limitation enhances the tone and style of the response, enhancing its overall structure and appeal.  The absence of question marks contributes to the overall clarity and professionalism of the provided information, making it easier for beginners to understand the algorithm. The absence of question marks simplifies the process, improving readability. |\n| Desired Writing Style: The response should be written in a clear and concise manner, with a tone that is informative and helpful, suitable for a beginner in speed solving. | The response maintains a clear, concise, and informative style, appropriate for beginners.  The tone is helpful and supportive.  The writing is intended to be easily understood, and the information is presented in a manner that is accessible to new learners of speed solving.  The simple writing ensures the algorithm is straightforward for beginners to learn, helping them improve and progress quickly.  The use of clear, concise language avoids confusion. |\n| Semantic Elements: The main theme of the response should focus on providing a simple J Perm PLL algorithm for beginners, highlighting its ease of use and simplicity. |  The response focuses on providing a simple J Perm PLL algorithm for beginners.  It emphasizes the algorithm\u2019s ease of use and simplicity.  The core message highlights the beginner-friendliness and ease of execution.  The simplicity and clarity of the presented algorithm are essential to assist new speed cubers in their learning journey.  The main emphasis is making learning as simple as possible. |\n| Morphological Constraints: Avoid using overly technical jargon or complex mathematical notation, and refrain from using formatting styles that may confuse the reader. | The response avoids using overly complex mathematical notation or technical jargon. It also avoids formatting that may confuse the reader.  This makes the response more accessible to a wider range of beginners. This style ensures the information remains clear, concise, and uncomplicated. The simple style ensures understanding is prioritized.  The uncomplicated language improves accessibility and understanding for a broader audience.  |\n| Multi-lingual Constraints: The response should be written in English. | The response is written in English. This is to ensure the greatest accessibility for the largest possible number of English-speaking users. This ensures the response is easily accessible to a global audience. This focus on English language improves inclusivity for a large segment of the global audience.  English is used for accessibility. |\n| Specific Literary Devices: Use a step-by-step breakdown of the algorithm to enhance clarity and facilitate understanding. |  The response uses a step-by-step approach to break down the algorithm.  This helps ensure clarity and understanding for the reader.  The breakdown uses numbered steps for better organization and ease of understanding. This organization improves understanding and ease of implementation.  The step-by-step explanation makes the learning process easier. |\n| Specific Grammatical Structure: The response should be written primarily in simple sentences, with occasional use of compound sentences to provide additional explanations. | The response primarily uses simple sentences.  Compound sentences are occasionally used for providing further context.  This grammatical structure ensures the information is easily accessible for beginners.   Simple sentence structures support clarity for new learners.   This grammatical choice improves readability.  |\n| Hierarchical Instructions: The response should prioritize explaining the algorithm, followed by a breakdown of the algorithm, and finally providing practice tips. | The response prioritizes the algorithm\u2019s explanation, then the breakdown, and finally practice tips. This structure helps to build understanding in stages. This hierarchy improves comprehension.  This organizational strategy focuses on building understanding in steps.  |\n| Paragraphs Constraints: The response should consist of three paragraphs, with a blank line separating each paragraph. | The response has three paragraphs separated by blank lines.   This structure aids readability.  This structure improves readability and organization.  The use of paragraphs enhances the organization and readability of the response. |\n| Specific Sentence: The response should start with a sentence that introduces the algorithm, and end with a sentence that encourages practice. | The response begins by introducing the algorithm and ends by encouraging practice. This structure helps to provide a solid start and finish to the response.  This structure improves the response\u2019s overall flow and presentation.  A strong introduction and conclusion create a clear framework for the explanation.  |", "caption": "Table 5:  An example from OpenAssistant of Crab after constraint back-translation and before combination.", "description": "This table shows an example of data from the OpenAssistant dataset after the constraint back-translation process has been applied but before the final constraints have been combined.  It illustrates the intermediate step in the CRAB dataset creation process, highlighting the different constraints identified and added to the original instruction and response pair.", "section": "2 Method"}]