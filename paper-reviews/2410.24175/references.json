{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This paper introduces the foundational practice of aligning LLMs to follow instructions using human feedback, a technique crucial for improving instruction-following capabilities and central to many subsequent advancements in the field."}, {"fullname_first_author": "Rohan Taori", "paper_title": "Alpaca: A strong, replicable instruction-following model", "publication_date": "2023-01-01", "reason": "This paper introduces the Alpaca model, a significant benchmark dataset used for training and evaluating instruction-following models, thus influencing the development and comparison of many subsequent LLM-based approaches."}, {"fullname_first_author": "Albert Q Jiang", "paper_title": "Mistral 7B", "publication_date": "2023-10-01", "reason": "This paper introduces the Mistral 7B language model, one of the backbone models used in the experiments, hence its performance is directly compared to the model proposed in the current work."}, {"fullname_first_author": "Haoran Sun", "paper_title": "Conifer: Improving complex constrained instruction-following ability of large language models", "publication_date": "2024-04-01", "reason": "This paper proposes a competitive approach to enhancing complex instruction following, which serves as a strong baseline against which the proposed approach is compared and evaluated in the current research."}, {"fullname_first_author": "Yuxin Jiang", "paper_title": "FollowBench: A multi-level fine-grained constraints following benchmark for large language models", "publication_date": "2024-01-01", "reason": "This paper introduces FollowBench, one of the main evaluation benchmarks used in the paper, therefore the performance of proposed methods are directly measured using this benchmark."}]}