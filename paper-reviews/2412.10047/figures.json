[{"figure_path": "https://arxiv.org/html/2412.10047/x1.png", "caption": "Figure 1. The transition from LLMs to LAMs.", "description": "This figure illustrates the transition from Large Language Models (LLMs) to Large Action Models (LAMs).  Initially, a user interacts with an LLM, providing textual queries and receiving textual output such as chatbot responses or generated code.  This stage represents the current capabilities of LLMs, which excel at language-based tasks.  However, to achieve real-world action, the LLM needs to be transformed into a LAM.  This transformation involves finetuning the LLM with action and plan trajectories.  The resulting LAM then interacts with an agent. The agent takes in task requests and utilizes the LAM to produce both textual and agent action outputs.  This output allows the agent to interact with an environment, perform actions, and gather feedback.  This feedback loop allows the LAM and agent to adapt and learn within a dynamic environment, enabling the execution of real-world tasks.  The figure visually depicts this progression, highlighting the integration of the LAM within an agent system and the crucial role of environmental interaction and feedback.", "section": "INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2412.10047/x2.png", "caption": "Figure 2. The objective difference between LLMs and LAMs.", "description": "This figure visually illustrates the core difference between Large Language Models (LLMs) and Large Action Models (LAMs).  It uses the example task \"Buy a jacket for men.\"  The LLM provides a textual, step-by-step plan for achieving this goal: 1. Open an online shopping website. 2. Search for \"jacket for men\". 3. Go through all jackets. The LLM stops at generating this plan and cannot execute the steps.  In contrast, the LAM takes the same goal and executes the necessary steps, interacting with the website environment. This shows how LAMs go beyond planning to perform real-world actions.", "section": "2 LARGE ACTION MODELS 101"}, {"figure_path": "https://arxiv.org/html/2412.10047/x3.png", "caption": "Figure 3. The process pipeline for LAM development and implementation.", "description": "The figure illustrates the five key stages involved in developing and implementing a Large Action Model (LAM). It begins with **Data Collection and Preparation**, where relevant data is gathered and processed. This is followed by **Model Training**, which involves techniques like supervised fine-tuning and reinforcement learning. The trained model then undergoes **Offline/Online Evaluation** to assess its performance in controlled and real-world environments. The next stage is **Integration and Grounding**, where the LAM is incorporated into an agent system and connected to external tools and the environment. Finally, **Online Evaluation** rigorously tests the LAM's performance in the real world, considering aspects like accuracy, efficiency, and robustness.", "section": "2.4 From Inception to Implementation"}, {"figure_path": "https://arxiv.org/html/2412.10047/x4.png", "caption": "Figure 4. The two-phrase data collection and preparation process.", "description": "This figure illustrates the two-stage process of data collection and preparation used for Large Action Model (LAM) training.  The first stage, \"Task-Plan Data Collection,\" focuses on gathering data related to tasks and their corresponding plans.  The second stage, \"Task-Action Data Collection,\" refines this data by grounding the tasks and plans in a specific environment (e.g., a Word document) and generating the corresponding low-level actions needed for execution.  This two-stage approach bridges the gap between high-level planning and executable actions, essential for training a LAM to perform real-world tasks.", "section": "3. DATA COLLECTION AND PREPARATION"}, {"figure_path": "https://arxiv.org/html/2412.10047/x5.png", "caption": "Figure 5. The pipeline to construct the task plan data.", "description": "This figure illustrates the multi-stage process used for collecting and preparing the task-plan data, which serves as crucial input for training Large Action Models (LAMs). The pipeline begins with gathering raw data from diverse sources, such as software application documentation, online how-to guides (WikiHow), and historical user search queries.  Following data extraction, a pre-processing stage filters and standardizes the data, ensuring its quality and relevance. The core of the process involves leveraging GPT, a large language model, to structure the data into a consistent JSON format comprising task descriptions and their corresponding plans, which are detailed, step-by-step instructions to achieve the given tasks. Lastly, a data evolution step enhances the dataset by generating additional, more complex tasks derived from the initial ones, further augmenting the training data.", "section": "3.1 Task-Plan Data"}, {"figure_path": "https://arxiv.org/html/2412.10047/x6.png", "caption": "Figure 6. The pipeline of task-action data conversion and collection.", "description": "This figure illustrates the four-stage pipeline for converting task-plan data, which includes high-level plans for user requests, into task-action data, which consists of the granular actions needed to execute plans within a specific application environment. The stages are:\n1. **Instantiation:** An LLM transforms abstract task-plan data into actionable task-action data grounded within a specific environment, such as a Word document. Target objects and functions for the task are also determined in this stage.\n2. **Execution:**  The instantiated task-action data is executed within the application environment to validate its correctness and collect execution trajectories. Screenshots of each step are taken for evaluation.\n3. **Evaluation:** The executed trajectory is evaluated by an LLM to assess whether the intended task was successfully completed.  This ensures high-quality training data.\n4. **Post-processing:**  Successful trajectories are combined with original task requests to form the final training data for the LAM, while discarded trajectories are excluded.", "section": "3.2 Task-Action Data"}, {"figure_path": "https://arxiv.org/html/2412.10047/x7.png", "caption": "Figure 7. An example of task instantiation.", "description": "This figure illustrates the process of task instantiation, where a given task and its corresponding plan are transformed into a more concrete and actionable task with a detailed action plan by grounding it to a specific environment (e.g., a document) and available control items. For instance, given the task 'Highlight Text in document' and a document named 'template.doc' containing the text 'Hello World,' the instantiated task becomes 'Highlight Text \"Hello World\" in template.doc'. The associated action plan is also generated. It shows two potential instantiated action sequences: the first one fails to match any control item in the environment, leading to task discard, while the second successfully finds a matching control item (\"Text Highlight Color\") and its associated label (\"37\"), enabling successful task execution.", "section": "3.2 Task-Action Data"}, {"figure_path": "https://arxiv.org/html/2412.10047/x8.png", "caption": "Figure 8. The overview of LAM training pipeline.", "description": "The figure provides a visual overview of the four-phase training pipeline used to develop a Large Action Model (LAM).  Each phase is represented by a distinct block, illustrating the data resources, data format, training method, and objective for that stage. Phase 1, \"Task-Plan Pretraining,\" focuses on teaching the model to generate structured plans from task descriptions. Phase 2, \"Learning from Experts,\" incorporates expert-labeled action trajectories to guide the model's action execution. Phase 3, \"Self-Boosting Exploration,\" encourages the model to learn from its own successes on tasks GPT-4 failed, improving adaptability. Finally, Phase 4, \"Learning from Reward Model,\" uses reinforcement learning to refine decision-making based on a reward model trained on successes and failures.", "section": "4 MODEL TRAINING"}, {"figure_path": "https://arxiv.org/html/2412.10047/x9.png", "caption": "Figure 9. The overall architecture of the AppAgent employed in UFO.", "description": "The architecture of AppAgent in UFO consists of the following components:\n- **LAM**: Large Action Model for decision-making.\n- **Memory**: Stores historical actions and plans for context.\n- **Grounding**: Maps actions to tools and functions.\n- **Action Executor**: Executes actions within the environment.\n- **Environment**: Represents the Windows OS and application.\n- **Env. State Data Collection**: Collects UI information (e.g., control type, title, position) using UI Automation API. \n- **Feedback**: Returns environment feedback to LAM.\n- **Screenshots**: Captures visual information of the environment. The AppAgent interacts with the environment via mouse clicks, keyboard input, or API calls, receiving feedback to adjust the plan dynamically.", "section": "6. INTEGRATION AND GROUNDING"}, {"figure_path": "https://arxiv.org/html/2412.10047/extracted/6067220/imgs/shape-file.png", "caption": "Figure 10. A word template file with the description \u201cA doc with a rectangle shape.\u201d", "description": "This figure showcases a screenshot of a Microsoft Word document serving as a template. The document's description is 'A doc with a rectangle shape,' indicating the presence of a rectangular shape within the document's content. This file is used during the instantiation stage of data collection and preparation, where tasks and their corresponding plans are transformed into actionable, environment-specific instructions for training the Large Action Model (LAM). The rectangle shape within the document serves as a target object for the LAM to interact with, enabling it to learn to execute actions related to shapes within a Word document.  This is one example of several templates used for instantiating actions, with others containing various Word elements such as text, tables, charts, and images to broaden the scope of training. Each template comes with a corresponding description, which aids in selecting the appropriate template for a given task during the instantiation process.", "section": "3. DATA COLLECTION AND PREPARATION"}, {"figure_path": "https://arxiv.org/html/2412.10047/extracted/6067220/imgs/review-file.png", "caption": "Figure 11. A word template file with the description \u201cA doc with comments and reviewer.\u201d", "description": "This figure showcases a screenshot of a Microsoft Word document template.  Distinguishing features include a section for comments on the right side and indications of a reviewer, possibly through tracked changes or comments. The layout of the document is simple with numbered placeholders like \"123\" and \"456\" likely indicating areas for text input. The top menu bar in Word is also visible.", "section": "3. Data Collection and Preparation"}, {"figure_path": "https://arxiv.org/html/2412.10047/extracted/6067220/imgs/chart-file.png", "caption": "Figure 12. A word template file with the description \u201cA doc with a chart.\u201d", "description": "A screenshot of a Word document containing a bar chart, used as a template in the instantiation phase of data collection. The chart presents data across four categories, with three series represented in different colors. The chart has a title and labels for the x and y-axes. This template, along with others, allows for more specific and actionable instructions when converting tasks and plans into actionable steps for training the LAM.", "section": "3. DATA COLLECTION AND PREPARATION"}]