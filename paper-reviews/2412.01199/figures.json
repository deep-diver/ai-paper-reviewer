[{"figure_path": "https://arxiv.org/html/2412.01199/x1.png", "caption": "Figure 1: This work presents a learnable approach for pruning the depth of pre-trained diffusion transformers. Our method simultaneously optimizes a differentiable sampling process of layer masks and a weight update to identify a highly recoverable solution, ensuring that the pruned model maintains competitive performance after fine-tuning.", "description": "The figure illustrates TinyFusion, a novel method for pruning pre-trained diffusion transformers.  Instead of solely focusing on minimizing immediate loss after pruning, TinyFusion optimizes both a differentiable sampling process for selecting layers to remove (represented by layer masks) and a weight update mechanism to simulate and improve the model's performance after subsequent fine-tuning. This dual optimization strategy aims to find a pruned model that is highly 'recoverable,' meaning it can regain strong performance after retraining with minimal computational cost.  The figure visually depicts how layer masks are sampled and refined iteratively using the differentiable sampling approach and how weights are updated to estimate post-fine-tuning performance.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.01199/x2.png", "caption": "Figure 2: The proposed TinyFusion method learns to perform a differentiable sampling of candidate solutions, jointly optimized with a weight update to estimate recoverability. This approach aims to increase the likelihood of favorable solutions that ensure strong post-fine-tuning performance. After training, local structures with the highest sampling probabilities are retained.", "description": "The figure illustrates TinyFusion, a method for learning shallow diffusion transformers.  It shows how the method learns a probability distribution over possible ways to prune layers (removing layers from the model).  This is done by jointly optimizing both the probability distribution (which layers are removed) and a weight update that simulates the effects of subsequent fine-tuning.  The goal is to bias the distribution toward pruning choices that result in good performance after fine-tuning, ensuring the smaller model retains strong performance.  The figure highlights the differentiable sampling of layer masks and the co-optimized weight update.  After training, TinyFusion retains only the network structures that showed the highest probability of success during training, effectively creating a shallower, faster model.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.01199/x3.png", "caption": "Figure 3: An example of forward propagation with differentiable pruning mask misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and LoRA for recoverability estimation.", "description": "This figure illustrates the forward propagation process within a diffusion transformer model that incorporates a differentiable pruning mask and LoRA for recoverability estimation.  The diagram shows how the pruning mask (m\u1d62) acts as a gate, selectively allowing or blocking the passage of information through layers. LoRA (Low-Rank Adaptation) is employed to simulate and estimate the model's recoverability after pruning. This process involves a weight update (\u0394\u03a6) to adjust model weights, improving its performance after the pruned layers have been fine-tuned. The figure visually demonstrates how the combined application of a learnable pruning mask and LoRA enables a differentiable calculation of recoverability, facilitating effective layer pruning within the diffusion transformer.", "section": "3.2 Tiny Fusion: Learnable Depth Pruning"}, {"figure_path": "https://arxiv.org/html/2412.01199/x4.png", "caption": "Figure 4: Depth pruning closely aligns with the theoretical linear speed-up relative to the compression ratio.", "description": "This figure shows a graph comparing the speed-up achieved by depth pruning against the theoretical linear speed-up.  The x-axis represents the compression ratio (percentage of layers removed), and the y-axis represents the speed-up factor. The graph demonstrates that depth pruning achieves a speed-up closely matching the expected linear increase as the compression ratio grows. This suggests that removing layers in this manner is an efficient way to compress diffusion transformer models.", "section": "4. Results on Diffusion Transformers"}, {"figure_path": "https://arxiv.org/html/2412.01199/x5.png", "caption": "Figure 5: Distribution of calibration loss through random sampling of candidate models. The proposed learnable method achieves the best post-fine-tuning FID yet has a relatively high initial loss compared to other baselines.", "description": "This figure shows the distribution of calibration loss across 100,000 randomly sampled candidate models created by pruning a diffusion transformer at 50% depth.  Each model represents a different pruning configuration.  The x-axis represents the calibration loss, which is the loss of the model after pruning but before fine-tuning. The y-axis represents the frequency or count of models with that specific calibration loss. The figure demonstrates that models with lower initial calibration loss do not necessarily lead to better performance (lower FID) after fine-tuning.  The proposed TinyFusion method, despite having a higher initial calibration loss, achieves the lowest FID score after fine-tuning, indicating it is effective in selecting models with high recoverability.", "section": "4.3. Analytical Experiments"}, {"figure_path": "https://arxiv.org/html/2412.01199/x6.png", "caption": "Figure 6: Visualization of the 2:4 decisions in the learnable pruning, with the confidence level of each decision highlighted through varying degrees of transparency. More visualization results for 1:2 and 7:14 schemes are available in the appendix.", "description": "This figure visualizes the decisions made during the learnable pruning process, specifically focusing on the 2:4 pruning scheme.  Each line represents a layer in the DiT-XL model, and the color intensity (transparency) of the data points along each line indicates the probability of that layer being pruned at each training iteration.  Lighter colors signify a lower probability of pruning. This visualization helps demonstrate how the model learns to identify and retain important layers during training, ultimately leading to the selection of a final pruned model. The appendix includes similar visualizations for the 1:2 and 7:14 pruning schemes.", "section": "3.2 TinyFusion: Learnable Depth Pruning"}, {"figure_path": "https://arxiv.org/html/2412.01199/x7.png", "caption": "Figure 7: Images generated by TinyDiT-D14 on ImageNet 224\u00d7\\times\u00d7224, pruned and distilled from a DiT-XL/2.", "description": "This figure displays images generated using the TinyDiT-D14 model.  TinyDiT-D14 is a smaller, more efficient version of the DiT-XL/2 model, created through a process of pruning (removing less important layers) and knowledge distillation (transferring knowledge from the larger model to the smaller one). The images showcase the model's ability to generate images on the ImageNet dataset, demonstrating its performance despite its reduced size and computational cost.", "section": "4.3 Analytical Experiments"}, {"figure_path": "https://arxiv.org/html/2412.01199/x8.png", "caption": "(a) DiT-XL/2 (Teacher)", "description": "This figure shows the distribution of activation values in the hidden states of the DiT-XL/2 model (teacher model). The x-axis represents the activation value (on a logarithmic scale), and the y-axis shows the density of the activation values. The distribution is shown as a histogram.  It highlights that there are a significant number of large activation values (positive and negative) in the teacher model. This is relevant to the discussion in section 4.4, knowledge distillation for recovery, which explains how these extreme activations can affect the distillation process between the teacher and student (pruned) models.", "section": "4. Knowledge Distillation for Recovery"}, {"figure_path": "https://arxiv.org/html/2412.01199/x9.png", "caption": "(b) TinyDiT-D14 (Student)", "description": "This figure is a histogram showing the distribution of activation values in the hidden states of the TinyDiT-D14 model.  The x-axis represents the activation values (on a logarithmic scale), and the y-axis represents the frequency of those values.  It is used to illustrate the presence of large or \"massive\" activation values within the model, which is a common issue that can negatively affect the model's performance and stability during fine-tuning, especially when performing knowledge distillation.  Comparing this to the distribution in the teacher model (Figure 8a) helps explain the challenges and the need for a technique like MaskedKD, which mitigates the effects of these outliers.", "section": "4.4. Knowledge Distillation for Recovery"}, {"figure_path": "https://arxiv.org/html/2412.01199/x13.png", "caption": "Figure 8: Visualization of massive activations\u00a0[47] in DiTs. Both teacher and student models display large activation values in their hidden states. Directly distilling these massive activations may result in excessively large losses and unstable training.", "description": "Figure 8 shows a comparison of activation distributions in the hidden states of a teacher (DiT-XL/2) and student (TinyDiT-D14) diffusion transformer model.  The histograms illustrate the presence of many large magnitude activations (both positive and negative) in both models. Directly using knowledge distillation to transfer these activations from teacher to student is problematic; it can lead to excessively large losses during training and instability in the training process. This highlights the need for a method to handle or mitigate these massive activations to improve the effectiveness of knowledge distillation.", "section": "4. Knowledge Distillation for Recovery"}, {"figure_path": "https://arxiv.org/html/2412.01199/x14.png", "caption": "Figure 9: 1:2 Pruning Decisions", "description": "This figure visualizes the learning process of the 1:2 pruning scheme during training. The x-axis represents the training iterations, and the y-axis represents the layer index in the DiT-XL model. Each curve shows the probability of a layer being pruned at each iteration.  The transparency of the data points indicates the probability of the layer being selected for pruning.  Darker points signify higher probabilities. This visualization illustrates how the model learns to make pruning decisions over time, and how different layers are selected at different stages of training.", "section": "7. Visualization of Pruning Decisions"}, {"figure_path": "https://arxiv.org/html/2412.01199/x15.png", "caption": "Figure 10: 2:4 Pruning Decisions", "description": "This figure visualizes the learning dynamics of pruning decisions during training, specifically focusing on the 2:4 pruning scheme.  In this scheme, the model is divided into blocks of four layers, with two layers retained.  Each curve represents a layer in the original DiT-XL model, and the transparency of the data points reflects their probability of being selected during pruning across training iterations.  The visualization shows how the learnable method progressively identifies and retains important layers while discarding less crucial ones, showcasing the iterative optimization process.", "section": "7. Visualization of Pruning Decisions"}]