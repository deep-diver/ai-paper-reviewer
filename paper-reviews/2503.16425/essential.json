{"importance": "This paper introduces a novel image generation framework, **TokenSet**, offering dynamic token allocation and enhanced robustness. This work can inspire more research to explore the non-serialized visual representation and generative model.", "summary": "TokenSet: Tokenizing images as unordered sets for dynamic capacity allocation and robust generation, breaking from fixed-position latent codes.", "takeaways": ["Introduces TokenSet, a novel image generation paradigm using set-based tokenization.", "Presents a dual transformation mechanism for modeling discrete sets as fixed-length sequences.", "Proposes Fixed-Sum Discrete Diffusion for effective set distribution modeling with summation invariance."], "tldr": "**Contemporary visual generation faces challenges with fixed compression ratios, leading to inefficient coding, especially in regions with varying semantic complexity.** Current tokenization methods generate serialized codes with fixed positional correspondence, allocating the same number of codes to both simplistic and semantically dense regions. This raises a fundamental question of whether visually simplistic regions should receive the same representational capacity as semantically rich areas. \n\nThis paper introduces **TokenSet**, a fundamentally new paradigm for image generation through set-based tokenization and distribution modeling. It proposes to tokenize images into unordered sets to enable dynamic attention allocation based on regional semantic complexity. The dual transformation mechanism converts sets into fixed-length integer sequences with summation constraints. Fixed-Sum Discrete Diffusion addresses the challenge of modeling discrete sets and enables effective set distribution modeling.", "affiliation": "University of Science and Technology of China", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.16425/podcast.wav"}