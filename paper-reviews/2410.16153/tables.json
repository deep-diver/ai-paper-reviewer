[{"figure_path": "2410.16153/tables/table_4_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the aggregate performance of various multilingual and multimodal large language models on the PANGEABENCH benchmark, highlighting the superior performance of PANGEA-7B.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_8_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the aggregate performance of various multilingual multimodal LLMs on the PANGEABENCH benchmark, highlighting PANGEA-7B's superior performance.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_9_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents the overall performance of various multilingual multimodal LLMs on the PANGEABENCH benchmark, highlighting the superior performance of PANGEA-7B.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_44_0.html", "caption": "Table 3: Comparison of models on the xChat dataset across different languages.", "description": "The table shows a comparison of different large language models' performance on the xChat benchmark across multiple languages.", "section": "H.1 XCHAT"}, {"figure_path": "2410.16153/tables/table_44_1.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the aggregate performance of various multimodal LLMs on the PANGEABENCH evaluation suite, highlighting the superior performance of PANGEA-7B in both English and multilingual scenarios.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_47_0.html", "caption": "Table 7: Comparison of models on the MaRVL dataset across different languages.", "description": "Table 7 shows the performance comparison of various models on the MaRVL benchmark across multiple languages, including English and multilingual settings.", "section": "3.2 MULTIMODAL TASKS"}, {"figure_path": "2410.16153/tables/table_49_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents the overall performance comparison of various multilingual multimodal large language models (MLLMs) across multiple benchmark datasets, highlighting PANGEA-7B's superior performance.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_50_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents an overview of the aggregate performance of various multimodal LLMs on the PANGEABENCH benchmark across English and multilingual scenarios.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_50_1.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the overall performance of various multilingual multimodal LLMs on the PANGEABENCH evaluation suite, highlighting the superior performance of PANGEA-7B.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_50_2.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the aggregate performance of various multilingual and multimodal LLMs on the PANGEABENCH benchmark, highlighting the superior performance of PANGEA-7B in both English and multilingual scenarios.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_51_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents the overall performance of various multilingual multimodal large language models on the PANGEABENCH benchmark, highlighting PANGEA-7B's superior performance compared to existing open-source models.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_51_1.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the overall performance of various multilingual multimodal LLMs on different benchmarks within PANGEABENCH, highlighting PANGEA-7B's superior performance.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_51_2.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents a comparison of the aggregate performance of various multilingual multimodal LLMs on the PANGEABENCH benchmark, highlighting the superior performance of PANGEA-7B.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_51_3.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents the overall performance of various multilingual multimodal LLMs on the PANGEABENCH benchmark, highlighting the superior performance of PANGEA-7B compared to other open-source models.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}, {"figure_path": "2410.16153/tables/table_52_0.html", "caption": "Table 1: Overall performance on the multilingual multimodal benchmarks in PANGEABENCH. The best-performing open model on each dataset is in bold and the second best is underlined.", "description": "Table 1 presents the overall performance comparison of various multilingual multimodal large language models (MLLMs) on the PANGEABENCH benchmark, highlighting PANGEA-7B's superior performance in multilingual and multicultural scenarios.", "section": "3 PANGEABENCH: EVALUATION OF MULTILINGUAL MULTIMODAL MODELS"}]