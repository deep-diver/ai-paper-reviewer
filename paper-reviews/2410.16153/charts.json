[{"figure_path": "2410.16153/charts/charts_1_0.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart visualizes the aggregate performance of various multimodal large language models (MLLMs) on the PANGEABENCH benchmark, comparing their performance in English and multilingual scenarios.", "section": "Multilingual Performance"}, {"figure_path": "2410.16153/charts/charts_2_0.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart shows the aggregate performance of various multimodal LLMs on the PANGEABENCH benchmark, highlighting PANGEA-7B's competitive performance in English and its superior performance in multilingual scenarios.", "section": "Multilingual Performance"}, {"figure_path": "2410.16153/charts/charts_10_0.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart compares the aggregate performance of various multilingual and English-centric multimodal LLMs on the PANGEABENCH benchmark, highlighting PANGEA-7B's superior performance in multilingual scenarios.", "section": "Multilingual Performance"}, {"figure_path": "2410.16153/charts/charts_10_1.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart compares the aggregate performance of various multilingual and English-centric multimodal LLMs on the PANGEABENCH benchmark, highlighting PANGEA-7B's superior performance in multilingual settings.", "section": "Multilingual Performance"}, {"figure_path": "2410.16153/charts/charts_10_2.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart visualizes the aggregate performance of various multimodal large language models (MLLMs) on the PANGEABENCH evaluation suite, highlighting PANGEA-7B's competitive performance in English and its superior performance in multilingual settings.", "section": "Multilingual Performance"}, {"figure_path": "2410.16153/charts/charts_11_0.png", "caption": "Figure 1: Overview of the aggregate performance of various multimodal LLMs on PANGEABENCH. Our PANGEA-7B demonstrates comparable performance to SoTA open-source models in English settings, while significantly outperforming them in multilingual scenarios.", "description": "The chart compares the aggregate performance of various multilingual and multimodal large language models (MLLMs) on the PANGEABENCH benchmark, showing PANGEA-7B's competitive performance in English and superior performance in multilingual settings.", "section": "Multilingual Performance"}]