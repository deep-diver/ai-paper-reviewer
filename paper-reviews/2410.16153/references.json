{"references": [{" publication_date": "2023", "fullname_first_author": "Damian Blasi", "paper_title": "Systematic inequalities in language technology performance across the world's languages", "reason": "This paper directly addresses the core issue of the PANGEA paper, demonstrating the underperformance of current language technology in various languages across the world. This underperformance is a key motivation for the development of PANGEA, making this a highly relevant and impactful reference.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Orevaoghene Ahia", "paper_title": "Do all languages cost the same? tokenization in the era of commercial language models", "reason": "This paper directly supports the motivation behind PANGEA, highlighting the high cost of inference for under-resourced languages. This cost is a key challenge addressed by PANGEA, making this a relevant and impactful reference for the paper.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Badr AlKhamissi", "paper_title": "Investigating cultural alignment of large language models", "reason": "This paper directly tackles the cultural bias in LLMs, a central focus of the PANGEA paper.  Understanding and addressing this bias is a core goal of PANGEA, making this paper highly relevant.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "reason": "LAION-5B is a crucial dataset used in the creation of PANGEAINS. Its use directly contributes to the data diversity and scale of the PANGEA model, making this paper an important reference.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "reason": "The Llama 3 models are used for scoring and filtering images in PANGEAINS. This highlights the importance of LLMs in the development of multicultural instructions, a key aspect of the PANGEAINS dataset creation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Guiming Hardy Chen", "paper_title": "ALLaVA: Harnessing GPT-4V-synthesized data for a lite vision-language model", "reason": "ALLaVA is among the several datasets used in PANGEAINS. This paper explains the contribution and characteristics of ALLaVA dataset, making it an essential reference for understanding the creation of PANGEAINS.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Khang T Doan", "paper_title": "Vintern-1B: An efficient multimodal large language model for Vietnamese", "reason": "Vintern-1B is another important dataset utilized within the PANGEAINS dataset.  Understanding its role and inclusion provides context for the overall design and diversity of PANGEAINS.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jonas Pfeiffer", "paper_title": "xGQA: Cross-lingual visual question answering", "reason": "xGQA is a benchmark dataset used within the PANGEABENCH evaluation suite. This paper details the creation and characteristics of xGQA, which is essential for understanding the design and performance assessment of PANGEA.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Soravit Changpinyo", "paper_title": "MAXM: Towards multilingual visual question answering", "reason": "MAXM is another important dataset in PANGEABENCH that helps evaluate multilingual visual question answering (VQA) capabilities. This paper details the creation and characteristics of MAXM, which is crucial for understanding the design of PANGEABENCH.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Haotian Liu", "paper_title": "Visually grounded reasoning across languages and cultures", "reason": "MaRVL, a dataset used in PANGEABENCH, focuses on multicultural reasoning and is highly relevant to the goals of PANGEA.  This paper details MaRVL and provides an in-depth understanding of the benchmark used in PANGEABENCH.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Wenxuan Zhang", "paper_title": "M3Exam: A multilingual, multimodal, multilevel benchmark for examining large language models", "reason": "M3Exam is a critical dataset within PANGEABENCH for evaluating multilingual reasoning skills. This paper provides an in-depth description of M3Exam, making it essential for understanding the evaluation methodology.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Jonathan H. Clark", "paper_title": "TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages", "reason": "TyDiQA is a crucial benchmark in PANGEABENCH for evaluating multilingual question answering capabilities.  Understanding this benchmark is critical for interpreting the results and assessing PANGEA's performance within the broader context of existing QA models.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "NLLB Team", "paper_title": "Scaling neural machine translation to 200 languages", "reason": "The NLLB model is relevant to PANGEA due to the use of machine translation for generating the PANGEAINS dataset.  This paper shows the impact of large scale multilingual translation which is directly relevant to PANGEA.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Ashish V. Thapliyal", "paper_title": "Crossmodal-3600: A massively multilingual multimodal evaluation dataset", "reason": "XM100, a dataset used in PANGEABENCH, is a subset of Crossmodal-3600. This paper details the creation and design of Crossmodal-3600, which is essential to understanding the composition and evaluation of XM100 in PANGEABENCH.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Xi Victoria Lin", "paper_title": "Few-shot learning with multilingual language models", "reason": "This paper discusses few-shot learning which is relevant to the design choices made for PANGEA.  Understanding the techniques behind few-shot learning provides important context for evaluating PANGEA's performance within the larger field of multilingual LLMs.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Bo Li", "paper_title": "LLaVA-OneVision: Easy visual task transfer", "reason": "LLaVA-OneVision is one of the models used as a baseline in PANGEABENCH.  Understanding its architecture and performance is important for evaluating PANGEA's relative strengths and weaknesses within the broader landscape of available multilingual multimodal models.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Matt Deitke", "paper_title": "Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models", "reason": "Molmo is one of the leading open-source multilingual models used for comparison in this study. This paper provides an in-depth understanding of Molmo's capabilities, thereby offering important context for analyzing PANGEA\u2019s performance relative to existing models.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Felix Hamborg", "paper_title": "news-please: A generic news crawler and extractor", "reason": "This paper describes the CC-News-Multilingual dataset, a vital source for creating the multilingual OCR dataset used in the supplementary materials.  Understanding the dataset is crucial for comprehending the supplementary information about the creation of the multilingual OCR dataset.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "An Yang", "paper_title": "Qwen2 technical report", "reason": "Qwen2 is the backbone of PANGEA and understanding its architecture and properties is crucial for assessing PANGEA\u2019s performance and design choices. This paper provides technical details about Qwen2, making it a highly relevant reference.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Lianmin Zheng", "paper_title": "Judging LLM-as-a-judge with mt-bench and chatbot arena", "reason": "This paper critically analyzes the limitations of using LLMs for evaluation. This is directly relevant to the design choices made in evaluating PANGEA, specifically the use of human-crafted benchmarks like xChat, which address limitations noted in Zheng et al., 2023.", "section_number": 3}]}