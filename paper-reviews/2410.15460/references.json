{"references": [{" publication_date": "2023a", "fullname_first_author": "Lei Huang", "paper_title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions", "reason": "This paper provides a comprehensive overview of the current state of hallucination research in LLMs, which is crucial for understanding the problem space. It categorizes existing approaches, highlights challenges, and identifies open questions, making it highly relevant to the introduction which focuses on the research gap in the field.  The survey's scope and depth make it a key foundational reference.", "section_number": 1}, {" publication_date": "2023a", "fullname_first_author": "Lei Huang", "paper_title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions", "reason": "This is a foundational work that comprehensively reviews the current state of hallucination research in LLMs, providing a crucial context for the \"Related Work\" section. It helps to establish the existing literature and the gap in research that the present study aims to address.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Chao Chen", "paper_title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "reason": "This paper is highly relevant to the \"Related Work\" section, as it discusses methods involving internal representations or hidden layers of the model for hallucination detection and mitigation. The focus on internal model dynamics and their relationship to hallucinations directly connects to the present study's exploration of LLM internal states and its proposed training methodology.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Vipula Rawte", "paper_title": "A Survey of Hallucination in Large Foundation Models", "reason": "The \"Related Work\" section benefits from the inclusion of this survey which covers a broad range of methods for detecting and mitigating hallucinations in large language models. It helps set the context for the authors' approach by providing a summary of existing techniques and their limitations.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Giwon Hong", "paper_title": "The Hallucinations Leaderboard \u2013 An Open Effort to Measure Hallucinations in Large Language Models", "reason": "This paper's focus on evaluating and benchmarking hallucination in LLMs aligns directly with the \"Oscillatory Behaviour Validation\" section. The Hallucination Leaderboard provides a valuable resource for comparing various hallucination detection metrics, complementing the study's own analysis and results.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Junyi Li", "paper_title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models", "reason": "This paper introduces HaluEval, which is a benchmark dataset for evaluating the hallucination rates in LLMs. The benchmark directly ties to the \"Oscillatory Behaviour Validation\" section, as the authors are using this dataset to analyze hallucination rates. The methodology, particularly the use of benchmark datasets for evaluation purposes, is important for reproducibility and comparison to previous work.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Junyi Li", "paper_title": "The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models", "reason": "This paper addresses the oscillatory behavior of hallucinations during LLM training, making it highly relevant to the \"Oscillatory Behaviour Validation\" section. The findings that directly support the authors' claims of oscillatory behavior in hallucination trends throughout the training process, adding credence to their own findings.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Chao Chen", "paper_title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "reason": "This paper is relevant to the \"Internal Training Dynamics\" section because it focuses on analyzing internal representations and hidden states of LLMs for hallucination detection. Its methodology of exploring internal states connects with the authors' exploration of sensitive neurons and the use of sentence embeddings.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Weihang Su", "paper_title": "Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models", "reason": "This paper directly informs the methodology in the \"Internal Training Dynamics\" section, particularly the use of sentence embedding vectors for identifying Sensitive Neurons and their variability.  The work is pivotal for the conceptualization and development of SeND since the approach for detecting sensitive neurons is inspired by this work.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Kun Dong", "paper_title": "Network Density of States", "reason": "This paper is highly important for the \"Efficient EigenScore Approximation\" section because it introduces the Density of States (DOS) concept used for approximating EigenScore.  It helps justify the mathematical foundations and theoretical underpinnings of the efficient EigenScore method proposed in the paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Ankit Pal", "paper_title": "Med-HALT: Medical Domain Hallucination Test for Large Language Models", "reason": "This paper is highly relevant to the \"Sensitive Neuron Dropout (SEND)\" section. The MedHALT dataset serves as a second experimental dataset, providing valuable insights into the robustness and generalizability of the SeND method across domains.  The use of MedHALT for evaluating the performance of SeND on a medical-related task is crucial for illustrating the broader applicability of their proposed solution.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Sewon Min", "paper_title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation", "reason": "This paper introduces FactScore, a metric for evaluating the factual accuracy of LLM outputs. The \"Sensitive Neuron Dropout (SEND)\" section uses FactScore to demonstrate the improvement achieved by SeND in terms of factual accuracy, providing a quantitative evaluation of the effectiveness of their approach. Its use adds credence to the claims made in the paper.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Tianyu Yu", "paper_title": "RLHF-V: Towards Trustworthy MLLMS via Behavior Alignment from Fine-grained Correctional Human Feedback", "reason": "The \"Related Work\" section references Reinforcement Learning with Human Feedback (RLHF), and this paper provides a more detailed analysis of a specific RLHF method. This context helps to highlight the limitations of post-hoc solutions, setting up the justification for SeND as an efficient, integrated approach for improving model reliability. ", "section_number": 1}, {" publication_date": "2014", "fullname_first_author": "Nitish Srivastava", "paper_title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "reason": "This foundational paper introduces the concept of dropout regularization in neural networks, which is conceptually related to the proposed SeND method. The \"Related Work\" section briefly discusses dropout, and this paper provides a deeper understanding of its mechanism and potential application in mitigating issues like overfitting, leading to the development of a novel training protocol.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Bikash Santra", "paper_title": "Deterministic dropout for deep neural networks using composite random forest", "reason": "This paper is relevant to the \"Related Work\" section, and explores the idea of modifying the random neuron dropout mechanism to improve performance. This work is directly related to the SeND which also modifies a standard training protocol by deterministically removing sensitive neurons, addressing the problem of variability in model outputs.", "section_number": 1}, {" publication_date": "2013", "fullname_first_author": "Jimmy Ba", "paper_title": "Adaptive dropout for training deep neural networks", "reason": "This paper introduces adaptive dropout, which is conceptually related to the SeND training protocol. The \"Related Work\" section mentions dropout regularization as a technique to address model variance, and this paper is directly related to the concepts utilized in SeND to improve model robustness and reduce variance during training. The paper also demonstrates how to implement it which is useful for replication purposes.", "section_number": 1}, {" publication_date": "2013", "fullname_first_author": "Pierre Baldi", "paper_title": "Understanding Dropout", "reason": "This paper provides additional insights into the mechanism of dropout and its effects on neural network training. The \"Related Work\" section mentions dropout, and this paper helps to explain the theoretical underpinnings of this technique and its potential for mitigating overfitting, thus providing a more comprehensive understanding of the methods discussed in the \"Related Work\" section and setting the stage for the improved methodology in this paper.", "section_number": 1}, {" publication_date": "2018", "fullname_first_author": "Shashi Narayan", "paper_title": "Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization", "reason": "This paper is highly relevant to the \"Oscillatory Behaviour Validation\" section because it provides a benchmark dataset (XSUM) used for evaluating the summarization performance of the models.  The use of XSUM as a benchmark dataset for assessing the factual accuracy of the generated text is a critical aspect of the empirical evaluation presented in the \"Oscillatory Behaviour Validation\" section.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Potsawee Manakul", "paper_title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models", "reason": "This paper is important for \"Oscillatory Behaviour Validation\" because it introduces SelfCheckGPT, a metric used in the paper for assessing self-consistency in model outputs, a key indicator of hallucination. It directly ties to the methodology used in this paper by providing another metric for evaluating the performance and stability of the LLMs through training.", "section_number": 2}]}