{"references": [{" publication_date": "July 2017", "fullname_first_author": "Mandar Joshi", "paper_title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension", "reason": "This paper is highly relevant because it introduces a large-scale dataset for reading comprehension, a task closely related to evaluating the factual accuracy and hallucination behavior of LLMs.  The dataset's size and the distant supervision methodology make it particularly suitable for testing and benchmarking the performance of large language models in retrieving and presenting factual information accurately.", "section_number": 1}, {" publication_date": "September 2023", "fullname_first_author": "Vipula Rawte", "paper_title": "A Survey of Hallucination in Large Foundation Models", "reason": "This survey paper provides a comprehensive overview of the current state of research on hallucinations in large language models. Its value comes from offering a structured classification of existing work, which allows for a clearer understanding of the scope of the problem and the various approaches that have been proposed to tackle it. This helps to understand the position and contribution of the current work within the existing research landscape.", "section_number": 1}, {" publication_date": "October 2023", "fullname_first_author": "Lei Huang", "paper_title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions", "reason": "This survey paper offers a valuable analysis of hallucinations in large language models. The systematic classification of hallucinations, along with a comprehensive taxonomy of existing research efforts to address them, provides a crucial context for evaluating the current work and its significance in the field. The identification of open research questions helps to guide future research in this area.", "section_number": 1}, {" publication_date": "October 2023", "fullname_first_author": "Junyi Li", "paper_title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models", "reason": "This paper is crucial because it introduces a large-scale benchmark dataset specifically designed to evaluate hallucinations in large language models.  The use of a standardized benchmark dataset provides a crucial metric for comparing different LLM architectures and mitigation strategies.  The comprehensive evaluation metrics used to measure hallucination help to ensure that the results are reliable and generalizable.", "section_number": 1}, {" publication_date": "July 2024", "fullname_first_author": "Leo Gao", "paper_title": "A framework for few-shot language model evaluation", "reason": "This is an important reference as it introduces a systematic framework for evaluating large language models. Given that the research is focused on improving the factual accuracy of LLMs, a robust, well-defined evaluation metric is essential to measure the effectiveness of the training protocol.  Using a validated evaluation metric ensures that the improvements in factual accuracy are not solely due to peculiarities or biases within the model itself.", "section_number": 2}, {" publication_date": "February 2024", "fullname_first_author": "Chao Chen", "paper_title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection", "reason": "This paper highlights the internal dynamics of LLMs which is important because the authors of the current work focus on the impact of the training process on the output of LLMs. Understanding the internal states of LLMs is crucial for developing more effective training protocols, and this paper provides valuable insights into this.", "section_number": 2}, {" publication_date": "March 2020", "fullname_first_author": "Bikash Santra", "paper_title": "Deterministic dropout for deep neural networks using composite random forest", "reason": "This paper is relevant because it introduces a deterministic approach to neuron dropout, a regularization technique used in training neural networks to prevent overfitting.  The authors of the current work apply a similar concept by selectively dropping neurons with high variability (sensitive neurons), suggesting that this paper provides a foundational understanding of such techniques.", "section_number": 2}, {" publication_date": "September 2023", "fullname_first_author": "Hongbin Ye", "paper_title": "Cognitive Mirage: A Review of Hallucinations in Large Language Models", "reason": "This review provides a valuable overview of existing research on hallucination in LLMs.  This provides a comprehensive understanding of the problem, allowing for a better assessment of the current work's contribution to the field.  The review allows for a comprehensive evaluation of the existing literature and allows for a proper context of where the current research falls within the field.", "section_number": 2}, {" publication_date": "October 2023", "fullname_first_author": "Sewon Min", "paper_title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation", "reason": "This paper introduces an important metric for evaluating factual precision in long-form text generation. This is highly relevant since one of the main contributions of this paper is to improve the factual accuracy of LLMs. Having a standardized metric for measuring factual accuracy helps to ensure that the improvements are reliable and generalizable.", "section_number": 2}, {" publication_date": "October 2023", "fullname_first_author": "Potsawee Manakul", "paper_title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models", "reason": "This paper is highly relevant due to its focus on hallucination detection in LLMs, a key issue that this work addresses. The paper introduces a novel zero-resource method, which makes it computationally efficient and easily applicable to various models. The zero-resource aspect is relevant because the current work aims to reduce the computational cost of hallucination detection.", "section_number": 2}, {" publication_date": "July 2024", "fullname_first_author": "Leo Gao", "paper_title": "A framework for few-shot language model evaluation", "reason": "This paper provides a crucial framework for evaluating language models, including evaluating the factual accuracy and hallucinations. Using a standardized evaluation framework is essential for benchmarking and comparing results, thus ensuring the reproducibility and generalizability of the findings from this paper. The systematic and comprehensive evaluation framework helps ensure that the reported results are consistent and reliable.", "section_number": 3}, {" publication_date": "June 2024", "fullname_first_author": "Weihang Su", "paper_title": "Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models", "reason": "This paper offers a valuable approach to hallucination detection which is relevant to this paper as it focuses on real-time detection using the internal states of LLMs, thus offering a different perspective on the problem.  The unsupervised nature of this approach offers the potential for integrating it with the training process to improve the reliability of LLMs.  The focus on internal states aligns with the goal of this research to investigate the relationship between internal representations and the emergence of hallucinations.", "section_number": 3}, {" publication_date": "October 2014", "fullname_first_author": "Nitish Srivastava", "paper_title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "reason": "This seminal paper on dropout regularization is fundamental to understanding the principles behind SeND. Dropout is a technique to prevent overfitting by randomly dropping out neurons during training, and this paper laid the foundation for such techniques. SeND builds upon these principles by selectively dropping neurons based on their sensitivity to factual accuracy, thereby offering a more targeted and efficient approach to improve LLM reliability.", "section_number": 3}, {" publication_date": "July 2019", "fullname_first_author": "Kun Dong", "paper_title": "Network Density of States", "reason": "This paper introduces the concept of Network Density of States (DOS), which is a key component of the Efficient EigenScore (EES) approximation method proposed in this research. The authors of the current paper leverage DOS to efficiently estimate the EigenScore, reducing computational complexity, especially when dealing with large language models. This is important because efficient computation is critical for the scalability of the proposed training protocol.", "section_number": 3}, {" publication_date": "August 2018", "fullname_first_author": "Shashi Narayan", "paper_title": "Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization", "reason": "This paper is highly relevant because summarization is one of the tasks used to evaluate the models in this research. Using XSUM, the authors evaluate hallucination behavior in summarization tasks, indicating the importance of this specific task in assessing model reliability and factual accuracy. The focus on summarization helps ensure the model's effectiveness in accurately conveying information, a key component of assessing factual consistency.", "section_number": 2}, {" publication_date": "October 2023", "fullname_first_author": "Junyi Li", "paper_title": "The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models", "reason": "This paper provides valuable empirical insights into the nature of factuality hallucinations in large language models. The authors' investigation of the oscillatory behavior of hallucinations during training is highly relevant to the current work and provides crucial context and support for the findings presented in this work. The close examination of hallucination dynamics adds depth to the current research findings.", "section_number": 2}, {" publication_date": "March 2024", "fullname_first_author": "Yunfan Gao", "paper_title": "Retrieval-Augmented Generation for Large Language Models: A Survey", "reason": "This paper provides a survey of the state of the art in retrieval-augmented generation for large language models. Retrieval-augmented generation is a technique to improve the factual accuracy of LLMs by combining generation with retrieval from external knowledge sources. This is relevant to the current work because enhancing factual accuracy is one of the primary goals, and this survey provides a background on techniques that can be used to improve the reliability of LLMs.", "section_number": 2}, {" publication_date": "July 2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 Herd of Models", "reason": "This paper is important because it introduces Llama 3, a series of large language models. As one of the future directions, the authors of the current work mention scaling the SeND protocol to larger LLMs like Llama 3.  Therefore, this paper directly highlights the potential applicability and scalability of the proposed approach.", "section_number": 4}, {" publication_date": "October 2023", "fullname_first_author": "Ankit Pal", "paper_title": "Med-HALT: Medical Domain Hallucination Test for Large Language Models", "reason": "This paper introduces a dataset (MedHALT) specifically designed for evaluating hallucinations in the medical domain. The relevance of this paper stems from the inclusion of MedHALT as one of the datasets used to evaluate the performance of the SeND protocol. The utilization of MedHALT highlights the applicability of the proposed method in high-stakes domains where factual accuracy is critical.", "section_number": 4}]}