{"references": [{"fullname_first_author": "Dave Zhenyu Chen", "paper_title": "ScanRefer: 3d object localization in RGB-D scans using natural language", "publication_date": "2020-08-23", "reason": "This paper introduces the ScanRefer benchmark dataset, which is a key dataset used for evaluating 3D visual grounding performance and is heavily used in this paper's experiments."}, {"fullname_first_author": "Daichi Azuma", "paper_title": "ScanQA: 3d question answering for spatial scene understanding", "publication_date": "2022-06-18", "reason": "This paper introduces the ScanQA benchmark dataset, which is used to evaluate the 3D question answering capabilities of the proposed model."}, {"fullname_first_author": "Dave Zhenyu Chen", "paper_title": "Scan2Cap: Context-aware dense captioning in RGB-D scans", "publication_date": "2021-06-19", "reason": "This paper introduces the Scan2Cap benchmark dataset, which is used for evaluating 3D dense captioning performance in this paper's experiments."}, {"fullname_first_author": "Yilun Chen", "paper_title": "Grounded 3d-llm with referent tokens", "publication_date": "2024-05-10", "reason": "This is a state-of-the-art model for 3D scene understanding, and the proposed method is compared against it."}, {"fullname_first_author": "Yuanhan Zhang", "paper_title": "Video instruction tuning", "publication_date": "2024-09-10", "reason": "This paper introduces the Video LLM that is used as the backbone of this paper's proposed model"}]}