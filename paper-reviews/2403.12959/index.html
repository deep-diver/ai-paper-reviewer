<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>WHAC: World-grounded Humans and Cameras &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="WHAC: World-grounded Humans and Cameras &#183; HF Daily Paper Reviews by AI"><meta name=description content="WHAC: Grounding humans and cameras together!"><meta name=keywords content="Computer Vision,3D Vision,üè¢ SenseTime Research,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="WHAC: World-grounded Humans and Cameras"><meta property="og:description" content="WHAC: Grounding humans and cameras together!"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-03-19T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-19T00:00:00+00:00"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="3D Vision"><meta property="article:tag" content="üè¢ SenseTime Research"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/cover.png"><meta name=twitter:title content="WHAC: World-grounded Humans and Cameras"><meta name=twitter:description content="WHAC: Grounding humans and cameras together!"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"WHAC: World-grounded Humans and Cameras","headline":"WHAC: World-grounded Humans and Cameras","abstract":"WHAC: Grounding humans and cameras together!","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2403.12959\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2024","dateCreated":"2024-03-19T00:00:00\u002b00:00","datePublished":"2024-03-19T00:00:00\u002b00:00","dateModified":"2024-03-19T00:00:00\u002b00:00","keywords":["Computer Vision","3D Vision","üè¢ SenseTime Research"],"mainEntityOfPage":"true","wordCount":"3487"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-03-05/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-05</p></a><a href=/ai-paper-reviewer/2025-03-06/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-06</p></a><a href=/ai-paper-reviewer/2025-03-07/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-07</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-05/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-05</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-06/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-06</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-07/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-07</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2403.12959/cover_hu4314960552026722103.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2403.12959/>WHAC: World-grounded Humans and Cameras</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">WHAC: World-grounded Humans and Cameras</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-03-19T00:00:00+00:00>19 March 2024</time><span class="px-2 text-primary-500">&#183;</span><span>3487 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">17 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2403.12959/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2403.12959/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/computer-vision/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Computer Vision
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/3d-vision/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">3D Vision
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-sensetime-research/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ SenseTime Research</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#ehps-scaled-vo>EHPS: Scaled VO</a></li><li><a href=#whac-architecture>WHAC Architecture</a></li><li><a href=#whac-a-mole-data>WHAC-A-Mole Data</a></li><li><a href=#accurate-recovery>Accurate Recovery</a></li><li><a href=#societal-impact>Societal Impact</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#ehps-scaled-vo>EHPS: Scaled VO</a></li><li><a href=#whac-architecture>WHAC Architecture</a></li><li><a href=#whac-a-mole-data>WHAC-A-Mole Data</a></li><li><a href=#accurate-recovery>Accurate Recovery</a></li><li><a href=#societal-impact>Societal Impact</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2403.12959</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Wanqi Yin et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-02-24</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2403.12959 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2403.12959 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2403.12959/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Estimating human & camera movement in the world coordinate system from a single camera is hard due to the lack of depth information. Existing methods fall short in dynamic scenes. This paper tackles the challenge by leveraging the relationship between the world, humans, and camera. It builds on two observations: camera-frame human pose estimation can recover depth, and human motions inherently provide spatial cues.</p><p>The paper introduces <strong>WHAC, a novel framework</strong> for estimating human pose, shape, and camera pose from monocular video. It also presents <strong>WHAC-A-Mole, a new dataset</strong> with accurate human and camera annotations & diverse motions. Experiments on benchmarks show WHAC&rsquo;s effectiveness, outperforming existing methods and handling challenging scenarios.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-0e14e6add50e8825f22d3407285d5490></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-0e14e6add50e8825f22d3407285d5490",{strings:[" Introduces WHAC, a novel framework for world-grounded human and camera trajectory estimation from monocular video without relying on traditional optimization. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-21033439cc3672a2be70744adee34585></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-21033439cc3672a2be70744adee34585",{strings:[" Presents WHAC-A-Mole, a new synthetic dataset with accurate annotations for humans and cameras, featuring diverse human motions and realistic camera trajectories. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-b47807107f1add904450a68893d2e42c></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-b47807107f1add904450a68893d2e42c",{strings:[" Demonstrates state-of-the-art performance on both standard and newly established benchmarks. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This research introduces a novel method for <strong>accurate human and camera motion capture from monocular video</strong>, using a new dataset to facilitate future work. It addresses the challenge of scaleless estimation, offering a robust solution applicable in areas like AR/VR, sports analysis, and robotics.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x1.png alt></figure></p><blockquote><p>üîº This figure illustrates the WHAC framework, which integrates three key components to estimate world-grounded human and camera trajectories. The first component is camera-frame SMPL-X estimation, which provides initial estimates of human pose and shape in the camera&rsquo;s coordinate system. This is combined with visual odometry (VO), which estimates the camera&rsquo;s trajectory in the world coordinate system, providing information about camera movement. Finally, the human-world component, the MotionVelocimeter, analyzes human movements to infer velocity and thus scale information, refining both camera and human trajectory estimates. The synergy of these three components allows WHAC to accurately estimate both camera and human trajectories with correct scale in the world.</p><details><summary>read the caption</summary>Figure 1: WHAC synergizes human-camera (camera-frame SMPL-X estimation), camera-world (visual odometry), and human-world (our proposed MotionVelocimeter) modeling for constructing world-grounded human and camera trajectories.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S4.T1.22><thead class=ltx_thead><tr class=ltx_tr id=S4.T1.22.17.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.1 style=padding-left:4pt;padding-right:4pt>Dataset</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.2 style=padding-left:4pt;padding-right:4pt>#Inst.</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.3 style=padding-left:4pt;padding-right:4pt>#Seq.</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.4 style=padding-left:4pt;padding-right:4pt>R/S</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.5 style=padding-left:4pt;padding-right:4pt>Multi.</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.6 style=padding-left:4pt;padding-right:4pt>Track.</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.7 style=padding-left:4pt;padding-right:4pt>Contact</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.8 style=padding-left:4pt;padding-right:4pt>HHI</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.9 style=padding-left:4pt;padding-right:4pt>Camera</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.22.17.1.10 style=padding-left:4pt;padding-right:4pt>Human</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S4.T1.8.2><td class="ltx_td ltx_align_left ltx_border_t" id=S4.T1.8.2.3 style=padding-left:4pt;padding-right:4pt>3DPW¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib41 title>41</a>]</cite></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.4 style=padding-left:4pt;padding-right:4pt>74.6K</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.5 style=padding-left:4pt;padding-right:4pt>60</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.6 style=padding-left:4pt;padding-right:4pt>R</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.7.1.1 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.7.1.1.m1.1"><semantics id="S4.T1.7.1.1.m1.1a"><mo id="S4.T1.7.1.1.m1.1.1" xref="S4.T1.7.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.1.1.m1.1b"><times id="S4.T1.7.1.1.m1.1.1.cmml" xref="S4.T1.7.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.1.1.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.2 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.8.2.2.m1.1"><semantics id="S4.T1.8.2.2.m1.1a"><mo id="S4.T1.8.2.2.m1.1.1" xref="S4.T1.8.2.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.2.2.m1.1b"><times id="S4.T1.8.2.2.m1.1.1.cmml" xref="S4.T1.8.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.2.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.2.2.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.9 style=padding-left:4pt;padding-right:4pt>Moving</td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.8.2.10 style=padding-left:4pt;padding-right:4pt>SMPL</td></tr><tr class=ltx_tr id=S4.T1.22.18.1><td class="ltx_td ltx_align_left" id=S4.T1.22.18.1.1 style=padding-left:4pt;padding-right:4pt>RICH¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib16 title>16</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.2 style=padding-left:4pt;padding-right:4pt>476K</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.3 style=padding-left:4pt;padding-right:4pt>141</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.4 style=padding-left:4pt;padding-right:4pt>R</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.5 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.6 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.9 style=padding-left:4pt;padding-right:4pt>Static*</td><td class="ltx_td ltx_align_center" id=S4.T1.22.18.1.10 style=padding-left:4pt;padding-right:4pt>SMPL</td></tr><tr class=ltx_tr id=S4.T1.12.6><td class="ltx_td ltx_align_left" id=S4.T1.12.6.5 style=padding-left:4pt;padding-right:4pt>HCM¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib21 title>21</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.9.3.1 style=padding-left:4pt;padding-right:4pt><math alttext="\ddagger" class="ltx_Math" display="inline" id="S4.T1.9.3.1.m1.1"><semantics id="S4.T1.9.3.1.m1.1a"><mo id="S4.T1.9.3.1.m1.1.1" xref="S4.T1.9.3.1.m1.1.1.cmml">‚Ä°</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.3.1.m1.1b"><ci id="S4.T1.9.3.1.m1.1.1.cmml" xref="S4.T1.9.3.1.m1.1.1">‚Ä°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.3.1.m1.1c">\ddagger</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.3.1.m1.1d">‚Ä°</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.6 style=padding-left:4pt;padding-right:4pt>25</td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.7 style=padding-left:4pt;padding-right:4pt>S</td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.10.4.2 style=padding-left:4pt;padding-right:4pt><math alttext="\ddagger" class="ltx_Math" display="inline" id="S4.T1.10.4.2.m1.1"><semantics id="S4.T1.10.4.2.m1.1a"><mo id="S4.T1.10.4.2.m1.1.1" xref="S4.T1.10.4.2.m1.1.1.cmml">‚Ä°</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.4.2.m1.1b"><ci id="S4.T1.10.4.2.m1.1.1.cmml" xref="S4.T1.10.4.2.m1.1.1">‚Ä°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.4.2.m1.1c">\ddagger</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.4.2.m1.1d">‚Ä°</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.11.5.3 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.11.5.3.m1.1"><semantics id="S4.T1.11.5.3.m1.1a"><mo id="S4.T1.11.5.3.m1.1.1" xref="S4.T1.11.5.3.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.5.3.m1.1b"><times id="S4.T1.11.5.3.m1.1.1.cmml" xref="S4.T1.11.5.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.5.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.5.3.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.4 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.12.6.4.m1.1"><semantics id="S4.T1.12.6.4.m1.1a"><mo id="S4.T1.12.6.4.m1.1.1" xref="S4.T1.12.6.4.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.6.4.m1.1b"><times id="S4.T1.12.6.4.m1.1.1.cmml" xref="S4.T1.12.6.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.6.4.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.6.4.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.9 style=padding-left:4pt;padding-right:4pt>Moving</td><td class="ltx_td ltx_align_center" id=S4.T1.12.6.10 style=padding-left:4pt;padding-right:4pt>SMPL</td></tr><tr class=ltx_tr id=S4.T1.14.8><td class="ltx_td ltx_align_left" id=S4.T1.14.8.3 style=padding-left:4pt;padding-right:4pt>EMDB¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib19 title>19</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.4 style=padding-left:4pt;padding-right:4pt>109K</td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.5 style=padding-left:4pt;padding-right:4pt>81</td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.6 style=padding-left:4pt;padding-right:4pt>R</td><td class="ltx_td ltx_align_center" id=S4.T1.13.7.1 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.13.7.1.m1.1"><semantics id="S4.T1.13.7.1.m1.1a"><mo id="S4.T1.13.7.1.m1.1.1" xref="S4.T1.13.7.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.7.1.m1.1b"><times id="S4.T1.13.7.1.m1.1.1.cmml" xref="S4.T1.13.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.7.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.7.1.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.7 style=padding-left:4pt;padding-right:4pt>N.A.</td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.2 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.14.8.2.m1.1"><semantics id="S4.T1.14.8.2.m1.1a"><mo id="S4.T1.14.8.2.m1.1.1" xref="S4.T1.14.8.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.8.2.m1.1b"><times id="S4.T1.14.8.2.m1.1.1.cmml" xref="S4.T1.14.8.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.8.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.8.2.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.8 style=padding-left:4pt;padding-right:4pt>N.A.</td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.9 style=padding-left:4pt;padding-right:4pt>Moving</td><td class="ltx_td ltx_align_center" id=S4.T1.14.8.10 style=padding-left:4pt;padding-right:4pt>SMPL</td></tr><tr class=ltx_tr id=S4.T1.16.10><td class="ltx_td ltx_align_left" id=S4.T1.15.9.1 style=padding-left:4pt;padding-right:4pt>EgoBody<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="S4.T1.15.9.1.m1.1"><semantics id="S4.T1.15.9.1.m1.1a"><msup id="S4.T1.15.9.1.m1.1.1" xref="S4.T1.15.9.1.m1.1.1.cmml"><mi id="S4.T1.15.9.1.m1.1.1a" xref="S4.T1.15.9.1.m1.1.1.cmml"></mi><mo id="S4.T1.15.9.1.m1.1.1.1" xref="S4.T1.15.9.1.m1.1.1.1.cmml">‚Ä†</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.15.9.1.m1.1b"><apply id="S4.T1.15.9.1.m1.1.1.cmml" xref="S4.T1.15.9.1.m1.1.1"><ci id="S4.T1.15.9.1.m1.1.1.1.cmml" xref="S4.T1.15.9.1.m1.1.1.1">‚Ä†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.9.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.15.9.1.m1.1d">start_FLOATSUPERSCRIPT ‚Ä† end_FLOATSUPERSCRIPT</annotation></semantics></math>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib47 title>47</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.3 style=padding-left:4pt;padding-right:4pt>175K</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.4 style=padding-left:4pt;padding-right:4pt>125</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.5 style=padding-left:4pt;padding-right:4pt>R</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.6 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.2 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.16.10.2.m1.1"><semantics id="S4.T1.16.10.2.m1.1a"><mo id="S4.T1.16.10.2.m1.1.1" xref="S4.T1.16.10.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.16.10.2.m1.1b"><times id="S4.T1.16.10.2.m1.1.1.cmml" xref="S4.T1.16.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.10.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.16.10.2.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.9 style=padding-left:4pt;padding-right:4pt>Moving</td><td class="ltx_td ltx_align_center" id=S4.T1.16.10.10 style=padding-left:4pt;padding-right:4pt>SMPL-X</td></tr><tr class=ltx_tr id=S4.T1.19.13><td class="ltx_td ltx_align_left" id=S4.T1.19.13.4 style=padding-left:4pt;padding-right:4pt>BEDLAM¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib3 title>3</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.5 style=padding-left:4pt;padding-right:4pt>951K</td><td class="ltx_td ltx_align_center" id=S4.T1.17.11.1 style=padding-left:4pt;padding-right:4pt>10.4K<math alttext="{}^{\diamond}" class="ltx_Math" display="inline" id="S4.T1.17.11.1.m1.1"><semantics id="S4.T1.17.11.1.m1.1a"><msup id="S4.T1.17.11.1.m1.1.1" xref="S4.T1.17.11.1.m1.1.1.cmml"><mi id="S4.T1.17.11.1.m1.1.1a" xref="S4.T1.17.11.1.m1.1.1.cmml"></mi><mo id="S4.T1.17.11.1.m1.1.1.1" xref="S4.T1.17.11.1.m1.1.1.1.cmml">‚ãÑ</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.17.11.1.m1.1b"><apply id="S4.T1.17.11.1.m1.1.1.cmml" xref="S4.T1.17.11.1.m1.1.1"><ci id="S4.T1.17.11.1.m1.1.1.1.cmml" xref="S4.T1.17.11.1.m1.1.1.1">‚ãÑ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.11.1.m1.1c">{}^{\diamond}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.17.11.1.m1.1d">start_FLOATSUPERSCRIPT ‚ãÑ end_FLOATSUPERSCRIPT</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.6 style=padding-left:4pt;padding-right:4pt>S</td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.18.12.2 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.18.12.2.m1.1"><semantics id="S4.T1.18.12.2.m1.1a"><mo id="S4.T1.18.12.2.m1.1.1" xref="S4.T1.18.12.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.18.12.2.m1.1b"><times id="S4.T1.18.12.2.m1.1.1.cmml" xref="S4.T1.18.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.12.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.18.12.2.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.3 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.19.13.3.m1.1"><semantics id="S4.T1.19.13.3.m1.1a"><mo id="S4.T1.19.13.3.m1.1.1" xref="S4.T1.19.13.3.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.19.13.3.m1.1b"><times id="S4.T1.19.13.3.m1.1.1.cmml" xref="S4.T1.19.13.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.13.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.19.13.3.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.9 style=padding-left:4pt;padding-right:4pt>Static</td><td class="ltx_td ltx_align_center" id=S4.T1.19.13.10 style=padding-left:4pt;padding-right:4pt>SMPL-X</td></tr><tr class=ltx_tr id=S4.T1.22.16><td class="ltx_td ltx_align_left" id=S4.T1.22.16.4 style=padding-left:4pt;padding-right:4pt>SynBody¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib42 title>42</a>]</cite></td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.5 style=padding-left:4pt;padding-right:4pt>2.7M</td><td class="ltx_td ltx_align_center" id=S4.T1.20.14.1 style=padding-left:4pt;padding-right:4pt>27K<math alttext="{}^{\diamond}" class="ltx_Math" display="inline" id="S4.T1.20.14.1.m1.1"><semantics id="S4.T1.20.14.1.m1.1a"><msup id="S4.T1.20.14.1.m1.1.1" xref="S4.T1.20.14.1.m1.1.1.cmml"><mi id="S4.T1.20.14.1.m1.1.1a" xref="S4.T1.20.14.1.m1.1.1.cmml"></mi><mo id="S4.T1.20.14.1.m1.1.1.1" xref="S4.T1.20.14.1.m1.1.1.1.cmml">‚ãÑ</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.20.14.1.m1.1b"><apply id="S4.T1.20.14.1.m1.1.1.cmml" xref="S4.T1.20.14.1.m1.1.1"><ci id="S4.T1.20.14.1.m1.1.1.1.cmml" xref="S4.T1.20.14.1.m1.1.1.1">‚ãÑ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.14.1.m1.1c">{}^{\diamond}</annotation><annotation encoding="application/x-llamapun" id="S4.T1.20.14.1.m1.1d">start_FLOATSUPERSCRIPT ‚ãÑ end_FLOATSUPERSCRIPT</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.6 style=padding-left:4pt;padding-right:4pt>S</td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center" id=S4.T1.21.15.2 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.21.15.2.m1.1"><semantics id="S4.T1.21.15.2.m1.1a"><mo id="S4.T1.21.15.2.m1.1.1" xref="S4.T1.21.15.2.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.21.15.2.m1.1b"><times id="S4.T1.21.15.2.m1.1.1.cmml" xref="S4.T1.21.15.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.15.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.21.15.2.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.3 style=padding-left:4pt;padding-right:4pt><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.22.16.3.m1.1"><semantics id="S4.T1.22.16.3.m1.1a"><mo id="S4.T1.22.16.3.m1.1.1" xref="S4.T1.22.16.3.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T1.22.16.3.m1.1b"><times id="S4.T1.22.16.3.m1.1.1.cmml" xref="S4.T1.22.16.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.22.16.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.22.16.3.m1.1d">√ó</annotation></semantics></math></td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.9 style=padding-left:4pt;padding-right:4pt>Static</td><td class="ltx_td ltx_align_center" id=S4.T1.22.16.10 style=padding-left:4pt;padding-right:4pt>SMPL-X</td></tr><tr class=ltx_tr id=S4.T1.22.19.2><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.1 style=padding-left:4pt;padding-right:4pt>WHAC-A-Mole</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.2 style=padding-left:4pt;padding-right:4pt>1.46M</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.3 style=padding-left:4pt;padding-right:4pt>2434</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.4 style=padding-left:4pt;padding-right:4pt>S</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.5 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.6 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.7 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.8 style=padding-left:4pt;padding-right:4pt>‚úì</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.9 style=padding-left:4pt;padding-right:4pt>Moving</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=S4.T1.22.19.2.10 style=padding-left:4pt;padding-right:4pt>SMPL-X</td></tr></tbody></table></table></figure><blockquote><p>üîº This table compares various existing human pose and shape estimation datasets. The columns describe the number of human instances, the number of video sequences, whether the data is real or synthetic, whether multiple people are present in each scene, the availability of track IDs to follow individual people across the video, the presence of human-human interactions, and whether the camera was static or moving during capture. It also indicates whether SMPL or SMPL-X human models are available for the data, and notes any specific characteristics of certain datasets such as the EgoSet dataset or datasets with very short video clips.</p><details><summary>read the caption</summary>Table 1: Dataset Comparison. #Inst.: number of human instances (crops). #Seq.: number of video sequences. R/S: Real or Synthetic. Multi.: multiperson scenes. Track.: track ID labels. HHI: human-human interaction motions. ‚Ä†‚Ä†\dagger‚Ä†: EgoSet. ‚Ä°‚Ä°\ddagger‚Ä°: unknown as the data is not released when this paper is written. ‚ãÑ‚ãÑ\diamond‚ãÑ: typically short (<100 frames) clips.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">EHPS: Scaled VO<div id=ehps-scaled-vo class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ehps-scaled-vo aria-label=Anchor>#</a></span></h4><p>While &ldquo;EHPS: Scaled VO&rdquo; isn&rsquo;t explicitly in the paper, we can infer its meaning. EHPS (Expressive Human Pose and Shape estimation) combined with Scaled VO (Visual Odometry) suggests a system leveraging both human-centric understanding and scene geometry for enhanced 3D reconstruction. <strong>The core idea is to resolve the scale ambiguity inherent in monocular VO by incorporating constraints from EHPS.</strong> Traditional VO often struggles to determine the true scale of the environment. However, if we can accurately estimate the size and pose of humans within the scene (using EHPS), this information provides valuable metric scale cues. The system could work by first establishing camera motion with VO then refining this trajectory using EHPS outputs for the human in the scene to fix the scale. It should provide more accurate and robust 3D scene understanding, especially in dynamic environments where both the camera and humans are moving. <strong>This synergy between human-centric understanding and scene geometry promises to overcome the limitations of each individual method</strong></p><h4 class="relative group">WHAC Architecture<div id=whac-architecture class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#whac-architecture aria-label=Anchor>#</a></span></h4><p>While the paper doesn&rsquo;t explicitly detail a &lsquo;WHAC Architecture&rsquo; section, the core idea revolves around a synergistic framework. It leverages <strong>camera-frame human pose estimation</strong> (e.g., SMPL-X), <strong>visual odometry (VO)</strong> for camera motion, and a novel <strong>MotionVelocimeter (MV)</strong> module to estimate human motion velocities and recover absolute scale. The architecture likely involves a pipeline where initial camera-relative human poses are estimated, VO provides scaleless camera trajectory, MV infers human velocity, and a scale-alignment process refines both human and camera trajectories into a world-grounded coordinate system. This iterative refinement is central to the &lsquo;architecture&rsquo;, correcting scale and orientation ambiguities by blending visual and motion cues. The integration is not a mere concatenation of modules, but a carefully orchestrated feedback loop to improve estimation accuracy. The core is to refine the motion and trajectory using MV and VO.</p><h4 class="relative group">WHAC-A-Mole Data<div id=whac-a-mole-data class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#whac-a-mole-data aria-label=Anchor>#</a></span></h4><p>While the actual heading may vary, the &lsquo;WHAC-A-Mole&rsquo; data likely refers to a <strong>novel, synthetically generated dataset</strong> introduced in the paper. Given the context, it would be designed to address limitations in existing datasets for world-grounded human and camera pose estimation. This suggests it contains accurately annotated 3D human poses (possibly SMPL-X parameters), camera trajectories, and scene information within a global coordinate system. The dataset likely features <strong>diverse human motions</strong>, including interactions, and <strong>realistic camera movements</strong>, perhaps mimicking cinematic techniques. The aim is to facilitate training and evaluation of models that can jointly estimate human and camera trajectories with accurate scale in real-world coordinates, overcoming the scaleless nature of monocular video. WHAC-A-Mole probably involves a comprehensive set of animated subjects and moving viewpoints for robust training. This synthetic nature allows for controlled variation and precise annotation, which is often lacking in real-world datasets. The dataset is probably split into training and testing sets for robust evaluation.</p><h4 class="relative group">Accurate Recovery<div id=accurate-recovery class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#accurate-recovery aria-label=Anchor>#</a></span></h4><p>Accurate recovery in the context of human pose estimation and camera trajectory estimation is a multifaceted challenge. <strong>Achieving high accuracy requires addressing ambiguities inherent in monocular vision</strong>, such as depth perception and scale determination. The synergy of combining camera-frame estimations, motion cues, and robust optimization techniques holds promise for recovering both human poses and camera trajectories with minimized error. <strong>Precise camera calibration is vital for accurate recovery</strong> for pose and camera parameters, and using external information can assist this process. Furthermore, developing novel metrics that adequately capture the nuanced aspects of accuracy becomes essential for evaluating improvements of the results. It needs to incorporate a balance of both human and camera recovery to ensure the estimation is good, and it is important to also take into account motion.</p><h4 class="relative group">Societal Impact<div id=societal-impact class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#societal-impact aria-label=Anchor>#</a></span></h4><p>This work, while advancing human pose and camera trajectory estimation, carries potential societal impacts that warrant careful consideration. On the positive side, the technology could revolutionize fields like <strong>motion capture for film and gaming,</strong> enabling more realistic and accessible character animation. It could also contribute to <strong>advancements in healthcare</strong>, allowing for remote monitoring of patients&rsquo; movements and rehabilitation progress. Furthermore, its potential applications in <strong>human-robot interaction</strong> could lead to more intuitive and seamless collaborations. However, there is a <strong>risk of misuse for surveillance purposes</strong>. The ability to accurately track human movements in the world, even from monocular video, could be exploited for unwarranted monitoring and tracking of individuals, raising serious privacy concerns. It will also be used for unwanted surveillance as it recovers human trajectories in the world frame. To mitigate these risks, responsible development practices, including <strong>robust privacy safeguards, ethical guidelines, and transparent communication</strong> about the technology&rsquo;s capabilities and limitations, are crucial. Open discussions involving researchers, policymakers, and the public are necessary to ensure that this technology is used in a way that benefits society while respecting individual rights and freedoms.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x2.png alt></figure></p><blockquote><p>üîº The figure illustrates the WHAC framework&rsquo;s workflow. It starts with an SMPL-X estimator that outputs camera-frame SMPL-X data with initially unknown depth. The depth is then recovered (Section 3.2). Simultaneously, visual odometry (VO) provides a scaleless camera trajectory. This trajectory is used to canonicalize (standardize) the human motion data, allowing for the estimation of human velocity and subsequently, scale (Section 3.3). A more refined camera trajectory is then derived, incorporating the scale information (Section 3.4). This refined camera trajectory is then used to further improve the accuracy of the human trajectory.</p><details><summary>read the caption</summary>Figure 2: Overview of WHAC. SMPL-X estimator extracts camera-frame SMPL-X with dummy depth, which is recovered in Sec.¬†3.2. The scaleless camera trajectory estimated by VO is then used to canonicalize the human trajectory to estimate its velocity and thus scale in Sec.¬†3.3. A camera trajectory is then derived for alignment and scale recovery, which subsequently updates the human trajectory in Sec.¬†3.4.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x3.png alt></figure></p><blockquote><p>üîº Figure 3 demonstrates the ambiguity in estimating 3D human trajectories from monocular video. Panel (a) shows that different camera trajectories (at different scales) will produce vastly different human trajectories, even if the camera-frame human root depth and translation are kept consistent. This highlights the challenge of scale estimation. Panel (b) illustrates that the same image could result from different combinations of focal length and human root depth, further emphasizing the ill-posed nature of the problem.</p><details><summary>read the caption</summary>Figure 3: a) Human trajectories HùêªHitalic_H derived from camera trajectories Cùê∂Citalic_C of different scales can be vastly different in both shape and direction, despite that the same camera-frame human root depth dtsubscriptùëëùë°d_{t}italic_d start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and translations thcsubscriptsuperscriptùë°ùëê‚Ñét^{c}_{h}italic_t start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT are used. b) Different pairs of focal length fùëìfitalic_f and tzsubscriptùë°ùëßt_{z}italic_t start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT can correspond to the same image.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x4.png alt></figure></p><blockquote><p>üîº Figure 4 visualizes examples from the WHAC-A-Mole dataset. Each example shows three rows: the top row displays an overview of the scene with the camera trajectory highlighted, the second row shows a camera view from that trajectory, and the bottom row presents the same camera view with SMPL-X body annotations overlaid. The dataset&rsquo;s motion sequences are from three sources: AMASS (a), DLP-MoCap (b-c), and DD100 (d-e).</p><details><summary>read the caption</summary>Figure 4: Visualization of WHAC-A-Mole sample sequences, animated with a) AMASS, b-c) DLP-MoCap, and d-e) DD100. In each sample, the first row depicts the overview (note the camera trajectory shown in bright rays), and the second and the third rows show the camera view and overlaid SMPL-X annotations.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x5.png alt></figure></p><blockquote><p>üîº Figure 5 presents challenging scenarios where motion estimation alone might fail. It showcases WHAC&rsquo;s ability to leverage information from human motion, camera movement, and scene context for improved accuracy. Specifically: (a) shows a skateboarding example, where the human may appear stationary in the camera frame, but is actually moving in the world; (b) shows a treadmill example where the human is moving, but the root translation in the world frame is minimal; and (c) demonstrates WHAC handling a fast-moving scene from a real-world video, again highlighting its ability to combine multiple sources of information.</p><details><summary>read the caption</summary>Figure 5: Visualization on in-the-wild hard cases. WHAC leverages human-camera-scene collaboration to resolve cases where motion prior alone would fail: a) Skateboarding and b) Treadmill. c) WHAC can also handle fast cases.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x6.png alt></figure></p><blockquote><p>üîº This figure visualizes the results of the proposed WHAC method on the EMDB dataset, focusing on world-space trajectory estimation. The top row (a1 and b1) shows camera trajectories, while the bottom row (a2 and b2) shows corresponding human trajectories. The plots clearly demonstrate WHAC&rsquo;s ability to accurately recover both camera and human movements, including scale, in the 3D world coordinate system. The example in sequence &lsquo;b&rsquo; highlights this capability, accurately capturing the downward motion of a human descending stairs. The grid lines in the plots represent a 2-meter spacing.</p><details><summary>read the caption</summary>Figure 6: Visualization of world space results on the EMDB dataset. a1) and b1) depict camera trajectories, while a2) and b2) illustrate human trajectories. Notably, in sequence b, the human is descending stairs, and WHAC effectively captures the global trajectory, indicating a downward direction besides recovering the absolute trajectory scale in the world space. The grid size in the plots is 2m.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x7.png alt></figure></p><blockquote><p>üîº Figure 7 visualizes the results of WHAC (World-grounded Humans and Cameras) on the WHAC-A-Mole dataset, demonstrating its ability to estimate human poses and shapes accurately in challenging scenarios. Each sample in the figure shows two rows: the top row displays the original video frames, while the bottom row overlays the estimated SMPL-X model on top of the video frames. The figure showcases several challenging cases: scenes with severe occlusions, intricate human interactions, and dynamic poses such as dancing, illustrating the robustness and accuracy of the WHAC method.</p><details><summary>read the caption</summary>Figure 7: Visualization of camera space results on WHAC-A-Mole dataset. Each sample comprises two rows: the first row displays the original input frames from the sequence, while the second row overlays the SMPL-X results. This visualization showcases WHAC‚Äôs performance on challenging scenes, including sequences with severe occlusions, intricate human interactions, and dynamic dancing poses.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2403.12959/x8.png alt></figure></p><blockquote><p>üîº The MotionVelocimeter module takes as input 3D joints from SMPL-X meshes that have been canonicalized (aligned to a standard pose). It processes these joints to output root velocities, also in the canonical space. This means the module focuses on the speed and direction of the human&rsquo;s root movement, relative to the starting point of the sequence. The use of canonicalized data simplifies the task and makes the velocity estimation more robust.</p><details><summary>read the caption</summary>Figure 8: Illustration of MotionVelocimeter module. The inputs are canonicalized 3D joints regressed from SMPL-X meshes, and the outputs are root velocities in the canonical space.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T2.5.5><thead class=ltx_thead><tr class=ltx_tr id=S5.T2.5.5.5><th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id=S5.T2.5.5.5.6 style=padding-left:4pt;padding-right:4pt></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.1.1.1.1 style=padding-left:4pt;padding-right:4pt>PA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.2.2.2 style=padding-left:4pt;padding-right:4pt>W-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.2.m1.1a"><mo id="S5.T2.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T2.2.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.3.3.3.3 style=padding-left:4pt;padding-right:4pt>WA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.3.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.3.m1.1a"><mo id="S5.T2.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T2.3.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.4.4.4.4 style=padding-left:4pt;padding-right:4pt>H-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.4.4.4.4.m1.1"><semantics id="S5.T2.4.4.4.4.m1.1a"><mo id="S5.T2.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T2.4.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.4.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.5.5.5.7 style=padding-left:4pt;padding-right:4pt>H-AS</th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.5.5.5.5 style=padding-left:4pt;padding-right:4pt>C-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.5.5.5.5.m1.1"><semantics id="S5.T2.5.5.5.5.m1.1a"><mo id="S5.T2.5.5.5.5.m1.1.1" stretchy="false" xref="S5.T2.5.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.5.m1.1b"><ci id="S5.T2.5.5.5.5.m1.1.1.cmml" xref="S5.T2.5.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.5.5.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T2.5.5.5.8 style=padding-left:4pt;padding-right:4pt>C-AS</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T2.5.5.6.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T2.5.5.6.1.1 style=padding-left:4pt;padding-right:4pt>OSX*¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib24 title>24</a>]</cite> + DPVO¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib39 title>39</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.2 style=padding-left:4pt;padding-right:4pt>90.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.3 style=padding-left:4pt;padding-right:4pt>1036.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.4 style=padding-left:4pt;padding-right:4pt>390.7</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.5 style=padding-left:4pt;padding-right:4pt>180.5</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.6 style=padding-left:4pt;padding-right:4pt>0.5</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.7 style=padding-left:4pt;padding-right:4pt>0.5</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T2.5.5.6.1.8 style=padding-left:4pt;padding-right:4pt>7.3</td></tr><tr class=ltx_tr id=S5.T2.5.5.7.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T2.5.5.7.2.1 style=padding-left:4pt;padding-right:4pt>SMPLer-X-B*¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib6 title>6</a>]</cite> + DPVO¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib39 title>39</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.2 style=padding-left:4pt;padding-right:4pt>76.7</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.3 style=padding-left:4pt;padding-right:4pt>842.3</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.4 style=padding-left:4pt;padding-right:4pt>335.4</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.5 style=padding-left:4pt;padding-right:4pt>138.3</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.6 style=padding-left:4pt;padding-right:4pt>0.5</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.7 style=padding-left:4pt;padding-right:4pt>0.5</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.7.2.8 style=padding-left:4pt;padding-right:4pt>7.3</td></tr><tr class=ltx_tr id=S5.T2.5.5.8.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T2.5.5.8.3.1 style=padding-left:4pt;padding-right:4pt>WHAC (GT Gyro)</th><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.2 style=padding-left:4pt;padding-right:4pt>76.5</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.3 style=padding-left:4pt;padding-right:4pt>343.8</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.4 style=padding-left:4pt;padding-right:4pt>182.0</td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.8.3.5.1>103.5</span></td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.8.3.6.1>0.9</span></td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.8.3.7.1>0.5</span></td><td class="ltx_td ltx_align_right" id=S5.T2.5.5.8.3.8 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.8.3.8.1>1.3</span></td></tr><tr class=ltx_tr id=S5.T2.5.5.9.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T2.5.5.9.4.1 style=padding-left:4pt;padding-right:4pt>WHAC</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.2.1>76.5</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.3.1>343.3</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.4.1>182.0</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.5.1>103.5</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.6.1>0.9</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.7.1>0.5</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T2.5.5.9.4.8 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T2.5.5.9.4.8.1>1.3</span></td></tr></tbody></table></table></figure><blockquote><p>üîº Table 2 presents a comparison of different methods&rsquo; performance on the WHAC-A-Mole dataset, focusing on world-frame evaluation metrics. The asterisk (*) indicates methods adapted for world-grounded evaluation. The metrics include PA-MPJPE (Procrustes-aligned mean per joint position error), W-MPJPE (world-frame MPJPE using the first two frames for alignment), WA-MPJPE (world-frame MPJPE using the entire sequence for alignment), H-ATE (human average trajectory error), H-AS (human alignment scale), C-ATE (camera average trajectory error), and C-AS (camera alignment scale). H-AS and C-AS values close to 1.0 represent better scale estimation accuracy.</p><details><summary>read the caption</summary>Table 2: World-frame evaluation on WHAC-A-Mole. *: adapted to world-grounded evaluation. H-AS and C-AS: the closer to 1.0, the better.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T3.5.5><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T3.5.5.5><th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id=S5.T3.5.5.5.6 style=padding-left:4pt;padding-right:4pt></th><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.1.1.1.1 style=padding-left:4pt;padding-right:4pt>PA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T3.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.m1.1d">‚Üì</annotation></semantics></math></td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.2.2.2.2 style=padding-left:4pt;padding-right:4pt>W-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.2.m1.1a"><mo id="S5.T3.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T3.2.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.m1.1b"><ci id="S5.T3.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.2.m1.1d">‚Üì</annotation></semantics></math></td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.3.3.3.3 style=padding-left:4pt;padding-right:4pt>WA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.3.m1.1a"><mo id="S5.T3.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T3.3.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.m1.1b"><ci id="S5.T3.3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.3.m1.1d">‚Üì</annotation></semantics></math></td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.4.4.4.4 style=padding-left:4pt;padding-right:4pt>H-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.4.4.4.4.m1.1"><semantics id="S5.T3.4.4.4.4.m1.1a"><mo id="S5.T3.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T3.4.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.4.m1.1b"><ci id="S5.T3.4.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.4.m1.1d">‚Üì</annotation></semantics></math></td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.5.5.5.7 style=padding-left:4pt;padding-right:4pt>H-AS</td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.5.5.5.5 style=padding-left:4pt;padding-right:4pt>C-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.5.5.5.5.m1.1"><semantics id="S5.T3.5.5.5.5.m1.1a"><mo id="S5.T3.5.5.5.5.m1.1.1" stretchy="false" xref="S5.T3.5.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.5.m1.1b"><ci id="S5.T3.5.5.5.5.m1.1.1.cmml" xref="S5.T3.5.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.5.5.m1.1d">‚Üì</annotation></semantics></math></td><td class="ltx_td ltx_align_right ltx_border_tt" id=S5.T3.5.5.5.8 style=padding-left:4pt;padding-right:4pt>C-AS</td></tr><tr class=ltx_tr id=S5.T3.5.5.6.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T3.5.5.6.1.1 style=padding-left:4pt;padding-right:4pt>GLAMR¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib45 title>45</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.2 style=padding-left:4pt;padding-right:4pt>56.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.3 style=padding-left:4pt;padding-right:4pt>756.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.4 style=padding-left:4pt;padding-right:4pt>286.2</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.5 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.6 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.7 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.6.1.8 style=padding-left:4pt;padding-right:4pt>-</td></tr><tr class=ltx_tr id=S5.T3.5.5.7.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.5.5.7.2.1 style=padding-left:4pt;padding-right:4pt>SLAHMR¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib43 title>43</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.2 style=padding-left:4pt;padding-right:4pt>61.5</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.3 style=padding-left:4pt;padding-right:4pt>807.4</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.4 style=padding-left:4pt;padding-right:4pt>336.9</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.5 style=padding-left:4pt;padding-right:4pt>207.8</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.6 style=padding-left:4pt;padding-right:4pt>1.9</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.7 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.7.2.8 style=padding-left:4pt;padding-right:4pt>-</td></tr><tr class=ltx_tr id=S5.T3.5.5.8.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.5.5.8.3.1 style=padding-left:4pt;padding-right:4pt>WHAM¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib35 title>35</a>]</cite> (GT Gyro)</th><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.2 style=padding-left:4pt;padding-right:4pt>41.9</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.3 style=padding-left:4pt;padding-right:4pt>436.4</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.4 style=padding-left:4pt;padding-right:4pt>165.9</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.5 style=padding-left:4pt;padding-right:4pt>83.2</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.6 style=padding-left:4pt;padding-right:4pt>1.5</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.7 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.8.3.8 style=padding-left:4pt;padding-right:4pt>-</td></tr><tr class=ltx_tr id=S5.T3.5.5.9.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T3.5.5.9.4.1 style=padding-left:4pt;padding-right:4pt>OSX-L*¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib24 title>24</a>]</cite> + DPVO¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib39 title>39</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.2 style=padding-left:4pt;padding-right:4pt>99.9</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.3 style=padding-left:4pt;padding-right:4pt>1186.2</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.4 style=padding-left:4pt;padding-right:4pt>458.8</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.5 style=padding-left:4pt;padding-right:4pt>235.4</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.6 style=padding-left:4pt;padding-right:4pt>2.3</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.9.4.7.1>14.8</span></td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T3.5.5.9.4.8 style=padding-left:4pt;padding-right:4pt>5.1</td></tr><tr class=ltx_tr id=S5.T3.5.5.10.5><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.5.5.10.5.1 style=padding-left:4pt;padding-right:4pt>SMPLer-X-B*¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib6 title>6</a>]</cite> + DPVO¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib39 title>39</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.2 style=padding-left:4pt;padding-right:4pt>42.5</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.3 style=padding-left:4pt;padding-right:4pt>930.1</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.4 style=padding-left:4pt;padding-right:4pt>375.8</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.5 style=padding-left:4pt;padding-right:4pt>200.6</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.6 style=padding-left:4pt;padding-right:4pt>2.0</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.10.5.7.1>14.8</span></td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.10.5.8 style=padding-left:4pt;padding-right:4pt>5.1</td></tr><tr class=ltx_tr id=S5.T3.5.5.11.6><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.5.5.11.6.1 style=padding-left:4pt;padding-right:4pt>WHAC (GT Gyro)</th><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.11.6.2.1>39.4</span></td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.3 style=padding-left:4pt;padding-right:4pt>392.5</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.4 style=padding-left:4pt;padding-right:4pt>143.1</td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.11.6.5.1>75.8</span></td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.11.6.6.1>1.1</span></td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.11.6.7.1>14.8</span></td><td class="ltx_td ltx_align_right" id=S5.T3.5.5.11.6.8 style=padding-left:4pt;padding-right:4pt>1.5</td></tr><tr class=ltx_tr id=S5.T3.5.5.12.7><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T3.5.5.12.7.1 style=padding-left:4pt;padding-right:4pt>WHAC</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.2.1>39.4</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.3.1>389.4</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.4.1>142.2</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.5 style=padding-left:4pt;padding-right:4pt>76.7</td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.6.1>1.1</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.7.1>14.8</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T3.5.5.12.7.8 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T3.5.5.12.7.8.1>1.4</span></td></tr></tbody></table></table></figure><blockquote><p>üîº Table 3 presents a comparison of different methods for estimating human and camera trajectories in a world coordinate system, specifically using the EMDB2 dataset. The metrics used are PA-MPJPE (Procrustes-aligned Mean Per Joint Position Error), W-MPJPE (world-frame MPJPE), WA-MPJPE (world-aligned MPJPE), H-ATE (Human Average Trajectory Error), H-AS (Human Alignment Scale), C-ATE (Camera Average Trajectory Error), and C-AS (Camera Alignment Scale). The lower the values for MPJPE and ATE, the better the accuracy of the trajectory estimation. The closer H-AS and C-AS are to 1.0, the better the scale estimation. The asterisk (*) indicates that methods were adapted for world-grounded evaluation. This adaptation is crucial because these methods were originally designed for camera-centric estimations; adapting them ensures fair comparison with world-grounded methods.</p><details><summary>read the caption</summary>Table 3: World-frame evaluation on EMDB2. *: adapted to world-grounded evaluation. H-AS and C-AS: the closer to 1.0, the better.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S5.T4.6><thead class=ltx_thead><tr class=ltx_tr id=S5.T4.6.6><th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id=S5.T4.6.6.7 style=padding-left:4pt;padding-right:4pt></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.1.1.1 style=padding-left:4pt;padding-right:4pt>PA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.m1.1a"><mo id="S5.T4.1.1.1.m1.1.1" stretchy="false" xref="S5.T4.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.2.2 style=padding-left:4pt;padding-right:4pt>PA-PVE-all<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.2.2.2.m1.1"><semantics id="S5.T4.2.2.2.m1.1a"><mo id="S5.T4.2.2.2.m1.1.1" stretchy="false" xref="S5.T4.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.m1.1b"><ci id="S5.T4.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.3.3.3 style=padding-left:4pt;padding-right:4pt>PVE-all<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.3.3.3.m1.1"><semantics id="S5.T4.3.3.3.m1.1a"><mo id="S5.T4.3.3.3.m1.1.1" stretchy="false" xref="S5.T4.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.m1.1b"><ci id="S5.T4.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.4.4.4 style=padding-left:4pt;padding-right:4pt>PVE-hand<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.4.4.4.m1.1"><semantics id="S5.T4.4.4.4.m1.1a"><mo id="S5.T4.4.4.4.m1.1.1" stretchy="false" xref="S5.T4.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.m1.1b"><ci id="S5.T4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.4.4.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.5.5.5 style=padding-left:4pt;padding-right:4pt>PVE-face<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.5.5.5.m1.1"><semantics id="S5.T4.5.5.5.m1.1a"><mo id="S5.T4.5.5.5.m1.1.1" stretchy="false" xref="S5.T4.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.m1.1b"><ci id="S5.T4.5.5.5.m1.1.1.cmml" xref="S5.T4.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.5.5.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T4.6.6.6 style=padding-left:4pt;padding-right:4pt>Accl.<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.6.6.6.m1.1"><semantics id="S5.T4.6.6.6.m1.1a"><mo id="S5.T4.6.6.6.m1.1.1" stretchy="false" xref="S5.T4.6.6.6.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.m1.1b"><ci id="S5.T4.6.6.6.m1.1.1.cmml" xref="S5.T4.6.6.6.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.6.6.m1.1d">‚Üì</annotation></semantics></math></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T4.6.7.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T4.6.7.1.1 style=padding-left:4pt;padding-right:4pt>GLAMR¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib45 title>45</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.2 style=padding-left:4pt;padding-right:4pt>114.3</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.3 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.4 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.5 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.6 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.7.1.7 style=padding-left:4pt;padding-right:4pt>173.5</td></tr><tr class=ltx_tr id=S5.T4.6.8.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T4.6.8.2.1 style=padding-left:4pt;padding-right:4pt>SLAHMR¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib43 title>43</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.2 style=padding-left:4pt;padding-right:4pt>79.1</td><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.3 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.4 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.5 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.6 style=padding-left:4pt;padding-right:4pt>-</td><td class="ltx_td ltx_align_right" id=S5.T4.6.8.2.7 style=padding-left:4pt;padding-right:4pt>25.8</td></tr><tr class=ltx_tr id=S5.T4.6.9.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T4.6.9.3.1 style=padding-left:4pt;padding-right:4pt>Hand4Whole¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib28 title>28</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.2 style=padding-left:4pt;padding-right:4pt>71.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.3 style=padding-left:4pt;padding-right:4pt>59.8</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.4 style=padding-left:4pt;padding-right:4pt>127.6</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.5 style=padding-left:4pt;padding-right:4pt>48.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.6 style=padding-left:4pt;padding-right:4pt>41.2</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T4.6.9.3.7 style=padding-left:4pt;padding-right:4pt>27.2</td></tr><tr class=ltx_tr id=S5.T4.6.10.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T4.6.10.4.1 style=padding-left:4pt;padding-right:4pt>OSX-L¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib24 title>24</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.2 style=padding-left:4pt;padding-right:4pt>66.5</td><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.3 style=padding-left:4pt;padding-right:4pt>54.6</td><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.4 style=padding-left:4pt;padding-right:4pt>115.7</td><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.5 style=padding-left:4pt;padding-right:4pt>50.5</td><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.6 style=padding-left:4pt;padding-right:4pt>41.0</td><td class="ltx_td ltx_align_right" id=S5.T4.6.10.4.7 style=padding-left:4pt;padding-right:4pt>24.7</td></tr><tr class=ltx_tr id=S5.T4.6.11.5><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T4.6.11.5.1 style=padding-left:4pt;padding-right:4pt>SMPLer-X-B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib6 title>6</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.2 style=padding-left:4pt;padding-right:4pt>47.1</td><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.3 style=padding-left:4pt;padding-right:4pt>40.7</td><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.4 style=padding-left:4pt;padding-right:4pt>72.7</td><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.5 style=padding-left:4pt;padding-right:4pt>43.7</td><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.6 style=padding-left:4pt;padding-right:4pt>32.4</td><td class="ltx_td ltx_align_right" id=S5.T4.6.11.5.7 style=padding-left:4pt;padding-right:4pt>18.9</td></tr><tr class=ltx_tr id=S5.T4.6.12.6><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T4.6.12.6.1 style=padding-left:4pt;padding-right:4pt>WHAC</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.2.1>46.9</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.3.1>39.0</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.4.1>64.7</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.5.1>41.0</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.6.1>26.3</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T4.6.12.6.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T4.6.12.6.7.1>11.6</span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparison of various camera-frame methods for expressive human pose and shape estimation using the EgoBody (EgoSet) dataset. The evaluation metrics include PA-MPJPE, PA-PVE-all, PVE-all, PVE-hand, PVE-face, and Accl. PA-MPJPE measures the error in pose estimation after aligning the root joint, while PVE measures per-vertex error across different parts of the body (whole body, hands, and face). Accl. represents the acceleration error, reflecting the smoothness of the estimated motion. Only whole-body methods (those using SMPL-X models) are included in the PVE variants.</p><details><summary>read the caption</summary>Table 4: Results of camera-frame methods on EgoBody (EgoSet) with SMPL-X ground truths. PVE variants are measured for whole-body (SMPL-X) methods only.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S5.T5.8><thead class=ltx_thead><tr class=ltx_tr id=S5.T5.8.9.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S5.T5.8.9.1.1 rowspan=2 style=padding-left:4pt;padding-right:4pt><span class=ltx_text id=S5.T5.8.9.1.1.1>Method</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan=4 id=S5.T5.8.9.1.2 style=padding-left:4pt;padding-right:4pt>EMDB1¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib19 title>19</a>]</cite></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan=4 id=S5.T5.8.9.1.3 style=padding-left:4pt;padding-right:4pt>3DPW¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib41 title>41</a>]</cite></th></tr><tr class=ltx_tr id=S5.T5.8.8><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.1.1.1 style=padding-left:4pt;padding-right:4pt>PA-PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.1.1.1.m1.1"><semantics id="S5.T5.1.1.1.m1.1a"><mo id="S5.T5.1.1.1.m1.1.1" stretchy="false" xref="S5.T5.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.m1.1b"><ci id="S5.T5.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.2.2.2 style=padding-left:4pt;padding-right:4pt>PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.2.2.2.m1.1"><semantics id="S5.T5.2.2.2.m1.1a"><mo id="S5.T5.2.2.2.m1.1.1" stretchy="false" xref="S5.T5.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.m1.1b"><ci id="S5.T5.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.3.3.3 style=padding-left:4pt;padding-right:4pt>T-PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.3.3.3.m1.1"><semantics id="S5.T5.3.3.3.m1.1a"><mo id="S5.T5.3.3.3.m1.1.1" stretchy="false" xref="S5.T5.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.m1.1b"><ci id="S5.T5.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.4.4.4 style=padding-left:4pt;padding-right:4pt>Accl.<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.4.4.4.m1.1"><semantics id="S5.T5.4.4.4.m1.1a"><mo id="S5.T5.4.4.4.m1.1.1" stretchy="false" xref="S5.T5.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.m1.1b"><ci id="S5.T5.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.4.4.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.5.5.5 style=padding-left:4pt;padding-right:4pt>PA-PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.5.5.5.m1.1"><semantics id="S5.T5.5.5.5.m1.1a"><mo id="S5.T5.5.5.5.m1.1.1" stretchy="false" xref="S5.T5.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.5.m1.1b"><ci id="S5.T5.5.5.5.m1.1.1.cmml" xref="S5.T5.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.5.5.5.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.6.6.6 style=padding-left:4pt;padding-right:4pt>PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.6.6.6.m1.1"><semantics id="S5.T5.6.6.6.m1.1a"><mo id="S5.T5.6.6.6.m1.1.1" stretchy="false" xref="S5.T5.6.6.6.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.6.6.6.m1.1b"><ci id="S5.T5.6.6.6.m1.1.1.cmml" xref="S5.T5.6.6.6.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.6.6.6.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.7.7.7 style=padding-left:4pt;padding-right:4pt>T-PVE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.7.7.7.m1.1"><semantics id="S5.T5.7.7.7.m1.1a"><mo id="S5.T5.7.7.7.m1.1.1" stretchy="false" xref="S5.T5.7.7.7.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.7.7.7.m1.1b"><ci id="S5.T5.7.7.7.m1.1.1.cmml" xref="S5.T5.7.7.7.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.7.7.7.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id=S5.T5.8.8.8 style=padding-left:4pt;padding-right:4pt>Accl.<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.8.8.8.m1.1"><semantics id="S5.T5.8.8.8.m1.1a"><mo id="S5.T5.8.8.8.m1.1.1" stretchy="false" xref="S5.T5.8.8.8.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.8.8.8.m1.1b"><ci id="S5.T5.8.8.8.m1.1.1.cmml" xref="S5.T5.8.8.8.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.8.8.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.8.8.8.m1.1d">‚Üì</annotation></semantics></math></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T5.8.10.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T5.8.10.1.1 style=padding-left:4pt;padding-right:4pt>Hand4Whole¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib28 title>28</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.2 style=padding-left:4pt;padding-right:4pt>99.5</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.3 style=padding-left:4pt;padding-right:4pt>143.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.4 style=padding-left:4pt;padding-right:4pt>36851.8</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.5 style=padding-left:4pt;padding-right:4pt>34.2</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.6 style=padding-left:4pt;padding-right:4pt>81.7</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.7 style=padding-left:4pt;padding-right:4pt>124.7</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.8 style=padding-left:4pt;padding-right:4pt>30279.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T5.8.10.1.9 style=padding-left:4pt;padding-right:4pt>31.0</td></tr><tr class=ltx_tr id=S5.T5.8.11.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T5.8.11.2.1 style=padding-left:4pt;padding-right:4pt>OSX-L¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib24 title>24</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.2 style=padding-left:4pt;padding-right:4pt>93.3</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.3 style=padding-left:4pt;padding-right:4pt>134.0</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.4 style=padding-left:4pt;padding-right:4pt>45526.0</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.5 style=padding-left:4pt;padding-right:4pt>30.3</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.6 style=padding-left:4pt;padding-right:4pt>76.9</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.7 style=padding-left:4pt;padding-right:4pt>117.8</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.8 style=padding-left:4pt;padding-right:4pt>38472.2</td><td class="ltx_td ltx_align_right" id=S5.T5.8.11.2.9 style=padding-left:4pt;padding-right:4pt>24.9</td></tr><tr class=ltx_tr id=S5.T5.8.12.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T5.8.12.3.1 style=padding-left:4pt;padding-right:4pt>SMPLer-X-B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib6 title>6</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.2 style=padding-left:4pt;padding-right:4pt>68.2</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.3 style=padding-left:4pt;padding-right:4pt>99.3</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.4 style=padding-left:4pt;padding-right:4pt>41298.0</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.5 style=padding-left:4pt;padding-right:4pt>24.4</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.12.3.6.1>62.6</span></td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.7 style=padding-left:4pt;padding-right:4pt>95.6</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.8 style=padding-left:4pt;padding-right:4pt>32532.0</td><td class="ltx_td ltx_align_right" id=S5.T5.8.12.3.9 style=padding-left:4pt;padding-right:4pt>24.8</td></tr><tr class=ltx_tr id=S5.T5.8.13.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T5.8.13.4.1 style=padding-left:4pt;padding-right:4pt>WHAC</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.2.1>61.0</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.3.1>91.2</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.4.1>140.2</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.5.1>18.4</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.6 style=padding-left:4pt;padding-right:4pt>62.8</td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.7.1>91.9</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.8 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.8.1>260.8</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T5.8.13.4.9 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T5.8.13.4.9.1>20.3</span></td></tr></tbody></table></table></figure><blockquote><p>üîº Table 5 presents a comparison of camera-frame evaluation metrics for different expressive human pose and shape estimation (EHPS) methods on the EMDB1 and 3DPW datasets. The metrics evaluated include Procrustes-aligned Per Vertex Error (PA-PVE), Per Vertex Error (PVE), Translation-aware PVE (T-PVE), and Acceleration Error (Accl.). The results show that WHAC outperforms existing mainstream EHPS methods in terms of recovering meaningful human depth (indicated by T-PVE) and achieving lower acceleration errors (Accl).</p><details><summary>read the caption</summary>Table 5: More camera-frame evaluations on EMDB1 and 3DPW. Compared to existing mainstream EHPS methods, WHAC recovers meaningful human depths (T-PVE) and achieves lower acceleration errors (Accl.).</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S5.T6.6><thead class=ltx_thead><tr class=ltx_tr id=S5.T6.6.6><th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id=S5.T6.6.6.7 style=padding-left:4pt;padding-right:4pt></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.1.1.1 style=padding-left:4pt;padding-right:4pt>PA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.m1.1a"><mo id="S5.T6.1.1.1.m1.1.1" stretchy="false" xref="S5.T6.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.m1.1b"><ci id="S5.T6.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.2.2.2 style=padding-left:4pt;padding-right:4pt>PA-PVE-all<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.2.2.2.m1.1"><semantics id="S5.T6.2.2.2.m1.1a"><mo id="S5.T6.2.2.2.m1.1.1" stretchy="false" xref="S5.T6.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.m1.1b"><ci id="S5.T6.2.2.2.m1.1.1.cmml" xref="S5.T6.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.3.3.3 style=padding-left:4pt;padding-right:4pt>PVE-all<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.3.3.3.m1.1"><semantics id="S5.T6.3.3.3.m1.1a"><mo id="S5.T6.3.3.3.m1.1.1" stretchy="false" xref="S5.T6.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.3.m1.1b"><ci id="S5.T6.3.3.3.m1.1.1.cmml" xref="S5.T6.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.4.4.4 style=padding-left:4pt;padding-right:4pt>PVE-hand<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.4.4.4.m1.1"><semantics id="S5.T6.4.4.4.m1.1a"><mo id="S5.T6.4.4.4.m1.1.1" stretchy="false" xref="S5.T6.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.4.4.4.m1.1b"><ci id="S5.T6.4.4.4.m1.1.1.cmml" xref="S5.T6.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.4.4.4.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.5.5.5 style=padding-left:4pt;padding-right:4pt>PVE-face<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.5.5.5.m1.1"><semantics id="S5.T6.5.5.5.m1.1a"><mo id="S5.T6.5.5.5.m1.1.1" stretchy="false" xref="S5.T6.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.5.5.5.m1.1b"><ci id="S5.T6.5.5.5.m1.1.1.cmml" xref="S5.T6.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.5.5.5.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T6.6.6.6 style=padding-left:4pt;padding-right:4pt>Accl.<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.6.6.6.m1.1"><semantics id="S5.T6.6.6.6.m1.1a"><mo id="S5.T6.6.6.6.m1.1.1" stretchy="false" xref="S5.T6.6.6.6.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.6.6.6.m1.1b"><ci id="S5.T6.6.6.6.m1.1.1.cmml" xref="S5.T6.6.6.6.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.6.6.6.m1.1d">‚Üì</annotation></semantics></math></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T6.6.7.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T6.6.7.1.1 style=padding-left:4pt;padding-right:4pt>OSX-L¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib24 title>24</a>]</cite></th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.2 style=padding-left:4pt;padding-right:4pt>90.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.3 style=padding-left:4pt;padding-right:4pt>88.1</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.4 style=padding-left:4pt;padding-right:4pt>155.7</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.5 style=padding-left:4pt;padding-right:4pt>83.3</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.6 style=padding-left:4pt;padding-right:4pt>85.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T6.6.7.1.7 style=padding-left:4pt;padding-right:4pt>38.9</td></tr><tr class=ltx_tr id=S5.T6.6.8.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T6.6.8.2.1 style=padding-left:4pt;padding-right:4pt>SMPLer-X-B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib6 title>6</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.2 style=padding-left:4pt;padding-right:4pt>76.7</td><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.3 style=padding-left:4pt;padding-right:4pt>74.8</td><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.8.2.4.1>116.2</span></td><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.8.2.5.1>70.6</span></td><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.6 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.8.2.6.1>63.1</span></td><td class="ltx_td ltx_align_right" id=S5.T6.6.8.2.7 style=padding-left:4pt;padding-right:4pt>44.0</td></tr><tr class=ltx_tr id=S5.T6.6.9.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T6.6.9.3.1 style=padding-left:4pt;padding-right:4pt>WHAC</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.9.3.2.1>76.5</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.9.3.3.1>74.8</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.4 style=padding-left:4pt;padding-right:4pt>117.8</td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.5 style=padding-left:4pt;padding-right:4pt>77.7</td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.6 style=padding-left:4pt;padding-right:4pt>63.2</td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T6.6.9.3.7 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T6.6.9.3.7.1>31.2</span></td></tr></tbody></table></table></figure><blockquote><p>üîº Table 6 presents a comparison of the performance of several camera-frame methods, including WHAC and SMPLer-X, on the WHAC-A-Mole dataset. The evaluation metrics used are PA-MPJPE, PA-PVE-all, PVE-all, PVE-hand, PVE-face, and Accl. The results show that WHAC achieves comparable performance to SMPLer-X across all metrics, but demonstrates a notably lower acceleration error, indicating better accuracy in capturing the smoothness and realism of human motion.</p><details><summary>read the caption</summary>Table 6: Results of camera-frame methods on WHAC-A-Mole. WHAC is on par with SMPLer-X but produces a lower acceleration error.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T8.3.3><thead class=ltx_thead><tr class=ltx_tr id=S5.T8.3.3.3><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S5.T8.3.3.3.4 style=padding-left:4pt;padding-right:4pt>Method</th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.1.1.1.1 style=padding-left:4pt;padding-right:4pt>WA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.1.1.1.1.m1.1"><semantics id="S5.T8.1.1.1.1.m1.1a"><mo id="S5.T8.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T8.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.1.1.1.1.m1.1b"><ci id="S5.T8.1.1.1.1.m1.1.1.cmml" xref="S5.T8.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.1.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.2.2.2.2 style=padding-left:4pt;padding-right:4pt>H-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.2.2.2.2.m1.1"><semantics id="S5.T8.2.2.2.2.m1.1a"><mo id="S5.T8.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T8.2.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.2.2.2.2.m1.1b"><ci id="S5.T8.2.2.2.2.m1.1.1.cmml" xref="S5.T8.2.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.2.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.3.3.3.3 style=padding-left:4pt;padding-right:4pt>C-ATE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.3.3.3.3.m1.1"><semantics id="S5.T8.3.3.3.3.m1.1a"><mo id="S5.T8.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T8.3.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.3.3.3.3.m1.1b"><ci id="S5.T8.3.3.3.3.m1.1.1.cmml" xref="S5.T8.3.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.3.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.3.3.3.5 style=padding-left:4pt;padding-right:4pt>C-AS</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T8.3.3.4.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T8.3.3.4.1.1 style=padding-left:4pt;padding-right:4pt>DPVO</th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.3.3.4.1.2 style=padding-left:4pt;padding-right:4pt>376.0</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.3.3.4.1.3 style=padding-left:4pt;padding-right:4pt>177.8</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.3.3.4.1.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.3.3.4.1.4.1>14.8</span></td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.3.3.4.1.5 style=padding-left:4pt;padding-right:4pt>5.10</td></tr><tr class=ltx_tr id=S5.T8.3.3.5.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T8.3.3.5.2.1 style=padding-left:4pt;padding-right:4pt>MV</th><td class="ltx_td ltx_align_right" id=S5.T8.3.3.5.2.2 style=padding-left:4pt;padding-right:4pt>233.2</td><td class="ltx_td ltx_align_right" id=S5.T8.3.3.5.2.3 style=padding-left:4pt;padding-right:4pt>129.9</td><td class="ltx_td ltx_align_right" id=S5.T8.3.3.5.2.4 style=padding-left:4pt;padding-right:4pt>134.1</td><td class="ltx_td ltx_align_right" id=S5.T8.3.3.5.2.5 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.3.3.5.2.5.1>1.10</span></td></tr><tr class=ltx_tr id=S5.T8.3.3.6.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T8.3.3.6.3.1 style=padding-left:4pt;padding-right:4pt>MV + DPVO</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.3.3.6.3.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.3.3.6.3.2.1>142.2</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.3.3.6.3.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.3.3.6.3.3.1>76.7</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.3.3.6.3.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.3.3.6.3.4.1>14.8</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.3.3.6.3.5 style=padding-left:4pt;padding-right:4pt>1.40</td></tr></tbody></table></table></figure><blockquote><p>üîº This ablation study analyzes the impact of key components (visual odometry and MotionVelocimeter) on the overall performance of the WHAC model. It assesses the effect of using visual odometry alone (DPVO), MotionVelocimeter alone (MV), and both components combined (MV + DPVO) on metrics such as weighted mean per joint position error (WA-MPJPE), human trajectory error (H-ATE), camera trajectory error (C-ATE), and camera scale accuracy (C-AS). The results demonstrate how the integration of both components enhances model performance, achieving improved accuracy in both human and camera trajectory estimation.</p><details><summary>read the caption</summary>Table 7: Ablation on key components. DPVO represents visual odometry, MV represents MotionVelocimeter.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T8.6.3><thead class=ltx_thead><tr class=ltx_tr id=S5.T8.6.3.3><th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id=S5.T8.6.3.3.4 style=padding-left:4pt;padding-right:4pt></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.4.1.1.1 style=padding-left:4pt;padding-right:4pt>T-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.4.1.1.1.m1.1"><semantics id="S5.T8.4.1.1.1.m1.1a"><mo id="S5.T8.4.1.1.1.m1.1.1" stretchy="false" xref="S5.T8.4.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.4.1.1.1.m1.1b"><ci id="S5.T8.4.1.1.1.m1.1.1.cmml" xref="S5.T8.4.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.4.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.4.1.1.1.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.5.2.2.2 style=padding-left:4pt;padding-right:4pt>W-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.5.2.2.2.m1.1"><semantics id="S5.T8.5.2.2.2.m1.1a"><mo id="S5.T8.5.2.2.2.m1.1.1" stretchy="false" xref="S5.T8.5.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.5.2.2.2.m1.1b"><ci id="S5.T8.5.2.2.2.m1.1.1.cmml" xref="S5.T8.5.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.5.2.2.2.m1.1d">‚Üì</annotation></semantics></math></th><th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id=S5.T8.6.3.3.3 style=padding-left:4pt;padding-right:4pt>WA-MPJPE<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T8.6.3.3.3.m1.1"><semantics id="S5.T8.6.3.3.3.m1.1a"><mo id="S5.T8.6.3.3.3.m1.1.1" stretchy="false" xref="S5.T8.6.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T8.6.3.3.3.m1.1b"><ci id="S5.T8.6.3.3.3.m1.1.1.cmml" xref="S5.T8.6.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.6.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T8.6.3.3.3.m1.1d">‚Üì</annotation></semantics></math></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T8.6.3.4.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T8.6.3.4.1.1 style=padding-left:4pt;padding-right:4pt>Dummy(5,000)</th><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.6.3.4.1.2 style=padding-left:4pt;padding-right:4pt>36020.4</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.6.3.4.1.3 style=padding-left:4pt;padding-right:4pt>6239.9</td><td class="ltx_td ltx_align_right ltx_border_t" id=S5.T8.6.3.4.1.4 style=padding-left:4pt;padding-right:4pt>604.6</td></tr><tr class=ltx_tr id=S5.T8.6.3.5.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T8.6.3.5.2.1 style=padding-left:4pt;padding-right:4pt>Assumed¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib20 title>20</a>]</cite></th><td class="ltx_td ltx_align_right" id=S5.T8.6.3.5.2.2 style=padding-left:4pt;padding-right:4pt>179.7</td><td class="ltx_td ltx_align_right" id=S5.T8.6.3.5.2.3 style=padding-left:4pt;padding-right:4pt>391.2</td><td class="ltx_td ltx_align_right" id=S5.T8.6.3.5.2.4 style=padding-left:4pt;padding-right:4pt>144.0</td></tr><tr class=ltx_tr id=S5.T8.6.3.6.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T8.6.3.6.3.1 style=padding-left:4pt;padding-right:4pt>GT</th><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.6.3.6.3.2 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.6.3.6.3.2.1>100.3</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.6.3.6.3.3 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.6.3.6.3.3.1>389.4</span></td><td class="ltx_td ltx_align_right ltx_border_bb" id=S5.T8.6.3.6.3.4 style=padding-left:4pt;padding-right:4pt><span class="ltx_text ltx_font_bold" id=S5.T8.6.3.6.3.4.1>142.2</span></td></tr></tbody></table></table></figure><blockquote><p>üîº This ablation study investigates the impact of using different focal length values on the accuracy of human root translation estimation. The table compares results using a dummy focal length (5000), a focal length estimated from image resolution, and ground truth focal length. The results demonstrate that using a reasonable estimate for the intrinsic parameter (focal length) significantly improves the accuracy of human root translation estimation.</p><details><summary>read the caption</summary>Table 8: Ablation on intrinsic sources. A reasonable intrinsic drastically improve human root translation estiamtion.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A4.T9.1><thead class=ltx_thead><tr class=ltx_tr id=A4.T9.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.1 style=padding-left:4pt;padding-right:4pt>Method</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.2 style=padding-left:4pt;padding-right:4pt>GLAMR<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib45 title>45</a>]</cite></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.3 style=padding-left:4pt;padding-right:4pt>SLAHMR<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib43 title>43</a>]</cite></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.4 style=padding-left:4pt;padding-right:4pt>PACE<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib21 title>21</a>]</cite></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.5 style=padding-left:4pt;padding-right:4pt>WHAM<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2403.12959v1#bib.bib35 title>35</a>]</cite></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.6 style=padding-left:4pt;padding-right:4pt>WHAC</th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=A4.T9.1.1.1.7 style=padding-left:4pt;padding-right:4pt>WHAC*</th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A4.T9.1.2.1><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.1 style=padding-left:4pt;padding-right:4pt>FPS</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.2 style=padding-left:4pt;padding-right:4pt>2.4</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.3 style=padding-left:4pt;padding-right:4pt>0.04</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.4 style=padding-left:4pt;padding-right:4pt>2.1</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.5 style=padding-left:4pt;padding-right:4pt>200</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.6 style=padding-left:4pt;padding-right:4pt>165</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id=A4.T9.1.2.1.7 style=padding-left:4pt;padding-right:4pt>2500</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of an ablation study investigating the impact of different intrinsic parameters (focal length) on the accuracy of human root translation estimation. The study compares the performance using a dummy focal length (5000), a focal length estimated from the image diagonal, and ground truth focal length. The results demonstrate that using a reasonable estimate of the focal length significantly improves the accuracy of the model.</p><details><summary>read the caption</summary>Table 8: Ablation on intrinsic sources. A reasonable intrinsic drastically improve human root translation estiamtion.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-ade030e73f2dc7b16fe774eaa2af9afe class=gallery><img src=https://ai-paper-reviewer.com/2403.12959/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2403.12959/19.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/&amp;title=WHAC:%20World-grounded%20Humans%20and%20Cameras" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/&amp;text=WHAC:%20World-grounded%20Humans%20and%20Cameras" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2403.12959/&amp;subject=WHAC:%20World-grounded%20Humans%20and%20Cameras" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2403.12959/index.md",oid_likes="likes_paper-reviews/2403.12959/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2410.22370/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Survey of User Interface Design and Interaction Techniques in Generative AI Applications</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-10-28T00:00:00+00:00>28 October 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>