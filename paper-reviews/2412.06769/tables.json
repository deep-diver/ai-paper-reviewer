[{"content": "| Method | GSM8k Acc. (%) | GSM8k # Tokens | ProntoQA Acc. (%) | ProntoQA # Tokens | ProsQA Acc. (%) | ProsQA # Tokens |\n|---|---|---|---|---|---|---|\n| CoT | 42.9 \u00b1 0.2 | 25.0 | 98.8 \u00b1 0.8 | 92.5 | 77.5 \u00b1 1.9 | 49.4 |\n| No-CoT | 16.5 \u00b1 0.5 | 2.2 | 93.8 \u00b1 0.7 | 3.0 | 76.7 \u00b1 1.0 | 8.2 |\n| iCoT | 30.0* | 2.2 | 99.8 \u00b1 0.3 | 3.0 | 98.2 \u00b1 0.3 | 8.2 |\n| Pause Token | 16.4 \u00b1 1.8 | 2.2 | 77.7 \u00b1 21.0 | 3.0 | 75.9 \u00b1 0.7 | 8.2 |\n| Coconut (Ours) | 34.1 \u00b1 1.5 | 8.2 | 99.8 \u00b1 0.2 | 9.0 | 97.0 \u00b1 0.3 | 14.2 |\n| - *w/o curriculum* | 14.4 \u00b1 0.8 | 8.2 | 52.4 \u00b1 0.4 | 9.0 | 76.1 \u00b1 0.2 | 14.2 |\n| - *w/o thought* | 21.6 \u00b1 0.5 | 2.3 | 99.9 \u00b1 0.1 | 3.0 | 95.5 \u00b1 1.1 | 8.2 |\n| - *pause as thought* | 24.1 \u00b1 0.7 | 2.2 | 100.0 \u00b1 0.1 | 3.0 | 96.6 \u00b1 0.8 | 8.2 |", "caption": "Table 1: Results on three datasets: GSM8l, ProntoQA and ProsQA. Higher accuracy indicates stronger reasoning ability, while generating fewer tokens indicates better efficiency. \u2217The result is from Deng et\u00a0al. (2024).", "description": "This table presents the results of three different reasoning tasks: GSM8k (grade-school level math problems), ProntoQA (5-hop logical reasoning problems), and ProsQA (a new logical reasoning dataset requiring stronger planning).  For each dataset and method, the table shows the accuracy and the number of tokens generated by the model.  Higher accuracy indicates stronger reasoning ability, while a lower number of tokens indicates better efficiency.  The results are compared across several methods: CoT (Chain-of-Thought), No-CoT (no chain of thought), iCoT (internalized chain of thought), Pause Token (using pause tokens), and COCONUT (the proposed method). One result marked with an asterisk (*) is taken from a previous study by Deng et al. (2024) for comparison purposes.", "section": "4 Experiments"}, {"content": "| # Nodes | # Edges | Len. of Shortest Path | # Shortest Paths |\n|---|---|---|---| \n| 23.0 | 36.0 | 3.8 | 1.6 |", "caption": "Table 2: Statistics of the graph structure in ProsQA.", "description": "Table 2 presents a statistical overview of the graph structures used in the ProsQA dataset.  It shows the average number of nodes and edges in the graphs, along with the average length of the shortest path between nodes and the average number of shortest paths.  These statistics provide insights into the complexity and structure of the logical reasoning problems within the ProsQA dataset, indicating the challenges involved in navigating and finding solutions within these graphs.", "section": "4.1 Reasoning Tasks"}, {"content": "| Dataset | Training | Validation | Test |\n|---|---|---|---|\n| GSM8k | 385,620 | 500 | 1319 |\n| ProntoQA | 9,000 | 200 | 800 |\n| ProsQA | 17,886 | 300 | 500 |", "caption": "Table 3: Statistics of the datasets.", "description": "This table presents a statistical overview of the three datasets used in the paper's experiments: GSM8k, ProntoQA, and ProsQA.  For each dataset, it shows the number of instances in the training, validation, and test sets.", "section": "4 Experiments"}, {"content": "| Method | GSM8k | ProntoQA | ProsQA |\n|---|---|---|---|\n| No-CoT | 0.03 | 0.03 | 0.08 |\n| CoT | 0.26 | 0.85 | 0.47 |\n| Coconut | 0.09 | 0.11 | 0.15 |", "caption": "Table 4: Inference time (in seconds) comparison across tasks and methods.", "description": "This table presents a comparison of the inference time, measured in seconds, for different reasoning methods across three tasks: GSM8k, ProntoQA, and ProsQA.  It shows the average time taken to generate an answer for each method, providing insights into the computational efficiency of various approaches.  The methods compared include No-CoT (no chain-of-thought), CoT (chain-of-thought), and COCONUT.", "section": "4.4 Results and Discussion"}]