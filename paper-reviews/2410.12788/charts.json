[{"figure_path": "2410.12788/charts/charts_8_0.png", "caption": "Figure 3: Performance of different methods on single-hop query in the CRUD QA dataset. ppl represents direct PPL Chunking, with a threshold of 0.5. comb. indicates PPL Chunking with dynamic combination, with a threshold of 0 when performing PPL Chunking. Precise chunk length results and performance of remaining multi-hop scenarios are included in Appendix A.3.", "description": "The chart compares the performance of different text chunking methods (rule-based, similarity-based, and two versions of Meta-Chunking) across various metrics (BLEU-1, BLEU-2, BLEU-3, BLEU-4, BLEU-Avg, ROUGE-L, BERTScore) for single-hop queries in the CRUD QA dataset.", "section": "4.2 ANALYSIS"}, {"figure_path": "2410.12788/charts/charts_9_0.png", "caption": "Figure 3: Performance of different methods on single-hop query in the CRUD QA dataset. ppl represents direct PPL Chunking, with a threshold of 0.5. comb. indicates PPL Chunking with dynamic combination, with a threshold of 0 when performing PPL Chunking. Precise chunk length results and performance of remaining multi-hop scenarios are included in Appendix A.3.", "description": "The chart compares the performance of different text chunking methods (Original, Llama_index, and three variations of PPL Chunking) on a single-hop query in the CRUD QA dataset, using BLEU scores and ROUGE-L.", "section": "4.2.2 COMPARATIVE ANALYSIS OF TWO PPL CHUNKING STRATEGIES"}]