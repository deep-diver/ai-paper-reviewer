[{"figure_path": "https://arxiv.org/html/2503.10633/x2.png", "caption": "Figure 1: \nThe model atlas - Stable Diffusion vs. Llama: The model atlas visualizes models as nodes in a graph, with directed edges indicating transformations (e.g., fine-tuning). This figure shows the top 30% most downloaded models in the Stable Diffusion and Llama regions. Node size reflects cumulative monthly downloads, and color denotes the transformation type relative to the parent model. Please zoom in to see the detailed model trajectories. We observe that the Llama region has more complex structure and a wider diversity of transformation techniques (e.g., quantization, merging) compared to Stable Diffusion. Note that node position is optimized for clarity [20] and does directly reflect distance between model weights. Zoom in to view edges, best viewed in color.", "description": "This figure visualizes a graph representation of machine learning models from the Hugging Face model repository, focusing on the Stable Diffusion and Llama model families.  Nodes represent individual models, with their size corresponding to the cumulative number of monthly downloads.  Directed edges connect models, showing the lineage of transformations applied (e.g., fine-tuning, quantization, merging). The color of an edge indicates the type of transformation. By comparing the two model families, the visualization highlights differences in model complexity and the types of transformations used, revealing that Llama models exhibit a richer diversity of transformation techniques and a more complex structure than Stable Diffusion models.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10633/x4.png", "caption": "Figure 2: The Hugging Face atlas: While this is a small subset (63,000 models) of the documented regions of HF, it already reveals significant trends. Depth and structure. The LLM connected component (CC) is deep and complex. It includes almost a third of all models. In contrast, while Flux is also substantial, its structure is much simpler and more uniform. Quantization. Zoom-in (A) highlights quantization practices across vision, language, and vision-language (V&L) models. Vision models barely use quantization, despite Flux containing more parameters (12B) than Llama (8B). Conversely, quantization is commonplace in LLMs, constituting a large proportion of models. VLMs demonstrate a balance between these extremes. Adapter and fine-tuning strategies. A notable distinction exists between discriminative (top) and generative (bottom) vision models. Discriminative models primarily employ fine-tuning, while generative models have widely adopted adapters like LoRA. The evolution of adapter adoption over time is evident: Stable-Diffusion 1.4 (SD) (1) mostly used full fine-tuning, while SD 1.5 (2), SD 2 (3), SD XL (4), and Flux (5) progressively use more adapters. Interestingly, the atlas reveals that audio models rarely use adapters, suggesting gaps in cross-community knowledge transfer. This inter-community variation is particularly evident in model merging. LLMs have embraced model merging, with merged models frequently exceeding the popularity of their parents. This raises interesting questions about the limited role of merging in vision models. For enhanced visualization, we display the top 30% most downloaded models. Zoom in to view edges, best viewed in color.", "description": "Figure 2 visualizes a portion of the Hugging Face model atlas, showcasing the relationships between 63,000 models.  The visualization highlights several key trends: the depth and complexity of Large Language Model (LLM) lineages compared to simpler structures like Flux; the prevalence of quantization in LLMs versus its near absence in vision models; and differing fine-tuning strategies between discriminative and generative vision models (discriminative models favor fine-tuning, while generative models use adapters like LoRA). The figure also shows how adapter usage has increased over time in certain model families (Stable Diffusion) and how LLMs utilize model merging more often than other model types.  The visualization includes nodes representing models and edges indicating transformations. Node sizes represent model popularity (top 30% of downloads shown), and colors represent transformation types. Zooming in is necessary to fully appreciate the details.", "section": "3. Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/x5.png", "caption": "Figure 3: Left: By analyzing over 314k models, we found that over 96%percent9696\\%96 % of CV models are situated one node away from the root, while only 55%percent5555\\%55 % of NLP models have this shallow depth. Over 5%percent55\\%5 % of NLP models have depth of at least five nodes. This shows that NLP models are much deeper than CV models, suggesting the NLP community embraces iterative refinement over new moving to the latest foundation models. Right: A significant portion of models on Hugging Face suffer from poor documentation quality.", "description": "This figure is a combined visualization showing two key aspects of the Hugging Face model repository. The left panel presents a bar chart comparing the depth of model trees in Computer Vision (CV) and Natural Language Processing (NLP).  It reveals that the vast majority (over 96%) of CV models have a shallow tree structure, with most being only one node away from the root.  Conversely, NLP models exhibit significantly greater depth, with over 5% having a depth of five or more nodes. This highlights a key difference in the model development approach between the two communities: CV leans towards using new foundation models, while NLP favors iterative refinement and building upon existing models. The right panel of the figure shows a pie chart illustrating the level of documentation available for models in the Hugging Face repository. It demonstrates that a substantial portion of models lack complete documentation.", "section": "3. Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/x6.png", "caption": "Figure 4: Quantizations are leaves:\nOur analysis of over 400,000 documented model relationships reveals that 99.41%percent99.4199.41\\%99.41 % of quantized models are leaf nodes. This figure shows this for a subset of the Llama-based models. Indeed, quantized models (magenta) are nearly always leaf nodes, corroborating the statistical finding.", "description": "This figure visualizes a subset of Llama-based models from the Hugging Face model repository to demonstrate a key observation: quantized models rarely have child models (i.e., they are leaf nodes).  An analysis of over 400,000 model relationships showed that 99.41% of quantized models are leaf nodes.  The figure uses color-coding (magenta) to highlight the quantized models, providing visual confirmation of this statistical finding. This suggests that quantized models are typically not further modified or used as bases for creating other models, possibly due to performance reasons.", "section": "3. Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/neurons_ablation.png", "caption": "Figure 5: Temporal dynamics indicate edge directionality: We analyzed over 400,000 documented model relationships and observed that in 99.73%percent99.7399.73\\%99.73 % of cases, earlier upload times correlate with topologically higher positions in the DAG. Here, we visualize this trend on a subset of the Llama model family. Green nodes indicate models where earlier upload times align with topological order, while red nodes represent exceptions to this trend. The source (in gray) vacuously satisfied this assumption. It is clear that nearly all nodes satisfy our assumption.", "description": "This figure demonstrates the strong correlation between model upload time and their position within the directed acyclic graph (DAG) structure of the model atlas.  By analyzing over 400,000 documented model relationships, the authors found that in 99.73% of cases, models uploaded earlier appear higher in the DAG hierarchy. The visualization focuses on a subset of the Llama model family, using green nodes to represent models that adhere to this temporal ordering and red nodes for exceptions. The single source model is shown in gray. The overwhelming prevalence of green nodes supports the temporal relationship as a strong indicator of the model lineage within the atlas.", "section": "4. Charting the atlas structure"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/base_model_relation_histogram.png", "caption": "Figure 6: Snake vs. Fan patterns: Snake patterns often arise from sequential training checkpoints, while fan patterns typically result from hyperparameter sweeps. In both structures the model weight variance is low. However, in snake patterns the weight distance has high correlation with model upload time, whereas in fan patterns the correlation is lower. Note colors are the same as Fig.\u00a04", "description": "This figure illustrates two distinct patterns observed in the evolution of machine learning models: 'snake' and 'fan' patterns. Snake patterns represent sequential model development, such as during checkpointing in training, where subsequent models exhibit minor changes and have weights highly correlated with their creation times.  Fan patterns emerge from hyperparameter sweeps where several models are trained with slightly different hyperparameters from a common ancestor; these models show low weight variance but have less correlation between their weight distance and creation times.  The figure visually compares the two patterns, highlighting how these temporal and structural differences can be used to differentiate between models developed through iterative refinement versus those generated by exploring different hyperparameters. ", "section": "4. Charting the atlas structure"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/6_rings.png", "caption": "Figure 7: Number of neurons: Accuracy as a function of the number of neurons, indeed, 100 presents a good tradeoff between performance and resources.", "description": "This figure shows the relationship between the number of neurons used and the accuracy of the model.  The x-axis represents the number of neurons, and the y-axis represents the model accuracy.  Multiple lines represent different model types (SD, Qwen, Llama).  The graph shows that while increasing the number of neurons generally improves accuracy, the gains diminish at higher neuron counts.  The plot highlights that using 100 neurons offers a strong balance between achieving high accuracy and managing computational resources.", "section": "Ablations"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/whisper.png", "caption": "Figure 8: Relation type in our dataset", "description": "This bar chart visualizes the distribution of various model relation types within the dataset used in the study.  It shows the proportions of different types of relationships between models, such as 'Adapter', 'Fine-tune', 'Quantization', 'Merge', 'Root', and 'Unknown'. This provides insight into the predominant ways models are derived or modified from one another within the Hugging Face repository.", "section": "3. Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/Qwen_VL.png", "caption": "Figure 9: Documentation level in Hugging Face", "description": "This figure shows the level of documentation completeness for models within the Hugging Face model repository.  It visually represents the percentage of models that have complete documentation for various attributes, such as the model's license, the type of model, the pipeline it's used in, and its base model.  The visualization highlights the significant incompleteness in model documentation, which is a key challenge addressed by the paper.", "section": "Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/gemma.png", "caption": "Figure 10: Individual connected components - 1/5", "description": "This figure is part of a series visualizing different connected components within a larger model atlas.  It shows a specific subgraph of the atlas, highlighting the relationships between various models.  Nodes represent individual models, edges represent relationships (such as fine-tuning or adaptation), node size likely indicates a metric like download count or usage, and node color likely represents the type of model relationship. This particular subgraph likely focuses on a subset of models related to computer vision or a similar domain, given the names of some models visible in other related figures in the paper.", "section": "Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/x9.png", "caption": "Figure 11: Individual connected components - 2/5", "description": "This figure shows one of five individual connected components from the Hugging Face model atlas.  It visualizes the relationships between different machine learning models within this specific component. Nodes represent individual models, and edges indicate the relationships (e.g., fine-tuning, adaptation) between them. Node size might correspond to a metric like the number of downloads, and color coding could represent the type of relationship or model attributes. This provides a detailed view of the evolution and connections within a subset of the larger model landscape.", "section": "Analyzing Hugging Face's model atlas"}, {"figure_path": "https://arxiv.org/html/2503.10633/extracted/6277902/figs/app/mistral.png", "caption": "Figure 12: Individual connected components - 3/5", "description": "This figure is part of a series visualizing different connected components within a larger model atlas.  It displays a specific subset of the atlas, showing the relationships between models (nodes) and the transformations applied between them (edges). The visualization highlights the structure and complexity of a particular area of the model landscape, potentially showing relationships such as fine-tuning, quantization, or merging, allowing the reader to trace the lineage of models and understand how they evolved.  Node sizes and colors likely represent additional metadata such as model popularity or type of transformation.", "section": "Analyzing Hugging Face's model atlas"}]