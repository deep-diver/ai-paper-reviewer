[{"figure_path": "2410.18538/figures/figures_1_0.png", "caption": "Figure 1: SMITE. Using only one or few segmentation references with fine granularity (left), our method learns to segment different unseen videos respecting the segmentation references.", "description": "The figure illustrates the SMITE method, showing how a few annotated images are used to train a model that can then segment unseen videos with similar objects.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18538/figures/figures_4_0.png", "caption": "Figure 2: SMITE pipeline. During inference (a), we invert a given video into a noisy latent by iteratively adding noise. We then use an inflated U-Net denoiser (b) along with the trained text embedding as input to denoise the segments. A tracking module ensures that the generated segments are spatially and temporally consistent via spatio-temporal guidance. The video latent z\u0142 is updated by a tracking energy Etrack (c) that makes the segments temporally consistent and also a low-frequency regularizer (d) Ereg which guides the model towards better spatial consistency.", "description": "Figure 2 illustrates the SMITE pipeline, detailing the process of video segmentation using an inflated U-Net, a tracking module, and a low-frequency regularizer to ensure temporal and spatial consistency.", "section": "4 METHOD"}, {"figure_path": "2410.18538/figures/figures_6_0.png", "caption": "Figure 4: Segment tracking module ensures that segments are consistent across time. It uses co-tracker to track each point of the object's segment (here it is nose) and then finds point correspondence of this segment (denoted by blue dots) across timesteps. When the tracked point is of a different class (e.g,. face) then it is recovered by using temporal voting. The misclassified pixel is then replaced by the average of the neighbouring pixels of adjacent frames. This results are temporally consistent segments without visible flickers.", "description": "This figure illustrates the segment tracking module that uses co-tracker to maintain consistent segments across time by employing temporal voting to correct misclassified pixels.", "section": "4.3 TEMPORAL CONSISTENCY"}, {"figure_path": "2410.18538/figures/figures_6_1.png", "caption": "Figure 3: Best viewed in Adobe Acrobat.", "description": "The figure shows a comparison of video segmentation results with and without different components of the SMITE pipeline, highlighting the impact of tracking and low-pass regularization on temporal consistency and fine-grained segment details.", "section": "4 METHOD"}, {"figure_path": "2410.18538/figures/figures_7_0.png", "caption": "Figure 5: SMITE-50 Dataset sample.", "description": "The figure shows sample images from the SMITE-50 dataset, showcasing different object categories (horses, cars, faces, and non-text) and their corresponding segmentations.", "section": "5 RESULTS AND EXPERIMENTS"}, {"figure_path": "2410.18538/figures/figures_8_0.png", "caption": "Figure 6: Visual comparisons with other methods demonstrate that SMITE maintains better motion consistency of segments and delivers cleaner, more accurate segmentations. Both GSAM2 and Baseline-I struggle to accurately capture the horse\u2019s mane, and GSAM2 misses one leg (Left), whereas our method yields more precise results. Additionally, both alternative techniques create artifacts around the chin (Right), while SMITE produces a cleaner segmentation.", "description": "Figure 6 shows visual comparisons of video segmentation results from SMITE against two baseline methods, highlighting SMITE\u2019s superior motion consistency, accuracy, and lack of artifacts.", "section": "5 RESULTS AND EXPERIMENTS"}, {"figure_path": "2410.18538/figures/figures_10_0.png", "caption": "Figure 7: Additional results. We visualize the generalization capability of SMITE model (trained on the reference images) in various challenging poses, shape, and even in cut-shapes.", "description": "Figure 7 shows additional results of SMITE model generalization on various challenging poses, shapes and cut-shapes.", "section": "5 RESULTS AND EXPERIMENTS"}, {"figure_path": "2410.18538/figures/figures_10_1.png", "caption": "Figure 8: Segmentation results in challenging scenarios . SMITE accurately segments out the objects under occlusion (\"ice-cream\") or camouflage (\"turtle\") highlighting the robustness of our segmentation technique.", "description": "Figure 8 shows example segmentation results from SMITE on challenging scenarios with occlusion and camouflage.", "section": "5 RESULTS AND EXPERIMENTS"}]