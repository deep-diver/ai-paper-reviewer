{"references": [{" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is foundational to the field of diffusion models, which are central to SMITE's approach.  It lays out the theoretical framework for denoising diffusion models, which are used in SMITE to generate and refine segmentations.  The concepts in this paper directly inform the design of SMITE's core components and its training strategy.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Aliasghar Khani", "paper_title": "Slime: Segment like me", "reason": "This paper introduces the concept of weighted accumulated self-attention (WAS) maps and flexible granularity image segmentation which SMITE directly extends and builds upon to enable video segmentation. The WAS map, a novel representation of image segments, is instrumental for SMITE's ability to handle fine-grained segmentations from limited reference images.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This is a highly influential paper in the field of latent diffusion models.  It presents a significant advancement in generating high-resolution images using latent diffusion models.  SMITE leverages the architecture and training methods of latent diffusion models, and this paper provides crucial insights into their implementation and optimization.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This paper introduces Segment Anything Model (SAM), a highly successful foundation model for image segmentation, capable of producing accurate and detailed segmentations of various objects, even without explicit training.  While SAM is not directly used in SMITE, it inspires the utilization of pretrained diffusion models for fine-grained video object segmentation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Tianhe Ren", "paper_title": "Grounded sam: Assembling open-world models for diverse visual tasks", "reason": "This work extends the Segment Anything Model (SAM) to video segmentation by employing a grounding mechanism and using foundation models.  SMITE also utilizes a pretrained diffusion model for video segmentation and this work serves as a related and inspiring example of using foundation models for visual tasks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Zhenqi Dai", "paper_title": "One-shot in-context part segmentation", "reason": "This paper addresses the challenge of one-shot part segmentation, which is highly relevant to SMITE's goal of achieving flexible granularity video segmentation from limited examples.  The techniques used to leverage contextual information and perform one-shot segmentation provide valuable insights for SMITE's design.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "Xmem++: Production-level video segmentation from few annotated frames", "reason": "This paper focuses on video segmentation from limited annotations, a problem directly addressed by SMITE.  The proposed methods in this paper showcase related techniques and benchmark results that help contextualize and evaluate SMITE's performance.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Qian Wang", "paper_title": "Zero-shot video semantic segmentation based on pre-trained diffusion models", "reason": "This paper addresses video semantic segmentation using pre-trained diffusion models, a highly relevant approach to SMITE. The strategies used for temporal consistency and handling the challenges inherent in video segmentation are directly related to the technical contributions of SMITE.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nikita Karaev", "paper_title": "Cotracker: It is better to track together", "reason": "This paper introduces CoTracker, a tracking algorithm that SMITE utilizes to ensure temporal consistency in its video segmentations. CoTracker's design and capabilities are critical for SMITE's ability to maintain accurate and consistent segmentations across video frames.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Shoufa Chen", "paper_title": "Gentron: Delving deep into diffusion transformers for image and video generation", "reason": "This paper explores video generation using diffusion transformers, a related technique that enhances the understanding of SMITE's use of inflated UNets. The methods used for generating videos informed some design choices made in SMITE, such as the use of 3D convolutional kernels.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This paper is closely related to the work done in SMITE, focusing on high-resolution video synthesis using latent diffusion models. The method used for creating high-resolution videos and the strategies for temporal consistency in video generation can be compared and contrasted with SMITE.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Yuren Cong", "paper_title": "Ssgvs: Semantic scene graph-to-video synthesis", "reason": "This paper proposes methods for semantic scene graph-to-video synthesis, a related area that shares similarities with video segmentation tasks, especially concerning the handling of objects and their properties.  The techniques discussed are relevant to SMITE's goals of generating temporally consistent segmentations.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Zhenqi Dai", "paper_title": "One-shot in-context part segmentation", "reason": "This paper presents a novel approach to one-shot part segmentation, providing insights into efficient learning methods for achieving flexible granularity segmentation.  The techniques for one-shot learning from limited samples are highly relevant to SMITE's method for generating segmentations from few reference images.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Henghui Ding", "paper_title": "Mose: A new dataset for video object segmentation in complex scenes", "reason": "This paper introduces a new dataset for video object segmentation which SMITE uses as a benchmark to evaluate the performance of its method. The introduction of a new dataset for evaluation directly improves the credibility and benchmarking possibilities of the experimental results presented by the authors.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Zixin Zhu", "paper_title": "Exploring pre-trained text-to-video diffusion models for referring video object segmentation", "reason": "This paper focuses on referring video object segmentation, which is a closely related task to the video segmentation problem addressed in SMITE.  The insights and techniques explored in this paper are highly relevant to SMITE's goal of achieving flexible-granularity segmentation from reference images.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "reason": "This paper showcases a groundbreaking method for zero-shot text-to-image generation using diffusion models.  SMITE leverages similar techniques in adapting a pretrained text-to-image diffusion model for video segmentation, making it a highly relevant foundational paper for understanding SMITE's core concepts.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "reason": "This paper demonstrates the capabilities of advanced text-to-image diffusion models and the state-of-the-art results achieved with these techniques. SMITE leverages a pre-trained text-to-image diffusion model and this paper provides a relevant context for understanding the pretrained model's capabilities.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Guillaume Le Moing", "paper_title": "Ccvs: context-aware controllable video synthesis", "reason": "This paper addresses video synthesis, a closely related field to video segmentation, and provides insights into handling temporal consistency.  The techniques for managing temporal aspects of videos are relevant to the solutions SMITE employs for achieving temporal consistency.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "Xmem++: Production-level video segmentation from few annotated frames", "reason": "This paper introduces a highly efficient video segmentation approach using limited annotations, which is directly relevant to the core problem and contributions of SMITE.  The strategies employed for achieving high-quality results with limited data serve as a useful comparison for SMITE's methods.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Yuren Cong", "paper_title": "Flatten: optical flow-guided attention for consistent text-to-video editing", "reason": "This paper proposes a novel approach to text-to-video editing using optical flow and attention mechanisms.  The techniques for ensuring temporal consistency and controlling video generation are relevant to SMITE's method, which also aims to produce consistent and temporally coherent video segmentations.", "section_number": 3}]}