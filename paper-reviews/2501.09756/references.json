{"references": [{"fullname_first_author": "Yogesh Balaji", "paper_title": "ediff-i: Text-to-image diffusion models with an ensemble of expert denoisers", "publication_date": "2022-11-01", "reason": "This paper introduces a novel approach to text-to-image diffusion models that uses an ensemble of expert denoisers, which is highly relevant to the SynthLight model's architecture and training strategy."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This seminal work demonstrates the superiority of diffusion models over GANs for image synthesis, which is fundamental to SynthLight's choice of diffusion models as its core technology."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-12-01", "reason": "This paper introduces a highly influential latent diffusion model for high-resolution image synthesis, providing a strong foundation for SynthLight's approach to generating realistic portrait images."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2022-07-12", "reason": "This paper introduces the concept of classifier-free guidance for diffusion models, a technique crucial for balancing image fidelity and relighting effects in SynthLight's inference process."}, {"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2023-01-01", "reason": "This paper introduces a method for learning image editing instructions, which is relevant to SynthLight's approach of learning to transform images according to lighting changes."}]}