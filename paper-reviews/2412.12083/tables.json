[{"content": "| | Albedo | | Normal | Metallic | Roughness |\n|---|---|---|---|---|---| \n| | SSIM\u2191 | PSNR\u2191 | Cosine Similarity \u2191 | MSE \u2193 | MSE \u2193 |\n| IID | 0.901 | 27.35 | - | 0.192 | 0.131 |\n| RGB\u2194X | 0.902 | 28.09 | 0.834 | 0.162 | 0.347 |\n| IntrinsicAnything | 0.901 | 28.17 | - | - | - |\n| GeoWizard | - | - | 0.871 | - | - |\n| Ours(single) | 0.935 | 32.79 | 0.928 | 0.037 | 0.058 |\n| Ours(multi) | **0.937** | **33.62** | **0.941** | **0.016** | **0.033** |", "caption": "Table 1: Quantitative evaluation of IDArb against baselines.\u00a0IDArb consistently achieves the best results among all albedo, normal, metallic and roughness metrics.", "description": "This table presents a quantitative comparison of IDArb against other baseline methods for intrinsic image decomposition using various metrics. IDArb consistently outperforms the baselines in albedo, normal, roughness, and metallic estimations, demonstrating its effectiveness.", "section": "4.2 Experimental Results"}, {"content": "| # OLAT Images | 2 | | 4 | | 8 | |\n|---|---|---|---|---|---|---| \n| Methods | Albedo<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.1.1.1.1.1.m1.1\"><semantics id=\"S4.T2.1.1.1.1.1.m1.1a\"><mo id=\"S4.T2.1.1.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.1.1.1.1.1.m1.1d\">&#x2191;</annotation></semantics></math> | Normal<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.2.2.2.2.2.m1.1\"><semantics id=\"S4.T2.2.2.2.2.2.m1.1a\"><mo id=\"S4.T2.2.2.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.2.2.2.2.2.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.2.2.m1.1b\"><ci id=\"S4.T2.2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.2.2.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.2.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.2.2.2.2.2.m1.1d\">&#x2191;</annotation></semantics></math> | Albedo<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.3.3.3.3.3.m1.1\"><semantics id=\"S4.T2.3.3.3.3.3.m1.1a\"><mo id=\"S4.T2.3.3.3.3.3.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.3.3.3.3.3.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.3.3.m1.1b\"><ci id=\"S4.T2.3.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.3.3.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.3.3.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.3.3.3.3.3.m1.1d\">&#x2191;</annotation></semantics></math> | Normal<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.4.4.4.4.4.m1.1\"><semantics id=\"S4.T2.4.4.4.4.4.m1.1a\"><mo id=\"S4.T2.4.4.4.4.4.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.4.4.4.4.4.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.4.4.4.4.m1.1b\"><ci id=\"S4.T2.4.4.4.4.4.m1.1.1.cmml\" xref=\"S4.T2.4.4.4.4.4.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.4.4.4.4.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.4.4.4.4.4.m1.1d\">&#x2191;</annotation></semantics></math> | Albedo<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.5.5.5.5.5.m1.1\"><semantics id=\"S4.T2.5.5.5.5.5.m1.1a\"><mo id=\"S4.T2.5.5.5.5.5.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.5.5.5.5.5.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.5.5.5.5.m1.1b\"><ci id=\"S4.T2.5.5.5.5.5.m1.1.1.cmml\" xref=\"S4.T2.5.5.5.5.5.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.5.5.5.5.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.5.5.5.5.5.m1.1d\">&#x2191;</annotation></semantics></math> | Normal<math alttext=\"&#x2191;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.6.6.6.6.6.m1.1\"><semantics id=\"S4.T2.6.6.6.6.6.m1.1a\"><mo id=\"S4.T2.6.6.6.6.6.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.6.6.6.6.6.m1.1.1.cmml\">&#x2191;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.6.6.6.6.6.m1.1b\"><ci id=\"S4.T2.6.6.6.6.6.m1.1.1.cmml\" xref=\"S4.T2.6.6.6.6.6.m1.1.1\">&#x2191;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.6.6.6.6.6.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.6.6.6.6.6.m1.1d\">&#x2191;</annotation></semantics></math> |\n| IID | 22.23 | - | 22.40 | - | 22.86 | - |\n| RGB <math alttext=\"&#x2194;\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.7.7.7.7.1.m1.1\"><semantics id=\"S4.T2.7.7.7.7.1.m1.1a\"><mo id=\"S4.T2.7.7.7.7.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T2.7.7.7.7.1.m1.1.1.cmml\">&#x2194;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.7.7.7.7.1.m1.1b\"><ci id=\"S4.T2.7.7.7.7.1.m1.1.1.cmml\" xref=\"S4.T2.7.7.7.7.1.m1.1.1\">&#x2194;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.7.7.7.7.1.m1.1c\">\\leftrightarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.7.7.7.7.1.m1.1d\">&#x2194;</annotation></semantics></math>X | 21.29 | 0.71 | 22.08 | 0.77 | 23.29 | 0.81 |\n| SDM-UniPS | 22.95 | 0.74 | 23.20 | 0.76 | 23.37 | 0.81 |\n| Ours | **23.50** | **0.83** | **23.64** | **0.84** | **25.15** | **0.85** |", "caption": "Table 2: Quantitative results for photometric stereo on NeRFactor. We evaluate performance using 2, 4, and 8 OLAT images, and achieve the best performance among all compared methods.", "description": "This table presents a quantitative comparison of different intrinsic decomposition methods' performance on the NeRFactor dataset for photometric stereo under the challenging One-Light-At-a-Time (OLAT) condition, using varying numbers of input images (2, 4, and 8). Performance metrics such as albedo (SSIM, PSNR) and normal (cosine similarity) are compared across methods like IID, RGB\u2194X, SDM-UniPS, and the proposed IDArb. The results demonstrate IDArb achieves the best performance across all metrics and input image counts.", "section": "4.2 Experimental Results"}, {"content": "|        | Nerfactor                |                   |         | Synthetic4Relight            |                  |         |\n|--------|-------------------------|-------------------|---------|-----------------------------|-------------------|---------|\n|        | Albedo (raw)          | Albedo (scaled) | Relighting | Albedo (raw) | Albedo (scaled) | Relighting | Roughness |\n| NVDiffRecMC      | 17.89                 | 25.88            | 22.65    | 17.03        | 29.64          | 24.05      | 0.046    |\n| NVDiffRecMC w/ Ours | **20.90** | **26.61** | **27.20** | **26.42** | **30.73** | **31.01** | **0.014** |\n", "caption": "Table 3: Ablation on\u00a0IDArb pseudo labels for optimization-based inverse rendering on NeRFactor and Synthetic4Relight datasets.", "description": "This table presents an ablation study on using IDArb's intrinsic component predictions as pseudo-labels to guide optimization-based inverse rendering methods, specifically NVDiffRecMC.  The experiments are conducted on NeRFactor and Synthetic4Relight datasets.  It compares NVDiffRecMC's raw and scaled albedo predictions, relighting quality, and estimated roughness, both with and without the IDArb-derived pseudo-labels.  The table demonstrates that using IDArb's predictions as a prior improves the optimization process in NVDiffRecMC, leading to enhanced relighting results and more physically plausible material estimation, particularly in mitigating color shifts in the reconstructed albedo.", "section": "4.4 Applications"}, {"content": "| # L | # V | 1 | 2 | 4 | 8 | 12 |\n|---|---|---|---|---|---|---| \n| 1 | 29.16 | 28.72 | 30.12 | 30.49 | 30.77 |\n| 2 | 29.96 | 30.26 | 30.96 | 31.13 | 31.26 |\n| 3 | 30.25 | 30.73 | 31.16 | 31.33 | 31.40 |", "caption": "Table 4: Albedo Performance \u2191\u2191\\uparrow\u2191 across different numbers of viewpoints (# V) and lightings (# L).", "description": "This table presents the Albedo performance measured by PSNR with varying number of input views and lighting conditions during training. \u2191 indicates higher is better. The table shows that both increasing the number of input views and lighting conditions could generally improve the albedo prediction performance.", "section": "4. EXPERIMENTS"}, {"content": "| # L | # V | 1 | 2 | 4 | 8 | 12 |\n|---|---|---|---|---|---|---| \n| 1 | | 0.909 | 0.910 | 0.925 | 0.930 | 0.932 |\n| 2 | | 0.922 | 0.927 | 0.930 | 0.933 | 0.934 |\n| 3 | | 0.926 | 0.931 | 0.931 | 0.934 | 0.935 |", "caption": "Table 5: Normal Performance \u2191\u2191\\uparrow\u2191 across different numbers of viewpoints (# V) and lightings (# L).", "description": "This table presents the performance of normal estimation across different numbers of input viewpoints and lighting conditions.  The values in the table represent Cosine Similarity, where higher values indicate better performance.", "section": "4. EXPERIMENTS"}, {"content": "| # L | # V | 1 | 2 | 4 | 8 | 12 |\n|---|---|---|---|---|---|---| \n| 1 | 0.105 | 0.116 | 0.068 | 0.059 | 0.050 |\n| 2 | 0.061 | 0.068 | 0.047 | 0.044 | 0.042 |\n| 3 | 0.061 | 0.056 | 0.048 | 0.045 | 0.040 |", "caption": "Table 6: Metallic Performance \u2193\u2193\\downarrow\u2193 across different numbers of viewpoints (# V) and lightings (# L).", "description": "Shows the metallic estimation performance measured by Mean Squared Error (MSE) with varying numbers of input views and lighting conditions. Lower MSE indicates better performance.", "section": "4. EXPERIMENTS"}, {"content": "| # L | # V | 1 | 2 | 4 | 8 | 12 |\n|---|---|---|---|---|---|---| \n| 1 | | 0.049 | 0.050 | 0.024 | 0.019 | 0.021 |\n| 2 | | 0.043 | 0.026 | 0.019 | 0.016 | 0.015 |\n| 3 | | 0.031 | 0.022 | 0.016 | 0.014 | 0.013 |", "caption": "Table 7: Roughness Performance \u2193\u2193\\downarrow\u2193 across different numbers of viewpoints (# V) and lightings (# L).", "description": "Shows the performance of roughness prediction with varying numbers of input views and lighting conditions using Mean Squared Error (MSE). Lower values indicate better performance.", "section": "4. EXPERIMENTS"}, {"content": "|                      | SSIM\u2191 | PSNR\u2191 | LPIPS\u2193 |\n|----------------------|-------|-------|--------|\n| Ours                 | 0.876 | 27.98 | 0.117  |\n| IntrinsicAnything | 0.896 | 25.66 | 0.150  |", "caption": "Table 8: Quantitative comparisons on MIT-Intrinsic.", "description": "This table presents a quantitative comparison of the proposed IDArb method and a baseline method, IntrinsicAnything, on the MIT-Intrinsic dataset. The metrics used for evaluation are SSIM, PSNR, and LPIPS.", "section": "4.2 Experimental Results"}, {"content": "|                       | Normal Cosine Distance\u2193 | Albedo SSIM\u2191 | Albedo PSNR\u2191 | Albedo LPIPS\u2193 | Re-rendering PSNR-H\u2191 | Re-rendering PSNR-L\u2191 | Re-rendering SSIM\u2191 | Re-rendering LPIPS\u2193 |\n| :-------------------- | :--------------------: | :----------: | :----------: | :----------: | :-----------------: | :-----------------: | :---------------: | :----------------: |\n| Ours(single)         |         0.041          |    0.978     |     41.30    |     0.039     |        24.11       |        31.28       |       0.969        |        0.024       |\n| Ours(multi)          |        **0.029**       |    **0.978** |    **41.46** |    **0.038** |       **24.36**    |       **31.43**    |      **0.970**     |       **0.024**    |\n| StableNormal         |        **0.038**       |              |              |              |                    |                    |                   |                    |\n| IntrinsicNeRF        |                       |    **0.981** |     39.31    |     0.048     |                    |                    |                   |                    |", "caption": "Table 9: Quantitative comparisons on Stanford-ORB.", "description": "This table presents a quantitative comparison of IDArb against StableNormal and IntrinsicNeRF on the Stanford-ORB dataset. The metrics used for evaluation include Cosine Distance for normals, SSIM, PSNR, and LPIPS for albedo, and PSNR-H, PSNR-L, SSIM, and LPIPS for re-rendering. IDArb is evaluated in both single-view and multi-view settings.", "section": "4. EXPERIMENTS"}]