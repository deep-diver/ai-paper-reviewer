[{"content": "| Method | TCPR | Chn | WebVid-10M PSNR (\u2191) | WebVid-10M SSIM (\u2191) | WebVid-10M LPIPS (\u2193) | WebVid-10M FVD (\u2193) | Panda-70M PSNR (\u2191) | Panda-70M SSIM (\u2191) | Panda-70M LPIPS (\u2193) | Panda-70M FVD (\u2193) |\n|---|---|---|---|---|---|---|---|---|---|---|\n| SD-VAE<sup>[27]</sup> | 64(1\u00d78\u00d78) | 4 | 30.19 | 0.8377 | 0.0568 | 284.90 | 30.46 | 0.8896 | 0.0395 | 182.99 |\n| SVD-VAE<sup>[4]</sup> | 64(1\u00d78\u00d78) | 4 | 31.18 | 0.8689 | 0.0546 | 188.74 | 31.04 | 0.9059 | 0.0379 | 137.67 |\n| CV-VAE<sup>[44]</sup> | 256(4\u00d78\u00d78) | 4 | 30.76 | 0.8566 | 0.0803 | 369.23 | 30.18 | 0.8796 | 0.0672 | 296.28 |\n| OD-VAE<sup>[6]</sup> | 256(4\u00d78\u00d78) | 4 | 30.69 | 0.8635 | 0.0553 | 255.92 | 30.31 | 0.8935 | 0.0439 | 191.23 |\n| Open-Sora VAE<sup>[45]</sup> | 256(4\u00d78\u00d78) | 4 | 31.14 | 0.8572 | 0.1001 | 475.23 | 31.37 | 0.8973 | 0.0662 | 298.47 |\n| Allegro<sup>[46]</sup> | 256(4\u00d78\u00d78) | 4 | 32.18 | 0.8963 | 0.0524 | 209.68 | 31.70 | 0.9158 | 0.0421 | 172.72 |\n| WF-VAE-S (Ours) | 256(4\u00d78\u00d78) | 4 | 31.39 | 0.8737 | 0.0517 | 188.04 | 31.27 | 0.9025 | 0.0420 | 146.91 |\n| WF-VAE-L (Ours) | 256(4\u00d78\u00d78) | 4 | 32.32 | 0.8920 | 0.0513 | 186.00 | 32.10 | 0.9142 | 0.0411 | 146.24 |\n| CogVideoX-VAE<sup>[39]</sup> | 256(4\u00d78\u00d78) | 16 | 35.72 | 0.9434 | 0.0277 | 59.83 | 35.79 | 0.9527 | 0.0198 | 43.23 |\n| WF-VAE-L (Ours) | 256(4\u00d78\u00d78) | 16 | 35.76 | 0.9430 | 0.0230 | 54.36 | 35.87 | 0.9538 | 0.0175 | 39.40 |", "caption": "Table 1: Quantitative metrics of reconstruction performance. Results demostrate that WF-VAE achieves state-of-the-art on reconstrcution performance comparing with other VAEs on WebVid-10M[2] and Panda70M[7] datasets. TCPR represents the token compression rate and Chn indicates the number of latent channels. The highest result is highlighted in bold, and the second highest result is underlined.", "description": "Table 1 presents a quantitative comparison of video reconstruction performance between WF-VAE and other state-of-the-art VAEs on the WebVid-10M and Panda70M datasets.  The metrics used for comparison are Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Fr\u00e9chet Video Distance (FVD).  Higher PSNR and SSIM values indicate better reconstruction quality, while lower LPIPS and FVD values are preferred. The table also shows the token compression rate (TCPR) and number of latent channels (Chn) for each model. The best performing model in each metric is shown in bold, and the second-best is underlined, highlighting WF-VAE's superior reconstruction quality and efficiency.", "section": "4. Experiments"}, {"content": "| Method | Chn | SkyTimelapse | UCF101 FVD\u2193 | UCF101 IS\u2191 |\n|---|---|---|---|---|\n| Allegro [46] | 4 | 117.28 | 1045.66 | 67.16 |\n| OD-VAE [6] | 4 | 130.79 | 1109.87 | 58.48 |\n| WF-VAE-S (Ours) | 4 | **103.44** | **1005.10** | 65.89 |\n| WF-VAE-L (Ours) | 4 | **113.67** | **929.55** | **70.53** |\n| CogVideoX [39] | 16 | 109.20 | 1117.57 | 57.47 |\n| WF-VAE-L (Ours) | 16 | **108.69** | **947.18** | **71.86** |", "caption": "Table 2: Quantitative evaluation of different VAE models for video generation. We assess video generation quality using FVD16 on both SkyTimelapse and UCF-101 datasets, and IS on UCF-101 following prior work [22].", "description": "Table 2 presents a quantitative comparison of various Video Variational Autoencoders (VAEs) in terms of their video generation capabilities.  The evaluation focuses on two metrics: Fr\u00e9chet Video Distance (FVD) at 16 frames (FVD16) and Inception Score (IS). FVD16 measures the visual quality and temporal coherence of generated videos, while IS assesses the diversity and quality of the generated samples.  The results are shown for two benchmark datasets: SkyTimelapse and UCF-101. For the UCF-101 dataset, both FVD16 and IS scores are reported.  The table helps to understand how well different VAEs generate videos and their performance relative to each other.", "section": "4. Experiments"}, {"content": "| Model | BC | Params (M) Enc | Params (M) Dec | Kinetics-400 PSNR\u2191 | Kinetics-400 LPIPS\u2193 |\n|---|---|---|---|---|---| \n| WF-VAE-S | 128 | 38 | 108 | 28.21 | 0.0779 |\n| WF-VAE-M | 160 | 58 | 164 | 28.44 | 0.0699 |\n| WF-VAE-L | 192 | 84 | 232 | 28.66 | 0.0661 |", "caption": "Table 3: \nScalability of WF-VAE. We evaluated PSNR and LPIPS on Kinetics-400\u00a0[16]. Reconstruction performance improves as model complexity increases.", "description": "This table presents the scalability results of the WF-VAE model.  The experiment evaluates the Peak Signal-to-Noise Ratio (PSNR) and the Learned Perceptual Image Patch Similarity (LPIPS) metrics on the Kinetics-400 dataset.  Three different configurations of the WF-VAE model were tested, each differing in the number of base channels (128, 160, and 192). The results demonstrate that the model's reconstruction performance improves as model complexity, measured by the number of base channels, increases.  The table helps to illustrate the trade-offs between model size and performance.", "section": "4. Experiments"}, {"content": "| Settings | Kinetics-400 | \n|---|---|---|\n| L1 | L2 | L3 | WL Loss | NM | PSNR \u2191 | LPIPS \u2193 |\n| \u2713 |  |  |  | L | 27.85 | 0.0737 |\n| \u2713 | \u2713 |  | \u2713 | L | 27.94 | 0.0737 |\n| \u2713 | \u2713 | \u2713 |  | L | 27.90 | 0.0692 |\n| \u2713 | \u2713 | \u2713 | \u2713 | L | **28.21** | <ins>0.0690</ins> |\n| \u2713 | \u2713 | \u2713 | \u2713 | G | <ins>28.03</ins> | **0.0684** |", "caption": "Table 4: Ablation studies on model architecture. We evaluate the impact of three key components: energy flow pathways across network layers, WL loss, and normalization methods (L: layer normalization\u00a0[1], G: group normalization\u00a0[36]).", "description": "This table presents an ablation study analyzing the impact of three key architectural components of the WF-VAE model on its performance.  The components are: 1) the energy flow pathways connecting low-frequency information to the latent representation, 2) the weight of the WL loss (which regularizes the model's energy flow), and 3) the type of normalization used (layer normalization [1] vs. group normalization [36]). The results are shown in terms of PSNR and LPIPS metrics on the Kinetics-400 dataset, demonstrating the contribution of each component to overall reconstruction quality.", "section": "4.3 Ablation Study"}, {"content": "| Method | Chn | BWI | Panda70M PSNR\u2191 | Panda70M LPIPS\u2193 |\n|---|---|---|---|---|\n|  |  | \u2717 | 31.71 | 0.0422 |\n| Allegro [46] | 4 | \u2713 | 25.31 (-6.40) | 0.1124 (+0.0702) |\n|  |  | \u2717 | 30.31 | 0.0439 |\n| OD-VAE [6] | 4 | \u2713 | 28.51 (-1.80) | 0.0552 (+0.0113) |\n|  |  | \u2717 | 32.10 | 0.0411 |\n| WF-VAE-L (Ours) | 4 | \u2713 | 32.10 (0.00) | 0.0411 (0.0000) |\n| CogVideoX [39] | 16 | \u2717 | 35.79 | 0.0198 |\n|  |  | \u2713 | 35.41 (-0.38) | 0.0218 (+0.0020) |\n|  |  | \u2717 | 35.87 | 0.0175 |\n| WF-VAE-L (Ours) | 16 | \u2713 | 35.87 (0.00) | 0.0175 (0.0000) |", "caption": "Table 5: Quantitative analysis of visual quality degradation induced by block-wise inference. Values in  red indicate degradation compared to direct inference, while values in  green demonstrate preservation of quality. BWI denotes Block-Wise Inference. Experiments are conducted on 33 frames with 256\u00d7256 resolution.", "description": "This table presents a quantitative comparison of visual quality when using block-wise inference versus direct inference in video variational autoencoders (VAEs).  The metrics evaluated are Peak Signal-to-Noise Ratio (PSNR) and Learned Perceptual Image Patch Similarity (LPIPS).  Positive differences from direct inference results (shown in green) indicate that block-wise inference preserves quality, while negative differences (shown in red) highlight quality degradation introduced by block-wise inference. The experiments are conducted on videos with 33 frames and 256x256 resolution.", "section": "4.4. Causal Cache"}, {"content": "| Notations | Descriptions |\n|---|---| \n| <math alttext=\"WT(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S6.T6.1.1.1.1.1.1.m1.1\"><semantics id=\"S6.T6.1.1.1.1.1.1.m1.1a\"><mrow id=\"S6.T6.1.1.1.1.1.1.m1.1.2\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.cmml\"><mi id=\"S6.T6.1.1.1.1.1.1.m1.1.2.2\" mathsize=\"144%\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.2.cmml\">W</mi><mo id=\"S6.T6.1.1.1.1.1.1.m1.1.2.1\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.1.cmml\">\\</mo><mi id=\"S6.T6.1.1.1.1.1.1.m1.1.2.3\" mathsize=\"144%\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.3.cmml\">T</mi><mo id=\"S6.T6.1.1.1.1.1.1.m1.1.2.1a\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.1.cmml\">\\</mo><mrow id=\"S6.T6.1.1.1.1.1.1.m1.1.2.4.2\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.cmml\"><mo id=\"S6.T6.1.1.1.1.1.1.m1.1.2.4.2.1\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.cmml\">(</mo><mo id=\"S6.T6.1.1.1.1.1.1.m1.1.1\" lspace=\"0em\" mathsize=\"144%\" rspace=\"0em\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.1.cmml\">\\</mo><mo id=\"S6.T6.1.1.1.1.1.1.m1.1.2.4.2.2\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.1.1.1.1.1.1.m1.1b\"><apply id=\"S6.T6.1.1.1.1.1.1.m1.1.2.cmml\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2\"><times id=\"S6.T6.1.1.1.1.1.1.m1.1.2.1.cmml\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.1\"></times><ci id=\"S6.T6.1.1.1.1.1.1.m1.1.2.2.cmml\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.2\">\\</ci><ci id=\"S6.T6.1.1.1.1.1.1.m1.1.2.3.cmml\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.2.3\">T</ci><ci id=\"S6.T6.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S6.T6.1.1.1.1.1.1.m1.1.1\">\\</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.1.1.1.1.1.1.m1.1c\">WT(\\cdot)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.1.1.1.1.1.1.m1.1d\">italic_W italic_T ( \\cdot )</annotation></semantics></math> | Wavelet transform |\n| <math alttext=\"IWT(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S6.T6.2.2.2.1.1.1.m1.1\"><semantics id=\"S6.T6.2.2.2.1.1.1.m1.1a\"><mrow id=\"S6.T6.2.2.2.1.1.1.m1.1.2\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.cmml\"><mi id=\"S6.T6.2.2.2.1.1.1.m1.1.2.2\" mathsize=\"144%\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.2.cmml\">I</mi><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.2.1\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.1.cmml\">\\</mo><mi id=\"S6.T6.2.2.2.1.1.1.m1.1.2.3\" mathsize=\"144%\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.3.cmml\">W</mi><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.2.1a\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.1.cmml\">\\</mo><mi id=\"S6.T6.2.2.2.1.1.1.m1.1.2.4\" mathsize=\"144%\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.4.cmml\">T</mi><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.2.1b\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.1.cmml\">\\</mo><mrow id=\"S6.T6.2.2.2.1.1.1.m1.1.2.5.2\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.cmml\"><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.2.5.2.1\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.cmml\">(</mo><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.1\" lspace=\"0em\" mathsize=\"144%\" rspace=\"0em\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.1.cmml\">\\cdot</mo><mo id=\"S6.T6.2.2.2.1.1.1.m1.1.2.5.2.2\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.2.2.2.1.1.1.m1.1b\"><apply id=\"S6.T6.2.2.2.1.1.1.m1.1.2.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2\"><times id=\"S6.T6.2.2.2.1.1.1.m1.1.2.1.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.1\"></times><ci id=\"S6.T6.2.2.2.1.1.1.m1.1.2.2.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.2\">I</ci><ci id=\"S6.T6.2.2.2.1.1.1.m1.1.2.3.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.3\">W</ci><ci id=\"S6.T6.2.2.2.1.1.1.m1.1.2.4.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.2.4\">T</ci><ci id=\"S6.T6.2.2.2.1.1.1.m1.1.1.cmml\" xref=\"S6.T6.2.2.2.1.1.1.m1.1.1\">\\cdot</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.2.2.2.1.1.1.m1.1c\">IWT(\\cdot)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.2.2.2.1.1.1.m1.1d\">italic_I italic_W italic_T ( \\cdot )</annotation></semantics></math> | Inverse wavelet transform |\n| <math alttext=\"\\mathbf{S}^{(l)}_{\\Box\\Box\\Box}\" class=\"ltx_Math\" display=\"inline\" id=\"S6.T6.3.3.3.1.1.1.m1.1\"><semantics id=\"S6.T6.3.3.3.1.1.1.m1.1a\"><msubsup id=\"S6.T6.3.3.3.1.1.1.m1.1.2\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.cmml\"><mi id=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.2\" mathsize=\"144%\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.2.cmml\">\\mathbf{S}</mi><mrow id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.cmml\"><mi id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.2\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.2.cmml\">\\Box</mi><mo id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1.cmml\">\\</mo><mi id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.3\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.3.cmml\">\\Box</mi><mo id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1a\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1.cmml\">\\</mo><mi id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.4\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.4.cmml\">\\Box</mi></mrow><mrow id=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.3\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.cmml\"><mo id=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.3.1\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.cmml\">(</mo><mi id=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.1\" mathsize=\"144%\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.1.cmml\">l</mi><mo id=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.3.2\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.cmml\">)</mo></mrow></msubsup><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.3.3.3.1.1.1.m1.1b\"><apply id=\"S6.T6.3.3.3.1.1.1.m1.1.2.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2\"><csymbol cd=\"ambiguous\" id=\"S6.T6.3.3.3.1.1.1.m1.1.2.1.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2\">subscript</csymbol><apply id=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.1.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.2\">superscript</csymbol><ci id=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.2.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.2.2\">\\mathbf{S}</ci><ci id=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.1.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.1.1.1\">l</ci></apply><apply id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3\"><times id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.1\"></times><ci id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.2.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.2\">\\Box</ci><ci id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.3.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.3\">\\Box</ci><ci id=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.4.cmml\" xref=\"S6.T6.3.3.3.1.1.1.m1.1.2.3.4\">\\Box</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.3.3.3.1.1.1.m1.1c\">\\mathbf{S}^{(l)}_{\\Box\\Box\\Box}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.3.3.3.1.1.1.m1.1d\">bold_S start_POSTSUPERSCRIPT ( italic_l ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u25a1 \u25a1 \u25a1 end_POSTSUBSCRIPT</annotation></semantics></math> | Wavelet subband within layer <math alttext=\"l\" class=\"ltx_centering\" display=\"inline\" id=\"S6.T6.4.4.4.2.1.1.m1.1\"><semantics id=\"S6.T6.4.4.4.2.1.1.m1.1a\"><mi id=\"S6.T6.4.4.4.2.1.1.m1.1.1\" mathsize=\"144%\" xref=\"S6.T6.4.4.4.2.1.1.m1.1.1.cmml\">l</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.4.4.4.2.1.1.m1.1b\"><ci id=\"S6.T6.4.4.4.2.1.1.m1.1.1.cmml\" xref=\"S6.T6.4.4.4.2.1.1.m1.1.1\">l</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.4.4.4.2.1.1.m1.1c\">l</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.4.4.4.2.1.1.m1.1d\">italic_l</annotation></semantics></math>, where <math alttext=\"\\Box\\Box\\Box\" class=\"ltx_centering\" display=\"inline\" id=\"S6.T6.5.5.5.3.2.2.m2.1\"><semantics id=\"S6.T6.5.5.5.3.2.2.m2.1a\"><mrow id=\"S6.T6.5.5.5.3.2.2.m2.1.1\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.cmml\"><mi id=\"S6.T6.5.5.5.3.2.2.m2.1.1.2\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.2.cmml\">\\Box</mi><mo id=\"S6.T6.5.5.5.3.2.2.m2.1.1.1\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.1.cmml\">\\</mo><mi id=\"S6.T6.5.5.5.3.2.2.m2.1.1.3\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.3.cmml\">\\Box</mi><mo id=\"S6.T6.5.5.5.3.2.2.m2.1.1.1a\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.1.cmml\">\\</mo><mi id=\"S6.T6.5.5.5.3.2.2.m2.1.1.4\" mathsize=\"144%\" mathrm=\"normal\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.4.cmml\">\\Box</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.5.5.5.3.2.2.m2.1b\"><apply id=\"S6.T6.5.5.5.3.2.2.m2.1.1.cmml\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1\"><times id=\"S6.T6.5.5.5.3.2.2.m2.1.1.1.cmml\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.1\"></times><ci id=\"S6.T6.5.5.5.3.2.2.m2.1.1.2.cmml\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.2\">\\Box</ci><ci id=\"S6.T6.5.5.5.3.2.2.m2.1.1.3.cmml\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.3\">\\Box</ci><ci id=\"S6.T6.5.5.5.3.2.2.m2.1.1.4.cmml\" xref=\"S6.T6.5.5.5.3.2.2.m2.1.1.4\">\\Box</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.5.5.5.3.2.2.m2.1c\">\\Box\\Box\\Box</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.5.5.5.3.2.2.m2.1d\">\u25a1 \u25a1 \u25a1</annotation></semantics></math> specifies the type of filtering (high or low pass) applied in three dimensions. |\n| <math alttext=\"\\mathcal{W}^{(l)}\" class=\"ltx_Math\" display=\"inline\" id=\"S6.T6.6.6.6.1.1.1.m1.1\"><semantics id=\"S6.T6.6.6.6.1.1.1.m1.1a\"><msup id=\"S6.T6.6.6.6.1.1.1.m1.1.2\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.cmml\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S6.T6.6.6.6.1.1.1.m1.1.2.2\" mathsize=\"144%\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.2.cmml\">\\mathcal{W}</mi><mrow id=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.3\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.cmml\"><mo id=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.3.1\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.cmml\">(</mo><mi id=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.1\" mathsize=\"144%\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.1.cmml\">l</mi><mo id=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.3.2\" maxsize=\"144%\" minsize=\"144%\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.cmml\">)</mo></mrow></msup><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.6.6.6.1.1.1.m1.1b\"><apply id=\"S6.T6.6.6.6.1.1.1.m1.1.2.cmml\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2\"><csymbol cd=\"ambiguous\" id=\"S6.T6.6.6.6.1.1.1.m1.1.2.1.cmml\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2\">superscript</csymbol><ci id=\"S6.T6.6.6.6.1.1.1.m1.1.2.2.cmml\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.2.2\">\\mathcal{W}</ci><ci id=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.1.cmml\" xref=\"S6.T6.6.6.6.1.1.1.m1.1.1.1.1\">l</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.6.6.6.1.1.1.m1.1c\">\\mathcal{W}^{(l)}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.6.6.6.1.1.1.m1.1d\">caligraphic_W start_POSTSUPERSCRIPT ( italic_l ) end_POSTSUPERSCRIPT</annotation></semantics></math> | The set of all subbands within layer <math alttext=\"l\" class=\"ltx_centering\" display=\"inline\" id=\"S6.T6.7.7.7.2.1.1.m1.1\"><semantics id=\"S6.T6.7.7.7.2.1.1.m1.1a\"><mi id=\"S6.T6.7.7.7.2.1.1.m1.1.1\" mathsize=\"144%\" xref=\"S6.T6.7.7.7.2.1.1.m1.1.1.cmml\">l</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.7.7.7.2.1.1.m1.1b\"><ci id=\"S6.T6.7.7.7.2.1.1.m1.1.1.cmml\" xref=\"S6.T6.7.7.7.2.1.1.m1.1.1\">l</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.7.7.7.2.1.1.m1.1c\">l</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.T6.7.7.7.2.1.1.m1.1d\">italic_l</annotation></semantics></math> |", "caption": "Table 6: Notations symbols and their descriptions.", "description": "This table lists notations used in the paper along with their corresponding descriptions.  It serves as a quick reference for readers to understand the meaning of symbols and abbreviations used throughout the paper.", "section": "6. Notations"}, {"content": "| Parameter | Setting |\n|---|---| \n| *Stage I - 800k step* |  |\n| Learning Rate | 1e-5 |\n| Total Batch Size | 8 |\n| Peceptual(LPIPS) Weight | 1.0 |\n| WL Loss Weight (\u03bb<sub>WL</sub>) | 0.1 |\n| KL Weight (\u03bb<sub>KL</sub>) | 1e-6 |\n| Learning Rate | 1e-5 |\n| Resolution | 256 \u00d7 256 |\n| Num Frames | 25 |\n| EMA Decay | 0.999 |\n| *Stage II - 200k step* |  |\n| Num Frames | 49 |\n| *Stage III - 200k step* |  |\n| Peceptual(LPIPS) Weight | 0.1 |", "caption": "Table 7: Training hyperparameters across three stages.", "description": "This table lists the hyperparameters used during the training process of the WF-VAE model. The training is divided into three stages, each with its own set of hyperparameters.  The parameters include the learning rate, batch size, weights for different loss functions (perceptual loss, KL divergence, and the custom WL loss), resolution of the input videos, number of frames, and EMA decay rate.  Understanding these settings is key to replicating the training process and analyzing the model's performance across the different stages.", "section": "8. Training Details"}]