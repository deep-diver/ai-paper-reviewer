{"references": [{" publication_date": "2023", "fullname_first_author": "Josh Achiam", "paper_title": "Gpt-4 technical report", "reason": "This paper is foundational as it provides the technical report for GPT-4, a highly influential large language model (LLM).  Understanding GPT-4's architecture and capabilities is critical for researchers working on private inference, as it represents a significant benchmark against which new methods can be compared. The introduction specifically mentions ChatGPT and GPT-2, making this a relevant foundational paper.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Matteo Alleman", "paper_title": "Task structure and nonlinearity jointly determine learned representational geometry", "reason": "This work provides critical insights into the role of non-linearities in shaping learned representations within neural networks, directly relevant to Section 3's investigation of non-linearities in LLMs for private inference. The paper's focus on the interplay between task structure and non-linearity helps to understand how non-linearities influence the learning dynamics and internal representations of LLMs.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Stella Biderman", "paper_title": "Pythia: A suite for analyzing large language models across training and scaling", "reason": "This paper is highly significant because it introduces Pythia, a benchmark suite for analyzing LLMs.  The introduction mentions the need for benchmarking and comparing new methods against existing state-of-the-art techniques.  Pythia provides a widely-used benchmark suite for this purpose.  The paper's focus on analyzing various aspects of LLMs (training, scaling, etc.) makes it valuable for researchers assessing the broader impact of changes introduced by AERO.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "reason": "This seminal paper establishes the few-shot learning capabilities of language models, a crucial aspect in evaluating the broader implications of AERO. Section 3 and the discussion of results heavily depend on the understanding of how few-shot learning relates to the architecture and training dynamics of LLMs. This paper provides the foundational context for assessing the ability of AERO-optimized models to maintain or improve few-shot learning capabilities.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Nicholas Carlini", "paper_title": "Stealing part of a production language model", "reason": "This paper addresses the security challenges associated with proprietary LLMs, particularly the risk of model extraction attacks. This is highly relevant to Section 1 which establishes the motivation for private inference by highlighting the privacy concerns associated with proprietary LLMs.  Understanding these attacks is crucial for developing robust private inference methods.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Dake Chen", "paper_title": "Rna-vit: Reduced-dimension approximate normalized attention vision transformers for latency efficient private inference", "reason": "This paper directly addresses the problem of efficient private inference (PI), which is the central theme of the paper.  Section 1 highlights the limitations of existing PI approaches.  This paper provides an example of an existing method that attempts to tackle the challenges of efficient PI, allowing for a comparison with the proposed AERO approach and highlighting the specific advancements AERO offers.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Xiang Cheng", "paper_title": "Transformers implement functional gradient descent to learn non-linear functions in context", "reason": "This paper offers a theoretical understanding of how transformers learn nonlinear functions in the context of their inputs.  This is highly relevant to Section 3, which investigates the role of non-linearities in LLMs, and is crucial for understanding the implications of removing or modifying non-linearities within the LLM architecture.  The theoretical analysis aids in understanding the behavior and impact of the changes introduced by AERO.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Naren Dhyani", "paper_title": "Privit: Vision transformers for fast private inference", "reason": "This work focuses on improving the efficiency of private inference for vision transformers.   Section 1 discusses the challenges of efficient private inference and mentions the need for reducing computational overheads.  This paper provides another example of an existing method that tries to address these challenges, serving as a useful comparison point for evaluating the advancements offered by the AERO framework.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Bobby He", "paper_title": "Simplifying transformer blocks", "reason": "This paper presents techniques for simplifying transformer blocks and improving the efficiency of LLMs.  This is directly relevant to AERO's goals of reducing non-linearities and FLOPs for efficient private inference.  The paper serves as a direct comparison point for evaluating AERO's performance and innovation in optimizing LLMs for private inference.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Xiaoyang Hou", "paper_title": "Ciphergpt: Secure two-party gpt inference", "reason": "This paper tackles secure two-party inference for LLMs, a crucial area related to private inference.  Section 1 sets the stage by discussing the need for private inference, highlighting its importance for protecting sensitive user data.  This paper illustrates a previous effort to achieve this secure inference, providing a comparison point for the improvements proposed by AERO.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Nikola Jovanovi\u0107", "paper_title": "Watermark stealing in large language models", "reason": "This paper explores the security vulnerabilities of large language models, focusing on watermark stealing attacks. This is relevant to Section 1, which establishes the motivation for private inference by highlighting the privacy concerns around proprietary LLMs.  Understanding the potential security threats is crucial for developing secure and effective private inference methods like AERO.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Brian Knott", "paper_title": "Crypten: Secure multi-party computation meets machine learning", "reason": "This paper introduces Crypten, a framework for secure multi-party computation (MPC) applied to machine learning.  Section 1 emphasizes the high communication and latency overheads of existing private inference methods. This paper is crucial as it presents an existing MPC framework for machine learning, which is directly relevant to the methods employed for private inference in LLMs.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Goode Lauren", "paper_title": "Chatgpt can now talk to you-and look into your life", "reason": "This news article highlights the growing concerns about privacy and the use of proprietary LLMs like ChatGPT. The introduction discusses the motivation for private inference due to the privacy risks associated with proprietary LLMs. This article emphasizes the urgency and relevance of the problem and supports the importance of research in private inference methods.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Dacheng Li", "paper_title": "MPCFORMER: FAST, PERFORMANT AND PRIVATE TRANSFORMER INFERENCE WITH MPC", "reason": "This paper presents MPCFORMER, a method for achieving fast and private transformer inference using multi-party computation (MPC).  Section 1 discusses the need for efficient private inference, highlighting the high latency and communication overheads of existing methods. This paper directly addresses this need, providing a relevant comparison point for evaluating the performance improvements offered by the AERO framework.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Liunian Harold Li", "paper_title": "Symbolic chain-of-thought distillation: Small models can also\" think\" step-by-step", "reason": "This paper explores techniques for improving the reasoning capabilities of smaller LLMs. Section 3 analyzes the impact of non-linearities on the performance of LLMs, including their influence on reasoning abilities. This paper is significant because it relates to the broader capabilities of LLMs and how the optimization of architecture in AERO affects the performance on more complex reasoning tasks.", "section_number": 3}, {" publication_date": "2013", "fullname_first_author": "Andrew L Maas", "paper_title": "Rectifier nonlinearities improve neural network acoustic models", "reason": "This paper is highly influential as it introduces the ReLU activation function, which is explored in detail within the context of private inference for LLMs in Section 3. The importance of this paper lies in the empirical findings regarding the effectiveness of ReLU, particularly in LayerNorm-free LLMs, and its overall contribution to improving the performance and efficiency of neural networks.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Niloofar Mireshghallah", "paper_title": "Can LLMs keep a secret? testing privacy implications of language models via contextual integrity theory", "reason": "This paper investigates the privacy implications of LLMs, which is a key motivation for the development of private inference techniques. Section 1 highlights the privacy concerns surrounding the use of proprietary LLMs, making this paper highly relevant.  It supports the need for AERO by showing the risks associated with using LLMs in scenarios where data privacy is critical.", "section_number": 1}, {" publication_date": "2018", "fullname_first_author": "Takeru Miyato", "paper_title": "Spectral normalization for generative adversarial networks", "reason": "This paper introduces spectral normalization, a regularization technique used in AERO to mitigate training instability in softmax-only LLMs. Section 4 discusses various techniques for preventing training collapse, including spectral normalization.  Understanding spectral normalization is crucial for evaluating the different approaches employed by AERO to address the challenges of training softmax-only models.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Neel Nanda", "paper_title": "Attribution patching: Activation patching at industrial scale", "reason": "This paper explores activation patching, a technique relevant to the discussion of non-linearities in LLMs for private inference. Section 3 analyzes the role of non-linearities in LLMs, which relates to the internal representations and learning dynamics of these models.  This paper offers insights into methods for manipulating internal activations and addresses related challenges.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper introduces the GPT-2 model, which is used extensively in the experimental evaluations within the paper. The introduction section mentions GPT-2 as a model where current private inference methods are inefficient, while Section 5 validates AERO using GPT-2 as a benchmark. This paper is foundational for understanding the model being evaluated and the baseline against which AERO's improvements are measured.", "section_number": 1}]}