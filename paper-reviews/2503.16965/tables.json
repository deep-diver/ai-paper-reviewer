[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.1.1.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S2.T1.1.1.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.2.1\"># LM Params</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S2.T1.1.1.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.3.1\">Accuracy</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.2.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Llama-3.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T1.1.2.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T1.1.2.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">79.11</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.3.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Qwen2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.3.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.3.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">81.45</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"S2.T1.1.4.1.1\">\\hdashline</span>Mllama</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.4.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">8B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.4.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">75.65</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.5.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Qwen2-VL</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.5.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.5.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">80.32</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.6.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">LLaVA-OneVision</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S2.T1.1.6.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S2.T1.1.6.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">78.31</td>\n</tr>\n</table>", "caption": "Table 1: \nModel results on VIVA action selection task.", "description": "This table presents the performance of various Large Language Models (LLMs) and Visual Language Models (VLMs) on the VIVA benchmark's action selection task.  The VIVA benchmark focuses on human-centered decision-making scenarios.  The table shows the model name, the number of parameters in the Language Model component, and the accuracy achieved on the task. This allows for a comparison of different models' abilities to make decisions in complex, human-centric situations.", "section": "2.3 Results and Analysis"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T2.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1\">\n<td class=\"ltx_td ltx_border_tt\" colspan=\"2\" id=\"S4.T2.1.1.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T2.1.1.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.2.1\">Train Size</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.2.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.2.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.2.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.2.2.1\">Data Source</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.2.3.1\">10k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.2.4.1\">20k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.5\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.2.5.1\">30k</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.3.1\" rowspan=\"2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text\" id=\"S4.T2.1.3.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.3.1.1.1\"></span> <span class=\"ltx_text\" id=\"S4.T2.1.3.1.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.1.3.1.1.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T2.1.3.1.1.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.3.1.1.2.1.1.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">Mllama</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T2.1.3.1.1.3\"></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.3.2.1\">GPT-4o</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">77.26</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.11</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.5\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.3.5.1\">79.60</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.4.1.1\">Llama (8B)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">77.18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">78.95</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.03</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.5.1\" rowspan=\"2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.1.5.1.1\">\\hdashline</span><span class=\"ltx_text\" id=\"S4.T2.1.5.1.2\"><span class=\"ltx_text\" id=\"S4.T2.1.5.1.2.1\"></span> <span class=\"ltx_text\" id=\"S4.T2.1.5.1.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.1.5.1.2.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T2.1.5.1.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.5.1.2.2.1.1.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">Qwen2-VL</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T2.1.5.1.2.3\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.5.2.1\">GPT-4o</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">82.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">82.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.5\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.5.1\">83.15</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.6.1.1\">Llama (8B)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">82.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">82.66</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.6.4.1\">83.15</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.7.1\" rowspan=\"2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.1.7.1.1\">\\hdashline</span><span class=\"ltx_text\" id=\"S4.T2.1.7.1.2\"><span class=\"ltx_text\" id=\"S4.T2.1.7.1.2.1\"></span> <span class=\"ltx_text\" id=\"S4.T2.1.7.1.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.1.7.1.2.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T2.1.7.1.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.7.1.2.2.1.1.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">LLaVA-OV</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T2.1.7.1.2.3\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.7.2.1\">GPT-4o</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.52</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.5\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.7.5.1\">80.81</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.8.1\" style=\"padding-left:5.1pt;padding-right:5.1pt;\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.1.8.1.1\">Llama (8B)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.8.2\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">78.79</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.8.3\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.8.4\" style=\"padding-left:5.1pt;padding-right:5.1pt;\">79.60</td>\n</tr>\n</table>", "caption": "Table 2: \nAccuracy of VLMs finetuned with different training data on VIVA benchmark. Data Source denotes the model used for training data creation, and Train Size represents the number of training samples used for finetuning.", "description": "This table presents the accuracy of three Visual Language Models (VLMs) after fine-tuning on text-only data generated by two different Language Models (LLMs). The VLMs are Mllama, Qwen2-VL, and LLaVA-OneVision. The LLMs are GPT-4 and Llama 8B.  The table shows the accuracy of each VLM trained on 10k, 20k, and 30k training samples generated by each LLM. This demonstrates the impact of both the LLM used for data generation and the size of the training dataset on VLM performance in a human-centered decision-making task using the VIVA benchmark.", "section": "4 How Do Textual Training Data Influence Model Performance?"}]