<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Graph Generative Pre-trained Transformer &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="Graph Generative Pre-trained Transformer &#183; HF Daily Paper Reviews by AI"><meta name=description content="G2PT: a novel graph generative model using sequence-based representation and transformer decoder, achieving superior performance on diverse tasks."><meta name=keywords content="Machine Learning,Graph Representation Learning,üè¢ Tufts University,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="Graph Generative Pre-trained Transformer"><meta property="og:description" content="G2PT: a novel graph generative model using sequence-based representation and transformer decoder, achieving superior performance on diverse tasks."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-01-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-02T00:00:00+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Graph Representation Learning"><meta property="article:tag" content="üè¢ Tufts University"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/cover.png"><meta name=twitter:title content="Graph Generative Pre-trained Transformer"><meta name=twitter:description content="G2PT: a novel graph generative model using sequence-based representation and transformer decoder, achieving superior performance on diverse tasks."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Graph Generative Pre-trained Transformer","headline":"Graph Generative Pre-trained Transformer","abstract":"G2PT: a novel graph generative model using sequence-based representation and transformer decoder, achieving superior performance on diverse tasks.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2501.01073\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-01-02T00:00:00\u002b00:00","datePublished":"2025-01-02T00:00:00\u002b00:00","dateModified":"2025-01-02T00:00:00\u002b00:00","keywords":["Machine Learning","Graph Representation Learning","üè¢ Tufts University"],"mainEntityOfPage":"true","wordCount":"3057"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-02-28/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-02-28</p></a><a href=/ai-paper-reviewer/2025-03-03/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-03</p></a><a href=/ai-paper-reviewer/2025-03-04/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-04</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-02-28/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-02-28</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-03/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-03</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-04/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-04</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2501.01073/cover_hu11789774342358477922.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2501.01073/>Graph Generative Pre-trained Transformer</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Graph Generative Pre-trained Transformer</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-01-02T00:00:00+00:00>2 January 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3057 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">15 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2501.01073/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2501.01073/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/machine-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Machine Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/graph-representation-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Graph Representation Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-tufts-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Tufts University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#graphseq-encoding>GraphSeq Encoding</a></li><li><a href=#g2pt-model>G2PT Model</a></li><li><a href=#fine-tuning-g2pt>Fine-tuning G2PT</a></li><li><a href=#generative-results>Generative Results</a></li><li><a href=#future-work>Future Work</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#graphseq-encoding>GraphSeq Encoding</a></li><li><a href=#g2pt-model>G2PT Model</a></li><li><a href=#fine-tuning-g2pt>Fine-tuning G2PT</a></li><li><a href=#generative-results>Generative Results</a></li><li><a href=#future-work>Future Work</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2501.01073</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Xiaohui Chen et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-01-06</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2501.01073 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2501.01073 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/graph-generative-pre-trained-transformer target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2501.01073/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Graph generation is crucial across various fields but existing models often face limitations in efficiency and scalability. Many rely on adjacency matrices, which can be computationally expensive for large graphs and struggle with effectively representing complex relationships in data. Others use auto-regressive frameworks that are often less expressive. This research addresses the inherent limitations by proposing a more efficient and flexible method.</p><p>The proposed method, named G2PT, utilizes a novel sequence-based graph representation, which greatly improves efficiency. This is coupled with the use of a transformer decoder for next-token prediction, leveraging the power of autoregressive modeling but avoiding its shortcomings. Experiments demonstrate that G2PT significantly outperforms state-of-the-art methods on various graph generation and prediction tasks, highlighting its flexibility and potential impact on various applications.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-54437fd14f521fbf10ee1d568ff67a4b></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-54437fd14f521fbf10ee1d568ff67a4b",{strings:[" G2PT uses a novel sequence-based graph representation that efficiently encodes graph structures. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-3a44316566825e8681e98ba34a606730></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-3a44316566825e8681e98ba34a606730",{strings:[" G2PT achieves superior generative performance and strong adaptability in downstream tasks. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-c40d1ef89503211ffe6bee5ceef08fb7></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-c40d1ef89503211ffe6bee5ceef08fb7",{strings:[" Fine-tuning strategies for goal-oriented generation and graph property prediction are explored. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is important because it <strong>introduces a novel approach to graph generation</strong> using a sequence-based representation and a transformer decoder, achieving state-of-the-art results. This method offers <strong>efficiency and flexibility</strong>, making it suitable for various downstream tasks, opening new avenues for research in molecular design and other graph-related fields. The <strong>exploration of fine-tuning strategies</strong> for different applications further enhances its value to researchers.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.01073/x4.png alt></figure></p><blockquote><p>üîº This figure illustrates how a graph is represented as a sequence of actions. First, all nodes are generated, each represented by its type and a unique index. Then, edges are added one by one, each defined by the source node index, the destination node index, and the edge type. The entire graph generation process is thus encoded as a sequence of tokens, which allows the use of a transformer-decoder architecture to model this sequence and predict the next token in the sequence during training. A unified vocabulary is used to represent all node types, edge types, and actions (node creation and edge creation), making this representation suitable for the transformer-decoder.</p><details><summary>read the caption</summary>Figure 1: Illustration of our proposed graph sequence representation. This representation can be viewed as a sequence of actions: first generating all nodes (node type, node index), then explicitly adding edges (source node index, destination node index, edge type) step by step until completion. A unified vocabulary is used to map different types of actions into a shared token space.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Model (Rep.)</th><th>Likelihood</th><th>Illustration</th><th>#Network Calls</th><th>#Variables</th><th>Decomposition</th></tr></thead><tbody><tr><td>Diffusion (<math alttext="\mathbf{A}" class="ltx_Math" display="inline" id="S1.T1.1.1.1.1.m1.1"><semantics id="S1.T1.1.1.1.1.m1.1a"><mi id="S1.T1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.m1.1.1.cmml">ùêÄ</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.m1.1.1">ùêÄ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.m1.1c">\mathbf{A}</annotation><annotation encoding="application/x-llamapun" id="S1.T1.1.1.1.1.m1.1d">bold_A</annotation></semantics></math>)</td><td>&lt;math alttext=&ldquo;p(\mathbf{A}^{T})\displaystyle\prod_{t=1}^{T}p(\mathbf{A}^{t-1}</td><td>\mathbf{A}^{t})&rdquo; class=&ldquo;ltx_Math&rdquo; display=&ldquo;inline&rdquo; id=&ldquo;S1.T1.2.2.2.2.m1.2&rdquo;><semantics id=S1.T1.2.2.2.2.m1.2a><mrow id=S1.T1.2.2.2.2.m1.2.2 xref=S1.T1.2.2.2.2.m1.2.2.cmml><mi id=S1.T1.2.2.2.2.m1.2.2.4 xref=S1.T1.2.2.2.2.m1.2.2.4.cmml>p</mi><mo id=S1.T1.2.2.2.2.m1.2.2.3 xref=S1.T1.2.2.2.2.m1.2.2.3.cmml>,\prod_{t=1}^{T}p(\mathbf{A}^{t-1}</td><td>\mathbf{A}^{t})</annotation></semantics></math></td><td><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height=66 id=S1.T1.3.3.3.3.1.g1 src=https://arxiv.org/html/2501.01073/x1.png width=332></td><td><math alttext="T" class="ltx_Math" display="inline" id="S1.T1.4.4.4.4.m1.1"><semantics id="S1.T1.4.4.4.4.m1.1a"><mi id="S1.T1.4.4.4.4.m1.1.1" xref="S1.T1.4.4.4.4.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S1.T1.4.4.4.4.m1.1b"><ci id="S1.T1.4.4.4.4.m1.1.1.cmml" xref="S1.T1.4.4.4.4.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.4.4.4.4.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S1.T1.4.4.4.4.m1.1d">italic_T</annotation></semantics></math></td></tr><tr><td>Auto-regressive (<math alttext="\mathbf{A}" class="ltx_Math" display="inline" id="S1.T1.6.6.6.1.m1.1"><semantics id="S1.T1.6.6.6.1.m1.1a"><mi id="S1.T1.6.6.6.1.m1.1.1" xref="S1.T1.6.6.6.1.m1.1.1.cmml">ùêÄ</mi><annotation-xml encoding="MathML-Content" id="S1.T1.6.6.6.1.m1.1b"><ci id="S1.T1.6.6.6.1.m1.1.1.cmml" xref="S1.T1.6.6.6.1.m1.1.1">ùêÄ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.6.6.6.1.m1.1c">\mathbf{A}</annotation><annotation encoding="application/x-llamapun" id="S1.T1.6.6.6.1.m1.1d">bold_A</annotation></semantics></math>)</td><td>&lt;math alttext="\displaystyle\prod_{i=2}^{n}\prod_{j=1}^{i-1}p(\mathbf{A}_{i,j}</td><td>\mathbf{A}<em>{&lt;i,% &lt;i-1},\mathbf{A}</em>{i,&lt;j})" class=&ldquo;ltx_Math&rdquo; display=&ldquo;inline&rdquo; id=&ldquo;S1.T1.7.7.7.2.m1.7&rdquo;><semantics id=S1.T1.7.7.7.2.m1.7a><mrow id=S1.T1.7.7.7.2.m1.7.7 xref=S1.T1.7.7.7.2.m1.7.7.cmml><mstyle displaystyle=true id=S1.T1.7.7.7.2.m1.7.7.2 xref=S1.T1.7.7.7.2.m1.7.7.2.cmml><munderover id=S1.T1.7.7.7.2.m1.7.7.2a xref=S1.T1.7.7.7.2.m1.7.7.2.cmml><mo id=S1.T1.7.7.7.2.m1.7.7.2.2.2 movablelimits=false xref=S1.T1.7.7.7.2.m1.7.7.2.2.2.cmml>\prod_{i=2}^{n}\prod_{j=1}^{i-1}p(\mathbf{A}_{i,j}</td><td>\mathbf{A}<em>{&lt;i,% &lt;i-1},\mathbf{A}</em>{i,&lt;j})</annotation></semantics></math></td><td><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height=66 id=S1.T1.8.8.8.3.1.g1 src=https://arxiv.org/html/2501.01073/x2.png width=332></td><td><math alttext="O(n^{2})" class="ltx_Math" display="inline" id="S1.T1.9.9.9.4.m1.1"><semantics id="S1.T1.9.9.9.4.m1.1a"><mrow id="S1.T1.9.9.9.4.m1.1.1" xref="S1.T1.9.9.9.4.m1.1.1.cmml"><mi id="S1.T1.9.9.9.4.m1.1.1.3" xref="S1.T1.9.9.9.4.m1.1.1.3.cmml">O</mi><mo id="S1.T1.9.9.9.4.m1.1.1.2" xref="S1.T1.9.9.9.4.m1.1.1.2.cmml">,\prod_{i=2}^{n}\prod_{j=1}^{i-1}p(\mathbf{A}_{i,j}</td>
      </tr>
      <tr>
          <td>Auto-regressive (<math alttext="E" class="ltx_Math" display="inline" id="S1.T1.11.11.11.1.m1.1"><semantics id="S1.T1.11.11.11.1.m1.1a"><mi id="S1.T1.11.11.11.1.m1.1.1" xref="S1.T1.11.11.11.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S1.T1.11.11.11.1.m1.1b"><ci id="S1.T1.11.11.11.1.m1.1.1.cmml" xref="S1.T1.11.11.11.1.m1.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.11.11.11.1.m1.1c">E</annotation><annotation encoding="application/x-llamapun" id="S1.T1.11.11.11.1.m1.1d">italic_E</annotation></semantics></math>)</td><td>&lt;math alttext=&ldquo;p(e_{1})\displaystyle\prod_{i=2}^{m}p(e_{i}</td><td>e_{&lt;i})&rdquo; class=&ldquo;ltx_Math&rdquo; display=&ldquo;inline&rdquo; id=&ldquo;S1.T1.12.12.12.2.m1.2&rdquo;><semantics id=S1.T1.12.12.12.2.m1.2a><mrow id=S1.T1.12.12.12.2.m1.2.2 xref=S1.T1.12.12.12.2.m1.2.2.cmml><mi id=S1.T1.12.12.12.2.m1.2.2.4 xref=S1.T1.12.12.12.2.m1.2.2.4.cmml>p</mi><mo id=S1.T1.12.12.12.2.m1.2.2.3 xref=S1.T1.12.12.12.2.m1.2.2.3.cmml>,\prod_{i=2}^{m}p(e_{i}</td><td>e_{&lt;i})</annotation></semantics></math></td><td><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height=66 id=S1.T1.13.13.13.3.1.g1 src=https://arxiv.org/html/2501.01073/x3.png width=332></td><td><math alttext="O(m)" class="ltx_Math" display="inline" id="S1.T1.14.14.14.4.m1.1"><semantics id="S1.T1.14.14.14.4.m1.1a"><mrow id="S1.T1.14.14.14.4.m1.1.2" xref="S1.T1.14.14.14.4.m1.1.2.cmml"><mi id="S1.T1.14.14.14.4.m1.1.2.2" xref="S1.T1.14.14.14.4.m1.1.2.2.cmml">O</mi><mo id="S1.T1.14.14.14.4.m1.1.2.1" xref="S1.T1.14.14.14.4.m1.1.2.1.cmml">,\prod_{i=2}^{m}p(e_{i}</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table provides a comparison of different graph generative model families, categorized by their data representation (adjacency matrix or edge set) and likelihood decomposition approach (diffusion-based or autoregressive). It shows the computational complexity in terms of the number of network calls and variables involved.  The illustration visually explains how each approach generates graph structures, step-by-step, using solid and dashed lines to depict edges and non-edges, with the current step highlighted in blue. Notably, the table highlights that the proposed Graph Generative Pre-trained Transformer (G2PT) is an autoregressive model working with the edge set representation.</p>
<details>
<summary>read the caption</summary>
Table 1: Overview of graph generative model families combined with the used data representation (Rep.). nùëõnitalic_n: number of nodes. mùëömitalic_m: number of edges. In the illustration, we use solid line for edges and dash line for non-edges, (non-)edges generated at current step are colored in blue. Our proposed G2PT is an Auto-regressive model that learns on Eùê∏Eitalic_E representation.
</details>
</blockquote>


<h3 class="relative group">In-depth insights 
    <div id="in-depth-insights" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#in-depth-insights" aria-label="Anchor">#</a>
    </span>        
    
</h3>


<h4 class="relative group">GraphSeq Encoding 
    <div id="graphseq-encoding" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#graphseq-encoding" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>The heading &ldquo;GraphSeq Encoding&rdquo; suggests a novel method for representing graphs as sequences, a crucial step in applying sequence-based models like transformers to graph-structured data.  A well-designed GraphSeq encoding would likely involve <strong>transforming graph elements (nodes and edges) into a sequential format</strong>, potentially by incorporating node features, edge types, and topological information.  The choice of sequencing (e.g., breadth-first search, depth-first search, random ordering) would significantly impact the model&rsquo;s ability to learn graph structures.  <strong>An effective encoding must balance expressiveness with efficiency</strong>; it should capture the essential characteristics of the graph while avoiding excessive length or redundancy.  The success of this approach hinges on how well the encoding captures graph features and allows the sequence model to accurately reconstruct or generate graphs.  Furthermore, the choice of vocabulary for tokenizing the sequence representation and the overall design would directly impact computational performance. Ultimately, the evaluation of GraphSeq would revolve around its effectiveness in downstream applications, such as graph generation and property prediction, demonstrating its capability to improve upon previous methods.</p>


<h4 class="relative group">G2PT Model 
    <div id="g2pt-model" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#g2pt-model" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>The G2PT model, a Graph Generative Pre-trained Transformer, presents a novel approach to graph generation.  <strong>Its core innovation lies in representing graphs as sequences of node and edge definitions</strong>, shifting away from adjacency matrices. This sequence-based representation allows for efficient encoding and leverages the power of transformer decoders for next-token prediction.  <strong>The model&rsquo;s auto-regressive nature enables sequential generation of graph structures</strong>, making it suitable for various downstream tasks, including goal-oriented generation and graph property prediction.  <strong>Fine-tuning strategies are explored for both scenarios</strong>, demonstrating the adaptability of the model to specific needs. Overall, G2PT showcases the effectiveness of combining transformer architecture with a carefully designed sequence representation for enhanced graph generation performance and versatility.  <strong>The model&rsquo;s strong performance across diverse datasets is a key strength</strong>, underlining its potential as a general-purpose graph generation foundation model.</p>


<h4 class="relative group">Fine-tuning G2PT 
    <div id="fine-tuning-g2pt" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#fine-tuning-g2pt" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>The section on &ldquo;Fine-tuning G2PT&rdquo; would explore how the pre-trained Graph Generative Pre-trained Transformer (G2PT) model can be adapted for downstream tasks. This involves <strong>transfer learning</strong>, leveraging the knowledge learned during pre-training on a large graph dataset to improve performance on specific tasks with limited data.  The authors likely investigate two main categories of downstream tasks: <strong>goal-oriented generation</strong> and <strong>graph property prediction</strong>. Goal-oriented generation focuses on generating graphs with specific properties, perhaps using techniques like <strong>reinforcement learning</strong> or <strong>rejection sampling</strong> to guide the generation process towards desired outcomes.  Graph property prediction would involve adapting G2PT to predict properties of graphs, such as molecular properties in drug discovery, directly using the learned representations. This could utilize supervised fine-tuning approaches.  The results of this fine-tuning would demonstrate G2PT‚Äôs <strong>adaptability and versatility</strong>, showcasing its effectiveness as a general-purpose foundation model for various graph-related applications. The analysis will likely show how the pre-training helps to overcome challenges associated with limited data in downstream tasks and how effectively G2PT can be adapted, highlighting its strengths compared to other models in this area.</p>


<h4 class="relative group">Generative Results 
    <div id="generative-results" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#generative-results" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>A dedicated &lsquo;Generative Results&rsquo; section in a research paper would ideally present a comprehensive evaluation of a novel graph generative model.  This would involve showcasing the model&rsquo;s ability to generate diverse and realistic graph structures, comparing its performance against existing state-of-the-art methods using established metrics, and providing qualitative visualizations of the generated graphs to illustrate their properties.  <strong>Quantitative metrics</strong> would likely include measures of graph structure such as node degree distribution, clustering coefficient, and path lengths, possibly also evaluating the novelty and uniqueness of generated graphs.  <strong>Qualitative analysis</strong> would involve visual inspection of generated samples, assessing their realism and plausibility within the target domain.  The results should be presented across different datasets to show the model&rsquo;s generalization ability and robustness. <strong>Crucially, the analysis should discuss any limitations</strong>, addressing challenges encountered during generation and suggesting areas for future improvement.  A thorough analysis of generative results is vital to establishing the significance and potential impact of a new graph generative model.</p>


<h4 class="relative group">Future Work 
    <div id="future-work" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#future-work" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>Future research directions for this Graph Generative Pre-trained Transformer (G2PT) model could explore <strong>improving the efficiency and scalability</strong> of the training process, particularly for larger and more complex graphs.  Investigating alternative training strategies beyond the current autoregressive approach, perhaps incorporating diffusion models or other generative techniques, could potentially unlock improved performance.  Another avenue of investigation would be to <strong>deepen the understanding of edge ordering techniques</strong>. The current approach shows sensitivity to the chosen ordering; therefore, developing a more universal and expressive edge ordering strategy is crucial.  Furthermore, exploring <strong>different graph representations beyond the sequence-based approach</strong> could potentially lead to more efficient models and broader applications.  Finally, applying G2PT to a wider range of downstream tasks, especially those involving complex relationship modeling and structural prediction problems, represents a promising area for future development.  <strong>Benchmarking G2PT against a more extensive set of state-of-the-art baselines</strong> on diverse datasets is also important to fully evaluate its capabilities and identify limitations.</p>


<h3 class="relative group">More visual insights 
    <div id="more-visual-insights" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#more-visual-insights" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<details>
<summary>More on tables
</summary>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>Model</th>
          <th>Planar</th>
          <th>Planar</th>
          <th>Planar</th>
          <th>Planar</th>
          <th>Planar</th>
          <th>Planar</th>
          <th>Tree</th>
          <th>Tree</th>
          <th>Tree</th>
          <th>Tree</th>
          <th>Tree</th>
          <th>Tree</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Deg. ‚Üì</td>
          <td>Clus. ‚Üì</td>
          <td>Orbit ‚Üì</td>
          <td>Spec. ‚Üì</td>
          <td>Wavelet ‚Üì</td>
          <td>V.U.N. ‚Üë</td>
          <td>Deg. ‚Üì</td>
          <td>Clus. ‚Üì</td>
          <td>Orbit ‚Üì</td>
          <td>Spec. ‚Üì</td>
          <td>Wavelet ‚Üì</td>
          <td>V.U.N. ‚Üë</td>
          <td></td>
      </tr>
      <tr>
          <td>GRAN (Liao et al., 2019)</td>
          <td>7e-4</td>
          <td>4.3e-2</td>
          <td>9e-4</td>
          <td>7.5e-3</td>
          <td>1.9e-3</td>
          <td>0</td>
          <td>1.9e-1</td>
          <td>8e-3</td>
          <td>2e-2</td>
          <td>2.8e-1</td>
          <td>3.3e-1</td>
          <td>0</td>
      </tr>
      <tr>
          <td>BiGG (Dai et al., 2020)</td>
          <td>7e-4</td>
          <td>5.7e-2</td>
          <td>3.7e-2</td>
          <td>1.1e-2</td>
          <td>5.2e-3</td>
          <td>5</td>
          <td>1.4e-3</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>1.2e-2</td>
          <td>5.8e-3</td>
          <td>75</td>
      </tr>
      <tr>
          <td>DiGress (Vignac et al., 2022)</td>
          <td>7e-4</td>
          <td>7.8e-2</td>
          <td>7.9e-3</td>
          <td>9.8e-3</td>
          <td>3.1e-3</td>
          <td>77.5</td>
          <td>2e-4</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>1.1e-2</td>
          <td>4.3e-3</td>
          <td>90</td>
      </tr>
      <tr>
          <td>BwR (Diamant et al., 2023)</td>
          <td>2.3e-2</td>
          <td>2.6e-1</td>
          <td>5.5e-1</td>
          <td>4.4e-2</td>
          <td>1.3e-1</td>
          <td>0</td>
          <td>1.6e-3</td>
          <td>1.2e-1</td>
          <td>3e-4</td>
          <td>4.8e-2</td>
          <td>3.9e-2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>HSpectre (Bergmeister et al., 2023)</td>
          <td>5e-4</td>
          <td>6.3e-2</td>
          <td>1.7e-3</td>
          <td>7.5e-3</td>
          <td>1.3e-3</td>
          <td>95</td>
          <td>1e-4</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>1.2e-2</td>
          <td>4.7e-3</td>
          <td>100</td>
      </tr>
      <tr>
          <td>DeFoG (Qin et al., 2024)</td>
          <td>5e-4</td>
          <td>5e-2</td>
          <td>6e-4</td>
          <td>7.2e-3</td>
          <td>1.4e-3</td>
          <td>99.5</td>
          <td>2e-4</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>1.1e-2</td>
          <td>4.6e-3</td>
          <td>96.5</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub></td>
          <td>4.7e-3</td>
          <td>2.4e-3</td>
          <td>0.00</td>
          <td>1.6e-2</td>
          <td>1.4e-2</td>
          <td>95</td>
          <td>2e-3</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>7.4e-3</td>
          <td>3.9e-3</td>
          <td>99</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub></td>
          <td>1.8e-3</td>
          <td>4.7e-3</td>
          <td>0.00</td>
          <td>8.1e-3</td>
          <td>5.1e-3</td>
          <td>100</td>
          <td>4.3e-3</td>
          <td>0.00</td>
          <td>1e-4</td>
          <td>7.3e-3</td>
          <td>5.7e-3</td>
          <td>99</td>
      </tr>
      <tr>
          <td>Model</td>
          <td>Lobster</td>
          <td>Lobster</td>
          <td>Lobster</td>
          <td>Lobster</td>
          <td>Lobster</td>
          <td>Lobster</td>
          <td>SBM</td>
          <td>SBM</td>
          <td>SBM</td>
          <td>SBM</td>
          <td>SBM</td>
          <td>SBM</td>
      </tr>
      <tr>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
          <td>&mdash;</td>
      </tr>
      <tr>
          <td>Deg. ‚Üì</td>
          <td>Clus. ‚Üì</td>
          <td>Orbit ‚Üì</td>
          <td>Spec. ‚Üì</td>
          <td>Wavelet ‚Üì</td>
          <td>V.U.N. ‚Üë</td>
          <td>Deg. ‚Üì</td>
          <td>Clus. ‚Üì</td>
          <td>Orbit ‚Üì</td>
          <td>Spec. ‚Üì</td>
          <td>Wavelet ‚Üì</td>
          <td>V.U.N. ‚Üë</td>
          <td></td>
      </tr>
      <tr>
          <td>GRAN (Liao et al., 2019)</td>
          <td>3.8e-2</td>
          <td>0.00</td>
          <td>1e-3</td>
          <td>2.7e-2</td>
          <td>-</td>
          <td>-</td>
          <td>1.1e-2</td>
          <td>5.5e-2</td>
          <td>5.4e-2</td>
          <td>5.4e-3</td>
          <td>2.1e-2</td>
          <td>25</td>
      </tr>
      <tr>
          <td>BiGG (Dai et al., 2020)</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>9e-3</td>
          <td>-</td>
          <td>-</td>
          <td>1.2e-3</td>
          <td>6.0e-2</td>
          <td>6.7e-2</td>
          <td>5.9e-3</td>
          <td>3.7e-2</td>
          <td>10</td>
      </tr>
      <tr>
          <td>DiGress (Vignac et al., 2022)</td>
          <td>2.1e-2</td>
          <td>0.00</td>
          <td>4e-3</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>1.8e-3</td>
          <td>4.9e-2</td>
          <td>4.2e-2</td>
          <td>4.5e-3</td>
          <td>1.4e-3</td>
          <td>60</td>
      </tr>
      <tr>
          <td>BwR (Diamant et al., 2023)</td>
          <td>3.2e-1</td>
          <td>0.00</td>
          <td>2.5e-1</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>4.8e-2</td>
          <td>6.4e-2</td>
          <td>1.1e-1</td>
          <td>1.7e-2</td>
          <td>8.9e-2</td>
          <td>7.5</td>
      </tr>
      <tr>
          <td>HSpectre (Bergmeister et al., 2023)</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>1.2e-2</td>
          <td>5.2e-2</td>
          <td>6.7e-2</td>
          <td>6.7e-3</td>
          <td>2.2e-2</td>
          <td>45</td>
      </tr>
      <tr>
          <td>DeFoG (Qin et al., 2024)</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>6e-4</td>
          <td>5.2e-2</td>
          <td>5.6e-2</td>
          <td>5.4e-3</td>
          <td>8e-3</td>
          <td>90</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub></td>
          <td>2e-3</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>5e-3</td>
          <td>8.5e-3</td>
          <td>100</td>
          <td>3.5e-3</td>
          <td>1.2e-2</td>
          <td>7e-4</td>
          <td>7.6e-3</td>
          <td>9.8e-3</td>
          <td>100</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub></td>
          <td>1e-3</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>4e-3</td>
          <td>1e-2</td>
          <td>100</td>
          <td>4.2e-3</td>
          <td>5.3e-3</td>
          <td>3e-4</td>
          <td>6.1e-3</td>
          <td>6.9e-3</td>
          <td>100</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table presents a quantitative comparison of the generative performance of different graph generative models on four generic graph datasets: Planar, Tree, Lobster, and Stochastic Block Model (SBM).  The performance is evaluated using several metrics including degree distribution, clustering coefficient, orbit counts, spectral properties, wavelet statistics, and the percentage of valid, unique, and novel graphs generated.  These metrics assess various structural and topological aspects of the generated graphs, offering a comprehensive evaluation of each model&rsquo;s ability to generate realistic and diverse graph structures.</p>
<details>
<summary>read the caption</summary>
Table 2: Generative performance on generic graph datasets.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>Rep.</th>
          <th>#Tokens ‚Üì</th>
          <th>Deg. ‚Üì</th>
          <th>Clus. ‚Üì</th>
          <th>Orbit ‚Üì</th>
          <th>Spec. ‚Üì</th>
          <th>Wavelet ‚Üì</th>
          <th>V.U.N. ‚Üë</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>ùêÄ</td>
          <td>2018</td>
          <td>8.6e-3</td>
          <td>1e-1</td>
          <td>8e-3</td>
          <td>3.2e-2</td>
          <td>6.1e-2</td>
          <td>94</td>
      </tr>
      <tr>
          <td>Ours</td>
          <td>737</td>
          <td>4.7e-3</td>
          <td>2.4e-3</td>
          <td>0.00</td>
          <td>1.6e-2</td>
          <td>1.4e-2</td>
          <td>95</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table compares the performance of graph generative models using two different graph representations: the proposed edge sequence representation and the traditional adjacency matrix representation.  It evaluates the generative quality on planar graphs, using metrics such as the number of valid, unique and novel graphs generated,  and the degree, clustering coefficient, orbital count, spectral properties, and wavelet statistics of the generated graphs. The comparison allows assessment of the effectiveness of the novel edge sequence representation against the standard adjacency matrix method.</p>
<details>
<summary>read the caption</summary>
Table 3: Generative performance comparison between the proposed edge sequence and adjacency matrix representations.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th><strong>A</strong></th>
          <th><strong>A</strong></th>
          <th><strong>Ours</strong></th>
          <th><strong>Ours</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/demo_planar_A_1.png" alt="demo_planar_A_1" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/demo_planar_A_2.png" alt="demo_planar_A_2" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/demo_planar_ours_1.png" alt="demo_planar_ours_1" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/demo_planar_ours_2.png" alt="demo_planar_ours_2" />
    
  </figure>
</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table presents a comparison of the performance of different graph generative models on molecular graph datasets.  It shows quantitative metrics evaluating the quality of generated molecules, including validity (percentage of valid molecules), uniqueness (percentage of unique molecules), novelty (percentage of novel molecules not present in training data),  fraction of molecules that pass certain filters, Frechet ChemNet Distance (FCD), Scaffold similarity, and other metrics specific to the MOSES and GuacaMol benchmarks. This allows for a direct comparison of how well each model generates realistic and diverse molecules.</p>
<details>
<summary>read the caption</summary>
Table 4: Generative performance on molecular graph datasets
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>Model</th>
          <th>MOSES Validity ‚Üë</th>
          <th>MOSES Unique ‚Üë</th>
          <th>MOSES Novelty ‚Üë</th>
          <th>MOSES Filters ‚Üë</th>
          <th>MOSES FCD ‚Üì</th>
          <th>MOSES SNN ‚Üë</th>
          <th>MOSES Scaf ‚Üë</th>
          <th>GuacaMol Validity ‚Üë</th>
          <th>GuacaMol Unique ‚Üë</th>
          <th>GuacaMol Novelty ‚Üë</th>
          <th>GuacaMol KL Div ‚Üë</th>
          <th>GuacaMol FCD ‚Üë</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>DiGress (Vignac et al., 2022)</td>
          <td>85.7</td>
          <td><strong>100</strong></td>
          <td><strong>95.0</strong></td>
          <td>97.1</td>
          <td>1.19</td>
          <td>0.52</td>
          <td>14.8</td>
          <td>85.2</td>
          <td><strong>100</strong></td>
          <td><strong>99.9</strong></td>
          <td>92.9</td>
          <td>68</td>
      </tr>
      <tr>
          <td>DisCo (Xu et al., 2024)</td>
          <td>88.3</td>
          <td><strong>100</strong></td>
          <td><strong>97.7</strong></td>
          <td>95.6</td>
          <td>1.44</td>
          <td>0.5</td>
          <td><strong>15.1</strong></td>
          <td>86.6</td>
          <td>86.6</td>
          <td>86.5</td>
          <td>92.6</td>
          <td>59.7</td>
      </tr>
      <tr>
          <td>Cometh (Siraudin et al., 2024)</td>
          <td>90.5</td>
          <td>99.9</td>
          <td>92.6</td>
          <td><strong>99.1</strong></td>
          <td>1.27</td>
          <td><strong>0.54</strong></td>
          <td><strong>16.0</strong></td>
          <td><strong>98.9</strong></td>
          <td>98.9</td>
          <td>97.6</td>
          <td><strong>96.7</strong></td>
          <td>72.7</td>
      </tr>
      <tr>
          <td>DeFoG (Qin et al., 2024)</td>
          <td>92.8</td>
          <td>99.9</td>
          <td>92.1</td>
          <td><strong>99.9</strong></td>
          <td>1.95</td>
          <td><strong>0.55</strong></td>
          <td>14.4</td>
          <td><strong>99.0</strong></td>
          <td><strong>99.0</strong></td>
          <td>97.9</td>
          <td><strong>97.9</strong></td>
          <td>73.8</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub></td>
          <td>95.1</td>
          <td><strong>100</strong></td>
          <td>91.7</td>
          <td>97.4</td>
          <td>1.10</td>
          <td>0.52</td>
          <td>5.0</td>
          <td>90.4</td>
          <td><strong>100</strong></td>
          <td><strong>99.8</strong></td>
          <td>92.8</td>
          <td>86.6</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub></td>
          <td><strong>96.4</strong></td>
          <td><strong>100</strong></td>
          <td>86.0</td>
          <td>98.3</td>
          <td><strong>0.97</strong></td>
          <td><strong>0.55</strong></td>
          <td>3.3</td>
          <td>94.6</td>
          <td><strong>100</strong></td>
          <td>99.5</td>
          <td>96.0</td>
          <td><strong>93.4</strong></td>
      </tr>
      <tr>
          <td>G2PT<sub>large</sub></td>
          <td><strong>97.2</strong></td>
          <td><strong>100</strong></td>
          <td>79.4</td>
          <td>98.9</td>
          <td><strong>1.02</strong></td>
          <td><strong>0.55</strong></td>
          <td>2.9</td>
          <td>95.3</td>
          <td><strong>100</strong></td>
          <td>99.5</td>
          <td>95.6</td>
          <td><strong>92.7</strong></td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table presents the results of molecular property prediction experiments using the Graph Generative Pre-trained Transformer (G2PT) model.  The performance is measured by the area under the Receiver Operating Characteristic curve (ROC-AUC).  The table shows ROC-AUC scores for multiple datasets (BBBP, Tox21, ToxCast, SIDER, ClinTox, MUV, HIV, BACE) and multiple model sizes, with mean and standard deviation reported across three independent runs, providing a comprehensive evaluation of the G2PT&rsquo;s predictive capabilities in various molecular property prediction tasks.</p>
<details>
<summary>read the caption</summary>
Table 5: Results for molecule property prediction in terms of ROC-AUC. We report mean and standard deviation over three runs.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>Model</th>
          <th>QM9</th>
          <th></th>
          <th></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td></td>
          <td>Validity‚Üë</td>
          <td>Unique‚Üë</td>
          <td>FCD‚Üì</td>
      </tr>
      <tr>
          <td>DiGress (Vignac et al., 2022)</td>
          <td>99.0</td>
          <td>96.2</td>
          <td>-</td>
      </tr>
      <tr>
          <td>DisCo (Xu et al., 2024)</td>
          <td>99.6</td>
          <td>96.2</td>
          <td>0.25</td>
      </tr>
      <tr>
          <td>Cometh (Siraudin et al., 2024)</td>
          <td>99.2</td>
          <td>96.7</td>
          <td>0.11</td>
      </tr>
      <tr>
          <td>DeFoG (Qin et al., 2024)</td>
          <td>99.3</td>
          <td>96.3</td>
          <td>0.12</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub></td>
          <td>99.0</td>
          <td>96.7</td>
          <td>0.06</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub></td>
          <td>99.0</td>
          <td>96.8</td>
          <td>0.06</td>
      </tr>
      <tr>
          <td>G2PT<sub>large</sub></td>
          <td>98.9</td>
          <td>96.7</td>
          <td>0.06</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table provides a comprehensive overview of the datasets used in the experiments.  For each dataset, it lists the number of node types, edge types, the average, minimum, and maximum number of nodes in the graphs, the number of training sequences used for each dataset, and the size of the vocabulary used for tokenization during training.  This information is crucial for understanding the scale and complexity of the datasets and how they were prepared for model training.</p>
<details>
<summary>read the caption</summary>
Table 6: Dataset statistics.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>MOSES</th>
          <th></th>
          <th></th>
          <th>GuacaMol</th>
          <th></th>
          <th></th>
          <th></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Train</td>
          <td>G2PT<sub>small</sub></td>
          <td>G2PT<sub>base</sub></td>
          <td>Train</td>
          <td>G2PT<sub>small</sub></td>
          <td>G2PT<sub>base</sub></td>
          <td></td>
      </tr>
      <tr>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_train_1.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_10m_1.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_85m_1.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_train_1.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_10m_1.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_85m_1.png" alt="" />
    
  </figure>
</td>
          <td></td>
      </tr>
      <tr>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_train_2.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_10m_2.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/moses_85m_2.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_train_2.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_10m_2.png" alt="" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/images/guac_85m_2.png" alt="" />
    
  </figure>
</td>
          <td></td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table details the hyperparameters used during the pre-training phase of the Graph Generative Pre-trained Transformer (G2PT) model.  It shows how these settings varied across three different model sizes (10M, 85M, and 300M parameters), impacting aspects like architecture (number of layers, heads, and the model&rsquo;s embedding dimension), optimization (optimizer, learning rate scheduler, weight decay), training process (batch size, gradient accumulation, gradient clipping), and warmup iterations.</p>
<details>
<summary>read the caption</summary>
Table 7: Hyperparameters for graph generative pre-training.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>Density</th>
          <th>QED Score</th>
          <th>SA Score</th>
          <th>GSK3Œ≤ Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x5.png" alt="https://arxiv.org/html/2501.01073/x5.png" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x6.png" alt="https://arxiv.org/html/2501.01073/x6.png" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x7.png" alt="https://arxiv.org/html/2501.01073/x7.png" />
    
  </figure>
</td>
          <td>(a) Rejection sampling fine-tuning (with self-bootstrap)</td>
      </tr>
      <tr>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x8.png" alt="https://arxiv.org/html/2501.01073/x8.png" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x9.png" alt="https://arxiv.org/html/2501.01073/x9.png" />
    
  </figure>
</td>
          <td>
  <figure>
    <img class="my-0 rounded-md" loading="lazy" src="https://arxiv.org/html/2501.01073/x10.png" alt="https://arxiv.org/html/2501.01073/x10.png" />
    
  </figure>
</td>
          <td>(b) Reinforcement learning framework (PPO)</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table lists the hyperparameters used for training the Proximal Policy Optimization (PPO) algorithm in the goal-oriented molecule generation experiments.  It shows hyperparameters specific to three different molecular properties being optimized: Quantitative Evaluation of Druglikeness (QED), Synthetic Accessibility (SA), and Glycogen Synthase Kinase 3 Beta (GSK3Œ≤) activity.  The table includes settings for advantage and reward normalization and clipping, entropy regularization, learning rates for the actor and critic networks, and the number of training iterations.</p>
<details>
<summary>read the caption</summary>
Table 8: Hyperparameters used for PPO training.
</details>
</blockquote>
<figure style="max-width: 100%; text-align: center;">
    <table style="width: 100%;">
      <caption style="caption-side: bottom; text-align: left; white-space: normal; display: block; max-width: 100%; color: var(--tw-prose-captions); margin-bottom: 10px;"></caption>
      <table>
  <thead>
      <tr>
          <th>BBBP</th>
          <th>Tox21</th>
          <th>ToxCast</th>
          <th>SIDER</th>
          <th>ClinTox</th>
          <th>MUV</th>
          <th>HIV</th>
          <th>BACE</th>
          <th>Avg.</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>AttrMask (Hu et al., 2020)</td>
          <td>70.2 ¬± 0.5</td>
          <td>74.2 ¬± 0.8</td>
          <td>62.5 ¬± 0.4</td>
          <td>60.4 ¬± 0.6</td>
          <td>68.6 ¬± 9.6</td>
          <td>73.9 ¬± 1.3</td>
          <td>74.3 ¬± 1.3</td>
          <td>77.2 ¬± 1.4</td>
      </tr>
      <tr>
          <td>InfoGraph (Sun et al., 2020)</td>
          <td>69.2 ¬± 0.8</td>
          <td>73.0 ¬± 0.7</td>
          <td>62.0 ¬± 0.3</td>
          <td>59.2 ¬± 0.2</td>
          <td>75.1 ¬± 5.0</td>
          <td>74.0 ¬± 1.5</td>
          <td>74.5 ¬± 1.8</td>
          <td>73.9 ¬± 2.5</td>
      </tr>
      <tr>
          <td>ContextPred (Hu et al., 2020)</td>
          <td>71.2 ¬± 0.9</td>
          <td>73.3 ¬± 0.5</td>
          <td>62.8 ¬± 0.3</td>
          <td>59.3 ¬± 1.4</td>
          <td>73.7 ¬± 4.0</td>
          <td>72.5 ¬± 2.2</td>
          <td>75.8 ¬± 1.1</td>
          <td>78.6 ¬± 1.4</td>
      </tr>
      <tr>
          <td>GraphCL (You et al., 2021)</td>
          <td>67.5 ¬± 2.5</td>
          <td>75.0 ¬± 0.5</td>
          <td>62.8 ¬± 0.2</td>
          <td>60.1 ¬± 1.3</td>
          <td>78.9 ¬± 4.2</td>
          <td>77.1 ¬± 1.0</td>
          <td>75.0 ¬± 0.4</td>
          <td>68.7 ¬± 7.8</td>
      </tr>
      <tr>
          <td>GraphMVP (Liu et al., 2022a)</td>
          <td>68.5 ¬± 0.2</td>
          <td>74.5 ¬± 0.0</td>
          <td>62.7 ¬± 0.1</td>
          <td>62.3 ¬± 1.6</td>
          <td>79.0 ¬± 2.5</td>
          <td>75.0 ¬± 1.4</td>
          <td>74.8 ¬± 1.4</td>
          <td>76.8 ¬± 1.1</td>
      </tr>
      <tr>
          <td>GraphMAE (Hou et al., 2022b)</td>
          <td>70.9 ¬± 0.9</td>
          <td>75.0 ¬± 0.4</td>
          <td>64.1 ¬± 0.1</td>
          <td>59.9 ¬± 0.5</td>
          <td>81.5 ¬± 2.8</td>
          <td>76.9 ¬± 2.6</td>
          <td>76.7 ¬± 0.9</td>
          <td>81.4 ¬± 1.4</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub> (No pre-training)</td>
          <td>60.7 ¬± 0.3</td>
          <td>66.4 ¬± 0.5</td>
          <td>57.0 ¬± 0.3</td>
          <td>61.6 ¬± 0.2</td>
          <td>67.8 ¬± 1.1</td>
          <td>45.8 ¬± 8.5</td>
          <td>70.1 ¬± 7.5</td>
          <td>68.8 ¬± 1.3</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub> (No pre-training)</td>
          <td>56.5 ¬± 0.2</td>
          <td>67.4 ¬± 0.4</td>
          <td>57.9 ¬± 0.1</td>
          <td>60.2 ¬± 2.8</td>
          <td>71.0 ¬± 5.6</td>
          <td>60.1 ¬± 1.3</td>
          <td>72.7 ¬± 1.1</td>
          <td>73.4 ¬± 0.3</td>
      </tr>
      <tr>
          <td>G2PT<sub>small</sub></td>
          <td>68.5 ¬± 0.5</td>
          <td>74.7 ¬± 0.2</td>
          <td>61.2 ¬± 0.1</td>
          <td>61.7 ¬± 1.0</td>
          <td>82.3 ¬± 2.2</td>
          <td>74.9 ¬± 0.1</td>
          <td>75.7 ¬± 0.4</td>
          <td>81.3 ¬± 0.5</td>
      </tr>
      <tr>
          <td>G2PT<sub>base</sub></td>
          <td>71.0 ¬± 0.4</td>
          <td>75.0 ¬± 0.3</td>
          <td>63.0 ¬± 0.5</td>
          <td>61.9 ¬± 0.2</td>
          <td>82.1 ¬± 1.1</td>
          <td>74.5 ¬± 0.3</td>
          <td>76.3 ¬± 0.4</td>
          <td>82.3 ¬± 1.6</td>
      </tr>
  </tbody>
</table>

    </table>
</figure>
<blockquote>
<p>üîº This table presents a sensitivity analysis of different edge ordering methods used in the Graph Generative Pre-trained Transformer (G2PT) model. It compares the performance of four different edge ordering approaches: degree-based ordering, Depth-First Search (DFS) ordering, Breadth-First Search (BFS) ordering, and uniform random ordering. The evaluation metrics used include validity, uniqueness, novelty, filtering, Frechet ChemNet Distance (FCD), Scaffold similarity, and structural similarity.  The results demonstrate that degree-based and BFS ordering strategies generally perform better than DFS and uniform ordering strategies, highlighting the impact of edge ordering on the model&rsquo;s performance.</p>
<details>
<summary>read the caption</summary>
Table 9: Sensitivity analysis on edge orderings.
</details>
</blockquote>
</details>


<h3 class="relative group">Full paper 
    <div id="full-paper" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#full-paper" aria-label="Anchor">#</a>
    </span>        
    
</h3>


<div id="gallery-17210e65fb2dbeaa4d3d5a242c821f51" class="gallery">
  
<img src="https://ai-paper-reviewer.com/2501.01073/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2501.01073/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />

</div>

          
          
          
        </div>
        
        

        
        
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/&amp;title=Graph%20Generative%20Pre-trained%20Transformer"
      title="Share on LinkedIn"
      aria-label="Share on LinkedIn"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/&amp;text=Graph%20Generative%20Pre-trained%20Transformer"
      title="Tweet on Twitter"
      aria-label="Tweet on Twitter"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/&amp;subject=Graph%20Generative%20Pre-trained%20Transformer"
      title="Send via email"
      aria-label="Send via email"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>


    </a>
      
    
  </section>


          
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_paper-reviews\/2501.01073\/index.md"
        var oid_likes = "likes_paper-reviews\/2501.01073\/index.md"
      </script>
      
      
      <script type="text/javascript" src="/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
      
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/ai-paper-reviewer/paper-reviews/2501.01423/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-01-02T00:00:00&#43;00:00">2 January 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/ai-paper-reviewer/paper-reviews/2501.01054/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Dynamic Scaling of Unit Tests for Code Reward Modeling</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-01-02T00:00:00&#43;00:00">2 January 2025</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
    
    <div class="pt-3">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="pt-3">
        <script src="https://utteranc.es/client.js"
  repo="pmnxis/pmnxis.github.io"
  issue-term="pathname"
  label="Comment"
  theme="dark-blue"
  crossorigin="anonymous"
  async>
</script>

      </div>
    </div>
    
    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
    <nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex flex-col list-none sm:flex-row">
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href="/ai-paper-reviewer/tags/"
            title="">
            
            Tags
          </a>
        </li>
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href="https://deep-diver.github.io/neurips2024/"
            title="">
            
            NeurIPS2024
          </a>
        </li>
        
      </ul>
    </nav>
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2025
      Hugging Face Daily Papers
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://deep-diver.github.io/ai-paper-reviewer/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js"
  data-id="chansung" data-description="Support me on Buy me a coffee!" data-message=""
  data-color="#FFDD00" data-position="Left" data-x_margin="18" data-y_margin="18"></script>

</html>
