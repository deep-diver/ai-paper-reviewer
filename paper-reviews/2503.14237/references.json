{"references": [{"fullname_first_author": "Limin Wang", "paper_title": "Temporal segment networks: Towards good practices for deep action recognition", "publication_date": "2016-01-01", "reason": "This is a fundamental paper in video action recognition, and is thus one of the most important reference paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This work on CLIP is important, as it is a common method of aligning visual features and text, which relates to the pre-training of this paper's model."}, {"fullname_first_author": "Ji Lin", "paper_title": "Tsm: Temporal shift module for efficient video understanding", "publication_date": "2019-01-01", "reason": "The paper focuses on improving the efficiency of video understanding and, thus, is closely related."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-01-01", "reason": "This work is fundamental to the understanding of vision transformers, as the models in the paper build on top of vision transformers."}, {"fullname_first_author": "Christoph Feichtenhofer", "paper_title": "Slowfast networks for video recognition", "publication_date": "2019-01-01", "reason": "The paper is related, because the paper addresses efficiency in video recognition through the slowfast network architecture."}]}