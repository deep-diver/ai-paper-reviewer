{"references": [{"fullname_first_author": "Joya Chen", "paper_title": "VideoLLM-online: Online video large language model for streaming video", "publication_date": "2024-00-00", "reason": "This paper is directly compared against throughout the current paper as a competing model for active real-time interaction with video LLMs."}, {"fullname_first_author": "Shangzhe Di", "paper_title": "Grounded question-answering in long egocentric videos", "publication_date": "2024-00-00", "reason": "This paper provides a dataset used in training the model, improving the model's performance on streaming video QA tasks."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This model is used for extracting frame-wise features from the video, forming a crucial component of the Dispider system."}, {"fullname_first_author": "Ye Liu", "paper_title": "E.T. Bench: Towards open-ended event-level video-language understanding", "publication_date": "2024-00-00", "reason": "This benchmark provides a subset of data used for training and evaluation, particularly for assessing the model's proactive response capabilities in real-time video interactions."}, {"fullname_first_author": "Junming Lin", "paper_title": "StreamingBench: Assessing the gap for MLLMs to achieve streaming video understanding", "publication_date": "2024-00-00", "reason": "This benchmark provides comprehensive evaluation of the model's performance in streaming video understanding, evaluating its real-time interaction capabilities and providing comparison data against competing models."}]}