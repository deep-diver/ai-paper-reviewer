{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a foundational visual language model that heavily influenced the design and development of multimodal large language models (MLLMs), which are central to the current study."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "publication_date": "2023-09-16", "reason": "This report details Qwen, a powerful large language model (LLM) used as a building block for many of the MLLMs evaluated in the paper, making it a crucial foundational reference."}, {"fullname_first_author": "Trishna Chakraborty", "paper_title": "Cross-modal safety alignment: Is textual unlearning all you need?", "publication_date": "2024-06-06", "reason": "This paper explores a counter-intuitive finding regarding multimodal safety, directly addressing a core phenomenon investigated in the current study, thereby making it highly relevant."}, {"fullname_first_author": "Yangyi Chen", "paper_title": "Dress: Instructing large vision-language models to align and interact with humans via natural language feedback", "publication_date": "2024-01-01", "reason": "This paper introduces a multimodal safety benchmark (VLSafe) that's analyzed in the current work; its dataset and methodology are directly relevant to the current research."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-01-01", "reason": "This paper introduces LLaVA, a prominent MLLM used extensively in the experiments and comparisons of the study, making it an essential reference for understanding the models being evaluated."}]}