[{"figure_path": "https://arxiv.org/html/2502.15987/x1.png", "caption": "Figure 1: Monthly number of fine-tuned models after a base model\u2019s release, with colors denoting the time when it was created.", "description": "This figure visualizes the growth of fine-tuned models derived from various base open-weight AI models over time.  The x-axis represents the time elapsed since the release of each base model, and the y-axis shows the cumulative number of fine-tuned models created. Each line represents a different base model, and the color of the line indicates the model's release date. This allows for a visual comparison of the adoption rates and overall popularity of different open-weight AI models over their lifespans.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.15987/x2.png", "caption": "Figure 2: (a) Distribution of values for \u03bb\ud835\udf06\\lambdaitalic_\u03bb, \u03bc\ud835\udf07\\muitalic_\u03bc, and \u03c3\ud835\udf0e\\sigmaitalic_\u03c3. (b) Pairwise relationships among immediacy (\u03bcisubscript\ud835\udf07\ud835\udc56\\mu_{i}italic_\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), longevity (\u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT), and relative fitness (\u03bbisubscript\ud835\udf06\ud835\udc56\\lambda_{i}italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) on log-scale axes.", "description": "Figure 2 is a two-part figure that visualizes the distribution and relationships of three key parameters from a model of open-weight AI model adoption.  Part (a) shows the distribution of values for immediacy (\u03bci), longevity (\u03c3i), and relative fitness (\u03bbi) through histograms.  This illustrates the range of adoption patterns observed across various AI models.  Part (b) presents scatter plots showing the pairwise correlations between these three parameters on log-scale axes. These plots reveal how the parameters interrelate; for instance, they show how models with high relative fitness may have varying immediacy and longevity values.", "section": "2 Framework for Analysis"}, {"figure_path": "https://arxiv.org/html/2502.15987/x3.png", "caption": "Figure 3: Density plots illustrating the cumulative number of fine-tuned models for relative fitness of (1\u2264\u03bbi\u2264101subscript\ud835\udf06\ud835\udc56101\\leq\\lambda_{i}\\leq 101 \u2264 italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2264 10) at the 2-month, 6-month, and 12-month marks, segmented by companies.", "description": "Figure 3 presents density plots illustrating the distribution of the cumulative number of fine-tuned models for open-weight models with a relative fitness (\u03bbi) between 1 and 10.  The distributions are shown separately for 2, 6, and 12 months after the model's release.  The plots are further segmented by company to visualize the differences in model adoption patterns across different organizations.  This allows for the observation of temporal changes in the frequency of fine-tuned models, revealing how various organizations' models evolve in their attractiveness over time. ", "section": "Organization-Specific analysis on model's importance relative to other models"}, {"figure_path": "https://arxiv.org/html/2502.15987/x4.png", "caption": "Figure 4: Monthly cumulative number of fine-tuned models following the release of the base model, with colors indicating the base models\u2019 creation years, illustrating trends in fine-tuning patterns over time.", "description": "Figure 4 presents a graph showing the cumulative number of fine-tuned models created each month after the release of various base models.  The x-axis represents time in months since the base model's release, and the y-axis represents the cumulative count of fine-tuned models.  Each line on the graph represents a different base model, with the color of the line indicating the year the corresponding base model was created. The figure visually demonstrates the varying adoption rates and overall popularity of different base models over time, highlighting the trends and patterns in the growth of fine-tuned models within the Hugging Face ecosystem.", "section": "2 Framework for Analysis"}, {"figure_path": "https://arxiv.org/html/2502.15987/x5.png", "caption": "Figure 5: Each subplot represents models, where the x-axis denotes the time, t(month), after release, and the y-axis represents the cumulative count (citsuperscriptsubscript\ud835\udc50\ud835\udc56\ud835\udc61c_{i}^{t}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT) on a logarithmic scale. Red dots indicate empirical data points, while blue curves correspond to the fitted function using the extracted parameters (\u03bbisubscript\ud835\udf06\ud835\udc56\\lambda_{i}italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, \u03bcisubscript\ud835\udf07\ud835\udc56\\mu_{i}italic_\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT).", "description": "Figure 5 visualizes the cumulative adoption trajectories of numerous AI models over time. Each subplot focuses on a single model, plotting the cumulative number of fine-tuned models (y-axis) against the time since the model's release in months (x-axis).  The y-axis uses a logarithmic scale to better represent the wide range of adoption levels.  Red dots represent the observed, empirical data points. The blue curve in each subplot is a fitted curve generated using a model with three parameters (\u03bb\u1d62, \u03bc\u1d62, \u03c3\u1d62), which were derived from fitting a model to the data. These parameters capture different aspects of the adoption curve's shape, such as growth rate, the time until peak adoption, and the decay rate of adoption.", "section": "Fitting Equation 1 on empirical data"}, {"figure_path": "https://arxiv.org/html/2502.15987/x6.png", "caption": "Figure 6: The cumulative number of fine-tuned models (ctsubscript\ud835\udc50\ud835\udc61c_{t}italic_c start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) over time (months) for Allen AI, Amazon, Apple, Beijing Academy of Artificial Intelligence(BAAI), CohereAI and DeepSeek.", "description": "This figure displays the cumulative number of fine-tuned models created over time (in months) for six different organizations: Allen AI, Amazon, Apple, Beijing Academy of Artificial Intelligence (BAAI), CohereAI, and DeepSeek.  Each organization's data is shown as a separate line graph. The y-axis represents the cumulative number of fine-tuned models, and the x-axis represents the time elapsed in months. This visualization helps illustrate the relative popularity and adoption rates of models from each organization within the Hugging Face ecosystem.", "section": "Organization-Specific analysis on model's importance relative to other models"}, {"figure_path": "https://arxiv.org/html/2502.15987/x7.png", "caption": "Figure 7: The cumulative number of fine-tuned models (ctsubscript\ud835\udc50\ud835\udc61c_{t}italic_c start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) over time (months) for Meta, Google, HuggingFace, IBM, Microsoft, and MistralAI.", "description": "This figure presents a comparison of the cumulative number of fine-tuned models over time (in months) for six prominent AI companies: Meta, Google, Hugging Face, IBM, Microsoft, and MistralAI.  Each company's data is displayed as a separate line graph, allowing for a visual comparison of the adoption rates and overall popularity of their respective base models within the HuggingFace platform. The graph provides insights into the temporal dynamics of model fine-tuning and the relative popularity of models released by these companies.", "section": "Organization-Specific analysis on model's importance relative to other models"}, {"figure_path": "https://arxiv.org/html/2502.15987/x8.png", "caption": "Figure 8: The cumulative number of fine-tuned models (ctsubscript\ud835\udc50\ud835\udc61c_{t}italic_c start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) over time (months) for Nvidia, OpenAI, Qwen, Salesforce, and StabilityAI.", "description": "This figure displays the cumulative number of fine-tuned models created from the base models of Nvidia, OpenAI, Qwen, Salesforce, and StabilityAI over a period of time (in months).  Each line represents a specific company and illustrates how the number of fine-tuned models derived from its base models increased over the months. This visualization provides a clear view of the adoption and usage trends for the open-source models released by these companies. The figure shows not only the growth in adoption but also possibly the duration of each company\u2019s model's popularity.", "section": "3 Organization-Specific analysis on model's importance relative to other models"}, {"figure_path": "https://arxiv.org/html/2502.15987/x9.png", "caption": "Figure 9: The line plot of the cumulative number of downloads over time (day) for individual models ordered based on the most cumulative downloads. The blue plot is the predictive trajectory using the citation model.", "description": "This figure visualizes the cumulative downloads of various open-weight AI models over time, displayed as individual line plots ordered by their total downloads. Each line represents a specific model, illustrating its download trajectory.  A key aspect of the visualization is the comparison between the actual download counts (represented by colored markers) and the predicted cumulative downloads generated by the citation model (the blue line). This comparison allows for an assessment of the model's predictive accuracy. The x-axis represents time in days, and the y-axis shows the cumulative number of downloads on a logarithmic scale.", "section": "E Analyzing the Cumulative Number of Downloads"}, {"figure_path": "https://arxiv.org/html/2502.15987/x10.png", "caption": "Figure 10: Predicting number of downloads of recently popular DeepSeek models. The black line plot predicts the cumulative number of downloads of DeepSeek models up to 75 days after its release.", "description": "Figure 10 presents the predicted cumulative download counts for various DeepSeek models over a 75-day period following their release.  Each colored line represents a different DeepSeek model variant, showing the actual download trajectory. The black line represents the model's prediction of the cumulative downloads for each variant up to 75 days post-release. This visualization demonstrates the model's ability to forecast the adoption trajectory of newly released open-source AI models based on early download data.  The graph displays the diverse growth patterns among different DeepSeek models.  Some models exhibit rapid initial adoption followed by slower growth, while others show more gradual, sustained increases in downloads.", "section": "E Analyzing the Cumulative Number of Downloads"}]