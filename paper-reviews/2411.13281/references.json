{"references": [{"fullname_first_author": "Wei-Lin Chiang", "paper_title": "Chatbot Arena: An open platform for evaluating LLMs by human preference", "publication_date": "2024-07-21", "reason": "This paper introduces the Chatbot Arena framework, which inspired the creation of VideoAutoArena, a key contribution of the current research."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-06", "reason": "This foundational paper on large language models (LLMs) provides essential context for understanding the capabilities and limitations of the models evaluated in VideoAutoArena."}, {"fullname_first_author": "Rohan Anil", "paper_title": "Gemini: A family of highly capable multimodal models", "publication_date": "2023-12-11", "reason": "The Gemini models are among the state-of-the-art models benchmarked in the study, and this paper offers vital background on these models and their capabilities."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The first-ever comprehensive evaluation benchmark of multi-modal LLMs in video analysis", "publication_date": "2024-05-21", "reason": "VideoMME is a major existing benchmark that is compared with the VideoAutoArena framework; hence, this paper provides crucial comparative context."}, {"fullname_first_author": "Yujie Lu", "paper_title": "WildVision: Evaluating vision-language models in the wild with human preferences", "publication_date": "2024-06-11", "reason": "This paper is another key existing benchmark used for comparison with the VideoAutoArena framework, highlighting the strengths and limitations of prior approaches."}]}