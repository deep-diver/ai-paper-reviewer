[{"figure_path": "2410.13276/tables/table_7_0.html", "caption": "Table 1: Comparing the perplexity of SeerAttention at post-training with MoA and MInference, using the Llama-3.1-8B-Instruct model on the PG19 dataset.", "description": "Table 1 compares the perplexity of SeerAttention at post-training with MoA and MInference, using the Llama-3.1-8B-Instruct model on the PG19 dataset across various sparsity levels and context lengths.", "section": "5.1 ACCURACY OF POST-TRAINING"}, {"figure_path": "2410.13276/tables/table_7_1.html", "caption": "Table 2: Comparing the accuracy of SeerAttention at post-training with MoA and MInference on LongBench.", "description": "Table 2 compares the accuracy of SeerAttention against MoA and MInference on the LongBench benchmark at post-training, showing SeerAttention's consistent outperformance under similar or higher sparsity ratios.", "section": "5.1 ACCURACY OF POST-TRAINING"}, {"figure_path": "2410.13276/tables/table_8_0.html", "caption": "Table 3: Perplexity of YaRN baseline, SeerAttention after YaRN and YaRN with SeerAttention.", "description": "Table 3 presents the perplexity scores of three different models: the YaRN baseline, SeerAttention applied after YaRN, and YaRN integrated with SeerAttention, across various sparsity levels on two datasets (PG19 and Proof-pile).", "section": "5.3 ACCURACY OF LONG-CONTEXT EXTENSION FINE-TUNING"}, {"figure_path": "2410.13276/tables/table_9_0.html", "caption": "Table 4: Time to First Token results (s).", "description": "Table 4 compares the time to first token (TTFT) in seconds across different models and sparsity levels, showing SeerAttention's latency advantage.", "section": "5.3 EFFICIENCY EVALUATION"}, {"figure_path": "2410.13276/tables/table_13_0.html", "caption": "Table 1: Comparing the perplexity of SeerAttention at post-training with MoA and MInference, using the Llama-3.1-8B-Instruct model on the PG19 dataset.", "description": "Table 1 compares the perplexity results of SeerAttention against MoA and MInference on the Llama-3.1-8B-Instruct model at post-training, varying sparsity levels and context lengths.", "section": "5.1 ACCURACY OF POST-TRAINING"}]