[{"figure_path": "https://arxiv.org/html/2411.15872/extracted/6026802/figures/brats_africa.jpg", "caption": "Figure 1: Cross sections of the four modalities obtained from a sample data-point from the provided dataset for the BraTS-Africa challenge along with the corresponding segmentation masks", "description": "Figure 1 presents a visual representation of four different MRI modalities (T1, T1Gd, T2, and FLAIR) obtained from a single patient's brain scan within the BraTS-Africa dataset.  Each modality offers a unique perspective on brain tissue properties.  The figure includes axial, coronal, and sagittal slices, allowing for a comprehensive 3D visualization of the brain tumor.  Crucially, the figure also overlays the corresponding segmentation masks, highlighting the areas identified as tumor by experts.  These masks delineate the exact boundaries of the tumor in each slice, serving as the ground truth for evaluating the accuracy of automated brain tumor segmentation algorithms.", "section": "Methods"}, {"figure_path": "https://arxiv.org/html/2411.15872/extracted/6026802/figures/ped_slice.png", "caption": "Figure 2: Different cross sections of the four modalities obtained from a sample data-point from the provided dataset for pediatrics challenge along with the corresponding segmentation masks", "description": "Figure 2 displays various cross-sections (axial, coronal, and sagittal views) of brain MRI scans from a pediatric patient.  Each modality (T1, T1ce, T2, and FLAIR) is shown, illustrating the different tissue contrasts revealed by each imaging sequence.  Overlaid on these images are corresponding segmentation masks which delineate different tumor regions of interest (ET: enhancing tumor, NETC: non-enhancing tumor core, CC: cystic component, ED: peritumoral edema). This figure visually demonstrates the complexity of pediatric brain tumor segmentation and the necessity of multi-modal image analysis for accurate results. ", "section": "2 Methods"}, {"figure_path": "https://arxiv.org/html/2411.15872/extracted/6026802/figures/mednext-fig.png", "caption": "Figure 3: (a) Architectural design of the MedNeXt. The network has 4 Encoder and Decoder layers each, with a bottleneck layer. MedNeXt blocks are present in Up and Downsampling layers as well. Deep Supervision is used at each decoder layer, with lower loss weights at lower resolutions. All residuals are additive while convolutions are padded to retain tensor sizes. For further details, we refer to [18]", "description": "The figure shows the architecture of the MedNeXt model, which is a U-Net-like network that uses MedNeXt blocks. These blocks combine the strengths of convolutional neural networks and transformers. The encoder downsamples the input, the bottleneck processes the features, and the decoder upsamples the output to the original resolution. Deep supervision is used to improve training stability and accuracy. Residual connections add the outputs of each layer to the input of the subsequent layer to prevent vanishing gradients.", "section": "2.2 MedNeXt"}]