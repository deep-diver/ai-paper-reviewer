[{"figure_path": "2410.18745/charts/charts_3_0.png", "caption": "Figure 1: Position frequency distribution exhibits a pronounced left-skewed pattern across training data of varying lengths. Figure 1a illustrates the natural data length distribution of SlimPajama-627B where oversized data is truncated into multiple 2K sequences. Figure 1b presents the case with a uniform length distribution and the position frequency decline quadratically. Figure 1c demonstrates that when all data are concatenated into a 2K sequence, the position frequency decreases linearly with increasing position indices. The X-axis represents data length (shown in orange) and position indices (shown in blue). The left Y-axis indicates the frequency of each position, while the right Y-axis represents the number of data for each length.", "description": "This chart visualizes the position frequency distribution in three scenarios: natural data distribution, uniform data distribution, and concatenated data distribution, all using the SlimPajama-627B dataset. Each scenario is represented as a sub-figure (a, b, c).  The x-axis in each sub-figure represents both data length (in orange) and position indices (in blue), while the left y-axis shows the frequency of each position and the right y-axis indicates the number of data points for each data length. The charts show that in the natural data distribution (a), the position frequency significantly decreases as the index increases, exhibiting a left-skewed pattern.  In contrast, the uniform data distribution (b) shows a quadratic decline, while the concatenated data distribution (c) exhibits a linear decline in frequency.", "section": "2 LEFT-SKEWED POSITION FREQUENCY DISTRIBUTION"}, {"figure_path": "2410.18745/charts/charts_4_0.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "This chart presents two subfigures, (a) and (b), showing the relationship between effective context length and different factors. Subfigure (a) plots the effective context length against the number of consumed tokens during training for two models: TinyLlama-1.3b-4k and TinyLlama-1.3b-2k. It demonstrates that the model trained with a longer context window (4k) achieves a greater effective context length with fewer consumed tokens. Subfigure (b) shows the relationship between effective length and the position frequency during training. It indicates that models achieve similar effective lengths when exposed to a similar frequency of position indices, regardless of the difference in maximum training length, suggesting that the frequency of exposure to different positions plays a critical role in determining the effective context length.", "section": "3 A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/charts/charts_5_0.png", "caption": "Figure 3: Position frequency distribution for models trained with different training lengths after consuming 1T tokens. With the same number of tokens, training length has little effect on small relative positions. For example, the relative position 0 appears 4K times in both a single 4K sequence and two 2K sequences with the same total token count of 4K in each case.", "description": "This histogram displays the position frequency distributions for two models trained with different sequence lengths (2K and 4K) after consuming 1 trillion tokens. The x-axis represents the relative position index, ranging from 0 to 4000, and the y-axis represents the position frequency in trillions.  The distribution is strongly left-skewed, showing that short relative positions are considerably more frequent than long ones. While the distributions for both 2K and 4K training lengths are similar for positions less than approximately 1000, the difference becomes more substantial at greater distances, indicating a less efficient training for longer positions in the model with a shorter training sequence length.", "section": "3 A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/charts/charts_6_0.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "This figure contains two sub-figures. Figure 2(a) shows the relationship between effective context length and consumed tokens for two different models trained with different context window sizes (2K and 4K).  The x-axis represents consumed tokens, and the y-axis represents the effective context length. Figure 2(b) shows the relationship between effective context length and position frequency. The x-axis represents effective length, and the y-axis represents the position frequency. Both sub-figures demonstrate that the effective context length of LLMs pretrained on SlimPajama is limited by the position frequency distribution, where models with longer context windows have higher position frequencies for longer distances. This indicates that training with a longer context window does not automatically result in an improved effective context length, and that the frequency of position indices during training plays an important role in the model's ability to capture distant information.", "section": "3 A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/charts/charts_6_1.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "This figure contains two sub-figures: (a) and (b). Figure (a) shows the relationship between the effective context length and consumed tokens for two models, TinyLlama-1.3b-4k and TinyLlama-1.3b-2k, trained with different context window sizes (4K and 2K, respectively). The x-axis represents consumed tokens, and the y-axis represents the effective context length. Figure (b) displays the relationship between the effective context length and position frequency for the same two models. The x-axis represents the effective context length, and the y-axis represents the position frequency f(i), which denotes how many times a specific position index i has been encountered during training. Both sub-figures illustrate that a larger training context window results in a greater effective context length when consuming the same number of tokens and that similar effective lengths can be achieved if models have been exposed to similar frequencies of position indices, regardless of the difference in maximum training length.", "section": "A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/charts/charts_10_0.png", "caption": "Figure 7: Ablation study on the local window W and shifted offset S where L is the training length.", "description": "The chart displays the ablation study results on the Needle-in-a-Haystack task (4 needles) for four different LLMs: TinyLlama-2K, Llama-2-4K, LWM-7B-32K, and Llama-3.1-128K. It shows the impact of varying the local window size (W) and shifted offset size (S) on model performance. The x-axis represents the local window size (W), while the y-axis shows the model performance in terms of accuracy.  The chart reveals that increasing local window size (W) improves performance, stabilizing beyond a certain value (32), across all models.  It further shows that the effect of varying the shifted offset size (S) on the performance of Llama3.1-128K with a local window size of 128. ", "section": "4 SHIFTED ROTARY POSITION EMBEDDING"}, {"figure_path": "2410.18745/charts/charts_10_1.png", "caption": "Figure 7: Ablation study on the local window W and shifted offset S where L is the training length.", "description": "This ablation study chart explores the impact of two hyperparameters in the STRING model: the local window size (W) and the shifted offset size (S). The x-axis represents different values for the shifted offset size (S), expressed as fractions of the training length (L).  The y-axis displays the performance, likely measured as accuracy or a similar metric. The chart presents four lines, each representing a different model with varying training lengths and context window sizes: TinyLlama-2K, Llama-2-4K, LWM-7B-32K, and Llama-3.1-128K.  The chart visualizes how changing the offset sizes impacts the model performance in each of the four models tested. The results reveal a performance improvement when W >32 and the trend slows down when S exceeds L/2.", "section": "4 SHIFTED ROTARY POSITION EMBEDDING"}, {"figure_path": "2410.18745/charts/charts_18_0.png", "caption": "Efficiency Test of STRING and the standard Flash Attention based on Llama3.1 8B. All experiments are run on a single NVIDIA 80G A100 GPU.", "description": "This chart presents the results of an efficiency test comparing STRING and standard Flash Attention using the Llama3.1 8B model.  The test was performed on a single NVIDIA 80G A100 GPU, varying the input length from 64K to 128K tokens. Two sub-charts are shown: (a) \"Inference time\", showing the average time per token (in seconds) for each method at different input lengths; and (b) \"GPU memory consumption\", showing the GPU memory usage (in gigabytes) for each method at different input lengths. The results indicate that STRING maintains comparable inference times and only slightly increases memory consumption compared to standard Flash Attention, suggesting minimal performance overhead.", "section": "A.3 EFFICIENCY TEST OF STRING"}]