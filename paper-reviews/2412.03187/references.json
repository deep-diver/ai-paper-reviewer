{"references": [{"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct Preference Optimization: Your language model is secretly a reward model", "publication_date": "2023", "reason": "This paper introduces Direct Preference Optimization (DPO), a core method used and extended in the current research."}, {"fullname_first_author": "Wenfeng Feng", "paper_title": "Mixture-of-LoRAs: An efficient multitask tuning method for large language models", "publication_date": "2024", "reason": "This paper proposes Mixture-of-LoRAs, a relevant model fusion technique compared against in the current work."}, {"fullname_first_author": "Fanqi Wan", "paper_title": "Knowledge fusion of large language models", "publication_date": "2024", "reason": "This paper introduces FuseLLM, a key explicit model fusion method compared against in the current work."}, {"fullname_first_author": "Albert Qiaochu Jiang", "paper_title": "Mistral 7B", "publication_date": "2023", "reason": "This paper introduces Mistral 7B, one of the important large language models used as a source model in the experiments."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024", "reason": "This paper introduces LLaMA 3, the target large language model used in the experiments."}]}