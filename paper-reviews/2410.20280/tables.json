[{"figure_path": "2410.20280/tables/table_5_0.html", "caption": "Table 1 Configuration Details of MarDini Models. We provide four models, differing primarily in the size of the planning module (3.1B vs. 1.3B parameters) and the attention mechanisms used in the generation module: spatio-temporal attention (S.-T. Attn.) vs. temporal attention (T. Attn).", "description": "This table details the configurations of four different MarDini models, varying in planning model size, generation model attention type, and the number of frames processed.", "section": "2.3 Architecture Design"}, {"figure_path": "2410.20280/tables/table_8_0.html", "caption": "Table 2 Effectiveness of MAR and DM design. The reported results are FVD on VIDIM-Bench. All experiments are evaluated at a resolution of [256 \u00d7 256] using DDIM scheduler with 25 steps.", "description": "Table 2 shows the effectiveness of using both masked autoregressive planning (MAR) and diffusion model (DM) for video interpolation, demonstrating that combining both components yields optimal results compared to using only one.", "section": "3.1 Ablation Studies and Analysis"}, {"figure_path": "2410.20280/tables/table_8_1.html", "caption": "Table 3 Efficiency of the MarDini's generations with and without the asymmetric design. Both latency and GPU memory is measured as the average time to generate a video using DDIM with 25 steps using a single A100 GPU, and with bf16 mixed precision.", "description": "Table 3 shows the efficiency of MarDini's video generation with and without the asymmetric design, comparing latency and GPU memory usage across different attention mechanisms and resolutions.", "section": "3.1 Ablation Studies and Analysis"}, {"figure_path": "2410.20280/tables/table_10_0.html", "caption": "Table 4 Performance of zero-shot video interpolation on VIDIM-Bench. The reported results are taken directly from VIDIM (Jain et al., 2024). AMT, RIFE, and FILM are single-inference methods, while LDMVFI, VIDIM, and our approach are based on diffusion models with multiple inference steps. MidF-SSIM and MidF-LPIPS represent the SSIM and LPIPS scores, respectively, for the middle frame. For MarDini-512, we downscale the generated videos to 256 resolution for a fair comparison.", "description": "Table 4 presents a comparison of MarDini's performance against several state-of-the-art methods on the VIDIM benchmark for zero-shot video interpolation, using multiple metrics such as FID, FVD, SSIM, and LPIPS.", "section": "3.2 Results on Video Interpolation"}, {"figure_path": "2410.20280/tables/table_11_0.html", "caption": "Table 4 Performance of zero-shot video interpolation on VIDIM-Bench. The reported results are taken directly from VIDIM (Jain et al., 2024). AMT, RIFE, and FILM are single-inference methods, while LDMVFI, VIDIM, and our approach are based on diffusion models with multiple inference steps. MidF-SSIM and MidF-LPIPS represent the SSIM and LPIPS scores, respectively, for the middle frame. For MarDini-512, we downscale the generated videos to 256 resolution for a fair comparison.", "description": "Table 4 presents a comparison of MarDini's performance against other zero-shot video interpolation methods on the VIDIM-Bench benchmark, using various metrics including FVD, FID, SSIM, and LPIPS.", "section": "3.2 Results on Video Interpolation"}]