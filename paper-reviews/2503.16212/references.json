{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This work is important as it introduces the chain-of-thought prompting method, a crucial technique for eliciting reasoning in large language models."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-01", "reason": "This paper is a foundational work that utilizes GSM8K, a key benchmark dataset for evaluating mathematical reasoning capabilities, and explores training verifiers to improve performance."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "publication_date": "2021-01-01", "reason": "This paper introduces the MATH dataset, which is a critical benchmark for assessing mathematical problem-solving abilities, particularly in higher-level mathematics."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-01", "reason": "This is a work describing DeepSeekMath, a math-specialized LLM that serves as one of the base models in the current work, demonstrating the advancements in mathematical reasoning within language models."}, {"fullname_first_author": "Longhui Yu", "paper_title": "Metamath: Bootstrap your own mathematical questions for large language models", "publication_date": "2024-01-01", "reason": "This paper presents MetaMath, an important data augmentation method to enhance mathematical reasoning of LLMs, and which is used as a comparison baseline in the current work."}]}