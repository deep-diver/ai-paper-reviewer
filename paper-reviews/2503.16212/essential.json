{"importance": "This paper introduces **MathFusion**, a novel method for improving mathematical reasoning in LLMs, addressing a critical need for more effective data augmentation techniques. It offers a new paradigm for enhancing LLMs' problem-solving capabilities, potentially impacting various fields relying on advanced AI reasoning. It also opens avenues for exploring relational learning in other complex domains.", "summary": "MathFusion: Instruction Fusion enhances LLM's math problem-solving!", "takeaways": ["MathFusion, a new framework using cross-problem instruction synthesis, significantly improves mathematical reasoning in LLMs.", "MathFusion's three fusion strategies (sequential, parallel, and conditional) each contribute to enhanced performance, with their combination yielding further improvements.", "MathFusion models demonstrate competitive performance and high data efficiency, outperforming existing methods with fewer synthetic instructions."], "tldr": "Large Language Models show promise in mathematical reasoning, but current data augmentation is limited to instance-level modifications, failing to capture relational structures. To address this, the paper introduces MathFusion. It draws inspiration from human learning, where math proficiency grows via interconnected concepts, enhancing reasoning through cross-problem instruction synthesis. The new framework uses 3 fusion strategies: sequential, parallel, and conditional fusion. \n\n The paper generates MathFusionQA, then fine-tunes models(DeepSeekMath-7B, Mistral-7B, Llama3-8B). MathFusion enhances mathematical reasoning while maintaining efficiency, boosting performance by 18.0 points in accuracy across benchmarks with only 45K additional instructions. MathFusion enables LLMs to capture underlying relational structures, improving complex, multi-step problem-solving. The models achieve better performance on diverse benchmarks.", "affiliation": "Renmin University of China", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.16212/podcast.wav"}