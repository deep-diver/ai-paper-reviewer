[{"figure_path": "2410.13852/charts/charts_8_0.png", "caption": "Figure 4: Task performance and efficiency improve as the policy learns from more past interactions. We present deployment results across three rounds for six concurrent systems, and three more rounds for the top system B-SUP, together with human-human references (HH) and a redeployment of the initial policy \u03c0\u03b8\u03bf (CONTROL). Left: interaction-level success rate (\u2191, higher is better). Center: interaction-level efficiency by # turns per interactions (\u2193). Right: micro-level performance by click accuracy (\u2191). Shades are 95% confidence intervals by bootstrapping with 10,000 resamples.", "description": "The chart displays how task performance and efficiency improve across multiple rounds of training as a language model learns from past interactions with humans.", "section": "6 RESULTS AND ANALYSIS"}, {"figure_path": "2410.13852/charts/charts_8_1.png", "caption": "Figure 5: Turn-level performance of B-SUP evaluated by post-hoc human annotations. Left: % turns where the policy's action a matches exactly the human listener's action a* (\u2191). Center: similarity between the policy's action and the human listener's action (\u2191). Even actions that receive negative feedback in deployment (NEG FB) are increasingly similar to human actions. Right: % turns that annotated to have received positive implicit feedback from human listeners (\u2191).", "description": "The chart in Figure 5 shows that the model's actions become increasingly similar to human actions over time, even when receiving negative feedback, and that the proportion of turns receiving positive feedback increases.", "section": "6 RESULTS AND ANALYSIS"}, {"figure_path": "2410.13852/charts/charts_9_0.png", "caption": "Figure 6: Confusion matrices of the binary (top row) and ternary (bottom row) feedback decoders over rounds. The feedback decoder yields precise positive signals, even in early rounds.", "description": "The chart displays the confusion matrices for binary and ternary feedback decoders across multiple rounds, showing the decoder's accuracy in identifying positive feedback signals.", "section": "4.1 DECODING IMPLICIT FEEDBACK THROUGH RETROSPECTION"}, {"figure_path": "2410.13852/charts/charts_10_0.png", "caption": "Figure 7: Language analysis of human instructions. All systems show a decrease in instruction complexity in the first three rounds, except for B-KTO, suggesting adaptation and improved efficiency on the speaker's side. Keyword-based analysis reveals that the number of reset/frustration signals drops, a reflection of the model learning and collaboration improving.", "description": "The chart displays the changes in vocabulary size, utterance length, and the frequency of \"reset\" and \"try again\" signals in human instructions across different rounds of interaction for various system variants in the Multiref experiment.", "section": "Language Analysis"}, {"figure_path": "2410.13852/charts/charts_21_0.png", "caption": "Figure 13: Cumulative number of human-bot interactions used to train the policy each round.", "description": "The chart displays the cumulative number of human-bot interactions used to train the language model's policy across six different system variants over six rounds of training.", "section": "6 RESULTS AND ANALYSIS"}, {"figure_path": "2410.13852/charts/charts_21_1.png", "caption": "Figure 14: Success rate of B-SUP with additional LoRA adapters in round 4 and 5.", "description": "The chart displays a comparison of the success rates of two different LoRA adapter configurations (original and enhanced) across six rounds of training.", "section": "D ADDITIONAL ENHANCED LORA LAUNCH"}]