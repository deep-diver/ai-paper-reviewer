{"references": [{"fullname_first_author": "Yuval Alaluf", "paper_title": "Cross-image attention for zero-shot appearance transfer", "publication_date": "2024-00-00", "reason": "This paper introduces a novel approach to zero-shot appearance transfer that leverages cross-image attention, which is relevant to the consistent image editing problem tackled in the main paper."}, {"fullname_first_author": "Mingdeng Cao", "paper_title": "MasaCtrl: Tuning-free mutual self-attention control for consistent image synthesis and editing", "publication_date": "2023-00-00", "reason": "This work presents a method for consistent image editing using self-attention mechanisms, providing a baseline approach and a comparison point for the main paper's technique."}, {"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "This paper focuses on training-free image editing, aligning with the approach in the main paper and providing a relevant comparison within the field of image manipulation."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat GANs on image synthesis", "publication_date": "2021-00-00", "reason": "This foundational paper demonstrates the superior performance of diffusion models over GANs for image synthesis, providing theoretical backing for the main paper which also utilizes diffusion models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This work introduces a latent diffusion model capable of generating high-resolution images, which is directly relevant to the main paper, as it utilizes diffusion models for image editing."}]}