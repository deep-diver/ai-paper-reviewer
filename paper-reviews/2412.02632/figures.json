[{"figure_path": "https://arxiv.org/html/2412.02632/x1.png", "caption": "(a) Reconstruction performance of GSQ with a latent dimension of 16 at 16\u00d7\\times\u00d7 spatial compression, compared to the state-of-the-art.", "description": "This figure shows a bar chart comparing the reconstruction performance (measured by FID score) of the proposed GSQ method with a latent dimension of 16 and 16x spatial compression against several state-of-the-art image reconstruction methods.  Lower FID indicates better reconstruction quality. GSQ demonstrates superior reconstruction quality compared to other methods.", "section": "4.1 Optimized Training for GSQ-VAE"}, {"figure_path": "https://arxiv.org/html/2412.02632/x2.png", "caption": "(b) Scaling behaviour of the latent dimension v.s. spatial compression factor in GSQ; d=16\ud835\udc5116d=16italic_d = 16 is fixed while groups G\ud835\udc3aGitalic_G increase to expand latent space.", "description": "This figure shows how the model scales with the latent dimension and spatial compression factor.  The latent dimension (d) is held constant at 16, while the number of groups (G), which control the latent space expansion, is varied.  The x-axis represents the latent dimension, while the y-axis shows the spatial compression factor. The plot illustrates the relationship between the latent dimension, the number of groups, and the spatial compression achieved by the model.", "section": "3.2 Simple Scaling with GSQ"}, {"figure_path": "https://arxiv.org/html/2412.02632/x3.png", "caption": "Figure 1: \nThe top figure shows GSQ-GAN\u2019s reconstruction performance compared to state-of-the-art methods, demonstrating superior results even without latent decomposition. Training with larger G\ud835\udc3aGitalic_G, which is more composed of groups, can further optimize the use of latent space, enhancing reconstruction quality. The bottom figure illustrates GSQ-GAN\u2019s efficient scaling behaviour, where expanded latent capacity effectively manages increased spatial compression, thus achieving higher fidelity reconstructions on highly spatial compressed latent. Notably, GSQ-GAN achieves these results with only 20 training epochs on ImageNet at 2562superscript2562256^{2}256 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT resolution, while methods, such as Luo et\u00a0al. (2024); Yu et\u00a0al. (2024b), require over 270 epochs.", "description": "Figure 1 demonstrates GSQ-GAN's superior image reconstruction capabilities compared to other state-of-the-art methods.  The top panel shows that GSQ-GAN achieves a lower reconstruction FID (Frechet Inception Distance) score, indicating better reconstruction quality, even without employing latent decomposition techniques. Increasing the number of groups (G) during training further improves performance by optimizing the use of latent space. The bottom panel illustrates GSQ-GAN's scalability. It shows that by increasing the latent capacity, GSQ-GAN maintains high-fidelity reconstruction even at high spatial compression ratios (16x downsampling in this case). This is achieved using significantly fewer training epochs (20) compared to existing methods (over 270 epochs).", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02632/x4.png", "caption": "Figure 2: Comparisons of quantizers for VAE-F8 training. VQ is initialized with uniform distribution; all models have the same backbone, latent dimension, and vocabulary size.", "description": "This figure compares the performance of different vector quantization (VQ) methods for training a variational autoencoder (VAE) on images with an 8x spatial compression factor.  The methods compared are VQ (Vector Quantization), RVQ (Residual Vector Quantization), FSQ (Finite Scalar Quantization), and the proposed GSQ (Grouped Spherical Quantization). All methods use the same VAE architecture (backbone), latent dimension, and codebook size, ensuring a fair comparison.  The graph shows the reconstruction error (rFID) over training steps, illustrating the relative efficiency and effectiveness of each quantization technique.  The key difference lies in how the latent vectors are quantized to discrete codebook indices, impacting the quality of the reconstructed images.", "section": "4.1 Optimized Training for GSQ-VAE"}, {"figure_path": "https://arxiv.org/html/2412.02632/x5.png", "caption": "Figure 3: GSQ-GAN ablations on wider and deeper networks w/ and w/o attention blocks. Models are trained on 2562superscript2562256^{2}256 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT resolution on ImageNet.", "description": "This figure displays the ablation study results of GSQ-GAN model trained on ImageNet with 256x256 resolution images. It shows the impact of increasing network width and depth, with and without attention blocks, on the model's reconstruction performance.  The results demonstrate that wider and deeper networks, especially those with attention blocks, lead to better reconstruction quality.  The x-axis likely represents a measure of network complexity (e.g., number of parameters), and the y-axis shows reconstruction error.", "section": "Scaling Behaviors of GSQ-GAN"}, {"figure_path": "https://arxiv.org/html/2412.02632/x6.png", "caption": "(a) Scaling of latent dimension and vocabulary size for GSQ at 8\u00d7\\times\u00d7 spatial compression.", "description": "This figure shows how the reconstruction quality of the GSQ model changes when varying the latent dimension and vocabulary size at 8x spatial compression.  The x-axis represents the latent dimension, while the y-axis shows the reconstruction error (rFID).  Multiple lines are plotted, each corresponding to different vocabulary sizes. The figure helps in understanding the impact of increasing latent dimension and vocabulary size on the model's performance during the compression process.  It helps to determine the optimal combination of latent dimension and vocabulary size for a given compression ratio.", "section": "4.3 Scaling Behaviors of GSQ-GAN"}, {"figure_path": "https://arxiv.org/html/2412.02632/extracted/6042220/figures/exp1_vae/learning_rate.png", "caption": "(b) Same scaling behaviour as the top figure with vocabulary size in logarithmic scale.", "description": "Figure 4b shows the relationship between reconstruction quality (rFID), latent dimension, and codebook size.  The x-axis represents the codebook size (vocabulary) on a logarithmic scale, and the y-axis represents rFID. Different lines represent different latent dimensions. The figure demonstrates that increasing codebook size generally improves reconstruction quality (lower rFID), and that the optimal codebook size may depend on the latent dimension.", "section": "4.3 Scaling Behaviors of GSQ-GAN"}, {"figure_path": "https://arxiv.org/html/2412.02632/x10.png", "caption": "Figure 4: The top figure illustrates the scaling of latent dimension and codebook size for GSQ at 8\u00d7\\times\u00d7 spatial compression, where a smaller latent dimension improves reconstruction, suggesting the latent space is not saturated for F8 downsampling. Optimising latent space size further enhances performance. The bottom figure shows the same trend with vocabulary size in logarithmic scale, indicating effective scaling as vocabulary size increases. All models are trained with G=1\ud835\udc3a1G=1italic_G = 1 and no latent decomposition, making this equivalent to VQ-based methods. All models are trained on ImageNet at 2562superscript2562256^{2}256 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT resolution.", "description": "This figure analyzes the impact of latent dimension and codebook size on the reconstruction quality of the GSQ image tokenizer at 8x spatial compression.  The top panel shows that smaller latent dimensions lead to better reconstruction, indicating the latent space is not fully utilized at this compression level. Increasing the codebook size further improves performance. The bottom panel presents the same data but with the vocabulary size shown on a logarithmic scale, highlighting the effectiveness of scaling the codebook size.  Importantly, all models in this experiment were trained using G=1, meaning there was no latent space decomposition, making them directly comparable to traditional VQ-based methods. The training dataset used was ImageNet with images of 256x256 resolution.", "section": "Scaling Behaviors of GSQ-GAN"}, {"figure_path": "https://arxiv.org/html/2412.02632/x11.png", "caption": "Figure 5: Latent dimension scaling for GSQ-GAN-F16 training, the latent space is saturated for F16 spatial compression; we expect to enhance reconstruction performance by increasing the latent dimension to increase the latent capacity. Only GSQ with latent decomposition can scale to a higher latent dimension.", "description": "Figure 5 demonstrates the effect of increasing latent dimensionality on the reconstruction performance of GSQ-GAN when the spatial compression ratio is 16 (F16).  The figure shows that increasing the latent dimension initially improves reconstruction quality, but beyond a certain point (D=16 in this case), adding more dimensions does not provide further gains. This saturation effect highlights the limitations of standard VQ techniques in high-dimensional latent spaces.  However, GSQ with latent decomposition (using multiple groups, G >1) successfully scales to much higher latent dimensions (32 and 64) and continues to show significant improvements in reconstruction performance. This highlights the effectiveness of GSQ in managing the complexity of high-dimensional spaces, resulting in improved image generation quality.", "section": "4.3.3 Latent Space and Downsample Factor, and Better Scaling with GSQ"}]