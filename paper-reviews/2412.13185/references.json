{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational concept of diffusion models, a core technique leveraged extensively in the current research on video generation."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial element of the current approach, enabling effective integration of text and image conditions for human motion generation."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-04-07", "reason": "DINOv2 provides a powerful encoder for processing scene images, which is vital to the current method's ability to condition human motion on scene context."}, {"fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "publication_date": "2022-01-01", "reason": "This paper is highly relevant due to the focus on human motion generation, using text as a conditioning factor, which is closely related to the current research objective."}, {"fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "publication_date": "2023-01-01", "reason": "This paper introduces a diffusion model specifically for human motion generation, providing a direct methodological comparison and advancement for the presented work."}]}