{"references": [{" publication_date": "2022", "fullname_first_author": "N. Carlini", "paper_title": "Extracting training data from large language models", "reason": "This paper is highly relevant because it introduces the concept of discoverable extraction, a key method for measuring memorization in LLMs that the current paper builds upon and improves.  The authors' critique of the limitations of single-sequence greedy sampling in discoverable extraction directly motivates the current paper's introduction of a probabilistic relaxation to address these shortcomings. The paper's findings on the extraction of training data are also directly compared to in the experimental section.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "N. Carlini", "paper_title": "Quantifying memorization across neural language models", "reason": "This paper is important because it provides a comprehensive overview of existing memorization measurement techniques in LLMs and directly informs the current research. The current research explicitly builds upon and improves existing methods by proposing a new probabilistic approach to address the limitations highlighted in this paper, particularly the limitations of relying solely on single-sequence greedy sampling. The work in this paper directly influences the experimental setup in the current study.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "N. Carlini", "paper_title": "The secret sharer: Evaluating and testing unintended memorization in neural networks", "reason": "This paper is crucial because it introduces the concept of canary memorization, which is a related technique for measuring memorization in neural networks. The current paper draws a connection between its proposed probabilistic measure and the concept of rank perplexity from this paper, highlighting the relationship between the proposed method and existing techniques for memorization assessment. Furthermore, its discussion on limitations helps in refining the current approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "S. Biderman", "paper_title": "Pythia: A suite for analyzing large language models across training and scaling", "reason": "This work is highly relevant because it provides a comprehensive benchmark for LLM memorization and evaluation. The current paper builds upon the existing knowledge and techniques described in this paper, using Pythia models in its empirical experiments for validation. Its contributions on memorization measurement methods are critical to the background and experimental design of the current work.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "S. Biderman", "paper_title": "Emergent and predictable memorization in large language models", "reason": "This paper contributes significantly to the understanding of memorization in LLMs, providing detailed analysis of various aspects of memorization and its implications.  The current paper directly builds upon and improves this foundational research on memorization by introducing a new probabilistic method that addresses the limitations highlighted in this paper, such as the reliance on single-sequence sampling. The insights from this paper heavily impact the current study\u2019s methodology and interpretation.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "V. Feldman", "paper_title": "What neural networks memorize and why: Discovering the long tail via influence estimation", "reason": "This paper provides a theoretical framework for understanding memorization in neural networks, which is crucial for the current paper's development and justification of a probabilistic approach to measuring memorization. The concepts presented here are used to support the theoretical foundation of the current work, showing why a probabilistic method is needed to overcome the limitations of previous techniques.  The paper also contributes to the conceptual understanding of memorization.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "G. Brown", "paper_title": "When is memorization of irrelevant training data necessary for high-accuracy learning?", "reason": "This paper is highly relevant because it delves into the theoretical underpinnings of memorization in machine learning, which is directly related to the current research's goal of improving the measurement of memorization in LLMs.  The theoretical framework helps to understand why and when memorization occurs, which informs the design of the current paper's improved method for measuring memorization. It directly influences the theoretical discussion of memorization within the paper.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "N. Carlini", "paper_title": "Extracting training data from large language models", "reason": "This work is important as it analyzes the risks of extracting training data from large language models, which is directly related to the current study's focus on measuring memorization and its associated risks. The current work builds on the findings and methods proposed in this paper to develop an improved approach that addresses the limitations of existing methods.  The experimental setup in this paper also heavily influences the current study.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "A. M. Kassem", "paper_title": "Alpaca against vicuna: Using LLMs to uncover memorization of LLMs", "reason": "This paper is highly relevant because it explores the use of LLMs to uncover memorization in other LLMs, which is a related and important topic to the current paper's focus on measuring memorization. The techniques and insights from this paper provide a useful comparative analysis and context for the current paper's novel methodology. This paper's discussion on the limitations of existing methods motivates the improvement proposed in the current research.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "S. Schwarzschild", "paper_title": "Rethinking llm memorization through the lens of adversarial compression", "reason": "This paper is important because it addresses the issue of memorization in LLMs from a different perspective \u2013 that of adversarial compression. The current paper acknowledges the need for different definitions based on different threat models and the unique limitations that each type of definition comes with. This paper is important for its consideration of alternative approaches and broader context within the field of LLM memorization research.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "S. Biderman", "paper_title": "Elephants never forget: Memorization and learning of tabular data in large language models", "reason": "This paper is highly relevant because it investigates the specific issue of memorization of tabular data within LLMs, which is a sub-problem within the broader context of LLM memorization addressed in the current research. The specific focus of the paper aligns with the current work's exploration of the risks and consequences of LLM memorization, offering valuable context within the larger research area.  The paper\u2019s methodology may be applicable to future iterations of the work presented here.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "W. Shi", "paper_title": "Detecting pretraining data from large language models", "reason": "This paper is relevant as it addresses a related challenge in the field: detecting pretraining data leakage from LLMs. The approaches and techniques used in this paper can help to contextualize the current work's approach to measuring memorization.  The discussion of limitations and potential future work directions offer insights for extending the work in the current paper.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "L. Gao", "paper_title": "The pile: An 800gb dataset of diverse text for language modeling", "reason": "This paper is highly relevant because it introduces the Pile dataset, a large dataset used to train many LLMs, including the Pythia model used in the current paper's experiments. Understanding the dataset is critical for interpreting the results of the current study.  The characteristics of this dataset are essential to understanding the contexts and limitations of the current findings.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "A. Chowdhery", "paper_title": "Palm: Scaling language modeling with pathways", "reason": "This work is important because it showcases the scaling of LLMs and discusses the potential issues related to memorization that arise with larger models. The current paper directly addresses the issue of memorization in large language models, focusing on the improvements in the measurement of memorization that are necessary for larger models.  This paper provides context for the current research\u2019s findings on the relationship between model size and memorization.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "R. Anil", "paper_title": "Palm 2 technical report", "reason": "This paper describes the Palm 2 model, a large language model that is relevant to the current research because it presents a significant benchmark in the field.  The current paper uses the Pythia model, which shares similarities with Palm 2, allowing for direct comparison and validation of findings in the current study.  The context provided by the architecture and training of Palm 2 informs the current research\u2019s methodology and interpretations.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "S. Kudugunta", "paper_title": "Madlad-400: A multilingual and document-level large audited dataset", "reason": "This work provides information on a large multilingual and document-level dataset.  While not directly used in the current study, it provides an important contextual background for the evaluation of memorization across different languages and the scale at which memorization occurs across various LLMs. The discussion of multilingual models and their potential for data leakage and memorization is relevant to the context and broader implications of the current study.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "S. Bordt", "paper_title": "Elephants never forget: Memorization and learning of tabular data in large language models", "reason": "This paper provides another recent benchmark for the memorization capabilities of large language models. The current paper builds upon existing work on measuring memorization and leverages the findings from other studies to develop an improved methodology for measuring memorization in large language models. The specific focus on tabular data also provides a specific and detailed analysis that helps inform the current study.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "M. Duan", "paper_title": "Do membership inference attacks work on large language models?", "reason": "This work addresses the related problem of membership inference attacks on LLMs and provides an important comparison to the current research\u2019s focus on memorization. The insights and methodology presented in this paper help to contextualize and refine the current paper's approach to measuring and analyzing memorization in LLMs, offering complementary perspectives.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "J. Huang", "paper_title": "Demystifying verbatim memorization in large language models", "reason": "This recent paper is highly relevant because it directly addresses the issue of verbatim memorization in large language models. The current paper builds upon the work done in this paper, proposing a new definition and methodology for measuring memorization that directly addresses the limitations of previous work, offering a more nuanced and realistic way of measuring memorization.", "section_number": 5}]}