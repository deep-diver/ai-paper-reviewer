[{"figure_path": "https://arxiv.org/html/2503.18878/extracted/6306108/img/word_distrib.png", "caption": "Figure 1: Illustration of steering (amplifying) reasoning-specific features during LLM generation. Default generation (blue) shows standard model reasoning, whereas steering (green) induces increased reasoning, self-correction, and graceful transition to the final answer\u2014evidence that the identified features are responsible for the reasoning concept.", "description": "This figure shows the impact of manipulating reasoning-related features within a large language model (LLM) during text generation. The control group (blue) demonstrates the model's natural reasoning process, which may be less detailed or lack self-correction.  In contrast, the experimental group (green) shows the effect of 'steering' or amplifying the identified reasoning features.  Steering produces a more thorough reasoning process with evidence of self-correction and a more natural progression towards the final answer.  This supports the claim that the identified features are directly responsible for the model's reasoning capabilities.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2503.18878/x1.png", "caption": "Figure 2: The distribution of top 30 words with the greatest change in frequency between reasoning traces of DeepSeek-R1 and ground-truth solutions of math problems. Orange dots show the normalized absolute frequency taken from Google Books Ngram Corpus. We remove the words with absolute frequency above the pre-defined threshold (orange line), and keep those with the high relative frequency indicating reasoning.", "description": "This figure shows the 30 words that most significantly changed in frequency between the reasoning traces generated by the DeepSeek-R1 model and the ground truth solutions for mathematical problems.  The x-axis represents the difference in frequency between the model's reasoning and the ground truth. Words to the right have a higher frequency in the model's reasoning, suggesting their importance in the model's reasoning process. The y-axis shows the words ranked by this frequency difference.  The size of the orange dots indicates the normalized absolute frequency of each word in the Google Books Ngram Corpus. Words with a frequency above a certain threshold (represented by the orange line) were excluded, focusing on words with high relative frequency in the model's reasoning output that are less common in general text.", "section": "3.1 Designing Reasoning Space"}, {"figure_path": "https://arxiv.org/html/2503.18878/x2.png", "caption": "(a) Top 10101010 negative and positive output logits of the feature", "description": "This figure shows the impact of a specific reasoning feature (identified using Sparse Autoencoders) on the model's output logits.  Panel (a) presents the top 10 negative and top 10 positive logits most strongly influenced by this feature. This highlights the feature's effect on the model's prediction probabilities for various tokens. Panel (b) displays the 20 contexts (inputs) where this feature exhibits the highest activation values. These contexts illustrate the types of situations or linguistic patterns that trigger the activation of this reasoning feature. The figure thus provides a detailed analysis of a single reasoning feature's effects on model predictions and the conditions under which it becomes most active.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x3.png", "caption": "(b) Top 20202020 max activating examples", "description": "This figure visualizes the top 20 examples where a specific reasoning feature in a Sparse Autoencoder (SAE) model shows the highest activation.  It demonstrates the contexts and phrases within the model's activations that strongly correlate with the feature's identification of reasoning processes like reflection, uncertainty, and exploration. Each example shows the input text where the feature is most active.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x4.png", "caption": "Figure 3: Empirical analysis results for the feature 17456174561745617456 in our SAE: (a) Distribution of the bottom and top logits influenced by one of the \u201creasoning\u201d features. (b) Contexts where the \u201creasoning\u201d feature activates the most. Increased color intensity represent higher activation values, with token highlighted in bold having the highest activation.", "description": "Figure 3 presents a detailed analysis of a specific reasoning feature (feature 17456) identified using Sparse Autoencoders (SAEs).  Panel (a) displays the distribution of the lowest and highest logit values associated with this feature. Logits are scores assigned to tokens during language model prediction; higher values represent increased probability. This distribution shows which tokens are most affected by this feature.  Panel (b) showcases various contexts in which feature 17456 demonstrates the highest activation level,  providing illustrative examples of how this feature influences the model's reasoning process. The color intensity in both panels correlates directly with the magnitude of activation values, enhancing the visualization of feature influence. Tokens appearing in bold represent the most significant activations within each context.", "section": "4 Evaluation"}, {"figure_path": "https://arxiv.org/html/2503.18878/x5.png", "caption": "(a) Top 10101010 negative and positive output logits of the feature", "description": "This figure presents a detailed analysis of a specific feature (feature number 17456) within a Sparse Autoencoder (SAE).  Panel (a) shows the top 10 most negative and top 10 most positive output logits influenced by this feature. Logits represent the model's confidence in predicting specific tokens, with higher values indicating stronger confidence.  This helps to understand the feature's effect on the model's output. Panel (b) displays the 20 contexts (input text snippets) where the feature exhibited the highest activation levels.  These contexts provide insights into the specific situations that activate this particular feature, thus clarifying its function and semantics within the model's reasoning process.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x6.png", "caption": "(b) Top 20202020 max activating examples", "description": "This figure visualizes the contexts where a specific reasoning feature in a Sparse Autoencoder (SAE) model exhibits the highest activation.  The figure shows 20 examples of text segments from the model's activations where this feature is most strongly activated, providing insights into the types of reasoning tasks or linguistic patterns that trigger this feature.  This helps in understanding the feature's role in the model's overall reasoning process.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x7.png", "caption": "Figure 4: Empirical analysis results for the feature 15136151361513615136 in our SAE: (a) Distribution of the bottom and top logits influenced by one of the \u201creasoning\u201d features. (b) Contexts where the \u201creasoning\u201d feature activates the most. Increased color intensity represent higher activation values, with token highlighted in bold having the highest activation.", "description": "Figure 4 presents a detailed analysis of a specific reasoning feature (feature 15136) identified using Sparse Autoencoders (SAEs) within a Large Language Model (LLM).  Part (a) shows the distribution of the lowest and highest logit values (representing the model's confidence in predictions) influenced by this feature. Part (b) illustrates the contexts within the LLM's activations where this reasoning feature exhibits its strongest activation.  The visualization uses color intensity to represent the magnitude of feature activation, highlighting tokens with the highest activation in bold.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x8.png", "caption": "(a) Top 10101010 negative and positive output logits of the feature", "description": "This figure shows the top 10 negative and positive output logits for a specific feature (identified using Sparse Autoencoders) in a large language model (LLM).  The figure helps to illustrate the impact of this feature on the LLM's output. Negative logits represent tokens that are less likely to be generated when the feature is active, while positive logits show tokens whose generation probability increases when the feature is active. This allows for analysis of how the activation of a single learned feature influences the LLM's word choices.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x9.png", "caption": "(b) Top 20202020 max activating examples", "description": "This figure shows the top 20 examples where a specific reasoning feature in the Sparse Autoencoder (SAE) model exhibits its highest activation.  It complements Figure 3a, which shows the distribution of activations. The contexts illustrated here provide insights into what kinds of situations or linguistic patterns trigger the activation of this particular reasoning feature, highlighting its role in the model's reasoning process. Each example includes the model's generated text showing the use of words and phrases related to reasoning and thought processes.", "section": "4.2 Empirical Analysis"}, {"figure_path": "https://arxiv.org/html/2503.18878/x10.png", "caption": "Figure 5: Empirical analysis results for the feature 17456174561745617456 in our SAE: (a) Distribution of the bottom and top logits influenced by one of the \u201creasoning\u201d features. (b) Contexts where the \u201creasoning\u201d feature activates the most. Increased color intensity represent higher activation values, with token highlighted in bold having the highest activation.", "description": "Figure 5 presents a detailed empirical analysis of a specific reasoning feature (feature ID: 17456) identified using Sparse Autoencoders (SAEs).  Part (a) shows the distribution of low-activation (negative logits) and high-activation (positive logits) tokens influenced by this feature. This visualization helps understand the feature's impact on the model's output. Part (b) displays various contexts (text examples) where this feature exhibits the strongest activation, providing insights into the situations that trigger the feature. The use of color intensity further enhances the visualization by representing activation strength, with the boldest tokens carrying the highest activation levels. This detailed analysis provides evidence of how the identified feature contributes to the model's reasoning capabilities.", "section": "4 Evaluation"}]