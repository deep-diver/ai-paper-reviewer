{"importance": "This paper introduces a real-time portrait video generation framework called ChatAnyone, enabling natural & expressive upper-body movements and facial expressions. It is **significant** for creating immersive digital interactions, and also sets the stage for future work in virtual avatars and human-computer interfaces.", "summary": "ChatAnyone: Stylized real-time portrait video generation with hierarchical motion diffusion model.", "takeaways": ["Introduces a hierarchical motion diffusion model for generating synchronized face and body control signals.", "Presents a hybrid control fusion generative model for high-quality portrait video with detailed hand gestures.", "Achieves real-time upper-body portrait video generation at 30fps on a 4090 GPU."], "tldr": "Real-time interactive video-chat portraits have gained traction. Existing methods primarily focus on generating head movements, often struggling with synchronized body motions and fine-grained control over facial expressions. To address these issues, this paper presents a framework for stylized real-time portrait video generation, enabling flexible video chat that extends to upper-body interactions.\n\nThe approach involves efficient hierarchical motion diffusion models that account for both explicit and implicit motion representations based on audio inputs, generating diverse facial expressions and synchronized head and body movements. The system supports efficient and continuous generation of upper-body portrait video, achieving 30fps on a 4090 GPU, which supports interactive video-chat in real-time.", "affiliation": "Alibaba Group", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.21144/podcast.wav"}