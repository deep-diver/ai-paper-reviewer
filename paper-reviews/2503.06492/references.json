{"references": [{"fullname_first_author": "Pravesh Agrawal", "paper_title": "Pixtral 12b", "publication_date": "2024-10-07", "reason": "This paper introduces one of the LVLMs that is evaluated using the VisualSimpleQA benchmark."}, {"fullname_first_author": "Anthropic", "paper_title": "Claude 3.5 sonnet model card addendum", "publication_date": "2024-00-00", "reason": "This paper introduces one of the closed-source LVLMs that is evaluated using the VisualSimpleQA benchmark."}, {"fullname_first_author": "Lin Chen", "paper_title": "Are we on the right way for evaluating large vision-language models?", "publication_date": "2024-03-00", "reason": "This paper introduces the MMBench benchmark and highlights concerns for evaluating LVLMs."}, {"fullname_first_author": "Zhe Chen", "paper_title": "Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling", "publication_date": "2024-12-05", "reason": "This paper introduces the InternVL2.5-8B LVLM that is evaluated using the VisualSimpleQA benchmark."}, {"fullname_first_author": "Common Crawl Foundation", "paper_title": "Common crawl", "publication_date": "2024-00-00", "reason": "This reference is among the most important because it describes the Common Crawl foundation, a source that helps to create LLMs."}]}