{"references": [{" publication_date": "2017", "fullname_first_author": "Aaron Van Den Oord", "paper_title": "Neural discrete representation learning", "reason": "This paper introduces the concept of vector quantization (VQ) for visual data, a crucial component in many discrete visual tokenization methods, including the one proposed in the LARP paper.  The technique of VQ is fundamental to representing continuous visual data in a discrete form suitable for autoregressive modeling and is highly influential in shaping the field.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This seminal work introduced the Transformer architecture, which forms the basis of many modern sequence-to-sequence models, including the one used in the LARP tokenizer.  The Transformer's ability to process long sequences efficiently and its effectiveness in capturing long-range dependencies made it a cornerstone of the LARP design.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This paper introduced the Vision Transformer (ViT), a revolutionary approach that adapts the Transformer architecture to image processing.  The LARP paper directly builds upon the ViT framework, using its spatialtemporal patchification and transformer encoder for effective video encoding and holistic tokenization.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Nicolas Carion", "paper_title": "End-to-end object detection with transformers", "reason": "This paper introduced the concept of using learned queries in a transformer architecture for object detection, a core technique in the LARP tokenizer design.  This method provides a flexible way of gathering global information from videos, enabling the holistic tokenization scheme used by LARP.", "section_number": 3}, {" publication_date": "2017", "fullname_first_author": "Samy Bengio", "paper_title": "Scheduled sampling for sequence prediction with recurrent neural networks", "reason": "This paper introduced the scheduled sampling technique, which is vital for addressing the exposure bias problem in autoregressive models.  Exposure bias occurs when the model is trained on ground-truth data but needs to rely on its own predictions during inference.  The scheduled sampling technique implemented by LARP helps to mitigate this problem during training.", "section_number": 3}, {" publication_date": "2014", "fullname_first_author": "Ian Goodfellow", "paper_title": "Generative adversarial nets", "reason": "Generative Adversarial Networks (GANs) are a powerful class of generative models, often used as a component in visual generation methods.  The LARP paper leverages a GAN loss during training, and the cited paper provides the foundational theory for training GANs.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Richard Zhang", "paper_title": "The unreasonable effectiveness of deep features as a perceptual metric", "reason": "This paper proposes the Learned Perceptual Image Patch Similarity (LPIPS) metric for assessing perceptual image similarity, which is used as part of the loss function during LARP training.  The LPIPS metric is a valuable component in ensuring the quality of the visual output.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Thomas Unterthiner", "paper_title": "Towards accurate generative models of video: A new metric & challenges", "reason": "This paper introduced the Fr\u00e9chet Video Distance (FVD) metric, which serves as the main evaluation metric for video quality in the LARP experiments.  FVD is a critical measure of video generation fidelity.", "section_number": 3}, {" publication_date": "2012", "fullname_first_author": "K Soomro", "paper_title": "UCF101: A dataset of 101 human actions classes from videos in the wild", "reason": "This paper introduces the UCF-101 dataset, a widely used benchmark for evaluating action recognition and video generation methods.  LARP uses this dataset to assess the performance of its model in a class-conditional video generation task.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper establishes the foundation for autoregressive language models, whose success inspired the application of autoregressive models to visual generation tasks. The work of LARP builds on the general principle of sequence-to-sequence modeling, which is critical to the methodology employed in this work.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Ali Razavi", "paper_title": "Generating diverse high-fidelity images with vq-vae-2", "reason": "This paper introduces the VQ-VAE-2 architecture, a significant advancement in vector-quantized variational autoencoders (VQVAE) improving the quality of image generation.  Although using images instead of videos, this paper's architecture significantly influenced many of the ideas behind LARP's use of VQ.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "reason": "This work is highly influential for its introduction of VQGAN, a powerful architecture demonstrating the effectiveness of combining GAN training with VQ for high-quality image generation. While not directly a video model, VQGAN strongly influenced the design of LARP's use of GANs and VQ in video tokenization.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper introduced denoising diffusion probabilistic models (DDPM), which are foundational to many current diffusion-based generative models. The LARP paper is not diffusion-based but this paper's influence on image generation and the overall field of generative models is highly significant.  The paper's influence can be seen in the general approach of generative modeling in the visual domain.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Tero Karras", "paper_title": "Analyzing and improving the image quality of stylegan", "reason": "StyleGAN is a highly impactful generative model that greatly improved the quality of generated images.  This paper's contribution to generative modeling is considerable, influencing the overall field of visual generative models, and also impacting the work of LARP by setting a high bar in visual generation.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "reason": "This paper presents the Llama model, one of the most efficient and versatile large language models (LLMs) available.  It's significant because the success of LLMs inspired the LARP team's efforts to adapt autoregressive models to visual generation tasks. The autoregressive modeling methods inspired by LLMs are crucial to the LARP approach.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "This paper expands on the original Llama model, adding to its capabilities and establishing the Llama 2 model.  As with the original Llama paper, the success of LLMs serves as the inspiration for this work, motivating the adoption of autoregressive methods to visual generation.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "reason": "This paper is significant because it demonstrates the state-of-the-art capabilities of large language models (LLMs).  The development of highly performant LLMs such as Qwen demonstrates a capacity for large-scale autoregressive generation, which is crucial to the methodology in this work.  The success of LLMs provides a clear motivating example for the work presented here.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Jiahui Zhang", "paper_title": "Regularized vector quantization for tokenized image synthesis", "reason": "This paper improves the quality of tokenized image synthesis by introducing regularization into the vector quantization (VQ) process. The LARP approach uses stochastic vector quantization, and this paper represents a significant step forward in the field of VQ for image synthesis, and hence is relevant to the work in this paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Jack W Rae", "paper_title": "Scaling language models: Methods, analysis & insights from training gopher", "reason": "This paper provides crucial insights into scaling laws for large language models. This information is highly relevant to the development of the LARP model, especially in terms of the architecture design choices for a successful model.", "section_number": 1}, {" publication_date": "2015", "fullname_first_author": "Samy Bengio", "paper_title": "Scheduled sampling for sequence prediction with recurrent neural networks", "reason": "This paper introduced the scheduled sampling technique, crucial for mitigating exposure bias in training autoregressive models.  Exposure bias occurs when the model is trained on ground-truth data during training but needs to rely on its own predictions during inference. LARP uses this technique to improve the training of its autoregressive prior model.", "section_number": 3}]}