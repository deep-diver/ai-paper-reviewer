[{"figure_path": "2410.22325/figures/figures_1_0.png", "caption": "Figure 1: Overview. We introduce a robotic representation evaluation metric termed manipulation centricity, which exhibits a strong correlation with downstream policy performance. Accordingly, we design a new pre-training method, MCR, to learn manipulation-centric representation from large-scale robotic datasets. Comprehensive experiments on both simulations and real robot validate the superiority of our proposed representation.", "description": "The figure shows an overview of the proposed Manipulation Centric Representation (MCR) method, highlighting its components and workflow from pre-training to real-world robot control.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.22325/figures/figures_3_0.png", "caption": "Figure 3: Task visualization. We consider 20 challenging and diverse manipulation tasks spanning 4 domains.", "description": "Figure 3 visualizes 20 diverse robotic manipulation tasks across four simulation environments, showcasing variations in complexity and end-effectors.", "section": "2 EXPERIMENTAL SETUP: EVALUATING ROBOTIC REPRESENTATIONS"}, {"figure_path": "2410.22325/figures/figures_4_0.png", "caption": "Figure 1: Overview. We introduce a robotic representation evaluation metric termed manipulation centricity, which exhibits a strong correlation with downstream policy performance. Accordingly, we design a new pre-training method, MCR, to learn manipulation-centric representation from large-scale robotic datasets. Comprehensive experiments on both simulations and real robot validate the superiority of our proposed representation.", "description": "The figure provides a visual overview of the proposed manipulation-centric representation (MCR) method, highlighting its key components and the workflow from data collection to downstream task performance evaluation.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.22325/figures/figures_6_0.png", "caption": "Figure 5: Illustration of objective \nLdyn.", "description": "The figure illustrates the dynamics alignment objective (Ldyn) in the MCR model, showing how the encoder and projector are used to align image features with robot state-action dynamics.", "section": "4.2 TRAINING MCR"}, {"figure_path": "2410.22325/figures/figures_8_0.png", "caption": "Figure 7: Real robot setup. We design 3 real-world robot tasks with different manipulation skills and objects.", "description": "The figure shows the experimental setup for three real-world robotic manipulation tasks, including the robot arm, gripper, camera, and various objects used in the experiments.", "section": "5.2 REAL ROBOT RESULTS"}, {"figure_path": "2410.22325/figures/figures_8_1.png", "caption": "Figure 1: Overview. We introduce a robotic representation evaluation metric termed manipulation centricity, which exhibits a strong correlation with downstream policy performance. Accordingly, we design a new pre-training method, MCR, to learn manipulation-centric representation from large-scale robotic datasets. Comprehensive experiments on both simulations and real robot validate the superiority of our proposed representation.", "description": "The figure provides an overview of the proposed Manipulation Centric Representation (MCR) method, showing the pipeline from data collection and pre-training to downstream robotic task evaluation.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.22325/figures/figures_10_0.png", "caption": "Figure 11: t-SNE visualization. We do t-SNE visualization on 10 simulation tasks from MetaWorld and 3 real robot tasks. Each dot represents an image frame and each color indicates a task. The results demonstrate that (1) our representation has the best clustering ability and (2) robot data is helpful to robotic representation compared to simulations. However, R3M remains inferior to the other two methods, reinforcing the critical role of robot datasets in enhancing robotic representations.", "description": "The t-SNE visualization shows that MCR produces better clustering of image frames from simulation and real robot tasks than R3M and R3M-DROID, highlighting the benefit of using robot data and the effectiveness of MCR in improving robotic representation.", "section": "5.5 TRAINING EFFICIENCY"}, {"figure_path": "2410.22325/figures/figures_19_0.png", "caption": "Figure 8: Grad-CAM on Rearrange.", "description": "The figure visualizes Grad-CAM results for different robotic representation methods on the Rearrange task, highlighting the regions each method focuses on.", "section": "5.2 REAL ROBOT RESULTS"}, {"figure_path": "2410.22325/figures/figures_20_0.png", "caption": "Figure 1: Overview. We introduce a robotic representation evaluation metric termed manipulation centricity, which exhibits a strong correlation with downstream policy performance. Accordingly, we design a new pre-training method, MCR, to learn manipulation-centric representation from large-scale robotic datasets. Comprehensive experiments on both simulations and real robot validate the superiority of our proposed representation.", "description": "This figure provides an overview of the proposed manipulation-centric representation (MCR) method, showing its components, training process, and evaluation.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.22325/figures/figures_21_0.png", "caption": "Figure 1: Overview. We introduce a robotic representation evaluation metric termed manipulation centricity, which exhibits a strong correlation with downstream policy performance. Accordingly, we design a new pre-training method, MCR, to learn manipulation-centric representation from large-scale robotic datasets. Comprehensive experiments on both simulations and real robot validate the superiority of our proposed representation.", "description": "Figure 1 provides an overview of the proposed Manipulation Centric Representation (MCR) method, illustrating its workflow from dataset collection and metric definition to pre-training and evaluation.", "section": "1 INTRODUCTION"}]