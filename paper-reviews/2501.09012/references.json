{"references": [{"fullname_first_author": "Yingying Deng", "paper_title": "StyTr2: Image style transfer with transformers", "publication_date": "2022-XX-XX", "reason": "This paper proposes a novel image style transfer method using transformers, which is directly relevant to the core topic of the main paper and is cited multiple times, indicating its significance in the field."}, {"fullname_first_author": "Nisha Huang", "paper_title": "DiffStyler: Controllable dual diffusion for text-driven image stylization", "publication_date": "2024-XX-XX", "reason": "This paper introduces a text-driven image stylization method using dual diffusion models, aligning with the main paper's focus on evaluating artistic stylization with multimodal LLMs."}, {"fullname_first_author": "Ruixiang Jiang", "paper_title": "Artist: Aesthetically controllable text-driven stylization without training", "publication_date": "2024-XX-XX", "reason": "This paper presents a novel text-driven stylization method without training, addressing the challenge of artistic evaluation without relying on extensive training data."}, {"fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2020-10-02", "reason": "This paper introduces denoising diffusion implicit models (DDIMs), which are foundational to many state-of-the-art image generation models and are implicitly relevant to the image stylization tasks in the main paper."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-XX-XX", "reason": "This paper introduces a large-scale dataset for training image-text models, providing a crucial resource for the multimodal LLMs used in the main paper's experiments."}]}