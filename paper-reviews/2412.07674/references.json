{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-06-11", "reason": "This paper is foundational to the field of diffusion models for image generation, introducing the core denoising process used in many subsequent models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-00-00", "reason": "This paper significantly advanced diffusion models by enabling the generation of high-resolution images, expanding the capabilities and applications of the technology."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is a crucial component of many modern text-to-image models, enabling effective alignment between textual descriptions and visual features."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-00-00", "reason": "DreamBooth is a significant advancement in controllable image generation, enabling fine-tuning of diffusion models for subject-specific customization."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-00-00", "reason": "This paper directly addresses the challenge of controlling specific visual attributes during text-to-image generation, a key focus of the FiVA dataset and adapter."}]}