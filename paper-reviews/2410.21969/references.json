{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that significantly influenced the development of Medical Vision-Language Pretraining (MedVLP) methods."}, {"fullname_first_author": "Alistair EW Johnson", "paper_title": "MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports", "publication_date": "2019-08-01", "reason": "This paper presents MIMIC-CXR, a large-scale publicly available dataset of chest X-rays and reports crucial for training and evaluating MedVLP models."}, {"fullname_first_author": "Zifeng Wang", "paper_title": "MedCLIP: Contrastive learning from unpaired medical images and text", "publication_date": "2022-12-01", "reason": "This paper introduces MedCLIP, a prominent MedVLP model that adapts CLIP for the medical domain, demonstrating strong performance and influencing subsequent research."}, {"fullname_first_author": "Shih-Cheng Huang", "paper_title": "GLORIA: A multimodal global-local representation learning framework for label-efficient medical image recognition", "publication_date": "2021-10-01", "reason": "This paper introduces GLORIA, an early influential MedVLP model employing both global and local contrastive learning, which helped to advance the state-of-the-art."}, {"fullname_first_author": "Chaoyi Wu", "paper_title": "MedKLIP: Medical knowledge enhanced language-image pre-training", "publication_date": "2023-10-01", "reason": "This paper introduces MedKLIP, a MedVLP method that leverages medical knowledge bases to improve the alignment of image and text representations, thereby improving the model's performance on downstream tasks."}]}