{"references": [{"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-10-00", "reason": "This paper introduces VideoCrafter1, a foundational open-source diffusion model for video generation which the current paper builds upon and compares against."}, {"fullname_first_author": "Ziqi Huang", "paper_title": "VBench: Comprehensive benchmark suite for video generative models", "publication_date": "2024-00-00", "reason": "This paper introduces VBench, the primary benchmark used to evaluate the performance of the proposed model in the current paper, providing a standardized way to compare against other models."}, {"fullname_first_author": "Simian Luo", "paper_title": "Latent consistency models: Synthesizing high-resolution images with few-step inference", "publication_date": "2023-10-00", "reason": "This paper introduces Latent Consistency Models, a technique for synthesizing high-resolution images with fewer steps, that are used as the basis for improving the current model's efficiency."}, {"fullname_first_author": "Eric Luhman", "paper_title": "Knowledge distillation in iterative generative models for improved sampling speed", "publication_date": "2021-01-00", "reason": "This paper discusses knowledge distillation, a fundamental method to improve sampling speed of diffusion models which is used in the proposed approach."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-00-00", "reason": "This paper introduces consistency models that are used in the approach of the current paper to improve speed and performance."}]}