[{"figure_path": "https://arxiv.org/html/2412.13147/x1.png", "caption": "Figure 1: Pass@16161616 v.s. Greedy Accuracy v.s. G-Pass@161.0subscript161.016_{1.0}16 start_POSTSUBSCRIPT 1.0 end_POSTSUBSCRIPT on LiveMathBench. This figure illustrates the gap between the performance of models using the Pass@\u206216Pass@16\\text{Pass@}16Pass@ 16 criterion (dark bars), typical greedy output (semi-light bars), and the performance under the G-Pass@\u2062161.0G-Pass@subscript161.0\\text{G-Pass@}16_{1.0}G-Pass@ 16 start_POSTSUBSCRIPT 1.0 end_POSTSUBSCRIPT criterion (light bars), highlights the instability of model performance across multiple samplings.", "description": "This figure compares the performance of several large language models (LLMs) on the LiveMathBench dataset using three different evaluation metrics: Pass@16, Greedy Accuracy, and G-Pass@16_1.0.  Pass@16 represents the probability of getting the correct answer in 16 attempts. Greedy Accuracy refers to the accuracy of the model's first attempt, without any sampling. G-Pass@16_1.0 measures the stability of the model by checking if it gets the correct answer in *all* 16 attempts. The figure uses a bar chart to show the scores for each model under each metric, highlighting the difference between peak potential (Pass@16) and consistent performance (G-Pass@16_1.0). The discrepancy between these metrics demonstrates the instability of LLM performance in complex reasoning tasks.", "section": "4 Performance and Analysis"}, {"figure_path": "https://arxiv.org/html/2412.13147/x2.png", "caption": "Figure 2: Comparison of Pass@k\ud835\udc58kitalic_k and G-Pass@k\ud835\udc58kitalic_k. In our simulation configuration, we set n=10\ud835\udc5b10n=10italic_n = 10, c={8,16,24,32}\ud835\udc508162432c=\\{8,16,24,32\\}italic_c = { 8 , 16 , 24 , 32 }, and then calculate Pass@k\ud835\udc58kitalic_k and G-Pass@k\ud835\udc58kitalic_k.", "description": "This figure compares Pass@k (the probability of getting at least one correct answer in k attempts) and the proposed G-Pass@k (generalized Pass@k that introduces a threshold and measures stability) given different c (number of correct answers). The plots are for different values of k, including 4, 8, 16, and 32. In the simulation, n (the number of trials) is set to 10 and c is varied.", "section": "3 Generalized Metric for LLM Reasoning"}, {"figure_path": "https://arxiv.org/html/2412.13147/x3.png", "caption": "Figure 3: Illustration of G-Pass@k\ud835\udc58kitalic_k w.r.t. different values of k\ud835\udc58kitalic_k for DeepSeek-Math-7b-RL, Qwen2.5-Math-72B-Instruct, QwQ-32B-Preview.", "description": "This figure shows how G-Pass@k changes with different k values (4, 8, and 16) at various thresholds (\u03c4 = 0.25, 0.5, 0.75, and 1.0) and different models (DeepSeek-Math-7b-RL, Qwen2.5-Math-72B-Instruct, and QwQ-32B-Preview). It aims to present the effectiveness of G-Pass@k for evaluating model performance and stability under various settings, where larger k can offer better differentiation for advanced models.", "section": "4.4 Further Analysis"}, {"figure_path": "https://arxiv.org/html/2412.13147/x4.png", "caption": "Figure 4: Illustration of G-Pass@k\ud835\udc58kitalic_k w.r.t. different values of n\ud835\udc5bnitalic_n for DeepSeek-Math-7b-RL and NuminaMath-72B-CoT.", "description": "This figure shows the effect of the number of sampling attempts (n) on the stability metric G-Pass@k. The plot illustrates that with limited sample numbers, the stability metric G-Pass@k varies significantly, especially when the tolerance parameter \\tau is small. With an increasing number of samples n, the estimation becomes more stable, with smaller fluctuations in G-Pass@k value. The figure includes two models DeepSeek-Math-7b-RL and NuminaMath-72B-CoT, showing that with a larger number of samples (n>48), the G-Pass@k values stabilize around 20% and 30%, respectively.", "section": "4.4.2 Performance w.r.t. n"}, {"figure_path": "https://arxiv.org/html/2412.13147/x5.png", "caption": "Figure 5: The data contamination experiment involves different contamination rounds, where #\u2062R\u2062e\u2062p\u2062l\u2062i\u2062c\u2062a\u2062t\u2062i\u2062o\u2062n#\ud835\udc45\ud835\udc52\ud835\udc5d\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\\#Replication# italic_R italic_e italic_p italic_l italic_i italic_c italic_a italic_t italic_i italic_o italic_n represents the number of these rounds. The term S\u2062l\u2062o\u2062p\u2062e\ud835\udc46\ud835\udc59\ud835\udc5c\ud835\udc5d\ud835\udc52Slopeitalic_S italic_l italic_o italic_p italic_e denotes the slope value of the G-Pass@16\u03c4subscript16\ud835\udf0f16_{\\tau}16 start_POSTSUBSCRIPT italic_\u03c4 end_POSTSUBSCRIPT curve with respect to \u03c4\ud835\udf0f\\tauitalic_\u03c4.", "description": "This figure shows the results of data contamination experiments on the Qwen2.5-7B model using the MATH500-L5 dataset.  The x-axis (\"#Replication\") represents the number of contamination rounds, which involves adding a portion of the MATH500-L5 data to the training set (Numina-Math-CoT).  A value of 0 signifies no contamination (training only on the clean Numina-Math data). With increasing contamination, the model's greedy performance generally improves, but its stability (G-Pass@16_{\\tau=1.0}) suffers, widening the gap between potential and actual reliable performance.  The right subplot focuses on the G-Pass@16 curve, showing that as contamination increases, the slope steepens (becomes more negative), further indicating a degradation in stability. The increasing slope magnitude (-3.41, -5.76, -5.83, -7.01) quantifies this.", "section": "4.4.4 Does Data Contamination or Overfitting Affect Stability?"}, {"figure_path": "https://arxiv.org/html/2412.13147/x6.png", "caption": "Figure 6: Illustration of estimation and the true value of G-Pass@k\u03c4subscript\ud835\udc58\ud835\udf0fk_{\\tau}italic_k start_POSTSUBSCRIPT italic_\u03c4 end_POSTSUBSCRIPT.", "description": "This figure presents the results of a simulation experiment designed to demonstrate that the proposed G-Pass@k\u03c4 metric provides an unbiased estimate, allowing for consistent comparisons across different values of *n*. The experiment assumes a model's probability of providing a correct solution (p*) is set to 0.4. For various *n* values, multiple random Bernoulli samplings generate corresponding *c* values. These *c* values are then used to calculate G-Pass@k\u03c4, subsequently determining the mean and variance to generate the plot.  The consistency of the estimated values around the true probability demonstrates that G-Pass@k\u03c4 is an unbiased estimator.", "section": "A.2 Estimation of G-Pass@k"}]