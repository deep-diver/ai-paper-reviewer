{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper is a technical report describing GPT-4, a large language model (LLM) that is used as a judge in this paper's proposed LLM-as-a-judge paradigm."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-12-06", "reason": "This paper is a foundational work showing that LLMs can be few-shot learners, which is relevant to the LLM-as-a-judge paradigm as it reduces the need for extensive fine-tuning of LLMs for different evaluation tasks."}, {"fullname_first_author": "Yuntao Bai", "paper_title": "Constitutional AI: Harmlessness from AI Feedback", "publication_date": "2022-12-08", "reason": "This paper introduces the Constitutional AI framework, a method that uses AI feedback to improve the harmlessness of LLMs, which is a key aspect of the LLM-as-a-judge paradigm."}, {"fullname_first_author": "Yen-Ting Lin", "paper_title": "LLM-Eval: Unified Multi-dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models", "publication_date": "2023-00-00", "reason": "This paper proposes LLM-Eval, a comprehensive evaluation framework for LLMs, which is directly relevant to the LLM-as-a-judge paradigm as it covers various evaluation aspects that can be assessed by LLMs."}, {"fullname_first_author": "Zongjie Li", "paper_title": "MLLM-as-a-judge: Assessing Multimodal LLM-as-a-judge with Vision-Language Benchmark", "publication_date": "2024-00-00", "reason": "This paper extends the LLM-as-a-judge paradigm to multimodal LLMs, which is an important contribution because it demonstrates the potential of LLMs as judges for tasks involving multiple modalities."}]}