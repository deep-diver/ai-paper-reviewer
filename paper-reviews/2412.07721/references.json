{"references": [{"fullname_first_author": "Omer Bar-Tal", "paper_title": "Lumiere: A space-time diffusion model for video generation", "publication_date": "2024-01-12", "reason": "This paper introduces a space-time diffusion model for video generation, which is a foundational model used in the current work for its video generation capabilities."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable Video Diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces Stable Video Diffusion, a key model used in the current work as the base model for its image-to-video generation and object motion control."}, {"fullname_first_author": "Hao He", "paper_title": "Cameractrl: Enabling camera control for text-to-video generation", "publication_date": "2024-04-02", "reason": "This paper introduces CameraCtrl, a method that models object movements with camera poses, which is the core idea used in the current work for its object motion control."}, {"fullname_first_author": "Zhouxia Wang", "paper_title": "MotionCtrl: A unified and flexible motion controller for video generation", "publication_date": "2024-00-00", "reason": "This paper introduces MotionCtrl, which is used as a foundation for adapting global camera motion control to local object motion control in the current work."}, {"fullname_first_author": "Weijia Wu", "paper_title": "DragAnything: Motion control for anything using entity representation", "publication_date": "2024-00-00", "reason": "This paper introduces DragAnything, a training-based object control method that is used as a baseline in the current work for comparison purposes."}]}