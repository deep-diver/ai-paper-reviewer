[{"content": "| Sampling | Ratio (%) | rFVD \u2193 | Max BS |\n|---|---|---|---| \n| Random frame | 3.125 | 479 | 13 |\n| Random patch | 1.563 | 401 | 21 |\n| Random patch | 3.125 | 238 | 13 |", "caption": "Table 1: Frame-wise reconstruction quality of image and video tokenizers.\nWe report metrics that measure the quality of reconstructed frames: PSNR, LPIPS, and SSIM, computed using the 128\u00d7\\times\u00d7128 resolution frames reconstructed by image and video tokenizers trained on the UCF-101 dataset [40].\nTotal # tokens denotes the number of tokens required for encoding 128-frame videos.\n# Frames denotes number of frames in a video used for training tokenizers.\n\u2193\u2193\\downarrow\u2193 and \u2191\u2191\\uparrow\u2191 denotes whether lower or higher values are better, respectively.", "description": "This table compares the performance of different image and video tokenizers in reconstructing 128x128 resolution video frames.  It evaluates models based on the number of tokens needed to encode a 128-frame video, the number of frames used during training, and the reconstruction quality metrics PSNR (higher is better), LPIPS (lower is better), and SSIM (higher is better).  The results show the trade-off between compression (number of tokens) and reconstruction accuracy across various models.", "section": "3.1 Experimental Setup"}]