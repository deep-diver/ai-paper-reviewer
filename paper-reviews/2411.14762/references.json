{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "publication_date": "2023", "reason": "This paper is highly relevant due to its focus on high-resolution video synthesis using latent diffusion models, a technique directly related to the methods explored in the main paper."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024", "reason": "This paper is important because it explores video generation models and their capacity to act as world simulators, which is a key application area relevant to the efficient long video tokenization problem."}, {"fullname_first_author": "Songwei Ge", "paper_title": "Long video generation with time-agnostic vqgan and time-sensitive transformer", "publication_date": "2022", "reason": "This paper is directly relevant to the core problem of the paper, addressing the challenge of efficient long video tokenization using transformers, which the target paper also uses."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "MaskGIT: Masked generative image transformer", "publication_date": "2022", "reason": "This paper is highly relevant because it introduces MaskGIT, a masked generative image transformer that is conceptually similar and technically related to the proposed CoordTok model."}, {"fullname_first_author": "Sihyun Yu", "paper_title": "Video probabilistic diffusion models in projected latent space", "publication_date": "2023", "reason": "This paper is highly relevant because it proposes a method for video generation using diffusion models in a projected latent space, providing a closely related baseline and a comparison framework for evaluating the new model."}]}