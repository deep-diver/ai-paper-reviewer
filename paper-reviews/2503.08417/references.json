{"references": [{"fullname_first_author": "F\u00e9lix G Harvey", "paper_title": "Robust motion in-betweening", "publication_date": "2020-01-01", "reason": "This paper is a foundational work on motion in-betweening that introduces a robust method, making it highly relevant to the current study."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "Dynamicrafter: Animating open-domain images with video diffusion priors", "publication_date": "2023-10-01", "reason": "This paper is used as a baseline and the approach is built upon in the current study, highlighting its importance in the field of video diffusion models."}, {"fullname_first_author": "Qitao Zhao", "paper_title": "A single 2d pose with context is worth hundreds for 3d human pose estimation", "publication_date": "2024-01-01", "reason": "This paper highlights the superiority of using contextual features over large datasets for 3D pose estimation, influencing the 3D joint estimation methodology in the study."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-01-01", "reason": "This paper's method on video diffusion is used as the basis for the motion in-betweening technique, enabling the generation of realistic video content."}, {"fullname_first_author": "Jia Qin", "paper_title": "Motion in-betweening via two-stage transformers", "publication_date": "2022-01-01", "reason": "This paper is a direct competitor and point of comparison to AnyMoLe. The research is significant in the motion in-betweening domain, using a two-stage transformer approach."}]}