{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision.", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a foundational model for learning visual representations from natural language supervision, which is widely used in MLLMs and serves as the visual backbone in LLaVA-UHD v2."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual Instruction Tuning.", "publication_date": "2024-01-01", "reason": "This work establishes the visual instruction tuning method and the baseline LLaVA model which is adopted in LLaVA-UHD v2"}, {"fullname_first_author": "Haotian Liu", "paper_title": "Improved Baselines with Visual Instruction Tuning", "publication_date": "2023-10-03", "reason": "This paper introduces LLaVA-1.5 as a baseline method compared with LLaVA-UHD v2."}, {"fullname_first_author": "Zonghao Guo", "paper_title": "LLaVA-UHD: an LLM perceiving any aspect ratio and high-resolution images.", "publication_date": "2024-01-01", "reason": "This paper introduces LLaVA-UHD which is the baseline method compared with LLaVA-UHD v2"}, {"fullname_first_author": "Tsung-Yi Lin", "paper_title": "Microsoft COCO: Common Objects in Context", "publication_date": "2014-01-01", "reason": "This work introduces the MS-COCO dataset which is utilized for JBU module pre-training."}]}