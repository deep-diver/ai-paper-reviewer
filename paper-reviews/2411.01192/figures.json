[{"figure_path": "https://arxiv.org/html/2411.01192/extracted/5957223/Figures/swan_tasks.png", "caption": "Figure 1: Details of ArabicMTEB", "description": "This figure provides a detailed breakdown of the ArabicMTEB benchmark, illustrating the eight distinct task categories it encompasses: Retrieval, Crosslingual Retrieval, Bitext Mining, Re-ranking, Semantic Textual Similarity, Pair Classification, Classification, and Clustering.  Each category is further categorized to indicate its relevance to the broader field of Arabic natural language processing.", "section": "4 ArabicMTEB Benchmark"}, {"figure_path": "https://arxiv.org/html/2411.01192/x1.png", "caption": "(a) Positive and hard negative generation", "description": "This figure illustrates the methodology used to generate synthetic data for training the Arabic embedding models.  Specifically, it demonstrates how positive and hard negative examples are created using a large language model (LLM), in this case Command-R+. The process involves generating tasks related to real-world usage and using the LLM to generate a positive example (a relevant document) and a hard negative example (a document that is closely related to the query but less useful).", "section": "3 Swan"}, {"figure_path": "https://arxiv.org/html/2411.01192/extracted/5957223/Figures/swan.png", "caption": "Figure 2: Methodology to generate our synthetic data.", "description": "This figure illustrates the process of generating synthetic data for Arabic text embedding models.  It starts with real-world text, using a model to create tasks. Then, it uses the model to generate synthetic data, which is further divided into Modern Standard Arabic (MSA) and dialectal Arabic data.", "section": "3 Swan"}]