{"references": [{" publication_date": "2023", "fullname_first_author": "J. Achiam", "paper_title": "Gpt-4 technical report", "reason": "This paper is foundational because it details GPT-4, a leading large language model (LLM) that underpins many multimodal models.  Understanding its architecture and capabilities is critical for evaluating the advancements in the field, including the proposed Janus model which is also an LLM based model.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "J. Bai", "paper_title": "Qwen-vl: A frontier large vision-language model with versatile abilities", "reason": "This paper introduces Qwen-VL, a state-of-the-art vision-language model that is directly compared against Janus in the experimental evaluation.  Its strong performance makes it an important benchmark for evaluating the effectiveness of Janus.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "X. Bi", "paper_title": "Deepseek llm: Scaling open-source language models with longtermism", "reason": "As Janus is also built on top of DeepSeek LLM, this paper provides crucial background information on the architecture and capabilities of the base LLM used in Janus.  It helps in understanding the advantages of scaling open-source language models for future multimodal models.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "T. B. Brown", "paper_title": "Language models are few-shot learners", "reason": "This paper is highly influential as it established the foundational capabilities of large language models (LLMs) to perform well on a variety of tasks with limited training data.  This is relevant to Janus, which also leverages an LLM's capabilities and benefits from effective training techniques.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "H. Chang", "paper_title": "Maskgit: Masked generative image transformer", "reason": "MaskGit represents a significant advancement in masked image modeling, directly influencing the design of Janus. Understanding MaskGit's architecture and contribution to the field is important for analyzing Janus's innovation in handling visual information.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "J. Chen", "paper_title": "Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "This paper is relevant as it presents a high-performing approach to text-to-image generation that leverages diffusion models.  Janus's visual generation capabilities are compared against this method, and understanding the strengths and weaknesses of Pixart is necessary to understand the contribution of Janus.", "section_number": 2}, {" publication_date": "2015", "fullname_first_author": "X. Chen", "paper_title": "Microsoft coco captions: Data collection and evaluation server", "reason": "This paper is crucial as it describes the Microsoft COCO Captions dataset, which is used as a benchmark for evaluating the visual generation capabilities of Janus.   Understanding the properties of this dataset is essential for interpreting and comparing the performance results.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Z. Chen", "paper_title": "How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites", "reason": "This paper provides valuable context by analyzing the state-of-the-art in open-source multimodal models and comparing them to commercial models.  This context is important for evaluating Janus's performance and position within the broader landscape of multimodal models.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "J. Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "reason": "The BERT model is a foundational transformer-based model that influences the design of many LLMs, including the base LLM used by Janus. Understanding BERT's contribution to the field of natural language processing (NLP) is important for evaluating Janus's overall architecture.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "P. Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "reason": "This paper demonstrates the superior performance of diffusion models over GANs for image synthesis.  Understanding the strengths and limitations of diffusion models is critical since Janus's visual generation capabilities are compared to other models that use this technology.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "R. Dong", "paper_title": "Dream-Ilm: Synergistic multimodal comprehension and creation", "reason": "DreamLLM is a strong competitor to Janus, and a direct comparison between them is made in the paper's experiments.  Understanding the strengths and limitations of DreamLLM is critical for interpreting Janus's performance.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "A. Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This paper introduced Vision Transformers (ViTs), which are now widely used in computer vision and impact the architecture of Janus. Understanding ViTs' capabilities and limitations is important for evaluating Janus's design choices.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "reason": "This paper is a crucial contribution to high-resolution image synthesis which directly impacts visual generation.  Janus's visual generation performance is compared against state-of-the-art models that often leverage these advancements.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "C. Fu", "paper_title": "Mme: A comprehensive evaluation benchmark for multimodal large language models", "reason": "This paper introduces MMBench, one of the key benchmarks used to evaluate Janus's performance on multimodal understanding tasks.  Understanding the properties and challenges of MMBench is crucial for interpreting and comparing the experimental results of Janus.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "O. Gafni", "paper_title": "Make-a-scene: Scene-based text-to-image generation with human priors", "reason": "Make-a-Scene is relevant to Janus's visual generation capabilities as it's another approach to text-to-image generation that leverages advanced techniques.   Comparing the performance of Janus against Make-a-Scene provides valuable insights into the relative strengths and weaknesses of different approaches.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Y. Ge", "paper_title": "Planting a seed of vision in large language model", "reason": "This work directly addresses the challenge of integrating visual capabilities into large language models, which is the central problem tackled by Janus.  Understanding the methods and results presented in this paper helps in contextualizing Janus's contributions.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Y. Ge", "paper_title": "Making llama see and draw with seed tokenizer", "reason": "This paper explores integrating visual generation capabilities into LLMs using innovative methods.  Understanding these methods is essential for evaluating the design and performance of Janus, which also aims to unify multimodal understanding and generation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Y. Ge", "paper_title": "Seed-x: Multimodal models with unified multi-granularity comprehension and generation", "reason": "SEED-X is a state-of-the-art multimodal model that is directly compared against Janus in the paper's experiments.  Understanding SEED-X's architecture and capabilities is crucial for evaluating the relative strengths and weaknesses of Janus.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "D. Ghosh", "paper_title": "Geneval: An object-focused framework for evaluating text-to-image alignment", "reason": "Geneval is a benchmark dataset used for evaluating the visual generation capabilities of Janus.  Understanding the properties and challenges of Geneval is essential for interpreting and comparing the performance results of Janus.", "section_number": 4}, {" publication_date": "2017", "fullname_first_author": "Y. Goyal", "paper_title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering", "reason": "This paper is relevant as it discusses the importance of image understanding in visual question answering (VQA) tasks. This context is crucial for understanding the challenges in multimodal understanding that Janus aims to address.", "section_number": 2}]}