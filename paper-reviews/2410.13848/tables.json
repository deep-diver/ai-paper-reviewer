[{"figure_path": "2410.13848/tables/table_7_0.html", "caption": "Table 1 | Detailed hyperparameters of our Janus. Data ratio refers to the ratio of multimodal understanding data, pure text data, and visual generation data.", "description": "Table 1 presents the hyperparameters used in each of the three stages of training Janus, specifying learning rate, scheduler, weight decay, gradient clipping, optimizer, warmup steps, training steps, batch size, and the data ratio for multimodal understanding, pure text data, and visual generation data.", "section": "4.1. Implementation Details"}, {"figure_path": "2410.13848/tables/table_8_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares Janus' performance on multimodal understanding benchmarks against other state-of-the-art models, highlighting its superior performance despite having comparable or smaller parameter sizes.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_9_0.html", "caption": "Table 3 | Evaluation of text-to-image generation ability on GenEval benchmark. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 3 compares the performance of various text-to-image generation models on the GenEval benchmark, showing Janus's superior performance compared to other models, particularly those using external pretrained diffusion models.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_10_0.html", "caption": "Table 4 | Evaluation of text-to-image generation ability on MSCOCO-30K and MJHQ-30K benchmark. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 4 compares the performance of various models on two text-to-image generation benchmarks, MSCOCO-30K and MJHQ-30K, using FID scores to evaluate image quality.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_10_1.html", "caption": "Table 5 | Ablation studies. We verify the effectiveness of decoupling visual encoding and compare unified training with task-specific training. \u201cUnd.\u201d, \u201cGen.\u201d and \u201cSE. Tokenizer\u201d denote \u201cunderstanding\u201d, \u201cgeneration\u201d and \u201csemantic tokenizer\u201d, respectively.", "description": "The table presents the ablation study results, comparing different visual encoders and training methods (unified vs. task-specific) on several multimodal understanding and generation metrics.", "section": "4.5. Ablation Studies"}, {"figure_path": "2410.13848/tables/table_18_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares the performance of Janus with state-of-the-art models on various multimodal understanding benchmarks, highlighting Janus's superior performance.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_19_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares Janus's performance on multimodal understanding benchmarks against other state-of-the-art models, showing its superior performance, especially compared to models of similar size.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_20_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares Janus with state-of-the-art models on several multimodal understanding benchmarks, showing its superior performance.", "section": "4.4. Comparison with State-of-the-arts"}, {"figure_path": "2410.13848/tables/table_21_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares Janus's performance on multimodal understanding benchmarks against other state-of-the-art models, showing its superior performance even compared to significantly larger models.", "section": "4. Multimodal Understanding Performance"}, {"figure_path": "2410.13848/tables/table_22_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares the performance of Janus with state-of-the-art models on several multimodal understanding benchmarks, including models that use external pretrained diffusion models.", "section": "4. Multimodal Understanding Performance"}, {"figure_path": "2410.13848/tables/table_23_0.html", "caption": "Table 2 | Comparison with state-of-the-arts on multimodal understanding benchmarks. \u201cUnd.\u201d and \u201cGen.\u201d denote \u201cunderstanding\u201d and \u201cgeneration\u201d, respectively. Models using external pretrained diffusion model are marked with \u2020.", "description": "Table 2 compares Janus's performance on multimodal understanding benchmarks against various state-of-the-art models, indicating its superiority across multiple metrics.", "section": "4.4. Comparison with State-of-the-arts"}]