{"references": [{"fullname_first_author": "Tsung-Yi Lin", "paper_title": "Microsoft coco: Common objects in context", "publication_date": "2014-09-06", "reason": "This paper introduces the MSCOCO dataset, a widely used dataset for image captioning and object detection, which is considered the baseline dataset."}, {"fullname_first_author": "Peter Anderson", "paper_title": "Bottom-up and top-down attention for image captioning and visual question answering", "publication_date": "2018-01-01", "reason": "This work introduces a bottom-up and top-down attention mechanism for image captioning, which significantly improved the performance of image captioning models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a model that learns visual concepts from natural language supervision, and is useful in current captioning metrics."}, {"fullname_first_author": "Oriol Vinyals", "paper_title": "Show and tell: A neural image caption generator", "publication_date": "2015-01-01", "reason": "This is one of the early works using neural networks for image captioning."}, {"fullname_first_author": "Kishore Papineni", "paper_title": "Bleu: a method for automatic evaluation of machine translation", "publication_date": "2002-01-01", "reason": "This paper introduces the BLEU metric, a widely used metric for evaluating the quality of machine-generated text, and serves as the baselines for the metric in this paper."}]}