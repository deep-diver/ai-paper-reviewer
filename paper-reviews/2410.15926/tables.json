[{"figure_path": "2410.15926/tables/table_8_0.html", "caption": "Table 1: POPE Results. acc: accuracy. f1: f1 score, measured by precision and recall. Baseline and VCD results are reported by paper [34].", "description": "Table 1 presents the accuracy and F1 scores of different models on the POPE benchmark, comparing the proposed CCA-LLaVA model with baseline and state-of-the-art models.", "section": "5.2 POPE"}, {"figure_path": "2410.15926/tables/table_9_0.html", "caption": "Table 2: CHAIR results. For evaluation setups, 512 and 64 refer to a hyperparater that relates to the length of LVLM repsonses, corresponding to long-text and short-text generation, respectively.", "description": "Table 2 presents CHAIR evaluation results for long and short text generation using greedy and beam search decoding methods, comparing baseline and CCA-LLaVA performance on sentence and instance levels.", "section": "5.3 CHAIR"}, {"figure_path": "2410.15926/tables/table_9_1.html", "caption": "Table 1: POPE Results. acc: accuracy. f1: f1 score, measured by precision and recall. Baseline and VCD results are reported by paper [34].", "description": "The table presents the accuracy and F1 scores of different models on the POPE benchmark for object hallucination mitigation, comparing the proposed CCA method with baselines and state-of-the-art methods.", "section": "5.2 POPE"}, {"figure_path": "2410.15926/tables/table_10_0.html", "caption": "Table 1: POPE Results. acc: accuracy. f1: f1 score, measured by precision and recall. Baseline and VCD results are reported by paper [34].", "description": "Table 1 presents the accuracy and F1 scores achieved by the proposed CCA-LLaVA model and other methods on the POPE benchmark for object hallucination mitigation, across different datasets and negative sampling strategies.", "section": "5.2 POPE"}, {"figure_path": "2410.15926/tables/table_17_0.html", "caption": "Table 1: POPE Results. acc: accuracy. f1: f1 score, measured by precision and recall. Baseline and VCD results are reported by paper [34].", "description": "Table 1 presents the accuracy and F1 scores achieved by the proposed CCA-LLaVA model and existing models on the POPE benchmark for object hallucination mitigation, across different datasets and negative sampling strategies.", "section": "5.2 POPE"}]