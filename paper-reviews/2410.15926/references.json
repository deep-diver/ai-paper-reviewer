{"references": [{" publication_date": "2022", "fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "reason": "This paper is highly relevant because it introduces Flamingo, a pioneering visual language model that demonstrates strong few-shot learning capabilities.  Its focus on visual language understanding and few-shot learning directly addresses the core challenges associated with object hallucination in LVLMs, making it a foundational paper for this research area.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Anas Awadalla", "paper_title": "Openflamingo: An open-source framework for training large autoregressive vision-language models", "reason": "The OpenFlamingo framework offers a valuable open-source platform for research and development in the field of large vision-language models. Its accessibility and potential for collaborative development are key factors contributing to its importance in the context of this research.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "reason": "Qwen-VL is noteworthy for its versatility in handling various vision-language tasks, including understanding, localization, and text reading.  Its broad capabilities are relevant to the broader context of addressing object hallucination, which requires robust understanding of the visual input and its relationship to textual descriptions.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Keqin Chen", "paper_title": "Shikra: Unleashing multimodal llm's referential dialogue magic", "reason": "Shikra's focus on referential dialogue in multimodal LLMs is significant because it demonstrates a higher level of language understanding and contextual reasoning.  This contextual awareness is crucial for reducing hallucinations in LVLMs, which often arise due to a lack of proper understanding of the visual context.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Wei-Ge Chen", "paper_title": "LLava-interactive: An all-in-one demo for image chat, segmentation, generation and editing", "reason": "LLaVA-interactive showcases the potential of LVLMs for interactive applications, including image chat, segmentation, and editing.  Its interactive nature and ability to handle complex visual instructions are relevant to the broader context of object hallucination research, which aims to create more reliable and interactive visual-language models.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Zhaorun Chen", "paper_title": "Halc: Object hallucination reduction via adaptive focal-contrast decoding", "reason": "This paper presents a novel method for reducing object hallucination by leveraging adaptive focal-contrast decoding. This specific approach is relevant to the research because it addresses the problem directly through modifications to the decoding process of the LVLM.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Wen-Lin Chiang", "paper_title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality", "reason": "Vicuna is a significant contribution due to its open-source nature and high performance in comparison to GPT-4. Its high-quality outputs highlight the potential of LVLMs and underscore the need for addressing object hallucination to ensure the reliability and accuracy of these models.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Wenliang Dai", "paper_title": "Instructblip: Towards general-purpose vision-language models with instruction tuning", "reason": "This paper introduces InstructBLIP, highlighting the power of instruction tuning for creating general-purpose vision-language models.  The ability to effectively guide models using instructions is important in the context of object hallucination, as carefully crafted instructions can help reduce the model's tendency to produce inaccurate responses.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "reason": "This work is foundational because it introduced the Transformer architecture to image recognition, significantly influencing the development of vision-language models.  The efficiency and scalability of Transformers are crucial for building the large models necessary to address the challenge of object hallucination.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Alessandro Favero", "paper_title": "Multi-modal hallucination control by visual information grounding", "reason": "This paper directly tackles the problem of multi-modal hallucination, addressing the specific issue of how visual information can be used to ground and control model responses.  The proposed methods are highly relevant to the approach presented in the current work.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Chaoyou Fu", "paper_title": "MME: A comprehensive evaluation benchmark for multimodal large language models", "reason": "MME is a comprehensive benchmark for evaluating multimodal large language models, addressing the need for standardized evaluation in this rapidly evolving field.  This benchmark is crucial for assessing the effectiveness of object hallucination mitigation strategies.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Pengcheng He", "paper_title": "Deberta: Decoding-enhanced bert with disentangled attention", "reason": "DeBERTA's focus on enhanced decoding and disentangled attention is relevant to the current work because it addresses a critical aspect of language model architecture.  Improved decoding mechanisms are crucial for reducing hallucinations, which often manifest as errors in the model's textual generation.", "section_number": 2}, {" publication_date": "1997", "fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "reason": "This seminal paper introduced the LSTM architecture, a recurrent neural network design that has had a profound influence on sequence modeling.  LSTMs' ability to handle long-range dependencies is directly relevant to mitigating the long-term decay effects of RoPE in LVLMs, which are a key contributor to object hallucination.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "LoRA is a highly efficient method for adapting large language models.  Its efficiency is crucial for practical applications, especially in the context of mitigating object hallucination, where retraining the entire model can be computationally prohibitive.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Zhiheng Huang", "paper_title": "Improve transformer models with better relative position embeddings", "reason": "This paper directly addresses the challenges of positional encoding in transformers, a core element of LVLMs.  Understanding and improving positional encoding is crucial for mitigating the problems of long-term decay and object hallucination caused by the misalignment of visual and textual features.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Qidong Huang", "paper_title": "Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation", "reason": "Opera provides a novel approach to mitigating hallucination by incorporating over-trust penalties and retrospection-allocation.  Its unique perspective and methods are valuable in the context of comparing and evaluating different approaches for reducing hallucinations in LVLMs.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Sicong Leng", "paper_title": "Mitigating object hallucinations in large vision-language models through visual contrastive decoding", "reason": "This work directly addresses object hallucination in LVLMs using visual contrastive decoding. The approach is closely related to the current research, and its comparison provides valuable insights into the relative merits of different strategies for mitigating hallucinations.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "reason": "BERT is a foundational model in the field of natural language processing, demonstrating the power of pre-trained language models and their ability to handle a wide range of downstream tasks. The understanding and improvements of BERT-like architectures are critical for creating high-performing LVLMs, and the success of BERT is highly relevant to the progress and challenges in the field of LVLMs and object hallucination.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Anna Rohrbach", "paper_title": "Object hallucination in image captioning", "reason": "This paper is highly relevant because it introduces the concept of \"object hallucination\" in image captioning, which is directly relevant to the problem of object hallucination in LVLMs. It provides a foundational understanding of the phenomenon and its impact, establishing the context for the current research.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Jianlin Su", "paper_title": "Roformer: Enhanced transformer with rotary position embedding", "reason": "RoFormer introduces rotary position embeddings, which are directly relevant to the current work because this paper investigates the role and impact of Rotary Positional Encoding (RoPE) in LVLMs and their contribution to object hallucination.", "section_number": 2}]}