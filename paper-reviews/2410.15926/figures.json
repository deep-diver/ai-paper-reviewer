[{"figure_path": "2410.15926/figures/figures_2_0.png", "caption": "Figure 1: Long-term decay of RoPE [61] in Large Vision Language Models (LVLMs). (a) a schematic view of inference in LVLMs, typically involving a pre-trained vision encoder, a large language model and a projector to map visual tokens to textual space. For each of V visual tokens Svision, we aggregate its information flow to instruction tokens Sinstruct and reshape the aggregation results to 2-D (\u221aV by \u221aV). Applying RoPE on visual tokens introduces long-term decay as illustrated in (c), referring to the phenomenon where information flowing from visual tokens to instruction tokens gradually decays from lower-right region (rightmost visual tokens in the 1-D sequence) to upper-left region (leftmost visual tokens). For instruction tokens, they have much less direct interaction with leftmost visual tokens as compared with rightmost visual tokens, leading to inferior multimodal alignment in the trained LVLMs. (b) and (c) are derived from the adversarial subset of the 3k POPE [41] image-instruction pairs. Best viewed in color.", "description": "The figure illustrates the long-term decay of Rotary Position Encoding (RoPE) in Large Vision Language Models (LVLMs), showing how information flow from visual tokens to instruction tokens diminishes with increasing relative distance.", "section": "1 Introduction"}, {"figure_path": "2410.15926/figures/figures_4_0.png", "caption": "Figure 1: Long-term decay of RoPE [61] in Large Vision Language Models (LVLMs). (a) a schematic view of inference in LVLMs, typically involving a pre-trained vision encoder, a large language model and a projector to map visual tokens to textual space. For each of V visual tokens Svision, we aggregate its information flow to instruction tokens Sinstruct and reshape the aggregation results to 2-D (\u221aV by \u221aV). Applying RoPE on visual tokens introduces long-term decay as illustrated in (c), referring to the phenomenon where information flowing from visual tokens to instruction tokens gradually decays from lower-right region (rightmost visual tokens in the 1-D sequence) to upper-left region (leftmost visual tokens). For instruction tokens, they have much less direct interaction with leftmost visual tokens as compared with rightmost visual tokens, leading to inferior multimodal alignment in the trained LVLMs. (b) and (c) are derived from the adversarial subset of the 3k POPE [41] image-instruction pairs. Best viewed in color.", "description": "The figure illustrates the long-term decay effect of Rotary Position Encoding (RoPE) in Large Vision Language Models (LVLMs), showing how information flow from visual to instruction tokens diminishes with distance due to RoPE's long-term decay.", "section": "1 Introduction"}, {"figure_path": "2410.15926/figures/figures_5_0.png", "caption": "Figure 2: Motivation Experiment. Given an image I with object O<sub>r</sub>, we crop O<sub>r</sub> and paste it to various spatial positions {v<sub>1</sub>, ..., v<sub>k</sub>} within a pre-defined template. For every pasting position, we ask two LVLMs (F<sub>b</sub> and F<sub>r</sub>) if object O<sub>r</sub> is in this template, where F<sub>b</sub> refers to a baseline model that follows raster-scan positional alignment strategy and F<sub>r</sub> refers to a model that resorts to reversal raster-scan position alignment strategy. The total number of correct responses at different pasting positions {v<sub>1</sub>, ..., v<sub>k</sub>} is reported in (a) and (b), which refers to results from model F<sub>b</sub> and F<sub>r</sub>, respectively. We observe that LVLM F<sub>b</sub> are more likely to generate correct responses when pasting object O<sub>r</sub> to lower region, while F<sub>r</sub> are less hallucinated when pasting object O<sub>r</sub> to upper region. Pasting positions with the most and the least correct responses are highlighted in solid-line and dotted-line red boxes. More details are provided in Appendix C.1. Best viewed in color.", "description": "The figure shows the aggregated correct responses of two LVLMs with different positional alignment strategies when pasting an object to various positions in a template image, revealing the impact of RoPE long-term decay on object hallucination.", "section": "3 Motivation"}, {"figure_path": "2410.15926/figures/figures_15_0.png", "caption": "Figure 4: ROPE in LLaMA. A schematic view for LLaMA where RoPE is highlighted, and an example illustration on how ROPE is applied over query or key feature. We use a short input sequence with length of 4 and feature dimension of 4 for demonstration purpose. Input tokens are rotated with angles, subject to token positions. For mathematical definition, please refer to Sec. 3.", "description": "The figure shows a schematic view of LLaMA architecture with Rotary Position Encoding (RoPE) highlighted, illustrating how RoPE applies rotation matrices to query and key tokens based on their positions.", "section": "3 Motivation"}, {"figure_path": "2410.15926/figures/figures_16_0.png", "caption": "Figure 5: Workflow illustration on how we synthesize testing data. Given an image and box annotation for one object instance, we crop it and paste it on a template image, initialized with ImageNet mean pixel values. We paste every cropped region on every spatial position. Resulting data constitutes a large amount of questions about object existence, diverse in spatial positions.", "description": "The figure illustrates the workflow of synthesizing testing data by cropping an object from an image and pasting it into various positions on a template image.", "section": "C Implementation Details"}, {"figure_path": "2410.15926/figures/figures_16_1.png", "caption": "Figure 1: Long-term decay of RoPE [61] in Large Vision Language Models (LVLMs). (a) a schematic view of inference in LVLMs, typically involving a pre-trained vision encoder, a large language model and a projector to map visual tokens to textual space. For each of V visual tokens Svision, we aggregate its information flow to instruction tokens Sinstruct and reshape the aggregation results to 2-D (\u221aV by \u221aV). Applying RoPE on visual tokens introduces long-term decay as illustrated in (c), referring to the phenomenon where information flowing from visual tokens to instruction tokens gradually decays from lower-right region (rightmost visual tokens in the 1-D sequence) to upper-left region (leftmost visual tokens). For instruction tokens, they have much less direct interaction with leftmost visual tokens as compared with rightmost visual tokens, leading to inferior multimodal alignment in the trained LVLMs. (b) and (c) are derived from the adversarial subset of the 3k POPE [41] image-instruction pairs. Best viewed in color.", "description": "The figure illustrates the long-term decay of RoPE in LVLMs, showing how information flow from visual to instruction tokens diminishes with distance, impacting multimodal alignment.", "section": "1 Introduction"}, {"figure_path": "2410.15926/figures/figures_17_0.png", "caption": "Figure 7: Qualitative comparison of open-ended generation between baseline and our method.", "description": "The figure shows a qualitative comparison of the open-ended text generation results between the baseline LLaVA model and the CCA-LLaVA model, highlighting the reduced hallucinations in the CCA-LLaVA model's output.", "section": "D.2 Qualitative Comparison"}, {"figure_path": "2410.15926/figures/figures_18_0.png", "caption": "Figure 9: Case Study where question is sampled from LLaVA-Bench [46]. LLaVA hallucinates hat in its long response, while CCA answers correctly without hallucination.", "description": "The figure shows a qualitative comparison of the responses generated by LLaVA and CCA-LLaVA to a question about the intended effect of a painting, illustrating CCA's ability to mitigate hallucinations.", "section": "5 Experiments"}, {"figure_path": "2410.15926/figures/figures_18_1.png", "caption": "Figure 10: Case Study where question is sampled from LLaVA-Bench [46]. CCA-LLaVA outperforms LLaVA on optical character recognition (left) and numerical prediction in given cases.", "description": "The figure shows two case studies comparing the performance of LLaVA and CCA-LLaVA on questions about product brand identification and fruit counting, highlighting CCA-LLaVA's improved accuracy.", "section": "5 Experiments"}]