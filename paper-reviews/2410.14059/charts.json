[{"figure_path": "2410.14059/charts/charts_4_0.png", "caption": "Figure 2: The visualization displays the top 25 most common root verbs (inner circle) and their top 4 associated direct noun objects (outer circle) extracted from the provided texts.", "description": "The chart visualizes the top 25 most frequent verbs and their associated nouns from the UCFE benchmark dataset, highlighting common financial interaction types.", "section": "4.2 Dataset Construction"}, {"figure_path": "2410.14059/charts/charts_4_1.png", "caption": "Figure 6: Comparison of average dialogue rounds and total tokens across different models in few shot tasks.", "description": "The chart displays the distribution of average dialogue rounds and total tokens used across different models in few-shot tasks of the UCFE benchmark.", "section": "4 User-Centric Financial Expertise Dataset"}, {"figure_path": "2410.14059/charts/charts_7_0.png", "caption": "Figure 5: Comparison of model performance on UCFE benchmark across three evaluators.", "description": "The radar chart visualizes and compares the overall performance of different LLMs across multiple evaluation criteria using three different evaluators.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_0.png", "caption": "Figure 6: Comparison of average dialogue rounds and total tokens across different models in few shot tasks.", "description": "The chart displays the average number of dialogue rounds and total tokens used across different large language models in few-shot tasks of the UCFE benchmark.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_1.png", "caption": "Figure 7: Correlation between human Elo scores and Claude-3.5-Sonnet Elo scores.", "description": "The chart displays the strong positive correlation between human expert evaluations and model performance as assessed by Claude-3.5-Sonnet.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_2.png", "caption": "Figure 5: Comparison of model performance on UCFE benchmark across three evaluators.", "description": "The chart displays a comparison of model performance on the UCFE benchmark across three different evaluators, showing the overall Elo scores for each model.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_14_0.png", "caption": "Figure 11: Geographical Distribution of Survey Respondents", "description": "The chart shows the geographical distribution of 804 survey respondents, with the majority from China (62.9%), followed by the USA (35.9%), and a small percentage from other regions (1.2%).", "section": "4 User-Centric Financial Expertise Dataset"}, {"figure_path": "2410.14059/charts/charts_14_1.png", "caption": "Figure 13: Results of whether preferring generation answers or predefined options from using EastMoney.", "description": "The chart displays the number of survey respondents who prefer generation answers, predefined options, or a mixture of both when completing financial tasks using EastMoney data.", "section": "4 User-Centric Financial Expertise Dataset"}, {"figure_path": "2410.14059/charts/charts_14_2.png", "caption": "Figure 12: Primary Source of Financial Information extracted from the survey", "description": "The bar chart displays the frequency of responses from survey participants regarding their primary sources of financial information.", "section": "4.1 User Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_15_0.png", "caption": "Figure 14: Win counts heatmap for all tasks. The heatmap illustrates the total number of wins where the target model outperforms the base model across all head-to-head comparisons.", "description": "The heatmap in Figure 14 shows the number of times each target model outperformed a baseline model across various tasks in the UCFE benchmark.", "section": "More Experiment Results"}]