[{"figure_path": "2410.14059/charts/charts_4_0.png", "caption": "Figure 2: The visualization displays the top 25 most common root verbs (inner circle) and their top 4 associated direct noun objects (outer circle) extracted from the provided texts.", "description": "The chart visualizes the top 25 most frequent verbs and their associated nouns from a corpus of financial texts, highlighting common financial interactions.", "section": "4.2 Dataset Construction"}, {"figure_path": "2410.14059/charts/charts_4_1.png", "caption": "Figure 6: Comparison of average dialogue rounds and total tokens across different models in few shot tasks.", "description": "The chart displays the distribution of average dialogue rounds and total tokens across different models in few-shot tasks, highlighting variations in model response length and interaction complexity.", "section": "4 User-Centric Financial Expertise Dataset"}, {"figure_path": "2410.14059/charts/charts_7_0.png", "caption": "Figure 5: Comparison of model performance on UCFE benchmark across three evaluators.", "description": "The radar chart visualizes the performance of different LLMs across various financial tasks, comparing results from three different evaluation methods.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_0.png", "caption": "Figure 6: Comparison of average dialogue rounds and total tokens across different models in few shot tasks.", "description": "The chart displays the average number of dialogue rounds and total tokens used across different large language models in few-shot tasks of the UCFE benchmark.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_1.png", "caption": "Figure 7: Correlation between human Elo scores and Claude-3.5-Sonnet Elo scores.", "description": "The chart displays a positive correlation between human expert judgments and model evaluations, indicating alignment between human preferences and model performance.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_8_2.png", "caption": "Figure 5: Comparison of model performance on UCFE benchmark across three evaluators.", "description": "The chart compares the overall Elo scores of various models plotted against model parameters (in billions), showing that mid-sized models perform particularly well.", "section": "5.4 Human Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_14_0.png", "caption": "Figure 11: Geographical Distribution of Survey Respondents", "description": "The chart shows the geographical distribution of survey respondents, with the majority from China, followed by the USA, and a small percentage from other regions.", "section": "4.1 User Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_14_1.png", "caption": "Figure 13: Results of whether preferring generation answers or predefined options from using EastMoney.", "description": "The chart displays the number of survey respondents who prefer generation answers, predefined options, or a mixture of both for financial tasks.", "section": "4.1 User Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_14_2.png", "caption": "Figure 12: Primary Source of Financial Information extracted from the survey", "description": "The bar chart displays the frequency of responses from survey participants regarding their primary source of financial information.", "section": "4.1 User Preference Alignment"}, {"figure_path": "2410.14059/charts/charts_15_0.png", "caption": "Figure 14: Win counts heatmap for all tasks. The heatmap illustrates the total number of wins where the target model outperforms the base model across all head-to-head comparisons.", "description": "The heatmap in Figure 14 shows the number of times each target model outperformed its base model across all tasks in the UCFE benchmark.", "section": "More Experiment Results"}]