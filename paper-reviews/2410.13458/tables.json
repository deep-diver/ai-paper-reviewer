[{"figure_path": "2410.13458/tables/table_2_0.html", "caption": "Table 1: Comparison of MEDINST to several datasets in biomedical field.", "description": "Table 1 compares MEDINST to other biomedical datasets across several criteria, including the presence of task instructions, multi-task datasets, and examples, as well as the number of tasks, instructions, annotated task types, and average task definition length.", "section": "1 Introduction"}, {"figure_path": "2410.13458/tables/table_4_0.html", "caption": "Table 1: Comparison of MEDINST to several datasets in biomedical field.", "description": "The table compares MEDINST with other biomedical datasets based on several features, including the presence of task instructions, multi-task datasets, examples, public availability, number of tasks, number of instructions, and average task definition length.", "section": "1 Introduction"}, {"figure_path": "2410.13458/tables/table_4_1.html", "caption": "Table 2: Dataset statistics across various categories.", "description": "Table 2 presents a summary of the MEDINST dataset, showing the number of datasets, instructions, and tasks across different categories.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}, {"figure_path": "2410.13458/tables/table_8_1.html", "caption": "Table 4: Multiple-choice accuracy evaluation on MMLU-Medicine, a subset of MMLU benchmark. The subjects used are anatomy (An), clinical knowledge (CK), college biology (CB), college medicine (CM), medical genetics (MG) and professional medicine (PM).", "description": "Table 4 presents the multiple-choice accuracy of several language models on the MMLU-Medicine benchmark, across six medical sub-domains.", "section": "4.4 Evaluation on Public English Benchmarks"}, {"figure_path": "2410.13458/tables/table_13_0.html", "caption": "Table 1: Comparison of MEDINST to several datasets in biomedical field.", "description": "The table compares MEDINST with other biomedical datasets based on features like task instructions, multi-task datasets, availability of examples, public accessibility, number of tasks and instructions, and number of annotated task types.", "section": "1 Introduction"}, {"figure_path": "2410.13458/tables/table_14_0.html", "caption": "Table 11: Dataset collection.", "description": "Table 11 presents the train, dev, and test data splits for 133 biomedical NLP tasks across 12 categories, including NER, RE, QA, and more.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}, {"figure_path": "2410.13458/tables/table_15_0.html", "caption": "Table 1: Comparison of MEDINST to several datasets in biomedical field.", "description": "The table compares MEDINST with other datasets in the biomedical field based on features such as the presence of task instructions, multi-task datasets, examples, and data size.", "section": "1 Introduction"}, {"figure_path": "2410.13458/tables/table_16_0.html", "caption": "Table 3: Test results of various models on MEDINST32. \u2020 indicates that the training sets of LLaMA3-MI includes the corresponding training sets of the datasets used by MEDINST32, whereas other models have not seen the MEDINST32 dataset. \u2193 represents that a lower score is better, while for other metrics, a higher score is better. The best and second-best results for each row are highlighted in bold and underlined, respectively. For the baselines, we use a few-shot prompt, providing two examples in the instruction. For the fine-tuned models, we use a zero-shot prompt.", "description": "Table 3 presents the evaluation results of different LLMs on the MEDINST32 benchmark, showing their performance across various difficulty levels and comparing their zero-shot and few-shot capabilities.", "section": "4.2 Results"}, {"figure_path": "2410.13458/tables/table_16_1.html", "caption": "Table 1: Comparison of MEDINST to several datasets in biomedical field.", "description": "Table 1 compares MEDINST to other biomedical datasets across several features, such as whether the dataset contains task instructions, multi-task datasets, and examples, as well as dataset size and number of tasks.", "section": "1 Introduction"}, {"figure_path": "2410.13458/tables/table_17_0.html", "caption": "Table 11: Dataset collection.", "description": "Table 11 presents the dataset employed in MEDINST, showing the number of training, development, and test samples for each task.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}, {"figure_path": "2410.13458/tables/table_18_0.html", "caption": "Table 11: Dataset collection.", "description": "The table presents the list of 98 biomedical datasets used in the MEDINST dataset, categorized into 12 task types and including the number of training, development, and test samples for each dataset.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}, {"figure_path": "2410.13458/tables/table_19_0.html", "caption": "Table 11: Dataset collection.", "description": "The table presents the dataset collection details, including the task type, and the number of training, development, and test samples for each dataset.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}, {"figure_path": "2410.13458/tables/table_20_0.html", "caption": "Table 11: Dataset collection.", "description": "Table 11 shows the dataset collection that includes the train, dev, and test sizes for each dataset used in the MEDINST dataset.", "section": "3 MEDINST: Meta Dataset of Biomedical Instructions"}]