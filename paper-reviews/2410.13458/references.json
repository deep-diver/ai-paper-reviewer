{"references": [{" publication_date": "2020", "fullname_first_author": "Tom B. Brown", "paper_title": "Language Models are Few-Shot Learners", "reason": "This paper is foundational to the field of instruction tuning of LLMs.  It demonstrates that LLMs can be adapted to perform well on various tasks with minimal fine-tuning, which is the basis for the data-centric approach used in this paper. The paper's findings directly inform the methodology used for training domain-specific LLMs.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Yizhong Wang", "paper_title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks", "reason": "This paper introduces a large-scale instruction dataset that achieves strong generalization performance across numerous NLP tasks. This study provides a benchmark and inspiration for creating a comparable biomedical dataset. Their methodology and results are key to this work's comparative analysis and success metric selection.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Monica Agrawal", "paper_title": "Large Language Models are Few-Shot Clinical Information Extractors", "reason": "This paper explores the application of LLMs to clinical information extraction, directly addressing a relevant biomedical task. Its focus on few-shot learning aligns with the paper's data-centric approach, showcasing the potential of this technique for biomedical tasks.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "reason": "This paper introduces a novel training methodology for LLMs focused on instruction following. The approach of using human feedback to refine the model's instructions is relevant to the creation and annotation of a high-quality instruction dataset, ensuring that task instructions are clear, consistent and easy to understand.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Sultan Alrowili", "paper_title": "BioM-Transformers: Building Large Biomedical Language Models with BERT, ALBERT and ELECTRA", "reason": "This paper presents specialized biomedical LLMs which are contrasted with the data-centric approach presented in this paper. It highlights the limitations of the traditional methods of specialized biomedical models that are not easily adaptable to new tasks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yanis Labrak", "paper_title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains", "reason": "This paper is a directly relevant work, presenting a similar methodology and goals. Comparing with this work allows an assessment of the contribution made by the current dataset in advancing the field of biomedical LLMs.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Tianyu Han", "paper_title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data", "reason": "This paper is highly relevant because it introduces a dataset for medical conversational AI, directly related to the domain of biomedical instruction datasets.  Comparing the scale and scope of MedAlpaca with MEDINST highlights the latter's contribution in terms of size and comprehensiveness.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yunxiang Li", "paper_title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge", "reason": "This paper is directly related to the research presented because it involves fine-tuning LLMs for medical applications using a large language model. Comparing ChatDoctor's approach and results with those of the current paper helps assess the effectiveness of the MEDINST dataset.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Xinlu Zhang", "paper_title": "AlpaCare:Instruction-tuned Large Language Models for Medical Application", "reason": "This paper explores a related topic, instruction-tuned LLMs for medical applications. By comparing AlpaCare with the current work, we can better understand the unique contributions of MEDINST.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jason Wei", "paper_title": "Finetuned Language Models Are Zero-Shot Learners", "reason": "This paper provides a comprehensive review of instruction-tuning and its impact on LLM performance, providing a solid theoretical foundation for the experimental design.  Its findings directly impact the methodology and analysis in this paper.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Yu Gu", "paper_title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing", "reason": "This paper presents a comparison of methods for biomedical language model training.  It's relevant because it highlights the limitations of task-specific models and provides context for the data-centric approach adopted in this paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shayne Longpre", "paper_title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning", "reason": "This paper discusses various aspects of instruction tuning for LLMs, including data design and methods. This is directly relevant to the design and annotation methodologies of the current paper's dataset.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Asma Ben Abacha", "paper_title": "On the Summarization of Consumer Health Questions", "reason": "This work is significant because it addresses a specific biomedical task that is incorporated in MEDINST. It showcases the importance of well-defined tasks and associated datasets for improving the accuracy and robustness of LLMs in biomedical applications.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Alan Fries", "paper_title": "BigBIO: A Framework for Data-Centric Biomedical Natural Language Processing", "reason": "This paper introduces a framework for creating and managing biomedical datasets. While not directly focused on instructions, BigBIO's approach to data organization and standardization are highly relevant to the development and management of MEDINST.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Robert Tinn", "paper_title": "BLURB (Biomedical Language Understanding and Reasoning Benchmark)", "reason": "This paper focuses on a biomedical language understanding benchmark. Including BLURB as a related work highlights the importance of constructing comprehensive benchmark datasets for evaluating LLMs' performance in biomedical NLP.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Yao Lu", "paper_title": "Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles", "reason": "This paper introduces a large-scale dataset for multi-document summarization of scientific articles.  This is relevant because it highlights the importance of creating large, diverse datasets for training effective LLMs, and also because summarization is a task included in MEDINST.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Arman Cohan", "paper_title": "Structural Scaffolds for Citation Intent Classification in Scientific Publications", "reason": "This paper focuses on citation intent classification, a relevant biomedical task included in MEDINST. Its inclusion emphasizes the importance of task diversity and the need for comprehensive dataset creation to support diverse task types.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Tushar Khot", "paper_title": "SciTaiL: A Textual Entailment Dataset from Science Question Answering", "reason": "This paper introduces SciTail, a textual entailment dataset from science question answering. Textual Entailment is one of the tasks included in MEDINST, showcasing the dataset's diversity in encompassing various NLP tasks.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "reason": "This paper introduces MMLU, a massive multitask language understanding benchmark, which serves as a standard for evaluating LLMs across diverse tasks.  Its inclusion showcases the importance of creating comprehensive benchmarks to facilitate robust model evaluation.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Pengfei Liu", "paper_title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "reason": "This paper provides a comprehensive overview of prompting methods used in NLP, which are essential for effective instruction tuning.  Understanding these methods is critical for designing and evaluating MEDINST and its effectiveness in training biomedical LLMs.", "section_number": 4}]}