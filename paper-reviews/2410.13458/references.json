{"references": [{" publication_date": "2020", "fullname_first_author": "Tom B. Brown", "paper_title": "Language Models are Few-Shot Learners", "reason": "This paper is foundational to the field of instruction tuning for LLMs. It demonstrates the surprising ability of large language models to adapt to various tasks with minimal fine-tuning, which is a central theme of this work. Its impact is evident in the widespread adoption of instruction tuning as a method for adapting base LLMs to specific tasks, including the work described in this paper.  The findings directly support the rationale behind using instruction finetuning as the primary method for adapting LLMs to the biomedical domain.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Yizhong Wang", "paper_title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks", "reason": "This paper introduces a large-scale instruction dataset that is directly relevant to the work in this paper. It offers a similar focus on using instructions for training LLMs and also explores the concept of generalization to new, unseen tasks. The comparison with this dataset highlights the unique contributions of MEDINST in the biomedical domain.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Finetuned Language Models Are Zero-Shot Learners", "reason": "This work is highly influential in establishing instruction finetuning as a powerful technique for adapting LLMs. The methods described here are foundational to the approach taken in this paper and provide strong support for using instruction finetuning to enhance the performance of LLMs on the biomedical tasks presented. The results from this paper are directly comparable to the ones obtained using MEDINST.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Yu Gu", "paper_title": "BLURB (Biomedical Language Understanding and Reasoning Benchmark)", "reason": "This work presents a biomedical benchmark dataset relevant to the paper's aim of evaluating LLMs on diverse biomedical tasks. The comparison to BLURB's scope and performance metrics is directly relevant and highlights MEDINST's advantages. Its methodology in evaluating models' generalization ability is also directly comparable with this paper's approach.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Monica Agrawal", "paper_title": "Large Language Models are Few-Shot Clinical Information Extractors", "reason": "This paper is among the earliest works to explore the use of LLMs in the clinical domain.  It is directly relevant to this paper because it demonstrates the feasibility of using LLMs for clinical tasks, establishing a foundation for subsequent research.  The comparison with this paper's results highlights the advancements achieved by MEDINST in terms of scale and comprehensiveness.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "The FLAN Collection: Designing Data and Methods for Effective Instruction Tuning", "reason": "This paper provides a detailed analysis of various methods for designing and using instruction datasets for training LLMs. The design principles and methodologies discussed here are highly relevant to this paper's approach in constructing MEDINST.  The insights and comparative results presented are extremely valuable for understanding the trade-offs in the design of instruction datasets.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Sultan Alrowili", "paper_title": "BioM-Transformers: Building Large Biomedical Language Models with BERT, ALBERT and ELECTRA", "reason": "This paper discusses the application of pre-trained language models to the biomedical domain.  It is relevant to the work presented as it demonstrates the use of pre-trained models as a starting point for developing biomedical LLMs.  The comparison highlights the novel contributions of MEDINST compared to previous approaches that relied on pre-trained models and task-specific modules.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Kexin Huang", "paper_title": "Clinical XLNet: Modeling Sequential Clinical Notes and Predicting Prolonged Mechanical Ventilation", "reason": "This paper explores a specific task of clinical note modeling, demonstrating the feasibility of applying specialized models to complex clinical tasks. It is relevant as it highlights a use case of LLMs for medical analysis. The comparison to the methods used here supports the need for a generalized dataset, such as MEDINST, instead of training models on individual specialized tasks.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Albert Q. Jiang", "paper_title": "Mistral 7B", "reason": "This paper introduces a state-of-the-art large language model, which is relevant to this paper because it demonstrates the ongoing advancements in LLM capabilities. The comparison with this model showcases the capabilities of MEDINST in improving the performance of even the most advanced LLMs on complex biomedical tasks.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA: Open and Efficient Foundation Language Models", "reason": "This paper introduces LLaMA, a foundational model used in this paper.  The relevance stems from the fact that MEDINST's performance improvements are evaluated on various instruction-tuned versions of this base LLM. Understanding LLaMA's capabilities and limitations is essential for evaluating MEDINST's contributions to biomedical LLM development. ", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "OpenAI", "paper_title": "GPT-4 Technical Report", "reason": "This paper introduces GPT-4, a powerful LLM used as a benchmark in this paper.  The comparison of MEDINST-trained models against GPT-4's performance highlights the effectiveness of MEDINST in enhancing LLM capabilities for biomedical tasks.  This comparison demonstrates the impact of MEDINST in improving LLM performance beyond what has previously been possible.", "section_number": 1}, {" publication_date": "2016", "fullname_first_author": "Simon Baker", "paper_title": "Automatic semantic classification of scientific literature according to the hallmarks of cancer", "reason": "This paper describes a method for automatically classifying scientific literature based on cancer hallmarks. This is relevant to the text classification tasks in MEDINST, which involve assigning categories to biomedical texts. The comparison highlights MEDINST's unique approach to building a dataset suitable for this purpose.", "section_number": 3}, {" publication_date": "2010", "fullname_first_author": "Martin Gerner", "paper_title": "LINNAEUS: A species name identification system for biomedical literature", "reason": "This paper introduces LINNAEUS, a named entity recognition (NER) system for biomedical literature, which is highly relevant to MEDINST's NER tasks.  Its discussion highlights the complexities of biomedical NER and the necessity for datasets like MEDINST which offer diverse NER data to improve the robustness of NER models. The comparison with LINNAEUS's methodology and results provides a benchmark against which to evaluate MEDINST's impact.", "section_number": 3}, {" publication_date": "2004", "fullname_first_author": "Nigel Collier", "paper_title": "Introduction to the Bio-entity Recognition Task at JNLPBA", "reason": "This paper describes the Bio-entity Recognition task, which is directly relevant to several tasks in MEDINST.  Its description helps to contextualize the complexities of these tasks, highlighting the need for a dataset like MEDINST that addresses the diversity of challenges in biomedical NER.  The insights provided in this paper provide a solid basis for comparison and analysis of the performance of the LLMs trained on MEDINST.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Arman Cohan", "paper_title": "Structural Scaffolds for Citation Intent Classification in Scientific Publications", "reason": "This paper focuses on citation intent classification, which is highly relevant to the text classification tasks within MEDINST.  The comparison demonstrates the unique features and approach taken in building MEDINST for the biomedical domain, highlighting its contribution to tasks similar to the one detailed here.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Tushar Khot", "paper_title": "SciTaiL: A Textual Entailment Dataset from Science Question Answering", "reason": "This paper introduces a textual entailment dataset which is used for evaluating the capabilities of LLMs for reasoning and inference, a highly relevant task for evaluating biomedical LLMs as well.  Comparing performance on SciTail against performance on MEDINST-related tasks helps highlight the contribution of MEDINST to improving LLM capabilities.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "reason": "This paper introduces MMLU, a large-scale multitask language understanding benchmark. The evaluation of the MEDINST-trained LLMs on MMLU (subset) highlights the generalization capabilities of models trained on MEDINST. Comparing MEDINST\u2019s results to MMLU helps measure its effect on cross-domain performance and general language understanding skills.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Pengfei Liu", "paper_title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "reason": "This paper provides a comprehensive survey of prompting methods in NLP, which is highly relevant to this paper's focus on instruction-tuning. The background information and insights into prompting techniques provide a strong foundation for understanding the methodology used in the current work, as well as analyzing the results obtained.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Shayne Longpre", "paper_title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning", "reason": "This paper explores instruction tuning for LLMs and offers valuable insights into designing effective instruction datasets.  The comparative analysis of data design principles and methodologies is highly relevant to this paper, highlighting the key design decisions and justifications in creating MEDINST.  The insights from this work directly influence the design and structure of MEDINST.", "section_number": 4}]}