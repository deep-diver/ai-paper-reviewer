[{"figure_path": "2410.09724/tables/table_4_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a comparison of the performance of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets using two evaluation metrics: Expected Calibration Error (ECE) and Area Under the ROC Curve (AUC).", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_9_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets, evaluating expected calibrated error (ECE), area under the ROC curve (AUC), and accuracy (ACC).", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_9_1.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "The table presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) on six datasets using two model families (Llama3-8B and Mistral-7B) across different prompting strategies (Direct Answers and Zero-Shot Chain-of-Thought).", "section": "4 Experiments"}, {"figure_path": "2410.09724/tables/table_10_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "The table presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets using two evaluation metrics (ECE and AUC).", "section": "4 Experiments"}, {"figure_path": "2410.09724/tables/table_18_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a comparison of the performance of several methods on six different datasets, showing the expected calibrated error (ECE), area under the receiver operating characteristic curve (AUC), and accuracy (ACC).", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_20_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a performance comparison of different methods on six datasets, evaluating Expected Calibration Error (ECE) and Area Under the ROC Curve (AUC) to assess calibration and accuracy.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_20_1.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents the performance comparison across six different datasets for five distinct methods: SFT, PPO, PPO+, PPO-M, and PPO-C, evaluating two metrics: ECE and AUC.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_21_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "This table presents a quantitative comparison of the performance of different methods (SFT, PPO, PPO+, PPO-M, and PPO-C) on six diverse datasets, evaluating their expected calibration error (ECE) and area under the receiver operating characteristic curve (AUC).", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_21_1.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents the performance comparison of different methods (SFT, PPO, PPO+, PPO-M, and PPO-C) across six datasets, evaluating their Expected Calibration Error (ECE), Area Under the Receiver Operating Characteristic Curve (AUC), and accuracy.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_23_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents the performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) on six datasets, evaluating Expected Calibration Error (ECE) and Area Under the Curve (AUC) for both direct answer and zero-shot chain-of-thought prompting strategies.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_27_2.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a quantitative comparison of the performance of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets, evaluating Expected Calibration Error (ECE) and Area Under the ROC Curve (AUC) to assess calibration and overall accuracy.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_31_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a quantitative comparison of different methods (SFT, PPO, PPO+, PPO-M, and PPO-C) across six evaluation datasets, using ECE and AUC metrics to assess calibration and performance.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_31_1.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "Table 1 presents a comparison of the performance of several methods on six datasets, showing the expected calibrated error (ECE), area under the receiver operating characteristic curve (AUC), and accuracy (ACC) for each method.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_31_2.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "The table presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) on six datasets using two model families (Llama3-8B and Mistral-7B), evaluating metrics like ECE and AUC.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_32_0.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "The table presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets, evaluating Expected Calibration Error (ECE), Area Under the Receiver Operating Characteristic Curve (AUC), and Accuracy.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.09724/tables/table_32_1.html", "caption": "Table 1: Performance comparison across various methods on six datasets. SFT: Supervised Fine-Tuned checkpoints, serving as the starting points for all methods. PPO\u2020: an ablation of our PPO-M method which uses vanilla reward model in PPO training but on our modified dataset (with confidence-query system prompts).", "description": "The table presents a performance comparison of different methods (SFT, PPO, PPO+, PPO-M, PPO-C) across six datasets, evaluating their expected calibration error (ECE), area under the receiver operating characteristic curve (AUC), and accuracy (ACC).", "section": "4 EXPERIMENTS"}]