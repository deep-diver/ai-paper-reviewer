[{"figure_path": "2410.17250/tables/table_3_0.html", "caption": "Table 1: Overview of Japanese LMM benchmarks. JMMMU is the first benchmark that evaluates expert-level skills and is the largest among culture-aware benchmarks.", "description": "Table 1 compares various Japanese LMM benchmarks based on their cultural focus, evaluation level, number of questions, and images.", "section": "Japanese LMM Benchmarks"}, {"figure_path": "2410.17250/tables/table_5_0.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "Table 2 presents the overall performance of various large multimodal models (LMMs) on the JMMMU benchmark, broken down by model type, subset (culture-agnostic and culture-specific), and individual subject areas, showing the overall performance and highlighting the best-performing models.", "section": "4.2 Main Result"}, {"figure_path": "2410.17250/tables/table_6_0.html", "caption": "Table 3: The effect of translation. Each column shows the model performance when image (I) and text (T) are in Japanese (jp) or in English (en). \u0394\u2081 shows the difference from IenTen.", "description": "Table 3 shows the impact of translating image and text on the performance of various LLMs in a culture-agnostic subset of the JMMMU benchmark.", "section": "5 Ablation"}, {"figure_path": "2410.17250/tables/table_12_0.html", "caption": "Table A: LMM's Japanese support.", "description": "Table A summarizes whether each large multimodal model (LMM) officially supports Japanese, indicating official support with a checkmark and lack of support with an X.", "section": "A LMMs' Japanese Support"}, {"figure_path": "2410.17250/tables/table_14_0.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "Table 2 presents the overall performance of various LLMs on the JMMMU benchmark, broken down by model type, subset (culture-agnostic and culture-specific), and individual subject areas, showing the average and best performing models.", "section": "4.2 Main Result"}, {"figure_path": "2410.17250/tables/table_16_1.html", "caption": "Table 1: Overview of Japanese LMM benchmarks. JMMMU is the first benchmark that evaluates expert-level skills and is the largest among culture-aware benchmarks.", "description": "Table 1 compares various Japanese LMM benchmarks across different aspects such as culture focus, knowledge level, and the number of questions and images.", "section": "Japanese LMM Benchmarks"}, {"figure_path": "2410.17250/tables/table_16_2.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "Table 2 presents the overall performance of various Large Multimodal Models (LMMs) on the JMMMU benchmark, broken down by model type, subset (culture-agnostic or culture-specific), and individual subject area.", "section": "4.2 Main Result"}, {"figure_path": "2410.17250/tables/table_16_3.html", "caption": "Table A: LMMs' Japanese support.", "description": "This table summarizes whether each large multimodal model (LMM) officially supports Japanese.", "section": "A LMMs' Japanese Support"}]