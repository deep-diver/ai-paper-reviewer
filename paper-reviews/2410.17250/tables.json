[{"figure_path": "2410.17250/tables/table_3_0.html", "caption": "Table 1: Overview of Japanese LMM benchmarks. JMMMU is the first benchmark that evaluates expert-level skills and is the largest among culture-aware benchmarks.", "description": "Table 1 compares several Japanese LMM benchmarks, highlighting JMMMU's unique focus on expert-level skills and its significantly larger size compared to existing culture-aware benchmarks.", "section": "Japanese LMM Benchmarks"}, {"figure_path": "2410.17250/tables/table_5_0.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "Table 2 presents the overall performance of various Large Multimodal Models (LMMs) on the JMMMU benchmark, broken down by model type, subset (culture-agnostic and culture-specific), and individual subjects, showing overall performance scores and highlighting the best-performing models.", "section": "4.2 Main Result"}, {"figure_path": "2410.17250/tables/table_6_0.html", "caption": "Table 3: The effect of translation. Each column shows the model performance when image (I) and text (T) are in Japanese (jp) or in English (en). \u0394\u2081 shows the difference from IenTen.", "description": "Table 3 presents the effects of translating images and/or text from English to Japanese on various large multimodal models' performance.", "section": "5 Ablation"}, {"figure_path": "2410.17250/tables/table_12_0.html", "caption": "Table A: LMMs' Japanese support.", "description": "This table summarizes the Japanese language support status for various large multimodal models (LMMs), indicating whether each model officially supports Japanese or not.", "section": "A LMMs' Japanese Support"}, {"figure_path": "2410.17250/tables/table_14_0.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "Table 2 presents the overall performance of various Large Multimodal Models (LMMs) on the JMMMU benchmark, broken down by model type, subset (culture-agnostic and culture-specific), and individual subject area, highlighting performance differences between English and Japanese and between open-source and proprietary models.", "section": "4.2 Main Result"}, {"figure_path": "2410.17250/tables/table_16_2.html", "caption": "Table 2: Overall results. CA (EN) shows the result on culture agnostic subset in English. The rest of the results are average and individual subjects' scores on JMMMU. \u2020denotes Japanese LMMs. The best-performing model among open source and proprietary models are in bold. Overall, the performance is up to 40.5% for open-source, and 58.6% for proprietary models, leaving great room for improvement.", "description": "The table presents the overall performance of various large multimodal models (LMMs) on the JMMMU benchmark, broken down by model type, subset (culture-agnostic, culture-specific), and individual subjects, showing performance gaps between English and Japanese and highlighting the need for improvement in cultural understanding.", "section": "4 Experiments"}, {"figure_path": "2410.17250/tables/table_16_3.html", "caption": "Table 1: Overview of Japanese LMM benchmarks. JMMMU is the first benchmark that evaluates expert-level skills and is the largest among culture-aware benchmarks.", "description": "Table 1 compares various Japanese LMM benchmarks based on their cultural focus, question type, and the number of questions and images.", "section": "Japanese LMM Benchmarks"}]