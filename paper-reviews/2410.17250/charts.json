[{"figure_path": "2410.17250/charts/charts_6_0.png", "caption": "Figure 3: Score correlation between subsets. While proprietary models (\u25a0) perform the best on both subsets, Japanese LMMs (\u2605) perform remarkably high on CS subset compared to models that perform similarly on CA subset.", "description": "The chart shows the correlation between the performance of various large multimodal models on culture-agnostic and culture-specific subsets of a Japanese benchmark, revealing that Japanese models perform particularly well on the culture-specific subset.", "section": "The Performance of Japanese LMMs"}, {"figure_path": "2410.17250/charts/charts_7_0.png", "caption": "Figure 5: Error distribution over culture-specific subjects. Lack of Knowledge is the majority error type at over 50%.", "description": "The chart shows the distribution of error types in GPT-40's responses to culture-specific questions, with the majority (53.8%) being due to a lack of knowledge.", "section": "5.3 Errors in Culture-specific Subjects"}, {"figure_path": "2410.17250/charts/charts_14_0.png", "caption": "Figure 3: Score correlation between subsets. While proprietary models (\u25a0) perform the best on both subsets, Japanese LMMs (\u2605) perform remarkably high on CS subset compared to models that perform similarly on CA subset.", "description": "The chart shows the correlation between the performance of various Large Multimodal Models (LMMs) on culture-agnostic and culture-specific subsets of a Japanese benchmark, highlighting the superior performance of Japanese LMMs on culture-specific tasks.", "section": "The Performance of Japanese LMMs"}]