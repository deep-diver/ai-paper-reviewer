[{"figure_path": "https://arxiv.org/html/2412.02259/x2.png", "caption": "Figure 1: Illustration of VideoGen-of-Thought (VGoT). (a) Comparison of existing methods with VGoT in multi-shot video generation.\nExisting methods struggle with maintaining consistency and logical coherence across multiple shots, while VGoT effectively addresses these challenges through a multi-shot generation approach.\n(b) Overview of our proposed framework VGoT, which is consist of the Script Module which generates detailed shot descriptions from five domains, the KeyFrame Module to create keyframes from scripts, the Shot-Level Video Module which synthesizes video latents on conditional with keyframes and scripts, and the Smooth Module ensures seamless transitions across shots, resulting in a cohesive video narrative.", "description": "Figure 1 illustrates the VideoGen-of-Thought (VGoT) framework. Panel (a) compares VGoT to existing multi-shot video generation methods, highlighting VGoT's ability to maintain consistency and coherence across multiple shots, unlike previous methods. Panel (b) provides a detailed breakdown of the VGoT framework, which consists of four modules: a Script Module that generates detailed shot descriptions from five domains (character, background, relation, camera pose, HDR), a KeyFrame Module that creates keyframes based on these scripts, a Shot-Level Video Module that synthesizes video latents conditioned on keyframes and scripts, and a Smooth Module that ensures seamless transitions for a cohesive narrative.", "section": "4. Method: VideoGen-of-Thought"}, {"figure_path": "https://arxiv.org/html/2412.02259/x3.png", "caption": "Figure 2: The FlowChart of VideoGen-of-Thought. Left: Shot descriptions are generated based on user prompts, describing various attributes including character details, background, relations, camera pose, and lighting HDR. Pre-shot descriptions provide a broader context for the upcoming scenes. Middle Top: Keyframes are generated using a text-to-image diffusion model conditioned with identity-preserving (IP) embeddings, which ensures consistent representation of characters throughout the shots. IP portraits help maintain visual identity consistency. Right: The shot-level video clips are generated from keyframes, followed by shot-by-shot smooth inference to ensure temporal consistency across different shots. This collaborative framework ultimately produces a cohesive narrative-driven video.", "description": "This figure illustrates the workflow of the VideoGen-of-Thought (VGoT) model.  Starting with a user prompt (a single sentence describing a short story), the system generates detailed shot descriptions, encompassing character details, background setting, relationships between characters, camera angles, and HDR lighting. These descriptions serve as input for generating consistent keyframes, leveraging text-to-image diffusion models and identity-preserving embeddings to ensure character consistency across shots.  These keyframes, along with the shot descriptions, are used to generate individual video clips (shots). Finally, a smoothing mechanism ensures seamless transitions between shots, resulting in a coherent, multi-shot video that reflects the initial story prompt.", "section": "4. Method: VideoGen-of-Thought"}, {"figure_path": "https://arxiv.org/html/2412.02259/x4.png", "caption": "Figure 3: Visual comparison of VGoT and baselines", "description": "Figure 3 presents a visual comparison of videos generated by VideoGen-of-Thought (VGoT) and several baseline methods. All methods are given the same input: a one-sentence prompt instructing them to generate a 30-shot video depicting the life of a classic American woman, Mary, from birth to death. The figure highlights VGoT's superior ability to generate high-quality, visually consistent, and narratively coherent videos compared to other state-of-the-art approaches.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02259/x5.png", "caption": "Figure 4: Visual showcases of VGoT generated multi-shot videos.", "description": "This figure showcases several multi-shot videos generated using the VideoGen-of-Thought (VGoT) model. Each video is based on a different one-sentence prompt, highlighting the model's ability to create coherent and visually appealing videos with multiple shots, from a short, simple story description. The examples illustrate the variety of stories and scenes VGoT can generate, demonstrating its capacity for multi-shot video generation.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02259/x6.png", "caption": "Figure 5: Visual Demonstration of the ablation studies of VGoT", "description": "This figure shows a visual comparison of videos generated by VGoT with and without different components.  Specifically, it demonstrates the impact of removing the identity-preserving (IP) embeddings and/or the enhanced prompt (EP) generation on the final video output.  By comparing these variations, the figure visually highlights the contributions of each component to the overall quality, consistency, and coherence of the generated multi-shot videos.", "section": "5.5 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2412.02259/x7.png", "caption": "Figure 6: VGoT Visual complement of the multi-camera video generated.", "description": "This figure showcases visual examples of multi-shot videos generated by the VideoGen-of-Thought (VGoT) model. Each row represents a different story, with multiple shots arranged to display the narrative flow generated by the model.  The figure demonstrates the model's ability to create visually coherent and consistent videos across multiple shots, maintaining character consistency and storytelling throughout.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02259/x8.png", "caption": "Figure 7: Visual comparison of VGoT with baselines Supplement.", "description": "This figure provides a visual comparison of the multi-shot videos generated by the proposed VideoGen-of-Thought (VGoT) model and four baseline methods (EasyAnimate, CogVideo, VideoCrafter1, VideoCrafter2) across five different story prompts.  Each row showcases the videos generated for a particular story, demonstrating the visual differences in the coherence, consistency, and overall quality of the generated videos between VGoT and the baselines.  The stories cover a variety of scenarios and involve diverse visual styles.", "section": "5. Experiments"}]