{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper provides a comprehensive technical overview of GPT-4, a large language model that is foundational to the Script Generation module in the proposed framework."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models, a fundamental technique used in various video generation modules within the proposed framework."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-06-01", "reason": "This paper presents high-resolution image synthesis using latent diffusion models, which serves as the basis for the Keyframe Generation module in the proposed framework."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a model that is used for generating text embeddings for the video generation process."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "Dynamicrafter: Animating Open-Domain Images With Video Diffusion Priors", "publication_date": "2025-05-01", "reason": "This paper introduces DynamiCrafter, a conditional video generation model used in the Shot-Level Video Generation module of the proposed framework."}]}