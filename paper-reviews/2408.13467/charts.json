[{"figure_path": "2408.13467/charts/charts_8_0.png", "caption": "Figure 2: Performance of Gemma 7B fine-tuned on varied volumes of synthetic dataset producted by various service LLMs including GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash. The first to third columns represent the performance of the model evaluated by GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash as judges, respectively. The first row show mean scores, while the second and third rows show the coverage percentage with scores of 50 and 70, respectively.", "description": "The chart displays the performance of Gemma 7B, a fine-tuned language model, across different volumes of synthetic datasets generated by various service LLMs, evaluated by three different service LLMs as judges.", "section": "4.4 In-depth LLMOps Pipeline Analysis"}, {"figure_path": "2408.13467/charts/charts_9_0.png", "caption": "Figure 3: The KDE Plots of Precision v.s. Similarity by varied synthetic dataset volumes with 2nk, n \u2208 {0,1,...,8} and various evaluators with GPT40, Claude 3 Sonnet, Gemini 1.5 Flash as judges from first to third columns, while the first and second rows represent the results of Gemma 2B (first row) and Gemma 7B (second row), respectively.", "description": "The chart shows the Kernel Density Estimate plots of precision and similarity scores for Gemma 2B and 7B models, evaluated by different service LLMs, across varying volumes of synthetic datasets.", "section": "4.4 In-depth LLMOps Pipeline Analysis"}, {"figure_path": "2408.13467/charts/charts_10_0.png", "caption": "Figure 4: Long-term operational cost comparison between fine-tuning a local LLM and API-based token usage of GPT40.", "description": "The chart compares the accumulated costs of fine-tuning a local LLM versus using GPT-40's API for different workloads over 24 months.", "section": "4.5 Cost Effectiveness of Long-term Deployment"}, {"figure_path": "2408.13467/charts/charts_19_0.png", "caption": "Figure 2: Performance of Gemma 7B fine-tuned on varied volumes of synthetic dataset producted by various service LLMs including GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash. The first to third columns represent the performance of the model evaluated by GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash as judges, respectively. The first row show mean scores, while the second and third rows show the coverage percentage with scores of 50 and 70, respectively.", "description": "The chart displays the performance of Gemma 7B, fine-tuned using different volumes of synthetic datasets generated by three service LLMs (GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash), and evaluated by the same three service LLMs.", "section": "4.4 In-depth LLMOps Pipeline Analysis"}]