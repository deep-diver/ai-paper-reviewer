{"references": [{" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "reason": "This is a foundational paper introducing chain-of-thought prompting and establishing its effectiveness in eliciting reasoning capabilities in large language models.  The current work builds directly upon this foundation, investigating when and why CoT fails, which directly relates to the original paper's focus on enhancing reasoning. ", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Maxwell Nye", "paper_title": "Show your work: Scratchpads for intermediate computation with language models", "reason": "This paper is highly relevant because it also explores prompting techniques to improve reasoning in language models, which helps contextualize the research on CoT and the specific focus on inference-time reasoning. The comparative analysis of different prompting techniques, along with their impact on model performance, directly aligns with the core themes of this study.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Zayne Sprague", "paper_title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning", "reason": "This paper provides a recent comprehensive meta-analysis of CoT's effectiveness, offering crucial context for the presented work. Its findings highlight the limitations of CoT in various tasks, particularly those beyond symbolic reasoning, directly supporting the current research exploring the boundary conditions and failure modes of CoT.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "reason": "This paper explores another technique related to chain-of-thought and addresses its limitations and performance. Comparing and contrasting these methods provides a broader understanding of inference-time reasoning in LLMs. Thus, it's relevant to the current work that focuses on identifying situations where CoT is detrimental to model performance.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Subbarao Kambhampati", "paper_title": "LLMs can't plan, but can help planning in LLM-modulo frameworks", "reason": "This research highlights the limits of LLMs in planning tasks, a cognitive domain related to the study's focus on inference-time reasoning and its limitations. The contrast between planning capabilities (lacking in LLMs) and reasoning capabilities (enhanced by CoT) provides important insights into the strengths and limitations of different cognitive processes in LLMs.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "reason": "This is a key benchmark paper defining a large-scale collection of tasks for evaluating language models' capabilities. The current study uses a diverse collection of tasks to evaluate its hypothesis; understanding the benchmark landscape is essential for interpreting the results and demonstrating the generalizability of its findings. ", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Mirac Suzgun", "paper_title": "Challenging BIG-Bench tasks and whether chain-of-thought can solve them", "reason": "This is another significant benchmark paper providing a substantial collection of challenging tasks for large language models. The current study evaluates the performance of CoT on a wider set of tasks, and understanding the benchmark landscape helps in evaluating the scope and significance of the results.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Richard Shiffrin", "paper_title": "Probing the psychology of ai models", "reason": "This is a highly relevant paper directly connecting AI model capabilities with psychological research. The current work directly leverages this cross-disciplinary approach to investigate the impact of CoT on models by using psychological findings. It directly supports the methodological choices and reasoning used in the current work.", "section_number": 2}, {" publication_date": "2016", "fullname_first_author": "Tania Lombrozo", "paper_title": "Explanatory preferences shape learning and inference", "reason": "This paper provides a foundation on human explanatory preferences that is used to formulate the hypothesis for this paper. The focus on how deliberation impacts human learning and inference directly aligns with the current study's focus on investigating the effect of CoT on model performance in tasks that are also affected by human deliberation.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Tania Lombrozo", "paper_title": "'Learning by thinking' in science and in everyday life", "reason": "This paper complements the 2016 Lombrozo paper by discussing the impact of thinking on learning more broadly. It provides a conceptual background and supporting evidence for the connection between human deliberation and learning, which directly supports the methodology and hypotheses of the current study.", "section_number": 3}, {" publication_date": "1990", "fullname_first_author": "Jonathan W Schooler", "paper_title": "Verbal overshadowing of visual memories: Some things are better left unsaid", "reason": "This classic paper on verbal overshadowing is highly relevant because it demonstrates how verbalization of a visual stimulus can impair performance in recognition tasks. The current study leverages this phenomenon by including a facial recognition task. The comparison directly informs and supports the argument that verbalizing may negatively impact LLMs, similar to humans.", "section_number": 3}, {" publication_date": "1993", "fullname_first_author": "Marte Fallshore", "paper_title": "Post-encoding verbalization impairs transfer on artificial grammar tasks", "reason": "This is a crucial study demonstrating the detrimental effect of verbalization on implicit learning. The current study utilizes a similar artificial grammar learning task, drawing a direct parallel to this experiment. This shows how verbalization can impair performance, thus informing the hypothesis that CoT might have similar negative impacts on LLMs.", "section_number": 4}, {" publication_date": "1990", "fullname_first_author": "Jonathan W Schooler", "paper_title": "Verbal overshadowing of visual memories: Some things are better left unsaid", "reason": "This paper demonstrates how verbalization of a visual stimulus can impair performance in recognition tasks. The current study replicates this in LLM testing, showing that describing visual stimuli (faces) reduces the performance of LLMs, similar to the impact on humans.", "section_number": 4}, {" publication_date": "2013", "fullname_first_author": "Joseph J Williams", "paper_title": "Explanation and prior knowledge interact to guide learning", "reason": "This study directly supports the hypothesis testing concerning tasks involving exceptions. It finds that explaining general rules leads to slower learning when exceptions exist. It provides the theoretical basis and empirical data for the current study's experiment on classifying data with exceptions.", "section_number": 4}, {" publication_date": "2012", "fullname_first_author": "Sangeet S Khemlani", "paper_title": "Hidden conflicts: Explanations make inconsistencies harder to detect", "reason": "This study is highly relevant as it demonstrates that explaining inconsistent statements can hinder humans' ability to detect logical inconsistencies.  The current work directly evaluates this, assessing whether a similar effect occurs with CoT prompting in LLMs.  It helps to validate and establish the heuristic that tasks where human deliberation hurts performance can be used to identify potential CoT failures.", "section_number": 4}, {" publication_date": "1999", "fullname_first_author": "Daniel L Schwartz", "paper_title": "Inferences through imagined actions: Knowing by simulated doing", "reason": "This study contrasts verbal and non-verbal reasoning processes in humans. This contrast informs the experiments in this paper, particularly those investigating spatial intuition and visual-motor tasks, by directly testing whether CoT might lead to performance drops in LLMs. The comparison highlights the different ways in which humans and models might process information and potentially react to CoT differently.", "section_number": 4}, {" publication_date": "2004", "fullname_first_author": "Ap Dijksterhuis", "paper_title": "Think different: the merits of unconscious thought in preference development and decision making", "reason": "This paper explores the role of unconscious thought processes in decision-making.  It's crucial to this study because it contrasts deliberate reasoning with more intuitive or unconscious processing, mirroring the comparison between direct prompting and chain-of-thought in the current study. This contrast provides a strong theoretical framework for analyzing the cases where CoT is detrimental and where it's not.", "section_number": 4}, {" publication_date": "2002", "fullname_first_author": "Jonathan W Schooler", "paper_title": "Re-representing consciousness: Dissociations between experience and meta-consciousness", "reason": "This paper provides a general theoretical framework on the nature of conscious and unconscious processing in humans. This is important for contextualizing the comparison between human deliberation and CoT in LLMs and helps to build a more nuanced theoretical understanding of how human cognitive limitations might relate to performance drops in LLMs. The comparison between conscious and unconscious processing is used to inform the design of experiments and the analysis of findings.", "section_number": 4}, {" publication_date": "2013", "fullname_first_author": "Joseph J Williams", "paper_title": "The hazards of explanation: Overgeneralization in the face of exceptions", "reason": "This paper demonstrates the negative impact of explanation on learning when exceptions to general rules exist.  The study leverages this to design an experiment to test the effects of CoT on learning from data with exceptions, showing how verbalization interferes with efficient pattern recognition. It provides the primary basis for the study's experiment examining performance on tasks involving learning with exceptions.", "section_number": 4}]}