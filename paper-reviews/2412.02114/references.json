{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational concept of diffusion models, a crucial component of OmniCreator's generative and editing capabilities."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is fundamental to OmniCreator's multimodal fusion architecture, enabling text-guided video generation and editing."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper presents Stable Diffusion, a key building block for OmniCreator, enabling efficient and high-quality image and video generation."}, {"fullname_first_author": "Jay Zhangjie Wu", "paper_title": "Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation", "publication_date": "2023-10-01", "reason": "Tune-A-Video is a highly relevant comparative method in the paper, representing a state-of-the-art approach to video editing that OmniCreator improves upon."}, {"fullname_first_author": "Ruoyu Feng", "paper_title": "Ccedit: Creative and controllable video editing via diffusion models", "publication_date": "2024-06-01", "reason": "CCEdit is another significant comparative model in the paper, providing a strong baseline for evaluating OmniCreator's video editing performance."}]}