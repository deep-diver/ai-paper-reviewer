{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational denoising diffusion probabilistic models (DDPMs) which are central to the Video Alchemist model's architecture."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP is a crucial component of Video Alchemist, enabling effective text and image conditioning."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2024-01-01", "reason": "DINOv2 serves as the image encoder in Video Alchemist, providing strong image representations for personalization."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "The Diffusion Transformer module is a key architectural innovation in Video Alchemist, facilitating efficient and effective video generation."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70M: Captioning 70M videos with multiple cross-modality teachers", "publication_date": "2024-01-01", "reason": "The Panda-70M dataset, used for training Video Alchemist, is a significant contribution to video personalization research."}]}