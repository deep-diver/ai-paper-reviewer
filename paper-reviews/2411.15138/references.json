{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper provides a comprehensive technical report on GPT-4, a large language model used in several aspects of this work, including material assignment and prompt generation."}, {"fullname_first_author": "Dave Zhenyu Chen", "paper_title": "Text2Tex: Text-driven texture synthesis via diffusion models", "publication_date": "2023-10-01", "reason": "This paper introduces the text-driven texture synthesis approach used in this work as a foundation for generating material maps from prompts, showcasing the importance of this method for material synthesis."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces the high-resolution image synthesis method using latent diffusion models which is leveraged in Material Anything as the foundation for its image-based material estimation and refinement methods."}, {"fullname_first_author": "Raphael Bensadoun", "paper_title": "Meta 3D Gen", "publication_date": "2024-07-01", "reason": "This paper proposes a framework for generating 3D objects with PBR materials from prompts or images, establishing a relevant baseline for the Material Anything model for comparison."}, {"fullname_first_author": "Matt Deitke", "paper_title": "Objaverse: A Universe of Annotated 3D Objects", "publication_date": "2023-06-01", "reason": "This paper introduces the Objaverse dataset, a large-scale dataset of 3D objects used to train Material Anything, demonstrating the critical role of this dataset in enabling the development of this method."}]}