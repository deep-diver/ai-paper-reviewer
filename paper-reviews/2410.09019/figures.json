[{"figure_path": "2410.09019/figures/figures_3_0.png", "caption": "Figure 1. Overview of MedMobile. Panel A) shows components of MultiMedQA [12], the evaluation tasks descriptions, and the number of questions in each data test set. MultiMedQA is a collection of 8 different datasets encompassing the medical domain. In tasks such as the MMLU, we test the model on its ability to perform complex reasoning tasks across medical and medical-adjacent domains. PubMedQA tests a model's ability to perform reasoned conclusions based on research-grade text. Finally, MedQA (USMLE) and MedMCQA evaluates the model on its ability to answer standardized medical questions necessary to be a licensed physician. In Panel B), we present a framework of medical Q&A evaluation and model building. MultiMedQA is used to evaluate a fine-tuned phi-3-mini model, MedMobile, and is optimized in its prompting using automatic differentiation with GPT-4 as described in TextGrad [15]. Responses are then filtered via an ensemble approach, where the most common answer is selected as the model's final answer. We also fine-tune our model on synthetic and manually medical questions, annotated with CoT by GPT-4. Panel C) exhibits a sample MedQA", "description": "The figure illustrates the components of MultiMedQA, the MedMobile framework for medical question answering, and an example output from MedMobile.", "section": "Main"}]