[{"figure_path": "2410.18071/figures/figures_1_0.png", "caption": "Figure 1: (a) shows underestimation caused by unsuitable prompts in MMT-Bench, (b) shows our proposed evaluation framework resolving this by customizing prompts.", "description": "Figure 1 demonstrates prompt sensitivity in a multimodal benchmark and illustrates the proposed TP-Eval framework for customizing prompts to improve model evaluation.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18071/figures/figures_5_0.png", "caption": "Figure 2: The overview of our automatic prompt customization structure.", "description": "This figure illustrates the overall pipeline of TP-Eval, which includes the prompt customization method to obtain the optimal prompt for a given MLLM.", "section": "4 METHOD"}]