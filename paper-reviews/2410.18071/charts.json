[{"figure_path": "2410.18071/charts/charts_7_0.png", "caption": "Figure 3: Results of different models on MMT-S (L2-category). Accuracy improvement is calculated by accuracy using the optimized prompt divided by accuracy using the original prompt. Three models showed varying improvement across different task types, while performance gains differ between models, highlighting the underestimation and bias introduced by original prompts and the effectiveness of our method.", "description": "The chart displays the accuracy improvement percentage for three different models across various tasks in the MMT-S benchmark after prompt optimization.", "section": "5.2 Main Results"}, {"figure_path": "2410.18071/charts/charts_8_0.png", "caption": "Figure 4: Overall performance with different prompt methods on MMMU with LLaVA. In most cases, the results after optimization surpass those achieved with the initial prompts, and they generally outperform the original questions as well.", "description": "The chart displays the overall performance of LLaVA on MMMU using original questions, initial prefix prompts, and optimized prefix prompts, revealing improvements through prompt optimization.", "section": "5.2 MAIN RESULTS"}, {"figure_path": "2410.18071/charts/charts_8_1.png", "caption": "Figure 5: Result of applying optimized prompts to other models. Applying customized prompts from one model to another yields performance changes that differ from each model's inherent characteristics.", "description": "The chart displays the performance changes when prompts optimized for one model are applied to other models, illustrating the model-specific nature of optimal prompts.", "section": "5.2.2 OPTIMALITY ANALYSIS"}, {"figure_path": "2410.18071/charts/charts_9_0.png", "caption": "Figure 6: Performance on whether to use introspection or not.", "description": "The chart displays the performance comparison of three different methods (original, no introspection, and the proposed method) on three tasks from the MMT-S benchmark, showing the effectiveness of incorporating introspection in the proposed method.", "section": "5.3 ABLATION STUDY"}, {"figure_path": "2410.18071/charts/charts_9_1.png", "caption": "Figure 7: Influence of re-ranking. Both excessively high and low a* can lead to a reduction in performance, and each model achieves optimal performance with a* \u2208 [0.5, 0.6].", "description": "The chart displays the impact of the re-ranking parameter (a*) on the accuracy of three different models (LLaVA, DeepSeek, and InternVL).", "section": "5.3 ABLATION STUDY"}]