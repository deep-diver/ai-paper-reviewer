[{"figure_path": "https://arxiv.org/html/2411.16341/extracted/5990804/figures/transpilation.png", "caption": "Figure 1: Conceptual representation of an asm-to-asm transpiler, which would enable direct \u201ctranslation\u201d from one machine language to another without needing the source code and by-passing the software stack.", "description": "Figure 1 illustrates the central concept of a direct assembly-to-assembly transpiler. Unlike traditional compilation methods that rely on high-level source code, this transpiler performs a direct translation between two different machine instruction sets (ISAs), such as x86 and ARM.  The process bypasses the typical software stack (compiler, linker, etc.), taking assembly code as input and producing equivalent assembly code in the target ISA as output. This offers a potential solution for translating legacy x86 code to ARM without requiring access to the original source code, resolving portability challenges in software.", "section": "3 APPROACH"}, {"figure_path": "https://arxiv.org/html/2411.16341/x1.png", "caption": "Figure 2: CRT pipeline stages: Data (AnghaBench data curation), Experimentation (model tuning and accuracy), and Optimization & Deployment (final training and Rosetta evaluation).", "description": "The figure illustrates the three main stages of the CRT (CISC to RISC transpiler) pipeline.  The Data stage involves the curation of the AnghaBench dataset, which consists of paired x86 and ARM assembly code generated from a large corpus of C programs. The Experimentation stage focuses on model selection and hyperparameter tuning using a subset of the data.  Various models are evaluated based on accuracy and other metrics to identify the optimal configuration. The Optimization & Deployment stage includes training the best-performing model on the complete dataset, followed by evaluation against Apple's Rosetta 2 transpiler to assess efficiency and performance of the transpiled code.", "section": "3.2 Training Stages and Model Selection"}, {"figure_path": "https://arxiv.org/html/2411.16341/x2.png", "caption": "(a)", "description": "The figure shows the relationship between the number of beams used during inference and the accuracy of the model for different training data sizes.  Increasing the number of beams allows the model to explore multiple decoding paths, improving accuracy at the cost of increased computational overhead. The accuracy plateaus at around 76% regardless of training data size when using only one beam.  Using multiple beams shows improved accuracy, particularly with larger training datasets, but the gains diminish as the number of beams is increased. ", "section": "Experiments and Evaluation"}, {"figure_path": "https://arxiv.org/html/2411.16341/x3.png", "caption": "(b)", "description": "The figure shows the accuracy of the DeepSeek-1.3B model over training steps, illustrating the model's performance improvement during the training process.  The graph plots accuracy against the number of training steps, revealing an overall upward trend indicating improvement in the model's ability to translate x86 assembly to ARM assembly.", "section": "3.2 Training Stages and Model Selection"}, {"figure_path": "https://arxiv.org/html/2411.16341/x4.png", "caption": "(c)", "description": "The figure shows the impact of quantization on the accuracy of the DeepSeek-1.3B model for both ARM and RISC-V64 architectures.  It compares the accuracy achieved using different quantization levels: float32 (full precision), bfloat16 (reduced precision), int8 (integer with 8 bits), and int4 (integer with 4 bits).  The graph illustrates the trade-off between model size/inference speed and accuracy resulting from quantization.  Lower bit depths generally lead to lower accuracy but also smaller model sizes and faster inference speeds.", "section": "3.2 Training Stages and Model Selection"}, {"figure_path": "https://arxiv.org/html/2411.16341/x5.png", "caption": "Figure 3: DeepSeek-1.3B performance: (a) Accuracy across beam sizes (1, 2, 4, 8) for different training data sizes. (b) Accuracy progression over training steps with a logarithmic trend. (c) Quantization impact (float32, bfloat16, int8, int4) on ARM and RISC-V64.", "description": "Figure 3 displays the performance of the DeepSeek-1.3B model in three subfigures. (a) shows how the model's accuracy on the task changes with different beam sizes (1, 2, 4, and 8) when trained on varying amounts of data. The plot demonstrates the impact of exploring multiple translation possibilities during inference.  (b) illustrates the model's accuracy improvement as training progresses, showing a logarithmic trend indicating diminishing returns from additional training. (c) examines the influence of quantization (reducing the precision of the model's numerical representations) using float32, bfloat16, int8, and int4 on the model's performance for both ARM and RISC-V64 architectures. This subfigure shows the tradeoff between accuracy and computational efficiency when using lower-precision representations.", "section": "Experiments and Evaluation"}, {"figure_path": "https://arxiv.org/html/2411.16341/x6.png", "caption": "Figure 4: Measured execution time, energy utilization, and RAM usage across different settings on Apple M2 Macbook.", "description": "This figure displays a comparison of execution time, CPU energy consumption, and RAM usage for three different scenarios on an Apple M2 MacBook: native ARM64 code execution, execution using Apple's Rosetta 2 translation layer (for x86 code), and execution of code transpiled from x86 to ARM64 using the proposed CRT method.  The results show significant performance improvements with CRT compared to Rosetta, demonstrating CRT's efficiency in executing transpiled code.", "section": "7 Case Study"}, {"figure_path": "https://arxiv.org/html/2411.16341/x7.png", "caption": "Figure 5: Confusion matrix of the proposed approach executed on QEMU (ARMv5) and M2 (ARMv8) for HumanEval programs.", "description": "This figure shows a confusion matrix that evaluates the performance of the proposed CRT (CISC-to-RISC transpiler) model on two different ARM architectures: ARMv5 (simulated using QEMU) and ARMv8 (Apple M2).  The matrix displays the counts of correct and incorrect translations for each architecture. The results are broken down by whether the translated assembly code successfully passes the HumanEval benchmark tests (indicating functional correctness).  The matrix helps to assess the accuracy and reliability of the CRT model across different hardware platforms, highlighting potential architectural-specific issues in the translation process.", "section": "7.3 ARMv5 versus ARMv8 Analysis"}, {"figure_path": "https://arxiv.org/html/2411.16341/x8.png", "caption": "Figure 6: Example Assembly Code Generated from Identical Source Program for x86, ARMv5, and ARMv8, with aligned assembly segments highlighted by functionality.", "description": "This figure compares assembly code generated from the same source code for three different architectures: x86 (CISC), ARMv5 (RISC), and ARMv8 (RISC).  It highlights how the same high-level operations translate into vastly different low-level instructions across these architectures, showcasing the complexities of translating assembly language between different instruction sets.  The alignment of code segments emphasizes the corresponding functionalities across the different ISAs, visually demonstrating the challenges inherent in assembly-to-assembly translation.", "section": "A.2 Assembly Code Comparison Across Architectures"}]