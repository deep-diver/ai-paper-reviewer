[{"content": "| Model | Param (B) | FLOPs (G) | Val. loss \u2193 | GPQA \u2191 | TriviaQA \u2191 | BBH \u2191 | HellaSwag \u2191 | WinoGrande \u2191 | Avg \u2191 |\n|---|---|---|---|---|---|---|---|---|---| \n| Dense-151M | 0.15 | 0.30 | 2.96 | 19.98 | 12.67 | 22.57 | 35.07 | 52.49 | 26.06 |\n| MoE-151M-2in32 | 2.04 | 0.35 | 2.63 | 17.30 | 33.27 | 23.24 | 48.44 | 55.96 | 33.20 |\n| UltraMem-151M-x12 | 2.03 | 0.35 | 2.67 | 19.42 | 28.97 | 22.65 | 43.96 | 50.83 | 29.99 |\n| Dense-680M | 0.68 | 1.36 | 2.64 | 21.09 | 27.16 | 24.65 | 48.83 | 54.93 | 33.27 |\n| MoE-680M-2in33 | 8.95 | 1.50 | 2.39 | 20.54 | 34.19 | 26.63 | 62.71 | 59.98 | 38.43 |\n| UltraMem-680M-x12 | 8.93 | 1.49 | 2.37 | 21.99 | 55.17 | 26.62 | 64.15 | 60.54 | 42.27 |\n| Dense-1.6B | 1.61 | 3.21 | 2.49 | 21.76 | 39.65 | 26.41 | 58.6 | 61.72 | 38.46 |\n| MoE-1.6B-2in34 | 21.36 | 3.52 | 2.30 | 21.32 | 59.56 | 29.46 | 67.34 | 63.93 | 45.07 |\n| UltraMem-1.6B-x12 | 21.41 | 3.50 | 2.24 | 24.66 | 66.38 | 30.63 | 71.52 | 66.38 | 48.26 |\n| Dense-6.5B | 6.44 | 12.88 | 2.30 | 19.98 | 57.28 | 31.14 | 69.73 | 65.9 | 46.19 |", "caption": "Table 1: Performance metrics of various models", "description": "This table presents a comparison of the performance metrics across different language models.  It includes both dense models (standard Transformer architectures) and sparse models (Mixture of Experts (MoE) and Ultra-Sparse Memory Network (UltraMem)).  The metrics shown are validation loss, and several downstream task performance scores (GPQA, TriviaQA, BBH, HellaSwag, Winogrande, DROP), along with the average score across these tasks.  Model parameters and FLOPs (floating-point operations per second) are also provided to contextualize performance in relation to model size and computational cost.", "section": "5.2 EVALUATION ON LANGUAGE MODELING DATASETS"}, {"content": "| Model | Training Loss \u2193 | Validation Loss \u2193 | Dense Params (M) | Sparse Params (G) | FLOPs (M) |\n|---|---|---|---|---|---| \n| PKM-151M-x10 | 2.604 | 2.828 | 173.01 | 1.534 | 346.06 |\n| +rm softmax | 2.570 (-0.034) | 2.822 (-0.006) | 173.01 | 1.534 | 346.06 |\n| +half vdim+proj | 2.556 (-0.014) | 2.800 (-0.022) | 178.47 | 1.529 | 356.98 |\n| +share query | 2.560 (+0.004) | 2.803 (+0.003) | 173.46 | 1.529 | 346.96 |\n| +split big mem&skip | 2.554 (-0.006) | 2.788 (-0.015) | 161.64 | 1.536 | 323.32 |\n| +query/key LN | 2.553 (-0.001) | 2.789 (+0.001) | 161.64 | 1.536 | 323.54 |\n| +IVE | 2.544 (-0.009) | 2.772 (-0.017) | 172.37 | 1.536 | 344.98 |\n| +TDQKR | 2.538 (-0.006) | 2.764 (-0.008) | 172.37 | 1.536 | 344.98 |\n| +MCS | 2.521 (-0.017) | 2.761 (-0.003) | 172.37 | 1.536 | 344.98 |\n| +improved init | 2.518 (-0.003) | 2.758 (-0.003) | 172.37 | 1.536 | 344.98 |\n| +value lr decay | 2.494 (-0.024) | 2.736 (-0.022) | 172.37 | 1.536 | 344.98 |\n| +query conv | 2.493 (-0.001) | 2.736 (0.000) | 172.38 | 1.536 | 345.02 |\n| **Total Diff** | **-0.111** | **-0.092** | **-0.64** | **+0.002** | **-1.04** |", "caption": "Table 2: Ablation study of model improvements", "description": "This table presents the results of an ablation study that systematically evaluates the impact of various design choices on the performance of the UltraMem model.  Each row represents a variation of the model, differing in a single aspect from the previous row.  The table shows the training and validation loss, the number of dense and sparse parameters, and the FLOPS (floating point operations per second).  By comparing the performance metrics across rows, the study quantifies the contribution of each modification to the overall model's effectiveness.", "section": "5.4 ABLATION"}, {"content": "| | IVE | | | | TDQKR | | | | MCS | | | |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | Baseline | E=4 | E=9 | E=16 | Baseline | r=2 | r=3 | r=4 | Baseline | h=2 | h=4 | h=8 |\n| Training loss \u2193 | 2.553 | -0.009 | -0.016 | -0.019 | 2.544 | -0.006 | -0.0065 | -0.0063 | 2.538 | -0.017 | -0.017 | -0.012 |\n| Validation loss \u2193 | 2.789 | -0.017 | -0.025 | -0.027 | 2.772 | -0.008 | -0.0084 | -0.0082 | 2.764 | -0.003 | +0.001 | +0.006 |\n| FLOPs(G) | 323.54 | +6.6% | +14.9% | +26.4% | 344.98 | +0.001% | +0.002% | +0.003% | 344.98 | +0.001% | +0.003% | +0.007% |", "caption": "Table 3: Ablation of different config on IVE, TDQKR, and MCS", "description": "This table presents the results of ablation studies conducted to evaluate the impact of different configurations on the performance of the UltraMem model.  Specifically, it analyzes the effects of Implicit Value Expansion (IVE), Tucker Decomposed Query-Key Retrieval (TDQKR), and Multi-Core Scoring (MCS) on both training loss and validation loss.  Different hyperparameters are tested for each component, allowing for a detailed comparison of their individual contributions to the overall model performance. The table shows the training and validation losses, number of parameters, and FLOPS for various configurations, enabling a quantitative assessment of the effectiveness of each ablation.", "section": "5.4 ABLATION"}, {"content": "| Configuration Key | Value |\n|---|---| \n| Weight decay | 0.1 |\n| \u03b2\u2081 | 0.9 |\n| \u03b2\u2082 | 0.95 |\n| LR | 6e-4/2.5e-4/2e-4/1.2e-4 |\n| LR end ratio | 0.1 |\n| LR schedule | cosine |\n| LR warmup ratio | 0.01 |\n| Dropout | 0.1 |\n| Batch size | 2048 |\n| Sequence length | 2048 |\n| Training step | 238418 |", "caption": "Table 4: Training hyper-parameters", "description": "This table lists the hyperparameters used during the training phase of the models in the paper.  It details settings for various aspects of the training process, including weight decay, optimization parameters (\u03b21 and \u03b22 for Adam), learning rate (LR) and its scheduling, dropout rate, batch size, sequence length, and the total number of training steps. Learning rates are specified for models with varying parameter counts (151M, 680M, 1.6B, and 6.5B parameters).", "section": "5.1 Setup"}, {"content": "| Configuration Key | Value |\n|---|---| \n| Tucker rank  r | 2 |\n| Multi-core scoring  h | 2 |\n| Virtual memory expansion  E | 4 |\n| Aux loss weight  \u03b1 | 0.001 |\n| Aux loss margin  \u03c4 | 0.15 |", "caption": "Table 5: Common UltraMem configuration", "description": "This table details the common hyperparameters used in configuring the UltraMem model.  It lists key settings and their corresponding values, providing essential information for understanding and replicating the experimental setup. These values were used consistently across the experiments involving the UltraMem model, ensuring consistency and comparability of results.", "section": "5.1 Setup"}, {"content": "| Model | Param | FLOPs | ARC-C\u2191 | GPQA\u2191 | Trivia | MMLU\u2191 | BBH | BoolQ\u2191 | Hella | Wino | AGI | DROP\u2191 | Avg\u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Dense-151M | 0.15 | 0.30 | 25.60 | 19.98 | 12.67 | 26.50 | 22.57 | 50.15 | 35.07 | 52.49 | 9.03 | 13.60 | 26.77 |\n| MoE-151M-2in32 | 2.04 | 0.35 | 26.96 | 17.30 | 33.27 | 26.58 | 23.24 | 55.96 | 48.44 | 55.96 | 9.34 | 18.57 | 31.56 |\n| UltraMem-151M-x12 | 2.03 | 0.35 | 25.68 | 19.42 | 28.97 | 25.62 | 22.65 | 47.74 | 43.96 | 50.83 | 10.00 | 14.08 | 28.89 |\n| Dense-680M | 0.68 | 1.36 | 24.06 | 21.09 | 27.16 | 24.64 | 24.65 | 46.42 | 48.83 | 54.93 | 9.44 | 22.97 | 30.42 |\n| MoE-680M-2in33 | 8.95 | 1.50 | 25.17 | 20.54 | 34.19 | 24.38 | 26.63 | 43.70 | 62.71 | 59.98 | 7.39 | 26.54 | 33.13 |\n| UltraMem-680M-x12 | 8.93 | 1.49 | 23.72 | 21.99 | 55.17 | 24.97 | 26.62 | 48.20 | 64.15 | 60.54 | 8.26 | 25.14 | 35.88 |\n| Dense-1.6B | 1.61 | 3.21 | 26.30 | 21.76 | 39.65 | 26.19 | 26.41 | 51.50 | 58.6 | 61.72 | 9.22 | 22.63 | 34.81 |\n| MoE-1.6B-2in34 | 21.36 | 3.52 | 25.43 | 21.32 | 59.56 | 26.18 | 29.46 | 42.78 | 67.34 | 63.93 | 6.63 | 28.81 | 37.14 |\n| UltraMem-1.6B-x12 | 21.41 | 3.50 | 25.94 | 24.66 | 66.38 | 24.67 | 30.63 | 59.8 | 71.52 | 66.38 | 8.77 | 29.99 | 40.88 |\n| Dense-6.5B | 6.44 | 12.88 | 28.16 | 19.98 | 57.28 | 27.68 | 31.14 | 68.2 | 69.73 | 65.9 | 9.23 | 33.12 | 41.04 |", "caption": "Table 6: Model parameter setting. Top-m\ud835\udc5amitalic_m means chosen expert number in MoE, means chosen value number times head number in UltraMem. Kdim means the key dimension in UltraMem. Knum means the number of keys, Knum2 is the number of values.", "description": "Table 6 provides a detailed breakdown of the model parameters used in the experiments, differentiating between dense models and sparse models (MoE and UltraMem). For dense models, it shows the hidden dimension, inner dimension, attention heads, number of layers, and total parameters and FLOPs.  For sparse models, it clarifies the meaning of key parameters: Top-m (number of experts chosen in MoE, or number of values multiplied by the number of heads in UltraMem), Kdim (key dimension in UltraMem), and Knum (number of keys in UltraMem, with Knum\u00b2 representing the number of values). This table is crucial for understanding the architectural differences and computational complexities across various model configurations.", "section": "5.1 Setup"}]