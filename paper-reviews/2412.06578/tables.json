[{"content": "| Method | Steps | PickScore\u2191 | CLIPFrame\u2191 | TFLOPs (per frame) | Latency (GPU) | Latency (Phone) |\n|---|---|---|---|---|---|---|\n| Fairy | 10 | 19.80 | 0.933 | - | - | - |\n| TokenFlow | 50 | 20.49 | 0.940 | 109.35 | 2.45s | - |\n| Rerender-A-Video | 20 | 19.58 | 0.909 | 107.52 | 2.13s | - |\n| ControlVideo | 50 | 20.06 | 0.930 | 89.49 | 5.63s | - |\n| InsV2V | 20 | 20.76 | 0.911 | 52.21 | 2.70s | - |\n| RAVE | 50 | 20.35 | 0.932 | 83.09 | 4.31s | - |\n| EVE | - | 20.76 | 0.922 | - | - | - |\n| Base Model | 10 | 20.34 | 0.943 | 21.31 | 1.37s | 7s |\n| + Mobile-Pix2Pix | 10 | 19.43 | 0.922 | 16.10 | 1.06s | 1.9s |\n| + Multi-Guidance Dist. | 10 | 19.60 | 0.919 | 5.50 | 0.82s | 0.6s |\n| + Adversarial Distillation | 1 | 19.40 | 0.913 | 0.76 | 0.11s | 0.08s |", "caption": "Table 1: End-to-end FLOPs and latency of video editing models on 480\u00d7480480480480\\times 480480 \u00d7 480 resolution on TGVE benchmark, normalized per frame. On-device latencies reported on 512\u00d7384512384512\\times 384512 \u00d7 384 frames. PickScore and CLIPFrame for competing methods (except RAVE) are from InsV2V\u00a0[7].", "description": "This table compares the computational efficiency and speed of various video editing models, including the proposed MoViE model, on the TGVE benchmark.  It shows the total number of floating point operations (FLOPs) per frame, GPU processing latency, and mobile phone processing latency for each model.  The resolution used for FLOP and GPU latency calculations was 480x480 pixels, while mobile phone latency was measured at 512x384 pixels.  For comparison, the table also includes the PickScore and CLIPFrame quality metrics reported in the InsV2V paper [7] for several existing models.  The number of diffusion steps used by each model is also listed.", "section": "4. Experiments"}, {"content": "| Type of Ablation | Ablation detail | CLIP-Image |\n|---|---|---|\n| Noise Distribution | m=0, s=1 | 0.759 |\n|  | m=-1, s=1 | 0.769 |\n|  | m=-1, s=2 | 0.765 |\n| Head Architecture | No guidance conditioning | 0.781 |\n|  | With guidance conditioning | 0.786 |", "caption": "Table 2: Ablation study on discriminator design choices in adversarial training.", "description": "This table presents the results of an ablation study investigating the impact of different discriminator design choices on the performance of adversarial training in the MoViE model.  Specifically, it examines the effects of varying the noise distribution and the presence or absence of guidance conditioning within the discriminator's architecture on the model's ability to generate high-quality, controlled edits. The results are quantified using the CLIP-Image similarity metric, which assesses how well the generated images align with the input images and editing instructions.", "section": "4. Experiments"}]