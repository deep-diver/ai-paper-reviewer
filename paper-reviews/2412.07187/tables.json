[{"content": "| Method | EMNIST (20 clients) | EMNIST (100 clients) | Fashion-MNIST (20 clients) | Fashion-MNIST (100 clients) | CIFAR-10 (20 clients) | CIFAR-10 (100 clients) | CINIC-10 (20 clients) | CINIC-10 (100 clients) |\n|---|---|---|---|---|---|---|---|---|\n| Local-only | 73.41 | 75.68 | 85.93 | 87.01 | 65.47 | 66.11 | 63.60 | 64.84 |\n| FedAvg | 72.77 | 78.87 | 85.67 | 88.11 | 70.02 | 76.24 | 57.00 | 59.11 |\n| pFedHN | **80.86** | 77.37 | 87.64 | 89.80 | 70.18 | **80.07** | 63.88 | 70.36 |\n| DP-FedAvg | 35.12 | 45.73 | 59.88 | 68.29 | 29.12 | 32.03 | 27.30 | 29.94 |\n| CENTAUR | 68.82 | 67.24 | 83.07 | 79.77 | 50.85 | 51.86 | 48.82 | 51.01 |\n| PPSGD | 71.16 | 71.18 | 84.47 | 82.94 | 52.17 | 53.92 | 49.98 | 52.91 |\n| HyperFL | 76.29 | **80.22** | **88.28** | **90.41** | **73.03** | 78.73 | **66.74** | **72.21** |", "caption": "Table 1: The comparison of final test accuracy (%) of different methods on various datasets. We apply full participation for FL system with 20 clients, and apply client sampling with rate 0.3 for FL system with 100 clients.", "description": "This table compares the final test accuracy achieved by different federated learning (FL) methods on four image classification datasets (EMNIST, Fashion-MNIST, CIFAR-10, and CINIC-10).  The accuracy is presented for two scenarios: one with full participation of 20 clients and another with client sampling (30% participation rate) of 100 clients. This comparison highlights the performance differences between various FL approaches, including FedAvg, a baseline FL algorithm, privacy-preserving techniques like DP-FedAvg, PPSGD, and CENTAUR, and other algorithms like pFedHN and the proposed HyperFL method. It demonstrates how the proposed HyperFL method compares to state-of-the-art methods in terms of model accuracy.", "section": "5 Experiments"}, {"content": "|       | Arch   | Local-only\u2020 | Local-only\u2020\u2020 | FedAvg\u2020 | FedAvg\u2020\u2020 | HyperFL-LPM |\n| :---- | :----: | :--------: | :--------: | :-----: | :-----: | :--------: |\n| EMNIST | ResNet | 72.83      | 80.35      | 68.99   | 75.21   | 80.32      |\n|        | ViT    | 76.95      | 80.04      | 70.92   | 76.42   | 79.92      |\n| CIFAR-10 | ResNet | 68.57      | 73.57      | 62.35   | 75.57   | 75.03      |\n|        | ViT    | 91.82      | 89.70      | 92.32   | 95.56   | 95.40      |", "caption": "Table 2: The comparison of final test accuracy (%) of different methods on various datasets with 20 clients. \u2020 Fixed feature extractor. \u2020\u2020 Adapter fine-tuning.", "description": "This table compares the performance of different federated learning methods on four image classification datasets (EMNIST, Fashion-MNIST, CIFAR-10, and CINIC-10) using 20 clients.  The methods compared include a local-only baseline, FedAvg (a standard federated learning algorithm), and HyperFL (the proposed method) with two configurations: one using a fully trainable feature extractor and another using a pre-trained model with only adapter parameters fine-tuned.  The table shows the final test accuracy achieved by each method, highlighting HyperFL's superior performance compared to the baselines and other approaches.  The use of \u2020 and \u2020\u2020 symbols indicates whether the feature extractor was fixed (pre-trained) or fully trainable, respectively, for different model configurations.", "section": "5 Experiments"}, {"content": "| Method | EMNIST PSNR | EMNIST SSIM | EMNIST LPIPS | CIFAR-10 PSNR | CIFAR-10 SSIM | CIFAR-10 LPIPS |\n|---|---|---|---|---|---|---|\n| FedAvg | 32.64 | 0.8925 | 0.0526 | 16.16 | 0.6415 | 0.0536 |\n| pFedHN | 31.24 | 0.8701 | 0.0807 | 16.02 | 0.6351 | 0.0504 |\n| pFedHN-PC | 28.38 | 0.8713 | 0.0645 | 15.80 | 0.6247 | 0.4407 |\n| DP-FedAvg | 7.74 | 0.2978 | 0.7051 | 7.90 | 0.2716 | 0.3204 |\n| CENTAUR | 9.52 | 0.2136 | 0.6712 | 9.80 | 0.2723 | 0.2882 |\n| PPSGD | 9.73 | 0.1889 | 0.6466 | 9.70 | 0.2788 | 0.2643 |\n| HyperFL | 7.85 | 0.3010 | 0.7147 | 8.35 | 0.2732 | 0.3132 |", "caption": "Table 3: Reconstruction results of IG.", "description": "This table presents the results of applying the Gradient Inversion (IG) attack to reconstruct the original training data from the gradients shared during federated learning.  It compares the performance of several different federated learning methods, including FedAvg, pFedHN, DP-FedAvg, CENTAUR, PPSGD and HyperFL, in terms of their ability to protect against this type of attack. The reconstruction quality is measured using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS). Higher PSNR and SSIM values and lower LPIPS indicate that the original image has been reconstructed more accurately, implying weaker privacy protection. ", "section": "4 Privacy Protection Analysis"}, {"content": "| | FedAvg | DP-FedAvg | PPSGD | CENTAUR | HyperFL |\n|---|---|---|---|---|---| \n| # Time (s) | 23 | 194 | 223 | 210 | 37 |", "caption": "Table 4: Training time of per training round on the EMNIST dataset with 20 clients of different methods.", "description": "This table presents the training time for each round of different federated learning methods using the EMNIST dataset with 20 clients. It compares the training efficiency of the proposed HyperFL framework with other differentially private federated learning methods (DP-FedAvg, PPSGD, CENTAUR) and the standard FedAvg method. The time is measured in seconds.", "section": "5 Experiments"}, {"content": "|---|---|---|---|---|---|---|\n|Method|EMNIST PSNR|EMNIST SSIM|EMNIST LPIPS|CIFAR-10 PSNR|CIFAR-10 SSIM|CIFAR-10 LPIPS|\n|FedAvg|24.26|0.9516|0.3024|23.09|0.9228|0.4363|\n|HyperFL|3.44|0.0459|0.7883|7.78|0.0137|0.7802|\n", "caption": "Table 5: Reconstruction results of ROG.", "description": "This table presents the results of the Reconstructed Original Images using the ROG (Reconstructed Original Gradient) attack method.  It shows the PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity) scores for the FedAvg and HyperFL models on the EMNIST and CIFAR-10 datasets.  These metrics quantify the quality of the reconstructed images and are used to evaluate the privacy-preserving capabilities of the models against ROG attacks.  Lower LPIPS and higher PSNR/SSIM indicate better privacy protection.", "section": "5.2 Experimental Results"}]