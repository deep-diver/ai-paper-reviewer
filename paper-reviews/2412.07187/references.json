{"references": [{"fullname_first_author": "McMahan, H.B.", "paper_title": "Communication-efficient learning of deep networks from decentralized data", "publication_date": "2017-00-00", "reason": "This paper introduces federated learning (FL), a privacy-preserving machine learning technique that is central to the current work."}, {"fullname_first_author": "Fredrikson, M.", "paper_title": "Model inversion attacks that exploit confidence information and basic countermeasures", "publication_date": "2015-00-00", "reason": "This paper introduces gradient inversion attacks (GIAs), a significant privacy threat in FL that motivates this research."}, {"fullname_first_author": "Geiping, J.", "paper_title": "Inverting gradients-how easy is it to break privacy in federated learning?", "publication_date": "2020-00-00", "reason": "This paper highlights the vulnerability of federated learning to gradient inversion attacks, directly informing the design of the proposed HyperFL framework."}, {"fullname_first_author": "Ha, D.", "paper_title": "HyperNetworks", "publication_date": "2017-00-00", "reason": "This paper introduces hypernetworks, a core component of the HyperFL framework, providing the foundation for its privacy-enhancing architecture."}, {"fullname_first_author": "Zhu, L.", "paper_title": "Deep leakage from gradients", "publication_date": "2019-00-00", "reason": "This paper presents another important gradient inversion attack, furthering the understanding of privacy vulnerabilities in FL and informing defense strategies like HyperFL."}]}