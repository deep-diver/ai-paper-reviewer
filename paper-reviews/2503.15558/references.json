{"references": [{"fullname_first_author": "Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture, which has revolutionized the field of language modeling and is a foundational building block for many modern AI models."}, {"fullname_first_author": "Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-01-01", "reason": "This paper presents Flamingo, a visual language model that is important in the context of multimodal AI, as this paper is referenced as a comparison in capabilities."}, {"fullname_first_author": "Liu", "paper_title": "LLAVA: Visual Instruction Tuning", "publication_date": "2023-01-01", "reason": "This paper introduces LLaVA, a visual language model that adopts a decoder-only architecture, a popular architectural decision used to simplify multimodal architectures."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-01", "reason": "This paper presents a specific framework and technique that has inspired the rewards and processes of this paper's Physical AI reasoning models."}, {"fullname_first_author": "Chen", "paper_title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2024-01-01", "reason": "This paper provides the foundation for the vision encoder used in this Physical AI paper."}]}