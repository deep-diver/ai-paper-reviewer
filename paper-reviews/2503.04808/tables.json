[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1\">\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.2.1\">Avg.</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.1\">AIME</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.5\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.5.1\">AMC</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.6\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.6.1\">Minerva</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.7\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.7.1\">Olympiad</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.2.1\">Accuracy</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.3.1\">MATH500</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.4.1\">2024</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.5\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.5.1\">2023</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.6\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.6.1\">Math</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.2.7\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.7.1\">Bench</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Multi-Attempt</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">45.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">73.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">20.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">35.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.7\" style=\"padding-top:1pt;padding-bottom:1pt;\">33.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T1.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">43.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">13.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">55.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">35.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.4.7\" style=\"padding-top:1pt;padding-bottom:1pt;\">37.5</td>\n</tr>\n</table>", "caption": "Table 1: Comparison of evaluation accuracy across multiple benchmarks.", "description": "This table presents a comparison of the average evaluation accuracy achieved by two different LLMs across five distinct benchmarks: AIME 2024, MATH 500, AMC 2023, Minerva Math, and OlympiadBench.  The two models are differentiated by their training methodology: one model was trained using a multi-attempt approach, while the other used a standard baseline method (single-turn).  The accuracy for each benchmark is shown for both models, allowing for a direct comparison of their performance based on different training strategies.", "section": "4 Experiments"}]