[{"figure_path": "https://arxiv.org/html/2411.02844/extracted/5978472/Chapters/figures/Image_models.png", "caption": "Figure 1: Comparison of outputs generated from various saliency and depth prediction models alongside the original image and annotations.", "description": "Figure 1 displays a comparative analysis of visual saliency and depth prediction models' outputs. It presents the original image from the COCO dataset alongside its ground truth annotations (mask), corresponding depth maps generated by Depth Anything and DPT-Large models, and saliency maps produced by Itti's model and DeepGaze IIE.  This visual comparison helps illustrate the differences in the information captured by each model and how these might relate to the original image and ground truth.", "section": "II. BACKGROUND"}, {"figure_path": "https://arxiv.org/html/2411.02844/extracted/5978472/Chapters/figures/image_grid.png", "caption": "Figure 2: Sample images from the COCO dataset along with their corresponding ground truth masks, depth maps generated by the Depth Anything Model, and Pearson correlation values.", "description": "Figure 2 presents a visual comparison of the Depth Anything model's performance on the COCO dataset.  It displays several sample images from the dataset alongside their corresponding ground truth segmentation masks (showing the true object boundaries).  Next to each image is the depth map produced by the Depth Anything model, illustrating its estimation of depth at each pixel. Finally, a Pearson correlation value is provided for each image, quantifying the similarity between the model's generated depth map and the ground truth mask.  This figure demonstrates how well the model's predictions align with the actual depth information in the images, and provides a visual way to understand the model's accuracy on different types of images within the COCO dataset.", "section": "V. EVALUATION"}, {"figure_path": "https://arxiv.org/html/2411.02844/extracted/5978472/Chapters/figures/image_grid_deepgaze.png", "caption": "Figure 3: Sample images from the Pascal VOC dataset along with their corresponding ground truth masks, saliency maps generated by the DeepGaze IIE Model, and Pearson correlation values.", "description": "Figure 3 shows example images from the Pascal VOC dataset.  For each image, it displays the original image, the ground truth segmentation mask (highlighting the object boundaries), a saliency map produced by the DeepGaze IIE model (showing areas of visual importance), and the Pearson correlation coefficient calculated between the saliency map and ground truth mask.  The Pearson correlation coefficient quantifies the similarity between the model's prediction of visually salient areas and the actual locations of the objects.", "section": "V. EVALUATION"}]