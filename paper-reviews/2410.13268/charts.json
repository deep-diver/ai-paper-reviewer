[{"figure_path": "2410.13268/charts/charts_8_0.png", "caption": "Figure 3: Distribution of three types of training data used by various models", "description": "The chart shows the distribution of speech, audio, and music training data used in five different speech LLMs.", "section": "4.1 Limited Types of Training Data"}, {"figure_path": "2410.13268/charts/charts_8_1.png", "caption": "Figure 4: Representation similarity of different speeches. Each speech pair has the same content but is spoken in a different style. The representation is generated by the Whisper encoder.", "description": "The chart displays the cosine similarity of speech embeddings generated by Whisper, comparing speech with different emotions and genders, and short versus long speech segments.", "section": "4.2 Inability to Comprehensively Perceive Acoustic Information"}, {"figure_path": "2410.13268/charts/charts_9_0.png", "caption": "Figure 5: Performance of speech LLMs with different instructions on speaker age task (left) and scene classification task (right). Gray line shows random selection accuracy. Details about the instructions and results are shown in App. D.", "description": "The chart displays the performance of different speech LLMs on speaker age and scene classification tasks using various instructions, comparing their accuracy against random selection.", "section": "4.3 Inadequate Instruction Following"}]