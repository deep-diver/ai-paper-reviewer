{"importance": "This paper is important for researchers as it introduces a novel framework that **significantly improves material retrieval accuracy** by bridging the gap between visual and material properties. The comprehensive dataset and innovative approach open new avenues for research in 3D asset generation, AR/VR, and digital content creation, enhancing the realism and context-awareness of virtual environments.", "summary": "MaRI: Accurately retrieves textures from images by bridging the gap between visual representations and material properties across diverse domains.", "takeaways": ["MaRI framework aligns visual and material properties in a shared embedding space.", "The framework constructs a comprehensive dataset comprising synthetic and real-world materials.", "MaRI outperforms existing methods in material retrieval tasks, demonstrating superior accuracy and generalization capabilities."], "tldr": "Existing methods for material retrieval rely on datasets that are shape-invariant and lighting-varied representations of materials, which are scarce and face challenges due to limited diversity and inadequate real-world generalization. Current approaches adopt traditional image search techniques, falling short in capturing the unique properties of material spaces and resulting in suboptimal retrieval performance. \n\nThis paper introduces **MaRI, a framework designed to bridge the feature space gap between synthetic and real-world materials**. MaRI constructs a shared embedding space that harmonizes visual and material attributes through contrastive learning and constructs a comprehensive dataset. Experiments demonstrate superior retrieval performance.", "affiliation": "University of Electronic Science and Technology of China", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.08111/podcast.wav"}