[{"content": "| Task Type | FLUX+GPT4o | DALL-E3+GPT4o | SD3+GPT4o | Pixart+GPT4o | InstructPix2Pix | MagicBrush | Anole | Emu2 | OmniGen | ChatDiT |\n|---|---|---|---|---|---|---|---|---|---|---| \n| T2I | **46.06** | 24.34 | 24.04 | 14.44 | 0 | 0 | 0 | 17.98 | 21.41 | **50.91** |\n| I2I | 12.13 | 6.95 | 10.79 | 7.75 | 17.58 | **19.07** | 0.64 | 7.05 | 8.17 | **21.58** |\n| Is2I | 4.89 | **5.27** | 4.69 | 3.48 | 0 | 0 | 0 | **8.98** | 2.77 | 2.36 |\n| T2Is | 20.15 | 14.36 | **21.59** | 17.46 | 0 | 0 | 1.74 | 0 | 0 | **27.77** |\n| Is2Is | **29.17** | 14.44 | 13.06 | **21.39** | 0 | 0 | 0 | 0 | 0 | 13.33 |\n| **Avg.** | **22.48** | 13.07 | 14.83 | 12.90 | 3.52 | 3.81 | 0.48 | 6.80 | 6.47 | **23.19** |", "caption": "Table 1: Comparison of ChatDiT with other models across various tasks on IDEA-Bench (Liang et\u00a0al., 2024). Performance metrics are reported for different task types: T2I (Text-to-Image), I2I (Image-to-Image), Is2I (Image set to Image), T2Is (Text-to-Image set), and Is2Is (Image set to Image set). \u201c+GPT4o\u201d indicates that user instructions and uploaded images are reformulated into per-output-image prompts, enabling text-to-image models to generate results. The top two scores for each task are highlighted in red (best) and blue (second best).", "description": "This table compares the performance of ChatDiT, a training-free image generation model, with other existing models on IDEA-Bench, a comprehensive benchmark for visual design tasks.  The table includes metrics for Text-to-Image (T2I), Image-to-Image (I2I), Image set to Image (Is2I), Text-to-Image set (T2Is), and Image set to Image set (Is2Is) generation. Some competing models use a \u201c+GPT4o\u201d approach, meaning they leverage GPT-4 to rephrase instructions and images into prompts for individual image generation.  The highest and second-highest scores for each task type are highlighted for easy comparison.", "section": "4.3 Results on IDEA-Bench"}]