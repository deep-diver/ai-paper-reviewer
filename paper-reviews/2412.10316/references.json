{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper introduced the foundational framework of denoising diffusion probabilistic models, which is the core generative model used in the described research and many modern image editing and generation techniques."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This work presents Latent Diffusion Models (LDMs) which enable high-resolution image synthesis and have become a widely used model in image editing tasks, forming the basis for several methods discussed in the paper."}, {"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2022-05-01", "reason": "This paper introduces Glide, a diffusion model that allows for guided image generation and editing using text prompts, a key capability referenced throughout the paper for instruction-based image manipulation."}, {"fullname_first_author": "Tero Karras", "paper_title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation", "publication_date": "2017-01-01", "reason": "While superseded by diffusion models, this work introduced progressive growing for GANs, significantly improving image generation quality and impacting subsequent inpainting approaches; the paper compares its methods against this important baseline."}, {"fullname_first_author": "Andrew Hertz", "paper_title": "Prompt-to-prompt image editing with cross-attention control", "publication_date": "2022-01-01", "reason": "This paper introduces a method for editing images based on user instructions by controlling the cross-attention layers of a diffusion model, a key related work for the instruction-based editing approach discussed."}]}