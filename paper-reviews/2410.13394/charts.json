[{"figure_path": "2410.13394/charts/charts_6_0.png", "caption": "Figure 3: Comparison of LLM score vs True score when the difference between the predictions is =1 and \u22652. We see that LLM Evaluator is more generous and awards higher scores. Refer Sec. \u00a75.3 for detailed results.", "description": "The chart compares LLM evaluation scores versus true scores for model responses, highlighting the tendency of LLMs to be more generous in their assessments.", "section": "5 Results"}, {"figure_path": "2410.13394/charts/charts_16_0.png", "caption": "Figure 4: Fertility scores of tokenizers for all baseline models.", "description": "The chart displays the fertility scores of various tokenizers used in the experiments across six different languages.", "section": "3 CIA: Cross Lingual Auto Evaluation"}]