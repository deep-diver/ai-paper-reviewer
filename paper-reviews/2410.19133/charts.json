[{"figure_path": "2410.19133/charts/charts_6_0.png", "caption": "Figure 3: Predicted and actual RewardBench scores for 16 held-out candidate datasets using the quadratic PPM.", "description": "The chart displays a strong positive correlation between the predicted and actual RewardBench scores of 16 held-out candidate datasets, indicating the effectiveness of the quadratic PPM in performance prediction.", "section": "4.1 DETAILS OF THE PERFORMANCE PREDICTION MODEL"}, {"figure_path": "2410.19133/charts/charts_6_1.png", "caption": "Figure 4: Comparison between our routing framework and random selection given different annotation budgets on various preference datasets. The optimal budget and its corresponding performance is marked by a star (\u2605). We report the average of the RewardBench score across three runs.", "description": "The chart compares the performance of reward models trained on hybrid annotations generated by the routing framework versus those trained on randomly mixed human and synthetic annotations, across different annotation budgets for four datasets.", "section": "4.2 GENERALIZATION TO UNSEEN PREFERENCE DATASETS"}, {"figure_path": "2410.19133/charts/charts_35_0.png", "caption": "Figure 8: Top ten subject of expertise needed to annotate instances for a subset routed to GPT-4 (left) and subset routed to Humans (right) in Helpsteer2.", "description": "The bar chart compares the proportion of instances needing specific subject expertise for human annotation versus GPT-4 annotation in the Helpsteer2 dataset.", "section": "K.1 Analysis of Helpsteer2 Instances"}, {"figure_path": "2410.19133/charts/charts_36_0.png", "caption": "Figure 8: Top ten subject of expertise needed to annotate instances for a subset routed to GPT-4 (left) and subset routed to Humans (right) in Helpsteer2.", "description": "The chart compares the proportion of instances routed to either GPT-4 or human annotators based on the required subject expertise for Helpsteer2.", "section": "K.1 ANALYSIS OF HELPSTEER2 INSTANCES"}, {"figure_path": "2410.19133/charts/charts_38_0.png", "caption": "Figure 4: Comparison between our routing framework and random selection given different annotation budgets on various preference datasets. The optimal budget and its corresponding performance is marked by a star (\u2605). We report the average of the RewardBench score across three runs.", "description": "The chart compares the performance of reward models trained on hybrid preference datasets created using the proposed routing framework versus those trained using randomly sampled mixtures of human and LM annotations, across different annotation budgets.", "section": "4.2 GENERALIZATION TO UNSEEN PREFERENCE DATASETS"}, {"figure_path": "2410.19133/charts/charts_39_0.png", "caption": "Figure 12: Comparison between our routing framework and a random selection given different annotation budgets on the Helpsteer2-Preferences dataset (Wang et al., 2024b).", "description": "The chart compares the RewardBench scores of reward models trained on hybrid annotations generated by the routing framework versus those trained on randomly mixed human and synthetic preferences for varying proportions of human annotations in the Helpsteer2-Preferences dataset.", "section": "4.2 Generalization to unseen preference datasets"}]