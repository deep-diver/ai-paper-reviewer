[{"figure_path": "https://arxiv.org/html/2412.02030/x2.png", "caption": "Figure 1: \nOur one-step diffusion pipeline generates vibrant and photorealistic images with exceptional detail in a single inference step, broadening the potential for text-to-image synthesis in applications like real-time interactive systems.", "description": "This figure showcases the high-fidelity image generation capabilities of the NitroFusion model.  It presents several example images produced by the one-step diffusion pipeline, demonstrating the model's ability to generate vibrant and photorealistic images with exceptional detail in a single inference step. The improved efficiency and quality of the NitroFusion model is highlighted, expanding the potential of text-to-image synthesis for real-time applications.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.02030/x3.png", "caption": "Figure 2: \nOur method distils a multi-step teacher model into an efficient one-step student generator. The Dynamic Adversarial Framework provides dynamic, stable feedback via a large dynamic Discriminator Head Pool, dynamically sampling a subset of heads in each iteration to provide unbiased and stable feedback to judge real or fake, effectively balancing one-step efficiency with high-quality generation.", "description": "This figure illustrates the distillation process of NitroFusion, a method that transforms a multi-step teacher diffusion model into a fast, one-step student model.  The key innovation is the Dynamic Adversarial Framework. It uses a large pool of discriminator heads, each specializing in different aspects of image quality at various noise levels.  In each training iteration, a subset of these heads is randomly selected to provide diverse and unbiased feedback to the student generator.  This dynamic approach prevents overfitting and ensures that the student model generates high-quality images, even in a single step.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.02030/x4.png", "caption": "Figure 3: \nOur discriminator employs a frozen UNet backbone with a dynamic pool of discriminator heads. At each iteration, a subset of heads is sampled and trained, with 1% of all heads randomly reinitialized to maintain diverse signals and prevent overfitting.", "description": "The figure illustrates the architecture of the discriminator used in the NitroFusion model.  It shows a frozen UNet backbone, acting as a feature extractor, with multiple lightweight discriminator heads attached at different levels. These heads are dynamically sampled for training at each iteration. A key aspect is the 'pool refresh' mechanism which periodically reinitializes 1% of the heads, preventing overfitting and maintaining a diverse range of feedback for high-quality image generation.", "section": "3.2. Dynamic Discriminator Pool"}, {"figure_path": "https://arxiv.org/html/2412.02030/x5.png", "caption": "Figure 4: \nVisual comparison of our models (NitroSD-Realism and NitroSD-Vibrant) against multi-step SDXL\u00a0[34], our teacher models (4-step DMD2\u00a0[52] and 8-step Hyper-SDXL\u00a0[37]), and selected 1-step state-of-the-art baselines\u00a0[42, 23].", "description": "This figure compares the image generation quality of two new models, NitroSD-Realism and NitroSD-Vibrant, with several other models.  It shows the results of generating images using different models, including multi-step models (SDXL, DMD2, and Hyper-SDXL) and single-step models (SDXL-Turbo, SDXL-Lightning). The comparison highlights the improved fidelity and detail achieved by the new NitroSD models, especially when compared to other single-step methods. The prompts used for image generation are also displayed.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02030/x6.png", "caption": "Figure 5: \nUser preferences study with other baseline models.", "description": "This figure shows the results of a user preference study comparing the image quality of NitroSD-Realism and NitroSD-Vibrant against other baseline models.  The study involved participants choosing between pairs of images generated by different models, allowing for a quantitative evaluation of user preference for each model. This helps to demonstrate the relative quality of NitroSD models compared to other state-of-the-art single and multi-step diffusion models.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02030/x7.png", "caption": "Figure 6: \nVisual comparison of our models (NitroSD-Realism and NitroSD-Vibrant) with other approaches across multiple steps, highlighting the clarity and improving quality of our method from 1-step to 4-step inference.", "description": "Figure 6 presents a visual comparison of the performance of the models NitroSD-Realism and NitroSD-Vibrant against other state-of-the-art approaches across multiple inference steps (1, 2, and 4).  The figure highlights a key advantage of NitroFusion: the progressive improvement in image clarity and overall quality as the number of inference steps increases. This demonstrates the model's ability to refine generated images effectively with increased computational cost.", "section": "4.1. Qualitative Comparison"}, {"figure_path": "https://arxiv.org/html/2412.02030/x8.png", "caption": "Figure 7: \nQualitative study of ablative configurations", "description": "This figure shows the results of an ablation study, which systematically removes components from the NitroFusion model to assess their individual contributions. By comparing the generated images with different components removed, it is possible to understand how these components impact the overall quality and characteristics of the generated images. The ablation study includes removing the multi-scale dual-objective GAN training, the pool refresh mechanism, and the dynamic discriminator pool. The results show the impact of each of these components on the generation quality.", "section": "4.5. Ablation Study"}, {"figure_path": "https://arxiv.org/html/2412.02030/x10.png", "caption": "Figure 8: \nResults from applying NitroSD-Realism to anime\u00a0[3] and oil painting\u00a0[5] base models. Our model effectively adapts to different artistic styles.", "description": "This figure demonstrates the adaptability of the NitroSD-Realism model to various artistic styles.  By applying the model's weights to pre-trained models specialized in anime and oil painting, the authors showcase its ability to generate images consistent with these styles without requiring additional training.  This highlights the model's generalization capabilities beyond the dataset it was originally trained on, indicating its robustness and potential for broader applications.", "section": "4.6. Extending to Diverse Teacher Models"}, {"figure_path": "https://arxiv.org/html/2412.02030/x11.png", "caption": "Figure 9: \n1- to 4-step refinement process of our NitroSD-Realism and -Vibrant, illustrating the progressive enhancement of image quality and detail across steps.", "description": "Figure 9 presents a visual comparison of the progressive enhancement in image quality and detail achieved through a bottom-up refinement process in the NitroFusion model.  It shows the results generated by the NitroSD-Realism and NitroSD-Vibrant models at 1, 2, and 4 steps of refinement. This helps to illustrate how increasing the number of steps improves image sharpness, clarity, and overall visual fidelity, demonstrating the model's ability to produce high-quality images with flexible and efficient deployment.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.02030/x12.png", "caption": "Figure 10: Additional visual comparison with state-of-the-art approaches.", "description": "Figure 10 presents a visual comparison of image generation results between NitroFusion (the model proposed in the paper) and several state-of-the-art single-step and multi-step diffusion models.  For multiple prompts, it shows the outputs of the 25-step SDXL baseline model, the single-step SDXL-Turbo, SDXL-Lightning, and DMD2 models, the 4-step DMD2 model, and finally, the single-step results of NitroSD-Realism and NitroSD-Vibrant. This allows for a direct comparison of image quality and detail across different models and approaches, highlighting the strengths of NitroFusion in terms of achieving high fidelity even in a single-step generation.", "section": "Experiments"}]