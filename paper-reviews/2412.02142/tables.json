[{"content": "| Category | General Mechanism | Example Models and Methods |\n|---|---|---|\n| **Personalized MLLM Text Generation** | Instruction (Sec. 3.1) | CGSMP Yong et al. (2023), ModICT Li et al. (2024c) |\n| (**Section 3**) | Alignment (Sec. 3.2) | MPDialog Agrawal et al. (2023), Athena 3.0 Fan et al. (2023) |\n|  | Generation (Sec. 3.3) | Wu et al. (2024b), PTSCG Wang et al. (2024a) |\n|  | Fine-tuning (Sec. 3.4) | Wang et al. (2023), PVIT Pi et al. (2024) |\n| **Personalized MLLM Image Generation** | Instruction (Sec. 4.1) | MuDI Jang et al. (2024), Zhong et al. (2024) |\n| (**Section 4**) | Alignment (Sec. 4.2) | \u03bb-ECLIPSE Patel et al. (2024), MoMA Song et al. (2024) |\n|  | Generation (Sec. 4.3) | Layout-and-Retouch Kim et al. (2024), Instantbooth Shi et al. (2024a) |\n|  | Fine-tuning (Sec. 4.4) | MS-Diffusion Wang et al. (2024d), UNIMO-G Li et al. (2024a) |\n| **Personalized MLLM Recommendation** | Instruction (Sec. 5.1) | InteraRec Karra and Tulabandhula (2024), X-Reflect Lyu et al. (2024b) |\n| (**Section 5**) | Alignment (Sec. 5.2) | PMG Shen et al. (2024), MMREC Tian et al. (2024) |\n|  | Generation (Sec. 5.3) | RA-Rec Yu et al. (2024), Wei et al. (2024a) |\n|  | Fine-tuning (Sec. 5.4) | GPT4Rec Zhang et al. (2024), MMSSL Wei et al. (2023) |\n| **Personalized MLLM Retrieval** | Instruction (Sec. 6.1) | ConCon-Chi Rosasco et al. (2024), Med-PMC Liu et al. (2024a) |\n| (**Section 6**) | Alignment (Sec. 6.2) | AlignBot Chen et al. (2024c), Xu et al. (2024) |\n|  | Generation (Sec. 6.3) | Ye et al. (2024a), Yo\u2019LLaVA Nguyen et al. (2024) |\n|  | Fine-tuning (Sec. 6.4) | FedPAM Feng et al. (2024), VITR Gong et al. (2023) |", "caption": "Table 1: Overview of Techniques for Personalized Multimodal Large Language Models (Sections\u00a03-6).", "description": "This table provides a categorized overview of the techniques used for personalization in multimodal large language models (MLLMs).  It groups techniques based on four key categories: Text Generation, Image Generation, Recommendation, and Retrieval. Within each category, it lists example models and methods that utilize different mechanisms such as instruction, alignment, generation, and fine-tuning to achieve personalization.  The table serves as a quick reference to understand the range of approaches used in personalizing MLLMs for different tasks and modalities.", "section": "2 Overview of Challenges and Techniques"}, {"content": "| Dataset Name | Description | Stats |\n|---|---|---|\n| ConCon-Chi [Rosasco et al. (2024)] | Benchmark for personalized vision-language tasks | 4008 images; 20 concepts; 101 contexts |\n| MSMTPInfo [Shi et al. (2024b)] | Evaluation for Agent Collaboration Network | 13 themes; multiple sessions; dynamic user topics |\n| Shoes [Berg et al. (2010)] | Dataset for interactive fashion image retrieval | 8900 training triplets; 1700 test triplets |\n| Fashion200k [Han et al. (2017)] | Large-scale fashion dataset with over 200K images | 172K training images; 33K test queries |\n| Business Dataset [Deng et al. (2009)] | User query images from a real image search engine | 50K images; 5 suggestions per image |\n| Yo\u2019LLaVA [Nguyen et al. (2024)] | Personalized language and vision assistant dataset | 40 subjects; 10-20 images per subject |\n| RefCOCOg [Mao et al. (2016)] | Images from MS-COCO with relational annotations | 21899 train, 1300 val and 2600 test images |\n| Flickr30K [Young et al. (2014)] | Benchmark for visual-semantic embedding networks | 29000 train, 1000 validation and 1000 test images |\n| MicroLens [Ni et al. (2023)] | Video introductions and cover images | 1 billion user-item interactions; 34 million users |\n| Amazon-Baby [McAuley et al. (2015)] | Images and product descriptions | 180 million relationships; 6 million objects; |\n| interaRec [Karra and Tulabandhula (2024)] | Screenshot based recommendations using multimodal large language models | 1,500 sessions; item IDs; screenshots of webpages |\n| POG [Chen et al. (2019)] | Fashion rec by personalized outfit generation | 1.43 million outfits; 80 most frequent categories; |\n| MovieLens [Ni et al. (2023)] | Describes 5-star rating and free-text tagging activity | 100K ratings; 3,683 tag applications; 9,742 movies |", "caption": "Table 2: Summary of Datasets.", "description": "This table provides a summary of various datasets used in research on personalized multimodal large language models (MLLMs).  Each dataset is listed with its name, a brief description of its content and purpose, and key statistics such as the number of images, texts, or other data points included.  The datasets cover diverse applications, including fashion image retrieval, personalized vision and language tasks, multimodal recommendation, and more. The table is valuable for researchers seeking suitable datasets for benchmarking personalized MLLM models across various tasks.", "section": "8 Datasets"}]