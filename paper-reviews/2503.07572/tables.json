[{"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S8.T1.5.5\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.6.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.6.1.1.1\" style=\"font-size:90%;\">Base model + Approach</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.2\"><span class=\"ltx_text\" id=\"S8.T1.5.5.6.1.2.1\" style=\"font-size:90%;\">AIME 2024</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.3\"><span class=\"ltx_text\" id=\"S8.T1.5.5.6.1.3.1\" style=\"font-size:90%;\">AIME 2025</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.4\"><span class=\"ltx_text\" id=\"S8.T1.5.5.6.1.4.1\" style=\"font-size:90%;\">AMC 2023</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.6.1.5.1\" style=\"font-size:90%;\">MinervaMATH</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S8.T1.5.5.6.1.6\"><span class=\"ltx_text\" id=\"S8.T1.5.5.6.1.6.1\" style=\"font-size:90%;\">MATH500</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S8.T1.5.5.6.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.6.1.7.1\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.7.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.7.2.1.1\" style=\"font-size:90%;\">DeepScaleR-1.5B-Preview</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.2\"><span class=\"ltx_text\" id=\"S8.T1.5.5.7.2.2.1\" style=\"font-size:90%;\">42.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.3\"><span class=\"ltx_text\" id=\"S8.T1.5.5.7.2.3.1\" style=\"font-size:90%;\">36.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.4\"><span class=\"ltx_text\" id=\"S8.T1.5.5.7.2.4.1\" style=\"font-size:90%;\">83.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.7.2.5.1\" style=\"font-size:90%;\">24.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.7.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.7.2.6.1\" style=\"font-size:90%;\">85.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S8.T1.5.5.7.2.7\"><span class=\"ltx_text\" id=\"S8.T1.5.5.7.2.7.1\" style=\"font-size:90%;\">54.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S8.T1.1.1.1.2\"><span class=\"ltx_text\" id=\"S8.T1.1.1.1.2.1\" style=\"font-size:90%;\">\u00a0\u00a0outcome-reward RL (GRPO)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.1.1.1.3\">\n<span class=\"ltx_text\" id=\"S8.T1.1.1.1.3.1\" style=\"font-size:90%;\">44.5 </span><span class=\"ltx_text\" id=\"S8.T1.1.1.1.3.2\" style=\"font-size:70%;\">(+1.7)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S8.T1.1.1.1.4.1\" style=\"font-size:90%;\">39.3 </span><span class=\"ltx_text\" id=\"S8.T1.1.1.1.4.2\" style=\"font-size:70%;\">(+2.6)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.1.1.1.1\">\n<span class=\"ltx_text\" id=\"S8.T1.1.1.1.1.2\" style=\"font-size:90%;\">81.5 </span><span class=\"ltx_text\" id=\"S8.T1.1.1.1.1.1\" style=\"font-size:70%;\">(<math alttext=\"-\" class=\"ltx_Math\" display=\"inline\" id=\"S8.T1.1.1.1.1.1.m1.1\"><semantics id=\"S8.T1.1.1.1.1.1.m1.1a\"><mo id=\"S8.T1.1.1.1.1.1.m1.1.1\" xref=\"S8.T1.1.1.1.1.1.m1.1.1.cmml\">\u2212</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T1.1.1.1.1.1.m1.1b\"><minus id=\"S8.T1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S8.T1.1.1.1.1.1.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T1.1.1.1.1.1.m1.1c\">-</annotation><annotation encoding=\"application/x-llamapun\" id=\"S8.T1.1.1.1.1.1.m1.1d\">-</annotation></semantics></math>1.5)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.1.1.1.5.1\" style=\"font-size:90%;\">24.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.1.1.1.6\"><span class=\"ltx_text\" id=\"S8.T1.1.1.1.6.1\" style=\"font-size:90%;\">84.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S8.T1.1.1.1.7\">\n<span class=\"ltx_text\" id=\"S8.T1.1.1.1.7.1\" style=\"font-size:90%;\">55.0 </span><span class=\"ltx_text\" id=\"S8.T1.1.1.1.7.2\" style=\"font-size:70%;\">(+0.5)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S8.T1.5.5.5.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.5.5.1\" style=\"font-size:90%;\">\u00a0\u00a0length penalty</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.2.2.2.1\">\n<span class=\"ltx_text\" id=\"S8.T1.2.2.2.1.2\" style=\"font-size:90%;\">40.3 </span><span class=\"ltx_text\" id=\"S8.T1.2.2.2.1.1\" style=\"font-size:70%;\">(<math alttext=\"-\" class=\"ltx_Math\" display=\"inline\" id=\"S8.T1.2.2.2.1.1.m1.1\"><semantics id=\"S8.T1.2.2.2.1.1.m1.1a\"><mo id=\"S8.T1.2.2.2.1.1.m1.1.1\" xref=\"S8.T1.2.2.2.1.1.m1.1.1.cmml\">\u2212</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T1.2.2.2.1.1.m1.1b\"><minus id=\"S8.T1.2.2.2.1.1.m1.1.1.cmml\" xref=\"S8.T1.2.2.2.1.1.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T1.2.2.2.1.1.m1.1c\">-</annotation><annotation encoding=\"application/x-llamapun\" id=\"S8.T1.2.2.2.1.1.m1.1d\">-</annotation></semantics></math>2.5)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.3.3.3.2\">\n<span class=\"ltx_text\" id=\"S8.T1.3.3.3.2.2\" style=\"font-size:90%;\">30.3 </span><span class=\"ltx_text\" id=\"S8.T1.3.3.3.2.1\" style=\"font-size:70%;\">(<math alttext=\"-\" class=\"ltx_Math\" display=\"inline\" id=\"S8.T1.3.3.3.2.1.m1.1\"><semantics id=\"S8.T1.3.3.3.2.1.m1.1a\"><mo id=\"S8.T1.3.3.3.2.1.m1.1.1\" xref=\"S8.T1.3.3.3.2.1.m1.1.1.cmml\">\u2212</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T1.3.3.3.2.1.m1.1b\"><minus id=\"S8.T1.3.3.3.2.1.m1.1.1.cmml\" xref=\"S8.T1.3.3.3.2.1.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T1.3.3.3.2.1.m1.1c\">-</annotation><annotation encoding=\"application/x-llamapun\" id=\"S8.T1.3.3.3.2.1.m1.1d\">-</annotation></semantics></math>6.4)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.4.4.4.3\">\n<span class=\"ltx_text\" id=\"S8.T1.4.4.4.3.2\" style=\"font-size:90%;\">77.3 </span><span class=\"ltx_text\" id=\"S8.T1.4.4.4.3.1\" style=\"font-size:70%;\">(<math alttext=\"-\" class=\"ltx_Math\" display=\"inline\" id=\"S8.T1.4.4.4.3.1.m1.1\"><semantics id=\"S8.T1.4.4.4.3.1.m1.1a\"><mo id=\"S8.T1.4.4.4.3.1.m1.1.1\" xref=\"S8.T1.4.4.4.3.1.m1.1.1.cmml\">\u2212</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T1.4.4.4.3.1.m1.1b\"><minus id=\"S8.T1.4.4.4.3.1.m1.1.1.cmml\" xref=\"S8.T1.4.4.4.3.1.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T1.4.4.4.3.1.m1.1c\">-</annotation><annotation encoding=\"application/x-llamapun\" id=\"S8.T1.4.4.4.3.1.m1.1d\">-</annotation></semantics></math>5.7)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.5.6\"><span class=\"ltx_text\" id=\"S8.T1.5.5.5.6.1\" style=\"font-size:90%;\">23.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.5.7\"><span class=\"ltx_text\" id=\"S8.T1.5.5.5.7.1\" style=\"font-size:90%;\">83.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S8.T1.5.5.5.4\">\n<span class=\"ltx_text\" id=\"S8.T1.5.5.5.4.2\" style=\"font-size:90%;\">50.8 </span><span class=\"ltx_text\" id=\"S8.T1.5.5.5.4.1\" style=\"font-size:70%;\">(<math alttext=\"-\" class=\"ltx_Math\" display=\"inline\" id=\"S8.T1.5.5.5.4.1.m1.1\"><semantics id=\"S8.T1.5.5.5.4.1.m1.1a\"><mo id=\"S8.T1.5.5.5.4.1.m1.1.1\" xref=\"S8.T1.5.5.5.4.1.m1.1.1.cmml\">\u2212</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T1.5.5.5.4.1.m1.1b\"><minus id=\"S8.T1.5.5.5.4.1.m1.1.1.cmml\" xref=\"S8.T1.5.5.5.4.1.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T1.5.5.5.4.1.m1.1c\">-</annotation><annotation encoding=\"application/x-llamapun\" id=\"S8.T1.5.5.5.4.1.m1.1d\">-</annotation></semantics></math>3.7)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.8.3\" style=\"background-color:#FFFF00;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S8.T1.5.5.8.3.1\"><span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.1.1\" style=\"font-size:90%;background-color:#FFFF00;\">\u00a0\u00a0<em class=\"ltx_emph ltx_font_bold ltx_font_italic\" id=\"S8.T1.5.5.8.3.1.1.1\">MRT</em> (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.8.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.8.3.2.1\" style=\"font-size:90%;background-color:#FFFF00;\">47.2<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.8.3.2.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.2.1.1.1\" style=\"font-size:78%;\">(+4.4)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.8.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.8.3.3.1\" style=\"font-size:90%;background-color:#FFFF00;\">39.7<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.8.3.3.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.3.1.1.1\" style=\"font-size:78%;\">(+3.0)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.8.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.8.3.4.1\" style=\"font-size:90%;background-color:#FFFF00;\">83.1<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.8.3.4.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.4.1.1.1\" style=\"font-size:78%;\">(+0.1)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.8.3.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.5.1\" style=\"font-size:90%;background-color:#FFFF00;\">24.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.8.3.6\"><span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.6.1\" style=\"font-size:90%;background-color:#FFFF00;\">85.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S8.T1.5.5.8.3.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.8.3.7.1\" style=\"font-size:90%;background-color:#FFFF00;\">55.9<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.8.3.7.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.8.3.7.1.1.1\" style=\"font-size:78%;\">(+1.4)</span></span></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.9.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.9.4.1.1\" style=\"font-size:90%;\">R1-Distill-Qwen-1.5B</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.2\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.2.1\" style=\"font-size:90%;\">28.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.3\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.3.1\" style=\"font-size:90%;\">26.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.4\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.4.1\" style=\"font-size:90%;\">69.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.5.1\" style=\"font-size:90%;\">19.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S8.T1.5.5.9.4.6\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.6.1\" style=\"font-size:90%;\">80.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S8.T1.5.5.9.4.7\"><span class=\"ltx_text\" id=\"S8.T1.5.5.9.4.7.1\" style=\"font-size:90%;\">44.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.10.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S8.T1.5.5.10.5.1\"><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.1.1\" style=\"font-size:90%;\">\u00a0\u00a0outcome-reward RL (GRPO)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.10.5.2\">\n<span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.2.1\" style=\"font-size:90%;\">29.8 </span><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.2.2\" style=\"font-size:70%;\">(+1.1)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.10.5.3\">\n<span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.3.1\" style=\"font-size:90%;\">27.3 </span><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.3.2\" style=\"font-size:70%;\">(+1.3)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.10.5.4\">\n<span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.4.1\" style=\"font-size:90%;\">70.5 </span><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.4.2\" style=\"font-size:70%;\">(+0.6)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.10.5.5\"><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.5.1\" style=\"font-size:90%;\">22.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S8.T1.5.5.10.5.6\"><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.6.1\" style=\"font-size:90%;\">80.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S8.T1.5.5.10.5.7\">\n<span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.7.1\" style=\"font-size:90%;\">46.0 </span><span class=\"ltx_text\" id=\"S8.T1.5.5.10.5.7.2\" style=\"font-size:70%;\">(+1.1)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S8.T1.5.5.11.6\" style=\"background-color:#FFFF00;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.1\"><span class=\"ltx_text\" id=\"S8.T1.5.5.11.6.1.1\" style=\"font-size:90%;background-color:#FFFF00;\">\u00a0\u00a0<em class=\"ltx_emph ltx_font_bold ltx_font_italic\" id=\"S8.T1.5.5.11.6.1.1.1\">MRT</em> (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.2.1\" style=\"font-size:90%;background-color:#FFFF00;\">30.3<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.11.6.2.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.11.6.2.1.1.1\" style=\"font-size:78%;\">(+1.6)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.3.1\" style=\"font-size:90%;background-color:#FFFF00;\">29.3<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.11.6.3.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.11.6.3.1.1.1\" style=\"font-size:78%;\">(+3.3)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.4.1\" style=\"font-size:90%;background-color:#FFFF00;\">72.9<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.11.6.4.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.11.6.4.1.1.1\" style=\"font-size:78%;\">(+3.0)</span></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.5.1\" style=\"font-size:90%;background-color:#FFFF00;\">22.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S8.T1.5.5.11.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.6.1\" style=\"font-size:90%;background-color:#FFFF00;\">80.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S8.T1.5.5.11.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S8.T1.5.5.11.6.7.1\" style=\"font-size:90%;background-color:#FFFF00;\">47.1<span class=\"ltx_text ltx_font_medium\" id=\"S8.T1.5.5.11.6.7.1.1\"> <span class=\"ltx_text\" id=\"S8.T1.5.5.11.6.7.1.1.1\" style=\"font-size:78%;\">(+2.2)</span></span></span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: Pass@1 performance of RL-trained MRT models on various math reasoning benchmarks. We compare models trained with MRT, outcome-reward RL with GRPO, and length penalty against baseline models. Results show that MRT consistently outperforms other training approaches, achieving state-of-the-art performance in its size category. MRT leads to a 2-3x improvement in accuracy over the base model compared to that of outcome-reward GRPO. Note that both base models are already trained with RL on a potentially a larger superset of prompts, or distilled from RL trained models, and thus we should expect the gains from any subsequent fine-tuning to be small in absolute magnitude. Despite this, we observe a statistically significant and systematic gain with MRT, which is \ud835\udfd0\u2212\ud835\udfd1\u00d7\\mathbf{2-3\\times}bold_2 - bold_3 \u00d7 of the gain from outcome-reward training.", "description": "This table presents the results of the Pass@1 evaluation metric across multiple math reasoning benchmarks.  The evaluation compares the performance of models trained using three different methods: Meta Reinforcement Fine-Tuning (MRT), outcome-reward reinforcement learning (RL) with GRPO, and an approach using length penalties.  The models are evaluated against baseline models. The results demonstrate that MRT consistently surpasses the other training methods, achieving state-of-the-art accuracy for its model size.  Specifically, MRT shows a 2-3 times improvement in accuracy over the baseline models compared to the outcome-reward RL method. It's important to note that the baseline models were already trained using RL, potentially on a larger dataset; thus, improvements from further fine-tuning are expected to be modest.  Despite this, the gains achieved by MRT are statistically significant and consistently exceed the gains from using outcome-reward training.", "section": "8. Experimental Evaluation"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"A2.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T2.1.1.1.1.1\">Hyperparameter</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T2.1.1.1.2.1\">Values</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T2.1.2.1.1\">learning_rate</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T2.1.2.1.2\">1.0e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.3.2.1\">num_train_epochs</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.3.2.2\">3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.4.3.1\">batch_size</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.4.3.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.5.4.1\">gradient_checkpointing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.5.4.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.6.5.1\">max_seq_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.6.5.2\">16384</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.7.6.1\">bf16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.7.6.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.8.7.1\">num_gpus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.8.7.2\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T2.1.9.8.1\">learning rate</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T2.1.9.8.2\">1e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T2.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T2.1.10.9.1\">warmup ratio</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T2.1.10.9.2\">0.1</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Hyperparameters used for MRT (STaR)", "description": "This table lists the hyperparameters used for training the Meta Reinforcement Fine-Tuning (MRT) model using the STaR (self-training with rejection sampling) algorithm.  It includes values for parameters such as the learning rate, the number of training epochs, batch size, gradient checkpointing setting, maximum sequence length, whether bf16 precision is used, and the number of GPUs used for training. The learning rate schedule's warmup ratio is also specified.", "section": "7.1. STaR and RL Variants of MRT"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"A2.T3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T3.1.1.1.1.1\">Hyperparameter</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T3.1.1.1.2.1\">Values</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T3.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T3.1.2.1.1\">learning_rate</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T3.1.2.1.2\">1.0e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.3.2.1\">lr_scheduler_type</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.3.2.2\">cosine</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.4.3.1\">warmup_ratio</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.4.3.2\">0.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.5.4.1\">weight_decay</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.5.4.2\">0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.6.5.1\">num_train_epochs</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.6.5.2\">1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.7.6.1\">batch_size</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.7.6.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.8.7.1\">max_prompt_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.8.7.2\">4096</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.9.8.1\">max_completion_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.9.8.2\">24576</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.10.9.1\">num_generations</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.10.9.2\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.11.10.1\">use_vllm</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.11.10.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.12.11.1\">vllm_gpu_memory_utilization</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.12.11.2\">0.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.13.12.1\">temperature</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.13.12.2\">0.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.14.13.1\">bf16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.14.13.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.15.14.1\">num_gpus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.15.14.2\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.16.15.1\">deepspeed_multinode_launcher</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.16.15.2\">standard</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T3.1.17.16.1\">zero3_init_flag</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T3.1.17.16.2\">true</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T3.1.18.17.1\">zero_stage</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T3.1.18.17.2\">3</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: Hyperparameters used for MRT (RL)", "description": "This table lists the hyperparameters used during the training process of the Meta Reinforcement Fine-Tuning (MRT) method using the Reinforcement Learning (RL) approach.  The hyperparameters control various aspects of the training process, influencing factors like the learning rate, batch size, network architecture, and optimization algorithm. These settings are crucial in achieving optimal performance and efficiency during the model training.", "section": "7. Practical Instantiations: Dense Rewards for Optimizing Test-Time Compute"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"A2.T4.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T4.1.1.1.1.1\">Hyperparameter</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T4.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T4.1.1.1.2.1\">Values</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T4.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T4.1.2.1.1\">learning_rate</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T4.1.2.1.2\">1.0e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.3.2.1\">num_train_epochs</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.3.2.2\">3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.4.3.1\">batch_size</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.4.3.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.5.4.1\">gradient_checkpointing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.5.4.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.6.5.1\">max_seq_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.6.5.2\">4096</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.7.6.1\">bf16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.7.6.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.8.7.1\">num_gpus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.8.7.2\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T4.1.9.8.1\">learning rate</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T4.1.9.8.2\">1e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T4.1.10.9.1\">warmup ratio</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T4.1.10.9.2\">0.1</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: Hyperparameters used for MRT (STaR)", "description": "This table lists the hyperparameters used for training the Meta Reinforcement Fine-Tuning (MRT) model using the STaR algorithm.  It includes settings for the learning rate, number of training epochs, batch size, gradient checkpointing, maximum sequence length, use of bf16 precision, number of GPUs used for training, and the learning rate warmup ratio. These hyperparameters were specifically tuned for the experiments using the STaR approach within the MRT framework.", "section": "7.1 STaR and RL Variants of MRT"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"A2.T5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.1.1.1.1.1\">Hyperparameter</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.1.1.1.2.1\">Values</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T5.1.2.1.1\">learning_rate</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.2.1.2\">1.0e-6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.3.2.1\">lr_scheduler_type</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.3.2.2\">cosine</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.4.3.1\">warmup_ratio</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.4.3.2\">0.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.5.4.1\">weight_decay</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.5.4.2\">0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.6.5.1\">num_train_epochs</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.6.5.2\">1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.7.6.1\">batch_size</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.7.6.2\">256</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.8.7.1\">max_prompt_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.8.7.2\">1500</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.9.8.1\">max_completion_length</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.9.8.2\">1024</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.10.9.1\">num_generations</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.10.9.2\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.11.10.1\">use_vllm</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.11.10.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.12.11.1\">vllm_gpu_memory_utilization</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.12.11.2\">0.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.13.12.1\">temperature</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.13.12.2\">0.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.14.13.1\">bf16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.14.13.2\">True</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.15.14.1\">num_gpus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.15.14.2\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.16.15.1\">deepspeed_multinode_launcher</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.16.15.2\">standard</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.1.17.16.1\">zero3_init_flag</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.1.17.16.2\">true</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T5.1.18.17.1\">zero_stage</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.1.18.17.2\">3</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 5: Hyperparameters used for MRT (RL)", "description": "This table lists the hyperparameters used for training language models using the Meta Reinforcement Fine-Tuning (MRT) paradigm with reinforcement learning (RL).  It details the specific settings used for the learning rate, scheduler type, weight decay, number of training epochs, batch size, maximum prompt and completion lengths, number of generations, use of the vllm library, GPU memory utilization settings, temperature, use of bf16 precision, number of GPUs, deepspeed multinode launcher settings, and zero stage settings. These hyperparameters are crucial for optimizing the performance and efficiency of test-time computation within the MRT-RL framework.", "section": "Implementation Details"}]