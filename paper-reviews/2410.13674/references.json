{"references": [{" publication_date": "2023", "fullname_first_author": "Sumyeong Ahn", "paper_title": "Cuda: Curriculum of data augmentation for long-tailed recognition", "reason": "This paper is highly relevant because it directly addresses the problem of long-tail classification, a key application of the proposed DisCL method.  The authors introduce a curriculum learning approach with engineered data augmentation, which is similar in spirit to the DisCL method. The importance stems from the direct comparison possible between the engineered augmentation technique of CUDA and the generative curriculum approach of DisCL; the comparison helps understand the relative contribution of each strategy in tackling the class imbalance problem.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Shekoofeh Azizi", "paper_title": "Synthetic data from diffusion models improves imagenet classification", "reason": "This paper demonstrates the effectiveness of using synthetic data generated from diffusion models to improve image classification performance.  This directly supports the core idea of DisCL, which also leverages synthetic data from diffusion models to improve the performance on challenging image classification tasks.  The relevance stems from the fact that the paper validates the use of synthetic data in improving classification tasks, making it a crucial piece of evidence for the viability of DisCL's underlying concept.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Hritik Bansal", "paper_title": "Leaving reality to imagination: Robust classification via generated datasets", "reason": "This work is highly relevant because it directly addresses the problem of improving model robustness through the use of synthetic datasets, a critical aspect of the proposed DisCL method. The importance lies in the shared goal of improving model robustness which is a direct consequence of addressing the syn-to-real gap.  The results presented in this paper provide supporting evidence for the claim that using synthetic data, generated strategically, can significantly boost model generalization and robustness.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Sara Beery", "paper_title": "Synthetic examples improve generalization for rare classes", "reason": "This paper investigates the use of synthetic data to improve generalization performance, particularly focusing on rare classes. This directly relates to the DisCL method's aim to address the limitations of scarce data, focusing on the under-represented tail classes in long-tail classification tasks. The relevance comes from the shared focus on synthetic data generation to enhance performance on underrepresented classes and the direct comparison between the different methods of synthetic data generation to improve performance on scarce data.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Sara Beery", "paper_title": "The iwildcam 2021 competition dataset", "reason": "This paper introduces the iWildCam dataset, a crucial dataset used in the experiments of the proposed DisCL method for evaluating performance on low-quality image data. The importance of this paper stems from the direct use of this dataset to assess DisCL's ability to learn from low-quality data, making it a critical component in validating the claim of improvement on the dataset.  The results on this dataset directly support the effectiveness of the DisCL approach in handling low-quality images.", "section_number": 5}, {" publication_date": "2009", "fullname_first_author": "Yoshua Bengio", "paper_title": "Curriculum learning", "reason": "This is a foundational paper on curriculum learning, a core concept underlying DisCL.  The authors introduce the idea of gradually increasing the difficulty of training data, mirroring human learning.  The importance is derived from the fact that DisCL is explicitly based on the concept of curriculum learning; this paper provides the fundamental theoretical foundation upon which the DisCL's curriculum strategy is based.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Kaidi Cao", "paper_title": "Learning imbalanced datasets with label-distribution-aware margin loss", "reason": "This paper proposes a method to address the class imbalance problem in long-tail recognition, which is a major focus of DisCL.  The importance of this paper is due to its focus on addressing the class imbalance in long-tail data.  The proposed approach helps tackle the specific problem of unbalanced class distribution in the ImageNet-LT dataset.  The comparison to this approach is an essential part of evaluating the efficacy of the DisCL's approach to address class imbalance.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Huiwen Chang", "paper_title": "Muse: Text-to-image generation via masked generative transformers", "reason": "This paper presents a state-of-the-art text-to-image generation model, relevant because DisCL uses a similar type of model (Stable Diffusion) as a foundation.  Its importance is due to the fact that the proposed DisCL method uses a pretrained model that could be considered similar to Muse.  The comparison helps demonstrate that the advancements introduced by the DisCL method go beyond simply using existing text-to-image models; it is a significant step towards more effectively and adaptively handling the limitations of such models.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Kevin Clark", "paper_title": "Text-to-image diffusion models are zero shot classifiers", "reason": "This work explores the surprising properties of text-to-image diffusion models and demonstrates that they are effective zero-shot classifiers. This is relevant to DisCL because the paper highlights the unexpected power of such models, providing further support for the authors' decision to utilize pretrained diffusion models as a basis for synthetic data generation.  The fact that diffusion models implicitly provide classification abilities motivates and justifies using pretrained diffusion models as a core building block for DisCL.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Lisa Dunlap", "paper_title": "Diversify your vision datasets with automatic diffusion-based augmentation", "reason": "This paper focuses on data augmentation using diffusion models, which is directly related to DisCL's use of diffusion models for synthetic data generation. The importance of this paper is that it expands on the concept of diffusion models to perform data augmentation; however, the DisCL method advances this work by providing a flexible curriculum framework to manage the distribution gap between synthetic and real-world images.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yunxiang Fu", "paper_title": "Dreamda: Generative data augmentation with diffusion models", "reason": "This work is similar to DisCL in that it proposes a method to generate synthetic data via diffusion models, thereby addressing the issue of data scarcity and low-quality data.  The importance of this paper is that it provides a direct comparison to DisCL, as both methods aim to use diffusion models to improve data quality, diversity, and quantity for enhanced model performance.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Sheng Guo", "paper_title": "Curriculumnet: Weakly supervised learning from large-scale web images", "reason": "This paper introduces a curriculum learning approach designed for weakly supervised learning using large-scale web images. The importance stems from the fact that DisCL also uses a curriculum learning strategy to address the challenge of training with hard samples and low-quality data. The comparison between CurriculumNet's curriculum learning approach and DisCL's approach is valuable to show the advancement of DisCL in leveraging synthetic data to aid curriculum learning effectively.", "section_number": 3}, {" publication_date": "2004", "fullname_first_author": "Thomas A Halgren", "paper_title": "Glide: a new approach for rapid, accurate docking and scoring. 2. enrichment factors in database screening", "reason": "This paper introduces the GLIDE algorithm, a diffusion model for rapid and accurate docking, which has been used in other works to generate synthetic data for image classification.  The importance of this paper lies in its role as an early precursor to modern diffusion models used in the context of image synthesis.  The use of GLIDE, as a successful early method, highlights the potential of diffusion models for generating synthetic datasets, justifying the selection of similar modern diffusion models in DisCL.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Pengxiao Han", "paper_title": "Latent-based diffusion model for long-tailed recognition", "reason": "This paper focuses on using diffusion models specifically for long-tailed recognition, a direct application of DisCL.  The importance comes from the direct comparison between the diffusion model-based approach of this paper and the DisCL method.  This comparison helps gauge the improvements provided by DisCL, which goes beyond simply using diffusion models by introducing the innovative and flexible curriculum learning strategy.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Ruifei He", "paper_title": "Is synthetic data from generative models ready for image recognition?", "reason": "This paper assesses the readiness of synthetic data from generative models for image recognition, providing insights into the challenges and potential of this approach.  The importance of this work stems from its attempt to answer the feasibility question of whether synthetic data, generated by generative models, could successfully replace the role of real data in image classification tasks. The findings of this paper are valuable for justifying the approach adopted by the DisCL method and for understanding the potential limitations associated with leveraging solely synthetic data in image classification tasks.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "reason": "This paper introduces classifier-free guidance for diffusion models, a technique crucial to DisCL's ability to generate synthetic-to-real images. The importance is derived from the fact that DisCL's ability to generate a spectrum of images, ranging from prototypical to highly realistic images, is directly enabled by the classifier-free guidance technique.  This paper provides the foundational technical support for the core mechanism used in DisCL to generate the synthetic data for training.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Chengkai Hou", "paper_title": "When to learn what: Model-adaptive data augmentation curriculum", "reason": "This paper investigates the use of model-adaptive data augmentation in curriculum learning, showcasing an approach similar to DisCL's adaptive curriculum strategy. The importance of this paper is that it presents a related approach that directly addresses the challenge of adaptive curriculum learning.  By comparing the results and techniques of this paper with those of DisCL, the effectiveness and efficiency of DisCL's approach can be better understood and appreciated.", "section_number": 3}, {" publication_date": "2014", "fullname_first_author": "Lu Jiang", "paper_title": "Self-paced learning with diversity", "reason": "This paper introduces self-paced learning with diversity, a technique that is conceptually related to DisCL's curriculum learning approach.  The importance stems from its similarity to the curriculum learning strategy of DisCL; however, DisCL goes beyond this technique by explicitly generating synthetic data with varying degrees of difficulty and using a novel method to address the syn-to-real gap, resulting in a much more flexible and effective curriculum learning framework.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Ziwei Liu", "paper_title": "Large-scale long-tailed recognition in an open world", "reason": "This paper introduces the ImageNet-LT dataset, a key dataset used in the experiments to evaluate the performance of the proposed DisCL method in addressing the long-tail classification problem.  The importance of this paper is due to the fact that the ImageNet-LT dataset forms a central component for evaluating the effectiveness of DisCL's approach.  The experimental results on this dataset provide critical evidence for the effectiveness of DisCL's method in handling long-tail data.", "section_number": 5}, {" publication_date": "2020", "fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "reason": "This paper introduces denoising diffusion implicit models (DDIM), a diffusion model that is used by DisCL for synthetic data generation. This paper forms the basis of the core technology used in DisCL to generate synthetic data. The importance of this paper is that the DDIM model serves as the core method for generating synthetic data in the DisCL framework. The DDIM method helps generate synthetic data that bridges the gap between synthetic and real data for enhanced model performance.", "section_number": 3}]}