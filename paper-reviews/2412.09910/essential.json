{"importance": "**DNNs in medical imaging are vulnerable to attacks.** This work is crucial as it demonstrates a novel attack method, P2P, exploiting text embeddings. This reveals vulnerabilities in medical image diagnosis DNNs, highlighting the need for robust defense mechanisms. P2P's text-guided nature offers new research directions in adversarial attacks and defenses within medical imaging, pushing towards safer and more reliable AI-driven diagnosis.", "summary": "New attack fools breast ultrasound AI using subtle text prompts.", "takeaways": ["P2P is a novel language-guided attack method using text prompts to generate adversarial examples.", "P2P outperforms existing attacks by creating subtle perturbations in ultrasound images, effectively misleading AI while preserving image quality.", "P2P's text-guided nature offers a new avenue for both attack and defense research in medical imaging security"], "tldr": "**AI shows promise in breast cancer diagnosis through medical imaging like ultrasound. However, these AI models can be fooled by tiny, invisible changes called adversarial attacks.**  Current attack methods either rely on distortions misaligned with human perception or require large datasets not feasible in the medical field due to data scarcity. This vulnerability raises concerns about reliability in real-world applications. **This work introduces Prompt2Perturb (P2P), a new way to create these attacks.** Unlike traditional methods, it uses text instructions, directly updating text embeddings within the AI model.  By focusing only on initial processing steps and leveraging clinically relevant terms, P2P creates subtle, realistic, and highly effective attacks. It maintains image quality and semantic meaning without noticeable distortions.", "affiliation": "University of British Columbia", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2412.09910/podcast.wav"}