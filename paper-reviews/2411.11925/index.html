<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Continuous Speculative Decoding for Autoregressive Image Generation &#183; AI Paper Reviews by AI</title>
<meta name=title content="Continuous Speculative Decoding for Autoregressive Image Generation &#183; AI Paper Reviews by AI"><meta name=description content="Researchers have developed Continuous Speculative Decoding, boosting autoregressive image generation speed by up to 2.33x while maintaining image quality."><meta name=keywords content="Computer Vision,Image Generation,üè¢ University of Chinese Academy of Sciences,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="Continuous Speculative Decoding for Autoregressive Image Generation"><meta property="og:description" content="Researchers have developed Continuous Speculative Decoding, boosting autoregressive image generation speed by up to 2.33x while maintaining image quality."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-11-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-18T00:00:00+00:00"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Image Generation"><meta property="article:tag" content="üè¢ University of Chinese Academy of Sciences"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/cover.png"><meta name=twitter:title content="Continuous Speculative Decoding for Autoregressive Image Generation"><meta name=twitter:description content="Researchers have developed Continuous Speculative Decoding, boosting autoregressive image generation speed by up to 2.33x while maintaining image quality."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"Continuous Speculative Decoding for Autoregressive Image Generation","headline":"Continuous Speculative Decoding for Autoregressive Image Generation","abstract":"Researchers have developed Continuous Speculative Decoding, boosting autoregressive image generation speed by up to 2.33x while maintaining image quality.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2411.11925\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2024","dateCreated":"2024-11-18T00:00:00\u002b00:00","datePublished":"2024-11-18T00:00:00\u002b00:00","dateModified":"2024-11-18T00:00:00\u002b00:00","keywords":["Computer Vision","Image Generation","üè¢ University of Chinese Academy of Sciences"],"mainEntityOfPage":"true","wordCount":"1799"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2411.11925/cover_hu358414472115640068.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2411.11925/>Continuous Speculative Decoding for Autoregressive Image Generation</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Continuous Speculative Decoding for Autoregressive Image Generation</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-18T00:00:00+00:00>18 November 2024</time><span class="px-2 text-primary-500">&#183;</span><span>1799 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">9 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2411.11925/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2411.11925/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/computer-vision/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Computer Vision
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/image-generation/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Image Generation
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-university-of-chinese-academy-of-sciences/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ University of Chinese Academy of Sciences</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#continuous-speculative-decoding>Continuous Speculative Decoding</a></li><li><a href=#denoising-trajectory-alignment>Denoising Trajectory Alignment</a></li><li><a href=#acceptance-rejection-sampling>Acceptance-Rejection Sampling</a></li><li><a href=#ablation-study--analysis>Ablation Study & Analysis</a></li><li><a href=#future-work--limitations>Future Work & Limitations</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#continuous-speculative-decoding>Continuous Speculative Decoding</a></li><li><a href=#denoising-trajectory-alignment>Denoising Trajectory Alignment</a></li><li><a href=#acceptance-rejection-sampling>Acceptance-Rejection Sampling</a></li><li><a href=#ablation-study--analysis>Ablation Study & Analysis</a></li><li><a href=#future-work--limitations>Future Work & Limitations</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2411.11925</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Zili Wang et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2024-11-20</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2411.11925 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2411.11925 target=_self role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/continuous-speculative-decoding-for target=_self role=button>‚Üó Papers with Code</a></p><audio controls><source src=https://ai-paper-reviewer.com/2411.11925/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Autoregressive image generation, while producing high-quality images, is computationally expensive. Existing speculative decoding techniques, effective for text models, hadn&rsquo;t been successfully applied to continuous-valued image generation models. This limitation stems from the difficulty in handling continuous probability distributions and adapting the acceptance criteria.</p><p>This research introduces Continuous Speculative Decoding, extending speculative decoding to the continuous space of autoregressive image generation. This involves developing a tailored acceptance criterion for diffusion distributions, employing trajectory alignment to ensure consistent outputs, and using a novel sampling method to address resampling challenges. The results demonstrate a significant speedup (up to 2.33x) with maintained image quality.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-f7fc642226b328afef190c3e28959ef9></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-f7fc642226b328afef190c3e28959ef9",{strings:[" Continuous Speculative Decoding accelerates autoregressive image generation significantly (up to 2.33x). "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-4e6e33e012ea1345491cd26d82d11568></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-4e6e33e012ea1345491cd26d82d11568",{strings:[" The method adapts speculative decoding to continuous-valued models, overcoming challenges related to probability distribution. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-5400457525607053a90e1e3002945c4e></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-5400457525607053a90e1e3002945c4e",{strings:[" The approach maintains comparable image quality to standard methods, making it a practical solution. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial because <strong>it significantly accelerates autoregressive image generation</strong>, a computationally expensive process. Its method is broadly applicable, opening avenues for faster, more efficient AI image tools and boosting research in related areas. This speed improvement <strong>enables real-time or near real-time image generation</strong>, impacting various applications from virtual reality to medical imaging.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x2.png alt></figure></p><blockquote><p>üîº This figure displays a comparison of image generation speeds using different methods. Three sets of images are shown, each with a default autoregressive model and the proposed continuous speculative decoding method. The latter shows a significant speed-up (2.15x, 2.32x, and 2.26x faster) while preserving the original image quality. This demonstrates the effectiveness of the proposed approach for accelerating inference without sacrificing the quality of autoregressive image generation.</p><details><summary>read the caption</summary>Figure 1: Continuous speculative decoding accelerates the inference speed while maintaining the original generation quality.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>$M_p$</th><th>$M_q$</th><th>$\gamma$</th><th>$\alpha$</th><th>Speedup ratio</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td>bs=1</td><td>bs=8</td><td>bs=128</td><td>bs=256</td><td></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>32</td><td>0.26</td><td><strong>1.18 √ó</strong></td><td><strong>1.21 √ó</strong></td><td><strong>1.44 √ó</strong></td><td><strong>1.49 √ó</strong></td><td></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>16</td><td>0.31</td><td>1.10 √ó</td><td>1.17 √ó</td><td>1.39 √ó</td><td>1.42 √ó</td><td></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>8</td><td>0.36</td><td>1.05 √ó</td><td>1.12 √ó</td><td>1.29 √ó</td><td>1.32 √ó</td><td></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>4</td><td>0.39</td><td>1.01 √ó</td><td>1.00 √ó</td><td>1.13 √ó</td><td>1.15 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>32</td><td>0.19</td><td><strong>1.44 √ó</strong></td><td><strong>1.61 √ó</strong></td><td><strong>2.17 √ó</strong></td><td><strong>2.33 √ó</strong></td><td></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>32</td><td>0.18</td><td>1.26 √ó</td><td>1.34 √ó</td><td>1.47 √ó</td><td>1.53 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>16</td><td>0.26</td><td>1.37 √ó</td><td>1.51 √ó</td><td>2.07 √ó</td><td>2.20 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>16</td><td>0.24</td><td>1.24 √ó</td><td>1.29 √ó</td><td>1.41 √ó</td><td>1.46 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>8</td><td>0.27</td><td>1.26 √ó</td><td>1.44 √ó</td><td>1.88 √ó</td><td>1.96 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>8</td><td>0.28</td><td>1.11 √ó</td><td>1.21 √ó</td><td>1.32 √ó</td><td>1.33 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>4</td><td>0.30</td><td>1.11 √ó</td><td>1.20 √ó</td><td>1.56 √ó</td><td>1.62 √ó</td><td></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>4</td><td>0.30</td><td>1.00 √ó</td><td>1.03 √ó</td><td>1.15 √ó</td><td>1.18 √ó</td><td></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the speedup achieved by the proposed continuous speculative decoding method compared to the original MAR model [21] under various experimental settings. It shows the speedup ratio for different combinations of model sizes (Mq and Mp), draft numbers (Œ≥), and batch sizes (bs). The acceptance rate (Œ±) is also given for each setting, indicating the proportion of draft tokens accepted by the target model. The results demonstrate how the speedup varies across different model sizes and the balance between computation cost and accuracy.</p><details><summary>read the caption</summary>Table 1: Results of speedup ratio on MAR¬†[21] under different model size, draft number and batch size. The bs refers to batch size. The acceptance rate Œ±ùõº\alphaitalic_Œ± of each setting is also represented.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Continuous Speculative Decoding<div id=continuous-speculative-decoding class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#continuous-speculative-decoding aria-label=Anchor>#</a></span></h4><p>Continuous speculative decoding presents a novel approach to accelerate autoregressive image generation, addressing the computational bottleneck inherent in sequential decoding. By extending speculative decoding from discrete token spaces to continuous domains, <strong>this method significantly enhances inference speed</strong>. The core idea involves a draft model generating a sequence of predictions, which are then verified by a more accurate target model. A key innovation is the development of a tailored acceptance criterion that effectively handles the continuous probability distributions typical of diffusion-based image generation models. <strong>Careful consideration of output distribution properties and a novel denoising trajectory alignment technique are crucial to maintaining the quality of generated images</strong>. Addressing the issue of low initial acceptance rates, token pre-filling methods enhance performance. Furthermore, <strong>the use of acceptance-rejection sampling skillfully circumvents complex integration challenges associated with resampling from the modified distribution, ensuring a computationally efficient process</strong>. The overall approach offers a <strong>substantial improvement in inference speed with minimal impact on image quality</strong>, making it a promising direction for optimizing autoregressive image generation models.</p><h4 class="relative group">Denoising Trajectory Alignment<div id=denoising-trajectory-alignment class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#denoising-trajectory-alignment aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Denoising Trajectory Alignment&rdquo; in the context of continuous autoregressive image generation addresses a critical challenge: <strong>inconsistency between the denoising trajectories of draft and target models.</strong> These models, used in speculative decoding for faster inference, generate images through a diffusion process. Without alignment, their respective paths through the denoising process can diverge significantly, leading to <strong>low acceptance rates</strong> in the speculative decoding algorithm and hindering its effectiveness. The solution proposes to <strong>align the output distributions</strong> by ensuring both models utilize the same random Gaussian noise at each step of the denoising process. This clever reparameterization forces the trajectories to converge, enhancing the consistency of probability density functions between the draft and target models. This alignment is crucial because it simplifies the calculation of the acceptance criterion for speculative decoding, directly impacting the efficiency of the speedup achieved. <strong>This technique tackles a core limitation of applying speculative decoding to continuous models</strong>, directly improving efficiency while largely preserving the generation quality.</p><h4 class="relative group">Acceptance-Rejection Sampling<div id=acceptance-rejection-sampling class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#acceptance-rejection-sampling aria-label=Anchor>#</a></span></h4><p>Acceptance-rejection sampling is a powerful Monte Carlo method used to generate random samples from a probability distribution. Its core idea is straightforward: <strong>generate samples from a simpler proposal distribution</strong> and then <strong>accept or reject them based on a carefully designed acceptance probability</strong>. This probability is proportional to the ratio of the target distribution&rsquo;s probability density function (PDF) to that of the proposal distribution. <strong>The key to success lies in choosing an appropriate proposal distribution that is easy to sample from and whose PDF closely approximates or dominates the target distribution&rsquo;s PDF</strong>. This ensures a reasonable acceptance rate. If the target distribution has regions of very low probability, the algorithm might struggle to generate samples from those regions, as the acceptance probability will be low. This process iterates until enough samples are generated. The algorithm&rsquo;s efficiency depends critically on the choice of proposal distribution. A well-chosen proposal distribution leads to a high acceptance rate; otherwise, many samples might be rejected, resulting in slow performance. The technique is especially useful when direct sampling from the target distribution is computationally challenging or infeasible. <strong>The beauty lies in its simplicity and adaptability to various scenarios, but successful application hinges on smart proposal distribution selection.</strong></p><h4 class="relative group">Ablation Study & Analysis<div id=ablation-study--analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ablation-study--analysis aria-label=Anchor>#</a></span></h4><p>An ablation study systematically evaluates the contribution of individual components within a proposed model. For a continuous speculative decoding model for autoregressive image generation, this would involve removing or modifying key aspects (e.g., denoising trajectory alignment, token pre-filling, acceptance-rejection sampling) and assessing the impact on performance metrics (speedup, FID, IS). <strong>Analyzing the results reveals the relative importance and effectiveness of each component.</strong> For instance, if removing denoising trajectory alignment significantly reduces the acceptance rate, it demonstrates its critical role in ensuring output consistency between draft and target models. Similarly, observing the impact of varied pre-filling ratios helps understand its effect on early acceptance rates and overall inference speed. By carefully dissecting these results, the study can pinpoint crucial design choices, justifying model complexity, and highlighting the strengths and weaknesses of the proposed architecture. <strong>It allows for optimization by identifying elements to further improve or refine.</strong> A thorough analysis should also connect these findings with the theoretical underpinnings, clarifying if the observed behavior aligns with the model&rsquo;s mathematical justification. <strong>Ultimately, a comprehensive ablation study enhances the credibility and understanding of the model by providing evidence-based insights into its design and function.</strong></p><h4 class="relative group">Future Work & Limitations<div id=future-work--limitations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-work--limitations aria-label=Anchor>#</a></span></h4><p>The research on continuous speculative decoding for autoregressive image generation presents exciting advancements, yet also reveals avenues for future exploration. <strong>Extending this method to even larger, more complex autoregressive models</strong> is crucial. Current experiments focused on relatively small models, limiting the observed speedup. Scaling to models with billions of parameters could yield substantial performance gains. Furthermore, <strong>investigating the impact of different architectures and training methodologies</strong> on the effectiveness of speculative decoding is warranted. The current work primarily utilized a specific model; exploring its compatibility with other autoregressive architectures will validate its generalizability and robustness. <strong>Addressing the trade-off between speed and image quality</strong> is another important direction. While the paper shows promising results in maintaining quality, optimizing the balance between speed and fidelity under various conditions requires further study. The acceptance criterion, a key component of the algorithm, could be further refined. Exploring alternative criteria or adaptive strategies that adjust the criterion based on the model&rsquo;s current state may lead to improved acceptance rates and faster inference. Finally, <strong>a thorough analysis of the computational complexity</strong> of the algorithm and identifying bottlenecks to enhance efficiency is needed. This includes examining the cost of the denoising trajectory alignment and token pre-filling processes. Overall, future research should focus on scaling, generalizability, quality optimization, and computational efficiency to solidify the practical impact of this innovative technique.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x3.png alt></figure></p><blockquote><p>üîº This figure compares discrete and continuous speculative decoding methods. Discrete methods easily calculate output probabilities and resample from adjusted distributions. However, continuous methods face the challenge of calculating probabilities in a continuous space and then sampling from modified distributions, which requires more complex calculations involving both draft and target model outputs.</p><details><summary>read the caption</summary>Figure 2: Comparison between discrete- and continuous-valued speculative decoding. Discrete models can conveniently compute output probabilities and be sampled from modified distributions. In contrast, continuous models require determining how to compute probabilities, and sampling from modified distributions via draft and target output distributions is often more challenging.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x4.png alt></figure></p><blockquote><p>üîº This figure illustrates the continuous speculative decoding process. It uses a draft model to generate a sequence of tokens (1, 2, 3 being prefix tokens, and x being the token to verify). The target model then compares the probability densities of the draft and target models for token x. If the draft model&rsquo;s density is less than the target model&rsquo;s, the token is accepted; otherwise, it&rsquo;s rejected with a probability determined by the ratio of the densities. If rejected, a new token is sampled from a modified distribution using acceptance-rejection sampling, and the process continues until a token is accepted.</p><details><summary>read the caption</summary>Figure 3: The overview of our proposed continuous speculative decoding. Continuous speculative decoding leverages the diffusion model component of continuous AR models. Tokens 1‚àº3similar-to131\sim 31 ‚àº 3 are prefix tokens, and token xùë•xitalic_x is to be verified. Upon obtaining and comparing the probability density values from the draft and target model, if q‚Å¢(x)<p‚Å¢(x)ùëûùë•ùëùùë•q(x)<p(x)italic_q ( italic_x ) < italic_p ( italic_x ), xùë•xitalic_x is accepted. otherwise, xùë•xitalic_x is rejected with probability 1‚àíp‚Å¢(x)q‚Å¢(x)1ùëùùë•ùëûùë•1-\frac{p(x)}{q(x)}1 - divide start_arg italic_p ( italic_x ) end_arg start_arg italic_q ( italic_x ) end_arg, followed by sampling from the modified distribution via acceptance-rejection sampling to obtain x‚Ä≤superscriptùë•‚Ä≤x^{\prime}italic_x start_postsuperscript ‚Ä≤ end_postsuperscript. </details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x5.png alt></figure></p><blockquote><p>üîº The figure illustrates the concept of denoising trajectory alignment in the context of continuous autoregressive image generation. The denoising process starts with a noise distribution and gradually refines it through a series of steps to generate the final data distribution. Each step in this process is represented as a point in a trajectory. The figure contrasts two scenarios: one where the trajectories generated by the draft and target models are aligned, resulting in similar output distributions; and another where the trajectories are not aligned, leading to different output distributions. This alignment is crucial for ensuring consistency between the draft and target models in speculative decoding, which improves the acceptance rate and efficiency of the method.</p><details><summary>read the caption</summary>Figure 4: Illustration of denoising trajectory alignment. The denoising process maps the noise distribution to data distribution through gradual denoising. These denoising steps generate a trajectory. Aligned trajectories lead to similar output distribution, while unaligned one produces a more distinct distribution.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x6.png alt></figure></p><blockquote><p>üîº This figure illustrates the challenge of sampling from the modified distribution in continuous speculative decoding. The dashed lines represent the probability density functions (PDFs) of the draft and target models. The red area represents the modified distribution, obtained by taking the positive difference between the target and draft model PDFs. The caption highlights that calculating the integral of this area is computationally complex due to the lack of an analytical solution, creating difficulty in directly sampling from this modified distribution.</p><details><summary>read the caption</summary>Figure 5: Illustration of the modified distribution (unnormalized), where the dashed lines represent the output distributions of the draft and target models, and the red area denotes the modified distribution. The integral of this area is hard to compute, and there is no analytical expression available, which complicates sampling.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x7.png alt></figure></p><blockquote><p>üîº This figure displays a set of images generated using the continuous speculative decoding method in conjunction with the MAR model. It visually demonstrates the quality of images produced by this accelerated inference technique. The images cover a variety of subjects and styles to showcase the model&rsquo;s capabilities.</p><details><summary>read the caption</summary>Figure 6: Qualitative Results. We show the images generated under continuous speculative decoding with MAR.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x8.png alt></figure></p><blockquote><p>üîº This figure displays a qualitative comparison of images generated using the continuous speculative decoding method described in the paper. It shows the impact of varying the draft length (represented by the Greek letter gamma, Œ≥) on the quality of the generated images. By comparing images generated with different Œ≥ values, the figure visually demonstrates how the length of the draft sequence affects the final output. Different rows show different classes of images, and multiple columns within each row illustrate variations in the generated images with increasing draft length. This allows the reader to assess the trade-off between speed and quality achieved by using speculative decoding with varying lengths of draft sequences.</p><details><summary>read the caption</summary>Figure 7: Qualitative Comparison Results. We show the generated images using the algorithm at various draft length Œ≥ùõæ\gammaitalic_Œ≥.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x9.png alt></figure></p><blockquote><p>üîº This figure shows the relationship between the number of draft tokens used in speculative decoding and the acceptance rate. As the number of drafts increases, the acceptance rate decreases. This is because using more drafts increases the chance of generating tokens that differ significantly from the target model&rsquo;s predictions, which leads to more rejections during the verification step.</p><details><summary>read the caption</summary>Figure 8: Acceptance ratio under different number of drafts. Larger number of drafts leads to the decay of acceptance ratio.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x10.png alt></figure></p><blockquote><p>üîº This figure compares image generation results using only a draft model (left) versus results after verification by a target model (right). The regions where the draft model&rsquo;s tokens were rejected and replaced by the target model are highlighted.</p><details><summary>read the caption</summary>Figure 9: Comparison on pure draft (left) and verified (right) generation results. Regions of rejected tokens are roughly marked out.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x11.png alt></figure></p><blockquote><p>üîº This figure demonstrates the impact of denoising trajectory alignment on image generation quality. The top row shows images generated without alignment, exhibiting noticeable artifacts and deformations. The bottom row presents images generated with the proposed denoising trajectory alignment technique. A comparison reveals that the aligned images display a significant reduction in artifacts and improved overall visual quality, highlighting the effectiveness of the alignment method in enhancing the consistency of the output distributions from the draft and target models.</p><details><summary>read the caption</summary>Figure 10: The examples without (upper) and with (lower) denoising trajectory alignment. After alignment, the generated images exhibit a reduction in deformations and artifacts, thereby achieving higher quality.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x12.png alt></figure></p><blockquote><p>üîº This figure visualizes the acceptance rate (Œ±) at each step of the autoregressive generation process using continuous speculative decoding. The x-axis represents the step number within the generation sequence. The y-axis represents the acceptance rate, which is the probability that a token generated by the draft model will be accepted by the target model. Multiple lines are shown, each corresponding to a different pre-filling ratio (0%, 5%, 15%). Pre-filling refers to the process of using tokens from the target model to prime the initial stages of the draft model&rsquo;s generation. The acceptance rate is averaged over 1000 samples for each data point to ensure statistical significance. The graph shows how the acceptance rate changes over the course of generation for various levels of pre-filling, demonstrating the impact of pre-filling on the overall efficiency of the continuous speculative decoding method.</p><details><summary>read the caption</summary>Figure 11: Per-step acceptance Œ±ùõº\alphaitalic_Œ± under different pre-filling ratios. Acceptance rate per step is averaged on 1000 samples.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x13.png alt></figure></p><blockquote><p>üîº This figure displays a comparison of image generation quality using different percentages of pre-filled tokens. Pre-filling involves using tokens from the target model at the start of generation before the draft model begins. The images show how different levels of pre-filling (0%, 5%, and 15%) impact the final generated image&rsquo;s quality, demonstrating the effect of this technique on the overall visual fidelity and detail of the output.</p><details><summary>read the caption</summary>Figure 12: Comparing image generation quality under different token pre-filling portions.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x14.png alt></figure></p><blockquote><p>üîº This figure shows how classifier-free guidance (CFG) scale affects the acceptance rate in continuous speculative decoding. The experiment varies both the CFG scale and the number of draft tokens used in the process. The results illustrate a general trend: as the CFG scale increases, the acceptance rate decreases, regardless of the number of drafts. This suggests that stronger class guidance might introduce more inconsistencies between the draft and target models, leading to lower acceptance rates.</p><details><summary>read the caption</summary>Figure 13: CFG scale has has a significant impact on the acceptance rate under different number of drafts.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x15.png alt></figure></p><blockquote><p>üîº This figure shows how temperature, a hyperparameter in the diffusion process of the MAR model, affects the acceptance rate during the token generation process. The left side shows the results without classifier-free guidance (CFG), and the right side shows the results with CFG. The number of drafts used was 8. The graphs illustrate the relationship between temperature and acceptance rate, revealing how different temperatures influence the probability distribution of the final output and consequently, the likelihood of a token being accepted during speculative decoding.</p><details><summary>read the caption</summary>Figure 14: Temperature influence on the acceptance rate. Left: without CFG. Right: with CFG.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/extracted/6006952/figures/more_accept.png alt></figure></p><blockquote><p>üîº This figure shows the number of times the rejection step is repeated during the acceptance-rejection sampling in the rejection phase of the algorithm. The x-axis represents the number of draft tokens used, while the y-axis represents the number of times the rejection step is executed. The plot shows the relationship between the number of draft tokens and the number of rejections in the algorithm, illustrating how the efficiency of the sampling process changes as the number of draft tokens increases.</p><details><summary>read the caption</summary>Figure 15: Empirical rejection times in acceptance-rejection sampling algorithm of the rejection phase.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/x16.png alt></figure></p><blockquote><p>üîº This figure visualizes the acceptance and rejection of tokens during the continuous speculative decoding process. The heatmap shows which tokens were accepted (dark green) and rejected (light green) by the target model during inference. This provides a visual representation of the model&rsquo;s decision-making process in the speculative decoding framework, highlighting which parts of the image were more easily or difficultly generated.</p><details><summary>read the caption</summary>Figure 16: Visualizations of accepted token heatmap. Dark green: accepted. Light green: rejected.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/extracted/6006952/figures/fox.png alt></figure></p><blockquote><p>üîº This figure compares image generation quality using the proposed continuous speculative decoding method with varying draft lengths (Œ≥) against the baseline method of using only the target model. Each row shows a category of images generated with different Œ≥ values. The leftmost column represents the target model (vanilla) output, providing a reference for comparison. Subsequent columns illustrate the results using the continuous speculative decoding method with increasing values of Œ≥, demonstrating the progression in image quality as more draft tokens are considered.</p><details><summary>read the caption</summary>Figure 17: Visual quality with increasing draft length Œ≥ùõæ\gammaitalic_Œ≥ compared with vanilla target model only generation. Best viewed zoom-in.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/extracted/6006952/figures/balloon.png alt></figure></p><blockquote><p>üîº This figure visualizes sample images generated by the Continuous Speculative Decoding method with a draft length (Œ≥) of 4. The generated images are all classified as arctic foxes (class label 297 from the ImageNet dataset). The figure showcases the visual quality of images produced using this method with a short draft sequence, offering insight into the model&rsquo;s performance at different draft lengths and its ability to generate coherent and relevant images.</p><details><summary>read the caption</summary>Figure 18: Visualization examples under Œ≥=4ùõæ4\gamma=4italic_Œ≥ = 4. Class label: arctic fox (297).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/extracted/6006952/figures/ice_cream.png alt></figure></p><blockquote><p>üîº This figure visualizes the results of image generation using the proposed continuous speculative decoding method. Specifically, it shows a grid of images generated with a draft length (Œ≥) of 8, all belonging to the &lsquo;balloon&rsquo; class (class ID 417 from the ImageNet dataset). Each image represents a sample generated by the model, demonstrating the variety and quality of images produced under these settings. The purpose is to show the visual results of the continuous speculative decoding approach for image generation and to demonstrate that the generated images maintain quality despite the speedup gained from speculative decoding.</p><details><summary>read the caption</summary>Figure 19: Visualization examples under Œ≥=8ùõæ8\gamma=8italic_Œ≥ = 8. Class label: balloon (417).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2411.11925/extracted/6006952/figures/volcano.png alt></figure></p><blockquote><p>üîº This figure displays a set of images generated by the model, showcasing the variety and quality of ice cream images produced. Each image is a different rendition of ice cream, demonstrating the model&rsquo;s capacity to generate diverse examples within a given class label. The images illustrate various types, presentations, and toppings of ice cream, highlighting the detailed and realistic generation capabilities of the model. The images were generated using a specific parameter setting (draft length (Œ≥)=16), indicating that this parameter might affect the quality or diversity of the generated images.</p><details><summary>read the caption</summary>Figure 20: Visualization examples under Œ≥=16ùõæ16\gamma=16italic_Œ≥ = 16. Class label: ice cream (928).</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>$M_p$</th><th>$M_q$</th><th>w/o CFG</th><th></th><th>w/ CFG</th><th></th></tr></thead><tbody><tr><td></td><td></td><td>FID ‚Üì</td><td>IS ‚Üë</td><td>FID ‚Üì</td><td>IS ‚Üë</td></tr><tr><td>MAR-L</td><td>MAR-L</td><td>2.60</td><td>221.4</td><td>1.78</td><td>296.0</td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>2.59 ¬± 0.04</td><td>218.4 ¬± 3.4</td><td>1.81 ¬± 0.05</td><td>303.7 ¬± 4.3</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>2.35</td><td>227.8</td><td>1.55</td><td>303.7</td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>2.36 ¬± 0.05</td><td>228.5 ¬± 2.2</td><td>1.60 ¬± 0.05</td><td>301.6 ¬± 2.6</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>2.34 ¬± 0.04</td><td>228.9 ¬± 2.8</td><td>1.57 ¬± 0.04</td><td>301.4 ¬± 2.5</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a comparison of Fr√©chet Inception Distance (FID) and Inception Score (IS) metrics for image generation on the ImageNet 256x256 dataset. It compares the performance of the original autoregressive model (MAR) with the proposed continuous speculative decoding method. The comparison is done for both unconditional and conditional image generation, demonstrating the impact of speculative decoding on both generation quality and speed. The results show that continuous speculative decoding achieves significant speedup without significantly sacrificing generation quality, remaining within a reasonable performance range of the baseline MAR model.</p><details><summary>read the caption</summary>Table 2: Evaluation of FID and IS comparison on ImageNet 256√ó256256256256\times 256256 √ó 256 unconditional and conditional generation. Continuous speculative decoding achieves acceleration while maintaining performance within a reasonable interval.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>$M_p$</th><th>$M_q$</th><th>$\gamma$</th><th>$\alpha$ (w/o align)</th><th>$\alpha$ (w/ align)</th></tr></thead><tbody><tr><td>MAR-L</td><td>MAR-B</td><td>32</td><td>0.10</td><td><strong>0.34</strong></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>16</td><td>0.12</td><td><strong>0.37</strong></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>8</td><td>0.12</td><td><strong>0.39</strong></td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>4</td><td>0.13</td><td><strong>0.37</strong></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>32</td><td>0.07</td><td><strong>0.30</strong></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>32</td><td>0.06</td><td><strong>0.33</strong></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>16</td><td>0.07</td><td><strong>0.33</strong></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>16</td><td>0.08</td><td><strong>0.35</strong></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>8</td><td>0.13</td><td><strong>0.31</strong></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>8</td><td>0.12</td><td><strong>0.34</strong></td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>4</td><td>0.14</td><td><strong>0.32</strong></td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>4</td><td>0.12</td><td><strong>0.34</strong></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents an ablation study analyzing the effect of denoising trajectory alignment on the acceptance rate in continuous speculative decoding. It compares the acceptance rates achieved with and without trajectory alignment across various model configurations, differing in draft and target model sizes and the number of draft tokens.</p><details><summary>read the caption</summary>Table 3: Ablation study on the impact of acceptance rate with and without denoising trajectory alignment.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>$M_p$</th><th>$M_q$</th><th>$\gamma$</th><th>$\alpha$/Speed</th><th></th><th></th></tr></thead><tbody><tr><td></td><td></td><td></td><td>$\alpha$/Speed</td><td>0%</td><td>5%</td></tr><tr><td>0%</td><td>5%</td><td>15%</td><td>MAR-L</td><td>MAR-B</td><td>32</td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>32</td><td>0.27/1.24 √ó</td><td>0.34/1.22 √ó</td><td><strong>0.37</strong>/1.21 √ó</td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>16</td><td>0.35/1.19 √ó</td><td>0.37/1.19 √ó</td><td><strong>0.38</strong>/1.17 √ó</td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>8</td><td>0.35/1.14 √ó</td><td><strong>0.39</strong>/1.13 √ó</td><td><strong>0.39</strong>/1.12 √ó</td></tr><tr><td>MAR-L</td><td>MAR-B</td><td>4</td><td>0.32/1.04 √ó</td><td>0.37/1.02 √ó</td><td><strong>0.39</strong>/1.00 √ó</td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>32</td><td>0.25/1.63 √ó</td><td>0.30/1.63 √ó</td><td><strong>0.33</strong>/1.61 √ó</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>32</td><td>0.24/1.36 √ó</td><td><strong>0.33</strong>/1.35 √ó</td><td>0.32/1.34 √ó</td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>16</td><td>0.32/1.53 √ó</td><td>0.33/1.52 √ó</td><td><strong>0.34</strong>/1.51 √ó</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>16</td><td>0.34/1.32 √ó</td><td><strong>0.35</strong>/1.29 √ó</td><td><strong>0.35</strong>/1.29 √ó</td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>8</td><td>0.33/1.47 √ó</td><td>0.31/1.47 √ó</td><td><strong>0.34</strong>/1.44 √ó</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>8</td><td>0.34/1.21 √ó</td><td>0.34/1.21 √ó</td><td><strong>0.35</strong>/1.21 √ó</td></tr><tr><td>MAR-H</td><td>MAR-B</td><td>4</td><td>0.31/1.21 √ó</td><td>0.32/1.21 √ó</td><td><strong>0.34</strong>/1.20 √ó</td></tr><tr><td>MAR-H</td><td>MAR-L</td><td>4</td><td>0.31/1.05 √ó</td><td><strong>0.34</strong>/1.03 √ó</td><td><strong>0.34</strong>/1.03 √ó</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents the results of an ablation study investigating the impact of the pre-filling ratio on the performance of continuous speculative decoding. The study varies the percentage of tokens pre-filled from the target model (0%, 5%, and 15%) while keeping other experimental settings consistent with Table 1. The results show the speedup achieved compared to the baseline and the acceptance rate (Œ±). The highest speedup for each setting is underlined and the highest acceptance rate is shown in bold. This allows for a direct comparison of speed and accuracy across different pre-filling strategies.</p><details><summary>read the caption</summary>Table 4: Ablation study on pre-filling ratio. The experimental configuration remains the same as Table¬†1. Underline indicates the highest speedup. Bold means the highest Œ±ùõº\alphaitalic_Œ±.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-ec7d1c860c4019809d21abe79ba2fa10 class=gallery><img src=https://ai-paper-reviewer.com/2411.11925/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2411.11925/18.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/&amp;title=Continuous%20Speculative%20Decoding%20for%20Autoregressive%20Image%20Generation" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/&amp;text=Continuous%20Speculative%20Decoding%20for%20Autoregressive%20Image%20Generation" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11925/&amp;subject=Continuous%20Speculative%20Decoding%20for%20Autoregressive%20Image%20Generation" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2411.11925/index.md",oid_likes="likes_paper-reviews/2411.11925/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2411.11767/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Drowning in Documents: Consequences of Scaling Reranker Inference</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-18T00:00:00+00:00>18 November 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2411.12364/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Ultra-Sparse Memory Network</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-11-19T00:00:00+00:00>19 November 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>