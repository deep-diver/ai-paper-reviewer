{"importance": "This paper is crucial for researchers working on **large language models (LLMs)** and **data synthesis**. It presents a novel method for expanding training datasets using a lightweight and scalable approach, offering a reliable pathway for scaling models beyond data limitations. The findings highlight the importance of prompt engineering and challenge conventional collapse detection metrics, opening new avenues for future research in synthetic data generation and LLM scaling.", "summary": "MAGA reformulates existing corpora to massively expand LLM pretraining data, boosting performance across various model sizes while maintaining quality.", "takeaways": ["MAGA, a lightweight and scalable method, significantly expands pretraining corpora by reformulating existing data.", "The expanded MAGACorpus consistently improves LLM performance across different model sizes, demonstrating the value of synthetic data.", "Prompt engineering is crucial for mitigating synthetic training collapse, while validation loss alone is insufficient for detecting it."], "tldr": "Current LLMs face a critical challenge: the scarcity of high-quality pretraining data.  Existing approaches for data augmentation, such as data repetition and upsampling, have limitations.  This paper introduces MAGA, a novel method that systematically synthesizes diverse and contextually-rich pretraining data from existing corpora. MAGA addresses this limitation by reformulating existing high-quality text collections into a significantly larger dataset, thereby overcoming the data bottleneck and enabling the training of larger and more powerful LLMs.\nMAGA utilizes a two-stage synthesis process involving a large language model and smaller, task-specific tool models. It incorporates a 'Limited Consistency' criterion for quality control and investigates the impact of prompt engineering on synthetic training. Experiments demonstrate consistent performance improvements across various model sizes, validating the effectiveness of MAGA in expanding training datasets and maintaining quality. Furthermore, the analysis challenges existing collapse detection metrics, shedding light on the limitations of using validation loss as a sole indicator.  This work provides valuable insights and a practical approach for scaling LLMs beyond data limitations.", "affiliation": "ByteDance", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2502.04235/podcast.wav"}