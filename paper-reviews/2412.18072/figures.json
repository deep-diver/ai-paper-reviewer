[{"figure_path": "https://arxiv.org/html/2412.18072/x1.png", "caption": "Figure 1: Illustration of MMFactory. Proposed MMFactory framework (a) contrasted with model routing approaches (c) and multimodal LLM with tools (b). Unlike both prior classes of methods, MMFactory proposes a pool of programmatic solutions, composed of series of selected models from the pool, for a given task while also benchmarking their performance and computational characteristics. See Section\u00a01 for full discussion.", "description": "Figure 1 compares MMFactory with two existing approaches for vision-language tasks: model routing and multimodal LLMs with tools.  Model routing selects a single model for a given task, while multimodal LLMs integrate tools within their framework.  In contrast, MMFactory proposes a diverse set of programmatic solutions for each task, each solution being a sequence of operations involving different models drawn from a model pool.  Moreover, MMFactory benchmarks the performance and computational cost of each proposed solution, allowing users to select the best option based on their constraints.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.18072/x2.png", "caption": "Figure 2: Overview of MMFactory. Our framework includes two primary components: Solution Router and Metric Router. The Solution Router generates a pool of potential solutions for the task, while the Metric Router evaluates these solutions, estimating their performance and computational cost to generate a performance curve. This curve enables users to select the model optimal for their task requirements.", "description": "MMFactory consists of two main parts: the Solution Router and the Metric Router.  The Solution Router takes in a task description and generates multiple potential solutions, each a program combining various vision and language models.  The Metric Router then evaluates these solutions, measuring their accuracy and computational cost.  This evaluation produces a performance curve, allowing users to compare solutions and select the one best suited to their needs (e.g., prioritizing accuracy over speed or vice-versa).", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.18072/x3.png", "caption": "Figure 3: Illustration of user specification inputs \ud835\udcabusuperscript\ud835\udcab\ud835\udc62\\mathcal{P}^{u}caligraphic_P start_POSTSUPERSCRIPT italic_u end_POSTSUPERSCRIPT.", "description": "Figure 3 shows an example of the user input specifications for the MMFactory framework.  The user needs to provide the following information: 1. TASK DEFINITION: This section describes the task. An example is provided where the user needs to identify the correspondence between a point in one image and several points in another image. 2. EXAMPLES from the task: This provides a few example inputs and outputs for the task to help the model understand the task requirements. 3. (OPTIONAL) USER CONSTRAINTS: This is an optional section, in which the user can specify additional constraints such as execution time or model size.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.18072/x4.png", "caption": "Figure 4: Illustration of multi-agent conversation. In the solution router, we have two team of agents performing conversation to get the final outputs.", "description": "This figure illustrates the multi-agent conversation process within the MMFactory's solution router.  Two teams of agents, the Solution Proposing Team and the Committee Team, engage in a conversation to collaboratively generate and refine solutions. The Solution Proposing Team is responsible for creating initial solution proposals, while the Committee Team reviews and provides feedback. This iterative process ensures that the final solution is robust, correct, and aligns with the user's requirements. The figure highlights the key agents involved and the flow of information between them.", "section": "3.3. Multi-agent solution router"}, {"figure_path": "https://arxiv.org/html/2412.18072/x5.png", "caption": "Figure 5: Qualitative examples of MMFactory. MMFactory\u00a0showcases its abilities to use and combine models by automatically constructing better prompts for MLLMs (in Sol 0) and developing solutions with similar logic but utilizing stronger models (in Sol 4).", "description": "Figure 5 presents qualitative examples illustrating MMFactory's capabilities.  It showcases how MMFactory automatically constructs improved prompts for large language models (LLMs), leading to more effective solutions (Solution 0, Sol 0).  Furthermore, it demonstrates MMFactory's ability to synthesize solutions with similar logical structures but employing more powerful models for enhanced performance (Solution 4, Sol 4). This highlights MMFactory's capacity to leverage and combine various models optimally.", "section": "4.2 Qualitative Analysis"}, {"figure_path": "https://arxiv.org/html/2412.18072/x6.png", "caption": "Figure 6: Ablation. Performance analysis with iteration. Lines in different colors represent different runs. Red cross denotes the highest performance in the run.", "description": "This figure presents an ablation study analyzing the effect of varying the number of iterations in a multi-agent conversation process within the MMFactory framework. Multiple runs were conducted, each represented by a different colored line, showing the model's performance (likely accuracy) across different numbers of iterations. The red cross on each line indicates the iteration with the highest performance achieved in that particular run. This visualization helps to determine the optimal number of iterations that balances performance gains against potential error propagation from excessive iterations.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.18072/x7.png", "caption": "Figure 7: Computational time. Solution generation cost plot (top). Average execution and routing cost per sample (bottom).", "description": "This figure presents a two-part analysis of computational costs. The top part shows a plot illustrating the time taken to generate solutions, highlighting the average time per iteration and the overall average time per solution.  The bottom part provides a table comparing the average execution and routing costs per sample for the MMFactory approach and a previous method (Sketchpad).  The execution cost reflects the total time from prompt input to final answer, while the routing cost represents the time spent coordinating tools (excluding tool execution). This comparison demonstrates the efficiency gains of the MMFactory approach in terms of both execution and routing times.", "section": "4. Experiments"}]