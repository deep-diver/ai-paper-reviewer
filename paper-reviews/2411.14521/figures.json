[{"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_compare_pretrained.jpg", "caption": "Figure 1: \nWe introduce MyTimeMachine to perform personalized age regression (top) and progression (bottom) by training a person-specific aging model from a few (\u223csimilar-to\\sim\u223c50) personal photos spanning over a 20-40 year range. Our method outperforms existing age transformation techniques to generate re-aged faces that closely resemble the characteristic facial appearance of the user at the target age.", "description": "This figure demonstrates the MyTimeMachine model's ability to perform both age regression and progression using a personalized approach. The top row showcases the model's age regression capabilities, taking an older image as input and generating a younger, realistic version while preserving the individual's identity. The bottom row illustrates the age progression function, starting with a younger image and producing an older, realistic representation.  In both cases, the model is trained on a relatively small number of personal photos (approximately 50) spanning 20-40 years.  The re-aged faces generated by MyTimeMachine are designed to closely resemble the individual's actual appearance at the target age, representing an improvement over existing general-purpose age transformation techniques.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_regression.jpg", "caption": "Figure 2: \nGiven an input face of Oprah Winfrey at 70 years old, our adapter re-ages her face to resemble her appearance at 30, while preserving the style of the input image.\nTo achieve personalized re-aging, we collect \u223csimilar-to\\sim\u223c50 images of an individual across different ages and train an adapter network that updates the latent code generated by the global age encoder SAM.\nOur adapter preserves identity during interpolation when the target age falls within the range of ages seen in the training data, while also extrapolating well to unseen ages.", "description": "This figure shows the results of the MyTimeMachine model on an image of Oprah Winfrey.  The input is a 70-year-old image. The model successfully de-ages the image to make Oprah appear to be approximately 30, maintaining the style and identity of the original image. This is achieved by training a personalized model using around 50 images of the same person across their lifespan, combined with a pre-trained global aging model (SAM). The adapter network adjusts the global aging features with personalized aging features, resulting in accurate and consistent re-aging across a range of target ages, both within and outside the training age range. ", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/user_study.jpg", "caption": "Figure 3: \nPerformance of age transformation techniques for age regression (first two rows) and age progression (last two rows). The first column shows the input image, and the second column provides a reference image of the same person at the target age. MyTM (Ours) is compared against other state-of-the-art methods including SAM\u00a0[2], CUSP\u00a0[14], AgeTransGAN\u00a0[17], and FADING\u00a0[7].", "description": "Figure 3 presents a comparison of facial age transformation results using different techniques. The top two rows illustrate age regression, where an older image is transformed to appear younger, while the bottom two rows show age progression where a younger image is transformed to appear older. Each set of rows shows results for a different individual. The leftmost column of each row displays the original input image of a particular individual. The second column provides a reference image of the same individual at the desired target age.  The remaining columns display the results obtained using different age transformation techniques: MyTimeMachine (the authors' proposed method), SAM, CUSP, AgeTransGAN, and FADING. This allows for a visual comparison of the quality and accuracy of each method in achieving realistic and identity-preserving transformations.", "section": "4.2. Comparison with Age Transformation Methods"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/video_reaging.jpg", "caption": "Figure 4: Performance of age transformation techniques for age regression, where an input test image around 70 is transformed to all target ages between 0 and 100. We show MyTM (Ours) trained on 40 years of data (ages 30\u223c70similar-to307030\\sim 7030 \u223c 70), with the age range included in the personal training data highlighted in red. An example image of the same person within 3 years of the target age is provided as a reference at bottom.", "description": "Figure 4 presents a comparison of different facial age transformation methods, focusing on age regression.  The input is a single image of a person around age 70.  Each method is used to generate images of the same person at various ages ranging from 0 to 100.  The results from MyTimeMachine (MyTM), the proposed method, are shown, along with results from several existing methods. The MyTM model was trained on a dataset spanning 40 years (ages 30-70), and the age range used in the training set is highlighted in red for each individual\u2019s results. A reference image of the person at an age close to the target age (\u00b13 years) is included at the bottom of the figure for comparison, helping to visually assess the accuracy of the different techniques in generating realistic-looking faces.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_progression.jpg", "caption": "Figure 5: User Study comparing our method with baselines\u2014FADING and SAM\u2014for age regression (atgt\u226470subscript\ud835\udc4etgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT \u2264 70) and age progression (atgt\u226540subscript\ud835\udc4etgt40a_{\\text{tgt}}\\geq 40italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT \u2265 40).\nWe present the percentage of user preference for our method over the baselines.", "description": "This figure presents the results of a user study comparing the authors' proposed method for age transformation against two state-of-the-art baselines: FADING and SAM.  The study focused on two scenarios: age regression (making someone look younger, where the target age is less than or equal to 70) and age progression (making someone look older, where the target age is greater than or equal to 40). The figure shows the percentage of times users preferred the authors' method over each baseline in each scenario, indicating the relative preference for the proposed method in terms of visual quality and accuracy of age transformation.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/fading_failure.jpg", "caption": "Figure 6: We apply video re-aging on a video of Jackie Chan from the movie Bleeding Steel. Left: The keyframe from the source video that we re-age with MyTM. Right: The re-aged face is mapped onto other frames of the source video via face-swapping.", "description": "This figure demonstrates the application of the MyTimeMachine (MyTM) model to video re-aging.  A keyframe from a video of Jackie Chan in the movie *Bleeding Steel* is selected. The MyTM model is used to re-age Jackie Chan's face in this keyframe.  Then, using face-swapping techniques, this re-aged face is seamlessly integrated into all the other frames of the original video, resulting in a temporally consistent video where Jackie Chan appears younger.", "section": "4.3. MyTM for Video Re-aging"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_baseline.jpg", "caption": "Figure 7:  Effect of training dataset size \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D on personalization. MyTM is trained on ages 30\u223csimilar-to\\sim\u223c70 and tested for atgt\u226470subscript\ud835\udc4etgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT \u2264 70. Visual examples of Robert De Niro are shown at the top, with quantitative results displayed below.", "description": "This figure demonstrates the impact of the training dataset size on the performance of the MyTimeMachine model.  The experiment focuses on age regression, where the model de-ages a 70-year-old face to a younger age (atgt\u226470).  The model was trained on a range of ages from 30 to 70. The figure displays examples of the results generated from using training datasets of various sizes (10, 50, and 100 images) for Robert De Niro.  The quantitative results, shown below the images, demonstrate the improvement in the quality of age transformation as the dataset size increases, indicating that using larger amounts of training data leads to better personalization and generalization.", "section": "4.1 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_regression_oprah.jpg", "caption": "Figure 8: \nContributions of our proposed loss functions and the adapter network for the age regression task, trained on ages 30\u223csimilar-to\\sim\u223c70 and tested for atgt\u226470subscript\ud835\udc4etgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT \u2264 70 on Al Pacino.", "description": "This figure demonstrates the impact of each component of the proposed personalized age transformation network, MyTimeMachine, on age regression performance.  It shows the results of experiments conducted on Al Pacino's images, using data spanning ages 30 to 70 for training and testing on images with target ages less than or equal to 70.  The ablation study progressively adds components\u2014a personalized aging loss, extrapolation regularization, and adaptive w-norm regularization\u2014to the baseline SAM model, and an adapter network, to show their individual contribution to the overall performance. The results illustrate improvements in identity preservation (IDsim) as each component is added.", "section": "3. MyTM: Designing a Personalized Age Adapter"}]