[{"figure_path": "2410.20474/figures/figures_1_0.png", "caption": "Figure 1: Spatially grounded images generated by our GROUNDIT. Each image is generated based on a text prompt along with bounding boxes, which are displayed in the upper right corner of each image. Compared to existing methods that often struggle to accurately place objects within their designated bounding boxes, our GROUNDIT enables more precise spatial control through a novel noisy patch transplantation mechanism.", "description": "Figure 1 shows spatially grounded images generated by the proposed GROUNDIT model, highlighting its ability to precisely place objects within designated bounding boxes compared to existing methods.", "section": "Introduction"}, {"figure_path": "2410.20474/figures/figures_4_0.png", "caption": "Figure 2: A single denoising step of GROUNDIT consists of two stages. Stage 1 (Sec. 5.1) performs Global Update, which updates the noisy image xt using a custom loss function and obtains t. Stage 2 (Sec. 5.3) performs Local Update, providing fine-grained control over individual bounding boxes through a novel noisy patch cultivation-transplantation technique.", "description": "The figure illustrates the two-stage denoising process in GROUNDIT, showing how global and local updates are performed using cross-attention maps and noisy patch transplantation.", "section": "5 GROUNDIT: Grounding Diffusion Transformers"}, {"figure_path": "2410.20474/figures/figures_6_0.png", "caption": "Figure 3: (A) Joint Token Denoising (Alg. 1). Two different noisy images, xt and yt, are each assigned positional embeddings based on their respective sizes. The two sets of image tokens are then merged and passed through DiT for a denoising step. Afterward, the denoised tokens are split back into xt\u22121 and yt\u22121. (B), (C) Semantic Sharing. Denoising two noisy images using joint token denoising results in semantically correlated content between the generated images. Here, y indicates that joint token denoising is during the initial 100% of the timesteps, after which the images are denoised for the remaining steps.", "description": "This figure illustrates the process of joint token denoising in diffusion transformers and demonstrates the phenomenon of semantic sharing, where denoising two images jointly leads to semantically similar outputs.", "section": "5.2 Semantic Sharing in Diffusion Transformers"}, {"figure_path": "2410.20474/figures/figures_9_0.png", "caption": "Figure 4: Qualitative comparisons between our GROUNDIT and baselines. Leftmost column shows the input bounding boxes, and columns 2\u20136 include the baseline results. The rightmost column includes the results of our GROUNDIT.", "description": "Figure 4 qualitatively compares the spatial grounding performance of GROUNDIT against several baselines across various text prompts and bounding boxes.", "section": "6 Results"}, {"figure_path": "2410.20474/figures/figures_14_0.png", "caption": "Figure 1: Spatially grounded images generated by our GROUNDIT. Each image is generated based on a text prompt along with bounding boxes, which are displayed in the upper right corner of each image. Compared to existing methods that often struggle to accurately place objects within their designated bounding boxes, our GROUNDIT enables more precise spatial control through a novel noisy patch transplantation mechanism.", "description": "The figure shows spatially grounded images generated by the proposed method, GROUNDIT, showcasing its ability to accurately place objects within designated bounding boxes.", "section": "Introduction"}, {"figure_path": "2410.20474/figures/figures_14_1.png", "caption": "Figure 5: Spatially grounded images generated by our GrounDiT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows example images generated by GrounDiT with varying aspect ratios and sizes, each based on a text prompt and bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_17_0.png", "caption": "Figure 5: Spatially grounded images generated by our GROUNDIT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows example images generated by the proposed GROUNDIT model with varying aspect ratios and sizes, demonstrating its ability to accurately place objects within specified bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_17_1.png", "caption": "Figure 5: Spatially grounded images generated by our GrounDiT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows examples of images generated by GrounDiT with varying aspect ratios and sizes, demonstrating the model's ability to accurately place objects within specified bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_17_2.png", "caption": "Figure 5: Spatially grounded images generated by our GROUNDIT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows examples of images generated by the proposed GROUNDIT model with varying aspect ratios and sizes, each based on a text prompt and bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_17_3.png", "caption": "Figure 5: Spatially grounded images generated by our GROUNDIT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows examples of images generated by the GROUNDIT model with different aspect ratios and bounding boxes, demonstrating the model's ability to generate images that accurately reflect the given text prompts and spatial constraints.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_17_4.png", "caption": "Figure 5: Spatially grounded images generated by our GROUNDIT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows examples of images generated by the proposed GROUNDIT model, demonstrating its ability to generate images with varying aspect ratios and sizes while maintaining accurate spatial grounding.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_19_0.png", "caption": "Figure 4: Qualitative comparisons between our GROUNDIT and baselines. Leftmost column shows the input bounding boxes, and columns 2-6 include the baseline results. The rightmost column includes the results of our GROUNDIT.", "description": "Figure 4 presents a qualitative comparison of GROUNDIT against several baseline methods for spatially grounded image generation, showcasing GROUNDIT's superior performance in handling complex grounding conditions.", "section": "6 Results"}, {"figure_path": "2410.20474/figures/figures_20_0.png", "caption": "Figure 5: Spatially grounded images generated by our GrounDiT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows examples of images generated by the GrounDiT model, demonstrating its ability to generate images with varying aspect ratios and sizes while accurately placing objects within specified bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_20_1.png", "caption": "Figure 1: Spatially grounded images generated by our GROUNDIT. Each image is generated based on a text prompt along with bounding boxes, which are displayed in the upper right corner of each image. Compared to existing methods that often struggle to accurately place objects within their designated bounding boxes, our GROUNDIT enables more precise spatial control through a novel noisy patch transplantation mechanism.", "description": "Figure 1 shows spatially grounded images generated by the proposed GROUNDIT model, highlighting its ability to accurately place objects within specified bounding boxes compared to existing methods.", "section": "Introduction"}, {"figure_path": "2410.20474/figures/figures_20_2.png", "caption": "Figure 2: A single denoising step of GROUNDIT consists of two stages. Stage 1 (Sec. 5.1) performs Global Update, which updates the noisy image xt using a custom loss function and obtains t. Stage 2 (Sec. 5.3) performs Local Update, providing fine-grained control over individual bounding boxes through a novel noisy patch cultivation-transplantation technique.", "description": "The figure illustrates the two-stage denoising process in the GROUNDIT framework, showing the global update stage using cross-attention maps and the local update stage using noisy patch transplantation for fine-grained spatial control.", "section": "5 GROUNDIT: Grounding Diffusion Transformers"}, {"figure_path": "2410.20474/figures/figures_20_3.png", "caption": "Figure 2: A single denoising step of GROUNDIT consists of two stages. Stage 1 (Sec. 5.1) performs Global Update, which updates the noisy image xt using a custom loss function and obtains t. Stage 2 (Sec. 5.3) performs Local Update, providing fine-grained control over individual bounding boxes through a novel noisy patch cultivation-transplantation technique.", "description": "The figure illustrates the two-stage denoising process in the proposed GROUNDIT model, showing the global update stage and the local update stage with noisy patch cultivation and transplantation.", "section": "5 GROUNDIT: Grounding Diffusion Transformers"}, {"figure_path": "2410.20474/figures/figures_20_4.png", "caption": "Figure 5: Spatially grounded images generated by our GROUNDIT with varying aspect ratios and sizes. Each image is generated based on a text prompt along with bounding boxes, which are displayed next to (or below) each image.", "description": "Figure 5 shows example images generated by the proposed GROUNDIT model, highlighting its ability to generate images with diverse aspect ratios and sizes according to the given bounding boxes.", "section": "A Appendix"}, {"figure_path": "2410.20474/figures/figures_20_5.png", "caption": "Figure 2: A single denoising step of GROUNDIT consists of two stages. Stage 1 (Sec. 5.1) performs Global Update, which updates the noisy image xt using a custom loss function and obtains t. Stage 2 (Sec. 5.3) performs Local Update, providing fine-grained control over individual bounding boxes through a novel noisy patch cultivation-transplantation technique.", "description": "The figure illustrates the two-stage denoising process of the GROUNDIT model, showing global and local updates for fine-grained spatial control.", "section": "5 GROUNDIT: Grounding Diffusion Transformers"}, {"figure_path": "2410.20474/figures/figures_20_6.png", "caption": "Figure 9: Additional spatially grounded images generated by out GROUNDIT.", "description": "Figure 9 shows additional examples of images generated by the GROUNDIT model, demonstrating its ability to accurately place objects within their corresponding bounding boxes, even in more complex scenes.", "section": "Results"}, {"figure_path": "2410.20474/figures/figures_20_7.png", "caption": "Figure 1: Spatially grounded images generated by our GROUNDIT. Each image is generated based on a text prompt along with bounding boxes, which are displayed in the upper right corner of each image. Compared to existing methods that often struggle to accurately place objects within their designated bounding boxes, our GROUNDIT enables more precise spatial control through a novel noisy patch transplantation mechanism.", "description": "The figure shows examples of spatially grounded images generated by the proposed GROUNDIT model, highlighting its ability to accurately place objects within specified bounding boxes.", "section": "Introduction"}, {"figure_path": "2410.20474/figures/figures_20_8.png", "caption": "Figure 9: Additional spatially grounded images generated by out GROUNDIT.", "description": "Figure 9 shows additional examples of images generated by the proposed GROUNDIT model, demonstrating its ability to generate images with multiple objects precisely placed within their designated bounding boxes.", "section": "Results"}]