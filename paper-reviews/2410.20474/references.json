{"references": [{" publication_date": "2022", "fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "reason": "This paper is highly relevant as it introduces Flamingo, a visual language model that demonstrates strong few-shot learning capabilities.  This is important for the current research, which focuses on training-free techniques, because efficient few-shot learning can facilitate effective use of limited training data, making it a valuable building block for other training-free models. Furthermore, Flamingo's visual capabilities and ability to handle language inputs are directly applicable to the text-to-image task tackled in the current research.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Omri Avrahami", "paper_title": "Spatext: Spatio-textual representation for controllable image generation", "reason": "This paper is significant because it introduces SpaText, a model that combines spatial and textual information effectively for image generation. This direct relevance to the problem of spatial grounding in text-to-image synthesis makes it a crucial reference. The incorporation of spatial information, which is a core aspect of the current research's focus, establishes it as highly important.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Eslam Mohamed Bakr", "paper_title": "HRS-bench: Holistic, reliable and scalable benchmark for text-to-image models", "reason": "The HRS-bench is crucial for evaluating the performance of the proposed text-to-image model, GROUNDIT. The benchmark provides a holistic assessment of spatial grounding accuracy, encompassing spatial, size, and color aspects, enabling comprehensive comparison against existing methods.  Its rigorous evaluation criteria are directly applicable to the current work, making it a cornerstone for evaluating the effectiveness of GROUNDIT and situating it within the existing landscape of research.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Omer Bar-Tal", "paper_title": "MultiDiffusion: Fusing diffusion paths for controlled image generation", "reason": "This work, focusing on controlled image generation via diffusion models, offers important insights applicable to the current research.  MultiDiffusion demonstrates the possibility of combining different diffusion paths to control the generation process effectively.  This controlled generation aspect, where the output image conforms to specific criteria or conditions, is directly related to the spatial grounding task tackled in the current paper, making this approach an important reference point.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This paper is foundational to the field of diffusion models, introducing a new approach to generative modeling based on the concept of denoising. The core ideas presented in this work, such as the forward diffusion process (adding noise) and the reverse process (denoising), are essential to understanding the mechanisms behind diffusion-based models such as DiT. This makes it a critical foundation for the current research.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Hila Chefer", "paper_title": "Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models", "reason": "This paper's exploration of attention mechanisms and their role in generating text-to-image diffusion models directly informs the current research's use of cross-attention maps in the spatial grounding process. The demonstrated efficacy of using attention maps to refine image generation based on text is directly relevant to the proposed GROUNDIT method. The emphasis on semantic alignment between image regions and text is particularly pertinent to the current spatial grounding focus.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Junsong Chen", "paper_title": "Pixart-\u03b1: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "reason": "PixArt-\u03b1 is the specific text-to-image diffusion model used as a basis for the GROUNDIT model.  Understanding its architecture and functionalities is essential for interpreting and evaluating the novel contributions of the current research because it serves as the foundational framework upon which GROUNDIT's improvements and innovations are built. Its utilization in the experiments and comparisons of results makes this a central and key reference.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Minghao Chen", "paper_title": "Training-free layout control with cross-attention guidance", "reason": "This paper is highly relevant because it provides a training-free approach to layout control in image generation. The approach directly addresses the challenge of spatial control without requiring model retraining, making it a crucial comparison point for the novel method proposed in the current research.  The paper's focus on training-free methods, its demonstrated ability to manipulate spatial aspects of the generated images, and its employment of cross-attention maps all establish its strong relevance.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Guillaume Couairon", "paper_title": "Zero-shot spatial layout conditioning for text-to-image diffusion models", "reason": "This paper provides a comparative training-free method for achieving spatial grounding in text-to-image diffusion models.  It directly addresses the same challenge of spatial control as the current research, offering a baseline for comparison and providing context for the proposed improvements.  Its methodology, which focuses on zero-shot capabilities, is aligned with the current research's emphasis on training-free approaches. The use of spatial layout conditioning further underscores its relevance.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Dave Epstein", "paper_title": "Diffusion self-guidance for controllable image generation", "reason": "This paper explores self-guidance in diffusion models for enhanced controllability during image generation, which is highly relevant to the present work's focus on achieving fine-grained control.  The use of diffusion models and the aim for better control over the generated images provide clear points of comparison with the novel methods proposed in the current research. The methods for improving control during the generation process are directly applicable to the challenge of precise spatial grounding.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "reason": "This paper showcases advancements in high-resolution image synthesis using rectified flow transformers, which offers insights into scaling up generative models. This aspect of scalability is important to the context of the current research, particularly in handling images with varying aspect ratios and multiple objects, each requiring its own attention. This makes it a valuable reference for understanding advanced model architectures and their capabilities.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Weixi Feng", "paper_title": "Training-free structured diffusion guidance for compositional text-to-image synthesis", "reason": "This paper tackles a similar problem using a training-free approach, focusing on structured diffusion guidance for text-to-image generation. The relevance stems from the shared goal of achieving precise spatial control without requiring extensive model retraining.  This serves as a strong comparison point for evaluating the performance and novelty of the proposed approach. The focus on compositionality is also pertinent to the current research, which strives to handle complex images with multiple objects.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Songwei Ge", "paper_title": "Expressive text-to-image generation with rich text", "reason": "This paper demonstrates a method for generating expressive images from rich text inputs. The emphasis on expressive image generation is relevant to the current research's goal of achieving high-quality images that faithfully represent both the global text prompt and local spatial constraints. This method helps contextually establish the value of generating high-quality images with attention to details.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Oran Gafni", "paper_title": "Make-a-scene: Scene-based text-to-image generation with human priors", "reason": "This paper explores scene-based text-to-image generation, providing insights into the incorporation of contextual information and spatial priors into the generation process.  The use of scene-based information and human priors directly relates to the current research's aim for achieving precise spatial grounding. This contextual information helps contextualize the problem and highlight the need for methods that go beyond simple text-to-image generation.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xiefan Guo", "paper_title": "Initno: Boosting text-to-image diffusion models via initial noise optimization", "reason": "This paper focuses on optimizing the initial noise in text-to-image diffusion models for improved image generation.  The technique of manipulating the initial noise is indirectly relevant to the current research's method of generating and transplanting noisy image patches.  This paper offers insights into how initial conditions influence the outcome of the generation process, providing a relevant context for discussing the impact of starting conditions in the GROUNDIT method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Amir Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "reason": "This paper's focus on prompt-to-prompt image editing, specifically using cross-attention control, is directly relevant to the current research's use of cross-attention maps in the spatial grounding process. The techniques and findings described in this paper are directly relevant for understanding the potential of leveraging attention mechanisms for precise control of generated images. The use of cross-attention maps informs the GROUNDIT framework's approach.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This foundational paper introduces the concept of denoising diffusion probabilistic models, which forms the theoretical basis for many modern generative models, including the Diffusion Transformers used in the current research.  Understanding the underlying principles of diffusion models is essential for comprehending the mechanisms behind both existing and novel approaches in image generation.  This paper provides the key theoretical foundation upon which DiT and the techniques in the current paper are built.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Hyeonho Jeong", "paper_title": "Ground-a-video: Zero-shot grounded video editing using text-to-image diffusion models", "reason": "This work extends text-to-image diffusion models to video editing, offering a broader context for the applications of spatial grounding.  The zero-shot capability is also relevant to the current research's training-free approach. The extension of similar techniques from images to videos highlights potential future directions in the application of spatial grounding and showcases a related area where similar challenges need to be addressed.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jaihoon Kim", "paper_title": "Synctweedies: A general generative framework based on synchronized diffusions", "reason": "This paper presents a general generative framework based on synchronized diffusions, offering insights into potential improvements and innovations that can be made in diffusion-based image generation. This is relevant to the current research as it explores a general framework for improving image generation, an area directly related to the proposed GROUNDIT model. Studying different generative frameworks informs the current research's choices and potential avenues for enhancements.", "section_number": 2}]}