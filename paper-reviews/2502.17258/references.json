{"references": [{"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This is the foundational paper on Stable Diffusion, the base model used by VideoGrain."}, {"fullname_first_author": "Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-10-01", "reason": "This work introduces ControlNet, a crucial component for providing structural guidance in video editing, and VideoGrain demonstrates versatility to ControlNet conditions."}, {"fullname_first_author": "Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2022-01-01", "reason": "This work is used by VideoGrain to perform editing with FateZero."}, {"fullname_first_author": "Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2021-01-01", "reason": "VideoGrain performs DDIM Inversion over the clean latent space."}, {"fullname_first_author": "Cong", "paper_title": "FLATTEN: optical flow-guided attention for consistent text-to-video editing", "publication_date": "2023-01-01", "reason": "VideoGrain employs FLATTEN for fair comparision with other baselines."}]}