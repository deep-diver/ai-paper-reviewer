[{"figure_path": "https://arxiv.org/html/2412.11689/x1.png", "caption": "Figure 1: Results of UnSplit attack on MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): MLP-based client model.", "description": "This figure presents a comparison of the UnSplit attack's effectiveness on MNIST data when employing different client-side models in a split learning setup. The top row displays the original MNIST images. The middle row showcases the reconstructed images when a CNN-based model is used on the client-side.  Lastly, the bottom row reveals the reconstructed images when an MLP-based model is used on the client-side.  The key observation is the failure of the UnSplit attack to reconstruct meaningful images when using the MLP-based client model, suggesting improved privacy preservation.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x2.png", "caption": "Figure 2: Results of UnSplit attack on F-MNIST. (Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): MLP-based client model.", "description": "This figure presents a comparison of the UnSplit attack's effectiveness on Fashion-MNIST data when employed against two different client model architectures in a Split Learning setup. The top row displays the original Fashion-MNIST images. The middle row shows the reconstructed images when a CNN-based model is used on the client-side. The bottom row presents the reconstructed images when an MLP-based model is employed on the client-side. As can be seen, the CNN-based client model is vulnerable to the attack.  The MLP-based client model, however, is resistant, with the attack failing to recover any meaningful representation of the original data.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x3.png", "caption": "Figure 3: Results of FSHA attack on MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): MLP-based client model.", "description": "This figure presents a comparison of the Feature-space Hijacking Attack (FSHA) performance on the MNIST dataset under two different client model architectures: a CNN-based model and an MLP-based model. The top row displays the original MNIST images. The middle row shows the reconstructed images when the client model uses a CNN architecture.  The bottom row illustrates the attack outcome when using an MLP-based client model. The figure aims to visually demonstrate the effectiveness of FSHA against these two architectures by comparing the quality of the reconstructed images. As shown in the figure, the attack achieves higher reconstruction quality with the CNN client model and fails when the client-side architecture contains dense layers.", "section": "4.2 FSHA"}, {"figure_path": "https://arxiv.org/html/2412.11689/x4.png", "caption": "Figure 4: Results of FSHA attack on F-MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): MLP-based client model.", "description": "This figure presents a comparison of the Feature-space Hijacking Attack (FSHA) on the Fashion-MNIST (F-MNIST) dataset with different client model architectures. The top row displays the original images. The middle row shows the reconstructed images when the client model is a Convolutional Neural Network (CNN).  The bottom row shows the reconstructed images when the client model is a Multilayer Perceptron (MLP).  The comparison demonstrates that FSHA is effective in reconstructing the original images when a CNN is used but fails when an MLP is used, highlighting the vulnerability of CNN-based client models and the robustness of MLP-based client models to this specific attack.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x5.png", "caption": "Figure 5: Encoder-decoder error and Reconstruction error for FSHA attack", "description": "This figure presents the Encoder-Decoder error and the Reconstruction error for the Feature-space Hijacking Attack (FSHA). The Encoder-Decoder error represents the mean squared error (MSE) between the original images from a public dataset and the images reconstructed using an encoder-decoder model. The Reconstruction error, on the other hand, denotes the MSE between the original private data held by the client and the data reconstructed by the attacker (server) using the client\u2019s model activations. The figure showcases these errors for both CNN-based and MLP-based client models across MNIST and Fashion-MNIST (F-MNIST) datasets. It illustrates that the encoder-decoder pair performs equally well in reconstructing public data, irrespective of the client's model architecture. However, the attack's success in reconstructing private data significantly depends on the client-side architecture, with MLP-based models demonstrating greater resistance to reconstruction.", "section": "4.2 FSHA"}, {"figure_path": "https://arxiv.org/html/2412.11689/x6.png", "caption": "Figure 6: Results of UnSplit attack on CIFAR-10.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): MLP-Mixer client model.", "description": "Figure 6 presents a comparison of the UnSplit attack's effectiveness on CIFAR-10 images when employing two different client model architectures within the Split Learning framework. The top row displays the original CIFAR-10 images. The middle row showcases the reconstructed images when a CNN-based model is used on the client-side. The bottom row presents the reconstructed images when an MLP-Mixer model is used on the client-side.  The figure visually demonstrates that using the MLP-Mixer model, which incorporates dense layers, makes the UnSplit attack ineffective at reconstructing the original images, supporting Hypothesis 1 of the paper.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x7.png", "caption": "Figure 7: While optimizing the non-convex function f\u2062(x)\ud835\udc53\ud835\udc65f(x)italic_f ( italic_x ), Adam can get stuck in the local minima in depence on the initialization.", "description": "This figure demonstrates how the Adam optimizer's performance can be affected by initialization when applied to the non-convex function f(y) = y\u00b2 + 6sin\u00b2(y), where y = W\u1d40X. The plot shows the function's value over optimization steps for two different initializations of W and X. The \"before rotation\" line represents the optimization path with the original initialization, converging towards the global minimum at y = 0. The \"after rotation\" line shows the optimization path after applying an orthogonal transformation to both W and X. In this scenario, the optimizer gets stuck in a local minimum, failing to reach the global optimum. This illustrates that for non-convex functions, the behavior of Adam, and potentially other adaptive optimizers, can be sensitive to the initial values of the weights and data.", "section": "A.4 Convergence"}, {"figure_path": "https://arxiv.org/html/2412.11689/x8.png", "caption": "Figure 8: MSE across different classes for the UnSplit attack.\n(Top row): CIFAR-10 \u2013 MLP-Mixer and CNN-based models.\n(Middle row): F-MNIST \u2013 MLP and CNN-based models.\n(Bottom row): MNIST \u2013 MLP and CNN-based models.", "description": "This figure presents Mean Squared Error (MSE) results across different classes for the UnSplit attack on three datasets: CIFAR-10, F-MNIST, and MNIST.  The top row shows results on CIFAR-10 using both an MLP-Mixer and a CNN-based client model. The middle row displays results on F-MNIST with MLP and CNN-based client models. The bottom row presents results on MNIST also with MLP and CNN-based client models.  Each plot within the rows shows the MSE for both the reconstructed image (Reconstruction MSE) and the intermediate activations at the cut layer (Cut Layer MSE). This allows for a comparison of the error in both the input space and the latent space at the cut layer for each class in the respective dataset.", "section": "C Additional experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x9.png", "caption": "Figure 9: Results of UnSplit attack on MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): SmallMLP client model.", "description": "This figure presents a comparison of the UnSplit attack's reconstruction capabilities on the MNIST dataset, showcasing the impact of client-side model architecture. The top row displays the original MNIST images. The middle row illustrates the reconstructed images when the client utilizes a CNN-based model, while the bottom row shows the results when the client employs a smaller MLP-based model (SmallMLP) designed to have a similar number of parameters as the CNN. Notably, even with this smaller MLP model, the UnSplit attack struggles to reconstruct meaningful images, aligning with the paper's core argument about the resistance of MLP-based architectures to such attacks.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x10.png", "caption": "Figure 10: Results of UnSplit attack on F-MNIST. (Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): SmallMLP client model.", "description": "Figure 10 shows the reconstruction results of the UnSplit attack on the Fashion-MNIST (F-MNIST) dataset. The top row displays the original images. The middle row presents the reconstructions when a CNN-based model is used on the client-side, which in this case results in almost perfect reconstruction of the input data. The bottom row shows the reconstructions when a much smaller MLP-based model (SmallMLP) is used on the client-side. As expected by the theory presented in the paper, the attacker cannot succeed against SmallMLP, highlighting that the usage of simple transformations (like usage of MLP instead of CNN) can be enough for data protection in Vertical Federated Learning.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x11.png", "caption": "Figure 11: Results of FSHA attack on MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): SmallMLP client model.", "description": "This figure presents the results of the Feature Space Hijacking Attack (FSHA) on the MNIST dataset. The top row displays the original MNIST images. The middle row shows the reconstructed images when a CNN-based model is used on the client-side. The bottom row presents the reconstructed images when a smaller MLP-based model (SmallMLP) is used on the client-side. As can be seen, the FSHA attack successfully reconstructs the original images when the client uses a CNN-based model. However, it completely fails when the client model is a SmallMLP model.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11689/x12.png", "caption": "Figure 12: Results of FSHA attack on F-MNIST.\n(Top): Original images.\n(Middle): CNN-based client model.\n(Bottom): SmallMLP client model.", "description": "This figure presents a comparison of the Feature-space Hijacking Attack (FSHA) results on the Fashion-MNIST (F-MNIST) dataset with two different client models. The top row displays the original images from the dataset.  The middle row shows the reconstruction results when a CNN-based model is used on the client-side. The bottom row shows the results when a smaller MLP-based model (SmallMLP) is used on the client side. SmallMLP is not as accurate as the four-layer MLP in other experiments but is designed to match CNN's number of parameters. As demonstrated, the CNN client model allows near-perfect reconstruction of the private data by the malicious server, while the MLP-based model effectively thwarts the attack.", "section": "4 Experiments"}]