[{"figure_path": "2410.18072/figures/figures_2_0.png", "caption": "Figure 1: Overview of the hierarchical capabilities of the Predictive Models. Models at higher stages demonstrate more advanced capabilities. We take the initial step in evaluating Predictive Generative Models up to the S3 stage, known as World Simulators, by introducing a parallel evaluation framework, WorldSimBench. WorldSimBench assesses the models both Explicit Perceptual Evaluation and Implicit Manipulative Evaluation, focusing on video generation and action transformation across three critical embodied scenarios.", "description": "Figure 1 provides a hierarchical overview of predictive models' capabilities, introducing WorldSimBench, a dual evaluation framework for World Simulators focusing on video generation and action transformation across three embodied scenarios.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/figures/figures_5_0.png", "caption": "Figure 2: Overview of Explicit Perceptual Evaluation. (Top) Instruction Prompt Generation. We use a large collection of video captions from the internet and our predefined embodied evaluation dimensions. These are expanded using GPT and manually verified to create a corresponding Task Instruction Prompt List for data generation and evaluation. (Bottom) HF-Embodied Dataset Generation. Massive internet-sourced embodied videos with captions are used to train data generation models. Fine-grained Human Feedback Annotation is then applied to the embodied videos according to the corresponding Task Instruction Prompt List, covering multiple embodied dimensions.", "description": "The figure illustrates the process of Explicit Perceptual Evaluation, including instruction prompt generation and HF-Embodied dataset generation with fine-grained human feedback annotation.", "section": "4.1 EXPLICIT PERCEPTUAL EVALUATION"}, {"figure_path": "2410.18072/figures/figures_7_0.png", "caption": "Figure 3: Overview of Implicit Manipulative Evaluation. Embodied tasks in different scenarios are decomposed into executable sub-tasks. The video generation model generates corresponding predicted videos based on the current instructions and real-time observations. Using a pre-trained IDM or a goal-based policy, the agent executes the generated sequence of actions. After a fixed timestep, the predicted video is refreshed by sampling again from the video generation model, and this process repeats. Finally, the success rates of various embodied tasks are obtained through monitors in the simulation environment.", "description": "The figure illustrates the Implicit Manipulative Evaluation process, decomposing embodied tasks into sub-tasks, using video generation models and video-to-action mapping for evaluation.", "section": "4.2 IMPLICIT MANIPULATIVE EVALUATION"}, {"figure_path": "2410.18072/figures/figures_22_0.png", "caption": "Figure 7: Rollout of Open-Ended Embodied Environment in Implicit Manipulative Evaluation.", "description": "The figure shows a sequence of images from a Minecraft simulation illustrating the rollout process of an embodied task in the Implicit Manipulative Evaluation.", "section": "4.2 IMPLICIT MANIPULATIVE EVALUATION"}, {"figure_path": "2410.18072/figures/figures_24_0.png", "caption": "Figure 8: Rollout of Autonomous Driving in Implicit Manipulative Evaluation.", "description": "The figure shows a sequence of frames from the autonomous driving simulation, illustrating the model's predictions and the corresponding actions taken by the agent.", "section": "4.2 Implicit Manipulative Evaluation"}, {"figure_path": "2410.18072/figures/figures_26_0.png", "caption": "Figure 9: Rollout of Robot Manipulation in Implicit Manipulative Evaluation.", "description": "The figure shows a sequence of images illustrating the execution of a robot manipulation task in a simulated environment, guided by textual instructions.", "section": "F Implicit Manipulative Evaluation-RM"}]