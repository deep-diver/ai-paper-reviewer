[{"figure_path": "2410.18072/tables/table_3_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "Table 1 compares existing Predictive Model benchmarks across several criteria, including input/output modality, model type, evaluation stage, and interaction type with the environment.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_8_0.html", "caption": "Table 3: The overall performance comparison between Human Preference Evaluator and GPT-40. HPE indicates Human Preference Evaluator. HPE@Lavie means that HPE is trained on videos except those generated by Lavie. The validation is conducted on videos generated by Laive under zero-shot setting.", "description": "The table compares the overall performance of the Human Preference Evaluator and GPT-40 across three embodied scenarios, showing the evaluator's superior performance in aligning with human preferences.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.18072/tables/table_17_0.html", "caption": "Table 4: Analysis of HF-Embodied Dataset. Samples scored higher than 3 in AD and RM are considered positive.", "description": "Table 4 presents the analysis of the HF-Embodied Dataset, showing the number of instructions, videos, dimensions, actions, positive samples (scores >3), and negative samples for three embodied scenarios: Open-Ended Embodied Environment, Autonomous Driving, and Robot Manipulation.", "section": "4.1 HF-EMBODIED DATASET"}, {"figure_path": "2410.18072/tables/table_17_1.html", "caption": "Table 5: Training Frames of Generation Models.", "description": "This table shows the number of frames used for training short and long videos for each of the eight video generation models.", "section": "B Detaild Implementation of Explicit Perceptual Evaluation"}, {"figure_path": "2410.18072/tables/table_18_0.html", "caption": "Table 3: The overall performance comparison between Human Preference Evaluator and GPT-40. HPE indicates Human Preference Evaluator. HPE@Lavie means that HPE is trained on videos except those generated by Lavie. The validation is conducted on videos generated by Laive under zero-shot setting.", "description": "The table compares the overall performance of a Human Preference Evaluator and GPT-40 across various metrics and scenarios for evaluating video generation models.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.18072/tables/table_19_0.html", "caption": "Table 7: Evaluation results in OE. The abbreviations are listed in Tab. 2.", "description": "The table presents the evaluation results of seven video generation models across seven dimensions in the Open-Ended Embodied Environment scenario.", "section": "C Detailed Result of Explicit Perceptual Evaluation"}, {"figure_path": "2410.18072/tables/table_20_0.html", "caption": "Table 8: Evaluation results in AD. The abbreviations are listed in Tab. 2.", "description": "The table presents a comparison of eight video generation models' performance across six evaluation dimensions in an autonomous driving scenario.", "section": "4.1 EXPLICIT PERCEPTUAL EVALUATION"}, {"figure_path": "2410.18072/tables/table_20_1.html", "caption": "Table 2: Hierarchical Evaluation Dimension. The dimensions are categorized into three main aspects: Visual Quality for evaluating the overall quality, Condition Consistency for evaluating the alignment to the input instruction, and Embodiment for evaluating embodied related factors like physical rules.", "description": "The table presents a hierarchical breakdown of evaluation dimensions for three embodied scenarios (Open-Ended Embodied Environment, Autonomous Driving, and Robot Manipulation), categorized into visual quality, condition consistency, and embodiment.", "section": "4.1 EXPLICIT PERCEPTUAL EVALUATION"}, {"figure_path": "2410.18072/tables/table_21_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares various existing predictive model benchmarks across several key features, including input and output modalities, interaction types, evaluation strategies, and the stage of predictive model capability.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_22_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares existing predictive model benchmarks across various dimensions, including input/output modalities, methods, evaluation strategies, and interaction types.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_24_0.html", "caption": "Table 12: Detail Result of Autonomous Driving in Implicit Manipulative Evaluation.", "description": "The table presents the evaluation results of three video generation models across eight metrics in the Autonomous Driving task within the Implicit Manipulative Evaluation.", "section": "5. EXPERIMENTS"}, {"figure_path": "2410.18072/tables/table_25_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares existing predictive model benchmarks across various aspects such as input/output modalities, evaluation strategies, and interaction types.", "section": "1 INTRODUCTION"}]