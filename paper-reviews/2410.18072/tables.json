[{"figure_path": "2410.18072/tables/table_3_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "Table 1 compares existing predictive model benchmarks based on input/output modalities, methods, stages, interactive environments, and evaluation strategies.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_8_0.html", "caption": "Table 3: The overall performance comparison between Human Preference Evaluator and GPT-40. HPE indicates Human Preference Evaluator. HPE@Lavie means that HPE is trained on videos except those generated by Lavie. The validation is conducted on videos generated by Laive under zero-shot setting.", "description": "The table compares the overall performance of the Human Preference Evaluator and GPT-40 across three embodied scenarios (Open-Ended Embodied Environment, Autonomous Driving, and Robot Manipulation) using different evaluation metrics.", "section": "5 EXPERIMENTS"}, {"figure_path": "2410.18072/tables/table_17_0.html", "caption": "Table 4: Analysis of HF-Embodied Dataset. Samples scored higher than 3 in AD and RM are considered positive.", "description": "Table 4 presents the analysis of the HF-Embodied Dataset, showing the number of instructions, videos, dimensions, actions, positive samples, and negative samples for each of the three embodied scenarios.", "section": "4.1 HF-EMBODIED DATASET"}, {"figure_path": "2410.18072/tables/table_17_1.html", "caption": "Table 5: Training Frames of Generation Models.", "description": "The table presents the number of training frames used for short and long videos across eight different video generation models.", "section": "B Detaild Implementation of Explicit Perceptual Evaluation"}, {"figure_path": "2410.18072/tables/table_18_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares various existing predictive model benchmarks across different dimensions, including input/output modalities, methods, evaluation strategies, and interaction types.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_19_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares existing predictive model benchmarks based on input modality, output modality, method, stage, interactive environment, and evaluation strategy.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_20_0.html", "caption": "Table 8: Evaluation results in AD. The abbreviations are listed in Tab. 2.", "description": "The table presents a comparison of the performance of several video generation models across various evaluation dimensions (Aesthetics, Instruction Alignment, Perspectivity, Trajectory, Key Element, Safety) in the context of Autonomous Driving.", "section": "4.1 EXPLICIT PERCEPTUAL EVALUATION"}, {"figure_path": "2410.18072/tables/table_20_1.html", "caption": "Table 2: Hierarchical Evaluation Dimension. The dimensions are categorized into three main aspects: Visual Quality for evaluating the overall quality, Condition Consistency for evaluating the alignment to the input instruction, and Embodiment for evaluating embodied related factors like physical rules.", "description": "This table categorizes the evaluation dimensions for three embodied scenarios (Open-Ended Embodied Environment, Autonomous Driving, and Robot Manipulation) into three aspects: Visual Quality, Condition Consistency, and Embodiment, each with specific sub-dimensions.", "section": "4.1 EXPLICIT PERCEPTUAL EVALUATION"}, {"figure_path": "2410.18072/tables/table_22_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "This table compares various existing predictive model benchmarks, highlighting their input/output modalities, methodologies, and interaction levels with the environment.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18072/tables/table_24_0.html", "caption": "Table 12: Detail Result of Autonomous Driving in Implicit Manipulative Evaluation.", "description": "This table presents the evaluation results of three video generation models across eight metrics in the Autonomous Driving scenario of the Implicit Manipulative Evaluation.", "section": "5.3 Design Features and Discussions"}, {"figure_path": "2410.18072/tables/table_25_0.html", "caption": "Table 1: Comparisons between existing Predictive Model benchmarks. Interactive Environment refers to the interaction with the simulation environment during the prediction phase. Task-Level Interaction denotes that each task interacts once, whereas Action-Level Interaction represents the frequency of interactions that occur through the generation of actions for control purposes.", "description": "Table 1 compares existing predictive model benchmarks across various criteria, including input/output modalities, model type, interaction type, and evaluation strategy.", "section": "1 INTRODUCTION"}]