{"references": [{"fullname_first_author": "Ren\u00e9 Ranftl", "paper_title": "Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer", "publication_date": "2020-00-00", "reason": "This paper is foundational to DepthLab's approach, introducing the use of diffusion models for depth estimation which DepthLab extends upon."}, {"fullname_first_author": "Bingxin Ke", "paper_title": "Repurposing diffusion-based image generators for monocular depth estimation", "publication_date": "2024-00-00", "reason": "DepthLab's architecture directly builds upon Marigold's dual-branch diffusion framework, adapting it for depth inpainting."}, {"fullname_first_author": "Johannes L. Sch\u00f6nberger", "paper_title": "Structure-from-motion revisited", "publication_date": "2016-00-00", "reason": "This paper's method is used in DepthLab for refining point clouds from DUST3R improving the quality of 3D reconstruction."}, {"fullname_first_author": "Angela Dai", "paper_title": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "publication_date": "2017-00-00", "reason": "The ScanNet dataset is one of the primary datasets used for training DepthLab, providing a rich source of realistic indoor depth data."}, {"fullname_first_author": "Yohann Cabon", "paper_title": "Dust3R: Geometric 3d vision made easy", "publication_date": "2024-00-00", "reason": "DepthLab leverages DUST3R for sparse-view reconstruction, using DepthLab to enhance the accuracy of DUST3R's depth maps"}]}