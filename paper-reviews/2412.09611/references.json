{"references": [{"fullname_first_author": "Patrick Esser", "paper_title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "publication_date": "2024-01-01", "reason": "This paper introduces the core architecture of Flux, a flow-based transformer model that is the foundation for the FluxSpace editing approach."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable Diffusion Models with Transformers", "publication_date": "2023-01-01", "reason": "This paper details the MM-DiT architecture which integrates text and image features, providing a framework for editing mechanisms in FluxSpace by enabling interaction between image and text representations."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-01-01", "reason": "This work is crucial as it introduces Latent Diffusion Models, offering a widely-used and effective framework that is used by some of the compared editing algorithms."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a model that learns visual concepts from natural language supervision, and it is the core of the conditioning mechanism used in FluxSpace for guidance and alignment with prompt semantics."}, {"fullname_first_author": "Manuel Brack", "paper_title": "LEDITS++: Limitless Image Editing using Text-to-Image Models", "publication_date": "2024-01-01", "reason": "This paper introduces a state-of-the-art semantic image editing method based on text-to-image diffusion models that is directly compared to FluxSpace in terms of qualitative and quantitative results."}]}