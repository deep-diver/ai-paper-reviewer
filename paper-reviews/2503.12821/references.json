{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper is crucial as it introduces LLaVA, which is used as the baseline model in the paper, and its visual instruction tuning methodology is directly relevant to the current work."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-01-01", "reason": "This is relevant because the current study focuses on instruction tuning of vision language models, and this is another one of the main relevant papers."}, {"fullname_first_author": "Shilong Liu", "paper_title": "Grounding dino: Marrying dino with grounded pre-training for open-set object detection", "publication_date": "2023-01-01", "reason": "Grounding DINO is utilized within their methodology in the current paper for identifying visual objects, making it a core component of their approach."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP is used as one of the vision encoders, so this CLIP pre-training method is highly relevant."}, {"fullname_first_author": "Gemini Team", "paper_title": "Gemini: a family of highly capable multimodal models", "publication_date": "2023-01-01", "reason": "Gemini is a powerful business model that has attracted significant attention and is very relevant to the Large Vision-Language Model. "}]}