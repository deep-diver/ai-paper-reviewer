[{"figure_path": "https://arxiv.org/html/2412.05983/x1.png", "caption": "Figure 1: Performance comparison of different models on multi-modal reasoning (MathViata, MathVerse) and visual structural extraction (ChartQA-SE, Table-SE) tasks.", "description": "Figure 1 presents a performance comparison of various multi-modal models across several tasks categorized into two groups: multi-modal reasoning and visual structural extraction.  For multi-modal reasoning, the models are evaluated on MathVista and MathVerse datasets, which test the ability of models to reason using both visual and textual information.  The visual structural extraction tasks evaluate the models' performance on ChartQA-SE and Table-SE datasets, focusing on their ability to extract structured information from charts and tables, respectively.  The figure visually compares the performance scores achieved by different models across these four tasks, providing insights into the strengths and weaknesses of each model in handling different types of multi-modal data.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x2.png", "caption": "Figure 2: Overview of our Chimera framework. Chimera uses Generalist-Specialist Collaboration Masking to facilitate the alignment with expert models. During inference, the Router R\ud835\udc45Ritalic_R decides expert invocations based on the visual input, resulting in a versatile model that excels across multiple specialized domains and tasks.", "description": "The figure illustrates the architecture of the Chimera framework, a multi-modal pipeline designed to enhance the performance of large multi-modal models (LMMs) on domain-specific tasks.  It shows how Chimera integrates domain-specific expert models with a generalist LMM. The framework uses a Generalist-Specialist Collaboration Masking (GSCM) mechanism to align features between the generalist and expert models, ensuring effective integration. During inference, a router module dynamically selects the appropriate expert model based on the input's visual content, enabling the model to handle various specialized domains (e.g., charts, tables, math) effectively.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.05983/x3.png", "caption": "Figure 3: Pre-training tasks of expert models considered by Chimera.", "description": "This figure provides a detailed breakdown of the pre-training tasks used for the expert models integrated into the Chimera framework.  It visually represents the different types of tasks (categorized as either low-level or high-level) along with examples of each.  Low-level tasks focus on precise extraction of specific visual content, such as converting tables to LaTeX or charts to markdown. High-level tasks involve a deeper understanding of the image, including tasks like chart-type and title prediction, or mathematical captioning using contrastive learning.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.05983/x4.png", "caption": "Table 7: Comparison of performance on Table-SE across different methods: TEDS, TEDS (structure only), and Edit Distance.", "description": "This table presents a comparison of the performance of different methods on the Table-SE (Table Structural Extraction) task.  Three metrics are used for comparison: TEDS (Tree-Edit Distance-based Similarity), TEDS (structure only), and Edit Distance.  The TEDS metric measures the similarity between two tree structures, representing the table structures generated by each model and the ground truth. The \"TEDS (structure only)\" metric focuses solely on the structural aspects of the tables, ignoring the content.  The Edit Distance metric provides a simpler comparison of the textual representation of tables.  By comparing these metrics across different methods, the table provides a detailed evaluation of the models' ability to accurately extract and reconstruct the structure and content of tables.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x5.png", "caption": "Table 8: Comparison of performance metrics across different methods on Doc-SE. Metrics include Edit Distance (lower is better), Precision, BLEU, and METEOR (higher is better).", "description": "Table 8 presents a comparative analysis of various models' performance on the document structure extraction (Doc-SE) task.  The metrics used for comparison include Edit Distance (lower scores indicate better performance), Precision, BLEU, and METEOR (higher scores are better).  Results are shown for both English and Chinese languages.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x6.png", "caption": "Figure 4: Comparison of Edit Distance \u2193\u2193\\downarrow\u2193 across different document categories on Document Structural Extraction (Doc-SE) task.", "description": "Figure 4 presents a comparison of the Edit Distance metric across various document categories within the Document Structural Extraction (Doc-SE) task. Lower Edit Distance indicates better performance. The figure visualizes how well the model performs on different document types, allowing for an assessment of its generalization capabilities and potential biases toward specific document structures.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x7.png", "caption": "Figure 5: Showcase of Table-SE task.", "description": "This figure showcases examples of the Table-SE task, which involves extracting tabular data from images and converting them into LaTeX format.  The figure displays several visual tables alongside their corresponding LaTeX code representations, demonstrating the model's ability to accurately transform visual tabular data into structured code.", "section": "6. Details of Table-SE and Doc-SE"}, {"figure_path": "https://arxiv.org/html/2412.05983/x8.png", "caption": "Figure 6: Showcase of Table-SE task.", "description": "This figure showcases examples of the Table-SE (Table Structural Extraction) task.  It presents several visual tables alongside their corresponding LaTeX code, demonstrating the model's ability to accurately extract and format table content from diverse table layouts.", "section": "6. Details of Table-SE and Doc-SE"}, {"figure_path": "https://arxiv.org/html/2412.05983/x9.png", "caption": "Figure 7: Output of Chimera-Reasoner-8B on Table Structural Extraction task.", "description": "This figure showcases the output of the Chimera-Reasoner-8B model when performing table structural extraction.  It demonstrates the model's ability to accurately extract and format tabular data from a visual table, converting it into LaTeX code. The visual table shown contains financial data, likely from a balance sheet, showing various financial metrics and amounts for different years.", "section": "9.1. Table Format Transformation"}, {"figure_path": "https://arxiv.org/html/2412.05983/x10.png", "caption": "Figure 8: Output of Chimera-Reasoner-8B on Table Structural Extraction task.", "description": "This figure showcases the results of Chimera-Reasoner-8B, a large multi-modal model, performing a table structural extraction task.  The image shows a complex table, likely containing numerical and textual data. The output displays the model's ability to accurately extract the structural information from the table and represent it in LaTeX format, a markup language commonly used for typesetting mathematical and scientific documents.  The comparison visually demonstrates the model's capability to understand the table's organization and convert it into a structured, machine-readable format.", "section": "9. Visualization of Chimera on Visual Content Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x11.png", "caption": "Figure 9: Output of Chimera-Reasoner-8B on Table Structural Extraction task.", "description": "This figure showcases the results of the Chimera-Reasoner-8B model on a table structural extraction task.  It displays the input visual table and the corresponding LaTeX code generated by the model. This example demonstrates the model's ability to accurately extract and format information from complex tables, converting visual data into a structured, machine-readable format.  The high level of detail presented allows assessment of the accuracy of the conversion. The model's success on this task highlights its capability for multi-modal reasoning and data extraction.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x12.png", "caption": "Figure 10: Output of Chimera-Reasoner-8B on Chart Structural Extraction task.", "description": "This figure showcases the results of the Chimera-Reasoner-8B model performing chart structural extraction.  It visually demonstrates the model's ability to accurately identify and extract information from various chart types (pie chart, line graph, bar chart) and output this information in a structured format (markdown).  This highlights Chimera's capability for visual content extraction, a domain where generalist models often struggle.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.05983/x13.png", "caption": "Figure 11: Output of Chimera-Reasoner-8B on Chart Structural Extraction task.", "description": "This figure showcases the results of the Chimera-Reasoner-8B model on a chart structural extraction task.  It visually demonstrates the model's ability to accurately extract and interpret data from various chart types, including bar charts and line charts, converting the visual information into a structured, machine-readable format. The displayed results highlight the model's performance on multi-modal reasoning and visual content extraction.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x14.png", "caption": "Figure 12: Output of Chimera-Reasoner-8B on Chart Structural Extraction task.", "description": "This figure showcases the effectiveness of the Chimera-Reasoner-8B model in extracting structured information from various chart types.  The input shows several charts, including line charts, bar charts, and pie charts, each containing different types of visual data and labels. The model's output is a markdown representation that accurately captures the key information present in each chart, including labels, data points, and chart titles. This demonstrates the model's ability to process and understand complex visual layouts and extract structured information effectively.", "section": "4.3. Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x15.png", "caption": "Figure 13: Output of Chimera-Extractor-1B on Document Structural Extraction task.", "description": "This figure showcases the capabilities of the Chimera-Extractor-1B model in extracting structural information from a document page.  It visually demonstrates the model's ability to identify and separate key components of the document, such as text blocks, tables, and other elements, and to represent this structure in a machine-readable format (Markdown). This highlights the model's ability to perform document understanding tasks beyond simple text extraction.", "section": "4.3 Comparison on Visual Structural Extraction"}, {"figure_path": "https://arxiv.org/html/2412.05983/x16.png", "caption": "Figure 14: Output of Chimera-Extractor-1B on Document Structural Extraction task.", "description": "This figure showcases the performance of the Chimera-Extractor-1B model on a document structural extraction task.  The input is a sample document page, and the output shows the structured markdown version extracted by the model.  This demonstrates the model's ability to accurately identify and extract key elements from a document page, separating content into logical units like headings, paragraphs, and references.", "section": "4.3 Comparison on Visual Structural Extraction"}]