[{"heading_title": "Refer Any Person", "details": {"summary": "**Referring to Any Person** is a pivotal task in computer vision, demanding the ability to identify and detect individuals based on natural language descriptions. This capability holds substantial practical value across diverse applications, including human-robot interaction and healthcare. This area of research aims to overcome the limitations of existing models that often struggle with real-world usability due to unclear task definitions and a lack of high-quality data. The task involves capturing a number of aspects in which humans can be referred to. This includes attributes, position, interaction, reasoning, and celebrity recognition. Developing robust models for referring to any person requires addressing challenges such as multi-instance referring, multi-instance discrimination, and rejection of non-existence. The focus on real-world scenarios necessitates models that can accurately identify multiple individuals and avoid hallucinating results when the referred person is not present in the image. "}}, {"heading_title": "HumanRef Dataset", "details": {"summary": "The HumanRef dataset is introduced to address the limitations of existing datasets in real-world human referring scenarios, particularly the **multi-instance referring** where a single expression relates to multiple individuals. A key design choice is including diverse human contexts such as natural settings, industrial scenes, healthcare, and sports. **Five key aspects** define how humans are referred: attributes, position, interaction, reasoning, and celebrity recognition. Data acquisition involves filtering high-resolution images with at least four individuals to ensure **multi-instance discrimination**. The dataset's annotation process includes manual labeling for attributes, position, interaction, and reasoning with automated pipelines for celebrity recognition and rejection. **HumanRef aims to better reflect complex, real-world interactions** and requires models to possess both robust perception and strong language comprehension."}}, {"heading_title": "RexSeek Design", "details": {"summary": "The RexSeek design emphasizes a **robust perception ability** and **strong language comprehension**. It integrates a person detector (DINO-X) for reliable individual detection and a multimodal LLM (Qwen2.5) for accurate interpretation of complex language. RexSeek formulates referring as a retrieval-based process, using vision encoders (CLIP, ConvNext) to extract image features. Rol features and positional embeddings capture object context, combined with text tokens, and fed into the LLM to identify the corresponding bounding box indices. This design enables RexSeek to excel at both human and general object referring, overcoming limitations of existing models."}}, {"heading_title": "Multi-Instance", "details": {"summary": "The concept of **multi-instance** is crucial for advancing computer vision, especially in tasks like referring expression comprehension. Existing datasets often assume a **one-to-one correspondence**, limiting their applicability in real-world scenarios where expressions can refer to **multiple objects or people**. Addressing this requires models to accurately identify and locate all relevant instances, not just a single one. This necessitates a shift in training data and evaluation metrics to accommodate multi-instance scenarios, pushing for more robust and practical vision systems. Failure to account for multi-instance referring leads to models with low recall and limited usability in complex, real-world environments."}}, {"heading_title": "Rejection Tests", "details": {"summary": "**Rejection tests are crucial for assessing a model's ability to abstain from making predictions when an object is absent.** A high-performing model should not hallucinate objects. **Current models struggle with this**, often predicting bounding boxes even when the referred object doesn't exist. Addressing hallucination necessitates careful dataset design and training strategies. **Incorporating negative examples** during training can significantly enhance rejection capabilities. Evaluation metrics must accurately quantify the model's performance in rejection scenarios. **In this context, the model must be able to identify if the person is not present and avoid hallucinating an output.**"}}]