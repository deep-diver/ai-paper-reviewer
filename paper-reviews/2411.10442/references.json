{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper is a technical report on GPT-4, a large language model that is frequently compared to and contrasted with the models in this paper."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-00-00", "reason": "This paper introduced the concept of few-shot learning in language models, a key technique that many of the models discussed in the paper leverage."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling Up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks", "publication_date": "2023-12-14", "reason": "This paper introduces InternVL, a multimodal model that is extensively used as a baseline and compared to the proposed model in the current paper."}, {"fullname_first_author": "Zhe Chen", "paper_title": "How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites", "publication_date": "2024-04-16", "reason": "This paper introduces InternVL2, a multimodal model that is used as a direct baseline for comparison in the paper, and its performance is compared to the proposed model."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training Language Models to Follow Instructions with Human Feedback", "publication_date": "2022-00-00", "reason": "This paper introduces RLHF, a training method that is used in several of the models discussed in the paper, and is relevant to the preference optimization methods used in this work."}]}