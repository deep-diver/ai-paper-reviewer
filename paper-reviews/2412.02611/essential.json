{"importance": "This paper is crucial for **multimodal LLM research** because it reveals significant limitations in current models' ability to understand audio-visual information.  It introduces a novel benchmark, **AV-Odyssey**, for more comprehensive evaluation and paves the way for future dataset creation and model development that better integrate audio-visual cues.  The **DeafTest**, used to evaluate basic listening abilities, also serves as a critical tool for highlighting fundamental limitations. This work addresses **a crucial gap in the field**, setting a new standard for evaluating multimodal models.", "summary": "AV-Odyssey Bench reveals that current multimodal LLMs struggle with basic audio-visual understanding, prompting the development of a comprehensive benchmark for more effective evaluation.", "takeaways": ["Multimodal LLMs often fail at simple audio-visual tasks humans find trivial.", "AV-Odyssey Bench provides a more thorough benchmark for evaluating multimodal LLMs' understanding of audio-visual information.", "DeafTest effectively highlights fundamental listening limitations in current LLMs."], "tldr": "Current multimodal large language models (MLLMs) show impressive performance in many areas but struggle with basic audio-visual understanding, as highlighted by a new test called DeafTest. This test revealed that even advanced MLLMs struggle with simple tasks such as identifying louder or higher-pitched sounds, revealing a critical gap in their audio processing capabilities.\nTo address this issue, the researchers introduced AV-Odyssey Bench, a comprehensive benchmark containing 4,555 carefully designed questions involving text, images, and audio. This benchmark challenges MLLMs to integrate information from all three modalities to accurately answer questions.  The results from AV-Odyssey show that even state-of-the-art models underperform significantly. This signifies a need for more advanced models and datasets focused on robust audio-visual integration.", "affiliation": "CUHK MMLab", "categories": {"main_category": "Multimodal Learning", "sub_category": "Multimodal Understanding"}, "podcast_path": "2412.02611/podcast.wav"}