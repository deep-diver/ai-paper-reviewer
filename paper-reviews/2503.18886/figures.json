[{"figure_path": "https://arxiv.org/html/2503.18886/x2.png", "caption": "Figure 1: Comparison for the prompt: \u201cA dense winter forest with snow-covered branches, the golden light of dawn filtering through the trees, and a lone fox leaving delicate paw prints in the fresh snow.\u201d Images generated using SD3.5\u00a0[5] with CFG and CFG-Zero\u22c6 (Ours).", "description": "Figure 1 shows a comparison of images generated from the text prompt: \"A dense winter forest with snow-covered branches, the golden light of dawn filtering through the trees, and a lone fox leaving delicate paw prints in the fresh snow.\"  The comparison highlights the difference in image quality and detail between using the standard Classifier-Free Guidance (CFG) method and the improved CFG-Zero* method proposed in the paper.  The images were generated using Stable Diffusion 3.5 (SD3.5).  The CFG-Zero* method demonstrates improved image fidelity and adherence to the prompt's description.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.18886/x5.png", "caption": "Figure 2: (Left) Conditional generation. (Right) CFG generation. (Prompt: \u201cA mysterious underwater city with bioluminescent corals and towering glass domes.\u201d)", "description": "This figure compares the results of image generation with and without classifier-free guidance (CFG).  The prompt used was: \u201cA mysterious underwater city with bioluminescent corals and towering glass domes.\u201d The image on the left shows a sample generated using standard conditional generation, lacking the detail and coherence found in the image on the right, which is generated using CFG. CFG helps align the generated image more closely with the user's specified prompt by guiding the sampling process towards a more appropriate output based on the user's condition. The difference showcases CFG's effectiveness in enhancing image quality and aligning generated images with given text prompts.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.18886/x6.png", "caption": "Figure 3: Results on mixture of Gaussians in \u211d2superscript\u211d2{\\mathbb{R}}^{2}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. Left: The Jensen\u2013Shannon divergence between the model\u2019s final flow sample distribution and the target distribution v.s. training epoch. Right: The velocity error norm \u2016\ud835\udc97~0\u03b8\u2212\ud835\udc97~0\u2217\u2016normsubscriptsuperscript~\ud835\udc97\ud835\udf030subscriptsuperscript~\ud835\udc97\u22170\\|\\tilde{{\\bm{v}}}^{\\theta}_{0}-\\tilde{{\\bm{v}}}^{\\ast}_{0}\\|\u2225 over~ start_ARG bold_italic_v end_ARG start_POSTSUPERSCRIPT italic_\u03b8 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - over~ start_ARG bold_italic_v end_ARG start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2225, with the ground truth norm shown in gray v.s. training epoch.", "description": "Figure 3 presents a comparative analysis of the performance of a flow matching model trained on a 2D Gaussian mixture.  The left panel displays the Jensen-Shannon (JS) divergence between the model's generated sample distribution and the true target distribution over training epochs. This metric quantifies the difference between the model's output and the desired outcome.  The right panel shows the Euclidean norm (magnitude) of the difference between the model's initial velocity estimate (v~0\u03b8) and the true optimal velocity (v~0\u2217) for each epoch. This error norm highlights how accurately the model predicts the optimal trajectory at the beginning of the sampling process. A gray line in the right panel represents the magnitude of the ground truth velocity, providing a visual reference for the scale of the error.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2503.18886/x7.png", "caption": "Figure 4: Qualitative comparisons between CFG and CFG-Zero\u22c6. Experiments are conducted using Lumina-Next, Stable Diffusion 3, and Stable Diffusion 3.5, with each model evaluated under its recommended optimal sampling steps and guidance scale settings. CFG results are shown in orange and\nOurs are highlighted in green boxes.", "description": "Figure 4 presents a qualitative comparison of image generation results using standard Classifier-Free Guidance (CFG) and the improved method CFG-Zero*.  Three different state-of-the-art models were used: Lumina-Next, Stable Diffusion 3, and Stable Diffusion 3.5.  Each model used its optimal settings for sampling steps and guidance scale. The images generated with CFG are shown in orange, while those generated with CFG-Zero* are highlighted in green boxes, allowing for a direct visual comparison of the quality and fidelity of the generated images.", "section": "5.1 Text-to-Image Generation"}, {"figure_path": "https://arxiv.org/html/2503.18886/x34.png", "caption": "Figure 5: User study on Lumina-Next, Stable Diffusion 3, Stable Diffusion 3.5, and Flux. The win rate of our method compared to CFG is presented.", "description": "This figure displays the results of a user study comparing the performance of CFG-Zero* against the standard CFG method across four different text-to-image models: Lumina-Next, Stable Diffusion 3, Stable Diffusion 3.5, and Flux.  For each model, the chart shows the percentage of times users preferred images generated by CFG-Zero* over those generated by CFG.  This provides a clear visual representation of CFG-Zero*'s relative effectiveness in generating higher-quality images compared to CFG across multiple leading models.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18886/x35.png", "caption": "Figure 6: Qualitative comparisons between CFG-Zero\u22c6 and CFG. Experiments are conducted using Wan-2.1 [1B]\u00a0[39], under its recommended optimal sampling steps and guidance scale settings.", "description": "Figure 6 showcases a qualitative comparison of video generation results using the Wan-2.1 [1B] model, with and without the CFG-Zero* method.  The experiments were conducted using the model's recommended parameters for optimal sampling steps and guidance scale. The figure directly compares the visual quality of videos generated by CFG-Zero* and standard CFG, allowing for a visual assessment of the improvements achieved by CFG-Zero* in terms of detail, color, and overall smoothness of the generated videos. Two example video prompts are shown: \"A bicycle gliding through a snowy field\" and \"An astronaut flying in space.\"", "section": "5.2 Text-to-Video Generation"}, {"figure_path": "https://arxiv.org/html/2503.18886/x36.png", "caption": "Figure 7: Abalation study on different sampling steps. Comparison of CLIP Score and Aesthetic Score between our method and CFG across different sampling steps.", "description": "This ablation study investigates the effect of varying the number of sampling steps on the performance of CFG-Zero* and standard CFG.  Two key metrics are compared across different step counts: CLIP Score (measuring image-text alignment) and Aesthetic Score (measuring visual appeal). The graphs visualize how these scores change for both methods as the number of sampling steps increases, allowing for a direct comparison of the impact of the proposed CFG-Zero* improvements on image quality and alignment with text prompts, across various sampling steps.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18886/x37.png", "caption": "Figure 8: Abalation study on different guidance scale. Comparison of CLIP Score and Aesthetic Score between our method and CFG across different guidance scale.", "description": "This ablation study investigates the effect of varying the guidance scale on the performance of both the standard CFG method and the proposed CFG-Zero* method.  Two metrics are used to evaluate performance: the CLIP Score, which measures the alignment between generated images and text prompts, and the Aesthetic Score, which assesses the visual quality of the generated images. The figure shows how these two scores change for CFG and CFG-Zero* as the guidance scale is varied.  This allows for an analysis of which method is more robust and performs better across a range of guidance scales, demonstrating the effectiveness of CFG-Zero* in improving both image-text alignment and visual quality compared to the baseline CFG.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18886/x38.png", "caption": "Figure A1: Flow sampling trajectory. Each panel shows the sample trajectories at a different time step.", "description": "Figure A1 visualizes the sampling trajectories of a flow matching model for different time steps (t=0, 0.2, 0.4, 0.6, 0.8, 1.0).  Each panel displays the sample trajectories generated using three different guidance methods: CFG (Classifier-Free Guidance), 'Cond' (conditional generation without guidance), and the proposed CFG-Zero*. The figure demonstrates how CFG-Zero* effectively guides the samples toward the target distribution, unlike CFG which causes the samples to deviate significantly, and Cond which results in high variance.", "section": "A1. Experiments on Mixed Gaussian"}, {"figure_path": "https://arxiv.org/html/2503.18886/x39.png", "caption": "Figure A2: Ablation study of zero-init steps.", "description": "This ablation study investigates the impact of the 'zero-init' technique on model performance.  The technique involves setting the initial velocity to zero for a specified number of steps in the ordinary differential equation (ODE) solver used during sample generation.  The figure likely shows how different numbers of zero-initialized steps affect key performance metrics, possibly including image quality scores and the alignment between generated images and text prompts (measured by metrics like FID or CLIP score).  The results would demonstrate whether zeroing out early ODE steps leads to improved or worse outcomes.", "section": "A1. Additional Experiments"}]