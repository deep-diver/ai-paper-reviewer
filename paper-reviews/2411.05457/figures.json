[{"figure_path": "https://arxiv.org/html/2411.05457/x1.png", "caption": "Figure 1: An Overview of the Tesoro Creation Pipeline.", "description": "The Tesoro dataset creation pipeline consists of four main stages: 1. Code parsing: Java files from the Stack corpus are parsed to extract functions and associated comments. 2. SATD detection: A pre-trained classifier identifies comments potentially containing self-admitted technical debt (SATD). 3. Sampling: An algorithm selects high-quality samples for annotation, balancing informative examples and instances with high uncertainty scores. 4. Annotation: Human annotators classify selected comments and their corresponding source code snippets into specific technical debt categories (design, defect, documentation, requirement/implementation, testing). The output of the pipeline is the Tesoro dataset, containing labeled SATD comments and their associated source code, which can be used to train and evaluate models for detecting technical debt in Java source code.", "section": "3 Proposed Methodology"}, {"figure_path": "https://arxiv.org/html/2411.05457/x2.png", "caption": "Figure 2: Extraction of comments and functions.", "description": "The figure illustrates how comments and functions are extracted from Java source code.  It shows a Java code snippet with several comments, some single-line and some multi-line.  The process involves parsing the code to identify function blocks and associating any comments located within or immediately preceding those blocks with the corresponding function.  This is crucial for associating technical debt, which might be indicated in comments, with the relevant parts of the code.", "section": "Proposed Methodology"}, {"figure_path": "https://arxiv.org/html/2411.05457/x3.png", "caption": "Figure 3: Overlap categories ratio from multiple binary classifiers prediction on a comment.", "description": "This figure shows the overlap ratios between categories predicted by multiple binary classifiers for a single comment. Each classifier is trained to identify a specific type of technical debt (TD). The figure helps visualize which TD types tend to be confused or predicted together by the models, providing insights into the complexities and ambiguities in classifying comments into various TD categories.", "section": "3.4 Sampling Strategy"}, {"figure_path": "https://arxiv.org/html/2411.05457/x4.png", "caption": "Figure 4: Category distribution in Tesorocomment. Left: distribution of TD categories within comments containing SATD. Right: percentage of comments that contain versus those that do not contain SATD.", "description": "This figure displays the distribution of technical debt (TD) categories in the TESOROcomment dataset.  The left panel shows the proportion of each TD type (Design, Implementation, Defect, Test, Documentation) within comments that have been identified as containing self-admitted technical debt (SATD). The right panel presents the overall distribution of comments in the dataset, highlighting the percentage of comments containing SATD versus those without SATD.  This provides a comprehensive overview of the dataset's composition and the prevalence of SATD.", "section": "4 Data Characteristics"}, {"figure_path": "https://arxiv.org/html/2411.05457/x5.png", "caption": "Figure 5: Statistics of Tesorocode. Left: Distribution of the number of comments per function. Right: Distribution of the number of TD types within a function.", "description": "This figure presents a statistical overview of the TESOROcode dataset, focusing on the distribution of comments and technical debt (TD) types within the functions. The left panel displays the distribution of the number of comments per function, showing the frequency of functions containing different numbers of comments. The right panel illustrates the distribution of the number of TD types per function, revealing the frequency of functions containing various combinations of TD types. Together, these visualizations provide insights into the dataset's characteristics, such as the average number of comments per function and the complexity of TD instances within each function.", "section": "4 Data Characteristics"}, {"figure_path": "https://arxiv.org/html/2411.05457/x6.png", "caption": "Figure 6: An in-depth analysis of CodeBERT and RoBERTa performance across three scenarios for 10 projects.", "description": "This figure presents a detailed comparison of CodeBERT and RoBERTa model performance across three different tasks (SATD identification, classification, and detection) when evaluated on ten distinct open-source projects.  Each project serves as a separate test set, and the models are trained on the remaining nine.  The graph visually represents the F1-score achieved by each model on each task for each project, allowing for a direct comparison of their performance under various conditions and highlighting relative strengths and weaknesses.", "section": "5 Experimental Results"}, {"figure_path": "https://arxiv.org/html/2411.05457/x7.png", "caption": "Figure 7: F1-score of various PLMs on Tesorocode across different model sizes, types, and pretraining datasets. \u25c6\u25c6\\blacklozenge\u25c6 denotes NL-based PLMs; \\filledstar\\filledstar\\filledstar represents code-based PLMs.", "description": "Figure 7 illustrates the F1-scores achieved by various pretrained language models (PLMs) when tasked with identifying technical debt solely from Java source code.  The models are categorized into three groups based on their architecture: encoder-based, encoder-decoder-based, and decoder-based.  The x-axis represents the model size (in billions of parameters), and the y-axis shows the F1-score, a measure of the model's performance.  Different symbols distinguish between natural language (NL)-based PLMs and code-based PLMs. This visualization allows for comparison of model performance across varying architectures and scales, providing insights into the effectiveness of different approaches for detecting technical debt directly from code.", "section": "Experimental Results"}]