{"references": [{" publication_date": "2017", "fullname_first_author": "Qianru Sun", "paper_title": "A domain based approach to social relation recognition", "reason": "This paper is foundational to the field, introducing the PIPA dataset and establishing a baseline for social relation recognition methods.  Its focus on domain-specific approaches is relevant to the modular design of SocialGPT, which tackles challenges of generalizability and interpretability that Sun et al. highlighted.", "section_number": 1}, {" publication_date": "2017", "fullname_first_author": "Junnan Li", "paper_title": "Dual-glance model for deciphering social relationships", "reason": "This work introduced the PISC dataset and the dual-glance model, a significant contribution to social relationship recognition.  The dual-glance method's integration of multiple contextual regions is conceptually relevant to SocialGPT's use of VFMs and the incorporation of visual details from the scene.", "section_number": 1}, {" publication_date": "2018", "fullname_first_author": "Zhouxia Wang", "paper_title": "Deep reasoning with knowledge graph for social relationship understanding", "reason": "This work's approach of integrating prior knowledge about social relationships through a knowledge graph into the model addresses the issue of generalizability in SocialGPT's introduction, making it a key related work. The results achieved are also a benchmark against SocialGPT's zero-shot performance.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Wanhua Li", "paper_title": "Graph-based social relation reasoning", "reason": "Li et al.'s work, focusing on graph-based reasoning to tackle multiple social relationships in a scene, is highly relevant to SocialGPT's approach.  The method's use of logical constraints among multiple relationships offers a comparative perspective on addressing the complexity of social scenes.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Haorui Wang", "paper_title": "Shifted gen-gat and cumulative-transformer based social relation recognition for long videos", "reason": "This paper explores social relation recognition in the context of long videos, extending the scope beyond static images.  This is relevant to SocialGPT's adaptability to various input modalities and its potential for generalization to temporal data.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Meng Zhang", "paper_title": "Multi-granularity reasoning for social relation recognition from images", "reason": "Zhang et al.'s multi-granularity approach mirrors SocialGPT's multi-level feature extraction, providing a parallel framework that tackles the complexity of social scene understanding.  The methods are related by focusing on a holistic understanding of visual context.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Yunfei Guo", "paper_title": "Social relation reasoning based on triangular constraints", "reason": "This work's use of triangular constraints among relationships offers a comparison point to SocialGPT's methodology.  It suggests an alternative approach to modeling dependencies between social relations within a scene.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Rishi Bommasani", "paper_title": "On the opportunities and risks of foundation models", "reason": "This paper provides a comprehensive overview of foundation models, including LLMs and VFMs, which are the core components of SocialGPT. Its discussion of risks associated with foundation models informs the ethical considerations of SocialGPT.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP is a crucial VFM used in SocialGPT. This paper's introduction of CLIP is fundamental to the perception phase of SocialGPT, enabling zero-shot image-text understanding which forms the base of the social story generation.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Robin Strudel", "paper_title": "Segmenter: Transformer for semantic segmentation", "reason": "Segmenter is a foundational model used for image segmentation in SocialGPT. The paper's introduction of Segmenter is fundamental to the perception phase of SocialGPT.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "SAM is a key VFM used for image segmentation in SocialGPT.  This paper's introduction of SAM is crucial for SocialGPT's perception phase, where it extracts visual information into a textual format.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Junnan Li", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "reason": "BLIP-2 is the VLM used in SocialGPT for image captioning and detailed information extraction. This paper introduces the core of the perception module in SocialGPT.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "reason": "This paper's exploration of chain-of-thought prompting is directly relevant to SocialGPT's approach of guiding LLMs to provide detailed reasoning.  The method enhances interpretability and helps bridge the gap between visual perception and textual reasoning.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Emergent abilities of large language models", "reason": "This paper explores the capabilities of LLMs, which forms the basis for the reasoning phase of SocialGPT. Understanding the emergent abilities of LLMs is crucial for designing effective prompting strategies within the SocialGPT framework.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Shunyu Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "reason": "This paper introduces the \"Tree of Thoughts\" prompting method, offering an alternative approach to chain-of-thought prompting explored in SocialGPT.  Understanding various prompting techniques helps optimize the reasoning phase and improves performance.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Taylor Shin", "paper_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts", "reason": "This paper on automatic prompt generation is highly relevant to GSPO in SocialGPT. AutoPrompt's approach of generating prompts automatically offers a comparative technique to GSPO's greedy search optimization method, enhancing LLM performance.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "reason": "Zhou et al.'s work on learning to prompt for vision-language models offers a different approach to prompt optimization compared to GSPO.  The paper serves as a baseline and provides a different perspective for efficient prompt engineering.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Junnan Li", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "reason": "BLIP-2 is a key VLM used in SocialGPT for image captioning and detailed information extraction. This paper's detailed description of BLIP-2's architecture and capabilities provide valuable insights for understanding the inner workings of SocialGPT's perception phase.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "reason": "LLaMA is one of the LLMs used in SocialGPT for reasoning. This paper's description of LLaMA's architecture, capabilities, and performance offers valuable insights for the reasoning phase of SocialGPT, highlighting its importance as a foundational model in the framework.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "LLaMA-2 is one of the LLMs used in SocialGPT for reasoning.  This paper's introduction of LLaMA-2, including its fine-tuned chat capabilities, is relevant to SocialGPT's reasoning phase, improving the quality of responses and making SocialGPT more adaptable to different LLM architectures.", "section_number": 5}]}