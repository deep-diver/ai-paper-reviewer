{"references": [{" publication_date": "2017", "fullname_first_author": "Qianru Sun", "paper_title": "A domain based approach to social relation recognition", "reason": "This paper is foundational for the field, introducing the PIPA dataset, a benchmark used throughout the paper and widely used in other social relationship recognition research. Its focus on a domain-based approach is relevant to the work done in SocialGPT, which seeks to improve the accuracy and generalizability of methods that have historically struggled.", "section_number": 1}, {" publication_date": "2019", "fullname_first_author": "Meng Zhang", "paper_title": "Multi-granularity reasoning for social relation recognition from images", "reason": "This paper explores multi-granularity reasoning, a concept relevant to SocialGPT's use of multiple sources of visual information. By exploring multiple levels of granularity, this paper is vital for understanding how to better extract information and contextual cues for relation prediction in SocialGPT.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Wanhua Li", "paper_title": "Graph-based social relation reasoning", "reason": "This work presents GR2N, a method that uses graph neural networks to leverage relationships between multiple social relations in the same image. This is directly relevant to SocialGPT, which may in future versions incorporate similar reasoning methods to enhance the understanding of complex visual scenes.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Haorui Wang", "paper_title": "Shifted gen-gat and cumulative-transformer based social relation recognition for long videos", "reason": "This work deals with temporal aspects of social relation recognition, which could be a future area of research for SocialGPT. By adapting the methods to temporal reasoning, improvements in accuracy and efficiency in video settings might be achieved.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Zhouxia Wang", "paper_title": "Deep reasoning with knowledge graph for social relationship understanding", "reason": "This paper integrates knowledge graphs into social relation reasoning, which can be a valuable addition to SocialGPT. By enriching the textual representation of images with knowledge graphs, the system can better understand and classify social relations.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Junnan Li", "paper_title": "Dual-glance model for deciphering social relationships", "reason": "This paper introduces the PISC dataset and the Dual-Glance model, which can be used as a comparison and reference point for SocialGPT. The model's architecture and its performance on the PISC dataset are highly relevant and useful for benchmarking SocialGPT's performance.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yunfei Guo", "paper_title": "Social relation reasoning based on triangular constraints", "reason": "This paper explores the use of triangular constraints to improve social relation reasoning. This concept is relevant to SocialGPT and could be integrated into the framework to improve the accuracy and reliability of the system.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Junnan Li", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "reason": "This paper is highly important because it introduces BLIP-2, a crucial vision-language foundation model used by SocialGPT for generating visual information. The use of BLIP-2 significantly impacts the quality and performance of SocialGPT.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This paper is highly important as it introduces the Segment Anything Model (SAM), a core component of SocialGPT used for precise image segmentation. The accuracy and efficiency of SAM directly impact the performance of SocialGPT.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "reason": "This paper introduces the concept of Chain-of-Thought prompting, a technique directly relevant to how SocialGPT utilizes LLMs for reasoning.  Understanding and utilizing this method is critical to SocialGPT's prompt engineering and accuracy.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Emergent abilities of large language models", "reason": "This paper explores the emergent abilities of large language models, providing valuable insights for better understanding and utilizing LLMs within SocialGPT. This is crucial for the design and implementation of the reasoning phase in SocialGPT.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "reason": "This work focuses on improving the reliability of LLM reasoning, a key aspect of SocialGPT's functionality. By incorporating self-consistency techniques, SocialGPT can increase the robustness of its LLM-based reasoning, making it less prone to errors.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Shunyu Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "reason": "This paper explores advanced prompting techniques for LLMs, offering valuable insights that can be used to improve SocialGPT's prompting strategies. By utilizing the \u2018Tree of Thoughts\u2019 approach, the system may be able to process complex problems more efficiently and accurately.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Pengfei Liu", "paper_title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing", "reason": "This survey paper provides a comprehensive overview of various prompting methods for LLMs, which can aid in improving the efficiency and effectiveness of SocialGPT's prompt design process. The knowledge gained from this survey will greatly benefit SocialGPT's prompt optimization.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Taylor Shin", "paper_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts", "reason": "This paper introduces Autoprompt, which automatically generates prompts for LLMs.  The concepts and techniques employed in Autoprompt are highly relevant to the design and implementation of GSPO, an important component of SocialGPT's prompt optimization strategy.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "reason": "This paper focuses on learning optimal prompts for vision-language models, which can be applied to improve SocialGPT's prompt design. Learning the best prompts can significantly improve SocialGPT\u2019s performance and efficiency.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Sachit Menon", "paper_title": "Visual classification via description from large language models", "reason": "This paper demonstrates the use of LLMs for visual classification, providing a theoretical foundation and valuable insights for SocialGPT\u2019s approach to converting visual tasks into generative tasks.  The concepts discussed here are crucial to the design and implementation of SocialGPT.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Junnan Li", "paper_title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "reason": "This paper introduces BLIP, a predecessor to BLIP-2, providing valuable context for understanding the development of the vision-language foundation models used in SocialGPT. The evolution of these models is highly relevant to the advancement of SocialGPT.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Yongchao Zhou", "paper_title": "Large language models are human-level prompt engineers", "reason": "This paper shows that LLMs can act as efficient prompt engineers and provides inspiration for developing automated techniques for tuning prompts. The principles and methods discussed in this work are closely related to those used in developing GSPO in SocialGPT.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Reid Pryzant", "paper_title": "Automatic prompt optimization with gradient descent and beam search", "reason": "This paper introduces an automatic prompt optimization technique using gradient descent and beam search, which is conceptually similar to the approach taken by GSPO in SocialGPT. Understanding this method enhances the comprehension of GSPO's effectiveness and efficiency.", "section_number": 5}]}