{"references": [{" publication_date": "2017", "fullname_first_author": "Qianru Sun", "paper_title": "A domain based approach to social relation recognition", "reason": "This paper is foundational to the field, introducing the PIPA dataset, a benchmark frequently used in social relation recognition research.  The introduction of the PIPA dataset is crucial because it provides a standardized evaluation method and dataset for future work in this area.  Many subsequent papers, including this one, build on their methodology and use their dataset for evaluation. It is widely cited and represents a significant contribution to the field.", "section_number": 1}, {" publication_date": "2017", "fullname_first_author": "Junnan Li", "paper_title": "Dual-glance model for deciphering social relationships", "reason": "This paper presents a novel approach to social relation recognition by employing a dual-glance model to leverage multiple contextual regions of an image. Their work is important because it shows the potential for incorporating rich contextual information into social relation recognition models which this paper builds upon in a different paradigm.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Wanhua Li", "paper_title": "Graph-based social relation reasoning", "reason": "This paper proposes a graph-based method to model social relations, representing an important step towards incorporating the structural information about social relations for improved performance and generalization.  The use of graph neural networks improves the accuracy and expressiveness of social relation recognition model, offering a powerful alternative that other approaches build upon.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Zhouxia Wang", "paper_title": "Deep reasoning with knowledge graph for social relationship understanding", "reason": "This work integrates rich prior knowledge of social relations into the models, which this paper aims to achieve via prompting LLMs. The incorporation of knowledge graphs into social relation reasoning models shows the potential of using external knowledge to improve model performance, generalization and explainability.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Meng Zhang", "paper_title": "Multi-granularity reasoning for social relation recognition from images", "reason": "This paper explores multi-granularity reasoning to improve the accuracy of social relationship recognition. The utilization of multiple levels of information provides a more comprehensive approach to modeling social relation reasoning. This multi-level approach is implicitly followed in the proposed system by using different granularities of visual information.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yunfei Guo", "paper_title": "Social relation reasoning based on triangular constraints", "reason": "This paper focuses on the logical constraints among multiple social relationships, enhancing the reasoning process. This work is relevant because it highlights the importance of considering the relationships between different social relations in an image. This is implicitly addressed in SocialGPT through the Social Story.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Junnan Li", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "reason": "BLIP-2 is a crucial VFM used in the perception phase of SocialGPT.  Its capacity for accurate and comprehensive image captioning is key to the success of the SocialGPT framework because it converts visual information into textual format which is used as input for the next stage.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "SAM is another critical VFM utilized in SocialGPT for object segmentation, providing precise segmentation masks.  High-quality segmentation masks are essential for creating the detailed and accurate textual descriptions needed for the next step of reasoning.  This directly impacts the accuracy and reliability of the Social Story.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP is a foundation model that connects images and text which is a fundamental element of current vision-language models.  This paper significantly influenced the development of VFMs such as BLIP-2 and is an important reference for understanding the foundations of the current vision-language models.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "reason": "This paper demonstrates the significant improvements that chain-of-thought prompting can provide for large language model reasoning, which is a key element of SocialGPT\u2019s reasoning phase. The chain-of-thought prompting method is used to elicit reasoning capabilities from LLMs, making this paper crucial for understanding how to effectively prompt LLMs.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Jason Wei", "paper_title": "Emergent abilities of large language models", "reason": "This paper explores the emergent capabilities of large language models which is essential for understanding how LLMs can be used for high-level cognitive tasks such as social relation reasoning. The insights from this paper are directly applicable to understanding the capabilities and limitations of LLMs in the SocialGPT framework.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Pengfei Liu", "paper_title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing", "reason": "This survey paper provides a systematic overview of prompting methods in NLP and highlights the importance of prompt engineering in improving LLM performance. This is highly relevant to SocialGPT because prompt engineering plays a crucial role in the performance of the LLM.", "section_number": 3}, {" publication_date": "2020", "fullname_first_author": "Taylor Shin", "paper_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts", "reason": "This paper proposes a method for automatically generating prompts for LLMs which is relevant because it addresses the challenge of manual prompt engineering which is a limitation of SocialGPT. Autoprompt\u2019s approach of automatically generating prompts influenced the design of GSPO.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "reason": "This paper demonstrates the importance of self-consistency in improving chain-of-thought reasoning in LLMs which is relevant because SocialGPT relies heavily on LLMs for generating explanations. The self-consistency technique is applicable for improving the reasoning capabilities of LLMs in SocialGPT.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Junnan Li", "paper_title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "reason": "BLIP is an important foundation model for vision-language tasks. This paper is foundational to understanding the power of vision-language models. Although SocialGPT primarily uses BLIP-2, understanding the foundational work behind BLIP-2 is essential.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "SAM is a key component of the SocialGPT framework, used for object segmentation in images.  This paper is important because it describes the SAM model which directly impacts the quality of the visual information used by SocialGPT.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "reason": "LLaMA is one of the large language models (LLMs) used in the experiments section of the paper. This paper is important because LLaMA is a powerful and widely used LLM and provides an alternative to the more costly GPT-3.5 used in some experiments.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "LLama 2 is another LLM used in SocialGPT\u2019s experiments providing a comparison across different LLMs.  The evaluation of SocialGPT across multiple LLMs showcases its ability to adapt to different models and its generalizability.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Jules White", "paper_title": "Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design", "reason": "This paper explores various prompt patterns for improving code quality using ChatGPT, which is relevant to this paper\u2019s approach of using prompts to improve the performance of LLMs. The exploration of different prompt patterns is helpful in understanding how prompt design can influence the results and improving the prompt engineering process for LLMs.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "reason": "This paper introduces a method for learning to prompt vision-language models which is relevant to SocialGPT because prompt engineering is a crucial aspect of the proposed framework. Learning to prompt offers an automated alternative to manual prompt engineering, making it a significant contribution to the field.", "section_number": 5}]}