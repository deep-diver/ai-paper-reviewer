[{"figure_path": "2410.21411/figures/figures_2_0.png", "caption": "Figure 1: (a) End-to-end learning-based framework for social relation reasoning. A dedicated neural network is trained end-to-end with full training data. (b) We propose a modular framework with foundation models for social relation reasoning. Our proposed SocialGPT first employs VFMs to extract visual information into textual format, and then perform text-based reasoning with LLMs, using either our manually designed SocialPrompt or optimized prompts.", "description": "The figure compares end-to-end learning-based framework with a modular framework using foundation models for social relation reasoning.", "section": "1 Introduction"}, {"figure_path": "2410.21411/figures/figures_2_1.png", "caption": "Figure 1: (a) End-to-end learning-based framework for social relation reasoning. A dedicated neural network is trained end-to-end with full training data. (b) We propose a modular framework with foundation models for social relation reasoning. Our proposed SocialGPT first employs VFMs to extract visual information into textual format, and then perform text-based reasoning with LLMs, using either our manually designed SocialPrompt or optimized prompts.", "description": "The figure compares two frameworks for social relation reasoning: (a) an end-to-end learning-based framework and (b) a proposed modular framework using foundation models (VFMs and LLMs).", "section": "1 Introduction"}, {"figure_path": "2410.21411/figures/figures_3_0.png", "caption": "Figure 2: The framework of SocialGPT, which follows the \"perception with VFMs, reasoning with LLMs\" paradigm. SocialGPT converts an image into a social story in the perception phase, and then employs LLMs to generate explainable answers in the reasoning phase with SocialPrompt.", "description": "The figure illustrates the SocialGPT framework, which uses Vision Foundation Models (VFMs) for perception, converting images into social stories, and Large Language Models (LLMs) for reasoning, generating explainable answers using SocialPrompt.", "section": "3 SocialGPT"}, {"figure_path": "2410.21411/figures/figures_5_0.png", "caption": "Figure 6: The comparisons of the default SAM masks and our SAM masks.", "description": "The figure compares the default SAM masks with the masks produced by the improved SAM approach proposed in the paper, highlighting the latter's ability to minimize over-segmentation and produce high-quality object-level masks.", "section": "3.1 Perception with Vision Foundation Models"}, {"figure_path": "2410.21411/figures/figures_9_0.png", "caption": "Figure 4: Visualization results of interpretability. We show the SocialGPT perception and reasoning process. We see that our model predicts correct social relationships with plausible explanations.", "description": "The figure visualizes SocialGPT's perception and reasoning process, demonstrating its ability to predict social relationships correctly and provide plausible explanations.", "section": "Qualitative Analysis"}, {"figure_path": "2410.21411/figures/figures_10_0.png", "caption": "Figure 5: Results when applying SocialGPT to sketch and cartoon images. The images are generated by GPT-4V. Our method generalizes well on these novel image styles.", "description": "The figure shows qualitative results of SocialGPT on images of different styles generated by GPT-4V, demonstrating the generalization capability of the proposed model.", "section": "Qualitative Analysis"}, {"figure_path": "2410.21411/figures/figures_14_0.png", "caption": "Figure 6: The comparisons of the default SAM masks and our SAM masks.", "description": "The figure compares the default SAM masks with the masks generated by the authors' improved SAM methodology, showing that the authors' method produces fewer, more coherent object segmentations.", "section": "3.1 Perception with Vision Foundation Models"}]