{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper provides a technical report on GPT-4, a powerful language model used as a baseline for comparison in the PhysGame benchmark."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of large language models (LLMs), which are the basis of the video LLMs evaluated in the PhysGame benchmark."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The first-ever comprehensive evaluation benchmark of multi-modal LLMs in video analysis", "publication_date": "2024-05-21", "reason": "Video-MME is a major benchmark for evaluating video LLMs, and its use demonstrates the broader applicability of PhysVLM beyond physics-specific tasks."}, {"fullname_first_author": "Bo Li", "paper_title": "LLaVA-OneVision: Easy visual task transfer", "publication_date": "2024-08-03", "reason": "LLaVA-OneVision is an important open-source video LLM, used in the study to compare with the developed PhysVLM.  The comparison highlights the relative performance gains achieved."}, {"fullname_first_author": "Wei-Lin Chiang", "paper_title": "Vicuna: An open-source chatbot impressing GPT-4 with 90%* chatGPT quality", "publication_date": "2023-03-01", "reason": "Vicuna is a key open-source model used as a component in the architecture of PhysVLM; demonstrating the choice of a strong, open-source base model for improved performance."}]}