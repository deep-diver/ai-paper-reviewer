{"references": [{" publication_date": "2023", "fullname_first_author": "Rohan Anil", "paper_title": "Palm 2 technical report", "reason": "This paper is highly relevant because it introduces PaLM 2, a large language model that is used as a benchmark in many of the app control studies discussed in the paper, providing context for the performance comparison of the proposed LiMAC method.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Hao Bai", "paper_title": "Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning", "reason": "This work is highly relevant as it explores training agents for device control in real-world conditions, which is directly related to the proposed LiMAC method that aims to control mobile apps.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "reason": "This paper introduces Qwen-VL, a vision-language model, which is directly relevant to the LiMAC framework that employs a fine-tuned VLM (vision-language model) as one of its core components. It provides a comparison model for the performance evaluation in the context of vision-language capabilities.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "reason": "This work is relevant because the LiMAC framework processes sequential data, and this paper introduces a method for RL using sequence modeling, which offers an alternative approach to sequential decision-making in the app agent control domain. The techniques presented in the paper are conceptually related to the transformer-based method in LiMAC.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Xiang Deng", "paper_title": "Mind2web: Towards a generalist agent for the web", "reason": "This paper explores the development of generalist agents for web control, which is conceptually related to the goal of LiMAC to achieve versatile and efficient app agent control. The comparison and contrast between web and mobile agents will provide insights into the challenges faced in the development of more general-purpose agents.", "section_number": 5}, {" publication_date": "2018", "fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "reason": "This is a highly relevant reference due to the use of BERT, a language model used for encoding textual information, which is a critical part of the proposed LiMAC framework. The comparison and analysis of the performance of BERT embeddings relative to other embedding techniques are crucial for the performance evaluation and comparison of LiMAC.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Izzeddin Gur", "paper_title": "A real-world webagent with planning, long context understanding, and program synthesis", "reason": "This paper discusses a real-world web agent that deals with planning and long-context understanding, which is conceptually similar to the goal of LiMAC to build an agent that can understand and respond to user tasks on mobile devices.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Wenyi Hong", "paper_title": "Cogagent: A visual language model for gui agents", "reason": "This paper introduces CogAgent, a visual language model specifically designed for GUI agents, which is directly comparable to LiMAC, which employs a similar approach using vision-language capabilities.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "This paper is highly relevant because it proposes LoRA, a technique to adapt large language models using low-rank updates, which is especially relevant to the LiMAC framework that utilizes fine-tuned VLMs.  The efficiency gains from using LoRA are directly relevant to the goals of LiMAC for lightweight and efficient mobile agents.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Wei Li", "paper_title": "On the effects of data scale on computer control agents", "reason": "This paper examines the effect of the scale of training data on the performance of computer control agents, which is directly relevant to the LiMAC methodology as the efficiency and effectiveness of LiMAC heavily depend on the amount of data used for training and fine-tuning.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Evan Zheran Liu", "paper_title": "Reinforcement learning on web interfaces using workflow-guided exploration", "reason": "This work is relevant to LiMAC because the paper investigates reinforcement learning applied to web interfaces. The methods presented in this paper have some conceptual similarities to the approaches used for training and fine-tuning VLMs, thus providing a context for comparison within the machine learning domain.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ilya Loshchilov", "paper_title": "Fixing weight decay regularization in adam", "reason": "This is highly relevant because AdamW, the optimizer discussed in this paper, is used in the implementation details of LiMAC. Understanding the nuances of AdamW, such as weight decay regularization, is essential for interpreting and understanding the experimental results.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "This paper introduces CLIP, a vision-language model, which is directly relevant to the LiMAC framework that employs a fine-tuned CLIP model for encoding image information. The comparison of performance and efficiency between different vision-language models is critical to the LiMAC methodology.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidinthewild: A large-scale dataset for android device control", "reason": "This paper introduces the Android-in-the-Wild (AitW) dataset, which is one of the main datasets used for evaluating the performance of LiMAC. Understanding the characteristics of the AitW dataset is essential for evaluating the generalizability and robustness of LiMAC.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents", "reason": "This work provides another benchmark for evaluating agents in mobile environments, which is contextually relevant to the LiMAC approach. By presenting additional benchmark results, the authors help determine the effectiveness and efficiency of LiMAC against state-of-the-art solutions.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This paper introduces the Transformer architecture, the foundation of the AcT (Action Transformer) component in LiMAC.  Understanding the Transformer architecture is critical for understanding the design choices and operation of LiMAC and for analyzing its performance and efficiency.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception", "reason": "This paper proposes a mobile agent system, which shares similarities with LiMAC in terms of its multi-modal nature, specifically integrating visual perception and language understanding. Comparing the LiMAC architecture with other similar agents improves our understanding of the contribution and originality of the proposed method.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration", "reason": "This is a follow-up work to the previous mobile agent system, furthering our understanding of how similar approaches to multi-modal mobile agents are designed and evaluated.  This paper contributes to evaluating the relative effectiveness and efficiency of the proposed method in comparison to other recently developed agents.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Bin Xiao", "paper_title": "Florence-2: Advancing a unified representation for a variety of vision tasks", "reason": "This paper introduces Florence-2, a vision-language model which is used as a benchmark VLM in the LiMAC experiments.  Understanding the architecture and performance characteristics of Florence-2 is essential for interpreting and understanding the experimental results reported in the LiMAC evaluation.", "section_number": 4}]}