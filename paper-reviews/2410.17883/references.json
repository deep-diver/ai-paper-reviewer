{"references": [{" publication_date": "2023", "fullname_first_author": "Rohan Anil", "paper_title": "Palm 2 technical report", "reason": "This paper is highly relevant because it introduces Palm 2, a large language model that is used by many of the baselines and discussed in the related work section.  Understanding its capabilities and limitations is crucial for evaluating the performance of LiMAC and other models.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Hao Bai", "paper_title": "Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning", "reason": "This paper is highly relevant as it presents a reinforcement learning approach for training mobile device control agents, an area directly related to LiMAC.  Comparing LiMAC's supervised learning approach with this reinforcement learning technique is key for understanding the different tradeoffs of these methods.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "reason": "This paper introduces Qwen-VL, a vision-language model that serves as a key component in the LiMAC architecture.  Understanding Qwen-VL's capabilities is crucial for analyzing the performance and limitations of LiMAC.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "reason": "This work introduces the Decision Transformer architecture, a sequence modeling approach used for reinforcement learning.  The concepts and techniques from Decision Transformer are relevant to LiMAC's sequential decision-making process, making it a valuable reference for understanding LiMAC's architecture and methodology.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Xiang Deng", "paper_title": "Mind2web: Towards a generalist agent for the web", "reason": "This paper focuses on a generalist web agent, which is related to the broader topic of app agents.  It helps to contextualize LiMAC's focus on mobile app control within the wider field of AI agents that can interact with various interfaces.", "section_number": 5}, {" publication_date": "2018", "fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "reason": "BERT is a highly influential language model used for text encoding in LiMAC. Understanding BERT's architecture and its role in the overall performance of LiMAC is crucial. This paper provides critical background on the fundamental language model used in the LiMAC framework.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Izzeddin Gur", "paper_title": "A real-world webagent with planning, long context understanding, and program synthesis", "reason": "This research is highly relevant because it presents a real-world web agent. Understanding the strengths and limitations of a real-world web agent informs the discussions and design choices made by the authors in creating the LiMAC architecture.  The comparison allows for a better understanding of the challenges of building agents that can interact with real-world interfaces.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Wenyi Hong", "paper_title": "Cogagent: A visual language model for gui agents", "reason": "This paper is highly relevant as it introduces CogAgent, a visual language model specifically designed for GUI agents.  The comparison with LiMAC sheds light on the architectural choices and performance characteristics of different approaches to visual language modeling for the task of controlling smartphone apps.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "This paper is highly relevant because it introduces LoRA, a technique used to fine-tune large language models such as Qwen-VL which is part of LiMAC. Understanding LoRA's contribution is crucial for analyzing the efficiency and performance of the LiMAC framework.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Wei Li", "paper_title": "On the effects of data scale on computer control agents", "reason": "This paper directly investigates the impact of data scale on computer control agents, a topic highly relevant to LiMAC's performance. Understanding how data scale affects the performance of computer control agents helps contextualize LiMAC\u2019s results and limitations.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Evan Zheran Liu", "paper_title": "Reinforcement learning on web interfaces using workflow-guided exploration", "reason": "This paper is relevant as it presents a reinforcement learning approach to web interface control, a field closely related to mobile app control addressed by LiMAC.  Comparing the reinforcement learning methodologies in both approaches helps contextualize LiMAC's supervised learning approach and discuss the strengths and weaknesses of both methodologies.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Ilya Loshchilov", "paper_title": "Fixing weight decay regularization in adam", "reason": "AdamW, an optimizer based on Adam, is used to train LiMAC.  This paper directly addresses the challenges of regularizing Adam, and understanding this optimization technique is crucial for interpreting the training process and results for LiMAC.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Aaron van den Oord", "paper_title": "Representation learning with contrastive predictive coding", "reason": "This paper is highly relevant as it introduces contrastive learning, a key technique used in the LiMAC framework for click prediction.  Understanding the underlying principles of contrastive learning is crucial for analyzing the performance of LiMAC\u2019s click targeting mechanism.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "This work introduces CLIP, a vision-language model used for image encoding in LiMAC.  Understanding the capabilities and limitations of CLIP is crucial for evaluating the performance and limitations of LiMAC's image processing component.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidinthewild: A large-scale dataset for android device control", "reason": "This paper introduces the Android-in-the-Wild (AitW) dataset, one of the two datasets used to evaluate LiMAC.  Understanding the characteristics of this dataset is crucial for interpreting the results and generalizability of LiMAC\u2019s performance.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents", "reason": "This paper introduces AndroidWorld, a dynamic benchmarking environment for autonomous agents.  Understanding AndroidWorld's capabilities and limitations is crucial for evaluating LiMAC\u2019s performance and contextualizing the overall results presented in the experiments.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This paper introduces the Transformer architecture, a fundamental component of AcT, the core module within LiMAC.  Understanding the architecture and capabilities of the Transformer model is critical for evaluating the design choices and performance of AcT and the overall LiMAC framework.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception", "reason": "This paper is highly relevant because it introduces Mobile-Agent, a mobile agent designed for multi-modal interaction which is similar to LiMAC.  Comparing LiMAC with Mobile-Agent helps to understand the relative strengths and weaknesses of different approaches to creating mobile app control agents.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration", "reason": "This paper is highly relevant because it introduces Mobile-Agent-V2, an updated version of the Mobile-Agent discussed above. It expands on the capabilities of Mobile-Agent and further informs the comparison of LiMAC with other multi-modal mobile app control agents. The improvements over the initial version provide insight into the potential future development of LiMAC.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Bin Xiao", "paper_title": "Florence-2: Advancing a unified representation for a variety of vision tasks", "reason": "This work introduces Florence-2, a vision-language model that is used as one of the baseline models in the LiMAC evaluation.  Understanding Florence-2\u2019s strengths and limitations is crucial for contextualizing LiMAC\u2019s performance.", "section_number": 4}]}