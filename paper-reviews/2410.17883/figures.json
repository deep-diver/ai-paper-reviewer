[{"figure_path": "2410.17883/figures/figures_4_0.png", "caption": "Figure 1: Illustration of AcT. A separate encoding of each UI element into a vector e<sub>t,i</sub> by using pretrained embedding models. The embeddings are then fed into the sequence of a transformer X<sub>t</sub> along with the previous timesteps in that episode. The prediction of the transformer is decoded to produce the next action which consists of a<sub>type</sub> and a<sub>spec</sub>", "description": "The figure illustrates the AcT architecture, showing how UI element embeddings are generated and fed into a transformer to predict the next action.", "section": "3.1 MODEL INPUTS"}, {"figure_path": "2410.17883/figures/figures_5_0.png", "caption": "Figure 2: The architecture of LiMAC. The history of observations-actions {ot, at-1, Ot-1..} and goal g are processed to vector x and passed to AcT. The image observation omg with the bounding boxes and the goal g are passed as inputs to the VLM. The VLM is only called if an action that requires text completion is selected, based on the action type output of AcT. The action is finally selected based on the protocol described in Section 3.", "description": "The figure illustrates the architecture of LiMAC, showing how the history of observations, actions, and goals are processed by AcT and a VLM to generate the final action.", "section": "3 THE LIGHTWEIGHT MULTI-MODAL APP CONTROL FRAMEWORK"}, {"figure_path": "2410.17883/figures/figures_16_0.png", "caption": "Figure 4: Relaxed target element in yellow (timestep 3) and failed action in red (final timestep). The target element of the click in timestep 3 is considered correct under our relaxed accuracy because its bounding box is almost identical to the correct element, and clicking either would have the same effect (opening the text bar). In the final timestep, the agent inputs text 'Detroit' rather than 'Las Vegas', a clear confusion between the origin and destination of the trip stated in the goal, leading to an incorrect prediction.", "description": "This figure shows a sample episode from the AndroidControl dataset, highlighting a case of relaxed accuracy in a click action and a failure in an input-text action, illustrating the model's performance and limitations.", "section": "E CASE STUDIES"}, {"figure_path": "2410.17883/figures/figures_16_1.png", "caption": "Figure 5: Relaxed input-text in yellow (timestep 4) and overall successful episode. Timestep 4 is considered correct under our relaxed input-text textual component because it is simply the singular form of the correct text, leading to a Jaccard index greater than 0.5 and presumably the same search results. The episode terminates successfully, with all timesteps being considered correct under our evaluation metrics.", "description": "This figure shows a successful episode where the agent correctly interacts with the phone interface to complete a task, with one timestep having a relaxed accuracy due to a minor discrepancy in the input text.", "section": "E CASE STUDIES"}]