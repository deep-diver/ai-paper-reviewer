[{"figure_path": "2410.12183/tables/table_7_0.html", "caption": "Table 1: Accuracy comparison with state-of-the-art methods on base-to-novel generalization. All methods use CLIP's ViT-B/16 as the vision encoder. Our TransAgent exhibits strong generalization ability and outperforms previous SOTA on all datasets. The best results are bolded.", "description": "Table 1 compares the performance of TransAgent against other state-of-the-art methods on eleven visual recognition datasets using base-to-novel generalization.", "section": "4 Experiments"}, {"figure_path": "2410.12183/tables/table_9_1.html", "caption": "Table 3: LAC Design.", "description": "Table 3 presents the results of ablating different designs for Language Agent Collaboration (LAC) module, showing the base, novel, and harmonic mean (HM) accuracy for different model choices and fusion methods.", "section": "4.2 Ablative Analysis"}, {"figure_path": "2410.12183/tables/table_16_0.html", "caption": "Table 7: Demonstration of heterogeneous agents specialized in different domains or tasks.", "description": "Table 7 presents the different agents used in the TransAgent framework, specifying their parameters, model type, pre-training tasks and datasets, and the type of knowledge they provide.", "section": "4 Experiments"}, {"figure_path": "2410.12183/tables/table_16_1.html", "caption": "Table 8: Memory and training time required for each dataset.", "description": "This table shows the memory usage (in MB) and training time per batch (in milliseconds) for different datasets and training settings (base-to-novel and 16-shot).", "section": "4 Experiments"}, {"figure_path": "2410.12183/tables/table_17_0.html", "caption": "Table 9: Accuracy comparison with previous methods on cross-dataset evaluation.", "description": "Table 9 presents a comparison of the accuracy achieved by various methods on cross-dataset evaluation, highlighting the superior performance of TransAgent.", "section": "4.1 Comparison with State-of-the-Art"}]