{"importance": "This research introduces EgoLife, a 300-hour egocentric dataset with multimodal annotations, addressing gaps in long-term, interpersonal AI assistance. It offers EgoLifeQA, a benchmark for life-oriented QA tasks. This work can stimulate further research in egocentric AI assistants and provide meaningful assistance in daily life. **The dataset, models, and benchmarks are released to encourage innovation in the field and enable long-context understanding.**", "summary": "EgoLife: Ultra-long egocentric dataset & benchmark enabling AI assistants to understand and enhance daily life. Datasets and models released!", "takeaways": ["EgoLife dataset offers unprecedented long-term egocentric data for studying daily activities and social interactions.", "EgoLifeQA benchmark introduces life-oriented question-answering tasks to advance egocentric AI.", "EgoButler, with EgoGPT and EgoRAG, tackles key challenges in egocentric AI, demonstrating effective omni-modal understanding and long-context reasoning."], "tldr": "Current egocentric vision systems and datasets often fall short in understanding ultra-long-term behavior patterns and complex social dynamics due to limited recording durations and monographic perspectives. **The EgoLife project bridges this gap by presenting a comprehensive data collection study** where six participants lived together for one week, continuously recording their daily activities using AI glasses, along with synchronized third-person video references. This results in the EgoLife Dataset, a 300-hour dataset with intensive annotation.\n\n**To showcase the dataset's potential, the project introduces EgoLifeQA,** a suite of long-context, life-oriented question-answering tasks designed to provide meaningful assistance in daily life. Additionally, it presents EgoBulter, an integrated system comprising EgoGPT and EgoRAG, to address the technical challenges of developing robust visual-audio models and facilitating long-context question answering. Experimental studies verify EgoBulter's mechanisms and guide future improvements.", "affiliation": "NTU S-Lab", "categories": {"main_category": "Multimodal Learning", "sub_category": "Human-AI Interaction"}, "podcast_path": "2503.03803/podcast.wav"}