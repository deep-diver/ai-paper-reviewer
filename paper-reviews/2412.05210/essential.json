{"importance": "This paper is crucial because it addresses the critical gap between existing code evaluation benchmarks and real-world human preferences.  By introducing **CodeArena**, a human-curated benchmark, and **SynCode-Instruct**, a large-scale synthetic instruction corpus, it provides researchers with valuable tools to improve the alignment of code LLMs with user expectations. This work has implications for building better, more user-friendly code generation tools, as well as for evaluating existing models.", "summary": "CodeArena, a novel benchmark, evaluates code LLMs based on human preferences, revealing performance gaps between open-source and proprietary models, and a large-scale synthetic instruction corpus improves model alignment.", "takeaways": ["CodeArena benchmark effectively measures alignment between model-generated code and human preference.", "Significant performance differences exist between open-source and proprietary code LLMs regarding human preference.", "Large-scale synthetic instruction data (SynCode-Instruct) improves code LLM performance and alignment."], "tldr": "Current code LLM evaluation focuses on code correctness, ignoring human preferences in practical coding tasks. This leads to a mismatch between model outputs and user expectations. Existing benchmarks like HumanEval and MBPP mainly assess code correctness through unit testing and lack diversity in programming languages and task types.\nTo bridge this gap, researchers introduce CodeArena, a comprehensive human-curated benchmark with 397 high-quality samples, and SynCode-Instruct, a large-scale synthetic instruction dataset. They systematically evaluate 40+ LLMs on CodeArena, revealing performance differences based on human preferences.  **CodeArena** effectively measures the alignment of model outputs with user preferences, while **SynCode-Instruct** improves the alignment of open-source code LLMs. This approach highlights the importance of considering human preference for code generation.", "affiliation": "Alibaba Group", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2412.05210/podcast.wav"}