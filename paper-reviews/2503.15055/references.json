{"references": [{"fullname_first_author": "Marah Abdin", "paper_title": "Phi-3 technical report: A highly capable language model locally on your phone", "publication_date": "2024-04-14", "reason": "This paper introduces Phi-3, a highly capable language model, potentially relevant for efficient local inference in cybersecurity applications, aligning with the paper's focus on smaller domain-adapted models."}, {"fullname_first_author": "Zaid Almahmoud", "paper_title": "A holistic and proactive approach to forecasting cyber threats", "publication_date": "2023-01-01", "reason": "This paper is relevant due to its focus on cyber threat forecasting, providing context for the broader field in which the paper's research on synthetic data generation for cyberattack detection is situated."}, {"fullname_first_author": "Gemini Team", "paper_title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context", "publication_date": "2024-03-05", "reason": "This paper presents Gemini 1.5, a multimodal model with a large context window that could improve the model's indicator retention in the tested framework."}, {"fullname_first_author": "Gemma Team", "paper_title": "Gemma: Open models based on gemini research and technology", "publication_date": "2024-03-08", "reason": "This is a top reference since this paper introduces Gemma, the open model family which is fine-tuned and tested in the framework, so the framework results are directly dependant on this model."}, {"fullname_first_author": "Thomas Wolf", "paper_title": "Transformers: State-of-the-art natural language processing", "publication_date": "2020-01-01", "reason": "This paper introduces the Transformers library, the library used to implement the framework, so the framework is directly dependant on this reference."}]}