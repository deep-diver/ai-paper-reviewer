{"references": [{"fullname_first_author": "Angela Dai", "paper_title": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "publication_date": "2017-00-00", "reason": "This paper introduces a large-scale dataset crucial for training and evaluating 3D scene understanding models."}, {"fullname_first_author": "Daichi Azuma", "paper_title": "Scanqa: 3d question answering for spatial scene understanding", "publication_date": "2022-00-00", "reason": "This paper presents a benchmark dataset for evaluating 3D scene understanding models' ability to answer questions about scenes."}, {"fullname_first_author": "Dave Zhenyu Chen", "paper_title": "Scanrefer: 3d object localization in rgb-d scans using natural language", "publication_date": "2020-00-00", "reason": "This paper introduces a benchmark dataset and task for evaluating the ability of models to locate objects in 3D scenes using natural language descriptions."}, {"fullname_first_author": "Sijin Chen", "paper_title": "Ll3da: Visual interactive instruction tuning for omni-3d understanding reasoning and planning", "publication_date": "2024-00-00", "reason": "This paper proposes a method for enhancing large 3D scene understanding by leveraging LLMs and is directly compared against in the current work."}, {"fullname_first_author": "Yining Hong", "paper_title": "3d-llm: Injecting the 3d world into large language models", "publication_date": "2023-00-00", "reason": "This paper is a foundational work on integrating large language models with 3D scene understanding, providing a basis for many of the methods compared in the current work."}]}