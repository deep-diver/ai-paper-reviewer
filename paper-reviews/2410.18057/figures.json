[{"figure_path": "2410.18057/figures/figures_1_0.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows example images from the CLEAR dataset illustrating the retain and forget sets for real faces and real-world objects.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_1_1.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows examples of images and questions from the CLEAR dataset, illustrating the retain and forget sets, as well as real faces and real-world images.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_1_2.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows example images from the CLEAR dataset, illustrating the \"retain\", \"forget\", \"real faces\", and \"real world\" categories.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_1_3.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows examples of images and questions from the CLEAR dataset, illustrating the retain and forget sets, as well as real faces and real-world images.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_2_0.png", "caption": "Figure 2: Summary of our dataset. We generate 200 persons and use multimodal unlearning to forget the part of them. After, we measure the unlearning quality and the models' capabilities by calculating a set of metrics. Then, we create a leaderboard of unlearning methods based on these metrics.", "description": "The figure summarizes the CLEAR dataset generation process, the unlearning model application, and the evaluation metrics used to assess multimodal unlearning performance.", "section": "4 CLEAR"}, {"figure_path": "2410.18057/figures/figures_4_0.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows examples of images and questions from the CLEAR dataset, illustrating the different data modalities and unlearning tasks.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_4_1.png", "caption": "Figure 1: The overview of our dataset.", "description": "The figure shows example images from the CLEAR dataset, illustrating the different image types used (real faces, real-world images) and the retain/forget split.", "section": "1 Introduction"}, {"figure_path": "2410.18057/figures/figures_5_0.png", "caption": "Figure 4: Distributions of the attributes of the author's faces. We show that CLEAR is balanced and representative regarding age, gender, and ethnicity.", "description": "The figure shows the distributions of age, gender, and ethnicity of the 200 fictitious authors in the CLEAR dataset, demonstrating its balance and representativeness.", "section": "4.1 Dataset Generation Process"}, {"figure_path": "2410.18057/figures/figures_19_0.png", "caption": "Figure 6: Visualization of logits distribution for the forget and holdout sets across 9 different unlearning methods. According to the U-MIA evaluation, a larger intersection of the distributions indicates a more successful unlearning outcome,", "description": "Figure 6 shows the visualization of logits distribution for the forget and holdout sets across 9 different unlearning methods, where a larger intersection of distributions indicates a more successful unlearning outcome.", "section": "G U-MIA and U-LIRA"}]