[{"figure_path": "2410.18057/tables/table_6_0.html", "caption": "Table 1: Unlearning methods on textual domain only. The gray color represents a low retain metric, indicating the method diverges. Hence, we do not consider them.", "description": "The table presents the results of applying various unlearning methods to a textual-only domain, evaluating their performance using Real, Retain, Forget metrics and Log Forget Quality.", "section": "5.1 Unlearning Textual Domain (LLMs)"}, {"figure_path": "2410.18057/tables/table_6_1.html", "caption": "Table 2: Results of unlearning on visual modality only. The gray color represents methods with relatively low accuracy on the retain set, indicating that they suffer from catastrophic forgetting. Therefore, we do not consider these methods to be successful.", "description": "Table 2 presents the results of applying various unlearning methods to the visual modality of the CLEAR benchmark, showing that most methods achieve high accuracy on the forget set with competitive U-LIRA and U-MIA values, but several methods suffer from catastrophic forgetting on the retain set.", "section": "5.2 Unlearning Visual Domain"}, {"figure_path": "2410.18057/tables/table_7_0.html", "caption": "Table 3: Results of unlearning of different modalities. We finetune on full datasets (both modalities), then forget on a single domain subset (text or visual) or full forget set. Original \u2013 model before unlearning. Gold - a model trained only on retain.", "description": "Table 3 shows the results of unlearning experiments conducted on textual, visual, and multimodal domains, comparing the performance of different unlearning methods.", "section": "5.3 Multimodal Experiments"}, {"figure_path": "2410.18057/tables/table_8_0.html", "caption": "Table 4: Results on experiments with and without LORA regularization. The gray color shows that the method completely fails on the retain set.", "description": "Table 4 presents the results of experiments on multimodal unlearning with and without LORA regularization, showing the impact of regularization on model performance in terms of real, retain, and forget metrics.", "section": "5.4 LORA Regularization"}, {"figure_path": "2410.18057/tables/table_20_0.html", "caption": "Table 1: Unlearning methods on textual domain only. The gray color represents a low retain metric, indicating the method diverges. Hence, we do not consider them.", "description": "Table 1 presents the performance of various unlearning methods on a textual-only domain, highlighting the divergence of some methods and their exclusion from further analysis.", "section": "5.1 Unlearning Textual Domain (LLMs)"}]