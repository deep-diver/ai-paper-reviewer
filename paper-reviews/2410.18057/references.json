{"references": [{" publication_date": "2023", "fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "reason": "This paper introduces Llama 2, a significant large language model (LLM) that is relevant to the study of machine unlearning due to its size and widespread use.  The model's architecture and training data are crucial considerations for implementing and evaluating unlearning techniques, making this a foundational reference for the research.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Albert Q. Jiang", "paper_title": "Mistral 7b", "reason": "This paper introduces Mistral 7B, another large language model (LLM) used in the study's experiments. Its characteristics and performance are important comparative points for analyzing the effectiveness of various unlearning methods on different LLMs.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ximing Lu", "paper_title": "Quark: Controllable text generation with reinforced unlearning", "reason": "This work is highly relevant because it directly addresses machine unlearning (MU) in the context of LLMs, focusing on controllable text generation.  The techniques and findings contribute significantly to the broader understanding and development of MU strategies.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Joel Jang", "paper_title": "Knowledge unlearning for mitigating privacy risks in language models", "reason": "This paper directly addresses privacy concerns in the context of language models, a key focus of the study's unlearning research. The techniques and findings presented are highly relevant to the challenges and solutions discussed in the paper.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Gabriel Ilharco", "paper_title": "Editing models with task arithmetic", "reason": "This paper explores model editing, a related area to machine unlearning, offering techniques that could potentially be adapted or combined with unlearning methods to achieve more refined control over model knowledge.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Ronen Eldan", "paper_title": "Who's harry potter? Approximate unlearning in LLMs", "reason": "This paper tackles approximate unlearning in LLMs which is directly relevant to the study's focus on machine unlearning. The approaches and findings are directly relevant to the challenge of balancing forgetting and retaining knowledge.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Pratyush Maini", "paper_title": "Tofu: A task of fictitious unlearning for LLMs", "reason": "This paper introduces TOFU, a textual unlearning benchmark, which is directly relevant to the study.  Its design and evaluation metrics provide valuable insights that are applicable to the design and evaluation of the CLEAR benchmark for multimodal unlearning.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Nathaniel Li", "paper_title": "The wmdp benchmark: Measuring and reducing malicious use with unlearning", "reason": "This paper presents WMDP, a textual benchmark focusing on unlearning harmful knowledge. The metrics and evaluation strategies are highly relevant to the study's multimodal unlearning evaluation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jin Yao", "paper_title": "Machine unlearning of pre-trained large language models", "reason": "This study directly addresses machine unlearning in large language models (LLMs), providing valuable insights and techniques that can inform the development of multimodal unlearning methods. The approaches and results contribute to a broader understanding of the challenges and solutions in the field.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jiaqi Li", "paper_title": "Single image unlearning: Efficient machine unlearning in multimodal large language models", "reason": "This paper directly addresses the challenge of unlearning in multimodal LLMs, focusing on visual unlearning.  The benchmark and techniques presented are highly relevant to the broader research on multimodal unlearning.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Trishna Chakraborty", "paper_title": "Cross-modal safety alignment: Is textual unlearning all you need?", "reason": "This work explores unlearning harmful content in visual language models (VLLMs).  The findings on the effectiveness of textual-only unlearning in certain scenarios are highly relevant to the study's investigation of multimodal unlearning challenges.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jamie Hayes", "paper_title": "Inexact unlearning needs more careful evaluations to avoid a false sense of privacy", "reason": "This paper highlights the importance of rigorous evaluation metrics for unlearning.  The discussion of strict vs. inexact unlearning and proposed evaluation metrics is directly relevant to the study's methodology and evaluation of unlearning methods.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "CLIP model is used in the paper for image generation. Its use is highly relevant to the evaluation of the CLEAR dataset and for generating images related to specific text prompts for the study\u2019s evaluation.  The model's capabilities and limitations in generating realistic and consistent images are important aspects of this dataset's reliability.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Tero Karras", "paper_title": "Analyzing and improving the image quality of stylegan", "reason": "StyleGAN2 is used for generating faces in the CLEAR dataset.  Understanding StyleGAN's capabilities and limitations in generating realistic and diverse faces is crucial for evaluating the dataset's quality and the generalizability of the results.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Zhen Li", "paper_title": "Photomaker: Customizing realistic human photos via stacked id embedding", "reason": "This diffusion model is highly relevant to the generation of images in the CLEAR dataset. The model's capabilities in generating realistic images from text prompts and face embeddings directly impact the quality and consistency of the dataset's visual component.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Yaobin Zhang", "paper_title": "Global-local gcn: Large-scale label noise cleansing for face recognition", "reason": "The MillionCelebs dataset is used for the real-world face evaluation.  The techniques and findings from this paper regarding face recognition are relevant to evaluating how well unlearning methods preserve the model\u2019s ability to recognize real-world faces.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Jamie Hayes", "paper_title": "Inexact unlearning needs more careful evaluations to avoid a false sense of privacy", "reason": "This paper is highly relevant to the study's methodology due to its emphasis on defining and evaluating unlearning quality.  The concept of \u2018inexact unlearning\u2019 and its distinction from \u2018strict unlearning\u2019 directly informs the experimental design and evaluation metrics.", "section_number": 5}, {" publication_date": "2022", "fullname_first_author": "Jinghan Jia", "paper_title": "Model sparsity can simplify machine unlearning", "reason": "This paper explores model sparsity as a technique to simplify machine unlearning.  The findings on the effects of sparsity on unlearning performance are highly relevant to the study's investigation of L1 regularization on LoRA weights to mitigate catastrophic forgetting.", "section_number": 6}, {" publication_date": "2024", "fullname_first_author": "Ruiqi Zhang", "paper_title": "Negative preference optimization: From catastrophic collapse to effective unlearning", "reason": "This paper introduces a novel method, Negative Preference Optimization (NPO), for machine unlearning.  The study uses NPO in its analysis, and understanding its mechanisms and performance is critical for interpreting the results.", "section_number": 6}, {" publication_date": "2023", "fullname_first_author": "Meghdad Kurmanji", "paper_title": "Towards unbounded machine unlearning", "reason": "This paper introduces SCRUB, an unlearning method used in the study. Understanding SCRUB's mechanisms and performance is crucial for analyzing the results of multimodal unlearning experiments.", "section_number": 6}]}