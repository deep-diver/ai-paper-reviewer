{"references": [{" publication_date": "2023", "fullname_first_author": "Clark Barrett", "paper_title": "Identifying and mitigating the security risks of generative ai", "reason": "This paper is highly relevant to the core theme of the study because it directly addresses security and privacy risks associated with generative AI, which are central concerns addressed by machine unlearning techniques.  The paper's comprehensive analysis of security risks and mitigation strategies provides a valuable context for understanding the significance of the research on machine unlearning.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Denis Bobkov", "paper_title": "The devil is in the details: Style-featureeditor for detail-rich stylegan inversion and high quality image editing", "reason": "This paper is highly relevant because it presents a method for high-quality image editing, which is crucial for generating realistic and high-quality images for use in the CLEAR dataset. Its contribution to high-quality image generation makes it an important supporting paper for the main work.", "section_number": 4}, {" publication_date": "2015", "fullname_first_author": "Yinzhi Cao", "paper_title": "Towards making systems forget with machine unlearning", "reason": "This paper is foundational to the field of machine unlearning, providing early conceptual groundwork and laying the groundwork for subsequent advancements discussed in the main paper. Its focus on enabling systems to \"forget\" information is directly related to the core objective of the main study.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Trishna Chakraborty", "paper_title": "Cross-modal safety alignment: Is textual unlearning all you need?", "reason": "This paper explores the critical question of whether textual unlearning alone is sufficient for multimodal models, which is directly relevant to the main research.  Its findings and approaches regarding cross-modal safety alignment are important for contextualizing and comparing with the research presented in the main paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jiali Cheng", "paper_title": "Multidelete for multimodal machine unlearning", "reason": "This paper is highly relevant as it directly addresses the issue of multimodal machine unlearning, a key focus of the main study. The proposed MultiDelete method offers a specific technique for MMU, providing a comparative point of reference for the methods and results presented in the main paper.", "section_number": 2}, {" publication_date": "2015", "fullname_first_author": "Cynthia Dwork", "paper_title": "The algorithmic foundations of differential privacy", "reason": "This is a foundational text in differential privacy, a core concept closely related to the privacy aspects of machine unlearning. The principles and techniques discussed in this book are highly relevant to the research and help contextualize the privacy concerns addressed by machine unlearning.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Ronen Eldan", "paper_title": "Who's harry potter? approximate unlearning in Ilms", "reason": "This paper addresses the task of approximate unlearning in LLMs, a crucial aspect in the main study. The focus on approximate unlearning, as opposed to exact unlearning, makes it a particularly relevant contribution to the work, as approximate unlearning is more practical in real-world scenarios.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Gabriel Ilharco", "paper_title": "Editing models with task arithmetic", "reason": "This paper is significant because it introduces a method for model editing, a closely related concept to unlearning. The methods and ideas in this work are highly relevant as they provide alternative approaches and theoretical foundations for understanding and improving unlearning techniques.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Joel Jang", "paper_title": "Knowledge unlearning for mitigating privacy risks in language models", "reason": "This paper is directly relevant as it specifically addresses privacy risks in language models and explores methods to mitigate them through knowledge unlearning. The techniques and findings in this study are directly comparable to the research presented in the main paper and offer valuable insights.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Tero Karras", "paper_title": "Analyzing and improving the image quality of stylegan", "reason": "This paper is crucial because it provides insights into improving the quality of images generated by StyleGAN, which was used in generating the facial images for the CLEAR dataset. It offers valuable technical background and methods for achieving high-quality image generation, a critical component of the multimodal unlearning research.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Meghdad Kurmanji", "paper_title": "Towards unbounded machine unlearning", "reason": "This paper is highly relevant as it directly addresses the challenge of unbounded machine unlearning, a complex issue in the field.  The advanced techniques and methodologies discussed in this study are of direct relevance to the research presented in the main paper.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jiaqi Li", "paper_title": "Single image unlearning: Efficient machine unlearning in multimodal large language models", "reason": "This paper focuses on single image unlearning in MLLMs, which is highly relevant to the main research.  The benchmark introduced in this paper (MMUBench), while not open source, still provides valuable insights into the challenges and approaches for evaluating visual unlearning in multimodal models.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Nathaniel Li", "paper_title": "The wmdp benchmark: Measuring and reducing malicious use with unlearning", "reason": "This work introduces a benchmark for textual unlearning, focusing on hazardous knowledge.  While it is not directly a multimodal benchmark, its contribution as a comprehensive benchmark for unlearning in LLMs provides valuable contextualization and comparison for the newly proposed CLEAR benchmark in the primary paper.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Bo Liu", "paper_title": "Continual learning and private unlearning", "reason": "This paper is directly related to the topic of private unlearning, a core focus of the study. It discusses continual learning alongside unlearning, offering valuable context and highlighting the interplay between continuous model adaptation and private data removal.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ximing Lu", "paper_title": "Quark: Controllable text generation with reinforced unlearning", "reason": "This paper presents a method for controllable text generation that incorporates reinforced unlearning. This method is relevant to the study because it demonstrates an innovative approach to combining text generation with unlearning, offering potential insights and comparative approaches for the research presented in the main paper.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Pratyush Maini", "paper_title": "Tofu: A task of fictitious unlearning for llms", "reason": "This work is highly relevant as it proposes a benchmark specifically for textual unlearning in LLMs. This contribution provides valuable contextualization and comparison points for the main study, which focuses on the development of a multimodal benchmark.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "reason": "This work is relevant because it introduces direct preference optimization (DPO), a technique directly applied in the main study for unlearning. The concepts and algorithms in this work are important to the main study as DPO is used as a primary unlearning method in the experiments and evaluation of CLEAR.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "This paper is important because it introduces the CLIP model, a crucial element used in one of the unlearning methods discussed in the main study.  The CLIP model's capacity for aligning text and image representations is relevant to the multimodal nature of the research.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Ayush Sekhari", "paper_title": "Remember what you want to forget: Algorithms for machine unlearning", "reason": "This paper offers valuable algorithmic advancements in machine unlearning, contributing to the theoretical foundations of the research presented in the main paper. Its focus on algorithmic approaches offers a different perspective and potential techniques for the development of improved unlearning methodologies.", "section_number": 2}]}