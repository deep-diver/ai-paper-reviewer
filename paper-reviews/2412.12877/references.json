{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduced Stable Diffusion, a foundational model for many current text-to-video and image editing approaches, including the one presented in this paper."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Structure and content-guided video synthesis with diffusion models", "publication_date": "2023-01-01", "reason": "This work provides a strong baseline and inspiration for diffusion-based video editing methods, serving as a benchmark for comparison."}, {"fullname_first_author": "Jay Zhangjie Wu", "paper_title": "Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation", "publication_date": "2023-01-01", "reason": "This paper introduces an efficient method for adapting pre-trained image diffusion models to video editing tasks, an important aspect of the current work."}, {"fullname_first_author": "Yuren Cong", "paper_title": "FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing", "publication_date": "2024-01-01", "reason": "FLATTEN is utilized in the proposed framework to maintain temporal consistency, a crucial component for video editing."}, {"fullname_first_author": "Hyeonho Jeong", "paper_title": "Ground-a-video: Zero-shot grounded video editing using text-to-image diffusion models", "publication_date": "2024-01-01", "reason": "GAV is a state-of-the-art method for multi-object video editing and serves as a primary comparison point for the proposed MIVE framework."}]}