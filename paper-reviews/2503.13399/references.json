{"references": [{"fullname_first_author": "James Burgess", "paper_title": "Orientation-invariant autoencoders learn robust representations for shape profiling of cells and organelles", "publication_date": "2024-01-01", "reason": "This reference is important as it represents prior work by the authors in shape profiling of cells and organelles, contributing to the foundation of their current research."}, {"fullname_first_author": "Anne E Carpenter", "paper_title": "Smart microscopes of the future", "publication_date": "2023-07-01", "reason": "This reference is important because it discusses advances in microscopy and the integration of AI in microscopy, aligning with the core themes of the MicroVQA benchmark."}, {"fullname_first_author": "Tom Hope", "paper_title": "A computational inflection for scientific discovery", "publication_date": "2023-08-01", "reason": "This reference is important because it discusses applications for Al in scientific discovery including microscopy, aligning with the key activities in biological research workflows: expert image understanding, hypothesis generation and experiment proposal."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-01-01", "reason": "This reference is important because it discusses fine-tuning with a dataset that better aligns with the MicroVQA data domain."}, {"fullname_first_author": "Xiang Yue", "paper_title": "MMMU: A massive multi-discipline multimodal understanding and reasoning benchmark for expert AGI", "publication_date": "2024-01-01", "reason": "This reference is important because it's a major multimodal benchmark that the authors compare MicroVQA with in terms of difficulty and reasoning level."}]}