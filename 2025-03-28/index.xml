<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-28s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/</link><description>Recent content in 2025-03-28s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 27 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/index.xml" rel="self" type="application/rss+xml"/><item><title>Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21380/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21380/</guid><description>OlymMATH: A new Olympiad-level math benchmark rigorously tests LLMs&amp;rsquo; reasoning, revealing limitations and paving the way for advancements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21380/cover.png"/></item><item><title>ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21144/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21144/</guid><description>ChatAnyone: Stylized real-time portrait video generation with hierarchical motion diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21144/cover.png"/></item><item><title>Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21696/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21696/</guid><description>Embodied-Reasoner: Integrates visual search, reasoning, and action for interactive tasks, outperforming existing models in embodied environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21696/cover.png"/></item><item><title>Exploring the Evolution of Physics Cognition in Video Generation: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21765/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21765/</guid><description>This survey explores the evolution of physics cognition in video generation, addressing the gap between visual realism and physical accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21765/cover.png"/></item><item><title>Large Language Model Agent: A Survey on Methodology, Applications and Challenges</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21460/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21460/</guid><description>This survey presents a methodology-centered taxonomy of LLM agent systems, linking design principles to emergent behaviors and identifying future research directions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21460/cover.png"/></item><item><title>LeX-Art: Rethinking Text Generation via Scalable High-Quality Data Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21749/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21749/</guid><description>LeX-Art: High-quality text-to-image generation via scalable data synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21749/cover.png"/></item><item><title>LOCATEdit: Graph Laplacian Optimized Cross Attention for Localized Text-Guided Image Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21541/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21541/</guid><description>LOCATEdit refines cross-attention maps with graph Laplacian regularization, achieving precise &amp;amp; localized text-guided image editing without artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21541/cover.png"/></item><item><title>Lumina-Image 2.0: A Unified and Efficient Image Generative Framework</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21758/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21758/</guid><description>Lumina-Image 2.0: A unified &amp;amp; efficient image generative framework, outperforming previous models with only 2.6B parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21758/cover.png"/></item><item><title>Optimal Stepsize for Diffusion Sampling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21774/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21774/</guid><description>Optimal Stepsize Distillation accelerates diffusion sampling by distilling knowledge from reference trajectories, achieving 10x speedup with minimal performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21774/cover.png"/></item><item><title>ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21729/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21729/</guid><description>ReaRAG enhances factuality in large reasoning models (LRMs) by integrating knowledge-guided reasoning with iterative retrieval augmented generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21729/cover.png"/></item><item><title>ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21248/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21248/</guid><description>ResearchBench: Benchmarking LLMs for Scientific Discovery via Inspiration-Based Task Decomposition.</description></item><item><title>UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21620/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21620/</guid><description>UI-R1 enhances GUI agents&amp;rsquo; action prediction using reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21620/cover.png"/></item><item><title>VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21755/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21755/</guid><description>VBench 2.0: A new benchmark suite advancing video generation evaluation with intrinsic faithfulness metrics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21755/cover.png"/></item><item><title>Video-R1: Reinforcing Video Reasoning in MLLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21776/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21776/</guid><description>Video-R1: First to explore rule-based RL for video reasoning in MLLMs, enhancing performance on key benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21776/cover.png"/></item><item><title>ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21088/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21088/</guid><description>Model Merging: An unlearning system, which combines specialized models, achieves top results in SemEval-2025 Task 4 by selectively erasing sensitive knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.21088/cover.png"/></item><item><title>Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20776/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20776/</guid><description>Feature4X: 4D Agentic AI from Monocular Video w/ Gaussian Feature Fields</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20776/cover.png"/></item><item><title>FinAudio: A Benchmark for Audio Large Language Models in Financial Applications</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20990/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20990/</guid><description>FINAUDIO: First benchmark for financial audio LLMs, enhancing financial audio analysis and investment decisions.</description></item><item><title>Synthetic Video Enhances Physical Fidelity in Video Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20822/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20822/</guid><description>Synthetic data can enhance the physical realism of video synthesis, paving the way for more believable generated content.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20822/cover.png"/></item><item><title>Unified Multimodal Discrete Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20853/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20853/</guid><description>UniDisc: a unified multimodal discrete diffusion model for joint text and image generation, surpassing autoregressive models in quality &amp;amp; efficiency!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-28/2503.20853/cover.png"/></item></channel></rss>