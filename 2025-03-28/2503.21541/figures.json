[{"figure_path": "https://arxiv.org/html/2503.21541/extracted/6315178/images/ICCV_overediting-2-3.png", "caption": "Figure 1: Our LOCATEdit demonstrates strong performance on various complex image editing tasks.", "description": "Figure 1 showcases several example results produced by LOCATEdit, demonstrating its capability to perform a variety of complex image editing tasks guided by text prompts.  Each example shows an original image alongside a modified version generated by LOCATEdit. The modifications demonstrate the model's ability to precisely target and edit specific regions of an image while preserving the integrity of the overall image structure and background fidelity.  The examples range from simple changes like altering the color of an object to more complex modifications such as adding or removing elements from a scene.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2503.21541/extracted/6315178/images/ICCV_main_figure_updated-21.png", "caption": "Figure 2: Example of over-editing caused due to imprecise masks.", "description": "This figure shows three examples of image editing results where imprecise masks have led to undesired modifications.  In each example, the LOCATEdit model produces a more localized edit, accurately targeting the desired area without affecting the surrounding image content.  In contrast, ViMAEdit struggles to achieve this level of precision and produces edits that spill into unwanted regions. These results highlight the challenges in creating accurate masks for effective text-guided image editing.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.21541/extracted/6315178/images/ICCV-self-attention-3-5.png", "caption": "Figure 3: Overview of our text-guided image editing pipeline. LOCATEdit refines cross-attention maps with graph Laplacian regularization for spatial consistency, uses an IP-Adapter for additional guidance, and employs selective pruning on text embeddings to suppress noise, ensuring the edited image preserves key structural details.", "description": "This figure illustrates the architecture of LOCATEdit, a text-guided image editing pipeline.  It shows a dual-branch framework (source and target) where each branch processes the image through a U-Net.  The key innovation is the use of CASA graphs (combining cross and self-attention maps) which are regularized using a graph Laplacian to improve the spatial consistency of the attention maps.  These refined attention maps guide the editing process.  Further, an IP-Adapter is utilized for additional guidance and selective pruning is applied to text embeddings to mitigate noise and preserve crucial structural information from the original image.  The figure visually details the flow of information and the interaction between these different components during the image editing process.", "section": "4. LOCATEdit"}, {"figure_path": "https://arxiv.org/html/2503.21541/extracted/6315178/images/convex_objective_visualization.png", "caption": "Figure 4: CASA (Cross and Self-Attention) Graph Construction workflow. The initial cross-attention maps are upsampled to form a patch-level adjacency graph, then Laplacian regularization enforces spatial consistency. Thresholding the refined maps yields final, more robust attention masks.", "description": "This figure illustrates the process of constructing a CASA (Cross and Self-Attention) graph, which enhances spatial consistency in cross-attention maps. First, initial cross-attention maps are upsampled to create a higher-resolution representation.  These upsampled maps are then used to form a patch-level adjacency graph, where each patch represents a node, and the connections between patches are weighted based on self-attention relationships. Laplacian regularization is then applied to this graph to smooth the attention values across the image, ensuring spatial coherence. Finally, the refined cross-attention maps are thresholded to generate more robust attention masks, which are more precise for image editing tasks.", "section": "4.3 Formulating CASA Graph"}, {"figure_path": "https://arxiv.org/html/2503.21541/extracted/6315178/images/masks-2.png", "caption": "Figure 5: Illustration of the convex objective J\u2062(m)\ud835\udc3dmJ(\\textbf{m})italic_J ( m ) in a 2D slice of the higher-dimensional space. The single global minimum, marked in red, highlights the function\u2019s convex nature.", "description": "The figure displays a 2D cross-section of the convex objective function J(m), which is used in optimizing the saliency maps in the LOCATEdit model. The plot shows that the function has a single global minimum (marked in red), clearly indicating its convex nature. This convexity guarantees that the optimization process will converge to the unique optimal solution, which represents the refined saliency maps that are spatially consistent and precise. The x and y axes represent the values of the saliency map m in the two dimensions being visualized, and the z-axis represents the value of the objective function J(m).", "section": "4.4 Graph Laplacian Regularization"}]