{"references": [{"fullname_first_author": "Guo", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-12", "reason": "This paper is important because it introduces the DeepSeek-R1 model and demonstrates the effectiveness of rule-based RL in enhancing reasoning capabilities in LLMs, which is a key concept the current paper builds upon."}, {"fullname_first_author": "Hong", "paper_title": "Cogagent: A visual language model for gui agents", "publication_date": "2024-01-01", "reason": "The CogAgent model is a significant baseline for GUI agents, representing a key approach using MLLMs for device control, task completion, and GUI understanding, making it a core reference for this domain."}, {"fullname_first_author": "Qin", "paper_title": "Ui-tars: Pioneering automated gui interaction with native agents", "publication_date": "2025-01-12", "reason": "UI-TARs presents a comprehensive approach by combining GUI-related pretraining with task-wise reasoning fine-tuning, showing a direction in aligning models with the intricacies of GUI interactions and motivating the need for alternative approaches like rule-based RL."}, {"fullname_first_author": "Wu", "paper_title": "Os-atlas: A foundation action model for generalist gui agents", "publication_date": "2024-10-23", "reason": "OS-Atlas represents a foundation action model for GUI agents, contributing to the landscape of existing approaches that the current paper aims to improve upon through reinforcement learning."}, {"fullname_first_author": "Shao", "paper_title": "Proximal Policy Optimization Algorithms", "publication_date": "2017-07-17", "reason": "This reference introduces the Group Relative Policy Optimization (GRPO) algorithm, which the current work uses as a foundation for RL training."}]}