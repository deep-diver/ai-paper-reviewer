{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This is a seminal work introducing Latent Diffusion Models, a crucial method upon which Lumina-Image 2.0, and most text-to-image generation models, are based."}, {"fullname_first_author": "William S Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2022-01-01", "reason": "It is one of the foundational works describing diffusion transformers, an architectural approach that is the core of Lumina-Image 2.0."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP (Contrastive Language-Image Pre-training) is a fundamental concept used for encoding both image and text, often used in text-to-image generative models and mentioned in this paper."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces the T5 transformer architecture, which is used as the text encoder, and used as an important baseline model in text-to-image models."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2021-01-01", "reason": "This study presents a technique, CFG (classifier-free guidance), to improve the quality of generated samples from diffusion models by better aligning them with input prompts."}]}