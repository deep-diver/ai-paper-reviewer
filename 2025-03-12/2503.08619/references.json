{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-01", "reason": "This paper is important because it details the GPT-4 model, which is used to generate high-quality captions for the LightGen training data."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-01-01", "reason": "This paper is important because the interpolated positional embeddings used in LightGen are inspired by DINOv2."}, {"fullname_first_author": "Lijie Fan", "paper_title": "Scaling autoregressive text-to-image generative models with continuous tokens", "publication_date": "2025-01-01", "reason": "This paper is important because LightGen builds upon the Fluid architecture described in this work as a base model."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat GANs on image synthesis", "publication_date": "2021-01-01", "reason": "This paper is important because it shows diffusion models performing better than GANs in image synthesis which has had a significant impact on the field."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper is important because it presents Stable Diffusion, a model that LightGen is compared against."}]}