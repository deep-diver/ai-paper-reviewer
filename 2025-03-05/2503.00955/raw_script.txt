[{"Alex": "Hey everyone, and welcome to the podcast! Today, we're diving headfirst into the wild world of AI fact-checking, Vietnamese style! We're tackling misinformation, LLMs, and a super cool system called SemViQA. Buckle up, it's gonna be a fun ride!", "Jamie": "Vietnamese AI fact-checking? Sounds specific! I'm Jamie, by the way. So, Alex, what exactly is SemViQA, and why should we care about fact-checking in Vietnamese?"}, {"Alex": "Great question, Jamie! SemViQA is basically a new AI system designed to automatically check if claims made in Vietnamese are true or false. It's important because, just like everywhere else, misinformation spreads rapidly online in Vietnam. And because Vietnamese is a 'low-resource' language, it doesn't have as many AI tools to help combat fake news compared to, say, English.", "Jamie": "Hmm, 'low-resource,' got it. So, existing methods aren\u2019t cutting it?"}, {"Alex": "Exactly! Existing systems often struggle with the nuances of Vietnamese \u2013 things like semantic ambiguity, homonyms (words that sound alike but mean different things), and complex sentence structures. They often trade accuracy for speed, which isn\u2019t ideal when you're trying to debunk false information.", "Jamie": "Okay, makes sense. So how does SemViQA do it differently?"}, {"Alex": "SemViQA uses a two-pronged approach. First, it uses Semantic-based Evidence Retrieval (SER) to find relevant information that could support or refute the claim. Then, it uses Two-step Verdict Classification (TVC) to make a final decision on whether the claim is true, false, or if there\u2019s not enough information.", "Jamie": "So it's like a detective, finding clues and then making a judgment. Tell me more about this SER \u2013 Semantic-based Evidence Retrieval. Sounds fancy!"}, {"Alex": "It is pretty neat! SER is actually a hybrid system. It uses both a traditional method called TF-IDF, which is fast for simple cases, and a more advanced component called a Question Answering Token Classifier, or QATC. QATC is used for more complex claims that require a deeper understanding of the context.", "Jamie": "Ah, so it's smart enough to know when to bring out the big guns! And what about the TVC, the Two-step Verdict Classification?"}, {"Alex": "TVC is all about making sure the classification is as accurate as possible. It first determines if a claim is supported, refuted, or if there's not enough information. Then, for the tricky cases, it refines its decision to avoid misclassification.", "Jamie": "A safety net for complex cases, I like it. What kind of results are we talking about? Did SemViQA actually work?"}, {"Alex": "It did! SemViQA achieved state-of-the-art results on two large Vietnamese fact-checking datasets, ISE-DSC01 and ViWikiFC. It secured first place in the UIT Data Science Challenge, achieving almost 80% strict accuracy on one of the datasets.", "Jamie": "Wow, that's impressive! So, it\u2019s not just theoretically cool; it actually performs in the real world. You mentioned something called SemViQA Faster earlier. What's that all about?"}, {"Alex": "SemViQA Faster is an optimized version of the system designed for speed. It improves the inference speed by seven times while maintaining competitive accuracy. Basically, it's the same core system, but tuned for faster performance without sacrificing too much accuracy.", "Jamie": "Seven times faster?! That\u2019s a game-changer. How did they manage that?"}, {"Alex": "The secret sauce involves processing multiple parts of a claim at once in a batch, enabling efficient batch inference. Think of it like assembling a car. The original SemViQA assembles all individual parts of one car sequentially. SemViQA Faster works with assembling all subparts of multiple cars and assembles them in parallel to gain throughput.", "Jamie": "Umm, clever! So, it's not just about being accurate, it's also about being practical. What were some of the biggest challenges they faced when building SemViQA?"}, {"Alex": "One major hurdle was the token limit of existing Vietnamese language models. These models can only process a limited number of words at a time, which is a problem for long and complex claims. That is why they implemented the whole system.", "Jamie": "Right, that makes sense, particularly for low resource language like Vietnamese where they cannot just expect new models being readily available. So how did SemViQA specifically deal with handling all those long claims, that may be way more than 512 tokens?"}, {"Alex": "To tackle this, they developed a specialized preprocessing pipeline to efficiently handle long-token sequences. The pipeline is designed to preserve the semantic integrity of the claims while optimizing tokenization for downstream processing. That means they didn't just chop up the claims randomly; they made sure the meaning was still clear to the AI.", "Jamie": "Ah, so preserving meaning while shrinking the size. Makes sense. Did they have to create special tools for Vietnamese or were they able to use things that already existed?"}, {"Alex": "They used a mix of existing and custom tools. For example, they used a tool called ViTokenizer for noise removal and tokenization. But they also developed their own strategies for enriching contextual information, especially for short or incomplete sentences.", "Jamie": "So a bit of both \u2013 adapting existing tech and creating new stuff where needed. I'm curious, what about the data they used to train SemViQA? Where did that come from?"}, {"Alex": "They primarily used two datasets: ISE-DSC01, which was used in a Vietnamese AI challenge, and ViWikiFC, which features over 20,000 claims from Wikipedia. ViWikiFC is particularly useful because it explicitly includes examples where there's not enough information to verify a claim, which is important for real-world applications.", "Jamie": "Sounds like they covered their bases with the data. So, given all this, what are some limitations of SemViQA?"}, {"Alex": "While SemViQA performs well, it still has limitations. For example, it relies on TF-IDF for initial evidence retrieval, which can miss deeper semantic relationships. Also, the Two-step Verdict Classification increases inference time compared to single-step approaches.", "Jamie": "So, there's still room for improvement. Hmm, where do you see this research heading in the future?"}, {"Alex": "The future of Vietnamese fact-checking, and SemViQA's role in it, is all about refining retrieval mechanisms and classification strategies. The goal is to enhance efficiency, robustness, and broader applicability in real-world scenarios. Adaptive data driven retreival strategies are something that can be explore.", "Jamie": "Interesting, sounds like there will be a SemViQA 2.0."}, {"Alex": "Exactly. Also this approach to fact checking may inspire other low resource languages to adopt SemViQA or similar architectures.", "Jamie": "Hmm that could definitely lead to interesting results, in languages where digital traces of information is limited. So this could be a starting point for them to establish that baseline."}, {"Alex": "Indeed, and these areas are not just limited to identifying disinformation.", "Jamie": "Ah interesting, what else could be improved?"}, {"Alex": "The team would probably explore the retrieval mechanisms. While the threshold based system is good, there may be better ways to achieve higher semantic extraction.", "Jamie": "All sounds good to me."}, {"Alex": "And the team would need to do the analysis, especially for low resource languages where a lot of work needs to be done.", "Jamie": "Yes of course. So given all of this conversation about the paper, are there any exciting news or findings?"}, {"Alex": "The exciting news for the NLP community is that SemViQA sets a new benchmark for Vietnamese fact verification. It also shows that it is possible to achieve both high accuracy and speed in low-resource languages, which is crucial for combating misinformation. The next steps involve refining the system to address its limitations and expanding its applicability to other real-world scenarios, or inspiring a next generation architecture for low resource language settings. With the current rise of misinformation and LLM systems, that makes it even more important to adopt these technologies!", "Jamie": "Well, Alex, this has been incredibly insightful! Thanks for breaking down the complexities of SemViQA and its potential impact. It's fascinating to see how AI is being used to tackle misinformation in different languages and contexts."}]