{"references": [{"fullname_first_author": "Willi Menapace", "paper_title": "Snap video: Scaled spatiotemporal transformers for text-to-video synthesis", "publication_date": "2024-01-01", "reason": "This paper describes the Snap Video architecture which is the based upon architecture in this work."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable Diffusion Models with Transformers", "publication_date": "2023-01-01", "reason": "This paper details the DiT architecture, used in the main method."}, {"fullname_first_author": "Edward J. Hu", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "publication_date": "2021-06-01", "reason": "This paper describes the LoRA method, which is key to this work's approach to efficient fine-tuning."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-01-01", "reason": "This paper describes a method for personalizing text-to-image diffusion models, an approach which the current paper seeks to extend to video."}, {"fullname_first_author": "Lijun Yu", "paper_title": "Language Model Beats Diffusion - Tokenizer is key to visual generation", "publication_date": "2024-01-01", "reason": "This paper describes the MAGVITv2 architecture, which is used as the autoencoder architecture in this work."}]}