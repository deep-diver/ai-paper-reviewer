<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-21s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/</link><description>Recent content in 2025-02-21s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 20 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/index.xml" rel="self" type="application/rss+xml"/><item><title>AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14669/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14669/</guid><description>AlphaMaze enhances LLMs&amp;rsquo; spatial intelligence via GRPO, achieving 93% accuracy in maze navigation and showing emergent reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14669/cover.png"/></item><item><title>Discovering highly efficient low-weight quantum error-correcting codes with reinforcement learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14372/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14372/</guid><description>RL optimizes quantum error-correcting codes, slashing physical qubit overhead for fault-tolerant quantum computing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14372/cover.png"/></item><item><title>Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14258/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14258/</guid><description>LLMs have &amp;lsquo;Temporal Heads&amp;rsquo; that process time-specific facts!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14258/cover.png"/></item><item><title>Dynamic Concepts Personalization from Single Videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14844/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14844/</guid><description>Personalizing video models for dynamic concepts is now achievable with Set-and-Sequence: enabling high-fidelity generation, editing, and composition!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14844/cover.png"/></item><item><title>How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14502/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14502/</guid><description>Packing new knowledge into LoRA adapters can harm LLMs! A delicate balance is needed to prevent performance decline.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14502/cover.png"/></item><item><title>LLM-based User Profile Management for Recommender System</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14541/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14541/</guid><description>PURE: LLM-driven user profile management boosts recommendation by harnessing user reviews for personalized insights while tackling token limits. PURE enhances LLMs for better recommendations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14541/cover.png"/></item><item><title>Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14768/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14768/</guid><description>Logic-RL unlocks LLM reasoning via rule-based reinforcement learning, generalizing to math problems after training on logic puzzles.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14768/cover.png"/></item><item><title>MLGym: A New Framework and Benchmark for Advancing AI Research Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14499/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14499/</guid><description>MLGYM: A new framework &amp;amp; benchmark to advance AI Research Agents</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14499/cover.png"/></item><item><title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14282/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14282/</guid><description>PC-Agent: A new hierarchical framework that significantly improves complex task automation on PCs by 32%!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14282/cover.png"/></item><item><title>RelaCtrl: Relevance-Guided Efficient Control for Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14377/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14377/</guid><description>RelaCtrl: Relevance-guided control boosts diffusion transformer efficiency, cutting parameters by intelligently allocating resources.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14377/cover.png"/></item><item><title>S*: Test Time Scaling for Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14382/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14382/</guid><description>S*: Hybrid test-time scaling for code generation, boosting both coverage and selection accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14382/cover.png"/></item><item><title>Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14846/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14846/</guid><description>CoSyn: Code-guided synth data for scaling text-rich image understanding, achieving SOTA via targeted multimodal data generation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14846/cover.png"/></item><item><title>SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14786/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14786/</guid><description>SigLIP 2: Multilingual Vision-Language Encoders with Semantic Understanding, Localization, and Dense Features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14786/cover.png"/></item><item><title>Unstructured Evidence Attribution for Long Context Query Focused Summarization</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14409/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14409/</guid><description>LLMs struggle with positional bias and lack transparency when summarizing long contexts. This paper introduces SUnsET dataset and fine-tuning methods to improve unstructured evidence citation and summ&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.14409/cover.png"/></item><item><title>Geolocation with Real Human Gameplay Data: A Large-Scale Dataset and Human-Like Reasoning Framework</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.13759/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.13759/</guid><description>New geolocation dataset &amp;amp; reasoning framework enhance accuracy and interpretability by leveraging human gameplay data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.13759/cover.png"/></item><item><title>How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12769/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12769/</guid><description>Multilingual LLMs Hallucinate! This study measures hallucination across 30 languages.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12769/cover.png"/></item><item><title>S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12853/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12853/</guid><description>S2R: Teaches LLMs to self-verify and self-correct, boosting reasoning with efficient reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-21/2502.12853/cover.png"/></item></channel></rss>