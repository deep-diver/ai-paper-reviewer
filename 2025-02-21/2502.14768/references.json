{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This paper is highly influential as it introduces the chain-of-thought prompting technique, a crucial method for improving reasoning in large language models, referenced for its importance in breaking down problems into manageable steps and enhancing logical reasoning."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-01", "reason": "This paper directly inspires the current work, exploring rule-based RL for reasoning, and is therefore a key reference for its approach to incentivizing reasoning capabilities in LLMs through reinforcement learning."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-01-01", "reason": "This paper is foundational for reinforcement learning, as the PPO algorithm is a standard technique used in the field and is used as a comparison in this work."}, {"fullname_first_author": "Chulin Xie", "paper_title": "On memorization of large language models in logical reasoning", "publication_date": "2024-01-01", "reason": "This paper provides the methodology used to analyse the memorization of large language models, and is thus highly relevant to the current work because it allows them to compare memorization to generalization."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering chess and shogi by self-play with a general reinforcement learning algorithm", "publication_date": "2017-01-01", "reason": "This paper is a landmark work demonstrating the power of reinforcement learning, and provides a basis for improving reasoning in LLMs by introducing tree based search."}]}