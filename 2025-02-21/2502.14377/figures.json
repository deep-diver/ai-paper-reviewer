[{"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/intro_fidandhdd.jpg", "caption": "Figure 1: Effect of skipping a specific position within the ControlNet block on the quality of the generated image. Higher FID and HDD indicate a more significant impact of the skipped layer on the quality of the final results, reflecting a stronger correlation with the generated image quality.", "description": "This figure shows the impact of removing individual ControlNet blocks on the quality of generated images.  The x-axis represents the index of the ControlNet block, while the y-axis shows FID (Fr\u00e9chet Inception Distance) and HDD (Hausdorff Distance) scores.  Higher FID and HDD values indicate a greater negative impact on image quality and faithfulness to the control input, revealing a stronger correlation between that specific block and the final image generation.  In essence, this plot visualizes the relevance of each ControlNet block to the overall quality and control effectiveness.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/method_importance.png", "caption": "Figure 2: The relevance diagram of different layers in the DiT-ControlNet was calculated based on the FID and HDD ranks. The overall trend shows an initial increase followed by a decrease. The selected placement positions of RelaCtrl in PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1 are marked with white numbers.", "description": "Figure 2 illustrates the relevance scores of different layers within the DiT-ControlNet architecture.  These scores were computed using a combination of FID (Fr\u00e9chet Inception Distance) and HDD (Hausdorff Distance) ranks, which measure image quality and control accuracy, respectively.  A lower rank indicates higher quality or better control.  The graph plots the relevance score for each layer, revealing a pattern of increasing relevance in the initial layers followed by a decline in deeper layers.  The white numbers in the figure highlight the layers selected for RelaCtrl's control mechanism in the PixArt-\u03b1 model. This demonstrates that RelaCtrl strategically integrates control only into the most relevant layers, thereby increasing efficiency and reducing unnecessary computation.", "section": "2.1. DiT-ControlNet Relevance Prior"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/method_arch.png", "caption": "Figure 3: The overall architecture of RelaCtrl. Control block locations are prioritized based on the ControlNet Relevance Score, ranked from highest to lowest. The direct duplication of the main branch in the original ControlNet is replaced with the carefully designed Reference-Guided Lightweight control block. Additionally, the Two-Dimensional Shuffle Mixer effectively reduces model parameters and computational overhead while preserving performance.", "description": "Figure 3 illustrates RelaCtrl's architecture, which improves upon previous methods by prioritizing control block placement based on a relevance score.  Instead of directly copying blocks from the main branch (as in prior ControlNet implementations), RelaCtrl uses a 'Relevance-Guided Lightweight Control Block' for efficiency.  The figure highlights the use of a Two-Dimensional Shuffle Mixer (TDSM) within the control blocks. The TDSM replaces the computationally expensive self-attention and feed-forward network (FFN) layers in each control block, resulting in a reduced parameter count and computational overhead while maintaining performance.", "section": "2. Methods"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/exp_compare.jpg", "caption": "Figure 4: Qualitative comparison of different methods. Please zoom in for better details.", "description": "This figure shows a qualitative comparison of different image generation models' performance on various control tasks. Each row represents a different image generation task with a text prompt, while each column displays the results of a different model.  The models included are UniControl, Uni-ControlNet, ControlNet-XS, ControlNext, PixArt-8, and RelaCtrl.  The images visually demonstrate the quality, control accuracy, and overall fidelity achieved by each model for each task. Zooming in allows for detailed comparison of the generated images.", "section": "3.2. Compared with SOTA methods"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/exp_visual.jpg", "caption": "Figure 5: Generation effects of RelaCtrl under varying control conditions.", "description": "This figure shows several examples of images generated using the RelaCtrl model under different control conditions.  Each row represents a different image generation task, with the control condition specified in text to the left of the corresponding images. The images generated with RelaCtrl exhibit various styles and features consistent with the provided control conditions. This demonstrates the model's ability to produce high-quality and controlled images with a wide range of creative directions.", "section": "3. Experiment"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/appendix_full_image1.png", "caption": "Figure 6: Impact of deleting specific locations on the generated metrics in ControlNet with 27 and 13 blocks.", "description": "This figure shows the impact of removing individual control blocks from the ControlNet architecture on the quality and control fidelity of generated images.  Two separate experiments are shown: one with a ControlNet consisting of 27 blocks and another with 13 blocks. For each experiment, the FID (Fr\u00e9chet Inception Distance) and HDD (Hausdorff Distance) scores are plotted against the index of the removed control block. The plots illustrate the relative importance of different control blocks for both image generation quality and effectiveness of control. The results highlight that the effects of removing a block vary across the model, with some blocks showing a more significant impact than others.", "section": "3.4 Ablation study"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/appendix_remove3.jpg", "caption": "Figure 7: Additional visual results of skipping specific ControlNet layers (7, 9, and 27), correspond to the highest, moderate, and lowest impact on the generated image.", "description": "This figure shows additional examples illustrating the impact of removing different ControlNet layers on image generation quality.  Specifically, it presents qualitative results for three scenarios: removing layer 7 (highest impact), layer 9 (moderate impact), and layer 27 (lowest impact). By comparing the generated images across these scenarios, the visualization emphasizes the varying degrees of influence that each layer exerts on both the generation quality and the accuracy of control.", "section": "3.4. Ablation study"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/appendix_flux.png", "caption": "Figure 8: Visual comparison of different control methods on Flux.1-dev.", "description": "This figure shows a comparison of image generation results from three different methods: OminiControl, ControlNet, and RelaCtrl.  Each method is applied to the Flux.1-dev model, demonstrating their respective capabilities in controlling the image generation process based on a given condition. The images show that each method produces different levels of control, with RelaCtrl achieving a better balance between high-quality generation and efficiency.", "section": "3. Experiment"}, {"figure_path": "https://arxiv.org/html/2502.14377/extracted/6219154/images/appendix_style.jpg", "caption": "Figure 9: The control effect of RelaCtrl on the fine-tuned PixArt model. The upper and lower rows show the four transitions: (1) Canny to paint, (2) Depth to oil, (3) HED to gufeng, and (4) Segmentation to pixel.", "description": "This figure showcases the results of applying the RelaCtrl method to a fine-tuned PixArt model.  The images demonstrate the model's ability to effectively translate different control inputs into various artistic styles. Four image transformation examples are presented:  (1) A Canny edge detection input transformed into a painting style, (2) Depth information translated into an oil painting style, (3) HED edge detection transformed into a \"gufeng\" (Chinese classical painting) style, and (4) A segmentation map resulting in a pixel art style image.  Each row illustrates the input and output for a single transition, highlighting RelaCtrl's capacity for diverse style transfer under different controlled conditions.", "section": "D.3. Inference with Community Models"}]