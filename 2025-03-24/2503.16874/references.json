{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-15", "reason": "This paper details the technical specifications of GPT-4, a foundational large language model that the current work builds upon."}, {"fullname_first_author": "Mirac Suzgun", "paper_title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them", "publication_date": "2022-10-22", "reason": "This paper introduces the BIG-Bench benchmark, which is used in the current work to evaluate the performance of the proposed model across various general tasks."}, {"fullname_first_author": "Chengrun Yang", "paper_title": "Large Language Models as Optimizers", "publication_date": "2024-05-07", "reason": "This paper discusses the use of large language models as optimizers, an approach related to the current work's method of automated prompt optimization."}, {"fullname_first_author": "Fangzhi Xu", "paper_title": "Symbol-LLM: Towards Foundational Symbol-Centric Interface for Large Language Models", "publication_date": "2024-06-11", "reason": "This paper proposes an interface for LLMs, which provides information on the tasks and datasets relevant to the research."}, {"fullname_first_author": "Yubo Wang", "paper_title": "MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark", "publication_date": "2024-06-03", "reason": "This paper introduces MMLU-Pro, a challenging multi-task benchmark used in the current work to evaluate the model's performance in general language understanding."}]}