{"references": [{"fullname_first_author": "Johnson, J.", "paper_title": "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning", "publication_date": "2017-00-00", "reason": "This paper introduced a benchmark dataset for visual reasoning, which is highly relevant to the current paper's focus on evaluating large multimodal models' visual reasoning capabilities."}, {"fullname_first_author": "Kojima, T.", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-00-00", "reason": "This paper demonstrated the zero-shot reasoning capabilities of large language models, which is a key concept in the context of evaluating large multimodal models' reasoning abilities."}, {"fullname_first_author": "Ramakrishnan, S. K.", "paper_title": "Does spatial cognition emerge in frontier models?", "publication_date": "2024-00-00", "reason": "This paper investigated the spatial reasoning capabilities of large language models, providing valuable insights into the limitations of current models and informing the design of challenging benchmarks."}, {"fullname_first_author": "Rahmanzadehgervi, P.", "paper_title": "Vision language models are blind", "publication_date": "2024-00-00", "reason": "This study highlighted the visual interpretation shortcomings of large multimodal models, which is a central theme of the current paper's benchmark."}, {"fullname_first_author": "Roberts, J.", "paper_title": "GRAB: A Challenging Graph Analysis Benchmark for Large Multimodal Models", "publication_date": "2024-00-00", "reason": "This paper presented a benchmark dataset focused on graph reasoning, which is relevant to the current paper's broader goal of developing challenging benchmarks for multimodal models."}]}