[{"figure_path": "https://arxiv.org/html/2503.13360/x1.png", "caption": "Figure 1: The visual forgetting phenomenon by removing the image at different reasoning stages. It shows that by the midpoint of the reasoning process, the model becomes less dependent on the image, causing text-over-relied outputs.", "description": "This figure illustrates the concept of \"visual forgetting\" in multimodal LLMs. The experiment involves interrupting the reasoning process at various stages (indicated by the x-axis, \"Cutoff Position of Reasoning Tokens\"), removing the image input, and then letting the model continue the reasoning using only the text generated so far. The y-axis shows the accuracy of the model's completion of the reasoning process.  The blue line (\"Normal Reasoning\") represents the accuracy when the image is available throughout; the orange line (\"Cutoff Image Reasoning\") represents accuracy when the image is removed at various points. The small difference in accuracy between the two lines, especially as the cutoff position approaches the midpoint, demonstrates that the model increasingly relies on the generated text rather than the original image as reasoning progresses. This shift in reliance, where visual information is neglected, is termed \"visual forgetting\".", "section": "2. Capturing the Visual Forgetting"}, {"figure_path": "https://arxiv.org/html/2503.13360/x2.png", "caption": "Figure 2: Illustration of layer-level and token-level attention weights. (a) The layer-level attention weights of image tokens across different response token positions. (b) The token-level attention weights at the middle layer. It shows that the model\u2019s attention to the image gradually decreases during the reasoning process.", "description": "Figure 2 visualizes the model's attention mechanism over the course of a multi-step reasoning process. Panel (a) displays the layer-level attention weights given to image tokens at various stages of the response generation. It demonstrates a clear trend: as the response progresses, the model's focus on visual information diminishes. Panel (b) provides a detailed view of the token-level attention weights at a specific middle layer, further illustrating the gradual decrease in attention toward image tokens as the reasoning process unfolds. This figure directly supports the paper's claim that models experience 'visual forgetting' during extended reasoning tasks, losing track of visual details in favor of the generated textual context.", "section": "2.1. Capturing the Visual Forgetting"}, {"figure_path": "https://arxiv.org/html/2503.13360/x3.png", "caption": "Figure 3: Overview of TVC System Design. We enable the model to have take-along visual conditioning capabilities through two stages: training and inference.", "description": "The figure illustrates the Take-along Visual Conditioning (TVC) system's design, detailing its two-stage process.  The training stage involves a Dynamic Visual Reaffirmation (DVR) method that strategically reinjects visual information at intervals during the reasoning process to maintain visual attention. The inference stage utilizes a Periodic Visual Calibration (PVC) mechanism that periodically re-introduces visual inputs, incorporating image compression to prevent information overload.  The overall system design allows the model to retain and re-engage with visual information throughout the reasoning chain, thereby mitigating the effect of 'visual forgetting'.", "section": "2. Take-along Visual Conditioning: Sustaining Visual Evidence for Multi-modal Long CoT Reasoning"}, {"figure_path": "https://arxiv.org/html/2503.13360/x4.png", "caption": "Figure 4: Data Generation Pipeline of TVC. We use iterative distillation to collect long-chain reasoning data, followed by a comprehensive response filtering process to ensure high-quality reasoning.", "description": "This figure illustrates the process of creating a high-quality dataset for training the Take-along Visual Conditioning (TVC) model.  It begins with an iterative distillation method where a teacher model generates long-chain reasoning data. This data then undergoes a multi-stage filtering process.  The filtering process includes several steps to eliminate low-quality responses, ensure data consistency and improve the efficiency of the reasoning process. The steps are: (1) Deterministic Initial Sampling using a temperature of 0 to get highly confident results; (2) Answer-Centric Reject Sampling where an LLM is used to validate answers and filter out incorrect ones; (3) Best-of-N Error Correction to recover potential errors in data; and finally (4) filtering for length and removal of reflection words to ensure reasoning quality and remove redundancy.  The end result is a refined dataset that greatly enhances the TVC model's performance.", "section": "3. Data-Centric Implementation of Multimodal Reasoning System"}, {"figure_path": "https://arxiv.org/html/2503.13360/x5.png", "caption": "Figure 5: Ablations on the amount of training data. TVC benefits from data scaling, continually improving the reasoning capabilities.", "description": "This figure shows the impact of varying amounts of training data on the performance of the Take-along Visual Conditioning (TVC) model.  The x-axis represents the amount of training data used (in thousands), and the y-axis represents the relative performance of the model compared to a baseline. As the amount of training data increases, the relative performance of the TVC model consistently improves, demonstrating its ability to benefit from and leverage larger datasets for improved reasoning capabilities.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.13360/x6.png", "caption": "Figure 6: Case Study of TVC. TVC effectively re-examines the image during the reflection process to correct mistakes, guiding the model to the correct answer.", "description": "This figure shows a case study comparing the reasoning process of a base model (without Take-along Visual Conditioning or TVC) and the TVC model. The task is a visual question answering problem involving identifying which cube in a set does not match a given unfolded net. The base model incorrectly identifies the answer due to neglecting certain object attributes when reasoning from the image.  In contrast, the TVC model uses dynamic visual reaffirmation.  This means that during the reasoning process, the model pauses and revisits the image, allowing it to re-focus on essential details and correct the initial error, leading to the correct answer. The attention weights at the token level are also displayed to illustrate this refocusing behavior.", "section": "4.5. Case Study"}, {"figure_path": "https://arxiv.org/html/2503.13360/x7.png", "caption": "Figure 7: The token and reflection word distribution of the long-chain reasoning dataset.", "description": "This figure shows two histograms visualizing the distribution of token counts and reflection word counts within a dataset used for long-chain reasoning.  The left histogram displays the distribution of token counts, revealing that most reasoning chains have a moderate number of tokens, while a smaller number of chains have significantly more tokens.  This indicates the dataset contains both concise and more elaborate reasoning chains. The right histogram displays the distribution of reflection word counts, a metric relating to the frequency with which a model's reasoning process involves revisiting prior steps or considering alternative paths.  A concentration in the lower counts suggests that most reasoning chains involve a limited amount of self-reflection. This implies that most reasoning chains proceeded in a relatively linear fashion, with only some involving repeated or iterative considerations.", "section": "B. More Details of Reasoning Dataset"}, {"figure_path": "https://arxiv.org/html/2503.13360/x8.png", "caption": "Figure 8: Qualitative Results of TVC.", "description": "Figure 8 shows a qualitative example illustrating how Take-along Visual Conditioning (TVC) improves the reasoning process.  The task involves identifying which cube doesn't match a given unfolded net.  The base CoT reasoning method makes an incorrect conclusion due to a lack of attention to details. The TVC method, however, demonstrates a step-by-step reasoning process that correctly identifies the mismatched cube by explicitly revisiting and analyzing the visual information, highlighting the benefits of TVC in maintaining visual attention during complex reasoning tasks.", "section": "4.5. Case Study"}]