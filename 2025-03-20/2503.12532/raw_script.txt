[{"Alex": "Hey everyone, welcome to the podcast! Today we're diving into some seriously cool tech \u2013 AI agents that can actually USE computers like we do! Forget just writing code, these bots are clicking, typing, and navigating Windows. We\u2019re unpacking a groundbreaking new method called STEVE, which is basically like giving AI a super-powered tutor for mastering computer tasks.", "Jamie": "Whoa, that sounds intense! So, these aren't just like... chatbots? They\u2019re actually controlling a computer?"}, {"Alex": "Exactly! Think of it as teaching a robot to use a computer the way YOU would. Opening files, browsing the web, even using specific applications. It\u2019s a huge leap towards true AI automation, and it's all thanks to clever training techniques. We have designed STEVE, a step verification pipeline for computer-use agent training.", "Jamie": "Okay, I'm intrigued. Where does the name STEVE even come from?"}, {"Alex": "STEVE is named as 'A Step Verification Pipeline', Jamie. This step verification pipeline is designed for computer-use agent training. Imagine teaching a child, you have to teach them every step to get to the overall achievement. The purpose of STEVE is like that, step-by-step verification.", "Jamie": "A step-by-step verification pipeline. I see, so how is this different from how AI agents are usually trained?"}, {"Alex": "Great question. Normally, training these AI agents requires tons of expertly annotated data, basically showing the AI exactly what to do at every single moment. That's super expensive and time-consuming. STEVE changes that.", "Jamie": "Hmm, so it's about making the training process more efficient? How does it achieve that?"}, {"Alex": "That's right. The key is a clever verification process. Instead of relying solely on perfect examples, STEVE uses a powerful AI \u2013 like GPT-40 \u2013 to judge whether each action the agent takes is correct, based on the screen before and after the action.", "Jamie": "So, GPT-40 is like the AI teacher looking over the agent's shoulder and saying, 'Yes, good job!' or 'Nope, try again'?"}, {"Alex": "Precisely! And this is where it gets interesting. STEVE doesn't just use the 'good job!' signals. It ALSO learns from the 'try again' moments. It leverages something called Kahneman & Tversky Optimization, or KTO, to learn from both positive AND negative actions.", "Jamie": "Umm, so even when the AI messes up, it's still a learning opportunity? That\u2019s kinda cool."}, {"Alex": "Totally! In the past, SFT (supervised finetuning) agents were trained using only positive data. However, it is inefficient as it neglects the negative samples, which in fact can also contribute.", "Jamie": "Hmm, that makes sense. So, what kind of impact does using STEVE have on the performance of these AI agents?"}, {"Alex": "A significant one! The research shows that agents trained with STEVE outperform those trained with traditional supervised finetuning. They\u2019re better at completing tasks and more efficient in their computer use. They have achieved leading performance in the challenging live desktop environment WinAgentArena, with great efficiency at a reduced cost.", "Jamie": "Wow, so not only is it cheaper to train them, but they're actually better at doing the job? What tasks are we talking about here?"}, {"Alex": "Think of everyday computer tasks: managing files, browsing the web, using office applications. The WinAgentArena benchmark, which the researchers used, includes a wide range of tasks across different domains.", "Jamie": "Okay, that gives me a better picture. So, this STEVE method allows them to train agents that can handle various tasks."}, {"Alex": "That\u2019s the point, Jamie. The key contributions are a more powerful GUI-grounding VLM, the scalable step verification pipeline STEVE, and KTO optimization to utilize both the positive and negative actions. STEVE effectively leverages both positive and negative samples in the trajectory data and avoids degrading the agent's UI localization ability.", "Jamie": "Alright, before we move on, what is a GUI-grounding VLM? It sounds like tech jargon to me."}, {"Alex": "GUI-grounding VLM stands for Graphical User Interface grounding Vision Language Model. A mouthful, I know! Essentially, it\u2019s an AI model that's really good at understanding and identifying elements on a computer screen \u2013 buttons, icons, text fields, and so on \u2013 and linking them to instructions.", "Jamie": "Ah, so it's like the agent's eyes and brain combined, helping it 'see' and understand what's on the screen. Got it! So, what are the next steps for this research?"}, {"Alex": "That's right! Well, the researchers have already achieved state-of-the-art results in several UI localization benchmarks. They\u2019re planning to explore how STEVE can be used to train agents that can handle even more complex tasks and adapt to different desktop environments.", "Jamie": "Hmm, different environments... like, switching between Windows and macOS?"}, {"Alex": "Potentially! That\u2019s a longer-term goal. But for now, the focus is on improving the robustness and generalizability of these agents within the Windows environment. Also, there is a potential to develop a multi-modal agent combining with other functions to boost computer-use abilities.", "Jamie": "That sounds like a huge undertaking! What were some of the challenges they faced while working on this project?"}, {"Alex": "A big challenge was preventing the agent from degrading UI localization. When models are finetuned on agent data, they can lose their sense of UI localization capabilities.", "Jamie": "UI localization... so it is kind of like forgetting how to see all of a sudden?"}, {"Alex": "Exactly. So, the step-by-step verification has been incorporated to take both negative and positive feedback into account. By taking both into account, the computer will eventually learn to see better.", "Jamie": "That's pretty interesting."}, {"Alex": "It really is. So, to quickly summarize the conversation, and the findings of the research paper. The team recognized recent advances in vision language models and designed STEVE, a step verification pipeline for computer-use agent training. The research is all about building AI agents that can use computers like humans and uses a step-by-step model to ensure the AI can see and perform as expected.", "Jamie": "Thanks for walking us through the paper. But one quick question before you go, is the name STEVE at all inspired by the late Steve Jobs? Did he use the computer well?"}, {"Alex": "Haha. That's a really great question. But no, STEVE is named as 'A Step Verification Pipeline'. It would be interesting to have named the agent Steve Jobs though... Someone needs to build that.", "Jamie": "Alright, maybe in the next iteration! Thanks!"}, {"Alex": "Haha. Thanks, Jamie!", "Jamie": "This was very cool. Hopefully we'll see it being applied more."}, {"Alex": "Thank you, Jamie! I hope so too!", "Jamie": "I learned a lot!"}, {"Alex": "And that's a wrap for today's episode! We've unpacked a really fascinating new approach to training AI agents for computer use. The potential for increased automation and efficiency is huge. The STEVE pipeline shows that AI can scale and adapt to perform daily tasks! This is going to open up lots of doors!", "Jamie": "Totally! Thanks for having me."}]