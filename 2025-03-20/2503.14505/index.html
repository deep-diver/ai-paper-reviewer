<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>MusicInfuser: Making Video Diffusion Listen and Dance &#183; HF Daily Paper Reviews by AI</title>
<meta name=title content="MusicInfuser: Making Video Diffusion Listen and Dance &#183; HF Daily Paper Reviews by AI"><meta name=description content="Sync your moves! MusicInfuser adapts video diffusion to make models listen and dance to music, preserving style and aligning movement."><meta name=keywords content="Multimodal Learning,Multimodal Generation,üè¢ University of Washington,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/"><meta property="og:site_name" content="HF Daily Paper Reviews by AI"><meta property="og:title" content="MusicInfuser: Making Video Diffusion Listen and Dance"><meta property="og:description" content="Sync your moves! MusicInfuser adapts video diffusion to make models listen and dance to music, preserving style and aligning movement."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="2025-03-20"><meta property="article:published_time" content="2025-03-18T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-18T00:00:00+00:00"><meta property="article:tag" content="Multimodal Learning"><meta property="article:tag" content="Multimodal Generation"><meta property="article:tag" content="üè¢ University of Washington"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/cover.png"><meta name=twitter:title content="MusicInfuser: Making Video Diffusion Listen and Dance"><meta name=twitter:description content="Sync your moves! MusicInfuser adapts video diffusion to make models listen and dance to music, preserving style and aligning movement."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"2025-03-20s","name":"MusicInfuser: Making Video Diffusion Listen and Dance","headline":"MusicInfuser: Making Video Diffusion Listen and Dance","abstract":"Sync your moves! MusicInfuser adapts video diffusion to make models listen and dance to music, preserving style and aligning movement.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/2025-03-20\/2503.14505\/","author":{"@type":"Person","name":"Hugging Face Daily Papers"},"copyrightYear":"2025","dateCreated":"2025-03-18T00:00:00\u002b00:00","datePublished":"2025-03-18T00:00:00\u002b00:00","dateModified":"2025-03-18T00:00:00\u002b00:00","keywords":["Multimodal Learning","Multimodal Generation","üè¢ University of Washington"],"mainEntityOfPage":"true","wordCount":"4650"}]</script><meta name=author content="Hugging Face Daily Papers"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">HF Daily Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><a href=/ai-paper-reviewer/2025-03-19/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-19</p></a><a href=/ai-paper-reviewer/2025-03-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-20</p></a><a href=/ai-paper-reviewer/2025-03-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>2025-03-21</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-19/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-19</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-20/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-20</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/2025-03-21/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>2025-03-21</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/2025-03-20/2503.14505/cover_hu3348709374243227242.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>HF Daily Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/2025-03-20/>2025-03-20s</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/2025-03-20/2503.14505/>MusicInfuser: Making Video Diffusion Listen and Dance</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">MusicInfuser: Making Video Diffusion Listen and Dance</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-03-18T00:00:00+00:00>18 March 2025</time><span class="px-2 text-primary-500">&#183;</span><span>4650 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">22 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_2025-03-20/2503.14505/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_2025-03-20/2503.14505/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">ü§ó Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/multimodal-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Multimodal Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/multimodal-generation/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Multimodal Generation
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-university-of-washington/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ University of Washington</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Hugging Face Daily Papers" src=/ai-paper-reviewer/img/avatar_hu1570846118988919414.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Hugging Face Daily Papers</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers on HF Daily Papers</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#music-aligned-t2v>Music-Aligned T2V</a></li><li><a href=#zica-for-fidelity>ZICA for Fidelity</a></li><li><a href=#hr-lora-for-motion>HR-LoRA for Motion</a></li><li><a href=#video-llm-eval>Video-LLM Eval</a></li><li><a href=#wild-data-robust>Wild Data Robust.</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#music-aligned-t2v>Music-Aligned T2V</a></li><li><a href=#zica-for-fidelity>ZICA for Fidelity</a></li><li><a href=#hr-lora-for-motion>HR-LoRA for Motion</a></li><li><a href=#video-llm-eval>Video-LLM Eval</a></li><li><a href=#wild-data-robust>Wild Data Robust.</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2503.14505</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Susung Hong et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>ü§ó 2025-03-20</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2503.14505 target=_self role=button>‚Üó arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2503.14505 target=_self role=button>‚Üó Hugging Face</a></p><audio controls><source src=https://ai-paper-reviewer.com/2503.14505/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Generating synchronized video and audio has been a difficult task, requiring larger and more complex models. The generation of dance movements from music is challenging due to the need to simultaneously consider multiple aspects, like style and beat. Current methods depend on motion capture data which is resource-intensive. To resolve this, the paper introduces MusicInfuser.</p><p>MusicInfuser adapts pre-trained text-to-video models to condition on music tracks using music-video cross-attention and a low-rank adapter. This method generates videos synchronized with the input music, with styles and appearances controllable via text prompts. MusicInfuser preserves the rich knowledge in the text modality, enabling various forms of control, while also introducing an evaluation framework using Video-LLMs.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-fa758e0676f2508402961cf743d93fa0></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-fa758e0676f2508402961cf743d93fa0",{strings:[" MusicInfuser adapts pre-trained text-to-video models to generate dance videos synchronized to music. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-d24949b5c79df3b96c4cfb18ac0b26ff></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-d24949b5c79df3b96c4cfb18ac0b26ff",{strings:[" The method uses music-video cross-attention and a low-rank adapter and only fine-tunes on dance videos. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-2fb3900a272672b0a4b4a8c3116dba18></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-2fb3900a272672b0a4b4a8c3116dba18",{strings:[" An evaluation framework using Video-LLMs assesses dance generation quality. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper introduces MusicInfuser, a method to generate synchronized dance videos, offering a promising direction for AI-driven content creation. <strong>It leverages existing diffusion models, enhancing their capabilities without extensive retraining</strong>, and opens avenues for further exploration in AI-assisted choreography.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x2.png alt></figure></p><blockquote><p>üîº MusicInfuser modifies pre-trained video diffusion models to generate dance videos synchronized with music. It does this by adding a lightweight cross-attention module and a low-rank adapter that aligns the model&rsquo;s output to the rhythm and style of the music input. The figure shows four examples of generated dance videos, each conditioned on a specific text prompt and a music track. Note that the movement may appear slower than in the actual videos due to the frame rate used to create the figure.</p><details><summary>read the caption</summary>Figure 1: MusicInfuser adapts video diffusion models to music, making them listen and dance according to the music. This adaptation is done in a prior-preserving manner, enabling it to also accept style through the prompt while aligning the movement to the music. Please refer to the project page videos, as the movement appears slower due to the frame sampling rate.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=S4.T1.2><thead class=ltx_thead><tr class=ltx_tr id=S4.T1.2.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S4.T1.2.1.1.1 rowspan=2><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.1.1 style=font-size:70%>Model</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.2 rowspan=2><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.2.1 style=font-size:70%>Modality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.3><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.3.1 style=font-size:70%>Style</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.4><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.4.1 style=font-size:70%>Beat</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.5><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.5.1 style=font-size:70%>Body</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.6><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.6.1 style=font-size:70%>Movement</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.7><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.7.1 style=font-size:70%>Choreography</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S4.T1.2.1.1.8><span class="ltx_text ltx_font_bold" id=S4.T1.2.1.1.8.1 style=font-size:70%>Dance Quality</span></th></tr><tr class=ltx_tr id=S4.T1.2.2.2><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.1><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.1.1 style=font-size:70%>Alignment</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.2><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.2.1 style=font-size:70%>Alignment</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.3><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.3.1 style=font-size:70%>Representation</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.4><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.4.1 style=font-size:70%>Realism</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.5><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.5.1 style=font-size:70%>Complexity</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S4.T1.2.2.2.6><span class="ltx_text ltx_font_bold" id=S4.T1.2.2.2.6.1 style=font-size:70%>Average</span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S4.T1.2.3.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S4.T1.2.3.1.1><span class=ltx_text id=S4.T1.2.3.1.1.1 style=font-size:70%;color:gray>AIST Dataset (GT)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib46 title><span class=ltx_text style=font-size:90%>46</span></a>]</cite></span></th><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.2><span class=ltx_text id=S4.T1.2.3.1.2.1 style=font-size:70%;color:gray>A+V</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.3><span class=ltx_text id=S4.T1.2.3.1.3.1 style=font-size:70%;color:gray>7.46</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.4><span class=ltx_text id=S4.T1.2.3.1.4.1 style=font-size:70%;color:gray>8.95</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.5><span class=ltx_text id=S4.T1.2.3.1.5.1 style=font-size:70%;color:gray>7.53</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.6><span class=ltx_text id=S4.T1.2.3.1.6.1 style=font-size:70%;color:gray>8.67</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.7><span class=ltx_text id=S4.T1.2.3.1.7.1 style=font-size:70%;color:gray>7.45</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S4.T1.2.3.1.8><span class=ltx_text id=S4.T1.2.3.1.8.1 style=font-size:70%;color:gray>8.01</span></td></tr><tr class=ltx_tr id=S4.T1.2.4.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S4.T1.2.4.2.1><span class=ltx_text id=S4.T1.2.4.2.1.1 style=font-size:70%>MM-Diffusion¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class=ltx_text id=S4.T1.2.4.2.1.2.1 style=font-size:70%>[</span><a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib39 title><span class=ltx_text style=font-size:90%>39</span></a><span class=ltx_text id=S4.T1.2.4.2.1.3.2 style=font-size:70%>]</span></cite></th><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.2><span class=ltx_text id=S4.T1.2.4.2.2.1 style=font-size:70%>A+V</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.3><span class=ltx_text id=S4.T1.2.4.2.3.1 style=font-size:70%>7.16</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.4><span class=ltx_text id=S4.T1.2.4.2.4.1 style=font-size:70%>8.56</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.5><span class=ltx_text id=S4.T1.2.4.2.5.1 style=font-size:70%>5.52</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.6><span class=ltx_text id=S4.T1.2.4.2.6.1 style=font-size:70%>7.05</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.7><span class=ltx_text id=S4.T1.2.4.2.7.1 style=font-size:70%>7.53</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.4.2.8><span class=ltx_text id=S4.T1.2.4.2.8.1 style=font-size:70%>7.16</span></td></tr><tr class=ltx_tr id=S4.T1.2.5.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S4.T1.2.5.3.1><span class=ltx_text id=S4.T1.2.5.3.1.1 style=font-size:70%>Mochi¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class=ltx_text id=S4.T1.2.5.3.1.2.1 style=font-size:70%>[</span><a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib44 title><span class=ltx_text style=font-size:90%>44</span></a><span class=ltx_text id=S4.T1.2.5.3.1.3.2 style=font-size:70%>]</span></cite></th><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.2><span class=ltx_text id=S4.T1.2.5.3.2.1 style=font-size:70%>T+V</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.3><span class=ltx_text id=S4.T1.2.5.3.3.1 style=font-size:70%>7.20</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.4><span class=ltx_text id=S4.T1.2.5.3.4.1 style=font-size:70%>8.34</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.5><span class="ltx_text ltx_font_bold" id=S4.T1.2.5.3.5.1 style=font-size:70%>7.47</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.6><span class=ltx_text id=S4.T1.2.5.3.6.1 style=font-size:70%>7.68</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.7><span class=ltx_text id=S4.T1.2.5.3.7.1 style=font-size:70%>7.82</span></td><td class="ltx_td ltx_align_center" id=S4.T1.2.5.3.8><span class=ltx_text id=S4.T1.2.5.3.8.1 style=font-size:70%>7.70</span></td></tr><tr class=ltx_tr id=S4.T1.2.6.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S4.T1.2.6.4.1><span class=ltx_text id=S4.T1.2.6.4.1.1 style=font-size:70%>MusicInfuser (Ours)</span></th><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.2><span class=ltx_text id=S4.T1.2.6.4.2.1 style=font-size:70%>T+A+V</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.3><span class="ltx_text ltx_font_bold" id=S4.T1.2.6.4.3.1 style=font-size:70%>7.56</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.4><span class="ltx_text ltx_font_bold" id=S4.T1.2.6.4.4.1 style=font-size:70%>8.89</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.5><span class=ltx_text id=S4.T1.2.6.4.5.1 style=font-size:70%>7.16</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.6><span class="ltx_text ltx_font_bold" id=S4.T1.2.6.4.6.1 style=font-size:70%>8.24</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.7><span class="ltx_text ltx_font_bold" id=S4.T1.2.6.4.7.1 style=font-size:70%>7.90</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S4.T1.2.6.4.8><span class="ltx_text ltx_font_bold" id=S4.T1.2.6.4.8.1 style=font-size:70%>7.95</span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a quantitative comparison of the dance generation quality produced by different models: MusicInfuser (the proposed model), MM-Diffusion, and Mochi. The quality is assessed across six key aspects: style alignment, beat alignment, body representation, movement realism, choreography complexity, and an overall dance quality score. Each metric is scored on a scale, and for models using text input (MusicInfuser and Mochi), an average score across a predefined set of prompts is reported, allowing for a more comprehensive evaluation of performance.</p><details><summary>read the caption</summary>Table 1: Dance quality metrics comparing different models. A, V, and T denote audio, video, and text input modalities, respectively. For the models that have text input modality, we report an average of scores using a predefined benchmark of prompts.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Music-Aligned T2V<div id=music-aligned-t2v class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#music-aligned-t2v aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;Music-Aligned T2V&rsquo; (Text-to-Video) focuses on generating videos where the visual content is synchronized with and responsive to a given music track. This involves more than just adding background music; it requires the AI model to understand the <strong>nuances of the music</strong>, such as its rhythm, tempo, and emotional tone, and translate these into corresponding visual movements and actions within the generated video. A key challenge is ensuring the generated motion isn&rsquo;t simply random but meaningfully related to the audio, creating a cohesive and aesthetically pleasing experience. This can be achieved through techniques like incorporating cross-modal attention mechanisms, which allow the model to learn correlations between audio features and visual elements. The ultimate goal is to enable users to create compelling and engaging video content that seamlessly integrates music and visuals, opening up new possibilities for artistic expression and creative applications in fields like music visualization, dance performance, and interactive media.</p><h4 class="relative group">ZICA for Fidelity<div id=zica-for-fidelity class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#zica-for-fidelity aria-label=Anchor>#</a></span></h4><p><strong>Zero-Initialized Cross-Attention (ZICA)</strong> likely aims to preserve the fidelity of a generative model when incorporating a new modality (e.g., audio). By initializing the cross-attention weights to zero, the model initially ignores the audio input, ensuring it continues to generate images or videos consistent with its pre-trained knowledge. This prevents abrupt changes in the output structure and style. As training progresses, the cross-attention weights gradually increase, allowing the audio to influence the generation process in a controlled manner. This approach helps to maintain the core visual structure and stylistic elements the model already knows how to produce, then gently nudge it using musical cues. A balanced method to adapt to new modalities, preserving a rich style!</p><h4 class="relative group">HR-LoRA for Motion<div id=hr-lora-for-motion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hr-lora-for-motion aria-label=Anchor>#</a></span></h4><p><strong>HR-LoRA</strong> which stands for Higher Rank Low-Rank Adaptation aims to adapt the attention weights for diffusion transformer blocks. The adapter serves two key purposes: (1) to effectively integrate audio features into the text-video processing pipeline, and (2) to shift the domain toward our target application, synthesizing clear choreography. To effectively model motion adaptation separately from spatial adaptation, the optimal rank for the linear map is increased compared to what is needed for static images. For adapting video tokens, a higher rank is required compared to image tokens, since video tokens contain temporal information.</p><h4 class="relative group">Video-LLM Eval<div id=video-llm-eval class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#video-llm-eval aria-label=Anchor>#</a></span></h4><p>Regarding &ldquo;Video-LLM Eval,&rdquo; my thoughts center on the crucial role of Video Large Language Models (LLMs) in evaluating video generation quality. <strong>Traditional metrics often fail</strong> to capture nuanced aspects like motion realism, style adherence, and synchronization in dance videos. Video-LLMs offer a promising avenue by leveraging their ability to understand both visual content and natural language. A Video-LLM evaluation framework could assess multiple dimensions of dance quality, video quality, and prompt alignment. <strong>Challenges include designing effective prompts</strong> for the Video-LLM and ensuring its evaluation aligns with human perception. <strong>Training or fine-tuning the Video-LLM</strong> specifically for evaluating dance videos might be necessary. The framework should also consider the <strong>inherent subjectivity</strong> in evaluating creative content. Addressing these challenges could lead to a more comprehensive and reliable assessment of dance video generation, pushing the boundaries of automated evaluation in multimodal AI.</p><h4 class="relative group">Wild Data Robust.<div id=wild-data-robust class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#wild-data-robust aria-label=Anchor>#</a></span></h4><p>Considering the idea of a &ldquo;Wild Data Robust&rdquo; heading, it suggests a focus on <strong>model performance and generalization in real-world, uncontrolled environments.</strong> Research in this area would likely explore techniques to make systems resilient to the noise, variability, and biases inherent in uncurated data. Key aspects would involve <strong>data augmentation strategies to simulate diverse conditions</strong>, <strong>robust loss functions that down-weight outliers</strong>, and <strong>domain adaptation methods to transfer knowledge from labeled to unlabeled or weakly labeled wild datasets.</strong> Evaluating robustness would necessitate benchmarks that accurately reflect the challenges of real-world deployment, focusing on metrics beyond average performance to capture worst-case scenarios and fairness across different subgroups. Investigations might involve leveraging self-supervised learning or continual learning paradigms to enable models to adapt and improve over time as they encounter new and evolving wild data distributions, making them more reliable and less prone to failure in unpredictable settings. A primary goal is to bridge the gap between idealized training conditions and the complexities of real-world applications, improving the practical utility of AI systems.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/extracted/6289646/fig/long.png alt></figure></p><blockquote><p>üîº Figure 2 demonstrates the model&rsquo;s ability to generate group dance videos. The key is leveraging the model&rsquo;s existing knowledge of dance and text, and modifying only the prompt. By changing the word &lsquo;[DANCERS]&rsquo; in the prompt &lsquo;&rsquo;[DANCERS] dancing in a studio with a white backdrop, captured from a front view&rsquo; to specify the number of dancers (e.g., &lsquo;a male and female dancer&rsquo;, &lsquo;multiple dancers&rsquo;, &lsquo;a group of dancers&rsquo;), the model generates corresponding videos with the correct number of dancers performing synchronized choreography.</p><details><summary>read the caption</summary>Figure 2: Due to the conservation of knowledge in video and text modalities, our model generalizes to generate group dance videos by modulating the prompt. To show this, the prompt is set to ‚Äú[DANCERS] dancing in a studio with a white backdrop, captured from a front view,‚Äù where [DANCERS] denotes the description for each number of dancers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x3.png alt></figure></p><blockquote><p>üîº This figure demonstrates the model&rsquo;s ability to generate longer dance videos (twice the length of training videos) using unseen music. Each row shows a different video generated using synthetic K-pop music (a genre not present in the AIST dataset) and the prompt &lsquo;a professional dancer dancing K-pop&mldr;&rsquo;. The consistent synchronization between the dance moves and music beat, along with stylistic consistency, highlights the model&rsquo;s generalizability and robustness to new, unseen music.</p><details><summary>read the caption</summary>Figure 3: We generate longer dance videos that are 2 times longer than the videos used for training. For each row, we use synthetic in-the-wild music tracks with a keyword ‚ÄúK-pop,‚Äù a type of music not existing in AIST¬†[46], and use a prompt ‚Äúa professional dancer dancing K-pop ‚Ä¶.‚Äù This shows our method is highly generalizable, even extending to longer videos with an unheard cateory of the music. The beat and style alignment can be more clearly observed in the videos on the project page.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x4.png alt></figure></p><blockquote><p>üîº MusicInfuser&rsquo;s architecture modifies a pretrained text-to-video diffusion model to incorporate music. It does so by adding two types of adapter networks: Zero-Initialized Cross-attention (ZICA) blocks and High-Rank LoRA (HR-LoRA) blocks. ZICA blocks introduce music information using cross-attention, while HR-LoRA blocks adapt the attention weights within the diffusion model&rsquo;s transformer layers. The placement of the ZICA blocks is strategically determined to balance the impact on different aspects of the generated video while minimizing computational cost, using a layer adaptability strategy described in section 4.6. The diagram visually depicts the flow of information (text, audio, and video) through these components, indicating which blocks are trainable and showing the overall process of music-conditioned video generation.</p><details><summary>read the caption</summary>Figure 4: Overall architecture of MusicInfuser. Our framework adapts a pre-trained diffusion model with audio embedding using ZICA blocks (Sec. 4.1) and HR-LoRA blocks (Sec. 4.2). The placement of ZICA blocks is selected based on layer adaptability (Sec. 4.6).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x5.png alt></figure></p><blockquote><p>üîº Figure 5 compares the dance videos generated by MusicInfuser and MM-Diffusion [39], a prior state-of-the-art method. The figure uses three music tracks as input. For each track, both methods generate dance videos. The first and third rows show that MusicInfuser produces fewer artifacts compared to MM-Diffusion. The first row demonstrates that MusicInfuser generates videos with more realistic and natural movements. The second and third rows highlight the more dynamic motion produced by MusicInfuser. Note that the same music track was used for each row, but the spectrogram is stretched for MM-Diffusion because MusicInfuser generates longer videos than MM-Diffusion. For MusicInfuser, the prompt &lsquo;a professional dancer dancing&mldr;&rsquo; was consistently used for all music tracks.</p><details><summary>read the caption</summary>Figure 5: Comparison of audio-driven generation with MM-Diffusion¬†[39]. Our method produces fewer artifacts (shown in the first and third rows), while generating more realistic dance videos with more natural movements (first row) and more dynamic motion (second and third rows). Note that we use the same music track for each row, and the spectrogram is stretched for MM-Diffusion since we generate longer videos. For our method, we use the fixed caption ‚Äúa professional dancer dancing ‚Ä¶‚Äù across all music tracks.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x6.png alt></figure></p><blockquote><p>üîº Figure 6 demonstrates the impact of altering the speed of the input audio on the generated dance video. The top row shows the dance when the audio is slowed down by a factor of 0.75, the middle row shows the original-speed dance, and the bottom row shows the dance when the audio is sped up by a factor of 1.25. The figure illustrates that increasing the audio speed leads to a greater number of movements in the generated dance and also changes the overall dynamic intensity and tone of the resulting dance.</p><details><summary>read the caption</summary>Figure 6: Speed control. The audio input is slowed down (the top row) or sped up (the bottom row) by 0.75 times and 1.25 times, respectively. This shows that speeding up generally results in more movements. Also see the change in the dynamicity, as speeding up the audio also increases the tone of the music.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x7.png alt></figure></p><blockquote><p>üîº Figure 7 showcases the model&rsquo;s ability to generalize to unseen music styles. Three distinct dance videos are generated, each synchronized to a different &lsquo;K-pop&rsquo; music track created using SUNO AI. The &lsquo;K-pop&rsquo; genre was not present in the training data, demonstrating the model&rsquo;s ability to adapt and generate appropriate choreography for new musical styles.</p><details><summary>read the caption</summary>Figure 7: Videos generated with three distinct in-the-wild music tracks created with SUNO AI. For each row, we use in-the-wild music tracks generated with a word ‚ÄúK-pop,‚Äù an unseen category.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/extracted/6289646/fig/beta_uniform.png alt></figure></p><blockquote><p>üîº Figure 8 showcases the diversity achievable by MusicInfuser. Using the same music track and the text prompt ‚Äúa professional dancer dancing‚Ä¶‚Äù, altering only the random seed results in several unique dance sequences. Each generated dance video features a distinct choreography, demonstrating the model‚Äôs capacity to produce varied creative outputs from the same inputs.</p><details><summary>read the caption</summary>Figure 8: By changing the seed, our method can produce diverse results given the same music and text. The generated choreography of each dance is different from each other. We use the fixed prompt ‚Äúa professional dancer dancing ‚Ä¶.‚Äù</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x8.png alt></figure></p><blockquote><p>üîº This figure shows a set of curves representing beta distributions with varying parameters. The x-axis represents the values of the beta distribution, and the y-axis shows the probability density. Each curve corresponds to a different beta distribution, with the parameter Œ≤ changing from 3.0 to 1.0 in increments. The curves illustrate how the shape of the beta distribution changes with the parameter Œ≤, going from a distribution concentrated near 0 to a uniform distribution as Œ≤ approaches 1. This visualization helps to understand the Beta-Uniform scheduling strategy used in the MusicInfuser model, where the noise distribution is gradually transitioned from a Beta distribution to a uniform distribution during the training process.</p><details><summary>read the caption</summary>Figure 9: Beta distributions.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x9.png alt></figure></p><blockquote><p>üîº This figure demonstrates how the model&rsquo;s generated choreography changes in complexity based on the prompt used. The top row showcases basic dance movements generated with a simple prompt. The middle row shows increased complexity with a more specific style and setting. The bottom row displays the most complex choreography, generated by a detailed and descriptive prompt. This illustrates the model&rsquo;s ability to control the level of detail and sophistication in the generated dance sequences via textual prompts.</p><details><summary>read the caption</summary>Figure 10: Changes in the complexity of choreography.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x10.png alt></figure></p><blockquote><p>üîº This figure compares the results of generating dance videos using two different methods: MusicInfuser and Mochi. MusicInfuser, the authors&rsquo; proposed method, uses the Mochi text-to-video model as a base but adds audio conditioning through their cross-attention mechanism. The figure showcases two examples where each method is prompted to generate a video of a dancer in a specific setting, based on the provided text. The comparisons in this figure highlight how MusicInfuser is able to generate videos that better adhere to the prompt and have higher levels of overall consistency and realism compared to the base Mochi model. Specifically, the authors point out that frames 2 and 5 in the top example, and frames 2-4 in the bottom example, most clearly illustrate this improvement in adherence and quality.</p><details><summary>read the caption</summary>Figure 11: MusicInfuser infuses listening capability into the text-to-video model (Mochi¬†[44]), while preserving the prompt adherence and improving overall consistency and realism (frames 2 and 5 of the top example, and frames 2‚Äì4 of the bottom example).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x11.png alt></figure></p><blockquote><p>üîº Figure 12 presents an ablation study comparing different model variations of MusicInfuser. All results use the same music track, random seed, and text prompt: &lsquo;a male dancer dancing in an art gallery with some paintings, captured from a front view&rsquo;. This allows a clear visual comparison of how each component (ZICA layer selection, Beta-Uniform scheduling, higher-rank LoRA, standard LoRA, and the addition of raw audio features) affects the generated dance video. Differences in dance quality, style adherence, and movement smoothness are easily observable.</p><details><summary>read the caption</summary>Figure 12: Ablation study. The prompt is set to ‚Äúa male dancer dancing in an art gallery with some paintings, captured from a front view‚Äù. The seed and music are set the same across all methods.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x12.png alt></figure></p><blockquote><p>üîº This ablation study visualizes the impact of different components of the MusicInfuser model on dance video generation. The experiment uses a consistent prompt (&lsquo;a male dancer wearing a suit dancing in the middle of a New York City, captured from a front view&rsquo;), music track, and random seed across all model variations. Each row shows the results for a specific model variant: the full MusicInfuser model, a model without the zero-initialized cross-attention layer selection, a model without the beta-uniform scheduling, a model without higher-rank LoRA, a model without LoRA, and a model using feature addition instead of the ZICA adapter. The generated video sequences allow for a visual comparison of how each model component affects the final dance generated.</p><details><summary>read the caption</summary>Figure 13: Ablation study. The prompt is set to ‚Äúa male dancer wearing a suit dancing in the middle of a New York City, captured from a front view‚Äù. The seed and music are set the same across all methods.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x13.png alt></figure></p><blockquote><p>üîº This figure displays a graph showing the layer adaptability results from the paper [26]. It specifically illustrates how the imaging and aesthetic quality change across different layers of the model. This information is crucial for determining the optimal layer selection strategy within a video generation model.</p><details><summary>read the caption</summary>Figure 14: Layer adaptability graph from [26], showing imaging and aesthetic quality.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/extracted/6289646/fig/failure.png alt></figure></p><blockquote><p>üîº This figure showcases three example videos generated by the MusicInfuser model, each synchronized to a different music track sourced from the internet. This demonstrates the model&rsquo;s capability to generalize to unseen music styles and maintain high-quality dance generation.</p><details><summary>read the caption</summary>Figure 15: Videos generated with three distinct in-the-wild music tracks.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2503.14505/x14.png alt></figure></p><blockquote><p>üîº Figure 16 shows examples where the MusicInfuser model fails to generate high-fidelity details, such as fingers and facial features. These failures are inherited from limitations in the underlying base model. Additionally, the model demonstrates a susceptibility to errors caused by focusing primarily on the silhouette of the dancers rather than precise details of their pose and movement. In essence, the model struggles with generating fine-grained details and can be misled by overall body shape.</p><details><summary>read the caption</summary>Figure 16: Failure cases. Our model inherits some issues from the base model, such as failing to generate fine details (e.g., fingers and faces) and being fooled by the silhouette of the dancers.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T2.2.1><thead class=ltx_thead><tr class=ltx_tr id=S5.T2.2.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id=S5.T2.2.1.1.1.1 rowspan=2><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.1.1>Model</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.1.1.1.2 rowspan=2><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.2.1>Modality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.1.1.1.3><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.3.1>Imaging</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.1.1.1.4><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.4.1>Aesthetic</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.1.1.1.5><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.5.1>Overall</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T2.2.1.1.1.6><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.1.1.6.1>Video Quality</span></th></tr><tr class=ltx_tr id=S5.T2.2.1.2.2><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T2.2.1.2.2.1><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.2.2.1.1>Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T2.2.1.2.2.2><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.2.2.2.1>Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T2.2.1.2.2.3><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.2.2.3.1>Consistency</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T2.2.1.2.2.4><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.2.2.4.1>Average</span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T2.2.1.3.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T2.2.1.3.1.1><span class=ltx_text id=S5.T2.2.1.3.1.1.1 style=color:gray>AIST Dataset (GT)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib46 title><span class=ltx_text style=font-size:90%>46</span></a>]</cite></span></th><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T2.2.1.3.1.2><span class=ltx_text id=S5.T2.2.1.3.1.2.1 style=color:gray>A+V</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T2.2.1.3.1.3><span class=ltx_text id=S5.T2.2.1.3.1.3.1 style=color:gray>9.76</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T2.2.1.3.1.4><span class=ltx_text id=S5.T2.2.1.3.1.4.1 style=color:gray>8.17</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T2.2.1.3.1.5><span class=ltx_text id=S5.T2.2.1.3.1.5.1 style=color:gray>9.77</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T2.2.1.3.1.6><span class=ltx_text id=S5.T2.2.1.3.1.6.1 style=color:gray>9.23</span></td></tr><tr class=ltx_tr id=S5.T2.2.1.4.2><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T2.2.1.4.2.1>MM-Diffusion¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib39 title><span class=ltx_text style=font-size:90%>39</span></a>]</cite></th><td class="ltx_td ltx_align_center" id=S5.T2.2.1.4.2.2>A+V</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.4.2.3>8.94</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.4.2.4>6.52</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.4.2.5>8.38</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.4.2.6>7.94</td></tr><tr class=ltx_tr id=S5.T2.2.1.5.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T2.2.1.5.3.1>Mochi¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib44 title><span class=ltx_text style=font-size:90%>44</span></a>]</cite></th><td class="ltx_td ltx_align_center" id=S5.T2.2.1.5.3.2>T+V</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.5.3.3>9.46</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.5.3.4><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.5.3.4.1>7.90</span></td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.5.3.5>8.98</td><td class="ltx_td ltx_align_center" id=S5.T2.2.1.5.3.6>8.78</td></tr><tr class=ltx_tr id=S5.T2.2.1.6.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T2.2.1.6.4.1>MusicInfuser (Ours)</th><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T2.2.1.6.4.2>T+A+V</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T2.2.1.6.4.3><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.6.4.3.1>9.60</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T2.2.1.6.4.4>7.87</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T2.2.1.6.4.5><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.6.4.5.1>9.39</span></td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T2.2.1.6.4.6><span class="ltx_text ltx_font_bold" id=S5.T2.2.1.6.4.6.1>8.95</span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a quantitative comparison of video quality across four different models: the ground truth (GT) from the AIST dataset, MM-Diffusion, Mochi, and the proposed MusicInfuser method. The metrics used to evaluate video quality are: imaging quality, aesthetic quality, overall consistency, and average video quality. The AIST dataset ground truth provides a baseline for comparison. For models that utilize text input (Mochi and MusicInfuser), the scores represent an average derived from a standardized set of prompts, ensuring fair comparison.</p><details><summary>read the caption</summary>Table 2: Video quality metrics comparing different models. For the models that have text input modality, we report an average of scores using a predefined benchmark of prompts.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T3.2.1><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T3.2.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id=S5.T3.2.1.1.1.1 rowspan=2><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.1.1.1.1>Model</span></th><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.2.1.1.1.2><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.1.1.2.1>Style</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.2.1.1.1.3><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.1.1.3.1>Creative</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.2.1.1.1.4><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.1.1.4.1>Overall</span></td><td class="ltx_td ltx_align_center ltx_border_tt" id=S5.T3.2.1.1.1.5><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.1.1.5.1>Prompt Align</span></td></tr><tr class=ltx_tr id=S5.T3.2.1.2.2><td class="ltx_td ltx_align_center" id=S5.T3.2.1.2.2.1><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.2.2.1.1>Capture</span></td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.2.2.2><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.2.2.2.1>Interpretation</span></td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.2.2.3><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.2.2.3.1>Satisfaction</span></td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.2.2.4><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.2.2.4.1>Average</span></td></tr><tr class=ltx_tr id=S5.T3.2.1.3.3><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T3.2.1.3.3.1>Mochi¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class=ltx_ref href=https://arxiv.org/html/2503.14505v1#bib.bib44 title><span class=ltx_text style=font-size:90%>44</span></a>]</cite></th><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.3.3.2><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.3.3.2.1>7.98</span></td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.3.3.3>9.04</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.3.3.4>9.55</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.3.3.5>8.86</td></tr><tr class=ltx_tr id=S5.T3.2.1.4.4><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.2.1.4.4.1>MusicInfuser (Ours)</th><td class="ltx_td ltx_align_center" id=S5.T3.2.1.4.4.2>7.80</td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.4.4.3><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.4.4.3.1>9.27</span></td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.4.4.4><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.4.4.4.1>9.80</span></td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.4.4.5><span class="ltx_text ltx_font_bold" id=S5.T3.2.1.4.4.5.1>8.96</span></td></tr><tr class=ltx_tr id=S5.T3.2.1.5.5><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id=S5.T3.2.1.5.5.1>No in-the-Wild Data</th><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.5.5.2>6.80</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.5.5.3>8.69</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.5.5.4>8.40</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T3.2.1.5.5.5>7.96</td></tr><tr class=ltx_tr id=S5.T3.2.1.6.6><th class="ltx_td ltx_align_left ltx_th ltx_th_row" id=S5.T3.2.1.6.6.1>Base Prompt 0%</th><td class="ltx_td ltx_align_center" id=S5.T3.2.1.6.6.2>7.45</td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.6.6.3>8.85</td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.6.6.4>9.43</td><td class="ltx_td ltx_align_center" id=S5.T3.2.1.6.6.5>8.58</td></tr><tr class=ltx_tr id=S5.T3.2.1.7.7><th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id=S5.T3.2.1.7.7.1>Base Prompt 100%</th><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.2.1.7.7.2>7.33</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.2.1.7.7.3>9.06</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.2.1.7.7.4>9.36</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T3.2.1.7.7.5>8.58</td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a quantitative comparison of the prompt alignment capabilities of different models, including MusicInfuser, Mochi, and a baseline with no in-the-wild data. The metrics assess how well the generated videos align with various aspects of the prompts, such as style capture, creative interpretation, and overall satisfaction. It helps demonstrate MusicInfuser&rsquo;s effectiveness at generating videos that accurately reflect user-specified parameters.</p><details><summary>read the caption</summary>Table 3: Prompt alignment metrics comparing different models.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id=S5.T4.2.1><thead class=ltx_thead><tr class=ltx_tr id=S5.T4.2.1.1.1><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id=S5.T4.2.1.1.1.1 rowspan=2><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.1.1>Model</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.2><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.2.1>Style</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.3><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.3.1>Beat</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.4><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.4.1>Body</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.5><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.5.1>Movement</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.6><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.6.1>Choreography</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id=S5.T4.2.1.1.1.7><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.7.1>Dance Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.8><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.8.1>Imaging</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.9><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.9.1>Aesthetic</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.10><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.10.1>Overall</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id=S5.T4.2.1.1.1.11><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.11.1>Video Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id=S5.T4.2.1.1.1.12 rowspan=2><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.1.1.12.1>Overall</span></th></tr><tr class=ltx_tr id=S5.T4.2.1.2.2><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.1><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.1.1>Alignment</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.2><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.2.1>Alignment</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.3><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.3.1>Representation</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.4><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.4.1>Realism</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.5><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.5.1>Complexity</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id=S5.T4.2.1.2.2.6><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.6.1>Average</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.7><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.7.1>Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.8><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.8.1>Quality</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column" id=S5.T4.2.1.2.2.9><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.9.1>Consistency</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id=S5.T4.2.1.2.2.10><span class="ltx_text ltx_font_bold" id=S5.T4.2.1.2.2.10.1>Average</span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=S5.T4.2.1.3.1><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=S5.T4.2.1.3.1.1>Full</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.2>7.56</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.3>8.89</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.4>7.16</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.5>8.24</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.6>7.90</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S5.T4.2.1.3.1.7>7.95</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.8>9.60</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.9>7.87</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.10>9.39</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=S5.T4.2.1.3.1.11>8.95</td><td class="ltx_td ltx_align_center ltx_border_t" id=S5.T4.2.1.3.1.12>8.33</td></tr><tr class=ltx_tr id=S5.T4.2.1.4.2><td class="ltx_td ltx_align_left ltx_border_r" id=S5.T4.2.1.4.2.1>No ZICA Layer Selection</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.2>7.31</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.3>8.81</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.4>7.28</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.5>7.70</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.6>7.96</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.4.2.7>7.81</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.8>9.33</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.9>7.78</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.10>9.04</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.4.2.11>8.72</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.4.2.12>8.15</td></tr><tr class=ltx_tr id=S5.T4.2.1.5.3><td class="ltx_td ltx_align_left ltx_border_r" id=S5.T4.2.1.5.3.1>No Higher Rank</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.2>7.37</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.3>8.76</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.4>6.86</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.5>7.75</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.6>7.98</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.5.3.7>7.74</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.8>9.55</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.9>7.94</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.10>9.49</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.5.3.11>8.99</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.5.3.12>8.21</td></tr><tr class=ltx_tr id=S5.T4.2.1.6.4><td class="ltx_td ltx_align_left ltx_border_r" id=S5.T4.2.1.6.4.1>No LoRA</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.2>7.48</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.3>8.62</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.4>7.02</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.5>7.53</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.6>7.95</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.6.4.7>7.72</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.8>9.43</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.9>8.08</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.10>9.36</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.6.4.11>8.96</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.6.4.12>8.18</td></tr><tr class=ltx_tr id=S5.T4.2.1.7.5><td class="ltx_td ltx_align_left ltx_border_r" id=S5.T4.2.1.7.5.1>No Beta-Uniform Schedule</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.2>8.04</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.3>9.07</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.4>6.35</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.5>7.88</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.6>7.91</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.7.5.7>7.85</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.8>9.17</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.9>7.85</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.10>9.37</td><td class="ltx_td ltx_align_center ltx_border_r" id=S5.T4.2.1.7.5.11>8.80</td><td class="ltx_td ltx_align_center" id=S5.T4.2.1.7.5.12>8.21</td></tr><tr class=ltx_tr id=S5.T4.2.1.8.6><td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id=S5.T4.2.1.8.6.1>Feature Addition</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.2>7.62</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.3>8.90</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.4>6.78</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.5>7.97</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.6>7.88</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id=S5.T4.2.1.8.6.7>7.83</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.8>9.44</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.9>7.88</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.10>9.31</td><td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id=S5.T4.2.1.8.6.11>8.88</td><td class="ltx_td ltx_align_center ltx_border_bb" id=S5.T4.2.1.8.6.12>8.22</td></tr></tbody></table></table></figure><blockquote><p>üîº This ablation study analyzes the individual contributions of different components within the MusicInfuser model. It shows the impact of removing the Zero-Initialized Cross-attention (ZICA) layer selection, the Beta-Uniform scheduling, the Higher Rank (HR-LORA) adapter, and the LORA adapter itself, as well as the impact of a naive &lsquo;Feature Addition&rsquo; baseline. The &lsquo;Feature Addition&rsquo; method simply expands the audio feature spatially and adds it directly to corresponding frames, lacking the more sophisticated integration methods used in the full MusicInfuser model. The results reveal the relative importance of each component in achieving the model&rsquo;s performance in terms of style and beat alignment, body representation, movement realism, choreography complexity, and overall dance quality.</p><details><summary>read the caption</summary>Table 4: Ablation study. Feature addition denotes that we spatially expand the audio feature and add the feature to the corresponding frame.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A8.T5.2><thead class=ltx_thead><tr class=ltx_tr id=A8.T5.2.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.1.1.1><span class="ltx_text ltx_font_bold" id=A8.T5.2.1.1.1.1>Test Music Code</span></th><th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id=A8.T5.2.1.1.2><span class="ltx_text ltx_font_bold" id=A8.T5.2.1.1.2.1>Genre</span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A8.T5.2.2.1><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.2.1.1>mLH4</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.2.1.2>LA style Hip-hop</td></tr><tr class=ltx_tr id=A8.T5.2.3.2><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.3.2.1>mKR2</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.3.2.2>Krump</td></tr><tr class=ltx_tr id=A8.T5.2.4.3><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.4.3.1>mBR0</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.4.3.2>Break</td></tr><tr class=ltx_tr id=A8.T5.2.5.4><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.5.4.1>mLO2</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.5.4.2>Lock</td></tr><tr class=ltx_tr id=A8.T5.2.6.5><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.6.5.1>mJB5</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.6.5.2>Ballet Jazz</td></tr><tr class=ltx_tr id=A8.T5.2.7.6><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.7.6.1>mWA0</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.7.6.2>Waack</td></tr><tr class=ltx_tr id=A8.T5.2.8.7><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.8.7.1>mJS3</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.8.7.2>Street Jazz</td></tr><tr class=ltx_tr id=A8.T5.2.9.8><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.9.8.1>mMH3</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.9.8.2>Middle Hip-hop</td></tr><tr class=ltx_tr id=A8.T5.2.10.9><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.10.9.1>mHO5</th><td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id=A8.T5.2.10.9.2>House</td></tr><tr class=ltx_tr id=A8.T5.2.11.10><th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id=A8.T5.2.11.10.1>mPO1</th><td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id=A8.T5.2.11.10.2>Pop</td></tr></tbody></table></table></figure><blockquote><p>üîº This table lists the music tracks used for testing the MusicInfuser model. Each track is identified by a unique code and is categorized by its corresponding dance genre. This allows for evaluating the model&rsquo;s performance across various dance styles and provides context for the generated dance videos.</p><details><summary>read the caption</summary>Table 5: List of test music codes with corresponding dance genres.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A10.T6.2><thead class=ltx_thead><tr class=ltx_tr id=A10.T6.2.1.1><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.1.1.1><span class="ltx_text ltx_font_bold" id=A10.T6.2.1.1.1.1>Category</span></th><th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id=A10.T6.2.1.1.2><span class="ltx_text ltx_font_bold" id=A10.T6.2.1.1.2.1>Dataset</span></th><th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id=A10.T6.2.1.1.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.1.1.3.1><span class=ltx_p id=A10.T6.2.1.1.3.1.1 style=width:372.6pt><span class="ltx_text ltx_font_bold" id=A10.T6.2.1.1.3.1.1.1>Prompt Template</span></span></span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A10.T6.2.2.1><td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.2.1.1>Prompt Format</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=A10.T6.2.2.1.2>AIST</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T6.2.2.1.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.2.1.3.1><span class=ltx_p id=A10.T6.2.2.1.3.1.1 style=width:372.6pt>{dancers_text} dancing {genre_name} in a {situation_name} setting in a studio with a white backdrop, captured from a {camera_view}</span></span></td></tr><tr class=ltx_tr id=A10.T6.2.3.2><td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.3.2.1>Prompt Format</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=A10.T6.2.3.2.2>AIST</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T6.2.3.2.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.3.2.3.1><span class=ltx_p id=A10.T6.2.3.2.3.1.1 style=width:372.6pt>a {camera_view} video of {dancers_text} performing {genre_name} choreography against a white background in a {situation_name} scene</span></span></td></tr><tr class=ltx_tr id=A10.T6.2.4.3><td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.4.3.1>Prompt Format</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=A10.T6.2.4.3.2>AIST</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T6.2.4.3.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.4.3.3.1><span class=ltx_p id=A10.T6.2.4.3.3.1.1 style=width:372.6pt>{dancers_text} executing {genre_name} movements in a minimalist studio space in a {situation_name} setting, shot from a {camera_view}</span></span></td></tr><tr class=ltx_tr id=A10.T6.2.5.4><td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.5.4.1>Prompt Format</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=A10.T6.2.5.4.2>AIST</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T6.2.5.4.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.5.4.3.1><span class=ltx_p id=A10.T6.2.5.4.3.1.1 style=width:372.6pt>a {genre_name} dance performance by {dancers_text} in a pristine white studio, {camera_view}, {situation_name}</span></span></td></tr><tr class=ltx_tr id=A10.T6.2.6.5><td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.6.5.1>Base Prompt</td><td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id=A10.T6.2.6.5.2>AIST</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T6.2.6.5.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.6.5.3.1><span class=ltx_p id=A10.T6.2.6.5.3.1.1 style=width:372.6pt>a professional dancer dancing in a studio with a white backdrop</span></span></td></tr><tr class=ltx_tr id=A10.T6.2.7.6><td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id=A10.T6.2.7.6.1>Base Prompt</td><td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id=A10.T6.2.7.6.2>YouTube</td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id=A10.T6.2.7.6.3><span class="ltx_inline-block ltx_align_top" id=A10.T6.2.7.6.3.1><span class=ltx_p id=A10.T6.2.7.6.3.1.1 style=width:372.6pt>a dance video</span></span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents various prompt templates used to generate dance videos. It categorizes the prompts by their format (parameterized or simple) and the dataset they are associated with (AIST or YouTube). The table provides examples of prompts for different categories such as dancers, dance genre, situation, and camera view, giving a comprehensive overview of the prompt variations used in the research.</p><details><summary>read the caption</summary>Table 6: Dance prompt templates categorized by type and dataset, including parameterized formats and simple base prompts.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id=A10.T7.2><thead class=ltx_thead><tr class=ltx_tr id=A10.T7.2.1.1><th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.1.1.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.1.1.1.1><span class=ltx_p id=A10.T7.2.1.1.1.1.1 style=width:472pt><span class="ltx_text ltx_font_bold" id=A10.T7.2.1.1.1.1.1.1>Prompts</span></span></span></th></tr></thead><tbody class=ltx_tbody><tr class=ltx_tr id=A10.T7.2.2.1><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.2.1.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.2.1.1.1><span class=ltx_p id=A10.T7.2.2.1.1.1.1 style=width:472pt>a male dancer dancing on a rooftop at sunset, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.3.2><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.3.2.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.3.2.1.1><span class=ltx_p id=A10.T7.2.3.2.1.1.1 style=width:472pt>a female dancer dancing in a subway station, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.4.3><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.4.3.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.4.3.1.1><span class=ltx_p id=A10.T7.2.4.3.1.1.1 style=width:472pt>a male dancer dancing in an art gallery with some paintings, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.5.4><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.5.4.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.5.4.1.1><span class=ltx_p id=A10.T7.2.5.4.1.1.1 style=width:472pt>a female dancer wearing a leather jacket dancing in a studio with a white backdrop, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.6.5><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.6.5.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.6.5.1.1><span class=ltx_p id=A10.T7.2.6.5.1.1.1 style=width:472pt>a male dancer wearing a hoodie dancing in a studio with a white backdrop, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.7.6><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.7.6.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.7.6.1.1><span class=ltx_p id=A10.T7.2.7.6.1.1.1 style=width:472pt>a female dancer wearing a denim vest dancing in a studio with a white backdrop, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.8.7><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.8.7.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.8.7.1.1><span class=ltx_p id=A10.T7.2.8.7.1.1.1 style=width:472pt>a female dancer wearing a Hawaiian dress dancing on Waikiki Beach at sunset with Diamond Head in the background, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.9.8><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.9.8.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.9.8.1.1><span class=ltx_p id=A10.T7.2.9.8.1.1.1 style=width:472pt>a male dancer wearing a suit dancing in the middle of a New York City, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.10.9><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.10.9.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.10.9.1.1><span class=ltx_p id=A10.T7.2.10.9.1.1.1 style=width:472pt>a male dancer wearing a chef‚Äôs uniform dancing in a busy restaurant kitchen with flames from the grill behind him, captured from a front view</span></span></td></tr><tr class=ltx_tr id=A10.T7.2.11.10><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id=A10.T7.2.11.10.1><span class="ltx_inline-block ltx_align_top" id=A10.T7.2.11.10.1.1><span class=ltx_p id=A10.T7.2.11.10.1.1.1 style=width:472pt>a female dancer wearing a Renaissance gown dancing in a Venetian masquerade ball with ornate chandeliers overhead, captured from a front view</span></span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table presents a collection of prompts used to generate dance videos. Each prompt describes a specific scenario, including the dancer&rsquo;s attire, the setting, and the viewpoint. These prompts are used to evaluate the model&rsquo;s ability to generate diverse and contextually relevant dance videos.</p><details><summary>read the caption</summary>Table 7: Collection of dance scene prompts with various subjects, attire, and settings.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table class="ltx_tabular ltx_centering ltx_align_middle" id=A10.T8.2><tbody class=ltx_tbody><tr class=ltx_tr id=A10.T8.2.1.1><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.1.1.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.1.1.1.1><span class=ltx_p id=A10.T8.2.1.1.1.1.1 style=width:99.4pt><span class="ltx_text ltx_font_bold" id=A10.T8.2.1.1.1.1.1.1>Metric</span></span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.1.1.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.1.1.2.1><span class=ltx_p id=A10.T8.2.1.1.2.1.1 style=width:397.5pt><span class="ltx_text ltx_font_bold" id=A10.T8.2.1.1.2.1.1.1>Prompt</span></span></span></td></tr><tr class=ltx_tr id=A10.T8.2.2.2><td class="ltx_td ltx_align_center ltx_align_top ltx_border_l ltx_border_r ltx_border_t" colspan=2 id=A10.T8.2.2.2.1><span class="ltx_text ltx_font_bold" id=A10.T8.2.2.2.1.1>Dance Quality</span></td></tr><tr class=ltx_tr id=A10.T8.2.3.3><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.3.3.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.3.3.1.1><span class=ltx_p id=A10.T8.2.3.3.1.1.1 style=width:99.4pt>Style Alignment</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.3.3.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.3.3.2.1><span class=ltx_p id=A10.T8.2.3.3.2.1.1 style=width:397.5pt>Rate the style alignment of the dance to music where: 0 means poor style alignment of the dance to music, 5 means moderate style alignment of the dance to music, and 10 means perfect style alignment of the dance to music. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.4.4><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.4.4.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.4.4.1.1><span class=ltx_p id=A10.T8.2.4.4.1.1.1 style=width:99.4pt>Beat Alignment</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.4.4.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.4.4.2.1><span class=ltx_p id=A10.T8.2.4.4.2.1.1 style=width:397.5pt>Rate the beat alignment of the dance to music where: 0 means poor beat alignment of the dance to music, 5 means moderate beat alignment of the dance to music, and 10 means perfect beat alignment of the dance to music. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.5.5><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.5.5.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.5.5.1.1><span class=ltx_p id=A10.T8.2.5.5.1.1.1 style=width:99.4pt>Body Representation</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.5.5.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.5.5.2.1><span class=ltx_p id=A10.T8.2.5.5.2.1.1 style=width:397.5pt>Rate the body representation of the dancer where: 0 means unrealistic/distorted proportions of the dancer, 5 means minor anatomical issues of the dancer, and 10 means anatomically perfect representation of the dancer. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.6.6><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.6.6.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.6.6.1.1><span class=ltx_p id=A10.T8.2.6.6.1.1.1 style=width:99.4pt>Movement Realism</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.6.6.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.6.6.2.1><span class=ltx_p id=A10.T8.2.6.6.2.1.1 style=width:397.5pt>Rate the movement realism of the dancer where: 0 means poor movement realism of the dancer, 5 means moderate movement realism of the dancer, and 10 means perfect movement realism of the dancer. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.7.7><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.7.7.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.7.7.1.1><span class=ltx_p id=A10.T8.2.7.7.1.1.1 style=width:99.4pt>Choreography Complexity</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.7.7.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.7.7.2.1><span class=ltx_p id=A10.T8.2.7.7.2.1.1 style=width:397.5pt>Rate the complexity of the choreography where: 0 means extremely basic choreography, 5 means intermediate choreography, and 10 means extremely complex/advanced choreography. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.8.8><td class="ltx_td ltx_align_center ltx_align_top ltx_border_l ltx_border_r ltx_border_t" colspan=2 id=A10.T8.2.8.8.1><span class="ltx_text ltx_font_bold" id=A10.T8.2.8.8.1.1>Video Quality</span></td></tr><tr class=ltx_tr id=A10.T8.2.9.9><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.9.9.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.9.9.1.1><span class=ltx_p id=A10.T8.2.9.9.1.1.1 style=width:99.4pt>Imaging Quality</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.9.9.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.9.9.2.1><span class=ltx_p id=A10.T8.2.9.9.2.1.1 style=width:397.5pt>Rate the imaging quality where: 0 means poor imaging quality, 5 means moderate imaging quality, and 10 means perfect imaging quality. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.10.10><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.10.10.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.10.10.1.1><span class=ltx_p id=A10.T8.2.10.10.1.1.1 style=width:99.4pt>Aesthetic Quality</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.10.10.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.10.10.2.1><span class=ltx_p id=A10.T8.2.10.10.2.1.1 style=width:397.5pt>Rate the aesthetic quality where: 0 means poor aesthetic quality, 5 means moderate aesthetic quality, and 10 means perfect aesthetic quality. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.11.11><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.11.11.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.11.11.1.1><span class=ltx_p id=A10.T8.2.11.11.1.1.1 style=width:99.4pt>Overall Consistency</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.11.11.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.11.11.2.1><span class=ltx_p id=A10.T8.2.11.11.2.1.1 style=width:397.5pt>Rate the overall consistency where: 0 means poor consistency, 5 means moderate consistency, and 10 means perfect consistency. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.12.12><td class="ltx_td ltx_align_center ltx_align_top ltx_border_l ltx_border_r ltx_border_t" colspan=2 id=A10.T8.2.12.12.1><span class="ltx_text ltx_font_bold" id=A10.T8.2.12.12.1.1>Prompt Alignment</span></td></tr><tr class=ltx_tr id=A10.T8.2.13.13><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.13.13.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.13.13.1.1><span class=ltx_p id=A10.T8.2.13.13.1.1.1 style=width:99.4pt>Style Capture</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.13.13.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.13.13.2.1><span class=ltx_p id=A10.T8.2.13.13.2.1.1 style=width:397.5pt>How well does the dance video capture the specific style mentioned in the prompt: ‚Äô{prompt}‚Äô? Rate 0-10 where: 0 means completely missed the style, 5 means some elements of the style are present, and 10 means perfectly captures the style. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.14.14><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.14.14.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.14.14.1.1><span class=ltx_p id=A10.T8.2.14.14.1.1.1 style=width:99.4pt>Creative Interpretation</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id=A10.T8.2.14.14.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.14.14.2.1><span class=ltx_p id=A10.T8.2.14.14.2.1.1 style=width:397.5pt>Based on the prompt ‚Äô{prompt}‚Äô, rate the creativity in interpreting the prompt 0-10 where: 0 means generic/standard interpretation, 5 means moderate creativity, and 10 means highly creative and unique interpretation. Output only the number.</span></span></td></tr><tr class=ltx_tr id=A10.T8.2.15.15><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id=A10.T8.2.15.15.1><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.15.15.1.1><span class=ltx_p id=A10.T8.2.15.15.1.1.1 style=width:99.4pt>Overall Prompt Satisfaction</span></span></td><td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id=A10.T8.2.15.15.2><span class="ltx_inline-block ltx_align_top" id=A10.T8.2.15.15.2.1><span class=ltx_p id=A10.T8.2.15.15.2.1.1 style=width:397.5pt>Rate the overall prompt satisfaction 0-10 where: 0 means the video fails to satisfy the prompt ‚Äô{prompt}‚Äô, 5 means it partially satisfies the prompt, and 10 means it fully satisfies all aspects of the prompt. Output only the number.</span></span></td></tr></tbody></table></table></figure><blockquote><p>üîº This table details the specific prompts used to evaluate the MusicInfuser model. It lists a series of prompts, each describing a different dance scene with variations in dancer attire, setting, and style. These prompts were used to generate dance videos and assess the model&rsquo;s ability to generate videos that align with both the textual description and the musical input. The assessment metrics used are also listed and described, indicating how the quality of style, beat alignment, body representation, movement realism, choreography complexity, and overall video quality were evaluated.</p><details><summary>read the caption</summary>Table 8: System prompts for evaluation</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-8ab9f0b12df264640ff507d0079240b7 class=gallery><img src=https://ai-paper-reviewer.com/2503.14505/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2503.14505/19.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/&amp;title=MusicInfuser:%20Making%20Video%20Diffusion%20Listen%20and%20Dance" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/&amp;text=MusicInfuser:%20Making%20Video%20Diffusion%20Listen%20and%20Dance" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/&amp;subject=MusicInfuser:%20Making%20Video%20Diffusion%20Listen%20and%20Dance" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_2025-03-20/2503.14505/index.md",oid_likes="likes_2025-03-20/2503.14505/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/2025-03-20/2503.13288/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">$œÜ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-03-17T00:00:00+00:00>17 March 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/2025-03-20/2503.15485/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">TULIP: Towards Unified Language-Image Pretraining</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-03-19T00:00:00+00:00>19 March 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=https://deep-diver.github.io/neurips2024/ title>NeurIPS2024</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Hugging Face Daily Papers</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>