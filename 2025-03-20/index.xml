<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-20s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/</link><description>Recent content in 2025-03-20s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Wed, 19 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/index.xml" rel="self" type="application/rss+xml"/><item><title>Cube: A Roblox View of 3D Intelligence</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15475/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15475/</guid><description>Roblox presents Cube, a 3D intelligence model using shape tokenization for text-to-shape, shape-to-text, and text-to-scene generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15475/cover.png"/></item><item><title>DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15265/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15265/</guid><description>DeepMesh: RL-guided auto-regressive creation of artist-quality 3D meshes, enhanced by tokenization &amp;amp; DPO for human-aligned aesthetics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15265/cover.png"/></item><item><title>Efficient Personalization of Quantized Diffusion Model without Backpropagation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14868/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14868/</guid><description>Personalize diffusion models efficiently on devices without backpropagation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14868/cover.png"/></item><item><title>ELTEX: A Framework for Domain-Driven Synthetic Data Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15055/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15055/</guid><description>ELTEX: Domain-driven synthetic data generation framework improves LLM performance in cybersecurity with less resources.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15055/cover.png"/></item><item><title>LEGION: Learning to Ground and Explain for Synthetic Image Detection</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15264/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15264/</guid><description>LEGION: Grounding and explaining synthetic image detection and refinement via multimodal learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15264/cover.png"/></item><item><title>Temporal Regularization Makes Your Video Generator Stronger</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15417/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15417/</guid><description>FluxFlow: Make your video generator stronger via temporal regularization!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15417/cover.png"/></item><item><title>TULIP: Towards Unified Language-Image Pretraining</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15485/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15485/</guid><description>TULIP enhances image-text pretraining by unifying generative data augmentation with contrastive learning, achieving state-of-the-art performance in visual understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.15485/cover.png"/></item><item><title>MusicInfuser: Making Video Diffusion Listen and Dance</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/</guid><description>Sync your moves! MusicInfuser adapts video diffusion to make models listen and dance to music, preserving style and aligning movement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.14505/cover.png"/></item><item><title>$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13288/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13288/</guid><description>Φ-Decoding: Adaptive foresight sampling balances inference-time exploration and exploitation for better LLM reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13288/cover.png"/></item><item><title>Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13360/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13360/</guid><description>TVC mitigates visual forgetting in multimodal LLMs, enhancing reasoning by strategically re-introducing and compressing visual information.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.13360/cover.png"/></item><item><title>Unlock Pose Diversity: Accurate and Efficient Implicit Keypoint-based Spatiotemporal Diffusion for Audio-driven Talking Portrait</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12963/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12963/</guid><description>KDTalker: Accurate &amp;amp; efficient audio-driven talking portrait via implicit keypoint-based spatiotemporal diffusion, unlocking diverse &amp;amp; realistic animations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12963/cover.png"/></item><item><title>ViSpeak: Visual Instruction Feedback in Streaming Videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12769/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12769/</guid><description>ViSpeak: Enables visual instruction feedback in streaming videos, enhancing human-AI interaction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12769/cover.png"/></item><item><title>STEVE: AStep Verification Pipeline for Computer-use Agent Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12532/</link><pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12532/</guid><description>STEVE: Step-verifying computer-use agent training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.12532/cover.png"/></item><item><title>GKG-LLM: A Unified Framework for Generalized Knowledge Graph Construction</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.11227/</link><pubDate>Fri, 14 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.11227/</guid><description>GKG-LLM: Unifying Knowledge Graph Construction with a novel 3-stage framework, empowering domain adaptation &amp;amp; resource efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-20/2503.11227/cover.png"/></item></channel></rss>