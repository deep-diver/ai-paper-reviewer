{"references": [{"fullname_first_author": "Zhuo, L.", "paper_title": "Lumina-next: Making lumina-t2x stronger and faster with next-dit", "publication_date": "2024-06-18", "reason": "This paper introduces Next-DiT, a crucial architecture that Lumina-Video builds upon for efficient and flexible video generation."}, {"fullname_first_author": "Lipman, Y.", "paper_title": "Flow matching for generative modeling", "publication_date": "2023-00-00", "reason": "This paper introduces flow matching, the core training method used in Lumina-Video, enabling efficient and high-quality video generation."}, {"fullname_first_author": "Yang, Z.", "paper_title": "Cogvideox: Text-to-video diffusion models with an expert transformer", "publication_date": "2024-08-00", "reason": "CogVideoX provides a strong baseline for video generation, and Lumina-Video builds on its architecture and training strategies for improved performance."}, {"fullname_first_author": "Esser, P.", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "Stable Diffusion 3, referenced in this paper, inspires Lumina-Video's scale-aware timestep shifting training strategy for enhanced efficiency."}, {"fullname_first_author": "Ho, J.", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2022-07-00", "reason": "Classifier-free guidance, introduced in this paper, is a key technique used in Lumina-Video to control the dynamics and quality of the generated videos."}]}