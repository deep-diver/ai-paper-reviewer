{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-31", "reason": "This paper introduces Flamingo, a significant visual language model that heavily influenced the design and development of encoder-free VLMs, providing a strong baseline and conceptual foundation for the current work."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This foundational paper introduced the CLIP model, which is widely used as a pre-trained vision encoder in many encoder-based VLMs; its concepts and techniques are essential for understanding and comparing against encoder-free approaches."}, {"fullname_first_author": "Haiwen Diao", "paper_title": "Unveiling encoder-free vision-language models", "publication_date": "2024-06-17", "reason": "This paper serves as a direct precursor to the current work, introducing the EVE model and laying the groundwork for further improvements in encoder-free VLMs, setting the stage for EVEv2.0's advancements."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2023-12-20", "reason": "This paper presents InternVL, a strong encoder-based VLM that offers a performance benchmark for encoder-free models and highlights the challenges and potential for bridging the gap between encoder-based and encoder-free architectures."}, {"fullname_first_author": "Rohan Bavishi", "paper_title": "Introducing our multimodal models", "publication_date": "2023-12-31", "reason": "This paper introduced the Fuyu model, one of the earliest and most influential monolithic VLMs, highlighting the potential and challenges of developing encoder-free, compositional VLMs without pre-trained vision encoders."}]}