<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-07s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/</link><description>Recent content in 2025-03-07s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 06 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/index.xml" rel="self" type="application/rss+xml"/><item><title>FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04222/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04222/</guid><description>FuseChat-3.0: Heterogeneous model fusion boosts LLM performance via preference optimization, creating efficient and powerful language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04222/cover.png"/></item><item><title>IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04644/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04644/</guid><description>IFIR: a new benchmark for instruction-following retrieval in expert domains, revealing current model limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04644/cover.png"/></item><item><title>Lost in Literalism: How Supervised Training Shapes Translationese in LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04369/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04369/</guid><description>LLMs show translationese due to supervised training biases. Polishing references and filtering unnatural instances can mitigate this issue.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.04369/cover.png"/></item><item><title>EgoLife: Towards Egocentric Life Assistant</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.03803/</link><pubDate>Wed, 05 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.03803/</guid><description>EgoLife: Ultra-long egocentric dataset &amp;amp; benchmark enabling AI assistants to understand and enhance daily life. Datasets and models released!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.03803/cover.png"/></item><item><title>LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.02972/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.02972/</guid><description>LINGOLY-TOO: A new benchmark to disentangle memorization from reasoning in LLMs using linguistic templatization and orthographic obfuscation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.02972/cover.png"/></item><item><title>Identifying Sensitive Weights via Post-quantization Integral</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.01901/</link><pubDate>Fri, 28 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.01901/</guid><description>PQI: Accurately identify sensitive weights in post-quantization to enhance LLM compression &amp;amp; performance!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-07/2503.01901/cover.png"/></item></channel></rss>