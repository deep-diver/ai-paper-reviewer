{"references": [{"fullname_first_author": "Yantao Liu", "paper_title": "Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament", "publication_date": "2025-01-22", "reason": "This is the main paper being discussed, introducing the Pairwise RM and its methodology."}, {"fullname_first_author": "Binghai Wang", "paper_title": "Secrets of RLHF in large language models part II: Reward modeling", "publication_date": "2024-01-06", "reason": "This paper is cited multiple times and directly related to reward models, a core concept in the main paper's approach."}, {"fullname_first_author": "Hunter Lightman", "paper_title": "Let's Verify Step by Step", "publication_date": "2023-05-20", "reason": "This work is directly referenced in the introduction and methodology sections, demonstrating the significance of related work."}, {"fullname_first_author": "Charlie Snell", "paper_title": "Scaling LLM test-time compute optimally can be more effective than scaling model parameters", "publication_date": "2024-08-03", "reason": "This paper discusses a relevant aspect of test-time scaling that connects to the main paper's focus on efficiency."}, {"fullname_first_author": "Nathan Lambert", "paper_title": "Rewardbench: Evaluating reward models for language modeling", "publication_date": "2024-03-13", "reason": "This paper contributes to the discussion surrounding reward models, providing a benchmark for evaluating the models that the main paper improves upon."}]}