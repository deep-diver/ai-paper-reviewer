{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper is foundational for cross-modal learning, a core technique used in the subject-consistent video generation method proposed in the paper."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-06-01", "reason": "This paper introduces a key model architecture used as a building block in the proposed video generation framework."}, {"fullname_first_author": "Adam Polyak", "paper_title": "Movie gen: A cast of media foundation models", "publication_date": "2024-10-01", "reason": "This paper introduces a large-scale video generation model that serves as a strong baseline for comparison and further development."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "This paper provides essential advancements in diffusion models, which are crucial to video generation tasks."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-01", "reason": "This paper demonstrates advancements in video diffusion models, offering a strong foundation for the proposed method."}]}