{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-31", "reason": "This paper is foundational to the understanding of how LLMs can be trained to follow instructions, a key capability for the meeting delegate system."}, {"fullname_first_author": "Sumit Asthana", "paper_title": "Summaries, highlights, and action items: Design, implementation and evaluation of an LLM-powered meeting recap system", "publication_date": "2023-12-31", "reason": "This paper directly addresses the task of summarizing meeting content, a related task that informs the design and evaluation of the meeting delegate system."}, {"fullname_first_author": "Manqing Mao", "paper_title": "Multi-user chat assistant (MUCA): a framework using LLMs to facilitate group conversations", "publication_date": "2024-12-31", "reason": "This paper explores the use of LLMs in facilitating group discussions, which is relevant to the design of a system that can participate effectively in meetings."}, {"fullname_first_author": "Fabrizio Gilardi", "paper_title": "ChatGPT outperforms crowd workers for text-annotation tasks", "publication_date": "2023-12-31", "reason": "This paper highlights the potential of LLMs for efficient data annotation, which is relevant to the creation of the benchmark dataset for the meeting delegate system."}, {"fullname_first_author": "Emily M. Bender", "paper_title": "On the dangers of stochastic parrots: Can language models be too big?", "publication_date": "2021-12-31", "reason": "This paper provides crucial context on the limitations of LLMs, informing the discussion of potential challenges and ethical considerations related to deploying an LLM-based meeting delegate."}]}