[{"figure_path": "https://arxiv.org/html/2502.21263/extracted/6242124/figures/brat_example.png", "caption": "Figure 1: Examples of ICD code assignments by annotators: each entity in green is annotated with its ICD code above and its English translation (in yellow).", "description": "Figure 1 showcases examples from the RuCCoD dataset, illustrating the annotation process for ICD codes.  Each highlighted entity (in green) represents a medical concept extracted from a Russian electronic health record (EHR).  Above each green entity is its corresponding ICD code, with an English translation provided in yellow.  This visualization clarifies how annotators linked specific diagnostic information within EHR text to standard ICD codes.", "section": "3 ICD Datasets"}, {"figure_path": "https://arxiv.org/html/2502.21263/extracted/6242124/figures/two_tasks.png", "caption": "Figure 2: Schematic description of ICD coding (in blue) and diagnosis prediction tasks (in yellow). Diagnosis prediction uses prior EHR data and current visit details, excluding the doctor\u2019s conclusion, which is used for ICD coding to generate AI-assigned ICD codes. Both original and AI ICD code lists are then used as targets to train different diagnosis prediction models.", "description": "This figure illustrates the two main tasks addressed in the paper: ICD coding and diagnosis prediction.  The ICD coding task (shown in blue) involves using a doctor's diagnostic conclusion (from the current visit) to assign ICD codes. An AI model is trained to perform this task, generating AI-assigned ICD codes.  The diagnosis prediction task (shown in yellow) predicts likely ICD codes based on a patient's complete medical history, excluding the doctor's conclusion from the current visit.  Both the original ICD codes (assigned by doctors) and the AI-generated ICD codes are used as training targets for the diagnosis prediction models, enabling comparison and improvement of AI performance.", "section": "2 ICD-Related Tasks"}, {"figure_path": "https://arxiv.org/html/2502.21263/extracted/6242124/figures/codes_stats_bigger.png", "caption": "Figure 3: Distribution of ICD code frequencies in the RuCCoD train set.", "description": "This histogram displays the frequency distribution of ICD codes within the RuCCoD training dataset.  The x-axis represents ICD codes sorted by their frequency of appearance in the dataset, and the y-axis shows the number of times each code appears.  The graph reveals a highly skewed distribution, with a relatively small number of codes appearing very frequently, and a large number of codes appearing very infrequently, reflecting the uneven distribution of diagnoses in real-world clinical data.", "section": "3 ICD Datasets"}, {"figure_path": "https://arxiv.org/html/2502.21263/extracted/6242124/figures/delta_scatter_bigger.png", "caption": "Figure 4: Comparison of weighted F1 scores on the manual diagnosis prediction test set for models trained on original and linked datasets at different training steps.", "description": "This figure shows the performance comparison between two models trained for diagnosis prediction on a manual test set. One model was trained using the original dataset (manually annotated), while the other was trained using a linked dataset (automatically annotated using ICD codes generated by a model).  The x-axis represents the training steps, and the y-axis represents the weighted F1-score, a metric that accounts for class imbalances in the dataset. The graph illustrates how the weighted F1-score changes as the models are trained over different numbers of steps.  It shows that the model trained on the automatically annotated dataset performs significantly better than the model trained on the original dataset.", "section": "5.2 Results"}, {"figure_path": "https://arxiv.org/html/2502.21263/extracted/6242124/figures/graph.png", "caption": "Figure 5: F1 score distribution for top and bottom 10% frequent ICD codes in the common test set.", "description": "This figure displays the F1-score distribution for the top and bottom 10% most frequent ICD codes within a common test set, comparing performance of the model trained on the original dataset versus the linked dataset.  The top 10% represents the most frequently occurring ICD codes, while the bottom 10% represents the least frequent codes, with a minimum frequency threshold of 15 instances within the test set. This visualization highlights the effect of training data (original vs. linked) on the model's ability to predict both frequent and infrequent disease codes.", "section": "5.2 Results"}]