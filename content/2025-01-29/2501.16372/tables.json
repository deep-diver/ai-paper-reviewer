[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Sx2.T1.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"Sx2.T1.4.5.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"Sx2.T1.4.5.1.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T1.4.5.1.2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.2.1\">Average Score</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T1.4.5.1.3\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.3.1\">Relative Score</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T1.4.5.1.4\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.4.1\">Total Params.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T1.4.5.1.5\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.5.1\">TFLOPs</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T1.4.5.1.6\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.5.1.6.1\">Inference Speedup</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx2.T1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"Sx2.T1.1.1.2\" style=\"padding:1pt 4.5pt;\">LoRA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T1.1.1.3\" style=\"padding:1pt 4.5pt;\">65.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T1.1.1.4\" style=\"padding:1pt 4.5pt;\">100.0%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T1.1.1.5\" style=\"padding:1pt 4.5pt;\">6.7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T1.1.1.6\" style=\"padding:1pt 4.5pt;\">1.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T1.1.1.1\" style=\"padding:1pt 4.5pt;\">1.00<math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.T1.1.1.1.m1.1\"><semantics id=\"Sx2.T1.1.1.1.m1.1a\"><mo id=\"Sx2.T1.1.1.1.m1.1.1\" xref=\"Sx2.T1.1.1.1.m1.1.1.cmml\">\u00d7</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx2.T1.1.1.1.m1.1b\"><times id=\"Sx2.T1.1.1.1.m1.1.1.cmml\" xref=\"Sx2.T1.1.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx2.T1.1.1.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx2.T1.1.1.1.m1.1d\">\u00d7</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T1.2.2.2\" style=\"padding:1pt 4.5pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"Sx2.T1.2.2.2.1\">\\cdashline</span>1-12\n<span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.2.2.2.2\">LoNAS (Heuristic Subnet)</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.2.2.3\" style=\"padding:1pt 4.5pt;\">65.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.2.2.4\" style=\"padding:1pt 4.5pt;\">99.1%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.2.2.5\" style=\"padding:1pt 4.5pt;\">5.6B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.2.2.6\" style=\"padding:1pt 4.5pt;\">1.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.2.2.1\" style=\"padding:1pt 4.5pt;\">1.23<math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.T1.2.2.1.m1.1\"><semantics id=\"Sx2.T1.2.2.1.m1.1a\"><mo id=\"Sx2.T1.2.2.1.m1.1.1\" xref=\"Sx2.T1.2.2.1.m1.1.1.cmml\">\u00d7</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx2.T1.2.2.1.m1.1b\"><times id=\"Sx2.T1.2.2.1.m1.1.1.cmml\" xref=\"Sx2.T1.2.2.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx2.T1.2.2.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx2.T1.2.2.1.m1.1d\">\u00d7</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T1.3.3.2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.3.3.2.1\">LoNAS (Search Subnet-1)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.3.3.3\" style=\"padding:1pt 4.5pt;\">67.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.3.3.4\" style=\"padding:1pt 4.5pt;\">102.0%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.3.3.5\" style=\"padding:1pt 4.5pt;\">5.6B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.3.3.6\" style=\"padding:1pt 4.5pt;\">1.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T1.3.3.1\" style=\"padding:1pt 4.5pt;\">1.28<math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.T1.3.3.1.m1.1\"><semantics id=\"Sx2.T1.3.3.1.m1.1a\"><mo id=\"Sx2.T1.3.3.1.m1.1.1\" xref=\"Sx2.T1.3.3.1.m1.1.1.cmml\">\u00d7</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx2.T1.3.3.1.m1.1b\"><times id=\"Sx2.T1.3.3.1.m1.1.1.cmml\" xref=\"Sx2.T1.3.3.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx2.T1.3.3.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx2.T1.3.3.1.m1.1d\">\u00d7</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"Sx2.T1.4.4.2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T1.4.4.2.1\">LoNAS (Search Subnet-2)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T1.4.4.3\" style=\"padding:1pt 4.5pt;\">65.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T1.4.4.4\" style=\"padding:1pt 4.5pt;\">99.7%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T1.4.4.5\" style=\"padding:1pt 4.5pt;\">5.1B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T1.4.4.6\" style=\"padding:1pt 4.5pt;\">1.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T1.4.4.1\" style=\"padding:1pt 4.5pt;\">1.41<math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.T1.4.4.1.m1.1\"><semantics id=\"Sx2.T1.4.4.1.m1.1a\"><mo id=\"Sx2.T1.4.4.1.m1.1.1\" xref=\"Sx2.T1.4.4.1.m1.1.1.cmml\">\u00d7</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx2.T1.4.4.1.m1.1b\"><times id=\"Sx2.T1.4.4.1.m1.1.1.cmml\" xref=\"Sx2.T1.4.4.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx2.T1.4.4.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx2.T1.4.4.1.m1.1d\">\u00d7</annotation></semantics></math>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: The performance of LoNAS using elastic adapters mode B, including accuracy score and model compression efficiency when fine-tuning LLaMA-7B on 15k unified commonsense reasoning dataset from LLM-Adapters (Hu et\u00a0al. 2023).\nThe average score represents the results across eight commonsense tasks. These results are reproduced from Mu\u00f1oz et\u00a0al. (2024)", "description": "This table presents the performance comparison of LoNAS (Low-Rank Neural Architecture Search) against the baseline LORA (Low-Rank Adaptation) method for fine-tuning a LLaMA-7B language model on a commonsense reasoning dataset.  It demonstrates LoNAS's efficiency in terms of accuracy, total parameters, floating point operations (FLOPs), and inference speedup.  The results are averaged across eight different commonsense tasks, showcasing the consistent improvement of LoNAS over LORA in terms of compression and speed without significant accuracy loss.  Different search strategies (heuristic and two search subnets) within LoNAS are compared, highlighting the impact of the search algorithm on the final model.", "section": "Efficient Neural Architecture Search with the Guidance of Low-Rank Adapters"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Sx2.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"Sx2.T2.1.1.1.1\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T2.1.1.1.2\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.1.1.2.1\">Accuracy</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T2.1.1.1.3\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.1.1.3.1\">Relative Acc.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T2.1.1.1.4\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.1.1.4.1\">Sparsity</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx2.T2.1.1.1.5\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.1.1.5.1\">Precision</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"Sx2.T2.1.2.2.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.2.2.1.1\">(Base + Adapter / Base)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"Sx2.T2.1.3.1.1\" style=\"padding:1pt 4.5pt;\">w/o tune</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T2.1.3.1.2\" style=\"padding:1pt 4.5pt;\">36.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T2.1.3.1.3\" style=\"padding:1pt 4.5pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T2.1.3.1.4\" style=\"padding:1pt 4.5pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx2.T2.1.3.1.5\" style=\"padding:1pt 4.5pt;\">FP16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T2.1.4.2.1\" style=\"padding:1pt 4.5pt;\">LoRA</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.4.2.2\" style=\"padding:1pt 4.5pt;\">44.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.4.2.3\" style=\"padding:1pt 4.5pt;\">100.0%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.4.2.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.4.2.5\" style=\"padding:1pt 4.5pt;\">FP16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T2.1.5.3.1\" style=\"padding:1pt 4.5pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"Sx2.T2.1.5.3.1.1\">\\cdashline</span>1-5\n<span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.5.3.1.2\">Shears</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.5.3.2\" style=\"padding:1pt 4.5pt;\">45.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.5.3.3\" style=\"padding:1pt 4.5pt;\">102.3%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.5.3.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.5.3.5\" style=\"padding:1pt 4.5pt;\">FP16 + FP16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T2.1.6.4.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.6.4.1.1\">SQFT + SparsePEFT</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.6.4.2\" style=\"padding:1pt 4.5pt;\">50.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.6.4.3\" style=\"padding:1pt 4.5pt;\">113.6%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.6.4.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.6.4.5\" style=\"padding:1pt 4.5pt;\">FP16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx2.T2.1.7.5.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.7.5.1.1\">SQFT</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.7.5.2\" style=\"padding:1pt 4.5pt;\">44.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.7.5.3\" style=\"padding:1pt 4.5pt;\">100.9%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.7.5.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx2.T2.1.7.5.5\" style=\"padding:1pt 4.5pt;\">INT4 + FP16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx2.T2.1.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"Sx2.T2.1.8.6.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx2.T2.1.8.6.1.1\">SQFT + QA-SparsePEFT</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T2.1.8.6.2\" style=\"padding:1pt 4.5pt;\">44.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T2.1.8.6.3\" style=\"padding:1pt 4.5pt;\">99.8%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T2.1.8.6.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx2.T2.1.8.6.5\" style=\"padding:1pt 4.5pt;\">INT4</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: The performance of Shears and SQFT from Mu\u00f1oz et\u00a0al. (2024), when fine-tuning Mistral-7B-v0.3 on GSM8K using elastic adapters mode A.", "description": "This table presents the performance comparison of different methods in fine-tuning the Mistral-7B-v0.3 language model on the GSM8K benchmark dataset.  Specifically, it contrasts the accuracy, relative accuracy improvement compared to a baseline, sparsity level achieved, and precision used for the LoRA, Shears, and SQFT methods.  Shears and SQFT utilize Elastic LoRA Adapters in Mode A, which means only the adapter ranks are allowed to be elastic. The table aims to illustrate how different model compression and fine-tuning techniques impact model performance and efficiency when working with large language models.", "section": "Addressing the Challenges of Merging Adapters with Low-precision Sparse Models"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Sx3.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"Sx3.T3.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"Sx3.T3.1.1.1.1\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx3.T3.1.1.1.2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.1.1.2.1\">Average</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx3.T3.1.1.1.3\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.1.1.3.1\">Relative</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx3.T3.1.1.1.4\" rowspan=\"2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.1.1.4.1\">Sparsity</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"Sx3.T3.1.1.1.5\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.1.1.5.1\">Non-zero</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx3.T3.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"Sx3.T3.1.2.2.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.2.2.1.1\">Score</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"Sx3.T3.1.2.2.2\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.2.2.2.1\">Score</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"Sx3.T3.1.2.2.3\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.2.2.3.1\">Params.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx3.T3.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"Sx3.T3.1.3.1.1\" style=\"padding:1pt 4.5pt;\">LoRA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx3.T3.1.3.1.2\" style=\"padding:1pt 4.5pt;\">51.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx3.T3.1.3.1.3\" style=\"padding:1pt 4.5pt;\">100.0%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx3.T3.1.3.1.4\" style=\"padding:1pt 4.5pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx3.T3.1.3.1.5\" style=\"padding:1pt 4.5pt;\">13.0B</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx3.T3.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Sx3.T3.1.4.2.1\" style=\"padding:1pt 4.5pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"Sx3.T3.1.4.2.1.1\">\\cdashline</span>1-5\n<span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.4.2.1.2\">Shears</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx3.T3.1.4.2.2\" style=\"padding:1pt 4.5pt;\">52.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx3.T3.1.4.2.3\" style=\"padding:1pt 4.5pt;\">101.8%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx3.T3.1.4.2.4\" style=\"padding:1pt 4.5pt;\">40%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx3.T3.1.4.2.5\" style=\"padding:1pt 4.5pt;\">8.0B</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx3.T3.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"Sx3.T3.1.5.3.1\" style=\"padding:1pt 4.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx3.T3.1.5.3.1.1\">Shears</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx3.T3.1.5.3.2\" style=\"padding:1pt 4.5pt;\">50.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx3.T3.1.5.3.3\" style=\"padding:1pt 4.5pt;\">99.6%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx3.T3.1.5.3.4\" style=\"padding:1pt 4.5pt;\">50%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx3.T3.1.5.3.5\" style=\"padding:1pt 4.5pt;\">6.7B</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: The performance of Shears for LLaMA-13B on a 10k unified math reasoning dataset from LLM-Adapters (Hu et\u00a0al. 2023) using elastic adapters mode A.\nThese results are reproduced from Mu\u00f1oz et\u00a0al. (2024), and the average score represents the results across four math tasks (GSM8K (Cobbe et\u00a0al. 2021), AQUA (Ling et\u00a0al. 2017), MAWPS (Lan et\u00a0al. 2022) and SVAMP (Patel, Bhattamishra, and Goyal 2021)).", "description": "This table presents the performance of the Shears method when fine-tuning a 13-billion parameter LLaMA model on a dataset of 10,000 unified math reasoning problems.  The evaluation uses four different math reasoning tasks: GSM8K, AQUA, MAWPS, and SVAMP. The table shows the average score across these tasks, relative score compared to a baseline, the sparsity achieved, and the numerical precision used (floating-point 16-bit or integer 4-bit).  The results are based on using Elastic Adapter Mode A, as detailed in the paper.", "section": "Addressing the Challenges of Merging Adapters with Low-precision Sparse Models"}]