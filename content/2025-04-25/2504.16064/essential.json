{"importance": "This paper introduces ReDi, a novel method enhancing generative models by jointly modeling image latents and semantic features. **This advances representation-aware generation**, offering significant improvements in quality and efficiency, inspiring future research into unified generative and representation learning frameworks.", "summary": "ReDi: Joint image-feature synthesis boosts generative image modeling, enhancing quality and training speed.", "takeaways": ["Joint modeling of image latents and semantic features significantly enhances generative performance.", "Representation Guidance, a novel inference strategy, leverages learned semantics to refine image generation.", "The proposed approach accelerates training convergence, achieving state-of-the-art results with minimal modifications to existing architectures."], "tldr": "Latent diffusion models excel in image generation, yet integrating representation learning poses challenges. Existing methods struggle to balance low-level reconstruction with meaningful representations. Yu et al. (2025)'s REPA demonstrated improved generation by distilling pretrained self-supervised representations. However, complex distillation objectives hinder simpler training and limit inference strategies. A better way to leverage representation learning is desirable.\n\nTo address these issues, the paper introduces ReDi, a generative framework that **bridges the gap between image generation and representation learning**. ReDi jointly models low-level image latents from a variational autoencoder and high-level semantic features from pretrained encoders like DINOv2 within a diffusion model. ReDi generates coherent image-feature pairs from noise, significantly boosting generation quality and efficiency with Representation Guidance. This unlocks semantic refinement and offers a new direction for representation-aware generative modeling.", "affiliation": "National Technical University of Athens", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2504.16064/podcast.wav"}