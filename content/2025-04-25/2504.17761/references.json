{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important because it introduces CLIP, a foundational model for vision-language tasks, which is relevant to image editing with natural language instructions."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper is important because it introduces T5, a text-to-text transformer model, which is often used as a text encoder in diffusion-based image editing systems."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-01-01", "reason": "This paper is important because it introduces Latent Diffusion Models (LDMs), a key advancement that improves the scalability of diffusion models, which is relevant to high-fidelity image synthesis."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper is important because it introduces ControlNet, injecting spatial control into the generation process."}, {"fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2020-01-01", "reason": "This paper is important because it introduces Denoising Diffusion Implicit Models, which is the core of high-fidelity image synthesis."}]}