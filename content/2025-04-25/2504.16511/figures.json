[{"figure_path": "https://arxiv.org/html/2504.16511/extracted/6375253/image/fwb_distribution.png", "caption": "Figure 1: The distribution change of data selected with Fineweb-edu Classifier. With the top5% documents selected, the ratio of certain domains including Health, Jobs and Education, increases for a large margin compared with original data", "description": "Figure 1 illustrates the impact of data selection using the Fineweb-edu classifier on the distribution of different domains within a dataset.  The original data distribution is compared to the distribution obtained after selecting the top 5% of documents based on the classifier's assessment. The figure highlights that the selected subset shows a significantly increased proportion of documents from domains such as \"Health,\" \"Jobs,\" and \"Education,\" compared to their representation in the original dataset. This demonstrates that data selection methods can lead to a skewed distribution, emphasizing the importance of considering diversity during data selection for large language model training.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.16511/x1.png", "caption": "Figure 2: The overall design of QuaDMix. First we extract the data features using classifier and quality scores (QS). Then we calculate quality rank for each domain with the merging parameters. Finally the sampling functions controlled by sampling parameters are applied to generate the final output data.", "description": "QuaDMix's data selection process is depicted.  It begins by extracting features from the raw data, specifically domain classification labels and multiple quality scores. These scores are then merged using domain-specific weights to create a single quality score for each data point.  The quality score for each data point is used to determine its rank within its domain.  Finally, a parameterized sampling function (with learned parameters) uses the quality rank and domain to determine the probability of selecting each data point for inclusion in the final, optimized dataset. This ensures that the selected data balances quality and diversity.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2504.16511/x2.png", "caption": "Figure 3: Left: The prediction model loss vs real model loss. Right: The regression model performance (MAE) vs training size.", "description": "This figure displays two plots to evaluate the effectiveness of the regression model used in the QuaDMix framework. The left plot shows a strong correlation between the predicted loss from the regression model and the actual loss obtained when training language models on datasets created using various QuaDMix parameters.  This confirms the regression model's ability to predict the performance of larger language models based on the performance of smaller proxy models trained on smaller datasets sampled using different QuaDMix parameter settings. The right plot shows the mean absolute error (MAE) of the regression model against different training sizes. As the training size increases, the MAE decreases, indicating improved accuracy in prediction.", "section": "3.3 Parameter Optimizing"}, {"figure_path": "https://arxiv.org/html/2504.16511/extracted/6375253/image/Sample_ratio_by_Domain_of_Bmk_Merge.png", "caption": "Figure 4: The visualization of optimal parameters from QuaDMix-BMK", "description": "This figure visualizes the optimal parameters learned by the QuaDMix-BMK model.  The left panel shows the distribution of tokens across different domains after applying QuaDMix-BMK's data selection process, compared to the original distribution in RefinedWeb.  The right panel displays the weights assigned by QuaDMix-BMK to different quality criteria (AskLLM, Fineweb-edu, DCLM) for each domain.  The relative heights of the bars indicate the importance of each domain and quality filter in shaping the final data distribution used for pre-training.", "section": "Experiments on Regression Model"}, {"figure_path": "https://arxiv.org/html/2504.16511/extracted/6375253/image/Weights_by_Domain_of_Bmk_Merge.png", "caption": "Figure 5: The prediction loss of QuaDMix-BMK surpasses QuaDMix-OH on all 5 downstream tasks.", "description": "This figure displays a comparison of prediction loss between two data selection methods, QuaDMix-BMK and QuaDMix-OH, across five downstream tasks.  QuaDMix-BMK consistently demonstrates lower prediction loss than QuaDMix-OH across all five tasks, visually highlighting its superior performance in predicting model performance based on the chosen data selection parameters.", "section": "4.2 Results"}]