[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.F4.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.F4.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S3.F4.1.1.1\" style=\"padding-left:1.4pt;padding-right:1.4pt;\">\n<img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_square\" height=\"657\" id=\"S3.F4.1.1.1.g1\" src=\"extracted/6386064/fig/vivid_dress.png\" width=\"598\"/>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: Quantitative comparison on the ViViD dataset. \u2217 indicates our method using the same mask with ViViD\u00a0[13].", "description": "This table presents a quantitative comparison of different virtual try-on methods on the ViViD dataset.  The metrics used assess the quality of the generated try-on results, including structural similarity (SSIM), learned perceptual image patch similarity (LPIPS), and two versions of the Video Frechet Inception Distance (VFID) - one using a ResNet-50 backbone and another using a more recent RexNet backbone.  Lower LPIPS scores and higher SSIM scores indicate better visual quality. Lower VFID scores imply better temporal consistency in the generated video. The table highlights the superior performance of the proposed 3DV-TON method, especially when using the same mask as the ViViD baseline. The asterisk (*) denotes results where 3DV-TON used the same mask as the ViViD method for fair comparison.", "section": "4. Experiments"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.F5.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.F5.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S4.F5.1.1.1\" style=\"padding-left:1.4pt;padding-right:1.4pt;\">\n<img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_square\" height=\"660\" id=\"S4.F5.1.1.1.g1\" src=\"extracted/6386064/fig/vivid_upper.png\" width=\"598\"/>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Quantitative comparison on HR-VVT benchmark.  Best results are highlighted in bold, the second are underlined.", "description": "This table presents a quantitative comparison of different video virtual try-on methods on the HR-VVT benchmark dataset.  The metrics used are SSIM (structural similarity index), LPIPS (Learned Perceptual Image Patch Similarity), VFIDI3D (Video Fr\u00e9chet Inception Distance using I3D), and VFIDRexNext (Video Fr\u00e9chet Inception Distance using 3D-ResNeXt).  Both paired and unpaired settings are evaluated.  The best-performing method for each metric is shown in bold, and the second-best is underlined.  This allows for a direct comparison of the performance of various methods on the task of generating high-quality and temporally consistent video try-on results.", "section": "4. Experiments"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.F6.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.F6.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S4.F6.1.1.1\" style=\"padding-left:1.4pt;padding-right:1.4pt;\">\n<img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_square\" height=\"663\" id=\"S4.F6.1.1.1.g1\" src=\"extracted/6386064/fig/vivid_lower.png\" width=\"598\"/>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: User preference rate on the HR-VVT benchmark and ViViD dataset.", "description": "This table presents the results of a user preference study comparing the performance of three different video virtual try-on methods: ViViD, CatV2TON, and the proposed 3DV-TON.  The study assessed three aspects of the generated videos: fidelity (accuracy of garment representation), consistency (temporal coherence throughout the video), and overall quality.  Results are shown for both the HR-VVT and ViViD datasets, allowing for comparison across different datasets and showcasing the relative strengths and weaknesses of each method in different aspects of video try-on generation.", "section": "4. Experiments"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.F7.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.F7.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\" id=\"S4.F7.1.1.1\" style=\"padding-left:1.4pt;padding-right:1.4pt;\">\n<img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_square\" height=\"503\" id=\"S4.F7.1.1.1.g1\" src=\"extracted/6386064/fig/taobao_dress.png\" width=\"598\"/>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: Quantitative ablations for the 3D guidance.", "description": "This table presents the quantitative results of ablation studies on the impact of 3D guidance in the 3DV-TON model.  It shows the improvements in SSIM (structural similarity index), LPIPS (learned perceptual image patch similarity), and VFID (video Fr\u00e9chet Inception Distance) metrics when using SMPL (Skinned Multi-Person Linear Model) and textured 3D guidance, demonstrating the effectiveness of the proposed approach.", "section": "4.5 Ablation Study"}]