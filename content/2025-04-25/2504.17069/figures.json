[{"figure_path": "https://arxiv.org/html/2504.17069/extracted/6384630/Images/fig_1/fig1_celeba_fashion-row.png", "caption": "Figure 1: Generation with our distilled order on the Fashion Product dataset (Left) and the Multimodal CelebA-HQ dataset (Right) with the corresponding generation order produced by our Ordered Autoregressive (OAR) model. The generation order is visualized through color intensity, progressing from yellow (early patches) to violet (later patches). Our learned order typically starts with simpler regions of the image before moving to more complex ones. For the Fashion Product dataset, this often means generating the white background first, while in the CelebA-HQ dataset, the model tends to begin with facial regions like the cheeks and chin, which are generally easier to generate.", "description": "This figure visualizes the generation process of the Ordered Autoregressive (OAR) model on two datasets: Fashion Product and Multimodal CelebA-HQ.  The left panel shows the Fashion Product dataset, where the model starts by generating the simple white background, then progresses to more complex areas like the objects. The right panel shows the CelebA-HQ dataset, where generation begins with basic facial features (cheeks, chin) and gradually moves to more detailed elements. Color intensity represents the generation order, with yellow indicating early patches and violet representing later patches. The figure demonstrates that the OAR model's learned generation order prioritizes simpler image regions, making the generation process more efficient and intuitive.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2504.17069/x1.png", "caption": "Figure 2: Different Autoregressive (AR) models. (Top) A raster scan is the normal approach for autoregressive generation from top left to bottom-right. The input token contains the content xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and the position lisubscript\ud835\udc59\ud835\udc56l_{i}italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. (Middle) Any-given-order learns to generate tokens at any possible location. However, the position of the next token should be given as input in an additional positional embedding. (Bottom) Our method, Ordered Autoregressive, uses the any-given-order model but generates all possible positions and selects the most likely one (darker yellow) as the next generated token.", "description": "Figure 2 illustrates three different autoregressive (AR) image generation approaches. The top panel shows the traditional raster-scan method, where patches are generated sequentially from top-left to bottom-right. Each input token includes the patch's content and its position. The middle panel depicts an 'any-given-order' approach, allowing patches to be generated in any order but requiring the position of the next patch as additional input.  The bottom panel presents the 'Ordered Autoregressive' method proposed in the paper. This method starts with an any-given-order model, but instead of receiving the next patch position as input, it generates all possible patch positions and selects the one with the highest probability (represented by darker yellow shading), resulting in a semantically aware generation order.", "section": "4 Our Method: Ordered AR"}, {"figure_path": "https://arxiv.org/html/2504.17069/extracted/6384630/Images/fig_samples/merged.png", "caption": "Figure 3: Examples of generation on the Fashion Products dataset. (Top) Generated images with raster AR mode. (Middle) Generated images with ordered AR model.\n(Bottom) Generation order, from yellow to violet. From these images, we see that our approach finds an order highly correlated with the image content, often resulting in better image quality.", "description": "Figure 3 demonstrates the impact of using different generation orders on image quality for the Fashion Products dataset. The top row displays images generated using a standard raster scan autoregressive (AR) model, progressing from top-left to bottom-right. The middle row shows images generated with the proposed ordered AR model, which learns a semantically aware order instead of using a fixed raster scan. The bottom row visualizes the learned generation order for each image using a color gradient from yellow (early patches) to violet (later patches). The color intensity shows the sequence in which the patches were generated. This visualization reveals that the ordered AR model tends to generate simpler regions first (like the background), before progressing to more complex image components.  By generating patches in an order highly correlated with the image content, the ordered AR model achieves improved image quality, as evident by comparing the middle row (ordered AR) with the top row (raster AR).", "section": "5 Experiments and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.17069/extracted/6384630/Images/celeba.png", "caption": "Figure 4: Examples of generation on the CelebA dataset. (Top) Generated images with raster AR mode. (Middle) Generated\nimages with ordered AR model. (Bottom) Generation order, from yellow to violet. On this dataset our model generates first the salient parts of a face, leaving hair and background at the end. Our model produces images with greater smoothness, rich context and more aligned with the text", "description": "Figure 4 presents a comparison of image generation results on the CelebA-HQ dataset using two different autoregressive (AR) models: a raster-scan AR model and the proposed ordered AR model.  The top row shows images generated by the raster-scan model, which processes image patches sequentially from left-to-right and top-to-bottom. The middle row displays images generated by the ordered AR model, which generates patches in a semantically meaningful order determined by the model itself. This order prioritizes generating salient facial features (such as eyes, nose, and mouth) before generating less important details like hair and the background. The bottom row visualizes this learned generation order using a color gradient, where yellow indicates earlier-generated patches and violet indicates later-generated patches.  The ordered AR model demonstrates improved image quality, with generated images exhibiting greater smoothness, richer contextual details, and better alignment with the text prompts compared to the images produced by the raster-scan AR model.", "section": "5 Experiments and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.17069/extracted/6384630/Images/avg.png", "caption": "Figure 5: Generation order with absolute and relative positioning encoding. (Top) With absolute encoding the generation is very scattered. (Bottom) With relative positioning the generation is more localized. The average euclidean distance between the subsequently generated patches in case of absolute encoding is 5.78 whereas in case of relative encoding it is 4.34", "description": "This figure visualizes the impact of absolute versus relative positional encodings on the generation order in an autoregressive image generation model.  The top panel shows the generation sequence with absolute positional encoding; the patches are scattered across the image.  In contrast, the bottom panel, using relative positional encoding, demonstrates a more localized generation process with patches clustered together.  Quantitatively, the average Euclidean distance between consecutively generated patches is significantly smaller (4.34) with relative encoding compared to absolute encoding (5.78), highlighting the effectiveness of relative encoding in generating spatially coherent images.", "section": "4.3 Relative Position Encoding"}]