[{"Alex": "Hey everyone, and welcome to the podcast! Today, we're diving deep into the world of AI, but not just any AI \u2013 the kind that speaks Iberian languages! Think Spanish, Portuguese, Catalan, and more. We\u2019re asking the big question: How good are these AI models really at understanding and communicating in these languages? Get ready to have your mind blown as we dissect a fascinating new benchmark in this area.", "Jamie": "That sounds super interesting, Alex! Iberian languages are spoken by hundreds of millions of people, so it's crucial that AI understands them well. So, tell me, what exactly is this 'benchmark' you mentioned?"}, {"Alex": "Great question, Jamie! This benchmark is called 'IberBench,' and it's designed to comprehensively evaluate Large Language Models, or LLMs, on a variety of NLP tasks in Iberian languages. It's more than just a simple test; it's an entire framework for assessing how well these models perform.", "Jamie": "Okay, so it's like a standardized test for AI in these languages? That's pretty cool. But umm, what makes IberBench different from other AI benchmarks out there?"}, {"Alex": "That's where it gets really interesting! Most existing benchmarks are very English-centric and often overlook the linguistic diversity of Iberian languages, including regional variations and industry-relevant tasks. IberBench fills that gap by incorporating a wide range of datasets that reflect this diversity and also focus on tasks that are actually useful in real-world applications.", "Jamie": "Hmm, that makes a lot of sense. So it's not just about academic exercises, but also about practical applications like sentiment analysis or toxicity detection in social media?"}, {"Alex": "Exactly! IberBench covers 22 task categories, including those you mentioned, as well as summarization, emotion analysis, and even identifying machine-generated text. It uses 101 datasets from evaluation campaigns and recent benchmarks, making it a really comprehensive tool.", "Jamie": "Wow, that's a broad scope! But how do they account for the fact that languages evolve and new datasets keep popping up?"}, {"Alex": "That's a key strength of IberBench: it's designed to be constantly updated and extensible. It enables continual updates and community-driven submissions of new models and datasets, all moderated by a committee of experts. This ensures that the benchmark remains relevant and reflects the current state of the field.", "Jamie": "So, it's a living benchmark, constantly adapting and improving. Who's behind all this work?"}, {"Alex": "IberBench is the work of a team of researchers from Symanto Research, Keepler Data Tech, Universitat Polit\u00e8cnica de Val\u00e8ncia, and the United Nations International Computing Centre, bringing together a range of expertise in NLP and Iberian languages.", "Jamie": "That's a diverse group of institutions! Alright, so they've built this benchmark, but what have they actually *found* by testing these LLMs?"}, {"Alex": "The findings are quite revealing! One key takeaway is that LLMs often perform worse on industry-relevant tasks compared to fundamental ones. This suggests there's still work to be done in adapting these models to practical applications.", "Jamie": "Interesting. So, the AI might be good at basic language understanding, but struggles with real-world stuff like understanding customer sentiment or detecting hate speech?"}, {"Alex": "Precisely! They also found that performance is generally lower for Galician and Basque compared to other Iberian languages. This likely reflects the relative scarcity of training data for those languages.", "Jamie": "Ah, that makes sense. Less data, less accurate models. Were there any specific tasks that the LLMs just couldn't crack?"}, {"Alex": "Yes, some tasks, like lexical borrowing detection \u2013 that's identifying English words used in Spanish \u2013 and machine-generated text detection, remain largely unsolved. The top-performing LLMs barely surpassed a random guesser on those.", "Jamie": "So, the AI is basically just guessing? That's a little concerning. What about the tasks where they performed *better*?"}, {"Alex": "In tasks like sentiment analysis, humor detection, and fake news detection, LLMs did outperform the random baseline, but still fell short of the performance achieved by systems specifically designed for those tasks in shared task competitions.", "Jamie": "So, they're better than random, but not as good as dedicated systems. Is there one model performing far better than others?"}, {"Alex": "The Qwen-2.5 family, particularly the 7B-Instruct model, really stood out. It consistently performed well across different tasks and languages. RigoChat-7b-v2, optimized for Spanish, also did very well.", "Jamie": "So, it seems like the Qwen models are the current champions of Iberian language AI. What's next for IberBench? What do they hope to achieve in the future?"}, {"Alex": "The IberBench team aims to continue adding new datasets and models to the benchmark, ensuring it stays current and relevant. They also want to encourage collaboration within the NLP research community to improve Iberian language technologies.", "Jamie": "And what about addressing those tasks where the models are really struggling, like lexical borrowing detection?"}, {"Alex": "That's a big area for future research. The IberBench results highlight the need for developing new techniques and datasets specifically designed to tackle these more challenging tasks. Perhaps focusing on models specifically designed for code-switching or incorporating more contextual information.", "Jamie": "Code-switching, as in, mixing languages within the same sentence? Is that common in Iberian languages?"}, {"Alex": "Definitely. It's very common, especially in bilingual communities. Recognizing and understanding these patterns is crucial for accurate NLP in those contexts.", "Jamie": "What about those cases where tuning to specific Iberian languages may degrade general Iberian capabilities?"}, {"Alex": "Yes, there's a balancing act between language-specific optimization and general Iberian language capabilities. The findings suggest that over-specialization in a single language can sometimes harm performance in others. Finding the right balance is key.", "Jamie": "Very interesting results! Where do you think the performance on English fits in this landscape?"}, {"Alex": "English performance poses a unique challenge. IberBench data for the English category is collected for machine translation to check the diversity of the models as a source for text to be translated. Also, most models show how hard the task of Machine Generated Text Detection and Attribution is when a human must distinguish from a regular English text", "Jamie": "Is that the end-game for IberBench - improve human performance? To replace human work?"}, {"Alex": "No no! IberBench does not aim to replace humans, but to rather improve human interaction. All models can perform an activity more efficiently than a human; IberBench is there to enhance the abilities of everyone for communication and labor in Iberian languages.", "Jamie": "Well, Alex, I'm excited to see what comes next from IberBench! What are some final thoughts from what you have learned from its creation?"}, {"Alex": "I think the next generation of models must balance between tuning to a specific Iberian language or a general ability to reason over all. We see that when a model is created specifically for languages in the Iberian peninsula may have issues when presented with the variety of Iberian languages that were used to generate the test data for these experiments.", "Jamie": "And does that mean there has been a drop in model quality and effectiveness?"}, {"Alex": "No! It does not! On the contrary, it means the general improvement is steady and sure! It means the future Iberian LLMs will need to be fine-tuned to a larger set of data in order to work on its best with all Iberian peninsular languages", "Jamie": "Amazing! In conclusion, what do we want to give as takeaway to the people here?"}, {"Alex": "So, to wrap it up, IberBench is a crucial new tool for evaluating AI in Iberian languages, highlighting the need for more diverse datasets, improved handling of industry-relevant tasks, and continued research into language-specific optimization. It's a big step forward in ensuring that AI truly understands and serves the hundreds of millions of people who speak these languages. Stay tuned for more updates as the benchmark evolves and new models emerge!", "Jamie": "Great summary, Alex! Thanks for breaking down this fascinating research for us."}]