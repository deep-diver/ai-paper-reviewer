[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A1.T9.2\">\n<tr class=\"ltx_tr\" id=\"A1.T9.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A1.T9.2.1.1\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A1.T9.2.1.2\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.2.1\">#Videos</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A1.T9.2.1.3\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.3.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A1.T9.2.1.4\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.4.1\">#Videos</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A1.T9.2.1.5\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.5.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A1.T9.2.1.6\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.1.6.1\">#Videos</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.1\" style=\"padding:1pt 10.0pt;\">COIN\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Tang et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib53\" title=\"\">2019</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A1.T9.2.2.2\" style=\"padding:1pt 10.0pt;\">151</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.3\" style=\"padding:1pt 10.0pt;\">QV-Highlights\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Lei et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib24\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A1.T9.2.2.4\" style=\"padding:1pt 10.0pt;\">1778</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.5\" style=\"padding:1pt 10.0pt;\">ActivityNet\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Fabian Caba\u00a0Heilbron and Niebles, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib16\" title=\"\">2015</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A1.T9.2.2.6\" style=\"padding:1pt 10.0pt;\">12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.1\" style=\"padding:1pt 10.0pt;\">HD-VILA\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Xue et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib65\" title=\"\">2022</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.3.2\" style=\"padding:1pt 10.0pt;\">695</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.3\" style=\"padding:1pt 10.0pt;\">YouCook2\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Zhou et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib84\" title=\"\">2018</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.3.4\" style=\"padding:1pt 10.0pt;\">710</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.5\" style=\"padding:1pt 10.0pt;\">TVSum\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Song et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib51\" title=\"\">2015</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.3.6\" style=\"padding:1pt 10.0pt;\">10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.1\" style=\"padding:1pt 10.0pt;\">ViTT\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Huang et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib21\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.4.2\" style=\"padding:1pt 10.0pt;\">2000</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.3\" style=\"padding:1pt 10.0pt;\">QuerYD\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Oncescu et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib41\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.4.4\" style=\"padding:1pt 10.0pt;\">566</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.5\" style=\"padding:1pt 10.0pt;\">YouMakeup\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib57\" title=\"\">2019</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.4.6\" style=\"padding:1pt 10.0pt;\">1801</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.1\" style=\"padding:1pt 10.0pt;\">VideoIC\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib56\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.5.2\" style=\"padding:1pt 10.0pt;\">2649</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.3\" style=\"padding:1pt 10.0pt;\">Movie101\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Yue et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib72\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.5.4\" style=\"padding:1pt 10.0pt;\">202</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.5\" style=\"padding:1pt 10.0pt;\">HiREST\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Zala et\u00a0al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2504.17343v1#bib.bib73\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A1.T9.2.5.6\" style=\"padding:1pt 10.0pt;\">469</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.6\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" colspan=\"5\" id=\"A1.T9.2.6.1\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.6.1.1\">Total</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"A1.T9.2.6.2\" style=\"padding:1pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.6.2.1\">11,043</span></td>\n</tr>\n</table>", "caption": "Table 1. Performance comparison on StreamingBench focusing on Real-Time Visual Understanding tasks. Real-Time Visual Understanding encompasses Object Perception (OP), Causal Reasoning (CR), Clips Summarization (CS), Attribute Perception (ATP), Event Understanding (EU), Text-Rich Understanding (TR), Prospective Reasoning (PR), Spatial Understanding (SU), Action Perception (ACP), and Counting (CT). \u201cVTokens(%)\u201d represents the percentage of video tokens remaining after dropping, where 100%percent100100\\%100 % indicates no dropping, and \u219382.6%\u2193absentpercent82.6\\downarrow 82.6\\%\u2193 82.6 % signifies an 82.6% reduction in video tokens. The bold values indicate the best performance and underlined values indicate the second best.", "description": "Table 1 presents a performance comparison of various models on the StreamingBench benchmark, focusing on real-time visual understanding tasks.  The benchmark includes tasks such as object perception, causal reasoning, clip summarization, attribute perception, event understanding, text-rich understanding, prospective reasoning, spatial understanding, action perception, and counting.  The table shows each model's accuracy on each task, along with the number of frames and the percentage of video tokens remaining after any token dropping that was performed.  A 100% value in the 'VTokens(%)' column indicates that no token dropping was done, while a value like \u219382.6% signifies a reduction of 82.6% in the number of video tokens used.  The best performance for each metric is shown in bold, and the second-best performance is underlined. This allows for a direct comparison of different models' efficiency and accuracy in processing streaming video data for real-time comprehension.", "section": "4. Results on Streaming Video Benchmarks"}]