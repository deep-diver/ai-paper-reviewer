[{"figure_path": "https://arxiv.org/html/2504.17343/x1.png", "caption": "Figure 1. This paper presents TimeChat-Online for efficient Streaming Video Understanding\u00a0(Chen et\u00a0al., 2024a). Its core design is the Differential Token Dropping (DTD) module that selectively preserves only significant temporal changes across video streams. The DTD eliminates 82.8% of redundant video tokens without any user-query guidance, while achieving a 1.76\u00d7\\times\u00d7 speedup in response latency and maintaining over 98% of original accuracy. Furthermore, it naturally monitors video scene transitions, facilitating online Proactive Responding.", "description": "This figure showcases TimeChat-Online, a system designed for efficient streaming video understanding.  Its key innovation is the Differential Token Dropping (DTD) module. DTD intelligently identifies and removes redundant visual information in video streams, resulting in an 82.8% reduction in the number of video tokens processed.  This reduction is achieved without relying on user queries or prompts, making the system highly efficient.  Despite the significant reduction in data, TimeChat-Online maintains over 98% of its original accuracy while achieving a 1.76x speedup in response time.  The DTD module also automatically detects scene changes in the video, which enables the system's proactive response feature.", "section": "3 TimeChat-Online Framework"}, {"figure_path": "https://arxiv.org/html/2504.17343/x2.png", "caption": "Figure 2. The core of TimeChat-Online lies in the Differential Token Dropping (DTD) design for efficiently encoding video streams. DTD captures significant temporal changes through three steps: (a) patchifying and encoding dense video frames, (b) calculating static redundancy between temporally-consecutive and spatially-identical video tokens, (c) dropping temporally-redundant video tokens while preserving the (temporal, height, width) positions of remaining tokens. DTD dynamically eliminates visual redundancy in the temporal dimension, yielding an adaptive drop ratio for each frame. During Real-Time Interaction, frames with low drop ratios in the timeline indicate video scene transitions, triggering TimeChat-Online to achieve Proactive Responding at these scene-oriented timestamps.", "description": "This figure illustrates the core mechanism of TimeChat-Online, called Differential Token Dropping (DTD).  DTD efficiently processes video streams by focusing only on significant changes between consecutive frames. The process is broken down into three steps: 1) The video frames are divided into patches, which are then encoded into visual tokens. 2) The algorithm then calculates the redundancy of visually similar patches between consecutive frames. 3) Finally, temporally redundant tokens are dropped, but their spatial and temporal information is preserved. This results in a variable drop rate for each frame, which helps identify significant changes in a video scene, such as scene transitions. These transitions are then used to trigger a proactive response feature in TimeChat-Online, enabling real-time interactions.", "section": "TimeChat-Online Framework"}, {"figure_path": "https://arxiv.org/html/2504.17343/x3.png", "caption": "Figure 3. Video redundancy of different video length on VideoMME\u00a0(Fu et\u00a0al., 2024).", "description": "This figure illustrates how video redundancy varies depending on video length within the VideoMME benchmark (Fu et al., 2024).  The x-axis represents the percentage of video tokens dropped, while the y-axis shows the accuracy.  Separate lines depict the results for short, medium, and long videos.  The plot demonstrates that longer videos exhibit significantly higher redundancy than shorter videos, allowing for a greater reduction in video tokens (higher drop ratio) without a substantial drop in accuracy. This highlights the potential for efficient video processing by exploiting naturally occurring redundancy in longer video content.", "section": "4.3 Results on Offline Long Video Tasks"}, {"figure_path": "https://arxiv.org/html/2504.17343/x4.png", "caption": "Figure 4. Case study of TimeChat-Online on StreamingBench. When a user proposes a question \u201cWhat specifically did the woman in red do?\u201d that can also be answered by the future moments, TimeChat-Online will proactively generate responses at the future trigger time (i.e., the video scene transition timestamps), which are indicated by the frames with low token drop ratios.", "description": "This figure showcases a real-world example of TimeChat-Online's proactive response capability during a streaming video question answering (Streaming VideoQA) task on the StreamingBench benchmark. A user asks, \"What specifically did the woman in red do?\"  The video shows the woman performing several actions over time.  Because the question can't be fully answered using only the currently available video segment, TimeChat-Online proactively generates responses at several points in the future. These future response times (Trigger Times) are cleverly identified by analyzing the Differential Token Drop (DTD) module's output. The DTD module's output curve shows points of low token drop ratios, indicating scene changes in the video stream.  These transitions act as natural triggers for generating answers as new, relevant information becomes available.", "section": "3 TimeChat-Online Framework"}, {"figure_path": "https://arxiv.org/html/2504.17343/x5.png", "caption": "Figure 5. Distribution of video durations across the 11,043 videos in our dataset. The minimum video length in our dataset is 5 minutes.", "description": "This histogram displays the distribution of video lengths within the TimeChat-Online-139K dataset. The x-axis represents the duration of videos, categorized into bins (e.g., \u22646 minutes, >6 minutes, >7 minutes, and so on). The y-axis shows the count or number of videos falling into each duration bin.  The graph visually represents the prevalence of different video lengths in the dataset, highlighting the number of short, medium, and long videos included. The caption indicates that the shortest video in this dataset is 5 minutes long.", "section": "3.3 TimeChat-Online-139K Collection"}, {"figure_path": "https://arxiv.org/html/2504.17343/x6.png", "caption": "(a) Feature-level: \u03c4f\u2062e\u2062a\u2062t=0.4,drop ratio=58.3%formulae-sequencesubscript\ud835\udf0f\ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc610.4drop ratiopercent58.3\\tau_{feat}=0.4,\\text{drop ratio}=58.3\\%italic_\u03c4 start_POSTSUBSCRIPT italic_f italic_e italic_a italic_t end_POSTSUBSCRIPT = 0.4 , drop ratio = 58.3 %", "description": "This figure visualizes the results of applying Differential Token Drop (DTD) with feature-level token dropping to a video from the StreamingBench dataset.  The left panel (a) shows the original video frames. The right panel (b) displays the drop ratio over time, indicating the proportion of tokens removed at each point in the video.  A threshold of \u03c4feat = 0.4 was used, resulting in a 58.3% reduction in the total number of tokens.  The visualization demonstrates how DTD selectively preserves significant temporal changes while eliminating redundant visual content.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x7.png", "caption": "(b) Pixel-level: \u03c4p\u2062i\u2062x\u2062e\u2062l=0.1subscript\ud835\udf0f\ud835\udc5d\ud835\udc56\ud835\udc65\ud835\udc52\ud835\udc590.1\\tau_{pixel}=0.1italic_\u03c4 start_POSTSUBSCRIPT italic_p italic_i italic_x italic_e italic_l end_POSTSUBSCRIPT = 0.1", "description": "Figure 7(b) visualizes the results of pixel-level token dropping with a threshold (\u03c4pixel) of 0.1.  This method focuses on eliminating redundant visual tokens by comparing the pixel-level similarity between consecutive patches within video frames. If the L1 distance between corresponding patches is below the set threshold, the latter patch is deemed redundant and dropped. The image displays the result of this process, highlighting the preserved and dropped tokens to illustrate how the approach selectively removes redundant visual information while maintaining crucial temporal changes.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x8.png", "caption": "Figure 6. Visualization of (a) Feature-level token dropping and (b) Pixel-level token dropping for the video case 752 from StreamingBench.", "description": "This figure visualizes the effects of both feature-level and pixel-level token dropping techniques on video case 752 from the StreamingBench dataset.  It provides a visual comparison of how each method handles redundancy in video frames, illustrating which parts of the video are deemed important enough to retain. Subfigure (a) displays the results of feature-level token dropping, while subfigure (b) shows the results of pixel-level token dropping. The differences highlight the varying approaches to identifying and preserving salient information in video streams.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x9.png", "caption": "(a) Feature-level: \u03c4f\u2062e\u2062a\u2062t=0.4,drop ratio=89.5%formulae-sequencesubscript\ud835\udf0f\ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc610.4drop ratiopercent89.5\\tau_{feat}=0.4,\\text{drop ratio}=89.5\\%italic_\u03c4 start_POSTSUBSCRIPT italic_f italic_e italic_a italic_t end_POSTSUBSCRIPT = 0.4 , drop ratio = 89.5 %", "description": "This figure visualizes the results of applying Differential Token Drop (DTD) with different threshold parameters.  The left-hand side shows the original video frames. The right-hand side shows the frames after applying DTD.  Specifically, (a) demonstrates feature-level DTD, and (b) demonstrates pixel-level DTD.  The drop ratio represents the percentage of video tokens that have been dropped. The results highlight the effectiveness of DTD in reducing visual redundancy and show that feature-level DTD is generally more effective at eliminating visual redundancy compared to pixel-level DTD.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x10.png", "caption": "(b) Pixel-level: \u03c4p\u2062i\u2062x\u2062e\u2062l=0.1subscript\ud835\udf0f\ud835\udc5d\ud835\udc56\ud835\udc65\ud835\udc52\ud835\udc590.1\\tau_{pixel}=0.1italic_\u03c4 start_POSTSUBSCRIPT italic_p italic_i italic_x italic_e italic_l end_POSTSUBSCRIPT = 0.1", "description": "This figure shows the results of pixel-level token dropping with a threshold (\u03c4pixel) of 0.1.  It visually demonstrates how the algorithm selectively removes redundant visual information from a video frame by comparing pixel values between temporally consecutive patches. Patches with pixel-level similarity above the threshold are considered redundant and dropped, while others are preserved. This process effectively reduces the number of video tokens while preserving significant visual content. The figure likely contains a visual representation of the frame before and after this token dropping process, highlighting the removed and retained patches. ", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x11.png", "caption": "Figure 7. Visualization of (a) Feature-level token dropping and (b) Pixel-level token dropping for the video case 671 from StreamingBench.", "description": "This figure shows a comparison of feature-level and pixel-level token dropping methods applied to video case 671 from the StreamingBench dataset.  The visualization helps to understand how these different token dropping strategies affect video encoding. (a) shows feature-level token dropping, where the model retains visually significant features across consecutive frames. (b) demonstrates pixel-level token dropping, which focuses on preserving pixel-level similarity between frames. By comparing the results of both methods, one can better appreciate the impact of different approaches to visual redundancy reduction in video streaming applications.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x12.png", "caption": "(a) Scene Transition Point w/ Trigger Time", "description": "This figure visualizes how video scene transitions are detected using the Differential Token Drop (DTD) method. The top panel (a) shows a specific scene transition point in the video and highlights it as a trigger time.  The trigger time is identified by a low drop ratio in the DTD's drop ratio curve. This signifies a significant visual change between consecutive frames, indicating a change of scene. The bottom panel (b) displays the drop ratio curve throughout the timeline of the video, clearly showcasing the location of trigger times (where the curve dips) corresponding to scene transitions.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x13.png", "caption": "(b) Drop Ratio - Timeline Curve", "description": "This figure shows the drop ratio over time. The drop ratio represents the percentage of video tokens dropped by the Differential Token Drop (DTD) module at each time step.  The x-axis represents the time, and the y-axis represents the drop ratio. The curve visually depicts how the DTD module adapts to the visual redundancy in the video stream by dynamically adjusting the number of tokens dropped.  High points on the curve indicate a larger proportion of tokens being dropped (high redundancy), while low points suggest that fewer tokens are being dropped (low redundancy). This visualization is essential for understanding how the DTD module's performance and efficiency vary over time and its effectiveness at reducing redundant information in streaming video.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x14.png", "caption": "Figure 8. Visualization of monitored Trigger Time via drop ratio curve. The colored highlighted frames correspond to trigger times that reveal video scene transitions. Our model utilizes a temporal patch size of 2.", "description": "This figure visualizes how the TimeChat-Online model identifies scene transitions in a video stream. The key is the 'drop ratio', which represents the percentage of video tokens removed by the Differential Token Drop (DTD) module at each frame.  A low drop ratio indicates a significant change in visual content, suggesting a scene transition.  The figure plots the drop ratio over time, highlighting frames (colored) where the drop ratio falls below a certain threshold (here, 0.6), indicating these are the detected scene transitions. The model uses a temporal patch size of 2 which helps the system to compare consecutive frames effectively. The figure shows that TimeChat-Online can accurately detect these transition points which are used to trigger proactive responses.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x15.png", "caption": "(a) Scene Transition Point w/ Trigger Time", "description": "This figure visualizes how video scene transitions are identified and used for proactive responding in the TimeChat-Online system.  The top panel (a) shows individual frames highlighted based on whether they were identified as a scene transition point. This is determined by the DTD module's drop ratio, with lower drop ratios indicating scene transitions. The bottom panel (b) shows the drop ratio over time, which visually illustrates where the significant temporal changes in the video occur and trigger proactive responses.  The colored highlighted frames correspond to trigger times that reveal video scene transitions.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x16.png", "caption": "(b) Drop Ratio - Timeline Curve", "description": "This figure shows the drop ratio over time. The drop ratio represents the percentage of video tokens dropped by the Differential Token Drop (DTD) module at each time step.  The x-axis represents the time, and the y-axis represents the drop ratio.  The curve visually shows how the DTD module dynamically adjusts the number of tokens dropped based on the visual content of the video.  Low points on the curve indicate significant visual changes, while high points indicate periods of visual redundancy.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x17.png", "caption": "Figure 9. Visualization of monitored Trigger Time via drop ratio curve. The colored highlighted frames correspond to trigger times that reveal video scene transitions. Our model utilizes a temporal patch size of 2.", "description": "Figure 9 visualizes how the TimeChat-Online model identifies scene transitions in streaming videos.  The x-axis represents the time progression of the video, while the y-axis shows the ratio of visual tokens dropped by the Differential Token Dropping (DTD) module.  A lower drop ratio indicates a more significant change in the video's visual content\u2014a scene transition. The colored, highlighted frames along the x-axis directly correspond to these moments of low drop ratio, visually highlighting the model's ability to detect scene transitions using the DTD module.  The graph's smooth curve further emphasizes the continuous monitoring capability of the DTD module in identifying meaningful changes.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x18.png", "caption": "Figure 10. Case study of TimeChat-Online on StreamingBench with drop ratio curve. When a user proposes a question \u201cWhat specifically did the woman in red do?\u201d that can also be answered by the future moments, TimeChat-Online will proactively generate responses at the future trigger time (i.e., the video scene transition timestamps), which are indicated by the frames with low token drop ratios.", "description": "This figure showcases a case study from the StreamingBench dataset, illustrating TimeChat-Online's proactive response capability.  A user asks, \"What specifically did the woman in red do?\"  The video shows the woman performing several actions over time.  Because the question can't be fully answered using only the currently available information, TimeChat-Online uses the drop ratio curve to identify future \"trigger times,\" which signify transitions between video scenes. These transitions are indicated by valleys in the drop ratio curve, where fewer tokens are dropped. The model then generates answers at these trigger times, adding the newly available visual information. The figure visually depicts the frames where these trigger times occur and provides the corresponding answers, thus demonstrating the system's ability to generate answers based on the dynamic flow of information in a streaming video.", "section": "3 TimeChat-Online Framework"}, {"figure_path": "https://arxiv.org/html/2504.17343/x19.png", "caption": "(a) Pixel-level: \u03c4p\u2062i\u2062x\u2062e\u2062l=0.01subscript\ud835\udf0f\ud835\udc5d\ud835\udc56\ud835\udc65\ud835\udc52\ud835\udc590.01\\tau_{pixel}=0.01italic_\u03c4 start_POSTSUBSCRIPT italic_p italic_i italic_x italic_e italic_l end_POSTSUBSCRIPT = 0.01", "description": "This figure visualizes the results of pixel-level token dropping with a threshold (\u03c4pixel) of 0.01. It showcases how the model selectively removes redundant visual tokens in video frames based on pixel-level similarity.  The image likely shows examples of video frames before and after the token dropping process, highlighting the reduction in visual information while preserving essential details.  The specific content shown depends on the visuals in the original figure; it could include images with marked redundant patches or tokens to illustrate the effectiveness of the method.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x20.png", "caption": "(b) Pixel-level: \u03c4p\u2062i\u2062x\u2062e\u2062l=0.05subscript\ud835\udf0f\ud835\udc5d\ud835\udc56\ud835\udc65\ud835\udc52\ud835\udc590.05\\tau_{pixel}=0.05italic_\u03c4 start_POSTSUBSCRIPT italic_p italic_i italic_x italic_e italic_l end_POSTSUBSCRIPT = 0.05", "description": "The figure visualizes the results of pixel-level token dropping with a threshold (\u03c4pixel) set to 0.05.  It shows which visual tokens are retained and which are dropped based on the similarity of pixel values between consecutive frames. This method aims to remove redundant information by preserving only tokens representing significant visual changes.  The image likely displays a comparison between the original video frames and the frames after the application of the pixel-level token dropping algorithm, highlighting the reduced number of tokens while hopefully maintaining crucial visual information.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x21.png", "caption": "(c) Pixel-level: \u03c4p\u2062i\u2062x\u2062e\u2062l=0.1subscript\ud835\udf0f\ud835\udc5d\ud835\udc56\ud835\udc65\ud835\udc52\ud835\udc590.1\\tau_{pixel}=0.1italic_\u03c4 start_POSTSUBSCRIPT italic_p italic_i italic_x italic_e italic_l end_POSTSUBSCRIPT = 0.1", "description": "This figure displays the results of pixel-level token dropping with a threshold of \u03c4pixel=0.1.  It visually demonstrates how the model selectively removes redundant visual tokens from a video frame by comparing the pixel-level similarity between consecutive frames.  Pixels with low similarity (below the threshold) are preserved, while those with high similarity (above the threshold) are dropped, effectively reducing redundancy without losing essential visual information. The image showcases a sample video frame before and after the pixel-level token dropping process, highlighting the tokens retained and the ones removed.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x22.png", "caption": "(d) Feature-level: \u03c4f\u2062e\u2062a\u2062t=0.7subscript\ud835\udf0f\ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc610.7\\tau_{feat}=0.7italic_\u03c4 start_POSTSUBSCRIPT italic_f italic_e italic_a italic_t end_POSTSUBSCRIPT = 0.7", "description": "This figure shows a visualization of the feature-level token dropping method used in the paper.  Different threshold values (\u03c4feat) are used to control how many tokens are dropped, simulating the filtering of less important visual information. The figure demonstrates that by adjusting \u03c4feat, the model can achieve different levels of token reduction, effectively managing visual redundancy in the video.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x23.png", "caption": "(e) Feature-level: \u03c4f\u2062e\u2062a\u2062t=0.6subscript\ud835\udf0f\ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc610.6\\tau_{feat}=0.6italic_\u03c4 start_POSTSUBSCRIPT italic_f italic_e italic_a italic_t end_POSTSUBSCRIPT = 0.6", "description": "This figure is a visualization of the Differential Token Dropping (DTD) method's feature-level token dropping. Specifically, it displays how this technique operates when the feature-level redundancy threshold (\u03c4feat) is set to 0.6.  The image visually represents a set of video frames (or patches) where certain tokens have been dropped, as indicated by the visual representation (likely grayscale or other visual cue).  The dropped tokens are those that are considered redundant according to the algorithm at this threshold. This visualization helps illustrate the effectiveness of the DTD in reducing the number of video tokens while preserving meaningful visual information.", "section": "3.2 Differential Temporal Token Drop"}, {"figure_path": "https://arxiv.org/html/2504.17343/x24.png", "caption": "(f) Feature-level: \u03c4f\u2062e\u2062a\u2062t=0.5subscript\ud835\udf0f\ud835\udc53\ud835\udc52\ud835\udc4e\ud835\udc610.5\\tau_{feat}=0.5italic_\u03c4 start_POSTSUBSCRIPT italic_f italic_e italic_a italic_t end_POSTSUBSCRIPT = 0.5", "description": "This figure visualizes the results of applying feature-level Differential Token Drop (DTD) with a threshold (\u03c4_feat) of 0.5.  It showcases how the algorithm selectively removes redundant visual tokens from a video sequence while preserving important temporal changes. The visualization likely displays a sequence of video frames before and after applying the DTD, allowing comparison of the original visual data and the reduced representation. It demonstrates the effectiveness of DTD in reducing data volume for efficient video processing while maintaining essential visual information.", "section": "3.2 Differential Temporal Token Drop"}]