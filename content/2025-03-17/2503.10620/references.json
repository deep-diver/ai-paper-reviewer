{"references": [{"fullname_first_author": "Duarte Miguel Alves", "paper_title": "TOWER: An open multilingual large language model for translation-related tasks", "publication_date": "2024-01-01", "reason": "This is the base LLM model that SPIRE is built upon, thus crucial for understanding the architecture and pre-training methodology."}, {"fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "publication_date": "2023-01-01", "reason": "Whisper is a strong baseline model for ASR and ST tasks, against which SPIRE's performance is compared."}, {"fullname_first_author": "Lo\u00efc Barrault", "paper_title": "SeamlessM4T-Massively Multilingual & Multimodal Machine Translation", "publication_date": "2023-01-01", "reason": "SeamlessM4T represents a comparable state-of-the-art multimodal model for ASR, MT and ST, serving as a key benchmark for SPIRE."}, {"fullname_first_author": "Changhan Wang", "paper_title": "VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation", "publication_date": "2021-01-01", "reason": "VoxPopuli is one of the three speech corpora used to train k-means, crucial for building DSUs."}, {"fullname_first_author": "Wei-Ning Hsu", "paper_title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units", "publication_date": "2021-01-01", "reason": "HuBERT is leveraged for the k-means clusterization to encode speech."}]}