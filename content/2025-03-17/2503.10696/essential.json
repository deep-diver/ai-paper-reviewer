{"importance": "This paper introduces a novel autoregressive modeling paradigm, addressing limitations in existing visual generation methods and opens avenues for future research in efficient and high-quality image and video synthesis, pushing the boundaries of AI-driven creative tasks. **The NAR's efficiency and quality trade-offs provide valuable insights for researchers seeking to enhance visual content creation.**", "summary": "NAR: Neighboring Autoregressive Modeling for efficient visual generation by locality-preserved, parallel decoding.", "takeaways": ["Introduces Neighboring Autoregressive Modeling (NAR), a novel paradigm for visual generation based on a near-to-far \"next-neighbor prediction\" mechanism.", "Presents dimension-oriented decoding heads, enabling parallel prediction of adjacent tokens and improving generation efficiency.", "Demonstrates superior generation quality and efficiency compared to existing autoregressive methods on image and video generation tasks."], "tldr": "Current autoregressive models use a raster-order paradigm, overlooking spatial/temporal locality in visuals. Tokens correlate more strongly with adjacent ones. To address this, the paper introduces **Neighboring Autoregressive Modeling (NAR)**. It reframes generation as progressive outpainting using a near-to-far \"next-neighbor prediction\" mechanism. Tokens decode based on Manhattan distance from the initial token. \n\nNAR uses dimension-oriented decoding heads for parallel adjacent token prediction. All tokens adjacent to decoded tokens are processed in parallel during inference, cutting model forward steps. Experiments show that **NAR boosts throughput and improves FID/FVD scores for image/video tasks.** It also outperforms models with larger parameter counts while using less training data, showing the approach's efficiency and effectiveness.", "affiliation": "Zhejiang University, China", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.10696/podcast.wav"}