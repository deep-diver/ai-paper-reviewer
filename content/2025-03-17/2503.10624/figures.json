[{"figure_path": "https://arxiv.org/html/2503.10624/x4.png", "caption": "Figure 1: Body Fitting on Clothed Humans. Given 3D clothed humans in any pose and clothing, ETCH accurately fits the body underneath. Our key novelty is modeling cloth-to-body SE(3)-equivariant \\gradientRGBtightness vectors254,217,118192,50,26 for clothed humans, abbreviated as ETCH, which resembles \u201cetching\u201d from the outer clothing down to the inner body. The ground-truth body is shown in blue, our fitted body in green, and ground-truth markers as  .", "description": "Figure 1 showcases the effectiveness of the ETCH method in fitting 3D body meshes to clothed humans across various poses and clothing styles.  The images display multiple examples where the algorithm accurately estimates the underlying body shape despite the presence of clothing.  The ground truth body is represented in blue, the ETCH-fitted body in green, and ground truth markers are shown in black. The key innovation of ETCH, as highlighted in the caption, is the use of SE(3)-equivariant tightness vectors to model the cloth-to-body relationship, allowing for robust and accurate fitting even in challenging scenarios.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10624/x5.png", "caption": "Figure 2: Registration vs. Fitting. Though both registration and fitting involve placing body inside clothing, \u201cregistration\u201d, like NICP\u00a0[41], focuses on matching the outer surface, whereas \u201cfitting\u201d emphasizes aligning with the underlying body, making it more robust to clothing variations.", "description": "Figure 2 illustrates the core difference between surface registration and body fitting in the context of 3D clothed humans.  Surface registration techniques, exemplified by NICP [41], primarily focus on aligning the outer surface of the clothing with a template mesh.  This approach is sensitive to clothing variations as the outer clothing shape influences the final registration.  In contrast, body fitting methods prioritize aligning the underlying body shape with the template, resulting in a more robust solution that is less affected by diverse clothing styles and poses. The figure visually demonstrates the results of both approaches, highlighting the improved accuracy and robustness of body fitting.", "section": "2. Related Work"}, {"figure_path": "https://arxiv.org/html/2503.10624/x7.png", "caption": "Figure 3: Terminology of Tightness-Vector and Marker-Confidence. We illustrate the key components used for data preparation: 1) Tightness Vectors \ud835\udc15\ud835\udc15\\mathbf{V}bold_V, which connect the outer surface points with underneath body, and transmitting 2) Marker-based Labels \ud835\udc0b\ud835\udc0b\\mathbf{L}bold_L and Confidence \ud835\udc02\ud835\udc02\\mathbf{C}bold_C. We also provide a 2D illustration that unifies these terms together. Sparse markers as  , and \\gradientRGBconfidence bar242,171,8105,41,100 indicates the geodesic distance to the closest marker.", "description": "Figure 3 illustrates the key components used for preparing the data to train the ETCH model.  It shows how the model learns to map the outer surface of clothing to the underlying body.  The figure highlights three key elements: 1) Tightness Vectors (V): These vectors connect points on the outer clothing surface to corresponding points on the underlying body surface, representing the displacement caused by the clothing.  The magnitude of these vectors encodes how tightly the garment fits the body.  2) Marker-based Labels (L):  These labels assign each point on the inner body surface to one of a set of predefined sparse markers on the body. These markers act as reference points for the body's shape. 3) Confidence (C): This value represents the uncertainty or confidence associated with the tightness vector for each point. A confidence bar visually represents the geodesic distance (shortest path along the surface) from the point on the inner body to the nearest sparse marker, indicating the level of certainty in the mapping.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10624/x8.png", "caption": "Figure 4: SO(3) Equivariant Pose vs. Tightness. Rainbow circle is the feature \u2131\u2062(\ud835\udc17)\u2131\ud835\udc17\\mathcal{F}(\\mathbf{X})caligraphic_F ( bold_X ), for articulated SO(3)-equiv, \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T denotes approximate rigid transformation of body part, while for our case, where the clothing roughly deforms with human poses, it refers to the tightness vector rotation.", "description": "This figure illustrates the difference between articulated SO(3) equivariance, used in methods like ArtEq, and the local SO(3) equivariance used in ETCH.  In articulated SO(3) equivariance, a rigid transformation (denoted by \\(\\mathcal{T}\\)) is applied to a body part, resulting in a consistent transformation of its features.  In contrast, ETCH's local SO(3) equivariance focuses on the tightness vector, which reflects the relationship between cloth and body.  The tightness vector's direction changes when the pose changes, but its overall behavior is similar due to its approximate equivariance, rather than a precise rigid transformation.  The rainbow circle represents the feature vector \\(\\mathcal{F}(\\mathbf{X})\\) showing the multi-dimensional features extracted from the point cloud.", "section": "3. Method"}]