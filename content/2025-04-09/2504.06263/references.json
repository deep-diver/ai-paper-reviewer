{"references": [{"fullname_first_author": "Shuai Bai", "paper_title": "Qwen2.5-vl technical report", "publication_date": "2025-02-13", "reason": "This paper is important because OmniSVG is built on top of Qwen2.5-VL model."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important because it establishes the baseline for vision-language pre-training."}, {"fullname_first_author": "Ajay Jain", "paper_title": "Vectorfusion: Text-to-svg by abstracting pixel-based diffusion models", "publication_date": "2023-01-01", "reason": "This paper is one of the first to tackle text-to-SVG generation, providing a baseline comparison for OmniSVG."}, {"fullname_first_author": "Junnan Li", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "publication_date": "2023-01-01", "reason": "This paper is important because the captions are generated by BLIP-2, an off-the-shelf VLM."}, {"fullname_first_author": "Tzu-Mao Li", "paper_title": "Differentiable vector graphics rasterization for editing and learning", "publication_date": "2020-01-01", "reason": "This paper is important because DiffVG enables end-to-end differentiability in vector graphics rasterization."}]}