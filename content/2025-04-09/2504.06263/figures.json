[{"figure_path": "https://arxiv.org/html/2504.06263/x2.png", "caption": "Figure 1: \nHighlighted features of OmniSVG. OmniSVG is capable of autoregressively generating high-quality SVGs across a wide spectrum of complexity \u2014 from simple icons to intricate anime characters. It demonstrates remarkable versatility through multiple generation modalities, including Text-to-SVG, Image-to-SVG, and Character-Reference SVG, making it a powerful and flexible solution for diverse creative tasks.", "description": "OmniSVG is a versatile model capable of generating high-quality Scalable Vector Graphics (SVGs) with varying complexity, from simple icons to intricate anime characters.  It achieves this through multiple generation modalities: Text-to-SVG, Image-to-SVG, and Character-Reference SVG. This flexibility makes it a powerful tool for various creative applications.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.06263/x8.png", "caption": "Figure 2: Overview of OmniSVG. OmniSVG\u00a0is built on a pre-trained vision-language model Qwen2.5-VL and incorporates an SVG tokenizer. The model tokenizes both text and image inputs as prefix tokens, while the SVG tokenizer encodes vector graphics commands into a unified representation space.", "description": "OmniSVG, a novel scalable vector graphics (SVG) generation model, leverages a pre-trained vision-language model (Qwen-2.5-VL) and a custom SVG tokenizer.  The architecture processes both text and image inputs, tokenizing them as prefixes. These prefixes are then concatenated with SVG commands (also tokenized) to create a unified input representation for the Qwen-2.5-VL model. The model then generates high-quality SVG outputs. This unified approach allows OmniSVG to effectively handle diverse input modalities and complexities, enabling various SVG generation tasks.", "section": "3. MMSVG-2M"}, {"figure_path": "https://arxiv.org/html/2504.06263/x9.png", "caption": "(a) Training PPL for our models.", "description": "This figure shows the training perplexity (PPL) of the OmniSVG models during training.  The training perplexity is a measure of how well the model predicts the next token in a sequence. A lower perplexity indicates better performance. The plot shows the perplexity decreasing as the number of processed tokens during training increases, suggesting that the model is learning and improving its ability to generate SVGs.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.06263/x10.png", "caption": "(b) Validation PPL for our models.", "description": "The figure shows the validation perplexity (PPL) results for different OmniSVG models.  Validation perplexity is a metric used to evaluate how well a language model predicts unseen data; lower values indicate better performance. The x-axis represents the number of processed tokens (in billions) during training, and the y-axis represents the validation perplexity.  The plot illustrates how the validation perplexity changes as the models are trained on a larger dataset (more tokens). Multiple lines are shown, each corresponding to an OmniSVG model with a different number of parameters (model size). This allows for a comparison of how model size impacts performance on unseen data.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2504.06263/x11.png", "caption": "Figure 3: Training and Validation Perplexity (PPL) for OmniSVG Models. We train all the models from scratch on 250 billion tokens. We observe that the performance grows with model sizes.", "description": "This figure displays the training and validation perplexity (PPL) for different sized OmniSVG models.  The x-axis shows the number of tokens processed (in billions) during training, and the y-axis represents the perplexity. Two separate lines are plotted: one for training perplexity and one for validation perplexity.  Both lines show a decreasing trend as the number of training tokens increases, indicating improved model performance with more training data. Notably, the larger models (as indicated by color/line style) exhibit lower perplexity, demonstrating that model performance improves with increased model size.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.06263/x12.png", "caption": "Figure 4: Qualitative comparison with SOTA methods on Text-to-SVG task. We compare the propose method with SOTA Text-to-SVG methods on our evaluation benchmarks, namely Icon, Illustration and Character. The proposed method outperforms existing state-of-the-art approaches in both instruction-following and the aesthetic quality of the generated SVGs.", "description": "Figure 4 presents a qualitative comparison of OmniSVG's Text-to-SVG capabilities against other state-of-the-art methods.  The comparison focuses on three benchmark categories: Icons, Illustrations, and Characters, each representing a different level of complexity in SVG generation. For each category, sample text prompts were used to generate SVGs using OmniSVG and competing methods.  The figure visually showcases the SVG outputs, allowing for a direct comparison of the accuracy with which each method followed the instructions (instruction-following) and the overall visual appeal and quality of the generated images (aesthetic quality). OmniSVG consistently produces superior results in both instruction-following and aesthetic quality across all three benchmark categories.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.06263/x13.png", "caption": "Figure 5: Qualitative comparison with SOTA methods on Image-to-SVG task. We compare the propose method with SOTA Image-to-SVG methods on our evaluation benchmarks. Despite generating plausible results on simple icon samples, optimization based methods like DiffVG\u00a0[25] and LIVE\u00a0[30] tend to output artifacts on complex images. GPT-4o\u00a0[18] is only able to generate icon-level SVG even given the complex input image. StarVector\u00a0[37] is able to generate SVG for the input icon image. However, when inputed the illustration or more complex character image, StarVector fails to generate SVGs. Please zoom-in for more details.", "description": "Figure 5 presents a qualitative comparison of various state-of-the-art (SOTA) image-to-SVG generation methods.  The figure showcases the performance of these methods across three different image complexities: icons, illustrations, and character images. The results reveal that while optimization-based methods like DiffVG and LIVE perform well on simpler icon images, they often produce unsatisfactory artifacts when applied to more intricate illustrations or character images.  In contrast, the GPT-4o model can only generate SVGs at the icon level of complexity, even when provided with complex input images.  StarVector demonstrates some success with icon images, but it consistently fails to produce satisfactory results for illustrations and character images.  This figure highlights the limitations of existing methods and emphasizes the superior performance of the proposed method (OmniSVG) in handling complex image-to-SVG tasks.", "section": "5.2 Qualitative Evaluations"}, {"figure_path": "https://arxiv.org/html/2504.06263/x14.png", "caption": "Figure 6: Generated SVG with Character-Reference (CRef) by OmniSVG. By training on MMSVG-Character with natural character image and SVG pair data, OmniSVG is capable of generating character SVGs through image references.", "description": "This figure showcases OmniSVG's capability to generate character-specific SVGs using image references.  The model was trained on the MMSVG-Character dataset, which contains pairs of images depicting characters and their corresponding SVG representations.  As shown, given a reference image, OmniSVG can accurately generate a new SVG of a similar character in a similar style, demonstrating its ability to learn and apply stylistic characteristics from example data.", "section": "5.2.2. Qualitative Evaluations"}, {"figure_path": "https://arxiv.org/html/2504.06263/x15.png", "caption": "Figure 7: Qualitative study on parametrization. Ablation studies on color parametrization (abbreviated as param.) and coordinate (abbreviated ad coord.) paramterization are conducted.", "description": "This figure displays the results of an ablation study on the effectiveness of different parametrization methods for SVG generation.  The study compares four variations:  using only color parameters, only coordinate parameters, neither color nor coordinate parameters, and using both color and coordinate parameters.  Each variation is tested with the same prompt, and the resulting generated SVG images are shown for comparison. The goal was to determine the optimal parametrization strategy for generating high-quality SVGs.", "section": "5.3. Ablation studies"}, {"figure_path": "https://arxiv.org/html/2504.06263/x16.png", "caption": "Figure 8: Illustration of the SVG generation capabilities of OmniSVG.", "description": "Figure 8 presents a comprehensive visual showcase of OmniSVG's capabilities in generating diverse and intricate SVG graphics across various categories.  The figure is structured into three main sections: Icons, Illustrations, and Characters. Each section displays a variety of SVG images, demonstrating the model's ability to generate high-quality results with varying levels of complexity and detail, from simple, stylized icons to more elaborate illustrations and detailed character designs. This figure highlights the versatility and effectiveness of the OmniSVG model in producing high-fidelity SVG outputs for a wide range of applications and artistic styles.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.06263/x17.png", "caption": "Figure 9: Limitation of OmniSVG on Image-to-SVG Task. OmniSVG can successfully generate vector style images, while fail to fit natural images.", "description": "Figure 9 demonstrates the limitations of OmniSVG when applied to the image-to-SVG task.  While OmniSVG excels at generating vector-style graphics, it struggles to accurately represent the nuances and complexities of natural photographs or realistic images.  The figure visually compares the outputs of OmniSVG with the input images, highlighting the differences and illustrating that OmniSVG produces vectorized renderings that do not capture the subtleties of texture, lighting, and shading present in natural scenes.", "section": "5.2.2 Qualitative Evaluations"}, {"figure_path": "https://arxiv.org/html/2504.06263/extracted/6346030/files/wordcloud.png", "caption": "Figure 10: Samples from MMSVG-2M dataset. The proposed MMSVG-2M dataset can be separated into three subset, namely Icon, Illustration and Character. Samples from Icon, Illustration and part of Character subsets are downloaded from Internet. Another part of Character subset is generated by our data creation pipeline, which can provide image and SVG pairs for image prompting task.", "description": "Figure 10 showcases examples from the MMSVG-2M dataset, a large-scale collection of scalable vector graphics (SVGs).  The dataset is divided into three subsets: Icons, Illustrations, and Characters.  The Icons and Illustrations subsets, along with a portion of the Character subset, were sourced from publicly available online resources.  The remaining portion of the Character subset was created using a custom data generation pipeline. This pipeline is particularly valuable because it generates paired image and SVG data, which is crucial for training models on image-to-SVG tasks.", "section": "3. MMSVG-2M"}]