{"references": [{"fullname_first_author": "Ming Li", "paper_title": "Controlnet++: Improving conditional controls with efficient consistency feedback", "publication_date": "2025-01-01", "reason": "It explores improvements to conditional controls with efficient consistency feedback, relevant for the paper's focus on improving control and performance."}, {"fullname_first_author": "Zhimin Li", "paper_title": "Hunyuan-dit: A powerful multi-resolution diffusion transformer with fine-grained chinese understanding", "publication_date": "2024-05-08", "reason": "Hunyuan-dit introduces a powerful multi-resolution diffusion transformer with fine-grained Chinese understanding, important for Seedream 2.0's Chinese language focus."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This foundational work on T5 is highly relevant due to the adoption of the ByT5 model, exploring transfer learning limits with a unified text-to-text transformer which influences architecture."}, {"fullname_first_author": "Jiahui Yu", "paper_title": "Scaling autoregressive models for content-rich text-to-image generation", "publication_date": "2022-06-01", "reason": "Scaling autoregressive models for content-rich text-to-image generation explores improving image generation by scaling autoregressive models, and is important for the Seedream 2.0's overall architecture"}, {"fullname_first_author": "Yuxi Ren", "paper_title": "Hyper-sd: Trajectory segmented consistency model for efficient image synthesis", "publication_date": "2025-01-01", "reason": "It introduces a trajectory segmented consistency model for efficient image synthesis, and is critical due to the paper's section on model acceleration."}]}