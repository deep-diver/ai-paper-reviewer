[{"figure_path": "https://arxiv.org/html/2503.08685/x1.png", "caption": "Figure 1: \nImage reconstruction using our structured visual tokenization approach, which uniquely enables decoding at any token count. Each column shows reconstructions resulting from progressively increasing the number of tokens, from a single token to 256 tokens.\nUnlike conventional tokenizers that require a fixed number of tokens for meaningful decoding, our method ensures that each token incrementally refines the image, with earlier tokens capturing the most salient features and later ones adding finer details.\nThis demonstrates the flexibility and effectiveness of our approach in producing coherent images even with very few tokens (view more in Fig.\u00a017 in the Appendix).", "description": "This figure demonstrates image reconstruction using a novel structured visual tokenization approach. Unlike traditional methods requiring a fixed number of tokens for decoding, this approach allows decoding with any number of tokens.  Each column displays reconstructions with an increasing number of tokens (1 to 256), illustrating how each added token incrementally refines the image. Early tokens capture the most prominent features, while later tokens add finer details. This showcases the method's flexibility and effectiveness in generating coherent images even from very limited token input.  For more examples, see Figure 17 in the Appendix.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.08685/x2.png", "caption": "(a) \nSemantic-spectrum coupling. Comparison of the frequency-power spectra for different tokenizers. Here, we decompose the tokens from the tokenizers to demonstrate their contribution to the spectrum of the generated image.\nThe VQ-VAE tokenizer\u00a0[48] is decomposed by performing PCA in its latent token space, and the 1D TiTok\u00a0[60] is decomposed by replacing all but the first k\ud835\udc58kitalic_k tokens with a mean token.\nFor Semanticist, on the other hand, we can clearly see that with any number of tokens, the spectrum remains closely matched with the original image, demonstrating that Semanticist can decouple semantics and spectrum in its tokenization process.", "description": "Figure 2(a) compares the frequency-power spectrum of images generated by three different visual tokenizers: VQ-VAE, TiTok, and Semanticist.  The spectrum shows the distribution of power across different frequencies, reflecting the balance between low-level details (high frequencies) and high-level semantic content (low frequencies).  In VQ-VAE, PCA is used to decompose the latent tokens, while in TiTok, all but the first k tokens are replaced by the mean token to analyze the spectrum. Semanticist shows the spectral profile consistently matches the ground truth image regardless of the number of tokens used. This demonstrates that Semanticist successfully decouples semantic and spectral information during tokenization, unlike other methods where semantic and spectral information are entangled.", "section": "2. Spectrum analysis and the PCA-like structure of our tokenizer"}, {"figure_path": "https://arxiv.org/html/2503.08685/x3.png", "caption": "(b) Our tokenizer decomposes the image into visual concepts following a PCA-like coarse-to-fine structure where first few tokens capture most semantic information and the rest refine the details.", "description": "This figure illustrates how the proposed tokenizer breaks down an image into a sequence of visual tokens.  It highlights the tokenizer's ability to capture the most important semantic information in the initial tokens, with subsequent tokens adding finer details. This 'coarse-to-fine' approach, mimicking the principle component analysis (PCA), allows for efficient and effective image representation using a relatively small number of tokens.  The PCA-like structure means the initial tokens represent the most significant aspects of the image, while later tokens add increasingly less significant details.", "section": "4. SEMANTICIST Architecture"}, {"figure_path": "https://arxiv.org/html/2503.08685/x4.png", "caption": "Figure 2: Spectrum analysis and the PCA-like structure of our tokenizer.", "description": "This figure compares the frequency-power spectra of different visual tokenizers to illustrate the concept of 'semantic-spectrum coupling' and to showcase the PCA-like structure of the proposed SEMANTICIST tokenizer.  Subfigure (a) displays the spectra for VQ-VAE (decomposed using PCA), TiTok (decomposed by replacing all but the first k tokens with a mean token), and SEMANTICIST. It highlights how SEMANTICIST uniquely maintains a consistent spectrum profile across various token counts, unlike others which show coupling between semantic content and low-level spectral details. Subfigure (b) visually demonstrates the SEMANTICIST tokenizer's coarse-to-fine tokenization process, illustrating how it decomposes an image into visual concepts, where initial tokens capture semantic information and subsequent tokens add finer details, mirroring the PCA-like structure.", "section": "2. Related Work"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/spectral_titok_ours.jpg", "caption": "Figure 3: \nSemanticist tokenizer architecture.\nThe ViT encoder resamples the 2D image patch tokens into a 1D causal sequence of concept tokens.\nThese concept tokens are then used as conditions to the DiT decoder to reconstruct the original image.\nTo induce a PCA-like structure in the concept tokens, we apply nested CFG.", "description": "The SEMANTICIST tokenizer uses a Vision Transformer (ViT) encoder to convert 2D image patches into a 1D sequence of concept tokens.  This 1D sequence is designed to have a PCA-like structure, meaning that the first few tokens capture the most important semantic information, while subsequent tokens add finer details. Nested classifier-free guidance (CFG) is applied to enforce this structure during training.  Finally, these concept tokens act as conditioning inputs for a Diffusion Transformer (DiT) decoder which reconstructs the original image. The figure illustrates the flow of information from the 2D image input through the encoder and decoder stages. The PCA-like structure of the output is a key feature of the SEMANTICIST design.", "section": "4. SEMANTICIST Architecture"}, {"figure_path": "https://arxiv.org/html/2503.08685/x5.png", "caption": "Figure 4: The explained variance ratio from Semanticist\u2019s PCA-like structure and the linear probing accuracy on the tokens.", "description": "This figure displays two line graphs, showcasing the relationship between the number of tokens and two key metrics: explained variance ratio and linear probing accuracy. The explained variance ratio, derived from Semanticist's PCA-like structure, demonstrates the decreasing proportion of variance explained by each subsequent token.  This indicates that the model prioritizes salient features in the initial tokens. The linear probing accuracy graph shows the classification accuracy achieved when using only a subset of the tokens as input features for a linear classifier. The downward trend suggests that while early tokens capture essential semantic information, later tokens contribute increasingly less to classification accuracy. The combined graphs illustrate Semanticist's ability to efficiently encode visual information using a structured and interpretable token representation.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/ar_examples.jpg", "caption": "Figure 5: Reconstructed images and their corresponding power-frequency plots, illustrating semantic-spectrum coupling. Each column shows reconstructions using only the first k\ud835\udc58kitalic_k tokens, increasing from left to right, alongside a plot of the reconstructed image\u2019s frequency power (blue) overlaid on the ground-truth (red) image.", "description": "This figure visually demonstrates the concept of \"semantic-spectrum coupling.\"  It shows a series of reconstructed images generated using progressively more tokens from a visual tokenizer. Each image is accompanied by a power-frequency plot. The plot displays the power distribution in the frequency domain for the generated image (blue) overlaid on the plot of the ground-truth image (red). As more tokens are used (moving from left to right), the reconstructed image becomes more detailed and accurate, and the blue line on the power spectrum plot more closely matches the red line. This demonstrates how the model's earlier tokens capture high-level semantic information, while later tokens add finer details, highlighting the way semantic information (represented by the images themselves) and low-level spectral details are entangled in the tokens. The difference between the blue and red lines show how the model does not initially capture low-level information with only a few tokens, but as more tokens are provided, the reconstruction matches the original better.", "section": "5.4 Semantic-spectrum Coupling"}, {"figure_path": "https://arxiv.org/html/2503.08685/x6.png", "caption": "Figure 6: Scaling behavior of different sized DiT decoder (qualitative results can be found in Fig.\u00a014 in the Appendix).", "description": "Figure 6 illustrates how the reconstruction quality of the model scales with different decoder sizes.  It shows that, as the size of the DiT decoder increases, the reconstruction fidelity (measured by rFID) improves, particularly with fewer tokens. This demonstrates the scaling behavior of the model and its ability to produce high-quality reconstructions even with compact representations and limited computation.", "section": "5. Ablation Study"}, {"figure_path": "https://arxiv.org/html/2503.08685/x7.png", "caption": "Figure 7: Examples of the intermediate generation results of \u03f5italic-\u03f5\\epsilonitalic_\u03f5LlamaGen-L trained on Semanticist tokens (see more from Fig.\u00a018).", "description": "This figure displays a series of images demonstrating the iterative generation process of the LlamaGen-L model.  Specifically, it shows how the model progressively refines an image from a very basic initial representation to a final, detailed image. Each image in the sequence represents a step in this process, illustrating the gradual addition of details and fine-grained features as the model iterates.  These intermediate stages offer insight into the model's internal workings and the manner in which it constructs complex visual scenes from a sequence of tokens generated by the Semanticist tokenizer.  More examples are available in Figure 18.", "section": "5. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/x8.png", "caption": "Figure 8: The preference score from the human perception test, all models and test configurations obtained a score close to 0.5, indicating Semanticist can encode image as effectively as how human language encodes the image.", "description": "A human perception test was conducted to evaluate Semanticist's ability to encode images effectively, similar to how human language encodes images. Participants were shown images reconstructed from either Semanticist or a distractor model with varying reveal times (100ms, 200ms, 300ms). They chose the image that best matched the original.  The results show that for all tested token dimensions, Semanticist consistently achieved preference scores close to 0.5, indicating its capacity to capture important image features comparable to human language models.", "section": "D. Additional Experiment Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/x9.png", "caption": "Figure 9: CLIP zero-shot accuracy on reconstructed images.", "description": "This figure shows the zero-shot classification accuracy of a pre-trained CLIP model on images reconstructed using the SEMANTICIST tokenizer.  The x-axis represents the number of tokens used for reconstruction, while the y-axis shows the CLIP accuracy.  Different lines represent different token dimensions (e.g., d16x256, d64x64, etc.), indicating how the dimension of each token affects the reconstruction quality and subsequent classification performance. The results demonstrate that higher accuracy is achieved with more tokens and with higher dimensional tokens. A ground truth image is also included for reference.", "section": "D.2 Zero-Shot CLIP on Reconstructed Images"}, {"figure_path": "https://arxiv.org/html/2503.08685/x10.png", "caption": "Figure 10: Frequency-power spectra of Titok decomposed with PCA at feature dimensions. The learning of semantic contents and spectral information are coupled.", "description": "This figure displays a frequency-power spectrum analysis of the TiTok tokenizer's latent space after Principal Component Analysis (PCA) decomposition.  Each sub-figure shows the power spectrum at different levels of feature decomposition. The key observation is that semantic information (high-level visual concepts) and spectral information (low-level details like texture and frequency patterns) are strongly coupled within the TiTok tokenization process.  This coupling indicates that TiTok's tokens don't effectively disentangle these different levels of image information, which can limit its interpretability and downstream performance.", "section": "D.3. Semantic Spectrum Coupling Effect Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_dim_comparison.jpg", "caption": "Figure 11: Ablation on the use of REPA (with d64\u00d7\\times\u00d764 concept tokens, DiT-L/2 decoder, see qualitative results in Fig.\u00a016). REPA improves the information density in preceding tokens.", "description": "This ablation study investigates the impact of the REPA (Representation Alignment for Generation) regularization technique on the SEMANTICIST model's performance.  The experiment uses 64x64 dimensional concept tokens and a DiT-L/2 decoder.  The figure compares the reconstruction performance (measured by rFID score on ImageNet 50K validation set) with and without REPA regularization, showing different numbers of tokens used. The results demonstrate that REPA enhances the information density of the initial tokens, leading to better reconstruction quality, especially when fewer tokens are used.", "section": "D.4. Additional Ablation Study"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_scale.jpg", "caption": "Figure 12: Reconstruction performance of different encoder configurations on ImageNet val 50K benchmark. A larger number of lower-dimensional tokens is more friendly for reconstruction tasks.", "description": "This figure displays a comparison of reconstruction performance using different encoder configurations on the ImageNet validation set (50K images).  The x-axis represents the number of tokens used for reconstruction, while the y-axis shows the reconstruction performance, likely measured by a metric like FID (Fr\u00e9chet Inception Distance) or PSNR (Peak Signal-to-Noise Ratio). Different curves represent different encoder configurations, varying the dimensionality of the tokens (e.g., 16, 32, 64, 256 dimensions). The key takeaway is that using a larger number of lower-dimensional tokens results in better reconstruction quality. This suggests that a strategy with more, less complex tokens is more effective for image reconstruction than fewer, highly complex tokens.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_xl_cfg.jpg", "caption": "Figure 13: Qualitative results of different token dimensions. Higher dimensional tokens encode more information, and lower dimensional tokens achieve clearer semantic decoupling and achieve better reconstruction.", "description": "This figure displays a qualitative comparison of image reconstruction using different token dimensions within the SEMANTICIST model.  The results showcase how higher dimensional tokens can encode more visual information, leading to more detailed reconstructions. Conversely, lower dimensional tokens demonstrate improved semantic decoupling (separation of semantic content and lower-level details), resulting in cleaner and potentially more interpretable reconstructions, even with fewer tokens used in the reconstruction process.", "section": "D.5 Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_64dim_repa.jpg", "caption": "Figure 14: Qualitative results of different DiT decoder scales (DiT-B/2, DiT-L/2, and DiT-XL/2) with d16\u00d7\\times\u00d7256 tokens. The quality of images generated with fewer tokens improves consistently as the decoder scales up.", "description": "This figure visualizes the impact of different DiT decoder scales (DiT-B/2, DiT-L/2, and DiT-XL/2) on image reconstruction quality using 16-dimensional tokens (d16x256).  Across various token counts (1, 2, 4, 8, 16, 32, 64, 128, 256),  it demonstrates how image quality improves as the decoder size increases.  Even with a small number of tokens, larger decoders generate more realistic and detailed images, highlighting the effectiveness of scaling up the decoder for improved reconstruction performance.", "section": "D.5 Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_xl_other.jpg", "caption": "Figure 15: Qualitative results of different CFG guidance scales for DiT decoder, which clearly controls image aesthetics.", "description": "This figure displays a comparison of image reconstruction results from a diffusion model's decoder, using varying classifier-free guidance (CFG) scales.  The results show that adjusting the CFG scale significantly affects the generated image's aesthetic qualities, demonstrating its effectiveness in controlling visual style and details.  Each row shows the progression of image generation with increasing numbers of tokens for a given CFG scale, allowing for a clear visual analysis of its impact. The results highlight how CFG influences the generation process, offering a technique for fine-tuning the visual style of the output images.", "section": "D.5 Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/ar_more.jpg", "caption": "Figure 16: Qualitative results on effects of REPA (with d64\u00d7\\times\u00d764 concept tokens). Instead of improving final reconstruction much, the benefit of REPA is mainly attributed to more faithful semantics in intermediate results.", "description": "This figure presents a qualitative comparison of image reconstruction results obtained with and without the REPA (Regularized Exponential Moving Average) technique.  Using d64x64 concept tokens, the images are reconstructed using varying numbers of tokens. The results show that while REPA doesn't significantly improve the final reconstruction quality (the final images on the rightmost columns look similar), it notably enhances the semantic fidelity of the intermediate results (images in the earlier columns). In other words, even when using a small number of tokens, the images generated with REPA better capture the essential semantic content of the scene, leading to more meaningful intermediate steps in the reconstruction process.", "section": "D.5 Qualitative Results"}]