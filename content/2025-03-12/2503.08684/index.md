---
title: "Perplexity Trap: PLM-Based Retrievers Overrate Low Perplexity Documents"
summary: "PLM retrievers overrate low-perplexity docs, causing source bias. This paper reveals the causal effect & offers a fix!"
categories: ["AI Generated", "ü§ó Daily Papers"]
tags: ["Natural Language Processing", "Information Extraction", "üè¢ Renmin University of China",]
showSummary: true
date: 2025-03-11
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2503.08684 {{< /keyword >}}
{{< keyword icon="writer" >}} Haoyu Wang et el. {{< /keyword >}}
 
{{< keyword >}} ü§ó 2025-03-12 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2503.08684" target="_self" >}}
‚Üó arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2503.08684" target="_self" >}}
‚Üó Hugging Face
{{< /button >}}



<audio controls>
    <source src="https://ai-paper-reviewer.com/2503.08684/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

Previous studies have shown that PLM-based retrieval models favor LLM-generated content, even when their semantic quality is comparable to human-written ones. This is known as source bias, which hurts the information access ecosystem.  However, the reasons for this bias were not clear. This paper explains information retrieval with a causal graph, showing that PLM retrievers use perplexity features for relevance, resulting in source bias by favoring documents with low perplexity.  Theoretical analysis showed the positive correlation between gradients in language modeling and retrieval tasks.



Based on the analysis, the authors suggest a causal inference-time debiasing method, called Causal Diagnosis and Correction (CDC).  CDC identifies the bias effect of perplexity and separates it from the overall relevance score. Experiments across three domains showed that CDC is effective at debiasing, **highlighting the validity of the explanatory framework**. The results showed that PLM-based retrievers assign higher relevance scores to documents with lower perplexity because these models have gradients of MLM and IR loss functions, leading to bias.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} PLM-based retrievers causally assign higher relevance scores to documents with lower perplexity, leading to source bias. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} The effect of perplexity in PLM-based retrievers is due to the positive correlation between objective gradients of retrieval and language modeling. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} The proposed Causal Diagnosis and Correction (CDC) method effectively counteracts the biased effect of perplexity, demonstrating effectiveness in eliminating source bias. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This paper reveals a critical source of bias in PLM-based retrievers, offering a novel causal-based debiasing method, **enhancing the fairness and reliability of information retrieval** and inspiring new research directions in mitigating AI-driven biases.

------
#### Visual Insights



![](https://arxiv.org/html/2503.08684/x1.png)

> üîº The figure shows the perplexity and estimated relevance scores for the DL19 dataset, where documents are generated by an LLM with varying sampling temperatures.  The x-axis represents the sampling temperature, while the y-axis shows the perplexity and estimated relevance scores.  It demonstrates the negative correlation between perplexity and estimated relevance scores, indicating that lower perplexity documents tend to receive higher estimated relevance scores. This supports the paper's argument that low-perplexity documents are overestimated by PLM-based retrievers.
> <details>
> <summary>read the caption</summary>
> (a) DL19
> </details>





{{< table-caption >}}
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.7.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.2">BERT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.3">RoBERTa</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.4">ANCE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.5">TAS-B</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.6">Contriever</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.7.1.1.1.7">coCondenser</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.7.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.1">DL19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.2.1.2.1">-9.32 (1e-4)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.2.1.3.1">-28.15 (2e-12)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.2.1.4.1">-0.52 (9e-3)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.2.1.5.1">-0.96 (1e-2)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.6">-0.02 (0.33)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.1.2.1.7"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.2.1.7.1">-0.69 (3e-2)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.1">TREC-COVID</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.3.2.2.1">-1.69 (2e-2)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.3">2.42 (8e-2)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.4">0.09 (0.21)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.3.2.5.1">-0.48 (6e-3)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.6"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.3.2.6.1">-0.05 (7e-7)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.1.3.2.7"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.3.2.7.1">-0.32 (8e-3)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.1">SCIDOCS</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.2">-2.44 (6e-2)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T1.7.1.4.3.3.1">-6.42 (2e-3)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.4">-0.23 (0.15)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.5">-0.39 (0.10)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.6">-0.02 (0.24)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.7.1.4.3.7">-0.26 (0.41)</td>
</tr>
</tbody>
</table>{{< /table-caption >}}

> üîº This table presents the results of a two-stage regression analysis conducted to quantify the causal effect of document perplexity on estimated relevance scores.  The analysis was performed using instrumental variables to control for confounding factors. The table shows the estimated causal effects for six different PLM-based retrieval models across three datasets representing different domains.  Bold values indicate statistically significant negative causal effects (p<0.05), suggesting that lower document perplexity is associated with higher estimated relevance scores, regardless of the model or dataset. This highlights a systematic bias where models tend to overrate low-perplexity documents.
> <details>
> <summary>read the caption</summary>
> Table 1: Quantified causal effects (and corresponding pùëùpitalic_p-value) for document perplexity on estimated relevance scores via two-stage regression. Bold indicates that the estimate can pass a significance test with pùëùpitalic_p-value<0.05absent0.05<0.05< 0.05. Significant negative causal effects are prevalent across various PLM-based retrievers in different domain datasets.
> </details>





### In-depth insights


#### Perplexity Trap
The concept of a 'Perplexity Trap' in the context of PLM-based retrievers is intriguing. It suggests that these models, while powerful, can be **misled by the perplexity of documents**, essentially the model's confidence in generating the text. The 'trap' arises because PLMs may **overrate documents with low perplexity**, often characteristic of machine-generated content, leading to a bias against human-written text, even when the latter is semantically superior. This can **undermine the trustworthiness and fairness** of information retrieval systems. The exploration of causal relationships, as proposed in the source material, is critical to understanding and mitigating this trap. **Identifying perplexity as a non-causal feature** that negatively impacts relevance estimation is a crucial step. Future work might explore more sophisticated debiasing strategies to ensure PLMs prioritize semantic relevance over superficial text generation characteristics.

#### Causal Source Bias
**Causal source bias** is a phenomenon where models exhibit preferences for content based on its source, regardless of its inherent quality. This bias can stem from the model learning spurious correlations between source characteristics (e.g., LLM-generated content having lower perplexity) and relevance scores. The model might inadvertently prioritize lower perplexity documents, leading to unfair ranking outcomes. Addressing causal source bias requires careful disentangling of the true causal relationships driving relevance from spurious correlations learned by the model, potentially using techniques like causal intervention or bias correction methods. The consequences of not addressing this is that humans may be less incentivized.

#### CDC Debiasing
**CDC Debiasing**, a key focus, aims to mitigate source bias where PLM-based retrievers overrate low-perplexity documents. It employs Causal Diagnosis and Correction (CDC), an inference-time method derived from causal analysis. CDC's two-stage process involves (i) **Bias Diagnosis**, estimating perplexity's impact on relevance scores using Instrumental Variables, and (ii) **Bias Correction**, separating the biased effect from overall relevance scores. This debiasing is achieved post-model training, integrating easily into existing PLM-based retrievers. Results show effective bias reduction and maintain retrieval performance, proving generalizability across domains and LLMs. The adjustable nature allows balancing information quality and provider fairness.

#### Gradient Analysis
**Gradient analysis** is a crucial method for comprehending how models, particularly PLM-based retrievers, learn and make decisions. By examining the gradients of the loss functions during training, we can gain insights into the model's sensitivity to different features and potential biases. In the context of PLM-based retrievers, gradient analysis can help reveal the relationship between document perplexity and relevance score estimation. A positive correlation between gradients suggests that the model might be inadvertently favoring documents with lower perplexity, leading to source bias. This analysis is vital for developing effective debiasing strategies.

#### IV Regression
Instrumental Variable (IV) regression is a powerful technique used in statistics to estimate causal effects when there is a correlation between the explanatory variable and the error term, violating a key assumption of ordinary least squares (OLS) regression. The core idea is to use an **instrumental variable that is correlated with the explanatory variable** but independent of the error term. This allows to isolate the exogenous variation in the explanatory variable and estimate its causal effect on the outcome variable. The method typically involves a two-stage least squares (2SLS) procedure: first, the explanatory variable is regressed on the instrument, and then the outcome variable is regressed on the predicted values from the first stage. **The coefficient on the predicted values in the second stage provides an estimate of the causal effect.** IV regression requires careful consideration of the validity of the instrument, which must satisfy relevance and exclusion restrictions. It is particularly useful in situations where endogeneity may be present, such as when there is omitted variable bias or reverse causality. This is a crucial point to note since endogeneity results in biased and inconsistent OLS estimates.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2503.08684/x2.png)

> üîº The figure shows the perplexity and estimated relevance scores for the TREC-COVID dataset. Documents were generated using LLMs with varying sampling temperatures.  The x-axis represents the sampling temperature, while the y-axis shows the perplexity and relevance scores. The plot illustrates the negative correlation between perplexity and relevance scores, indicating that lower perplexity documents tend to receive higher relevance scores from the PLM-based retriever. This supports the paper's central hypothesis that low perplexity, often associated with LLM-generated text, leads to inflated relevance scores. This specific figure shows data for the TREC-COVID dataset, one of the three datasets used in the paper to test the findings.
> <details>
> <summary>read the caption</summary>
> (b) TREC-COVID
> </details>



![](https://arxiv.org/html/2503.08684/x3.png)

> üîº The figure shows the relationship between perplexity and estimated relevance scores for the SCIDOCS dataset. Documents were generated using different sampling temperatures. The Pearson correlation coefficient highlights a strong negative correlation between the two variables, indicating that documents with lower perplexity tend to receive higher relevance scores. This suggests that PLM-based retrievers have a bias towards low-perplexity documents, which often are LLM-generated.
> <details>
> <summary>read the caption</summary>
> (c) SCIDOCS
> </details>



![](https://arxiv.org/html/2503.08684/x4.png)

> üîº This figure displays the relationship between document perplexity and estimated relevance scores, as calculated by the ANCE model.  Three datasets (DL19, TREC-COVID, and SCIDOCS) are used, and in each, documents were generated using an LLM with varying sampling temperatures.  The x-axis represents the sampling temperature, and the y-axes show the perplexity and estimated relevance scores.  Each subplot shows a strong negative correlation between perplexity and relevance score; documents with lower perplexity receive higher relevance scores. The Pearson correlation coefficient for each dataset is displayed to quantify this negative relationship.
> <details>
> <summary>read the caption</summary>
> Figure 1: Perplexity and estimated relevance scores of ANCE on positive query-document pairs in three dataset, where documents are generated by LLM rewriting with different sampling temperatures. The Pearson coefficients highlight the significant negative correlation between the two variables.
> </details>



![](https://arxiv.org/html/2503.08684/x5.png)

> üîº This causal graph illustrates the relationships between different factors contributing to source bias in PLM-based retrievers.  The graph shows how the document source (human-written or LLM-generated), document semantics, query semantics, and document perplexity all influence the estimated relevance score.  Crucially, it highlights the causal link between document perplexity and the estimated relevance score, indicating that low perplexity documents are causally assigned higher relevance scores regardless of their semantic quality, leading to source bias.
> <details>
> <summary>read the caption</summary>
> Figure 2: The proposed causal graph for explaining source bias.
> </details>



![](https://arxiv.org/html/2503.08684/x6.png)

> üîº This figure visualizes the relationship between model perplexity and ranking performance (NDCG@3) across three datasets: DL19, TREC-COVID, and SCIDOCS.  It shows that models with lower perplexity tend to exhibit better ranking performance.  Each point represents the average perplexity and NDCG@3 score for a specific model. The x-axis shows the perplexity, and the y-axis shows the NDCG@3 score. This plot helps demonstrate the effect of perplexity on retrieval performance and supports the paper's claim that lower perplexity scores lead to source bias because models tend to favor low perplexity documents.
> <details>
> <summary>read the caption</summary>
> Figure 3: Model perplexity and ranking performance (NDCG@3) on averaged results of DL19, TREC-COVID, and SCIDOCS.
> </details>



![](https://arxiv.org/html/2503.08684/x7.png)

> üîº The figure illustrates the instrumental variable (IV) regression method used to disentangle the causal effect of document perplexity (P<sub>d</sub>) on estimated relevance scores (R<sub>q,d</sub>) from confounding factors.  The method uses two-stage least squares (2SLS). In the first stage, the document source (S<sub>d</sub>), acting as an instrumental variable, is regressed against document perplexity (P<sub>d</sub>) to obtain predicted perplexity values. In the second stage, the predicted perplexity is used as a predictor to estimate the relevance scores (R<sub>q,d</sub>).  The causal effect of perplexity is derived from the coefficient (Œ≤ÃÇ<sub>2</sub>) of the predicted perplexity in the second stage.
> <details>
> <summary>read the caption</summary>
> Figure 4: By leveraging IV regression on SdsubscriptùëÜùëëS_{d}italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, PdsubscriptùëÉùëëP_{d}italic_P start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT is decomposed into causal and non-causal parts. A precise causal effect can be obtained from the coefficient of the second-stage regression, i.e., Œ≤^2subscript^ùõΩ2\hat{\beta}_{2}over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.
> </details>



![](https://arxiv.org/html/2503.08684/x8.png)

> üîº The figure shows the perplexity and estimated relevance scores for documents generated by LLMs with different sampling temperatures on the DL19 dataset.  The x-axis represents the sampling temperature, ranging from 0 to 1.  The y-axis on the left shows the perplexity of the generated documents. The y-axis on the right shows the estimated relevance scores given by the retriever. The plot visually demonstrates a strong negative correlation between document perplexity and estimated relevance scores.  Lower perplexity documents receive higher relevance scores, highlighting the source bias problem.
> <details>
> <summary>read the caption</summary>
> (a) DL19
> </details>



![](https://arxiv.org/html/2503.08684/x9.png)

> üîº The figure shows the perplexity and estimated relevance scores for the TREC-COVID dataset, where documents are generated by an LLM with different sampling temperatures.  The x-axis represents the sampling temperature, and the y-axis shows the perplexity and relevance score.  The graph illustrates the negative correlation between perplexity and estimated relevance scores. Lower perplexity documents receive higher relevance scores, demonstrating the source bias of PLM-based retrievers.
> <details>
> <summary>read the caption</summary>
> (b) TREC-COVID
> </details>



![](https://arxiv.org/html/2503.08684/x10.png)

> üîº The figure shows the relationship between perplexity and estimated relevance scores for the SCIDOCS dataset.  Specifically, it displays how the estimated relevance score changes as a function of the perplexity, highlighting the inverse relationship where lower perplexity documents receive higher relevance scores. The data was obtained by generating LLM-rewritten documents with varying sampling temperatures.  The Pearson correlation coefficient is also shown to quantify the strength of the negative relationship.
> <details>
> <summary>read the caption</summary>
> (c) SCIDOCS
> </details>



![](https://arxiv.org/html/2503.08684/x11.png)

> üîº This figure displays the relationship between perplexity and estimated relevance scores produced by the Contriever model.  Three datasets are used, and in each, documents were generated by an LLM using various sampling temperatures. The x-axis represents the sampling temperature, and the y-axes show both perplexity and the estimated relevance scores.  The plots illustrate a negative correlation between perplexity and estimated relevance, indicating that lower-perplexity documents (those generated with lower sampling temperatures) tend to receive higher relevance scores.
> <details>
> <summary>read the caption</summary>
> Figure 5: Perplexity and estimated relevance scores of Contriever on positive query-document pairs in three datasets, where documents are generated by LLM with different sampling temperatures.
> </details>



![](https://arxiv.org/html/2503.08684/x12.png)

> üîº The figure shows the perplexity and estimated relevance scores for the DL19 dataset, where documents were generated by an LLM with different sampling temperatures. The x-axis represents the sampling temperature, while the y-axis shows the perplexity and estimated relevance scores. The Pearson correlation coefficient is also displayed, highlighting the significant negative correlation between perplexity and estimated relevance scores. This illustrates that documents with lower perplexity are given higher estimated relevance scores by the PLM-based retriever, leading to source bias.
> <details>
> <summary>read the caption</summary>
> (a) DL19
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.7.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.1.1.1" rowspan="3"><span class="ltx_text" id="S5.T2.7.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.7.1.1.1.2">DL19 (In-Domain)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.7.1.1.1.3">TREC-COVID (Out-of-Domain)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T2.7.1.1.1.4">SCIDOCS (Out-of-Domain)</th>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.1">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.2">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.3">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.4">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.5">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T2.7.1.2.2.6">Bias</th>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.1">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.2">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.3">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.4">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.5">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.6">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.7">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.8">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.9">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.10">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.11">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T2.7.1.3.3.12">+CDC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.7.1.4.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.1">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.2">75.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.3">77.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.4">-23.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.5">5.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.6">53.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.7">45.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.8">-39.58</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.9">-18.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.10">10.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.11">10.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.12">-2.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.7.1.4.1.13">29.19</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.5.2">
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.1">Roberta</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.2">72.79</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.3">71.33</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.4">-36.32</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.5">4.45</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.6">46.31</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.7">45.86</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.8">-48.14</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.9">-10.51</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.10">8.85</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.11">8.24</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.12">-30.90</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.5.2.13">32.13</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.6.3">
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.1">ANCE</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.2">69.41</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.3">67.73</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.4">-21.03</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.5">34.95</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.6">71.01</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.7">69.94</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.8">-33.59</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.9">-1.94</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.10">12.73</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.11">12.31</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.12">-1.57</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.6.3.13">26.26</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.7.4">
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.1">TAS-B</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.2">74.97</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.3">75.63</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.4">-49.17</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.5">-9.97</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.6">63.95</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.7">62.84</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.8">-73.36</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.9">-37.42</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.10">15.04</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.11">14.15</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.12">-1.90</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.7.4.13">23.48</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.8.5">
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.1">Contriever</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.2">72.61</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.3">73.83</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.4">-21.93</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.5">-5.33</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.6">63.17</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.7">61.35</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.8">-62.26</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.9">-31.33</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.10">15.45</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.11">15.09</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.12">-6.96</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.1.8.5.13">1.63</td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.1.9.6">
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.1">coCondenser</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.2">75.50</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.3">75.36</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.4">-18.99</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.5">9.60</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.6">70.94</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.7">71.07</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.8">-67.95</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.9">-45.39</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.10">13.93</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.11">13.79</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.12">-5.95</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.7.1.9.6.13">1.06</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents the performance and bias of several popular PLM-based retrieval models, with and without the application of the proposed CDC debiased method.  Performance is measured using NDCG@3 on three different datasets. The bias metric (Relative Œî) indicates the preference of the model towards either LLM-generated or human-written documents; a more negative value suggests stronger bias towards LLM-generated content, while a more positive value indicates bias towards human-written content.
> <details>
> <summary>read the caption</summary>
> Table 2: Performance (NDCG@3333) and bias (Relative ŒîŒî\Deltaroman_Œî¬†(Dai et¬†al., 2024c) on NDCG@3333) of different PLM-based retrievers with and without our proposed CDC debiased method on three datasets. Note that a more negative bias metric value indicates a greater bias towards LLM-generated documents, while a more positive value indicates a greater bias towards human-written documents.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.7.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.1.1.1" rowspan="3"><span class="ltx_text" id="S5.T3.7.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T3.7.1.1.1.2">Llama-2 (In-Domain)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T3.7.1.1.1.3">GPT-4 (Out-of-Domain)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T3.7.1.1.1.4">GPT-3.5 (Out-of-Domain)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S5.T3.7.1.1.1.5">Mistral (Out-of-Domain)</th>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.1">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.2">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.3">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.4">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.5">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.6">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.7">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S5.T3.7.1.2.2.8">Bias</th>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.1">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.2">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.3">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.4">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.5">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.6">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.7">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.8">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.9">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.10">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.11">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.12">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.13">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.14">+CDC</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.15">Raw</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T3.7.1.3.3.16">+CDC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.7.1.4.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.1">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.2">35.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.3">35.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.4">-12.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.5">6.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.6">36.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.7">35.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.8">-3.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.9">6.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.10">35.97</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.11">35.27</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.12">-5.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.13">18.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.14">35.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.15">35.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.16">0.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.1.4.1.17">13.07</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.5.2">
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.2">38.09</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.3">36.76</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.4">-29.54</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.5">-0.88</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.6">38.53</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.7">37.70</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.8">-11.98</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.9">4.52</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.10">39.17</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.11">38.00</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.12">-35.39</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.13">14.09</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.14">38.29</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.15">37.28</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.16">-17.95</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.5.2.17">16.78</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.6.3">
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.1">ANCE</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.2">42.13</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.3">42.13</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.4">-8.81</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.5">4.59</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.6">42.67</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.7">42.99</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.8">-5.53</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.9">3.28</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.10">42.76</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.11">42.96</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.12">-13.59</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.13">6.09</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.14">42.62</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.15">42.71</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.16">-8.59</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.6.3.17">1.82</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.7.4">
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.1">TAS-B</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.2">52.95</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.3">53.94</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.4">-15.04</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.5">-7.96</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.6">52.12</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.7">52.44</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.8">-4.94</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.9">-0.05</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.10">52.83</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.11">52.90</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.12">-5.65</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.13">5.57</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.14">52.18</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.15">52.69</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.16">-8.71</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.7.4.17">-2.00</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.8.5">
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.1">Contriever</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.2">55.19</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.3">55.37</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.4">-2.87</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.5">1.07</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.6">55.78</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.7">55.70</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.8">-5.32</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.9">-4.44</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.10">56.11</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.11">56.17</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.12">-7.43</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.13">-2.81</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.14">56.13</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.15">56.28</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.16">-4.13</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.1.8.5.17">-2.39</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.1.9.6">
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.1">coCondenser</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.2">49.53</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.3">49.40</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.4">-12.98</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.5">-9.26</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.6">48.57</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.7">48.91</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.8">5.04</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.9">6.04</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.10">48.59</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.11">48.81</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.12">-1.00</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.13">5.30</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.14">49.57</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.15">49.92</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.16">-5.90</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T3.7.1.9.6.17">-0.76</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº Table 3 presents the NDCG@3 scores and relative bias (measuring the difference in NDCG@3 scores between human-written and LLM-generated documents) for various retrieval models on a mixed SciFact dataset comprising documents generated by different LLMs.  The Bias Diagnosis was performed on the DL19 dataset using Llama-2, and the Causal Diagnosis and Correction (CDC) method's generalizability was then tested across both different LLMs and datasets.  This demonstrates whether a model trained to debias on one LLM and dataset can effectively debias on different LLMs and datasets.
> <details>
> <summary>read the caption</summary>
> Table 3: Performance (NDCG@3333) and bias (Relative ŒîŒî\Deltaroman_Œî¬†(Dai et¬†al., 2024c) on NDCG@3333) of the retrievers on mixed SciFact corpus from different LLMs. Bias Diagnosis is conducted on DL19 corpus from Llama-2, where CDC performs generalization at both LLM and data-domain levels.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A4.T4.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.T4.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="A4.T4.1.1.1.1.1.1">Temperature</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A4.T4.1.1.1.1.2">DL19</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.2.2.1">Human</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.2.2.2">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.2.2.3">Equal</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.3.3.1">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.3.3.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.3.3.3">5% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.3.3.4">95% (83.8%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.4.4">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.4.4.1">0.20</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.4.4.2">0.0%(0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.4.4.3">5% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.4.4.4">95% (94.2%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.5.5">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.5.5.1">0.40</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.5.5.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.5.5.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.5.5.4">100% (79.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.6.6">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.6.6.1">0.60</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.6.6.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.6.6.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.6.6.4">100% (84.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.7.7">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.7.7.1">0.80</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.7.7.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.7.7.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.7.7.4">100% (94.5%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.8.8">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.8.8.1">1.00</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.8.8.2">0.0%(0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.8.8.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.8.8.4">100% (94.5%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.9.9.1" rowspan="2"><span class="ltx_text" id="A4.T4.1.1.9.9.1.1">Temperature</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A4.T4.1.1.9.9.2">TREC-COVID</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.10.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.10.10.1">Human</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.10.10.2">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.10.10.3">Equal</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.11.11.1">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.11.11.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.11.11.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.11.11.4">100% (84.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.12.12">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.12.12.1">0.20</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.12.12.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.12.12.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.12.12.4">100% (94.5%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.13.13">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.13.13.1">0.40</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.13.13.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.13.13.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.13.13.4">100% (74.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.14.14">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.14.14.1">0.60</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.14.14.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.14.14.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.14.14.4">100% (94.5%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.15.15">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.15.15.1">0.80</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.15.15.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.15.15.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.15.15.4">100% (79.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.16.16">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.16.16.1">1.00</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.16.16.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.16.16.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.16.16.4">100% (84.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.17.17">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.17.17.1" rowspan="2"><span class="ltx_text" id="A4.T4.1.1.17.17.1.1">Temperature</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A4.T4.1.1.17.17.2">SCIDOCS</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.18.18">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.18.18.1">Human</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.18.18.2">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.18.18.3">Equal</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.19.19">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.19.19.1">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.19.19.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.19.19.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T4.1.1.19.19.4">100% (84.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.20.20">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.20.20.1">0.20</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.20.20.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.20.20.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.20.20.4">100% (84.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.21.21">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.21.21.1">0.40</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.21.21.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.21.21.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.21.21.4">100% (79.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.22.22">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.22.22.1">0.60</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.22.22.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.22.22.3">5.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.22.22.4">95% (83.8%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.23.23">
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.23.23.1">0.80</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.23.23.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.23.23.3">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center" id="A4.T4.1.1.23.23.4">100% (79.6%)</td>
</tr>
<tr class="ltx_tr" id="A4.T4.1.1.24.24">
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T4.1.1.24.24.1">1.00</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T4.1.1.24.24.2">0.0% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T4.1.1.24.24.3">5% (0.0%)</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A4.T4.1.1.24.24.4">95% (89.0%)</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents the results of a human evaluation experiment designed to assess the semantic relevance of LLM-generated versus human-written documents.  Three human annotators evaluated pairs of documents (one human-written and one LLM-generated) for each of three datasets (DL19, TREC-COVID, SCIDOCS) and various sampling temperatures. The evaluation focused on which document within each pair was more semantically relevant to the given query. The numbers in parentheses represent the percentage of annotators who unanimously agreed on the more relevant document.
> <details>
> <summary>read the caption</summary>
> Table 4: Human evaluation on which document is more relevant to the given query semantically? The numbers in parentheses are the proportion agreed upon by all three human annotators.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T5.9.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T5.9.7.8.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="A5.T5.9.7.8.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A5.T5.9.7.8.1.2">DL19</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A5.T5.9.7.8.1.3">TREC-COVID</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="A5.T5.9.7.8.1.4">SCIDOCS</th>
</tr>
<tr class="ltx_tr" id="A5.T5.9.7.9.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="A5.T5.9.7.9.2.1">Temperature</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.2">0.0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.3">0.2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.4">0.4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.5">0.6</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.6">0.0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.7">0.2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.8">0.4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.9">0.6</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.10">0.0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.11">0.2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.12">0.4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T5.9.7.9.2.13">0.6</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T5.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="A5.T5.3.1.1.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.3.1.1.1.m1.1"><semantics id="A5.T5.3.1.1.1.m1.1a"><msub id="A5.T5.3.1.1.1.m1.1.1" xref="A5.T5.3.1.1.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.3.1.1.1.m1.1.1.2" xref="A5.T5.3.1.1.1.m1.1.1.2.cmml"><mi id="A5.T5.3.1.1.1.m1.1.1.2.2" xref="A5.T5.3.1.1.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.3.1.1.1.m1.1.1.2.1" xref="A5.T5.3.1.1.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.3.1.1.1.m1.1.1.3" xref="A5.T5.3.1.1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.3.1.1.1.m1.1b"><apply id="A5.T5.3.1.1.1.m1.1.1.cmml" xref="A5.T5.3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.3.1.1.1.m1.1.1.1.cmml" xref="A5.T5.3.1.1.1.m1.1.1">subscript</csymbol><apply id="A5.T5.3.1.1.1.m1.1.1.2.cmml" xref="A5.T5.3.1.1.1.m1.1.1.2"><ci id="A5.T5.3.1.1.1.m1.1.1.2.1.cmml" xref="A5.T5.3.1.1.1.m1.1.1.2.1">^</ci><ci id="A5.T5.3.1.1.1.m1.1.1.2.2.cmml" xref="A5.T5.3.1.1.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.3.1.1.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.3.1.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.3.1.1.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.3.1.1.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(BERT)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.2">-7.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.3">-7.78</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.4">-7.77</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.5">-7.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.6">-1.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.7">-1.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.8">-1.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.9">-1.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.10">-2.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.11">-2.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.12">-2.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T5.3.1.1.13">-2.46</td>
</tr>
<tr class="ltx_tr" id="A5.T5.4.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A5.T5.4.2.2.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.4.2.2.1.m1.1"><semantics id="A5.T5.4.2.2.1.m1.1a"><msub id="A5.T5.4.2.2.1.m1.1.1" xref="A5.T5.4.2.2.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.4.2.2.1.m1.1.1.2" xref="A5.T5.4.2.2.1.m1.1.1.2.cmml"><mi id="A5.T5.4.2.2.1.m1.1.1.2.2" xref="A5.T5.4.2.2.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.4.2.2.1.m1.1.1.2.1" xref="A5.T5.4.2.2.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.4.2.2.1.m1.1.1.3" xref="A5.T5.4.2.2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.4.2.2.1.m1.1b"><apply id="A5.T5.4.2.2.1.m1.1.1.cmml" xref="A5.T5.4.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.4.2.2.1.m1.1.1.1.cmml" xref="A5.T5.4.2.2.1.m1.1.1">subscript</csymbol><apply id="A5.T5.4.2.2.1.m1.1.1.2.cmml" xref="A5.T5.4.2.2.1.m1.1.1.2"><ci id="A5.T5.4.2.2.1.m1.1.1.2.1.cmml" xref="A5.T5.4.2.2.1.m1.1.1.2.1">^</ci><ci id="A5.T5.4.2.2.1.m1.1.1.2.2.cmml" xref="A5.T5.4.2.2.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.4.2.2.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.4.2.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.4.2.2.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.4.2.2.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(RoBERTa)</th>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.2">-23.57</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.3">-23.50</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.4">-23.45</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.5">-23.97</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.6">1.73</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.7">1.73</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.8">1.77</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.9">1.80</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.10">-6.02</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.11">-6.04</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.12">-6.13</td>
<td class="ltx_td ltx_align_center" id="A5.T5.4.2.2.13">-6.47</td>
</tr>
<tr class="ltx_tr" id="A5.T5.5.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A5.T5.5.3.3.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.5.3.3.1.m1.1"><semantics id="A5.T5.5.3.3.1.m1.1a"><msub id="A5.T5.5.3.3.1.m1.1.1" xref="A5.T5.5.3.3.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.5.3.3.1.m1.1.1.2" xref="A5.T5.5.3.3.1.m1.1.1.2.cmml"><mi id="A5.T5.5.3.3.1.m1.1.1.2.2" xref="A5.T5.5.3.3.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.5.3.3.1.m1.1.1.2.1" xref="A5.T5.5.3.3.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.5.3.3.1.m1.1.1.3" xref="A5.T5.5.3.3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.5.3.3.1.m1.1b"><apply id="A5.T5.5.3.3.1.m1.1.1.cmml" xref="A5.T5.5.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.5.3.3.1.m1.1.1.1.cmml" xref="A5.T5.5.3.3.1.m1.1.1">subscript</csymbol><apply id="A5.T5.5.3.3.1.m1.1.1.2.cmml" xref="A5.T5.5.3.3.1.m1.1.1.2"><ci id="A5.T5.5.3.3.1.m1.1.1.2.1.cmml" xref="A5.T5.5.3.3.1.m1.1.1.2.1">^</ci><ci id="A5.T5.5.3.3.1.m1.1.1.2.2.cmml" xref="A5.T5.5.3.3.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.5.3.3.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.5.3.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.5.3.3.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.5.3.3.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(ANCE)</th>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.2">-0.44</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.3">-0.44</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.4">-0.44</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.5">-0.45</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.6">0.07</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.7">0.07</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.8">0.07</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.9">0.07</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.10">-0.22</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.11">-0.22</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.12">-0.22</td>
<td class="ltx_td ltx_align_center" id="A5.T5.5.3.3.13">-0.23</td>
</tr>
<tr class="ltx_tr" id="A5.T5.6.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A5.T5.6.4.4.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.6.4.4.1.m1.1"><semantics id="A5.T5.6.4.4.1.m1.1a"><msub id="A5.T5.6.4.4.1.m1.1.1" xref="A5.T5.6.4.4.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.6.4.4.1.m1.1.1.2" xref="A5.T5.6.4.4.1.m1.1.1.2.cmml"><mi id="A5.T5.6.4.4.1.m1.1.1.2.2" xref="A5.T5.6.4.4.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.6.4.4.1.m1.1.1.2.1" xref="A5.T5.6.4.4.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.6.4.4.1.m1.1.1.3" xref="A5.T5.6.4.4.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.6.4.4.1.m1.1b"><apply id="A5.T5.6.4.4.1.m1.1.1.cmml" xref="A5.T5.6.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.6.4.4.1.m1.1.1.1.cmml" xref="A5.T5.6.4.4.1.m1.1.1">subscript</csymbol><apply id="A5.T5.6.4.4.1.m1.1.1.2.cmml" xref="A5.T5.6.4.4.1.m1.1.1.2"><ci id="A5.T5.6.4.4.1.m1.1.1.2.1.cmml" xref="A5.T5.6.4.4.1.m1.1.1.2.1">^</ci><ci id="A5.T5.6.4.4.1.m1.1.1.2.2.cmml" xref="A5.T5.6.4.4.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.6.4.4.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.6.4.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.6.4.4.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.6.4.4.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(TAS-B)</th>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.2">-0.81</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.3">-0.80</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.4">-0.80</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.5">-0.82</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.6">-0.34</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.7">-0.34</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.8">-0.35</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.9">-0.35</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.10">-0.37</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.11">-0.37</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.12">-0.37</td>
<td class="ltx_td ltx_align_center" id="A5.T5.6.4.4.13">-0.39</td>
</tr>
<tr class="ltx_tr" id="A5.T5.7.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A5.T5.7.5.5.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.7.5.5.1.m1.1"><semantics id="A5.T5.7.5.5.1.m1.1a"><msub id="A5.T5.7.5.5.1.m1.1.1" xref="A5.T5.7.5.5.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.7.5.5.1.m1.1.1.2" xref="A5.T5.7.5.5.1.m1.1.1.2.cmml"><mi id="A5.T5.7.5.5.1.m1.1.1.2.2" xref="A5.T5.7.5.5.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.7.5.5.1.m1.1.1.2.1" xref="A5.T5.7.5.5.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.7.5.5.1.m1.1.1.3" xref="A5.T5.7.5.5.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.7.5.5.1.m1.1b"><apply id="A5.T5.7.5.5.1.m1.1.1.cmml" xref="A5.T5.7.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.7.5.5.1.m1.1.1.1.cmml" xref="A5.T5.7.5.5.1.m1.1.1">subscript</csymbol><apply id="A5.T5.7.5.5.1.m1.1.1.2.cmml" xref="A5.T5.7.5.5.1.m1.1.1.2"><ci id="A5.T5.7.5.5.1.m1.1.1.2.1.cmml" xref="A5.T5.7.5.5.1.m1.1.1.2.1">^</ci><ci id="A5.T5.7.5.5.1.m1.1.1.2.2.cmml" xref="A5.T5.7.5.5.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.7.5.5.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.7.5.5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.7.5.5.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.7.5.5.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(Contriever)</th>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.2">-0.01</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.3">-0.01</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.4">-0.01</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.5">-0.01</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.6">-0.03</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.7">-0.03</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.8">-0.04</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.9">-0.04</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.10">-0.02</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.11">-0.02</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.12">-0.02</td>
<td class="ltx_td ltx_align_center" id="A5.T5.7.5.5.13">-0.02</td>
</tr>
<tr class="ltx_tr" id="A5.T5.8.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="A5.T5.8.6.6.1">
<math alttext="\hat{\beta}_{2}" class="ltx_Math" display="inline" id="A5.T5.8.6.6.1.m1.1"><semantics id="A5.T5.8.6.6.1.m1.1a"><msub id="A5.T5.8.6.6.1.m1.1.1" xref="A5.T5.8.6.6.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.8.6.6.1.m1.1.1.2" xref="A5.T5.8.6.6.1.m1.1.1.2.cmml"><mi id="A5.T5.8.6.6.1.m1.1.1.2.2" xref="A5.T5.8.6.6.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.8.6.6.1.m1.1.1.2.1" xref="A5.T5.8.6.6.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.8.6.6.1.m1.1.1.3" xref="A5.T5.8.6.6.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.8.6.6.1.m1.1b"><apply id="A5.T5.8.6.6.1.m1.1.1.cmml" xref="A5.T5.8.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.8.6.6.1.m1.1.1.1.cmml" xref="A5.T5.8.6.6.1.m1.1.1">subscript</csymbol><apply id="A5.T5.8.6.6.1.m1.1.1.2.cmml" xref="A5.T5.8.6.6.1.m1.1.1.2"><ci id="A5.T5.8.6.6.1.m1.1.1.2.1.cmml" xref="A5.T5.8.6.6.1.m1.1.1.2.1">^</ci><ci id="A5.T5.8.6.6.1.m1.1.1.2.2.cmml" xref="A5.T5.8.6.6.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.8.6.6.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.8.6.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.8.6.6.1.m1.1c">\hat{\beta}_{2}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.8.6.6.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>(coCondenser)</th>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.2">-0.58</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.3">-0.58</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.4">-0.58</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.5">-0.59</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.6">-0.23</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.7">-0.23</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.8">-0.24</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.9">-0.24</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.10">-0.25</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.11">-0.25</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.12">-0.25</td>
<td class="ltx_td ltx_align_center" id="A5.T5.8.6.6.13">-0.26</td>
</tr>
<tr class="ltx_tr" id="A5.T5.9.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b" id="A5.T5.9.7.7.1"><math alttext="\hat{\beta}_{1}" class="ltx_Math" display="inline" id="A5.T5.9.7.7.1.m1.1"><semantics id="A5.T5.9.7.7.1.m1.1a"><msub id="A5.T5.9.7.7.1.m1.1.1" xref="A5.T5.9.7.7.1.m1.1.1.cmml"><mover accent="true" id="A5.T5.9.7.7.1.m1.1.1.2" xref="A5.T5.9.7.7.1.m1.1.1.2.cmml"><mi id="A5.T5.9.7.7.1.m1.1.1.2.2" xref="A5.T5.9.7.7.1.m1.1.1.2.2.cmml">Œ≤</mi><mo id="A5.T5.9.7.7.1.m1.1.1.2.1" xref="A5.T5.9.7.7.1.m1.1.1.2.1.cmml">^</mo></mover><mn id="A5.T5.9.7.7.1.m1.1.1.3" xref="A5.T5.9.7.7.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T5.9.7.7.1.m1.1b"><apply id="A5.T5.9.7.7.1.m1.1.1.cmml" xref="A5.T5.9.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T5.9.7.7.1.m1.1.1.1.cmml" xref="A5.T5.9.7.7.1.m1.1.1">subscript</csymbol><apply id="A5.T5.9.7.7.1.m1.1.1.2.cmml" xref="A5.T5.9.7.7.1.m1.1.1.2"><ci id="A5.T5.9.7.7.1.m1.1.1.2.1.cmml" xref="A5.T5.9.7.7.1.m1.1.1.2.1">^</ci><ci id="A5.T5.9.7.7.1.m1.1.1.2.2.cmml" xref="A5.T5.9.7.7.1.m1.1.1.2.2">ùõΩ</ci></apply><cn id="A5.T5.9.7.7.1.m1.1.1.3.cmml" type="integer" xref="A5.T5.9.7.7.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T5.9.7.7.1.m1.1c">\hat{\beta}_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.T5.9.7.7.1.m1.1d">over^ start_ARG italic_Œ≤ end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.2">-0.44</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.3">-0.44</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.4">-0.44</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.5">-0.43</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.6">-0.41</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.7">-0.41</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.8">-0.40</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.9">-0.39</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.10">-0.41</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.11">-0.40</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.12">-0.40</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T5.9.7.7.13">-0.38</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table shows how changing the temperature parameter during the generation of LLM-rewritten documents affects the estimated causal coefficients (Œ≤1 and Œ≤2). These coefficients represent the impact of document perplexity on the estimated relevance scores.  The analysis is done for three different datasets (DL19, TREC-COVID, SCIDOCS) and six different PLM-based retrieval models (BERT, RoBERTa, ANCE, TAS-B, Contriever, and coCondenser). The table helps to demonstrate that the causal effect of perplexity on relevance scores is robust across various datasets, models, and generation temperatures. 
> <details>
> <summary>read the caption</summary>
> Table 5: The influence of generation temperatures on the magnitude of the causal coefficients Œ≤1,Œ≤2subscriptùõΩ1subscriptùõΩ2\beta_{1},\beta_{2}italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The coefficients are estimated from all positive query-document pairs.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A5.T6.7.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T6.7.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.1.1.1" rowspan="3"><span class="ltx_text" id="A5.T6.7.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="A5.T6.7.1.1.1.2">DL19 (In-Domain)</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="A5.T6.7.1.1.1.3">TREC-COVID (Out-of-Domain)</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="A5.T6.7.1.1.1.4">SCIDOCS (Out-of-Domain)</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.1">Performance</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.2">Bias</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.3">Performance</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.4">Bias</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.5">Performance</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A5.T6.7.1.2.2.6">Bias</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.1">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.2">Std</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.3">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.4">Std</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.5">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.6">Std</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.7">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.8">Std</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.9">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.10">Std</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.11">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.3.3.12">Std</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.1">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.2">77.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.3">0.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.4">5.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.5">4.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.6">45.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.7">1.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.8">-18.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.9">6.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.10">10.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.11">0.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.12">29.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.7.1.4.4.13">9.35</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.5.5">
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.2">71.33</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.3">0.48</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.4">4.45</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.5">0.80</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.6">45.86</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.7">0.78</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.8">-10.51</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.9">3.58</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.10">8.24</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.11">0.18</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.12">32.13</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.5.5.13">7.28</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.6.6">
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.1">ANCE</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.2">67.73</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.3">0.15</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.4">34.95</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.5">11.51</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.6">69.94</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.7">0.77</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.8">-1.94</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.9">4.63</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.10">12.31</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.11">0.33</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.12">26.26</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.6.6.13">10.61</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.7.7">
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.1">TAS-B</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.2">75.63</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.3">0.24</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.4">-9.97</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.5">5.25</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.6">62.84</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.7">0.48</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.8">-37.42</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.9">3.99</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.10">14.15</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.11">0.16</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.12">23.48</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.7.7.13">5.84</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.8.8">
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.1">Contriever</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.2">73.83</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.3">0.27</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.4">-5.33</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.5">1.93</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.6">61.35</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.7">0.73</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.8">-31.33</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.9">3.22</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.10">15.09</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.11">0.10</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.12">1.63</td>
<td class="ltx_td ltx_align_center" id="A5.T6.7.1.8.8.13">1.89</td>
</tr>
<tr class="ltx_tr" id="A5.T6.7.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.1">coCondenser</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.2">75.36</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.3">0.47</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.4">9.60</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.5">8.49</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.6">71.07</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.7">0.45</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.8">-45.39</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.9">8.55</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.10">13.79</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.11">0.21</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.12">1.06</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T6.7.1.9.9.13">2.79</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents the average NDCG@3 scores and relative bias (measuring the difference between the performance on human-written and LLM-generated documents) for six different PLM-based retrieval models.  The results are shown for three different datasets (DL19, TREC-COVID, and SCIDOCS) and are averaged across five repetitions of the experiment to demonstrate the robustness of the results. The table compares the performance before and after applying the proposed CDC (Causal Diagnosis and Correction) debiasing method.  The mean and standard deviation are provided for each metric and dataset.
> <details>
> <summary>read the caption</summary>
> Table 6: Mean and standard deviation of Performance (NDCG@3333) and bias (Relative ŒîŒî\Deltaroman_Œî¬†[Dai et¬†al., 2024c] on NDCG@3333) of different PLM-based retrievers with our proposed CDC debiased method on three datasets in five repetitions.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T7.13">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T7.13.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.1.1.1" rowspan="2"><span class="ltx_text" id="A5.T7.13.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="A5.T7.13.1.1.2">DL19</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="A5.T7.13.1.1.3">TREC-COVID</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="A5.T7.13.1.1.4">SCIDOCS</th>
</tr>
<tr class="ltx_tr" id="A5.T7.13.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.1">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.2">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.3">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.4">Bias</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.5">Performance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A5.T7.13.2.2.6">Bias</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T7.13.3.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.1">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.2"><span class="ltx_text ltx_font_bold" id="A5.T7.13.3.1.2.1">4.56e-03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.3.1.3.1">5.33e-04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.4"><span class="ltx_text ltx_font_bold" id="A5.T7.13.3.1.4.1">1.87e-03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.3.1.5.1">3.97e-05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.6">1.37e-01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.13.3.1.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.3.1.7.1">1.47e-03</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.13.4.2">
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.2">7.26e-02</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.4.2.3.1">2.33e-04</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.4">1.22e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.4.2.5.1">5.46e-05</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.6">8.48e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.4.2.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.4.2.7.1">9.45e-07</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.13.5.3">
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.1">ANCE</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.2">1.74e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.5.3.3.1">4.48e-03</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.4">4.61e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.5.3.5.1">3.09e-04</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.6">1.62e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.5.3.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.5.3.7.1">2.25e-05</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.13.6.4">
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.1">TAS-B</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.2">6.16e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.6.4.3.1">3.19e-04</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.4">8.58e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.6.4.5.1">1.27e-03</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.6"><span class="ltx_text ltx_font_bold" id="A5.T7.13.6.4.6.1">6.67e-04</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.6.4.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.6.4.7.1">2.16e-04</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.13.7.5">
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.1">Contriever</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.2">2.77e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.7.5.3.1">3.94e-02</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.4">2.98e-01</td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.7.5.5.1">5.03e-04</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.6"><span class="ltx_text ltx_font_bold" id="A5.T7.13.7.5.6.1">4.44e-02</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.13.7.5.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.7.5.7.1">7.65e-03</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.13.8.6">
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.1">coCondenser</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.2">8.82e-01</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.3"><span class="ltx_text ltx_font_bold" id="A5.T7.13.8.6.3.1">1.16e-02</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.4">5.95e-01</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.5"><span class="ltx_text ltx_font_bold" id="A5.T7.13.8.6.5.1">3.81e-04</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.6">2.71e-01</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A5.T7.13.8.6.7"><span class="ltx_text ltx_font_bold" id="A5.T7.13.8.6.7.1">1.58e-03</span></td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº Table 7 presents the results of statistical significance tests performed on the NDCG@3 (Normalized Discounted Cumulative Gain at position 3) and Relative Œî (a measure of bias) metrics, both with and without the application of the proposed CDC (Causal Diagnosis and Correction) debiasing method.  The p-values from these tests are shown, with bold text highlighting results that are statistically significant at the p<0.05 level.  The results demonstrate that while the CDC method significantly affects the bias, it does not substantially impact the overall performance (NDCG@3).
> <details>
> <summary>read the caption</summary>
> Table 7:  The pùëùpitalic_p-value of significance test conducted on the NDCG@3333 and Relative ŒîŒî\Deltaroman_Œî¬†[Dai et¬†al., 2024c] on NDCG@3333 with and without CDC debias method, with bold fonts indicating the Performance or Bias can pass a significance test with pùëùpitalic_p-value<0.05absent0.05<0.05< 0.05. As expected, most Performance DOES NOT pass the significance test while all the Bias DOES pass the significance test.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/2503.08684/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2503.08684/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}