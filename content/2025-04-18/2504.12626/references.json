{"references": [{"fullname_first_author": "B. Chen", "paper_title": "Diffusion forcing: Next-token prediction meets full-sequence diffusion.", "publication_date": "2025-01-01", "reason": "This paper is cited for noise scheduling and augmentation in history frames that generally reduce dependency on past frames."}, {"fullname_first_author": "R. Henschel", "paper_title": "Streamingt2v: Consistent, dynamic, and extendable long video generation from text.", "publication_date": "2024-03-01", "reason": "This paper is cited for using reference images as anchors for video generation."}, {"fullname_first_author": "Z. Huang", "paper_title": "VBench: Comprehensive benchmark suite for video generative models.", "publication_date": "2024-01-01", "reason": "This paper is cited for being a source of consistent multi-dimension metrics for video evaluation."}, {"fullname_first_author": "T. Yin", "paper_title": "From slow bidirectional to fast causal video generators.", "publication_date": "2024-12-01", "reason": "This paper is cited as CausVid, and a structure that resembles it has been implemented and evaluated by the paper."}, {"fullname_first_author": "S. Yin", "paper_title": "Nuwa-xl: Diffusion over diffusion for extremely long video generation.", "publication_date": "2023-03-01", "reason": "This paper is cited as an example of implementing a Diffusion-over-Diffusion architecture."}]}