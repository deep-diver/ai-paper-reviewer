[{"figure_path": "https://arxiv.org/html/2504.12782/x1.png", "caption": "Figure 1: \nGeometric perspective on concept erasure in diffusion models.\n(a) Conventional Denoising Trajectory. A high-dimensional Gaussian sample, starting on a large sphere, converges to the human data manifold via classifier-free guidance (CFG).\n(b) Anchor-Free Finetuned Trajectory. Finetuning often modifies the orientation of the predicted conditional score functions so that they direct away from the unwanted concept manifold. This results in a condition direction \ud835\udf39\u2062(\ud835\udc84)=\u03f5\ud835\udf3d\u2062(\ud835\udc9bt,t,\ud835\udc84)\u2212\u03f5\ud835\udf3d\u2062(\ud835\udc9bt,t)\ud835\udf39\ud835\udc84subscriptbold-italic-\u03f5\ud835\udf3dsubscript\ud835\udc9b\ud835\udc61\ud835\udc61\ud835\udc84subscriptbold-italic-\u03f5\ud835\udf3dsubscript\ud835\udc9b\ud835\udc61\ud835\udc61\\bm{\\delta}(\\bm{c})=\\bm{\\epsilon}_{\\bm{\\theta}}(\\bm{z}_{t},t,\\bm{c})-\\bm{%\n\\epsilon}_{\\bm{\\theta}}(\\bm{z}_{t},t)bold_italic_\u03b4 ( bold_italic_c ) = bold_italic_\u03f5 start_POSTSUBSCRIPT bold_italic_\u03b8 end_POSTSUBSCRIPT ( bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , bold_italic_c ) - bold_italic_\u03f5 start_POSTSUBSCRIPT bold_italic_\u03b8 end_POSTSUBSCRIPT ( bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) nearly opposite to that of the original model, making the trajectory more likely to produce out-of-distribution samples. Note that, in the absence of an unconditional constraint, modifications to the conditional output also affect the unconditional output due to shared model parameters.\n(c) Anchor-Based Finetuned Trajectory. The model is finetuned so that the predicted score functions (or keys & values) for the unwanted concept align with those of the original model conditioned on a benign anchor, ensuring final samples lie on the anchor manifold, though not necessarily at the highest-probability mode.\n(d) Our Trajectory\u00a0(ANT). In the early stage (when t>t\u2032\ud835\udc61superscript\ud835\udc61\u2032t>t^{\\prime}italic_t > italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT), the conditional score functions remain directed toward the natural data mode, keeping the finetuned model aligned with the original. When t<t\u2032\ud835\udc61superscript\ud835\udc61\u2032t<t^{\\prime}italic_t < italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, they are finetuned to point away from the unwanted concept manifold. ANT encourages that unconditional score functions remain unchanged throughout all stages.", "description": "Figure 1 illustrates four different trajectories in diffusion models for concept erasure. (a) shows the standard denoising trajectory where a sample moves from a high-dimensional Gaussian distribution towards the natural image manifold guided by classifier-free guidance (CFG). (b) depicts an anchor-free approach where finetuning alters the score function to repel samples from the unwanted concept manifold, potentially leading to out-of-distribution samples. (c) illustrates an anchor-based method that aligns the score function of unwanted concepts with those of benign anchor concepts to steer samples toward the anchor manifold. Finally, (d) presents the proposed ANT method that preserves the early-stage score function while carefully adjusting later stages to avoid the unwanted concept manifold.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2504.12782/x2.png", "caption": "Figure 2: Generation results of different concept erasure methods conditioned on the concept \u201ccat\u201d. The anchor-free method (ESD) often produces images with visual artifacts or content that is out of distribution. The anchor-based method (MACE), which maps \u201ccat\u201d to \u201cforest\u201d, performs reasonably well in simple contexts but results in unnatural or incoherent outputs in more complex scenarios. In contrast, our trajectory-aware method (ANT) effectively removes the target concept while preserving the overall structure and contextual integrity of the generated images.", "description": "Figure 2 compares the performance of different concept erasure methods on diffusion models, using the concept \"cat\".  The anchor-free method (ESD) struggles, often resulting in images with visual artifacts or content unrelated to the prompt. The anchor-based method (MACE), which replaces \"cat\" with \"forest\", shows some success in simple scenarios. However, in more complex contexts, MACE produces unnatural or incoherent outputs.  In contrast, the researchers' novel trajectory-aware method (ANT) effectively removes the concept \"cat\" while maintaining the overall structure and coherence of the generated images.", "section": "2. Related Work"}, {"figure_path": "https://arxiv.org/html/2504.12782/x3.png", "caption": "Figure 3: Effect of condition direction reversal at different timesteps. Each column represents a distinct semantic condition, and each row shows generated outputs under varying reversal strategies. (a) displays originally generated images using a diffusion process (timestep 50\u21921). (b)\u2013(d) show results when the condition direction \ud835\udf39\u2062(\ud835\udc84)=\u03f5\ud835\udf3d\u2062(\ud835\udc9bt,t,\ud835\udc84)\u2212\u03f5\ud835\udf3d\u2062(\ud835\udc9bt,t)\ud835\udf39\ud835\udc84subscriptbold-italic-\u03f5\ud835\udf3dsubscript\ud835\udc9b\ud835\udc61\ud835\udc61\ud835\udc84subscriptbold-italic-\u03f5\ud835\udf3dsubscript\ud835\udc9b\ud835\udc61\ud835\udc61\\bm{\\delta}(\\bm{c})=\\bm{\\epsilon}_{\\bm{\\theta}}(\\bm{z}_{t},t,\\bm{c})-\\bm{%\n\\epsilon}_{\\bm{\\theta}}(\\bm{z}_{t},t)bold_italic_\u03b4 ( bold_italic_c ) = bold_italic_\u03f5 start_POSTSUBSCRIPT bold_italic_\u03b8 end_POSTSUBSCRIPT ( bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , bold_italic_c ) - bold_italic_\u03f5 start_POSTSUBSCRIPT bold_italic_\u03b8 end_POSTSUBSCRIPT ( bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) is reversed at different timesteps (25, 35, and 45). With a proper t\u2032superscript\ud835\udc61\u2032t^{\\prime}italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, specific attributes can be removed while preserving image naturalness. If t\u2032superscript\ud835\udc61\u2032t^{\\prime}italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is too early, structural integrity is lost; if too late, only fine details are affected.", "description": "Figure 3 illustrates the impact of altering the condition direction during different stages of the denoising process in a diffusion model.  The condition direction,  \u03b4(c) = \u03f5\u03b8(zt, t, c) - \u03f5\u03b8(zt, t), represents the difference between the conditional and unconditional predictions of the model. By reversing this direction at various timesteps (t'), the model's ability to modify specific image attributes (such as occupation, gender, and age in this example) is tested.  Panel (a) shows the generation of original images.  Panels (b) through (d) demonstrate the impact of changing the condition direction at timesteps 25, 35, and 45 respectively. The results show that reversing the condition direction at an appropriate time (t'=35) allows selective attribute modification without disrupting the overall image structure. Reversal too early (t'=45) leads to structural artifacts, while reversal too late (t'=25) only affects fine image details.", "section": "Method"}, {"figure_path": "https://arxiv.org/html/2504.12782/x4.png", "caption": "Figure 4: Each subplot shows the number of active parameters (y-axis) against the number of intersected saliency maps (x-axis) for four concepts: (a) Nudity, (b) Donald Trump, (c) Van Gogh Style, and (d) Dog. The number of active parameters converges across different concept types with around 100 intersected saliency maps.", "description": "This figure visualizes the convergence of the number of active parameters identified using the intersection of multiple saliency maps.  Four different concepts\u2014(a) Nudity, (b) Donald Trump, (c) Van Gogh Style, and (d) Dog\u2014are examined. Each subplot displays the count of active parameters (Y-axis) against the number of intersected saliency maps (X-axis).  The results show that regardless of the concept, the number of active parameters stabilizes around 100 intersected saliency maps, indicating a consistent trend in parameter selection across different concepts.", "section": "3.3. The Heavy Hitters Among the Parameters"}, {"figure_path": "https://arxiv.org/html/2504.12782/x5.png", "caption": "Figure 5: Generation of the concept-specific saliency map \ud835\udc74\u2217superscript\ud835\udc74\\bm{M}^{*}bold_italic_M start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT. GPT-4 generates prompts \ud835\udc9e={ci}i=1Nc\ud835\udc9esuperscriptsubscriptsubscript\ud835\udc50\ud835\udc56\ud835\udc561subscript\ud835\udc41\ud835\udc50\\mathcal{C}=\\{c_{i}\\}_{i=1}^{N_{c}}caligraphic_C = { italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, each paired with random seeds \ud835\udcae={sj}j=1Ns\ud835\udcaesuperscriptsubscriptsubscript\ud835\udc60\ud835\udc57\ud835\udc571subscript\ud835\udc41\ud835\udc60\\mathcal{S}=\\{s_{j}\\}_{j=1}^{N_{s}}caligraphic_S = { italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, which are used to compute gradient maps. After thresholding, saliency maps are obtained, and their intersection across all prompts and seeds yields \ud835\udc74\u2217superscript\ud835\udc74\\bm{M}^{*}bold_italic_M start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT.", "description": "This figure illustrates the process of generating a concept-specific saliency map (M*) used to identify crucial model parameters for efficient concept erasure.  Multiple prompts (C) and random seeds (S) are used to generate gradient maps, which pinpoint parameters strongly correlated with the target concept.  After thresholding these maps, their intersection across all prompts and seeds yields the final concept-specific saliency map (M*), guiding the finetuning process to only adjust the most relevant parameters for removing the undesired concept. This approach avoids unnecessary adjustments of other parts of the model, improving accuracy and efficiency of erasure.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.12782/x6.png", "caption": "Figure 6: Multi-LoRA fusion for multi-concept erasure.", "description": "This figure illustrates the process of fusing multiple LoRA (Low-Rank Adaptation) modules in a multi-concept erasure framework.  Each LoRA module is trained to remove a specific unwanted concept from the image generation model.  The fusion process combines the individual LoRA modules in a way that effectively removes multiple concepts simultaneously without negatively impacting the generation of other, desired concepts. The diagram visually depicts the fusion objective that aims to find a set of optimal parameters that minimizes the discrepancy between the original weight matrices and the updated matrices after incorporating the adjustments from each LoRA module.", "section": "3.4 Boosting the Performance of Multi-Concept Erasure Frameworks"}, {"figure_path": "https://arxiv.org/html/2504.12782/x7.png", "caption": "Figure 7: Qualitative comparison of erasing 100 celebrities from SD v1.4. John Wayne and Tom Hiddleston are in the erasure group for evaluating erasure performance; John Lennon and Gal Gadot are in preservation group for assessing preservation performance. Preserving John Lennon is challenging due to the shared first name with John Wayne.", "description": "Figure 7 presents a qualitative comparison of the results from erasing 100 celebrities from Stable Diffusion v1.4.  The top two rows show the results of erasing John Wayne and Tom Hiddleston, respectively, demonstrating the effectiveness of the erasure technique. The bottom two rows display the results for John Lennon and Gal Gadot who were in the preservation group, showcasing the model's ability to preserve unrelated identities. Note that erasing John Wayne presented a significant challenge for the model due to John Lennon's shared first name.", "section": "4.3. Erasing Celebrity"}, {"figure_path": "https://arxiv.org/html/2504.12782/x8.png", "caption": "Figure 8: Qualitative comparison on art style erasure. The images on the same row are generated using the same random seed. Chris Van Allsburg and Claude Monet are in the erasure group, while Adriaen Van Outrecht and Adrian Ghenie are in the retention group.", "description": "Figure 8 presents a qualitative comparison of the results of art style erasure across different methods.  Each row shows images generated from the same random seed, allowing for direct comparison of how each method handles the task.  The top two rows display results for the erasure of styles by Chris Van Allsburg and Claude Monet, demonstrating the effectiveness of each method in removing those specific artistic influences. The bottom two rows display results for preserving the styles of Adriaen Van Outrecht and Adrian Ghenie, showing how well each method avoids unintended alterations to unrelated styles during the erasure process.  The figure highlights the relative strengths and weaknesses of different approaches to art-style erasure, demonstrating whether they successfully remove the targeted styles while maintaining the integrity of the unrelated styles.", "section": "4.4. Erasing Art Style"}]