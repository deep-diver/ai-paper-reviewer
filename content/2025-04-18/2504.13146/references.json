{"references": [{"fullname_first_author": "Aaron Jaech", "paper_title": "Openai o1 system card", "publication_date": "2024-12-01", "reason": "This system card provides comprehensive information about the capabilities and limitations of the specified OpenAI system and sets a precedent of transparency, which is the core objective of the main paper."}, {"fullname_first_author": "Geoffrey Hinton", "paper_title": "Distilling the knowledge in a neural network", "publication_date": "2015-03-01", "reason": "This paper is fundamental to the concept of knowledge distillation, which the current paper aims to defend against, marking it as a key point of reference."}, {"fullname_first_author": "Daya Guo", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-01", "reason": "This paper describes a state-of-the-art LLM with strong reasoning capabilities that could be a target for distillation, making it a relevant example in the context of the current study."}, {"fullname_first_author": "Andy Zou", "paper_title": "Universal and transferable adversarial attacks on aligned language models", "publication_date": "2023-07-01", "reason": "This paper relates to the broader issue of model security and vulnerabilities in LLMs, aligning with the concern of the core paper on protecting models."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-01", "reason": "This paper discusses a methodology for solving math word problems, relevant as the evaluation task uses a math dataset, emphasizing the importance of understanding how models solve math problems for better protection."}]}