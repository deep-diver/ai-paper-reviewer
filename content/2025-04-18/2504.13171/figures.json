[{"figure_path": "https://arxiv.org/html/2504.13171/x1.png", "caption": "Figure 1: Example of applying sleep-time compute on Multi-Query GSM-Symbolic-P1. Sleep-time compute processes the original raw context, adding additional computations that can potentially be useful for future queries. Moreover, contexts can be shared across related queries enabling savings in total cost per query.", "description": "Figure 1 illustrates the concept of sleep-time compute using the Multi-Query GSM-Symbolic-P1 dataset.  The figure shows two scenarios: a standard test-time compute setting, where the model receives the query and context simultaneously at test time; and a sleep-time compute setting, where the model processes the context offline during 'sleep time' to perform pre-computations and create a more informative context.  These pre-computations can include identifying patterns, predicting answers, and generating additional information that might be helpful for answering future queries related to the same context. The sleep-time compute approach significantly reduces the computational cost and latency at test time by reusing the pre-computed information from sleep time for subsequent queries on the same context.  In the example, sleep-time compute identifies useful information and precomputes relevant quantities within the learned context. This reduces the computational work required at test time when answering questions related to the same context, effectively saving computation.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.13171/x2.png", "caption": "Figure 2: Example of separating an instance from GSM-Symbolic into context, and question, creating an instance in Stateful GSM-Symbolic.", "description": "The figure illustrates the transformation of a problem instance from the original GSM-Symbolic dataset into the new Stateful GSM-Symbolic dataset.  The original GSM-Symbolic dataset presents a single query-answer pair where a question and the context to answer the question are interwoven.  The Stateful GSM-Symbolic dataset, however, decouples the context and the query.  The left panel shows the original GSM-Symbolic format with the context and question combined in a single text.  The right panel shows how this is separated in Stateful GSM-Symbolic, making the context and query distinct, allowing for sleep-time compute to be applied more effectively.  This separation enables the model to pre-process the context (c) at sleep time before receiving the query (q) at test time, improving efficiency and reducing compute cost.", "section": "4.1 Datasets"}, {"figure_path": "https://arxiv.org/html/2504.13171/x3.png", "caption": "Figure 3: The test-time compute vs. accuracy tradeoff for on Stateful GSM-Symbolic. Shaded area indicates where sleep-time compute improves the pareto test-time accuracy trade-off.", "description": "This figure shows the Pareto frontier for the tradeoff between test-time compute and accuracy on the Stateful GSM-Symbolic dataset.  The x-axis represents the average number of test-time tokens used per question, while the y-axis represents the accuracy achieved.  Separate lines are shown for models using standard test-time compute only and models augmented with sleep-time compute. The shaded region highlights where incorporating sleep-time compute results in a Pareto improvement\u2014achieving either higher accuracy with the same compute, or the same accuracy with less compute. This illustrates that sleep-time compute can improve the efficiency of test-time computation without sacrificing model performance.", "section": "5.1 Improving Pareto Test-Time Trade-off with sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x4.png", "caption": "Figure 4: The test-time compute vs. accuracy tradeoff on Stateful AIME for various reasoning models. Applying sleep-time compute allows models to reach similar levels of performance with much less compute at test-time. The shaded area indicates the pareto improvement from sleep-time compute.", "description": "This figure displays the Pareto frontier for test-time compute versus accuracy on the Stateful AIME dataset for several reasoning models.  The x-axis represents the average number of test-time tokens used per question, and the y-axis represents the accuracy achieved.  Separate lines show the performance of each model under a standard test-time compute approach and with the addition of sleep-time compute. The shaded regions highlight the Pareto improvements achieved by incorporating sleep-time compute, demonstrating that similar accuracy levels can be reached with significantly less test-time computation. This illustrates the efficiency gains of sleep-time compute in reducing the computational cost of achieving high accuracy.", "section": "5.1 Improving Pareto Test-Time Trade-off with sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x5.png", "caption": "Figure 5: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful GSM-Symbolic. We see that sleep-time compute generally pareto dominates pass@k.", "description": "Figure 5 presents a comparison of two methods for enhancing Large Language Model (LLM) performance on the Stateful GSM-Symbolic dataset: test-time scaling with sleep-time compute and parallel test-time scaling with pass@k. The graph illustrates the trade-off between test-time compute (measured as average tokens used per query) and accuracy. The results reveal that sleep-time compute consistently outperforms pass@k across various compute budgets, achieving higher accuracy with the same or less compute. This suggests that sleep-time compute is a more efficient strategy for improving LLM performance on this type of task.", "section": "5.1 Improving Pareto Test-Time Trade-off with sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x6.png", "caption": "Figure 6: Comparing test-time scaling with sleep-time compute against parallel test-time scaling with pass@k on Stateful AIME. We see that sleep-time compute generally pareto dominates pass@k.", "description": "This figure compares two methods for scaling test-time computation in large language models (LLMs): sleep-time compute and parallel test-time scaling using pass@k.  Both approaches aim to improve accuracy on challenging reasoning tasks. The x-axis represents the amount of test-time compute used (measured in tokens), and the y-axis represents the accuracy achieved. The graph shows that sleep-time compute consistently outperforms parallel pass@k scaling. For a given level of accuracy, sleep-time compute requires significantly less test-time compute than pass@k, indicating its superior efficiency. This dominance is visualized as a Pareto improvement, where sleep-time compute achieves a higher accuracy for the same amount of compute, or requires less compute to achieve the same accuracy.", "section": "Experiments and Results"}, {"figure_path": "https://arxiv.org/html/2504.13171/x7.png", "caption": "Figure 7: Scaling up sleep-time compute for different test-time compute budgets on Stateful GSM-Symbolic, by generating up multiple c\u2032superscript\ud835\udc50\u2032c^{\\prime}italic_c start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT in parallel. Applying more sleep-time compute shifts the pareto beyond the standard test-time-compute vs. accuracy curve.", "description": "This figure displays the results of an experiment evaluating the impact of scaling up sleep-time compute on the Pareto frontier of test-time compute versus accuracy.  The experiment uses the Stateful GSM-Symbolic dataset, a modified version of GSM-Symbolic designed for stateful reasoning problems. The x-axis represents the average number of test-time tokens per question, and the y-axis represents the accuracy achieved. Multiple lines are shown, each representing a different level of sleep-time compute scaling (achieved by generating multiple versions of the precomputed context 'c' in parallel during the sleep-time phase). The figure demonstrates that increasing the scale of sleep-time compute leads to a Pareto improvement, meaning that higher accuracy can be achieved with the same or less test-time compute.  The improvement is so substantial that the new Pareto frontier extends beyond what was achievable with test-time compute alone.", "section": "5.1 Improving Pareto Test-Time Trade-off with sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x8.png", "caption": "Figure 8: Increasing the amount of sleep-time compute for different test-time compute budgets on Stateful AIME by varying the reasoning effort when applying the sleep-time compute prompt. Applying more sleep-time compute further moves the test-time-compute vs. accuracy pareto curve.", "description": "This figure shows how increasing the amount of computation performed during the 'sleep time' phase (before receiving the actual query) affects the performance of a model on the Stateful AIME dataset.  The x-axis represents the amount of computation at test time, while the y-axis represents the accuracy of the model.  Different lines show the model's performance with varying levels of 'sleep-time' computation, achieved by adjusting the level of reasoning effort in the sleep-time prompt. The shaded area highlights the Pareto improvement, showing that using more 'sleep-time' computation leads to significant gains in test-time efficiency, allowing the model to achieve the same accuracy level with much less computation at test time.  This improves the Pareto frontier of test-time compute versus accuracy.", "section": "5.1 Improving Pareto Test-Time Trade-off with sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x9.png", "caption": "Figure 9: Amortizing sleep-time compute, using the Multi-Query GSM-Symbolic dataset. When there are fewer questions per context, we see that it is less favorable to use sleep-time compute, in terms of total cost. However, as the questions per context are increased, we see that applying sleep-time compute can improve the cost-accuracy pareto.", "description": "This figure analyzes the cost-effectiveness of using sleep-time compute in scenarios with multiple related queries about the same context.  The x-axis represents the average total inference cost per query, and the y-axis shows the accuracy achieved.  Different lines show results for different numbers of questions asked per context (1, 2, 5, and 10).  The figure demonstrates that when only a few queries are asked per context, using sleep-time compute is less beneficial in terms of overall cost.  As the number of queries per context increases, the benefits of sleep-time compute become more significant; it shifts the cost-accuracy Pareto curve outward, improving the overall cost-effectiveness. This indicates that amortizing sleep-time compute across related questions significantly reduces the average cost per query while maintaining or even improving accuracy.", "section": "Amortizing sleep-time compute across queries with shared context"}, {"figure_path": "https://arxiv.org/html/2504.13171/x10.png", "caption": "Figure 10: GSM-Symbolic questions binned by how predictable they are from the context. We compare the performance of sleep-time compute and standard test-time compute in the lowest test-time compute budget setting on both P1 and P2. The gap between sleep-time compute and standard test-time inference widens as the question becomes more predictable from the context.", "description": "This figure analyzes the impact of query predictability on the effectiveness of sleep-time compute.  It divides GSM-Symbolic questions (P1 and P2 datasets) into five groups based on how easily they can be predicted from the given context.  The x-axis represents these predictability bins (higher values mean higher predictability). The y-axis shows the accuracy difference between sleep-time compute and standard test-time compute, both using the minimal test-time compute budget.  The results demonstrate that as the questions become more predictable (moving to higher predictability bins), the performance advantage of sleep-time compute increases, as shown by the widening gap between the two methods.", "section": "5.4 Predictable queries benefit more from sleep-time compute"}, {"figure_path": "https://arxiv.org/html/2504.13171/x11.png", "caption": "Figure 11: Applying sleep-time compute to SWE-Features. We see that at lower test-time budgets, sleep-time compute has higher F1 score than standard test-time scaling. However, at higher budgets, standard test-time scaling is better.", "description": "This figure shows the results of applying sleep-time compute to the SWE-Features dataset. The x-axis represents the average number of test-time tokens per question, and the y-axis represents the F1 score. The blue line shows the performance of the model with sleep-time compute, and the grey line shows the performance of the model with standard test-time compute only. As shown, when the test-time budget is low, sleep-time compute outperforms the standard test-time compute in terms of F1 score.  However, as the test-time budget increases, the performance of the standard test-time compute surpasses that of sleep-time compute.", "section": "A Case Study of Sleep-time Compute for Agentic SWE"}, {"figure_path": "https://arxiv.org/html/2504.13171/x12.png", "caption": "Figure 12: Prompt for level 0 verbosity", "description": "This figure displays the prompt used for level 0 verbosity in the Letta model.  The prompt instructs the model to answer questions accurately and concisely, basing its response on its persona. To communicate with the user, the model should use the `send_message` function. The prompt directs the model to check the `rethink_memory` block for relevant information before answering.  It emphasizes using existing information and avoiding unnecessary computation, recommending a direct, single-sentence response containing only the numerical answer.", "section": "4 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2504.13171/x13.png", "caption": "Figure 13: Prompt for level 1 verbosity", "description": "This figure shows the prompt used for level 1 verbosity in the Letta model.  The prompt instructs the model to answer questions concisely and accurately, using only the necessary tokens.  It directs the model to check its internal \"rethink_memory_block\" for relevant information before generating a response, avoiding redundant computation.  The final answer should include a short explanation followed by the numerical result.", "section": "4 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2504.13171/x14.png", "caption": "Figure 14: Prompt for level 2 verbosity", "description": "This figure shows the prompt used for level 2 verbosity in the Letta reasoning system.  The prompt instructs the model to answer questions accurately and concisely, using only the necessary number of tokens.  It emphasizes the use of the 'rethink_memory_block' for information retrieval, avoiding redundant computations. The model should respond directly with the numerical answer at the end of the message without providing further reasoning.", "section": "4 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2504.13171/x15.png", "caption": "Figure 15: Prompt for level 3 verbosity", "description": "This figure shows the prompt used for level 3 verbosity in the Letta system.  The prompt instructs the model to answer questions accurately and concisely, using only the necessary tokens and relying on information already present in the `rethink_memory_block`. It emphasizes avoiding redundant computation and only using internal monologue when strictly necessary. The final answer should be a single numerical value.", "section": "4 Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2504.13171/x16.png", "caption": "Figure 16: Prompt for level 4 verbosity", "description": "This figure displays the prompt used for level 4 verbosity in the Letta reasoning system.  Level 4 verbosity prompts the model to reason through problems step-by-step and explain its reasoning process clearly. The model should use the 'rethink_memory_block' to access information and avoid redundant computations.  The model should clearly explain each step of its reasoning, including any recomputations of numbers found in the 'rethink_memory_block'. The final numerical answer should be presented at the end of the response.  This approach prioritizes thoroughness and explanation, aiming to improve the transparency and understandability of the model's decision-making process.", "section": "Experimental Setup"}, {"figure_path": "https://arxiv.org/html/2504.13171/x17.png", "caption": "Figure 17: Prompt for sleep-time compute", "description": "This figure shows the prompt used for sleep-time compute in the experiments. The prompt instructs the model to act as Letta-Offline-Memory, a digital companion that reorganizes and consolidates memories at each step using the `rethink_memory` function. The core memory unit contains initial system instructions and context, including persona and user details. Read-only blocks store persona information and user details, allowing for consistent responses. Read-write blocks allow for dynamic memory updates using `rethink_memory`. The prompt emphasizes integrating new information, prioritizing new data, and considering potential consequences of updates. It instructs the model to draw logical conclusions and potential hypotheses using internal monologue when uncertain. The final output should replace outdated facts in the new memory block.", "section": "4 Experimental Setup"}]