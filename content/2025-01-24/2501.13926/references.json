{"references": [{"fullname_first_author": "Lightman, H.", "paper_title": "Let's verify step by step", "publication_date": "2023-05-20", "reason": "This paper introduces a step-by-step verification method for enhancing reasoning in large language models, which is directly relevant to the current paper's approach of applying similar strategies to image generation."}, {"fullname_first_author": "Wei, J.", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper is foundational for the concept of Chain-of-Thought (CoT) prompting, a key technique explored in the current paper for improving autoregressive image generation."}, {"fullname_first_author": "Zhang, R.", "paper_title": "Mathverse: Does your multimodal LLM truly see the diagrams in visual math problems?", "publication_date": "2024-10-01", "reason": "This paper explores the application of CoT reasoning in multimodal LLMs for solving mathematical problems, providing a related example of applying multi-step reasoning to a complex task."}, {"fullname_first_author": "Ramesh, A.", "paper_title": "Hierarchical Text-Conditional Image Generation with CLIP Latents", "publication_date": "2022-04-06", "reason": "This paper introduces a significant advancement in text-to-image generation, using CLIP latent representations, which forms a key basis for the current paper's investigation into autoregressive image generation."}, {"fullname_first_author": "Xie, J.", "paper_title": "Show-o: One single transformer to unify multimodal understanding and generation", "publication_date": "2024-08-12", "reason": "This paper introduces the Show-o model, a crucial baseline model used in the current paper's experiments for evaluating the effectiveness of the proposed reasoning strategies."}]}