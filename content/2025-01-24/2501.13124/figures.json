[{"figure_path": "https://arxiv.org/html/2501.13124/x1.png", "caption": "Figure 1: Illustration of debate. Illustration of the debate procedure between debater A and debater B.", "description": "This figure illustrates a three-turn debate between two large language models (LLMs) acting as debaters,  Debater A and Debater B.  Each turn involves a prompt that presents a science knowledge question and an answer, instructing the debaters to argue for or against the correctness of the answer. Debater A argues for the correctness, while Debater B initially argues against it and then presents a counterargument in response to Debater A's points. This process simulates how a debate could help extract reliable information from potentially untrustworthy models, forming a crucial step in the weak-to-strong generalization approach described in the paper.", "section": "Argument Generation through Debate"}, {"figure_path": "https://arxiv.org/html/2501.13124/x2.png", "caption": "Figure 2: Ablation study on the cardinality of the ensemble. Here, our approach uses debate ensembles.", "description": "This figure displays the results of an ablation study investigating the impact of varying the number of weak models within an ensemble on the performance of a weak-to-strong generalization approach.  The x-axis represents the number of weak models in the ensemble (cardinality), and the y-axis shows the accuracy achieved.  Two datasets, SciQ and AnthropicHH, are shown, illustrating how the optimal ensemble size may vary depending on the dataset. The experiment uses debate ensembles, a specific type of ensemble where the weak models are trained on different debate transcripts.  The figure demonstrates the relationship between ensemble size and model performance, showing that beyond a certain cardinality (e.g. 4 models), increasing the number of weak models provides diminishing returns.", "section": "Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2501.13124/x3.png", "caption": "Figure 3: Ablation on the number of turns of debate. Here, our approach uses debate ensembles.", "description": "This ablation study investigates the impact of varying the number of turns in the debate process on the overall performance of the model.  Using debate ensembles, the experiment measures accuracy on the SciQ and AnthropicHH datasets while adjusting the number of turns in the debate from 3 to 6.  The results illustrate the relationship between debate length and model accuracy, revealing whether extending the debate improves or hinders performance and whether there's a point of diminishing returns.", "section": "Ablation Studies"}]