{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper describes GPT-4, a large language model from OpenAI, which is frequently used as a baseline and evaluator in this paper."}, {"fullname_first_author": "Zheng Chu", "paper_title": "TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models", "publication_date": "2024-01-01", "reason": "This paper is cited as a related work and motivates the need for more comprehensive temporal reasoning benchmarks, similar to the introduced one."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "publication_date": "2022-01-01", "reason": "This paper introduces chain-of-thought prompting, a technique used in this study to enhance temporal reasoning performance."}, {"fullname_first_author": "Wenhu Chen", "paper_title": "A Dataset for Answering Time-Sensitive Questions", "publication_date": "2021-01-01", "reason": "This paper introduces a dataset related to answering time-sensitive questions and is a related benchmark to this paper's focus on temporal reasoning."}, {"fullname_first_author": "An Yang", "paper_title": "Qwen2.5 Technical Report", "publication_date": "2024-01-01", "reason": "This paper describes the Qwen2.5, a specific version of the Qwen model family that performs well on the Chinese Time Reasoning benchmark."}]}