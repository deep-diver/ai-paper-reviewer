{"references": [{"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "This paper introduces 3D Gaussian Splatting (3DGS), a novel approach for real-time radiance field rendering, which is the core technology WildGS-SLAM leverages for scene representation."}, {"fullname_first_author": "Zachary Teed", "paper_title": "Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras", "publication_date": "2021-01-01", "reason": "WildGS-SLAM's tracking component is based on DROID-SLAM, making it a crucial element for camera pose estimation in dynamic environments."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-01-01", "reason": "WildGS-SLAM utilizes DINOv2 features to predict per-pixel uncertainty, a key aspect of removing dynamic distractors from the scene."}, {"fullname_first_author": "Hidenobu Matsuki", "paper_title": "Gaussian splatting slam", "publication_date": "2024-01-01", "reason": "This paper uses Gaussian Splatting for SLAM; a direct predecessor to the WildGS-SLAM approach and important comparison point."}, {"fullname_first_author": "Erik Sandstr\u00f6m", "paper_title": "Splat-slam: Globally optimized rgb-only slam with 3d gaussians", "publication_date": "2024-01-01", "reason": "Splat-SLAM is the state-of-the-art (SoTA) in monocular Gaussian Splatting SLAM, offering high-accuracy mapping with robust global consistency that WildGS-SLAM improves upon in dynamic environments."}]}