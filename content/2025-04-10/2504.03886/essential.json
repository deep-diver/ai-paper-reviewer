{"importance": "This paper introduces WildGS-SLAM, a novel monocular SLAM system, offering a robust solution for dynamic environments by integrating uncertainty-aware mapping. This approach enhances **reconstruction accuracy** and enables artifact-free view synthesis, paving the way for more reliable SLAM applications in real-world scenarios. It sets a new benchmark for SLAM in dynamic environments and opens avenues for uncertainty modeling in geometric mapping.", "summary": "WildGS-SLAM: A novel monocular SLAM system robust to dynamic scenes, using uncertainty-aware mapping to remove distractors and improve reconstruction quality.", "takeaways": ["WildGS-SLAM robustly handles dynamic environments without needing explicit depth or semantic labels.", "A new uncertainty-aware tracking and mapping pipeline removes dynamic distractors effectively.", "The Wild-SLAM Dataset enables comprehensive benchmarking in dynamic environments."], "tldr": "Simultaneous Localization and Mapping (SLAM) in dynamic environments is challenging because traditional SLAM systems assume static scenes, leading to errors when objects move independently. Recent methods use motion segmentation or semantic info but struggle to generalize across varied motion patterns, especially with real-world distractions, occlusions, and lighting changes. Existing uncertainty-aware methods in scene reconstruction and view synthesis require camera poses as input.\n\nTo solve this, **WildGS-SLAM** leverages a 3D Gaussian Splatting (3DGS) representation robustly in dynamic environments using monocular RGB input. It integrates uncertainty-aware tracking and mapping, removing dynamic distractors without depth or semantic labels. A shallow multi-layer perceptron (MLP) and DINOv2 features predict per-pixel uncertainty, guiding dynamic object removal during tracking and mapping. This enhances dense bundle adjustment and Gaussian map optimization. Evaluation shows improved performance in dynamic environments compared to state-of-the-art methods.", "affiliation": "Stanford University", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2504.03886/podcast.wav"}