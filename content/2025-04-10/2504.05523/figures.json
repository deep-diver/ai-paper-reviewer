[{"figure_path": "https://arxiv.org/html/2504.05523/x1.png", "caption": "(a) Finetuned models with Llama3 8B baseline", "description": "This figure displays cross-time perplexity results for finetuned models using Llama3-8B as a baseline.  It shows how the perplexity (a measure of how well a model predicts a sequence of words) varies across different time periods for the models. The x-axis represents time periods within the corpus, and the y-axis represents the normalized perplexity. Each line represents a different model trained on a specific time slice of the data. The plot allows comparison of model perplexity within its own time slice and against other time slices, indicating whether the model is able to distinguish between time periods effectively.", "section": "4 Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x2.png", "caption": "(b) Pretrained models with BabyLlama2 baseline", "description": "This figure shows the cross-time perplexities for pretrained models using the BabyLlama2 baseline.  The x-axis represents the time period, and the y-axis represents the normalized log perplexity. Different colored lines represent different time slices.  The graph helps visualize how well each model trained on a specific time period performs on text from different time periods, indicating whether the model's knowledge is limited to its training period or if it has a better understanding of language across time.", "section": "4 Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x3.png", "caption": "Figure 1: Cross-time perplexities", "description": "This figure displays the cross-time perplexity for two sets of language models: finetuned models (using Llama3-8B as a base) and pretrained models (using BabyLlama2).  Each line represents a model trained on a specific 10-million-word slice of the corpus, spanning different historical periods. The x-axis shows the time period and the y-axis represents the perplexity (a measure of how well the model predicts the next word). The perplexity scores are calculated for each model across all five time slices (cross-time). Lower perplexity indicates better prediction performance. This figure helps visualize how well each model generalizes across different time periods, highlighting the performance differences between the finetuned and pretrained models.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2504.05523/x4.png", "caption": "(a) Finetuned models with Llama3 8B baseline", "description": "This figure shows the cross-time perplexity of finetuned models using Llama3-8B as a baseline.  The x-axis represents the time period, and the y-axis represents the normalized log perplexity.  Multiple lines represent different time slices the models were trained on. The plot helps visualize how well each model generalizes to time periods outside its training data, indicating whether it is sensitive to specific time periods or a-historical.  Lower perplexity values indicate better fluency and potentially better adherence to the linguistic characteristics of the specific time period.", "section": "4 Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x5.png", "caption": "(b) Pretrained models with BabyLlama2 baseline", "description": "This figure shows the cross-time perplexities of pretrained models using the BabyLlama2 baseline.  The x-axis represents the time period, and the y-axis represents the perplexity.  Multiple lines represent perplexity scores for different time slices (e.g., 1750-1820, 1820-1850, etc.), illustrating how well each model trained on a specific period predicts text from other periods. Lower perplexity generally suggests better model performance and a closer fit to the respective time slice, while higher perplexity suggests poorer performance or the presence of information from other periods.", "section": "4 Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x6.png", "caption": "Figure 2: Model performance on the top 100 completion cloze task", "description": "This figure displays the performance of both pretrained and finetuned models on a cloze task.  The x-axis represents the time period, and the y-axis represents the percentage of correctly completed cloze tasks within the top 100 predictions. Separate graphs are shown for models pretrained using the BabyLlama2 and Llama3-8B baselines. The figure highlights the varying performance of the models across different time periods, demonstrating how the pretrained models tend to excel within their specific time period while the finetuned models show less specialization.", "section": "3.3 Evaluation"}, {"figure_path": "https://arxiv.org/html/2504.05523/x7.png", "caption": "Figure 3: Probability of Leakage, over pretrained and finetuned models.", "description": "This figure shows the probability of the finetuned and pretrained models making predictions based on data from time periods outside of their training data.  A high probability of leakage indicates that the model is 'leaking' information from other time periods and not solely relying on the data it was trained on. This is especially problematic for tasks like lexical sense-change analysis which requires precise temporal boundaries. The figure visually represents the extent of this leakage across different time periods for both model types, allowing for a comparison of their ability to respect the intended historical divisions.", "section": "4 Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x8.png", "caption": "Figure 4: Natural appearances of \u201dstation\u201d with a descending probability trajectory and manually labelled for sense.", "description": "Figure 4 shows the probability trajectories of two different senses of the word \"station\" over time. The probabilities are calculated using the pretrained models from different time periods.  The x-axis represents the time period, and the y-axis represents the probability. The graph shows a clear distinction between the two senses: \"station\" referring to a train station and \"station\" referring to a temporary camp or stopover.  The probability of the \"train station\" sense increases sharply around the mid-19th century, reflecting the adoption of railways, while the \"camp/stopover\" sense maintains a relatively stable, but gradually increasing probability over the same time frame. This visualization supports the paper's claim that pretrained models effectively capture historically specific changes in word meaning, as they assign higher probabilities to the appropriate sense within each period.", "section": "4.3 Diachronic analysis"}, {"figure_path": "https://arxiv.org/html/2504.05523/x9.png", "caption": "Figure 5: Count of cloze tasks for per time slice for the set filtered for our data (14.6 thousand examples).", "description": "This figure shows the distribution of cloze tasks across different time periods after filtering the dataset.  The x-axis represents the time periods (1750-1820, 1820-1850, etc.), and the y-axis shows the number of cloze tasks in each time period. A total of 14,600 cloze tasks were used in the analysis. The bar chart visually represents the frequency of cloze tasks within each specified time period, illustrating how the dataset's temporal coverage is distributed.", "section": "3.3 Evaluation"}, {"figure_path": "https://arxiv.org/html/2504.05523/x10.png", "caption": "(a) Baseline (DoRA) MRR", "description": "This figure shows the mean reciprocal rank (MRR) performance of the DoRA finetuned models over time.  The x-axis represents the time period (1750-1820, 1820-1850, etc.), and the y-axis represents the MRR.  Separate lines represent the MRR for each time period's test set.  The plot visualizes how well the models trained on a specific time period generalize to other time periods, highlighting the model's ability to capture historical linguistic changes.", "section": "4. Results and discussion"}, {"figure_path": "https://arxiv.org/html/2504.05523/x11.png", "caption": "(b) BabyLlama MRR", "description": "This figure shows the mean reciprocal rank (MRR) performance of the pretrained BabyLlama models across different time slices. The MRR is a metric that measures the ranking accuracy of a model's top predictions.  Lower MRR values indicate lower ranking accuracy. The x-axis represents the time slices (1750-1820, 1820-1850, 1850-1880, 1880-1910, 1910-1940), and the y-axis shows the MRR.  The plot helps to visualize how the model's ability to predict the correct word changes over time for each slice.  The line representing the baseline model provides a comparison.", "section": "4.2 BLIMP"}]