[{"figure_path": "https://arxiv.org/html/2504.06514/extracted/6346885/figures/illu.png", "caption": "Figure 1: Illustration of MiP-Overthinking. When queried by questions with missing premises, the response length of reasoning models increases excessively, and they cannot abstain from answering with MiP identified. The left shows a query with an undefined variable, while the right compares a well-defined GSM8K question with its MiP variant (with a critical numerical condition removed). Reasoning models\u2019 responses to MiP questions are much longer than those for well-defined questions and those generated by non-reasoning models. The left corner of each response report the response length and thinking time by DeepSeek-R1.", "description": "The figure illustrates the phenomenon of MiP-Overthinking, where reasoning models generate excessively long responses to questions with missing premises (MiP).  The left panel shows a simple question with an undefined variable, highlighting the model's inability to abstain from answering.  The right panel contrasts a standard well-defined question from the GSM8K dataset with its MiP version (missing a key numerical fact). Reasoning models provide significantly longer and less effective answers to the MiP questions compared to well-defined questions and those from non-reasoning models.  Response length (in tokens) and processing time (in seconds) are reported in the upper left corner of each example, as measured using the DeepSeek-R1 model.", "section": "2 Missing Premise Definition and Construction"}, {"figure_path": "https://arxiv.org/html/2504.06514/x1.png", "caption": "Figure 2: Response lengths, accuracy on well-defined questions, and abstain rate of reasoning/non-reasoning models on MiP questions from our MiP-GSM8K dataset.\n(1) Existing reasoning models generate significantly longer responses for MiP questions than well-defined questions, while non-reasoning models generate responses of similar lengths for both types of questions, indicating MiP-Overthinking for reasoning models.\n(2) For both questions, reasoning models generate longer responses than non-reasoning models, indicating General Overthinking.\n(3) Although the longer responses by reasoning models slightly improve the accuracy for well-defined questions, it does not enhance the abstain rate for MiP questions, indicating a contradiction on the test-time scaling law.", "description": "Figure 2 presents a comparative analysis of reasoning and non-reasoning LLMs' performance on both well-defined and ill-defined (MiP) questions from the MiP-GSM8K dataset.  The figure shows three key aspects: (1) The response lengths of reasoning models dramatically increase when presented with MiP questions, exhibiting what the authors term \"MiP-Overthinking.\"  In contrast, non-reasoning models generate similarly length responses regardless of whether the question is well-defined or ill-defined. (2)  Across both question types, reasoning models produce significantly longer responses than their non-reasoning counterparts, illustrating \"General Overthinking.\" (3) Although longer responses in reasoning models slightly improve accuracy on well-defined questions, the increased length does not lead to an improvement in abstaining from ill-defined (MiP) questions. This contradicts the expected test-time scaling law, which suggests longer responses should correlate with better performance on complex tasks.", "section": "3 Overthinking under Missing Premise"}, {"figure_path": "https://arxiv.org/html/2504.06514/x2.png", "caption": "Figure 3: The step-level similarity heatmaps for s1.1 responses towards well-defined (left) and MiP (right) questions in MiP-GSM8K dataset. To avoid differences in matrix size, we only consider responses with more than 50 steps and visualize the average simialrity matrix across first 50 steps. The heatmap for MiP questions has a higher averaged similarity and lower standard variance, also shown in the heatmap, which indicates the considerable redundancy in its content when responding to MiP questions.", "description": "This figure displays heatmaps visualizing the similarity between consecutive reasoning steps in the responses generated by the S1.1 model to both well-defined and MiP questions from the MiP-GSM8K dataset.  Only responses exceeding 50 steps were included in the analysis, and the heatmaps show the average similarity across the first 50 steps to maintain consistent matrix sizes. The heatmap for MiP questions exhibits higher average similarity and lower variance across steps compared to the heatmap for well-defined questions. This suggests substantial redundancy and repetitive reasoning in the model's responses to MiP questions.", "section": "3.4 Step-level Similarities"}, {"figure_path": "https://arxiv.org/html/2504.06514/x3.png", "caption": "Figure 4: An example of reasoning model (s1.1-32B) response to a MiP question. The response exhibits five distinct thinking patterns, highlighted in different colors: \\raisebox{-0.9pt}{1}\u20ddRevisit Question (yellow), where the model reexamines the original query; \\raisebox{-0.9pt}{2}\u20ddVisit Knowledge (red), where the model accesses domain-specific knowledge; \\raisebox{-0.9pt}{3}\u20ddPropose Assumption (blue), where the model proposes and investigates various hypotheses; \\raisebox{-0.9pt}{4}\u20ddSelf Doubt (green), where the model questions its own reasoning and expresses uncertainty; and \\raisebox{-0.9pt}{5}\u20ddPause/Check (purple), where the model pauses to review previous steps. These patterns demonstrate the model\u2019s complex but potentially inefficient reasoning process when confronted with missing premises.", "description": "Figure 4 presents a detailed analysis of a reasoning model's response to a question with a missing premise. The model's response is broken down into five distinct thinking patterns, each highlighted with a different color and explained in detail:  Revisiting the question, accessing domain-specific knowledge, proposing and investigating hypotheses, expressing self-doubt, and pausing to review previous steps. The figure illustrates how the model engages in a complex but inefficient reasoning process due to the lack of necessary information to answer the question correctly.", "section": "3.5 Thinking Patterns through Example"}, {"figure_path": "https://arxiv.org/html/2504.06514/x4.png", "caption": "Figure 5: The transition flow between in-process suspicion of MiP and the final successful abstention on different reasoning models. For each Sankey diagram, the left bars represent whether the model suspects the given question is unsolvable during its thinking process, i.e., Suspected or Unsuspected; the right bars represent the final abstention, categorized into Abstain (preferred) or Non-abstain. Most existing reasoning models have suspected that the given question might be unsolvable, but only for a very small portion, the models insist on their suspicion.", "description": "This figure visualizes how different reasoning models transition from initially suspecting a missing premise (MiP) during their reasoning process to their final decision of either abstaining from answering or providing an answer.  Each Sankey diagram shows the proportion of models that suspected a MiP and then either abstained (the preferred outcome) or did not abstain (meaning they attempted to answer despite the missing premise).  The figure highlights that most reasoning models detect the MiP, but only a small percentage actually abstain, demonstrating a deficiency in critical thinking, despite recognizing the problem.", "section": "Overthinking under Missing Premise"}, {"figure_path": "https://arxiv.org/html/2504.06514/x5.png", "caption": "Figure 6: Comparison of response length, abstain rate of MiP, and accuracy of well-defined questions before and after tuning on 50 responses from DeepSeek-R1 on the MiP-Formula dataset. The results demonstrate rapid onset of MiP-Overthinking behavior after exposure to a small number of MiP examples during fine-tuning.", "description": "This figure displays the impact of fine-tuning a language model (Qwen-2.5-7B-Instruct) on a small dataset of 50 MiP (Missing premise) examples from DeepSeek-R1's responses on the MiP-Formula dataset.  Before fine-tuning, the model exhibits relatively short response lengths for both well-defined and MiP questions, with a high accuracy rate for well-defined questions and a relatively high abstention rate for MiP questions. After fine-tuning with the MiP examples, the model's response length increases significantly for both question types.  The accuracy on well-defined questions remains high, but the abstention rate on MiP questions drops substantially.  This demonstrates that exposure to even a small number of MiP examples during fine-tuning can rapidly induce MiP-Overthinking behavior in the model, characterized by excessively long responses to ill-posed questions, a failure to identify and abstain from answering these questions, and a contradictory effect on the accuracy and abstention rate metrics.", "section": "Overthinking under Missing Premise"}]