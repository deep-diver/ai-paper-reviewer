[{"figure_path": "https://arxiv.org/html/2504.06958/x1.png", "caption": "Figure 1: \nOverview of VideoChat-R1. Through reinforcement learning fine-tuning using GRPO, VideoChat-R1 has powerful spatio-temporal perception capabilities and can apply these capabilities in chatting scenarios.", "description": "This figure illustrates the architecture and functionality of VideoChat-R1, a video multimodal large language model enhanced with reinforcement learning.  The diagram shows how reinforcement learning fine-tuning with Group Relative Policy Optimization (GRPO) improves spatio-temporal perception capabilities.  Limited training samples are used to achieve significant improvements in specific tasks without sacrificing the model's general capabilities.  The figure also highlights examples of VideoChat-R1's enhanced abilities to understand and respond to queries related to video content, showcasing both improved spatio-temporal perception and its integration within chat-based interactions.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.06958/x2.png", "caption": "Figure 2: \nExamples on temporal grounding task. VideoChat-R1 gives a more accurate time interval after thinking.", "description": "Figure 2 presents two examples demonstrating VideoChat-R1's improved accuracy in temporal grounding compared to a standard fine-tuned (SFT) model.  Temporal grounding is the task of identifying the specific time segment within a video that corresponds to a given textual description. In both examples, the ground truth (correct answer) temporal segment is shown, followed by the outputs of the SFT model and VideoChat-R1.  Noticeably, VideoChat-R1 provides a more precise time interval than the SFT model in both cases.  This improved accuracy is attributed to the model's 'thinking' process, which allows it to refine its answer before providing a final output. The figure highlights the benefits of the reinforcement learning fine-tuning approach used for VideoChat-R1 in improving the model's spatio-temporal reasoning capabilities.", "section": "4.3 Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2504.06958/x3.png", "caption": "Figure 3: \nExamples on Video QA task. It can be seen that VideoChat-R1 can not only answer questions correctly but also provide relatively accurate reference time periods (glue).", "description": "Figure 3 presents two examples of VideoChat-R1 performing Video Question Answering (QA) tasks.  The model not only answers the questions correctly (selecting the right option from a multiple choice list) but also provides a time interval from the video (denoted as 'glue') that supports its answer. This shows the model's improved ability to both comprehend video content and pinpoint relevant segments within the video.  Each example shows the video question, the provided options, the ground truth answer and its corresponding timestamp, SFT's answer and timestamp, and VideoChat-R1's answer, timestamp and reasoning process.  VideoChat-R1's ability to provide the time interval ('glue') demonstrates its enhanced spatio-temporal awareness.", "section": "4.2 Ablation Studies and Discussions"}]