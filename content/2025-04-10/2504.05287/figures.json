[{"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/pipeline_full.png", "caption": "Figure 1: Our method achieves robust dexterous grasping from single-view object point clouds. It performs adaptive motions to disturbances such as object movement and external forces (a), and can grasp various objects with random poses, diverse shapes, sizes, materials, and masses, including shiny, heavy, deformable, thin, and transparent objects (b).", "description": "This figure demonstrates the robustness and dexterity of the proposed method for dexterous grasping.  Subfigure (a) showcases the adaptive motion capabilities of the robotic hand in response to external disturbances like object movement and applied forces.  The robot hand successfully adjusts its grasp to maintain a stable hold despite these perturbations. Subfigure (b) highlights the method's ability to grasp a wide variety of objects with diverse characteristics, including differences in shape, size, material (e.g., shiny, heavy, deformable), and mass.  The successful grasps in (b) demonstrate the generalization capacity of the approach to unseen objects.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/grasp_frame_new.png", "caption": "Figure 2: Overview of our framework. We first train a teacher policy with reinforcement learning (RL) which can access privileged information including ground-truth contacts and impulses, fully observable real-time object point clouds, and noise-free robot joint angles. Then we train a student policy with access only to initial single-view object point clouds and noisy robot joint angles. The student policy is trained with a mixed curriculum learning framework, which initially utilizes imitation learning (IL) for efficient teacher policy distillation, and gradually transitions to RL for exploration to deal with disturbances.\nThe contact and impulse reconstruction loss remains active during the whole student training process.", "description": "This figure illustrates the framework for training a robot to grasp objects using a mixed curriculum learning approach.  A teacher policy is first trained with reinforcement learning (RL) using privileged information (ground-truth contacts, impulses, full object point cloud, noise-free joint angles). Then, a student policy is trained using only initial single-view object point cloud data and noisy joint angles. This student policy is trained using a mixed curriculum: initially with imitation learning (IL) from the teacher policy, and then gradually transitioning to RL to improve adaptability to disturbances.  A contact and impulse reconstruction loss function is used throughout the entire training process for both policies.", "section": "III. METHOD"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/hardware.png", "caption": "Figure 3: Pre-grasping pose of our method. The finger angles are initialized to get a partially opened hand, while the arm joints are initialized according to the end-effector 6D pose by inverse kinematics. Specifically, the heading direction x (the red arrow) of the hand points to the object point cloud center c from a fixed starting point, and the palm direction y (the green arrow) is determined to enclose the objects from a narrow edge while avoiding singularity problems.\nThe hand is then set 25cm away from c along x.", "description": "The figure illustrates the pre-grasping pose configuration for the robot hand and arm before grasping an object.  The finger joints are initially set to a partially open state. Inverse kinematics is used to calculate the arm joint angles based on the desired 6D pose of the hand. The hand's heading direction (red arrow) points towards the object's center, while the palm direction (green arrow) is oriented to encompass the object from a narrow side, avoiding any potential singularity issues.  The hand is positioned 25 cm away from the object's center along its heading direction.", "section": "III. METHOD"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/objects5.jpg", "caption": "Figure 4: Hardware setup", "description": "The hardware setup for the dexterous grasping experiments consists of a Universal Robots UR5 robotic arm, a Wonik Robotics Allegro dexterous hand, and an Intel RealSense D435i RGB-D camera mounted above a table. The camera provides single-view object point clouds, while the robot arm and hand execute the grasping actions. The system operates with the policy running at 5 Hz and low-level PD controllers for the hand and arm running at 100 Hz.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/printed.jpg", "caption": "Figure 5: Real objects used for large-scale evaluation", "description": "This figure showcases the 512 real-world objects used for large-scale evaluation of the proposed robust dexterous grasping method.  The objects represent a diverse range of shapes, sizes, materials, and weights, encompassing everyday items to test the generalizability and robustness of the robotic grasping system in real-world scenarios.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/adapt4.jpg", "caption": "Figure 6: Objects used for comparisons and ablation", "description": "The figure displays 30 objects employed in the comparative analysis and ablation study. These objects, selected for their diverse shapes, sizes, and materials, were used in both simulation and real-world experiments to thoroughly evaluate the robustness and generalizability of the proposed method compared to existing techniques. The inclusion of a variety of object types ensures comprehensive testing of the grasping algorithm across different scenarios.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/spring_obj.png", "caption": "Figure 7: Our method can adapt the poses for stable grasping when unexpected collision occurs due to internal disturbances (a), deal with unobserved object movement (b), and maintain robust grasps when the object slips due to large external forces (c).", "description": "Figure 7 demonstrates the robustness of the proposed method in handling various real-world disturbances during grasping.  (a) shows how the method adapts grasping poses to recover from unexpected collisions caused by internal disturbances. (b) showcases the ability to maintain successful grasps even when objects move unexpectedly before or during the grasping process. Finally, (c) illustrates the resilience of the system in maintaining a stable grasp when external forces are applied, preventing the object from slipping.", "section": "IV. EXPERIMENTS"}]