[{"figure_path": "https://arxiv.org/html/2504.07092/x1.png", "caption": "Figure 1: Where Should We Go? Object-centric learning (OCL) has focused on developing unsupervised mechanisms to separate the representation space into discrete slots. However, the inherent challenges of this task have led to comparatively less emphasis on exploring downstream applications and exploring fundamental benefits. Here, we introduce simple, effective OCL mechanisms by separating objects in pixel space and encoding them independently. We present a case study that demonstrates the downstream advantages of our approach for mitigating spurious correlations. We outline the need to develop benchmarks aligned with fundamental goals of OCL, and explore the downstream efficacy of OCL representations.", "description": "Object-centric learning (OCL) traditionally focuses on unsupervised methods for separating objects into representation slots.  This approach, while valuable, has limitations and has not fully explored the downstream benefits and practical applications of OCL. This figure illustrates the shift proposed by the authors, towards simpler, more effective OCL methods that separate objects in pixel space (image segmentation) before encoding them. This approach is shown to mitigate spurious correlations and offers advantages in practical applications.  The figure highlights the need for new benchmarks aligned with the core objectives of OCL, emphasizing the need to assess the impact of object-centric representations on downstream tasks.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.07092/x2.png", "caption": "Figure 2: Overview of Object-Centric Classification with Applied Masks (OCCAM). There are two main parts. The first part (\u00a7\u00a03.2.1) uses entity segmentation masks for object-centric representation generation. The second part (\u00a7\u00a03.2.2) performs robust classification by selecting representations corresponding to the foreground object and using them for classification. Indices [i0,\u2026,ik,\u2026]subscript\ud835\udc560\u2026subscript\ud835\udc56\ud835\udc58\u2026[i_{0},\\ldots,i_{k},\\ldots][ italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \u2026 ] correspond to each object in the scene.", "description": "This figure illustrates the Object-Centric Classification with Applied Masks (OCCAM) method, which consists of two stages. The first stage generates object-centric representations by using entity segmentation masks to isolate individual objects from the scene.  Each object is assigned an index (i0, i1,...ik). The second stage performs robust classification by selecting the representation corresponding to the foreground object and using it for classification.  This allows for focusing on relevant object features while discarding potentially misleading background cues.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.07092/x3.png", "caption": "Figure 3: Qualitative Results on Object Discovery.\nDinosaur, SlotDiffusion, and FT-Dinosaur are existing object-centric learning (OCL) approaches. Sam and HQES refer to zero-shot segmentation methods. Images are from Movi-E. Sam and HQES masks fit objects much better than the masks predicted by OCL methods. All columns except for HQES are taken from [11].", "description": "This figure displays qualitative results on object discovery using various methods.  The first three columns show results from existing object-centric learning (OCL) approaches: Dinosaur, SlotDiffusion, and FT-Dinosaur.  The last two columns present results from zero-shot segmentation methods: SAM and HQES. All images are taken from the Movi-E dataset. The comparison highlights that SAM and HQES generate masks that more accurately fit the objects within the image, compared to the OCL methods.  Note that the data in the first three columns is taken from a previous publication ([11]).", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.07092/x4.png", "caption": "Figure 4: Foreground Object Detection. ROC-curves for foreground detection methods. For each scoring scheme, we measure how well the true foreground objects in the ImageNet-validation dataset are detected. More details in \u00a7\u00a0E.", "description": "This ROC curve compares different methods for foreground object detection.  Each curve represents a different scoring scheme used to identify foreground objects in images from the ImageNet validation set. The x-axis shows the false positive rate (the proportion of background objects incorrectly identified as foreground), while the y-axis shows the true positive rate (the proportion of foreground objects correctly identified).  A higher curve indicates better performance, with a curve closer to the top-left corner signifying high accuracy in identifying foreground objects while minimizing false positives. More details on the experiment setup and the scoring schemes are provided in section E of the paper.", "section": "4.3. Foreground Detectors Comparison"}]