{"importance": "This research introduces a tool to understand **how language models learn from vast datasets**. It allows researchers to investigate fact-checking, hallucination, and creativity, opening avenues for understanding model behavior and improving reliability. It impacts research in interpretability and responsible AI development.", "summary": "OLMOTRACE: Tracing LM outputs back to training tokens.", "takeaways": ["OLMOTRACE enables tracing language model outputs to their training data in real-time.", "The system uses an extended version of infini-gram to achieve fast tracing results.", "OLMOTRACE supports exploring fact-checking, hallucination, and creativity of language models."], "tldr": "Large language models are trained on massive datasets. It is hard to understand why they generate certain responses. Existing tracing methods cannot be scaled to multi-trillion token setting due to computation needs. This paper introduces a system for tracing language models back to their training data to address these issues. \n\nOLMOTRACE finds verbatim matches between language model output and documents. An extended version of infini-gram indexes training data. It also introduces a novel parallel algorithm speeds the matching process. The system allows users to explore fact-checking, creative expression, and math skills of language models.", "affiliation": "Allen Institute for AI", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2504.07096/podcast.wav"}