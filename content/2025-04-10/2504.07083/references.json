{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important as it introduces CLIP, a model used in the current paper for extracting features and evaluating text-trajectory alignment."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper is crucial as it introduces Stable Diffusion, a model utilized as a text encoder in the auto-regressive architecture of GenDoP."}, {"fullname_first_author": "Junyi Zhang", "paper_title": "Monst3r: A simple approach for estimating geometry in the presence of motion", "publication_date": "2024-01-01", "reason": "This reference is significant because the DataDoP dataset construction relies on MonST3R to estimate scene geometry, extract camera trajectories, and create corresponding depth maps."}, {"fullname_first_author": "Susan Zhang", "paper_title": "OPT: open pre-trained transformer language models", "publication_date": "2022-01-01", "reason": "This paper is an important resource, since  the GenDoP decoder D adopts the OPT architecture as its backbone transformer network, allowing it to generate trajectory token sequences."}, {"fullname_first_author": "Gabriel Ilharco", "paper_title": "Open-clip", "publication_date": "2021-01-01", "reason": "This reference is key as RGBD-conditioned encoders in the GenDoP framework use the pretrained and learnable CLIP Vision Model to extract image and depth features."}]}