{"importance": "This paper rigorously examines language model reasoning, revealing the instability from subtle factors. By providing a standardized evaluation, it fosters reproducibility, essential for reliable progress in AI.", "summary": "LM reasoning progress is less robust than perceived. Standardized evaluations are key for reliable progress.", "takeaways": ["Mathematical reasoning benchmarks are highly sensitive to implementation choices.", "Reinforcement learning approaches for reasoning show limited improvements and are prone to overfitting.", "Supervised finetuning delivers more stable and generalizable reasoning improvements."], "tldr": "Language models (LMs) have shown impressive advances in reasoning, but current evaluations often lack transparency and rigor. This paper investigates the reliability of these advancements, finding that performance on mathematical reasoning benchmarks is surprisingly sensitive to minor changes in implementation, such as decoding parameters, random seeds, and even hardware configurations. Many reported gains stem from unclear comparisons or unreported sources of variance, raising concerns about the true progress in the field. The authors highlight the need for more standardized and reproducible evaluation practices to ensure that improvements are genuine and robust.\n\nTo address these issues, the paper proposes a standardized evaluation framework with clear best practices and reporting standards. Applying this framework, they reassess recent methods, revealing that reinforcement learning (RL) techniques often yield only modest improvements compared to previous claims and are susceptible to overfitting, especially on small datasets. In contrast, supervised finetuning (SFT) methods demonstrate more consistent generalization. The authors release all code, prompts, and model outputs to foster reproducibility and establish more rigorous foundations for future work. The research underscores the critical importance of robust, multi-seed evaluations for reliable performance estimates.", "affiliation": "University of T\u00fcbingen", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2504.07086/podcast.wav"}