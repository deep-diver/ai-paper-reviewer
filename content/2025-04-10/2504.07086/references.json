{"references": [{"fullname_first_author": "Rishabh Agarwal", "paper_title": "Deep reinforcement learning at the edge of the statistical precipice", "publication_date": "2021-01-01", "reason": "This paper is an important reference due to its exploration of the challenges and limitations of deep reinforcement learning, particularly concerning statistical reliability, influencing the discussion on reproducibility in the context of language model reasoning."}, {"fullname_first_author": "Marcin Andrychowicz", "paper_title": "What matters in on-policy reinforcement learning? a large-scale empirical study", "publication_date": "2020-01-01", "reason": "This empirical study provides insights into the critical factors in on-policy reinforcement learning and serves as a comparative benchmark for improvements made to language models."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "publication_date": "2021-01-01", "reason": "This paper introduces the MATH dataset, a key benchmark for assessing mathematical problem-solving abilities in language models, making it crucial for evaluating progress in reasoning."}, {"fullname_first_author": "Jonathan Uesato", "paper_title": "Solving math word problems with process-and outcome-based feedback", "publication_date": "2022-01-01", "reason": "This reference is important as it presents methods for training language models to solve math word problems using reinforcement learning with feedback on both the process and outcome, directly relating to improving reasoning capabilities."}, {"fullname_first_author": "Aitor Lewkowycz", "paper_title": "Solving quantitative reasoning problems with language models", "publication_date": "2022-01-01", "reason": "This paper presents methods for language models to solve quantitative reasoning problems, offering a comparison point for recent approaches attempting to solve benchmarks."}]}