{"importance": "This work introduces **CIGEVAL**, a novel framework for evaluating conditional image generation, crucial for assessing AI-synthesized images. **CIGEVAL** aligns better with human judgment than existing metrics, offering a more reliable and explainable evaluation.", "summary": "CIGEVAL: Agentic framework for conditional image generation evaluation, improving human alignment.", "takeaways": ["CIGEVAL is a unified agentic framework using LMMs for comprehensive image generation evaluation.", "Fine-tuning open-source LMMs with CIGEVAL significantly enhances their evaluation performance.", "CIGEVAL achieves high correlation with human assessments, closely matching inter-annotator agreement."], "tldr": "Conditional image generation has seen progress, but reliable, task-agnostic evaluation remains a challenge. Existing metrics are often task-specific, lack explainability, and don't align well with human judgment, making it difficult to assess AI-synthesized images effectively. Even powerful multimodal models like GPT-40 struggle with subtle image nuances, leading to low correlation with human ratings in various image editing tasks.\n\nThis paper introduces **CIGEVAL**, an agentic framework leveraging large multimodal models to tackle conditional image generation evaluation. It integrates a multi-functional toolbox and a fine-grained evaluation framework. Synthesized evaluation trajectories allow smaller LMMs to autonomously select tools for nuanced analysis. Experiments show CIGEVAL aligns closely with human assessments, surpassing previous state-of-the-art methods.", "affiliation": "Harbin Institute of Technology (Shenzhen)", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2504.07046/podcast.wav"}