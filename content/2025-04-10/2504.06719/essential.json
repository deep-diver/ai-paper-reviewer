{"importance": "This paper introduces a new benchmark and method for 3D self-supervised learning, bridging the gap with supervised approaches. It offers improved off-the-shelf features and opens avenues for task-agnostic 3D scene understanding, accelerating research towards more effective 3D foundation models and **reducing reliance on labeled data**.", "summary": "MSM: Narrows the gap between supervised and self-supervised learning in 3D scene understanding with a novel Masked Scene Modeling objective.", "takeaways": ["A new evaluation protocol is introduced to assess self-supervised features for 3D scene understanding.", "Masked Scene Modeling (MSM) is proposed, a novel self-supervised framework tailored to hierarchical 3D models.", "The proposed MSM model achieves competitive, and sometimes superior, performance compared to supervised models in downstream tasks using only off-the-shelf features."], "tldr": "Self-supervised learning has revolutionized 2D computer vision, but its potential in 3D scene understanding remains limited. Current 3D self-supervised methods often serve merely as weight initializations for task-specific fine-tuning, hindering their utility for general-purpose feature extraction. This is due to the lack of a systematic evaluation protocol tailored for 3D scenes and the absence of effective 3D-scene specific masked prediction objectives that account for the hierarchical nature of 3D models. To resolve this, the paper introduces a robust evaluation protocol designed to assess the quality of self-supervised features in 3D scene understanding using multi-resolution feature sampling of hierarchical models for rich point-level representations that capture the semantic capabilities of the model. \n\nAddressing the limitations, this paper introduces the **Masked Scene Modeling (MSM)** framework. MSM is trained natively in 3D, employing a novel self-supervised approach that reconstructs deep features of masked patches in a bottom-up manner, specifically tailored for hierarchical 3D models. Experiments demonstrate that MSM not only competes with supervised models but also surpasses existing self-supervised approaches by a significant margin. This work marks a step toward versatile, task-agnostic 3D feature extraction.", "affiliation": "TU Wien", "categories": {"main_category": "Computer Vision", "sub_category": "Scene Understanding"}, "podcast_path": "2504.06719/podcast.wav"}