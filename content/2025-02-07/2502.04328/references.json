{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "publication_date": "2022-XX-XX", "reason": "This paper introduces Whisper, a large speech recognition model that is used as a component in Ola's architecture."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2024-XX-XX", "reason": "This paper introduces InternVL, a large vision-language model that serves as a foundation for Ola's progressive modality alignment strategy."}, {"fullname_first_author": "Bo Li", "paper_title": "LLaVA-OneVision: Easy visual task transfer", "publication_date": "2024-XX-XX", "reason": "This paper introduces LLaVA-OneVision, a large vision-language model whose architecture and training techniques influence Ola's design."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The first-ever comprehensive evaluation benchmark of multi-modal LLMs in video analysis", "publication_date": "2024-XX-XX", "reason": "This paper introduces VideoMME, a benchmark dataset used to evaluate Ola's performance on video understanding tasks."}, {"fullname_first_author": "QwenTeam", "paper_title": "Qwen2 technical report", "publication_date": "2024-XX-XX", "reason": "This paper introduces Qwen-2.5, a large language model that forms the base model for Ola, significantly contributing to its capabilities."}]}