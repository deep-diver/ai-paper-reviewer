[{"figure_path": "https://arxiv.org/html/2503.15055/x1.png", "caption": "Figure 1: Efficient LLM Token Extraction Pipeline", "description": "The ELTEX pipeline systematically integrates explicit domain indicator extraction with dynamic prompting to generate high-fidelity synthetic data.  It consists of five main components: (1) sample data collection and deduplication, (2) token extraction prompt construction, (3) synthetic data generation, (4) final deduplication, and (5) post-generation quality assurance (QA).  Each stage is designed to maintain the quality and diversity of the generated data while preserving critical domain nuances.", "section": "3 ELTEX Framework"}, {"figure_path": "https://arxiv.org/html/2503.15055/x2.png", "caption": "Figure 2: Comparison of Self-BLEU Scores between Generated and Original Data.", "description": "The figure shows a comparison of Self-BLEU scores for generated and original datasets.  Self-BLEU is a metric measuring the similarity of generated text to itself; higher scores suggest higher coherence and quality in the generated data.  The violin plot visualizes the distribution of Self-BLEU scores, allowing a comparison of the central tendency and the variability of the scores for both the generated (synthetic) and original (real) data. This helps to assess the quality of the synthetic data generated by the ELTEX framework.  The comparison is crucial to understanding if the synthetic data retains similar linguistic characteristics to the original data.", "section": "3.4 Deduplication Process"}, {"figure_path": "https://arxiv.org/html/2503.15055/x3.png", "caption": "(a) Cyberattack Messages", "description": "The figure shows the retention rate of cyberattack-related messages generated using different temperature settings during synthetic data generation.  The x-axis represents the temperature values, ranging from 0.0 to 1.0, and the y-axis indicates the percentage of messages retained after the deduplication process.  Different lines represent the retention rates achieved with different similarity thresholds (0.8, 0.9, and 1.0). The graph helps in determining the optimal temperature setting that balances message diversity and data retention.", "section": "D.2 Temperature Experiments for Synthetic Data Generation"}, {"figure_path": "https://arxiv.org/html/2503.15055/x4.png", "caption": "(b) General Messages", "description": "The figure shows the retention percentage of general messages generated using different temperature settings during synthetic data generation.  The x-axis represents the temperature values, ranging from 0.0 to 1.0, while the y-axis displays the percentage of generated messages retained after the deduplication process.  Multiple lines represent different similarity thresholds (0.8, 0.9, and 1.0) used during deduplication, showcasing how the retention rate changes at various temperatures and thresholds.", "section": "D.2 Temperature Experiments for Synthetic Data Generation"}, {"figure_path": "https://arxiv.org/html/2503.15055/x5.png", "caption": "Figure 3: Retention percentage across different temperature settings and similarity thresholds (0.8, 0.9, 1.0). Note that even with threshold 1.0, exact duplicates are still removed by the deduplication service.", "description": "This figure shows how the retention rate of synthetic data generated by a language model is affected by varying temperature settings (a measure of randomness) and similarity thresholds used for deduplication.  Each line represents a different threshold (0.8, 0.9, or 1.0), showing the percentage of generated messages retained after deduplication at each temperature setting.  Even with the strictest threshold (1.0), some exact duplicates were removed by a separate deduplication process.", "section": "D.2 Temperature Experiments for Synthetic Data Generation"}, {"figure_path": "https://arxiv.org/html/2503.15055/x6.png", "caption": "(a) Real Data", "description": "This figure shows the results of applying the UMAP dimensionality reduction technique to the DBSCAN clustering results of real cyberattack-related messages. Each point represents a message, colored and positioned based on its cluster assignment and embedding. The plot reveals the distribution and relationships among different clusters, allowing for insights into the semantic structure of the real data. This visual representation is helpful in understanding the diverse patterns and relationships within the messages. The non-uniform distribution of points and clusters suggests that real-world data often exhibits both distinct and overlapping events.", "section": "D.3 Clustering Analysis on Synthetic Data"}]