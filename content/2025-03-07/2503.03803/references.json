{"references": [{"fullname_first_author": "Jakob Engel", "paper_title": "Project aria: A new tool for egocentric multi-modal ai research", "publication_date": "2023-08-01", "reason": "This paper introduces the Meta Aria glasses, which are used to capture egocentric data in the EgoLife project."}, {"fullname_first_author": "Dima Damen", "paper_title": "The epic-kitchens dataset: Collection, challenges and baselines", "publication_date": "2021-11-01", "reason": "This paper introduces the EPIC-KITCHENS dataset, a foundational egocentric dataset that is used as a benchmark for comparison in EgoLife."}, {"fullname_first_author": "Kristen Grauman", "paper_title": "Ego4d: Around the world in 3,000 hours of egocentric video", "publication_date": "2022-06-01", "reason": "This paper introduces the Ego4D dataset, a large-scale egocentric dataset that serves as a benchmark for comparison and is a source of data for other datasets used in EgoLife."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-01-01", "reason": "This paper introduces a visual instruction tuning method used in EgoLife."}, {"fullname_first_author": "Bo Li", "paper_title": "Llava-onevision: Easy visual task transfer", "publication_date": "2024-08-01", "reason": "This paper introduces the LLaVA-OneVision model, which is used as a base model for EgoGPT in EgoLife."}]}