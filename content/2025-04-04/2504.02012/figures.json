[{"figure_path": "https://arxiv.org/html/2504.02012/x2.png", "caption": "Figure 1: Our approach integrates a VQ-VAE autoencoder (\ud835\udc04\ud835\udc04\\mathbf{E}bold_E\u2013\ud835\udc03\ud835\udc03\\mathbf{D}bold_D) with a transformer prior. First, the VQ-VAE encodes vectorized network parameters (see Section 2.2), and then the transformer is trained on the resulting codebook (see Section 3). Additionally, prompts\u2014including data, task, or architecture details\u2014are processed using multimodal or language modeling techniques (see Section 3), with an example training simplified prompt template provided in Remark 1.", "description": "Figure 1 illustrates the Instruction-Guided Parameter Generation (IGPG) framework.  The framework uses a Vector Quantized Variational Autoencoder (VQ-VAE) to encode neural network parameters into a discrete representation. This encoded representation is then fed into a transformer model, which is trained to predict the parameters based on task instructions, dataset information, and architecture details. The transformer learns the relationships between the encoded parameters and the provided instructions, allowing it to generate new parameters conditioned on these factors.  The process begins with the VQ-VAE encoding the network parameters. A transformer then predicts parameters based on prompts that include details about the task, dataset, and network architecture. The output of the model is a set of generated parameters that are ready to be used in a neural network.  Remark 1 in the paper provides an example of a training prompt. ", "section": "INSTRUCTION-GUIDED PARAMETERS GENERATION"}, {"figure_path": "https://arxiv.org/html/2504.02012/x3.png", "caption": "Figure 2: Transfer learning evaluation on novel datasets: CIFAR100, CIFAR10, Aircraft30, and PETS10 compared to random initialization.", "description": "Figure 2 presents the results of transfer learning experiments conducted on four datasets: CIFAR-100, CIFAR-10, Aircraft30, and PETS10. The performance of the model initialized using the proposed Instruction-Guided Parameter Generation (IGPG) method is compared against a model initialized randomly. The x-axis shows the number of fine-tuning epochs, and the y-axis represents the accuracy achieved.  The figure visually demonstrates the effectiveness of IGPG in quickly adapting pretrained models to new datasets.  Even starting from a lower baseline than a randomly initialized model, the IGPG-initialized model rapidly surpasses random initialization in terms of accuracy within a few epochs of fine-tuning.", "section": "4.3 Transfer Learning and Fine-tuning on Unseen Datasets"}, {"figure_path": "https://arxiv.org/html/2504.02012/x4.png", "caption": "Figure 3: Performance evaluation with seen and unseen ResNet architectures on CIFAR-10 against models pretrained on CIFAR-100 and Random Initialization.", "description": "Figure 3 presents a comparative analysis of model performance across different ResNet architectures on the CIFAR-10 dataset.  Three scenarios are considered: using models pretrained on CIFAR-100, employing the IGPG method for parameter generation, and using random initialization of weights.  The results showcase how IGPG-generated parameters achieve performance comparable to those of pretrained models, and significantly outperform the random initialization approach.  Both seen (architectures used during training) and unseen (architectures not used during training) architectures are evaluated to demonstrate the generalization capabilities of IGPG.  The figure clearly visualizes the accuracy achieved by each method across different ResNet architectures.", "section": "4.3 TRANSFER LEARNING AND FINE-TUNING ON UNSEEN DATASETS"}, {"figure_path": "https://arxiv.org/html/2504.02012/x5.png", "caption": "(a) CIFAR10", "description": "The figure shows a scatter plot comparing the accuracy of the Instruction-Guided Parameter Generation (IGPG) method against the accuracy of pretrained models on the CIFAR-10 dataset.  Each point represents a specific model architecture. The x-axis shows the accuracy achieved using IGPG, while the y-axis shows the accuracy of the corresponding pretrained model. The regression line shows a strong positive correlation (r=1.00), indicating that IGPG produces model weights with accuracy very similar to that of pretrained models.", "section": "4.3 TRANSFER LEARNING AND FINE-TUNING ON UNSEEN DATASETS"}, {"figure_path": "https://arxiv.org/html/2504.02012/x6.png", "caption": "(b) CIFAR100", "description": "The figure shows a scatter plot comparing the accuracy of weights generated by the IGPG model against the accuracy of pretrained models for the CIFAR-100 dataset. Each point represents a model architecture.  A perfect correlation would fall on the y=x line, demonstrating that the IGPG-generated weights achieve similar performance to pretrained weights. The regression line is also shown, indicating the strength of this correlation.", "section": "4.3 TRANSFER LEARNING AND FINE-TUNING ON UNSEEN DATASETS"}]