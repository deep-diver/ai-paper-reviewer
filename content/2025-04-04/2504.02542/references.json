{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-01", "reason": "This paper is essential as the authors adopt the stable video diffusion model (SVD) as their codebase, building upon its advancements."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-12-01", "reason": "This paper introduces the Mamba architecture, which the authors use as a key component in their model for efficient spatio-temporal feature processing."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper presents the Transformer architecture, the attention mechanism serves as a baseline for comparisons and a component the authors replace in their parallel-control mamba layer."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "The paper is integral, as the study leverages Stable Diffusion, a latent diffusion model, for high-resolution image synthesis as the backbone of their approach."}, {"fullname_first_author": "Fa-Ting Hong", "paper_title": "Implicit identity representation conditioned memory compensation network for talking head video generation", "publication_date": "2023-01-01", "reason": "This paper presents prior work from the authors in talking head generation, providing a foundation upon which they build in the current study."}]}