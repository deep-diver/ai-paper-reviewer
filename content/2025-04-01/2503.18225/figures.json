[{"figure_path": "https://arxiv.org/html/2503.18225/x1.png", "caption": "Figure 1: Visualizations (Left) of the original LoRA (Hu et\u00a0al., 2022) and (Right) of our proposed method DeLoRA. In addition to the low-rank matrices B,A\ud835\udc35\ud835\udc34B,Aitalic_B , italic_A, we introduce a normalization \u039e\u039e\\Xiroman_\u039e and a scaling factor \u03bb\ud835\udf06\\lambdaitalic_\u03bb, which effectively decouple the angular learning from the adaptation strength.", "description": "Figure 1 provides a visual comparison of the original LoRA method and the proposed DeLoRA method. The left panel illustrates the LoRA architecture, showing the low-rank matrices B and A being multiplied and added to the original weight matrix W.  The right panel shows the DeLoRA architecture, which incorporates a normalization factor (\u039e) and a scaling factor (\u03bb) in addition to the low-rank matrices. These added components are designed to decouple the learning of the transformation's direction (angle) from its magnitude (strength), resulting in improved robustness and adaptability. The figure highlights the key differences between the two methods by emphasizing the additional components incorporated into DeLoRA.", "section": "2 Decoupled Low-Rank Adaptation (DeLoRA)"}, {"figure_path": "https://arxiv.org/html/2503.18225/x2.png", "caption": "Figure 2: Learning rate robustness plots in Subject-driven generation task in terms of DINO scores (Left) and Euclidean distance between a finetuned vs pretrained projection layer weights (Right). Learning rates used for robustness evaluation were derived by multiplying the base learning rate in a range of factors.", "description": "This figure displays the results of an experiment evaluating the robustness of different parameter-efficient fine-tuning (PEFT) methods to variations in the learning rate.  The left panel shows DINO scores, a measure of subject fidelity in image generation, for various learning rates. The scores are obtained by multiplying the base learning rate by a range of factors, demonstrating how model performance changes with different learning rates. The right panel shows the Euclidean distance between the weights of a finetuned model and those of its pretrained counterpart for the same range of learning rates. This distance provides insight into how much the model's parameters change during fine-tuning, which is relevant to stability and the risk of catastrophic forgetting. The figure helps to assess how each method's performance and parameter shift is affected by the choice of learning rate.", "section": "3.4 Insights"}, {"figure_path": "https://arxiv.org/html/2503.18225/extracted/6303293/figures/overtraining3.png", "caption": "Figure 3: (Left) Euclidean Distance of finetuned weights to pretrained weights as a function of the number of training steps. (Right) Qualitative examples show that LoRA exhibits significant artifacts earlier in the process compared to DeLoRA, which maintains better image quality.", "description": "Figure 3 presents a comparative analysis of the training dynamics of LoRA and DeLoRA.  The left panel shows a line graph plotting the Euclidean distance between the weights of the finetuned model and the pretrained model's weights over the course of training. This distance represents the magnitude of changes made to the model during finetuning. The right panel provides qualitative results showcasing image generation using LoRA and DeLoRA. This visual comparison demonstrates how LoRA produces images with noticeable artifacts earlier in the training process, while DeLoRA generates higher-quality images that maintain a better visual fidelity. This illustrates DeLoRA's improved robustness and stability during training.", "section": "3.4 INSIGHTS"}, {"figure_path": "https://arxiv.org/html/2503.18225/x3.png", "caption": "Figure 4: Average column norms of parameters in the attention modules of Stable Diffusion\u2019s Unet", "description": "This figure visualizes the average column norms of the parameters within the attention modules of Stable Diffusion's U-Net.  It displays these norms for various layers and blocks within the U-Net, including the down blocks, up blocks, and mid block.  The x-axis represents the different layers and blocks, and the y-axis shows the average column norms. This visualization helps to illustrate the heterogeneity of parameter norms across the different components of the model.  Understanding these norm distributions can be important for designing and interpreting parameter-efficient fine-tuning techniques for generative models like Stable Diffusion.", "section": "3.4 Insights"}, {"figure_path": "https://arxiv.org/html/2503.18225/x4.png", "caption": "Figure 5: Robustness analysis between DoRA with and without magnitude updates, with respect to learning rate changes from the optimal learning rate.", "description": "Figure 5 presents a comparative analysis of DoRA's robustness with and without magnitude updates. It illustrates how the performance of DoRA changes when the learning rate deviates from its optimal value. The left subplot showcases the DINO scores while the right one displays the Euclidean distance between the finetuned and pretrained projection layer weights. This visualization helps in understanding the impact of magnitude updates on DoRA's robustness against learning rate variations.", "section": "3.4 INSIGHTS"}, {"figure_path": "https://arxiv.org/html/2503.18225/x5.png", "caption": "Figure 6: Learning rate robustness plots for DeLoRA in Subject-driven generation task in terms of DINO scores (Left) and Euclidean distance finetuned vs pretrained weights of a projection layer (Right). Ablation testing impact of increasing learning rate for boundary (\u03bb\ud835\udf06\\lambdaitalic_\u03bb) or angular weights (B\u2062A\ud835\udc35\ud835\udc34BAitalic_B italic_A).", "description": "Figure 6 presents an ablation study on DeLoRA's robustness to learning rate variations in the context of subject-driven image generation.  The left panel displays DINO scores, a measure of subject fidelity in generated images, plotted against different learning rates for the scaling parameter (\u03bb) and the angular weights (BA).  The right panel shows the Euclidean distance between the finetuned and pretrained weights of a projection layer, also as a function of the learning rate for \u03bb and BA. This dual visualization allows for a comprehensive assessment of how changes in learning rate affect both the performance (DINO score) and the stability (distance from pretrained weights) of DeLoRA.  The results show the impact of varying learning rates on DeLoRA's performance and stability.", "section": "3.4 INSIGHTS"}, {"figure_path": "https://arxiv.org/html/2503.18225/x6.png", "caption": "Figure 7: Examples generated by DeLoRA-finetuned Stable Diffusion for personalized generation on a small set of subject-specific images (left), and for semantic map to image on ADE20K (right).", "description": "This figure shows examples of image generation results obtained using DeLoRA, a parameter-efficient fine-tuning method.  The left side displays images generated for a personalized generation task, where Stable Diffusion is fine-tuned to generate images of a specific subject in various contexts based on given text prompts. The right side shows results from a semantic map to image task, where DeLoRA fine-tunes Stable Diffusion to generate realistic images that closely adhere to the structure of a provided segmentation map (ADE20K dataset).  This visually demonstrates DeLoRA's ability to adapt a large-scale pre-trained model to various downstream image generation tasks with high fidelity.", "section": "3.1 TASKS"}, {"figure_path": "https://arxiv.org/html/2503.18225/x7.png", "caption": "Figure 8: Prolonged finetuning generated examples generated by DeLoRA, LoRA, and DoRA methods, up to time step 2600.", "description": "Figure 8 presents a qualitative comparison of image generation results from DeLoRA, LoRA, and DoRA models after prolonged training, up to 2600 time steps. The images visually showcase the differences in output quality and stability across the three methods, providing insights into each model's ability to maintain image coherence and avoid artifacts during extended training.", "section": "Qualitative Examples"}]