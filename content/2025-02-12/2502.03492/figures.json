[{"figure_path": "https://arxiv.org/html/2502.03492/x1.png", "caption": "Figure 1: Performance scaling of our CTRL critic (finetuned on Qwen2.5-Coder-32B-Ins, henceforth Qwen2.5-Coder) compared to other critics across different generators on CodeContests. CTRL demonstrates strong critiquing capabilities not only when paired with its base model but also with a stronger generator (GPT-4o, right). Shaded regions indicate standard error across 5 seeds.", "description": "This figure showcases the performance improvement achieved by iterative critique-revision using the proposed CTRL framework.  Two graphs are shown: one demonstrates the performance of the CTRL critic (finetuned on Qwen2.5-Coder-32B-Ins) when paired with the Qwen2.5-Coder generator, and the other shows the results when paired with a stronger GPT-40 generator.  The x-axis represents the number of critique-revision iterations, and the y-axis represents the pass rate (Pass@1).  The figure highlights the significant performance scaling of CTRL across multiple iterations and different generator models.  The shaded regions illustrate the standard error calculated across five independent trials.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.03492/x2.png", "caption": "Figure 2: Illustration of the critique-correction process for a coding problem. Top: An initial solution is proposed by the task-performing using a min-heap approach. Bottom: The critic identifies flaws in the implementation (incorrect heap access and inefficient query handling) and suggests specific improvements, leading to a corrected max-heap solution. This example is taken from critiques of CTRL on LiveCodeBench, which demonstrates how structured feedback from the critic can guide meaningful improvements in code generation.", "description": "This figure illustrates the iterative process of code improvement using the proposed CTRL framework.  The top panel shows an initial solution to a coding problem that utilizes a min-heap data structure. However, the critic identifies two crucial flaws: incorrect access of heap elements and inefficient query handling. The bottom panel depicts the critic's feedback, which pinpoints these issues and suggests specific improvements.  The improved solution, shown in the bottom panel, uses a max-heap and effectively addresses the identified problems. This example highlights the effectiveness of CTRL in providing actionable feedback that leads to significant improvements in code quality, showcasing its ability to guide a model toward correct code generation. This is taken from critiques of CTRL on LiveCodeBench.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.03492/x3.png", "caption": "Figure 3: Simulation results showing success probability (pcorrectsubscript\ud835\udc5dcorrectp_{\\text{correct}}italic_p start_POSTSUBSCRIPT correct end_POSTSUBSCRIPT) as a function of the number of attempts, comparing different levels of critiquing and discrimination ability.", "description": "This figure displays the results of simulations comparing the effectiveness of different levels of critiquing and discrimination abilities in an iterative improvement process. The success probability (pcorrect) is plotted against the number of attempts. Three critiquing scenarios are examined: no critiquing (representing independent sampling of solutions), weak critiquing, and strong critiquing, each with varying levels of discrimination ability. The simulations demonstrate that strong critiquing abilities significantly improve success rates compared to no critiquing, even with weak discrimination.", "section": "Varying Critiquing Ability"}, {"figure_path": "https://arxiv.org/html/2502.03492/x4.png", "caption": "Figure 4: Compounding error analysis. Regression rate measures the frequency of correct initial solutions being revised into incorrect ones. Shaded regions indicate standard error over 5 seeds.", "description": "This figure analyzes the compounding error rate during iterative refinement.  The regression rate shows how often initially correct solutions become incorrect after revisions.  Two plots are shown, one for each of the two generator models, Qwen2.5-Coder and GPT-4, paired with the CTRL critic.  The shaded areas represent the standard error calculated across five different random seeds, providing a measure of variability in the results.", "section": "4.2. Evaluating Critics for Iterative Critique-revisions"}, {"figure_path": "https://arxiv.org/html/2502.03492/x5.png", "caption": "Figure 5: Comparison of pass@1 rates by problem difficulty with CTRL critics on CodeContests. Results are averaged over 5 seeds.", "description": "This figure shows the success rate (Pass@1) of the CTRL critic model on the CodeContests benchmark, categorized by problem difficulty levels (Easy, Medium, Hard).  The results demonstrate how the effectiveness of the CTRL critic scales with problem complexity.  Each data point represents the average Pass@1 rate across five independent runs of the experiment, showcasing the model's robustness.", "section": "4.2. Evaluating Critics for Iterative Critique-revisions"}, {"figure_path": "https://arxiv.org/html/2502.03492/x6.png", "caption": "Figure 6: Model performance comparison on JudgeBench.", "description": "The figure compares the performance of various large language models (LLMs) on the JudgeBench benchmark, which evaluates LLMs' ability to discriminate between correct and incorrect outputs.  The models compared include several strong LLMs and the CTRL critic. The x-axis shows different LLMs and the y-axis shows the accuracy of each model's discrimination ability. The figure highlights the performance of the CTRL critic in relation to other, often stronger models.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.03492/x7.png", "caption": "Figure 7: Comparison of solution similarities between original and revised code guided by CTRL on CodeContests. Left: Distribution of similarity scores for self-critique and our CTRL method. Right: Box plot showing the statistical distribution of similarity scores. Lower scores indicate more substantial revisions.", "description": "Figure 7 presents a comparison of code similarity between the original code and the revised code generated using two different methods on the CodeContests dataset. The left panel displays the distribution of similarity scores for both self-critique and the CTRL method.  A lower similarity score suggests a more substantial change or revision of the code. The right panel provides a box plot visualization of these distributions, offering a clearer comparison of the central tendencies and spreads of similarity scores between the two methods.", "section": "4.2. Evaluating Critics for Iterative Critique-revisions"}, {"figure_path": "https://arxiv.org/html/2502.03492/x8.png", "caption": "Figure 8: Overview of our two-stage training pipeline CTRL.", "description": "The figure illustrates the two-stage training pipeline of the CTRL framework. The first stage involves Supervised Fine-Tuning (SFT), where an initial solution is generated, and its correctness is validated through execution feedback. This feedback is then used to generate critiques that are subsequently utilized for supervised fine-tuning. The second stage is Reinforcement Learning (RL) training, which uses the critic's feedback to guide the generator in producing improved solutions. This process iteratively refines the solutions using the sandbox environment for validation.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.03492/x9.png", "caption": "Figure 9: Graphical models for refinement processes: (left) only using discrimination (best-of-n\ud835\udc5bnitalic_n sampling) and (right) using both discrimination and critiquing (sequential critique-revision).", "description": "Figure 9 illustrates the difference between refinement processes using only discrimination (best-of-n sampling) and those employing both discrimination and critiquing (sequential critique-revision). The left panel shows a best-of-n sampling approach where multiple solutions (y0, y1, y2...yn) are generated independently, and the best solution is selected based on a discrimination function.  In contrast, the right panel depicts a sequential critique-revision process.  Here, an initial solution (y0) is generated, critiqued, and revised iteratively to produce a sequence of improved solutions (y1, y2...yn) until a satisfactory solution is found. This highlights the iterative nature of using critiques to improve solution quality.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.03492/x10.png", "caption": "(a) The effect of the number of votes on the accuracy of majority voting in reward calculation. As the number of votes increases, the accuracy improves significantly, demonstrating the scalability and robustness of the majority voting approach.", "description": "This figure shows how the accuracy of the majority voting reward calculation improves as the number of votes increases.  The x-axis represents the number of votes used in the majority voting process, and the y-axis represents the accuracy of the reward calculation. The graph demonstrates that the accuracy increases significantly as more votes are used. This suggests that the majority voting approach is scalable and robust, meaning it performs reliably and consistently even with large numbers of votes.", "section": "C.4 Evaluation"}]