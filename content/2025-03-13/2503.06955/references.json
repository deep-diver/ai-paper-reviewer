{"references": [{"fullname_first_author": "Deepak Gopinath", "paper_title": "Fairmotion-tools to load, process and visualize motion capture data", "publication_date": "2020-01-01", "reason": "This paper is important because it provides tools to load, process, and visualize motion capture data, which is a fundamental step in many motion generation tasks."}, {"fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "publication_date": "2022-01-01", "reason": "This paper is highly relevant as it directly addresses the task of generating 3D human motions from text descriptions, a core focus of the 'Motion Anything' paper."}, {"fullname_first_author": "Ruilong Li", "paper_title": "Ai choreographer: Music conditioned 3d dance generation with aist++", "publication_date": "2021-01-01", "reason": "This paper introduces a method for music-conditioned 3D dance generation, and has a dataset (AIST++) used in the 'Motion Anything' paper for evaluation."}, {"fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "publication_date": "2022-01-01", "reason": "This paper is crucial as it lays the foundation for using diffusion models in human motion generation, an area of interest and comparison for 'Motion Anything'."}, {"fullname_first_author": "Mingyuan Zhang", "paper_title": "Motiondiffuse: Text-driven human motion generation with diffusion model", "publication_date": "2024-01-01", "reason": "This work provides a foundational approach of human motion generation through text with diffusion model and as such it helps contextualize contributions."}]}