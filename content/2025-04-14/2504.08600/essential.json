{"importance": "This paper introduces SQL-R1, an innovative NL2SQL model trained via RL, tackling complex database scenarios and enhancing generalization. This model offers insights into balancing performance and cost, advancing NL2SQL system applicability and opening avenues for reasoning and real-world application research.", "summary": "SQL-R1: Trains NL to SQL reasoning using reinforcement learning, boosting complex query performance.", "takeaways": ["SQL-R1 achieves competitive accuracy on Spider and BIRD benchmarks using a 7B base model.", "Reinforcement learning enhances NL2SQL reasoning by dynamically adjusting decision-making strategies.", "Cold start training with specific data strengthens instruction-following and SQL generation abilities."], "tldr": "**Natural Language to SQL (NL2SQL)** helps users interact with databases by translating natural language into SQL. However, existing methods using supervised fine-tuning (SFT) struggle with complex queries. SFT may limit adaptability in new environments. Also, the lack of interpretability of NL2SQL reasoning limits the application of the model in high-risk fields, such as finance and healthcare. Hence, there is a need to enhance reasoning and generalization in NL2SQL models.\n\nThis paper introduces **SQL-R1**, a new NL2SQL reasoning model trained using reinforcement learning (RL). SQL-R1 uses a specialized RL-based reward function and augmented training with synthetic data. It achieves high accuracy on Spider and BIRD benchmarks using only a 7B base model. This approach addresses challenges in complex database scenarios and enhances the model's reasoning capabilities.", "affiliation": "Hong Kong University of Science and Technology", "categories": {"main_category": "Natural Language Processing", "sub_category": "Question Answering"}, "podcast_path": "2504.08600/podcast.wav"}