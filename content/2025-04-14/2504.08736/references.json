{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-10-01", "reason": "This paper introduces the Vision Transformer (ViT) architecture, which is used in the GigaTok tokenizer."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces VQGAN, a foundational approach combining vector quantization with GANs for image synthesis, which forms the basis for the tokenizer training in GigaTok."}, {"fullname_first_author": "Junnan Li", "paper_title": "BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "publication_date": "2023-01-01", "reason": "This paper introduces the Q-Former architecture, used as the transformer module when designing 1D tokenizers."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-01", "reason": "This paper presents LLaMA, which is used as the style model and downstream AR generator in GigaTok."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2023-04-01", "reason": "This paper introduces DINOv2, which is used to apply semantic regularization when training the tokenizer."}]}