{"importance": "PixelFlow enables **end-to-end trainable** image generation in raw pixel space, offering new possibilities for visual generation. It challenges the reliance on latent-space models, opening doors for innovation, better image quality, and artistic control.", "summary": "PixelFlow: End-to-end pixel-space generative model achieves impressive image quality and artistic control, outperforming latent-space models.", "takeaways": ["PixelFlow achieves state-of-the-art image generation by directly operating in raw pixel space, avoiding the need for pre-trained VAEs.", "PixelFlow utilizes a cascade flow modeling approach, efficiently handling high-resolution images with reduced computational costs.", "PixelFlow demonstrates competitive visual quality and semantic control on class-conditional and text-to-image generation tasks."], "tldr": "Latent Diffusion Models (LDMs) have become standard for generative modeling. However, they decouple the VAE and diffusion components, hindering joint optimization. An alternative is to implement diffusion models in raw pixel space, but is computationally expensive. Previous Pixel Diffusion Models (PDMs) adopt cascaded approach, with each stage having separate networks which limits end-to-end design.\n\nTo address these issues, this paper introduces **PixelFlow**, a family of image generation models that operate directly in raw pixel space, simplifying image generation and enabling end-to-end training. It achieves affordable computation cost through efficient cascade flow modeling. PixelFlow achieves great FID score on ImageNet. The qualitative text-to-image results highlights strong image quality, artistry, and semantic control.", "affiliation": "University of Hong Kong", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2504.07963/podcast.wav"}