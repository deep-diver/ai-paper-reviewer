{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that enables ThinkDiff's multimodal capabilities by providing aligned image and text embeddings."}, {"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces Stable Diffusion, a crucial diffusion model architecture upon which ThinkDiff builds its image generation capabilities."}, {"fullname_first_author": "Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), the foundational framework for the text-to-image diffusion models used in ThinkDiff."}, {"fullname_first_author": "Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper introduces ControlNet, which is directly related to ThinkDiff's objective of improving in-context reasoning in diffusion models through fine-grained control."}, {"fullname_first_author": "Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-01-01", "reason": "This paper demonstrates the capabilities of large language models (LLMs) in few-shot learning, a concept that's directly relevant to ThinkDiff's proxy task aligning VLMs with LLMs for multimodal reasoning."}]}