[{"figure_path": "https://arxiv.org/html/2502.11901/x1.png", "caption": "Figure 1: Illustration of repository-level data generation pipeline.", "description": "This figure illustrates the pipeline used to generate repository-level data for training the proof-oriented programming model.  It starts with existing type declarations and proofs from repositories.  A problem synthesis loop generates new problems by creating variations of existing proofs, using an LLM to generate solutions (new problem-solution pairs). A repair loop is also included. This loop takes existing proofs that are erroneous and uses an LLM to attempt repair.  The verification step uses F*'s solver to check the correctness of both newly generated and repaired proofs. The process then augments the existing data with these verified new and repaired problem-solution pairs, resulting in a richer and more diverse training dataset.", "section": "4 Project-Level Dataset Synthesis"}, {"figure_path": "https://arxiv.org/html/2502.11901/x2.png", "caption": "Figure 2: Function-level Proof-oriented programming example.", "description": "This figure shows an example of a function-level proof-oriented programming problem in the F* programming language.  It presents a function, `list_with_length`, which takes a list of integers as input and returns a tuple containing the original list and its length. The task is to write an F* program that proves a property: for any list of integers, the length of the list returned by `list_with_length` is equal to the length of the original list. The figure illustrates the problem statement, including the function code and the property to be proved, showcasing the formal verification aspect of proof-oriented programming.", "section": "Function-Level Dataset Collection"}, {"figure_path": "https://arxiv.org/html/2502.11901/x3.png", "caption": "Figure 3: Length Comparison between Generated Definitions vs Existing Definitions.", "description": "Figure 3 is a bar chart comparing the lengths of generated definitions (synthetically created for the F* programming language) with the lengths of definitions found in existing F* repositories.  The x-axis represents the length of the definitions (likely measured in characters or tokens), and the y-axis shows the frequency of definitions of that particular length.  The chart helps to visualize the distribution of definition lengths in both the generated and existing datasets, demonstrating whether the generated data accurately reflects the length characteristics of real-world F* code.", "section": "4 Project-Level Dataset Synthesis"}, {"figure_path": "https://arxiv.org/html/2502.11901/x4.png", "caption": "Figure 4: PoPilot repairing failed outputs for state-of-the-art models.", "description": "This figure shows the results of using PoPilot to repair incorrect outputs generated by several state-of-the-art large language models (LLMs).  The x-axis represents different LLMs, and the y-axis represents the percentage of correctly repaired outputs. The bars show the success rates for three different approaches: (1) Generation with 5 attempts at generation followed by 5 repair attempts (Gen@5+Self Repair@5), (2) Generation with 5 attempts and the use of PoPilot for repair (Gen@5 + Ours Repair@5), and (3) Generation with only 10 attempts at generation (Gen@10).  The figure highlights PoPilot's ability to significantly improve the repair performance of other models.", "section": "6.4 Result"}, {"figure_path": "https://arxiv.org/html/2502.11901/x5.png", "caption": "Figure 5: Distribution of Top 10 Error Types of Model-Generated Repair Data.", "description": "This figure shows the distribution of the top ten error types found in the model-generated repair data.  The data consists of incorrect proofs generated by a language model, which were then used as input to train a model for repairing erroneous proofs in a proof-oriented programming language, F*.  The chart visualizes the frequency of different error types, providing insights into the types of errors most frequently made by the model. This information is valuable for understanding the model's weaknesses and for guiding future data augmentation and model training efforts.", "section": "4.2 Creating Repair Data"}]