[{"figure_path": "https://arxiv.org/html/2502.11330/extracted/6208615/figure/motivation_figure.png", "caption": "Figure 1: \nOur SysGen pipeline provides two main points: system message generation and newly-generated answer.\nWe manually select eight key fuctionalities of system messages and generate phrases with specific tags to original SFT datasets that lack of system messages.\nOur pipeline generates better aligned assistant responses with system messages given user-oriented instruction.", "description": "The SYSGEN pipeline consists of two stages:  First, it automatically generates system messages by identifying eight key functionalities (role, content, task, action, style, background, tool, format) within existing supervised fine-tuning (SFT) datasets that lack system messages. These functionalities are tagged with specific phrases.  Second, the pipeline leverages these newly generated system messages to produce better aligned assistant responses that are more consistent with user instructions.", "section": "3 SYSGEN: Pipeline of System and Assistant Response Generation"}, {"figure_path": "https://arxiv.org/html/2502.11330/x1.png", "caption": "Figure 2: \nOverall SysGen data construction pipeline. Our pipeline consists of four phases:\n(Phase 1) We gather SFT datasets which do not contain system messages and use open-source models to generate system messages with manually selected eight key fuctionality tags.\n(Phase 2) We then remove incorrectly generated tag tokens and reorganize tags with phrases in a predefined order for consistency.\n(Phase 3) We use a LLM-as-a-judge approach with self-model feedback to filter out empty, overly specific, and unnatural phrases.\n(Phase 4) We finally remove tags to create natural system messages and generate new responses along with the user instructions.", "description": "The SYSGEN pipeline consists of four phases.  Phase 1 gathers SFT datasets lacking system messages and uses open-source LLMs to generate system messages with eight key functionality tags. Phase 2 filters out incorrectly generated tags and reorganizes them for consistency. Phase 3 employs an LLM-as-a-judge approach with self-model feedback to remove empty, overly specific, or unnatural phrases. Finally, Phase 4 removes tags to create natural system messages and generates new, aligned assistant responses along with user instructions.", "section": "3 SYSGEN: Pipeline of System and Assistant Response Generation"}, {"figure_path": "https://arxiv.org/html/2502.11330/x2.png", "caption": "Figure 3: \nA statistic that verifies whether the newly-generated answer is more suitable for the user query than the original answer.\nIt records the probability that GPT-4o would respond with the newly-generated answer being better than the original answer (the probability should ideally exceed 50%).", "description": "This figure displays the results of a comparative analysis using GPT-4 to determine which response, the original or the newly generated one, is more appropriate for a given user query. The y-axis represents the percentage, indicating the likelihood of GPT-4 selecting the newly generated response as superior. Ideally, this percentage should be above 50%, suggesting that the newly generated responses are indeed better aligned with user intent. The chart presents the comparative results across various datasets, offering a visual representation of the model's effectiveness in generating more appropriate responses.", "section": "3.4 Phase 4: Assistant Response Generation"}, {"figure_path": "https://arxiv.org/html/2502.11330/x3.png", "caption": "Figure 4: \nThe GPT4o LLM-as-a-judge results of measuring the alignment between generated system messages and new assistant responses. We use 20 samples for each data source which sums up to 100 samples in total per models.", "description": "This figure displays the results of an evaluation performed using GPT-4, a large language model, to assess the alignment between newly generated system messages and their corresponding assistant responses.  The evaluation involved 20 samples from each of several data sources, resulting in a total of 100 samples per model. The results visually represent the degree of alignment, likely showing the percentage of responses deemed aligned or not aligned with their corresponding system messages.", "section": "6.3 New assistant responses align to the system messages"}]