[{"figure_path": "https://arxiv.org/html/2502.01584/x1.png", "caption": "Figure 1: We benchmark the latest reasoning models on the NPR Sunday Puzzle Challenge. The questions exercise general knowledge and are difficult for humans to solve, but the answers are easy to verify. These general knowledge puzzles show capability differences between reasoning models that are not evident from benchmarks that exercise deep technical knowledge.", "description": "The figure presents a bar chart comparing the accuracy of various large language models (LLMs) on the NPR Sunday Puzzle Challenge.  The challenge uses general knowledge questions that are difficult even for humans to solve, but solutions are easily verifiable. The results highlight how these puzzles reveal performance differences between LLMs not apparent in benchmarks focusing on specialized, technical knowledge.  Models like OpenAI's 01 perform significantly better on these general knowledge puzzles compared to other models that achieve comparable performance on more technical benchmarks.", "section": "4 Results"}, {"figure_path": "https://arxiv.org/html/2502.01584/x2.png", "caption": "Figure 2: The last few lines of R1\u2019s output on Challenge\u00a04.2.", "description": "The figure displays the final portion of DeepSeek R1's output when attempting to solve Challenge 4.2 from the NPR Sunday Puzzle Challenge benchmark.  It illustrates a failure mode where the model, despite extensive reasoning, ultimately fails to arrive at the correct answer, providing an incorrect response instead.", "section": "4.2 How Models Give Up"}, {"figure_path": "https://arxiv.org/html/2502.01584/x3.png", "caption": "Figure 3: The last few lines of R1\u2019s output on Challenge\u00a04.2.", "description": "Figure 3 displays the final portion of DeepSeek R1's response to Challenge 4.2 from the NPR Sunday Puzzle Challenge benchmark.  It showcases R1's reasoning process leading up to its answer, revealing its uncertainty and tendency to explore multiple possibilities before concluding (or giving up).  The example highlights R1's potential for reaching an incorrect conclusion despite initially seeming on the right track.  The figure illustrates a novel failure mode of reasoning models; getting stuck reasoning and arriving at a wrong answer.", "section": "4.2 How Models Give Up"}]