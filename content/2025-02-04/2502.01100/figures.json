[{"figure_path": "https://arxiv.org/html/2502.01100/x1.png", "caption": "Figure 1: \nAccuracy vs number of Z3 conflicts for Llama-3 (left), showing the size scaling effect on the reasoning performance. The middle figure shows the curves for gpt-4o(-mini) vs o1 and R1, showing the scaling effect of model size and test-time compute. The right figure shows the scaling effect of repeated sampling by pass@k metric with different sample sizes.", "description": "This figure shows three subplots illustrating different aspects of scaling in large language model (LLM) logical reasoning performance. The left subplot displays Llama-3's accuracy against the number of Z3 conflicts (a measure of problem complexity), demonstrating how accuracy decreases as complexity increases. The middle subplot compares the accuracy of several models (gpt-40, gpt-40-mini, o1, R1) across varying problem complexities and model sizes, illustrating the impact of model scaling and test-time compute. The right subplot shows the scaling effect of repeated sampling using the pass@k metric, where accuracy is measured by taking the best result from k samples.", "section": "3. Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.01100/x2.png", "caption": "Figure 2: \nThis example of ZebraLogic features 3 houses (N=3) and 3 attributes (M=3), with 6 clues (K=6). The Background outlines the attributes, their possible values, and the uniqueness constraints. The Clues provide additional constraints regarding the attributes. The task for the model is to determine the correct assignment of attributes to each house based on these clues, as illustrated in the Solution grid.", "description": "Figure 2 illustrates a ZebraLogic puzzle.  It demonstrates a simplified example with 3 houses, each having 3 attributes (name, drink, hobby). Six clues are provided to constrain the possible assignments of attribute values to houses. The background section provides the attributes and their possible values, along with the inherent uniqueness constraint stating each attribute must have a different value per house. The clues add further constraints, and the model's task is to deduce the correct assignment of values to each house, as displayed in the 'solution' grid.", "section": "2. Problem Formulation of Logical Reasoning"}, {"figure_path": "https://arxiv.org/html/2502.01100/x3.png", "caption": "Figure 3: \nAccuracy vs Search Space Size (log scale) comparing multiple scaling behavior of LLMs on ZebraLogic. Left: Scaling model sizes. Right: Scaling test-time compute through two approaches - increasing sample size (via pass@k evaluation) and extending chain-of-thought reasoning length. Both model size and test-time compute show diminishing returns as search space complexity grows beyond a certain complexity.\nMore results are presented in Sec.\u00a03.", "description": "Figure 3 presents a comparative analysis of Large Language Model (LLM) performance on ZebraLogic, a novel dataset designed to evaluate logical reasoning capabilities.  The figure shows how accuracy changes with increasing search space complexity using two different scaling approaches. The left panel shows the impact of scaling the model size (number of parameters) on accuracy.  The right panel demonstrates how scaling test-time computation affects accuracy, using two methods: increasing the number of samples (pass@k) and increasing the length of chain-of-thought reasoning.  The overall trend shows diminishing returns in accuracy for both model size and test-time computation as the complexity of the reasoning task (measured by search space size) grows beyond a certain threshold.", "section": "3. Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.01100/x4.png", "caption": "Figure 4: The o1 models\u2019 hidden CoT tokens vs. the number of Z3 conflicts. Each point is an example with a certain number of Z3 conflicts. Larger number of Z3 conflicts are associated with harder reasoning problems.", "description": "This figure illustrates the relationship between the number of hidden chain-of-thought (CoT) tokens generated by the OpenAI's o1 models and the number of Z3 conflicts encountered during the solving process of logic grid puzzles.  Each point in the scatter plot represents a single puzzle, with its x-coordinate indicating the number of Z3 conflicts (a measure of puzzle complexity) and its y-coordinate showing the number of hidden CoT tokens generated by the model during solving.  A larger number of Z3 conflicts signifies a more complex reasoning problem. The figure shows how o1 models dynamically adjust the number of hidden CoT tokens used based on puzzle complexity.", "section": "6. Scaling Test-Time Compute with Extensive Chain-of-Thoughts Tokens"}, {"figure_path": "https://arxiv.org/html/2502.01100/x5.png", "caption": "Figure 5: \nTop: Distribution of hidden reasoning tokens generated by o1-mini and o1-preview models.\nBottom: Distribution of visible reasoning tokens across GPT-4o-mini, GPT-4o, o1-mini, and o1-preview models.\nMean hidden reasoning tokens per model: o1-mini generates 5,144.6 tokens and o1-preview generates 5,346.3 tokens.\nMean visible reasoning tokens per model: GPT-4o-mini (502.9), GPT-4o (543.7), o1-mini (305.7), and o1-preview (402.4).", "description": "Figure 5 presents a comparative analysis of hidden and visible reasoning tokens generated by different large language models (LLMs).  The top panel displays the distribution of hidden reasoning tokens produced by the o1-mini and o1-preview models.  The bottom panel shows the distribution of visible reasoning tokens for GPT-4o-mini, GPT-4o, o1-mini, and o1-preview.  Key findings include the significantly higher number of hidden tokens generated by the o1 models (5,144.6 for o1-mini and 5,346.3 for o1-preview) compared to the GPT models (502.9 and 543.7 respectively). This difference highlights a key architectural distinction between the models, suggesting a more extensive internal reasoning process within the o1 models.", "section": "Additional Experimental Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2502.01100/extracted/6173744/assets/sampling.png", "caption": "Figure 6: \nAnalysis of inference-time compute scaling using Best-of-N (BoN) sampling across different ZebraLogic puzzle size groups. The curves demonstrate how increasing the number of samples affects model performance, with separate plots for Small, Medium, Large, and X-Large puzzle categories.", "description": "Figure 6 presents the results of an experiment evaluating the effect of increasing the number of samples on the performance of different LLMs when solving logic puzzles of varying complexity.  The experiment used Best-of-N (BoN) sampling, where N candidate solutions were generated for each puzzle, and the best solution among those candidates was selected.  The figure shows the accuracy of different models across four categories of puzzle sizes: Small, Medium, Large, and X-Large, each representing a different level of complexity. Separate plots are provided for each category, allowing for a detailed visualization of how the number of samples influences model performance across different complexity levels. The results demonstrate that increasing the number of samples can improve accuracy, but the extent of improvement varies depending on the model and the complexity of the puzzle.", "section": "5. Scaling Test-Time Compute with Repeated Sampling: Promises & Challenges"}, {"figure_path": "https://arxiv.org/html/2502.01100/x6.png", "caption": "Figure 7: \nHeatmaps illustrating puzzle complexity metrics across different ZebraLogic problem sizes. The left heatmap represents the log-scaled search space size, categorized from Small to X-Large based on the grid configurations (houses \u00d7 attributes). The right heatmap shows the average number of Z3 conflicts encountered during solving, with higher counts indicating greater logical complexity.", "description": "Figure 7 presents two heatmaps visualizing the complexity of ZebraLogic puzzles.  The left heatmap displays the log-scaled size of the solution space for puzzles with varying numbers of houses and attributes. The solution space size is categorized into four levels: Small, Medium, Large, and X-Large, reflecting increasing difficulty. The right heatmap shows the average number of conflicts encountered by the Z3 SMT solver while solving each puzzle. A higher number of conflicts indicates a greater level of logical complexity and increased difficulty for LLMs to solve the puzzle.", "section": "2.5. Measuring Effective Instance Complexity"}]