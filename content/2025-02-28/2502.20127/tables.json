[{"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.2.1\">Framework</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.3.1\">Type</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.4.1\">Verified</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.5.1\">Lite</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\" id=\"S4.T1.1.1.2.1\" style=\"background-color:#F1F1F1;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.2.1.1\" style=\"background-color:#F1F1F1;\">Proprietary Models</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.3.1\">Claude-3.5-Sonnet\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Cla (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib2\" title=\"\">2024</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.3.2\">Openhands</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.3\">Agent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.4\">53.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.5\">41.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.4.1\">Claude-3.5-Sonnet\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Cla (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib2\" title=\"\">2024</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.4.2\">Agentless</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.3\">Pipeline</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.4\">50.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.5\">40.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.5.1\">GPT-4o\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">OpenAI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib24\" title=\"\">2024a</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.5.2\">SWE-SynInfer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3\">Pipeline + Agent</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.4\">31.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.5\">20.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\" id=\"S4.T1.1.1.6.1\" style=\"background-color:#F1F1F1;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.6.1.1\" style=\"background-color:#F1F1F1;\">7 - 14B Open-source Models</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.7.1\">SWE-Gym-Qwen-7B\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Pan et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib27\" title=\"\">2024</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.7.2\">Openhands</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.7.3\">Agent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.7.4\">10.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.7.5\">10.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.8.1\">SWE-Gym-Qwen-14B\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Pan et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib27\" title=\"\">2024</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.8.2\">Openhands</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.8.3\">Agent</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.8.4\">16.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.8.5\">12.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.9.1\">Lingma-SWE-GPT-7B\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Ma et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib18\" title=\"\">2024a</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.9.2\">SWE-SynInfer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.3\">Pipeline + Agent</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.4\">18.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.5\">12.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.10.1\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.10.1.1\" style=\"background-color:#E3E3FF;\">SoRFT-Qwen-7B (Ours)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.10.2\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.10.2.1\" style=\"background-color:#E3E3FF;\">Agentless</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.3\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.10.3.1\" style=\"background-color:#E3E3FF;\">Pipeline</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.4\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.10.4.1\" style=\"background-color:#E3E3FF;\">21.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.5\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.10.5.1\" style=\"background-color:#E3E3FF;\">14.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\" id=\"S4.T1.1.1.11.1\" style=\"background-color:#F1F1F1;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.11.1.1\" style=\"background-color:#F1F1F1;\">32 - 72B Open-source Models</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.12.1\">Lingma-SWE-GPT-72B\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Ma et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib18\" title=\"\">2024a</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.12.2\">SWE-SynInfer</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.12.3\">Pipeline + Agent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.12.4\">30.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.12.5\">22.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.13.1\">SWE-Fixer-Qwen-72B\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Xie et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib42\" title=\"\">2025a</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.13.2\">SWE-Fixer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.3\">Pipeline</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.4\">30.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.5\">23.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.14.1\">SWE-Gym-Qwen-32B\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Pan et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2502.20127v1#bib.bib27\" title=\"\">2024</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.14.2\">Openhands</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.3\">Agent</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.4\">20.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.5\">15.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.1.15.1\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.15.1.1\" style=\"background-color:#E3E3FF;\">SoRFT-Qwen-32B (Ours)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.1.15.2\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.15.2.1\" style=\"background-color:#E3E3FF;\">Agentless</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.15.3\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.15.3.1\" style=\"background-color:#E3E3FF;\">Pipeline</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.15.4\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.15.4.1\" style=\"background-color:#E3E3FF;\">30.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.15.5\" style=\"background-color:#E3E3FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.15.5.1\" style=\"background-color:#E3E3FF;\">24.0</span></td>\n</tr>\n</table>", "caption": "Table 1: The %Resolved performance of various models on SWE-Bench Verified and SWE-Bench Lite. Given that all fine-tuning approaches are inherently framework-specific, we compare SoRFT-Qwen with previous fine-tuned models within corresponding frameworks.", "description": "This table compares the performance of different large language models (LLMs) on two benchmark datasets for software issue resolution: SWE-Bench Verified and SWE-Bench Lite.  The performance metric used is the percentage of issues resolved (%Resolved). Because different LLMs were fine-tuned within specific frameworks (e.g., Agentless, Openhands), this table focuses on comparing the SoRFT-Qwen model to other models that were fine-tuned using the same framework.  This ensures a fair comparison by controlling for the influence of the underlying framework.", "section": "4 Experiments"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.2.1\">%Resolved</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.3.1\">%Applied</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.1.1.2.1\">Qwen2.5-Coder-7B-Instruct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.2.2\">7.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.2.3\">55.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.3.1\">\u00a0\u00a0\u2003+ SFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.3.2\">18.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.3.3\">85.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.4.1\">\u00a0\u00a0\u2003+ SFT + RL (Our SoRFT-Qwen-7B)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.4.2.1\">21.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.4.3.1\">95.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.1.1.5.1\">Qwen2.5-Coder-32B-Instruct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.5.2\">25.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.5.3\">84.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.6.1\">\u00a0\u00a0\u2003+ SFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.6.2\">28.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.6.3\">90.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S5.T2.1.1.7.1\">\u00a0\u00a0\u2003+ SFT + RL (Our SoRFT-Qwen-32B)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S5.T2.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.7.2.1\">30.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S5.T2.1.1.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.7.3.1\">95.8</span></td>\n</tr>\n</table>", "caption": "Table 2: Performance comparison of model with different training strategy on SWE-bench Verified.", "description": "This table presents a comparison of the performance of a language model trained using different methods on the SWE-Bench Verified dataset.  It shows the improvement in issue resolution (% Resolved) and the successful application of generated code edits (% Applied) when using supervised fine-tuning (SFT) alone versus when combining SFT with rule-based reinforcement learning (RL) as in the SoRFT approach. The table helps to demonstrate the effectiveness of the SoRFT method in improving model performance.", "section": "4 Experiments"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.1.1.2\">LiveCodeBench</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.1.1.3\">RepoQA</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.2.1\">Qwen2.5-Coder-7B-Instruct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.1.2.2\">34.18</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.1.2.3\">85.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S5.T3.1.1.3.1\">SoRFT-Qwen-7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S5.T3.1.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.3.2.1\">34.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S5.T3.1.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.3.3.1\">90.0</span></td>\n</tr>\n</table>", "caption": "Table 3: Performance comparison on LiveCodeBench and RepoQA.", "description": "This table presents a comparison of the performance of two models, Qwen2.5-Coder-7B-Instruct and SoRFT-Qwen-7B, on two code generation benchmarks: LiveCodeBench and RepoQA.  LiveCodeBench focuses on self-contained code generation tasks, while RepoQA assesses a model's ability to extract information from long-context code snippets.  The table shows the percentage of tasks successfully completed (%Resolved) and the accuracy of the generated code (%Applied) for each model and benchmark, allowing for a direct comparison of their performance on different types of code generation challenges.", "section": "5 Results and Analysis"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A4.T4.1.1\">\n<tr class=\"ltx_tr\" id=\"A4.T4.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T4.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.1.2.1\">%File Hit</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.1.3.1\">%Func Hit</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.1.4.1\">%Line Hit</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A4.T4.1.1.2.1\">Qwen2.5-Coder-7B-Instruct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.2.2\">59.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.2.3\">51.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T4.1.1.2.4\">17.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A4.T4.1.1.3.1\">SoRFT-Qwen-7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A4.T4.1.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.3.2.1\">77.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A4.T4.1.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.3.3.1\">66.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A4.T4.1.1.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A4.T4.1.1.3.4.1\">23.6</span></td>\n</tr>\n</table>", "caption": "Table 4: Performance comparison on issue resolving subtasks.", "description": "Table 4 presents a comparison of the performance of different models on three subtasks involved in resolving software issues: file localization, function localization, and line localization.  It shows the percentage of times each model successfully identified the correct file, function, and line of code related to the issue.  This helps to assess the effectiveness of the models at various stages of the issue-resolution process.", "section": "4. Results and Analysis"}]