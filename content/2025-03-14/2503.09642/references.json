{"references": [{"fullname_first_author": "J. Ansel", "paper_title": "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation", "publication_date": "2024-04-01", "reason": "This paper details the architecture used for accelerated training efficiency in Open-Sora 2.0, which used PyTorch compile."}, {"fullname_first_author": "H. W. Chung", "paper_title": "Scaling instruction-finetuned language models", "publication_date": "2024-01-01", "reason": "This paper is referenced to highlight the application of scaling principles to language models, which also influenced video generation modeling."}, {"fullname_first_author": "P. Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper is referenced because the training objective is based on that used in Stable Diffusion 3, in this paper."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper highlights CLIP-Large, a model used for text encoding, improving alignment between text and visual concepts, and leading to more accurate prompt adherence in video generation."}, {"fullname_first_author": "S. Li", "paper_title": "Colossal-ai: A unified deep learning system for large-scale parallel training", "publication_date": "2023-01-01", "reason": "This paper details the efficient parallel training system, ColossalAI, used to train Open-Sora 2.0."}]}