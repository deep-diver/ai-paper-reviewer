[{"figure_path": "https://arxiv.org/html/2503.10351/extracted/6277631/Figures/framework.png", "caption": "Figure 1: Promsing directions for MT using LRMs (e.g., DeepSeek R1), including some foundational and classical MT scenarios such as stylized translation, new challenges with LRMs like self-reflection, and some new challenges for LRMs.", "description": "This figure illustrates the promising applications of Large Reasoning Models (LRMs) in machine translation (MT).  It showcases how LRMs address traditional MT challenges (stylized translation, document translation, multimodal translation) while also highlighting new opportunities and challenges enabled by LRMs. Specifically, it emphasizes the significant shift from simple text conversion to a more dynamic reasoning task that includes contextual coherence, cultural intentionality, and self-reflection.  The figure uses DeepSeek R1 as a representative example of such LRMs. The new challenges include self-reflection and auto-pivoting.", "section": "1. Introduction"}]