[{"figure_path": "https://arxiv.org/html/2503.10637/x2.png", "caption": "Figure 1: Diversity Distillation: (a) a base diffusion model is very slow and has good diversity (b) a distilled model is fast but sacrifices diversity (c) we show how the diversity of the base model can be distilled into the fast model by substituting the first timestamp. Control Distillation: (d) Control methods like Concept sliders can be transferred from a base model to distilled models, effectively distilling control", "description": "Figure 1 demonstrates the core concepts of the paper: diversity and control distillation.  (a) showcases a base diffusion model known for its slower speed but higher sample diversity. (b) shows a distilled model, which is faster but suffers from reduced sample diversity (mode collapse). (c) illustrates the authors' proposed diversity distillation technique, where the first timestamp from the base model is used in conjunction with the rest of the faster distilled model's steps to recover and even surpass the diversity of the original base model. Finally, (d) visually represents control distillation, showing how control methods (such as concept sliders) trained on the base model can be directly applied to the distilled model without requiring any retraining, demonstrating the preservation of control mechanisms during the distillation process.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10637/x3.png", "caption": "Figure 2: Customization adapters (custom diffusion\u00a0[16] and dreambooth\u00a0[26]) and concept control adapters (concept sliders\u00a0[8]) trained on SDXL-base model can be transferred to all the distilled modeled without any additional finetuning. This demonstrates that concept representations are preserved through the diffusion distillation process", "description": "Figure 2 visually demonstrates the concept transferability between base and distilled diffusion models.  It shows that customization adapters (like Custom Diffusion and DreamBooth, which alter specific visual aspects of generated images) and concept control adapters (like Concept Sliders, which provide granular control over features) trained on a base SDXL model can be directly applied to various distilled models (SDXL-Turbo, SDXL-Lightning, SDXL-LCM, SDXL-DMD) without any additional training.  The successful transfer across different distilled models highlights that the underlying concept representations remain intact during the distillation process, despite changes in model weights.", "section": "3. Control Distillation"}, {"figure_path": "https://arxiv.org/html/2503.10637/x4.png", "caption": "Figure 3: DT-Visualization reveals generation inconsistencies. When prompted with \u201cImage of dog and cat sitting on sofa,\u201d the SDXL model produces an image with only a dog. However, DT-Visualization at T=10\ud835\udc4710T=10italic_T = 10 shows the model initially conceptualizing a cat face (red box) before abandoning this element in the final generation. This demonstrates how diffusion models can discard semantic elements during the denoising process.", "description": "This figure showcases the capabilities of Diffusion Target (DT) Visualization, a novel technique introduced in the paper to analyze diffusion model's decision-making process during image generation. It uses the prompt \u201cImage of dog and cat sitting on sofa\u201d. While the final generated image shows only a dog, DT-Visualization at an intermediate timestep (T=10) reveals that the model initially considered generating a cat face, indicated by a red box around the cat face in the visualization. This cat face element is, however, absent in the final generated image. This demonstrates the dynamic nature of diffusion models' generation process where initially considered elements can be discarded in later steps.", "section": "4. DT: Diffusion Target Visualization"}, {"figure_path": "https://arxiv.org/html/2503.10637/x5.png", "caption": "Figure 4: Comparison of standard diffusion visualization vs. our Diffusion Target (DT) visualization. Left: Standard visualization of intermediate latents shows subtle differences between base and distilled models. Right: Our DT visualization technique reveals dramatic differences in how models predict the final output. Distilled models commit to final image structure in the first timestep, while base models gradually refine structure across multiple steps, explaining the observed mode collapse in distilled models.", "description": "This figure compares standard diffusion visualization with the novel Diffusion Target (DT) visualization technique.  The left side shows standard visualizations of intermediate latent representations during the diffusion process for both base and distilled models.  These standard visualizations reveal only subtle differences between the base and distilled models. The right side shows the DT visualization, which predicts the final image at each timestep without completing the full denoising process. This reveals a dramatic difference in how the models predict the final output.  Distilled models commit to the final image structure very early in the process, after just the first timestep. In contrast, base models gradually refine the structure across many timesteps. This difference in generation behavior explains why distilled models exhibit mode collapse (reduced diversity) compared to base models.", "section": "4. DT: Diffusion Target Visualization"}, {"figure_path": "https://arxiv.org/html/2503.10637/x6.png", "caption": "Figure 5: Measuring the dreamsim distance between intermediate DT-visualization and final image reveals that distilled models establish structural image composition within the initial diffusion step, whereas base models require approximately 30% of steps to achieve comparable structural definition.", "description": "The figure shows a graph plotting the DreamSim distance between intermediate DT-visualizations and final images for both base and distilled diffusion models. The x-axis represents the percentage of diffusion timesteps completed, while the y-axis represents the DreamSim distance. The graph reveals that distilled models establish significant structural composition very early in the process, usually within the first 10%, while base models require approximately 30% of total timesteps for similar structural definition. This supports the study's hypothesis that early timesteps play a disproportionate role in determining output diversity.", "section": "4. DT: Diffusion Target Visualization"}, {"figure_path": "https://arxiv.org/html/2503.10637/x7.png", "caption": "Figure 6: Visual comparison of generation diversity. Each row shows three different generations (different random seeds) for the same prompt using: (left) base model, (middle) distilled model, and (right) our diversity distillation approach. Note how the distilled model produces visually similar outputs across seeds, while our approach restores diversity comparable to the base model while maintaining similar inference speed as distilled model.", "description": "This figure visually compares the diversity of image generation results from three different models: a base diffusion model, a distilled model, and a hybrid model using diversity distillation.  Each row represents a different prompt, and within each row, three images are shown\u2014each generated from the same prompt but with different random seeds.  The base model produces diverse outputs, showing substantial variation between the three images. The distilled model, in contrast, shows very similar outputs across different random seeds, demonstrating a loss in diversity.  The diversity distillation approach generates images with diversity comparable to the base model, yet maintaining the speed advantages of the distilled model. This illustrates how the proposed method effectively addresses the mode collapse issue often observed in distilled diffusion models, preserving both computational efficiency and sample diversity.", "section": "5. Diversity Distillation"}, {"figure_path": "https://arxiv.org/html/2503.10637/x8.png", "caption": "Figure 7:  (a) Impact of guidance scale from the base model on diversity shows optimal performance around 0 guidance. (b) Effect of the number of distilled model steps (k\ud835\udc58kitalic_k) being replaced by base model inference. Running distilled model from first timestep (k=1\ud835\udc581k=1italic_k = 1) provides diversity gains with minimal computational overhead. (c) Comparing the total timesteps of base model when replacing the first timestep of distilled model shows that replacing 1-1 timesteps of distilled with base is most ideal.", "description": "This figure analyzes the impact of different hyperparameters on the diversity and efficiency of a hybrid inference approach for diffusion models. Panel (a) demonstrates that using minimal guidance from the base model is optimal for maintaining diversity. Panel (b) shows that using the base model for even just the first timestep significantly improves diversity with minimal computational overhead. Panel (c) reveals the optimal balance between diversity enhancement and computational efficiency occurs when replacing one timestep from the distilled model with one timestep from the base model.", "section": "5.2. Hyperparameter Analysis"}, {"figure_path": "https://arxiv.org/html/2503.10637/x9.png", "caption": "Figure A.1: Reverse Control Transfer: Control mechanisms (Custom Diffusion [16] and Concept Sliders [8]) trained on distilled models can be effectively transferred to base models without retraining. This bidirectional transferability confirms that concept representations are preserved during diffusion distillation. Note: LCM LoRA transfers were excluded due to training difficulties with the LCM architecture.", "description": "This figure demonstrates that control mechanisms, such as Custom Diffusion and Concept Sliders, trained on distilled diffusion models can be successfully applied to base diffusion models without any further training. This experiment verifies that the fundamental conceptual representations within the models remain consistent even after the distillation process, highlighting the preservation of these representations regardless of the model's modifications. It also notes that LoRA transfer experiments were not conducted for the LCM architecture due to difficulties in training.", "section": "A. Control Distillation: Reverse Transfer"}, {"figure_path": "https://arxiv.org/html/2503.10637/x10.png", "caption": "Figure B.1: Comparison of generation diversity across different models for the prompt \u201dimage of a toy.\u201d Each image shows different seeds for the same model. Note the structural similarity in distilled model outputs compared to the greater variation in base model and our hybrid approach.", "description": "This figure compares the image generation diversity of three different models using the same prompt: \"image of a toy.\"  The leftmost column displays images generated by the base diffusion model, demonstrating a wide variety of toy types and styles. The middle column shows images from the distilled model, revealing significantly less diversity in both the type of toys and their overall appearance. The images are structurally similar, demonstrating mode collapse. The rightmost column showcases the results of the proposed diversity distillation technique. The diversity of the generated images is substantially improved compared to the distilled model, showing similar variety to the base model, indicating the effectiveness of this method in mitigating mode collapse while maintaining computational efficiency.", "section": "B. Mode Collapse and Diversity"}, {"figure_path": "https://arxiv.org/html/2503.10637/x11.png", "caption": "Figure B.2: Comparison of generation diversity for \u201dimage of a flower\u201d Distilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.", "description": "This figure compares the image generation diversity of three different models when generating images of flowers. The left column shows the output of the base diffusion model; the middle column shows the output of a distilled model; and the right column shows the output of the proposed diversity distillation method.  Each column displays multiple images generated using different random seeds, making it possible to compare the diversity of outputs across different random seeds. The comparison demonstrates that the distilled model shows less diversity compared to the base model, while the proposed method is able to recover the diversity of the base model while still retaining the speed advantage of the distilled model.", "section": "B. Mode Collapse and Diversity"}, {"figure_path": "https://arxiv.org/html/2503.10637/x12.png", "caption": "Figure B.3: Additional diversity comparison for \u201dcity street\u201dDistilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.", "description": "This figure compares the image generation diversity of three different approaches: a base diffusion model, a distilled model, and a hybrid approach combining both.  The \"city street\" prompt was used to generate multiple images using each method with varying random seeds. The base model (left column) shows a wide range of diverse city street scenes. The distilled model (middle column) demonstrates significantly reduced diversity, generating very similar-looking images across different seeds, which indicates mode collapse.  The hybrid approach (right column), proposed by the authors, combines both models strategically, effectively restoring a level of diversity comparable to the base model while retaining the speed benefits of the distilled model.", "section": "B. Mode Collapse and Diversity"}, {"figure_path": "https://arxiv.org/html/2503.10637/x13.png", "caption": "Figure B.4: Diversity comparison for abstract prompt: \u201dpicture of a monster\u201d Distilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.", "description": "Figure B.4 visually compares the diversity of images generated from a base diffusion model, a distilled diffusion model, and the proposed diversity distillation approach.  The prompt used was \"picture of a monster\". The left column displays the base model's output across multiple generation runs (different random seeds). Noticeable variation in monster designs is present. The middle column shows the distilled model's output.  Here, the diversity is significantly reduced; the generated monsters are very similar across the multiple runs, indicating mode collapse. The right column presents the results from the proposed diversity distillation method, demonstrating a significant improvement in diversity. The generated monsters are much more varied, comparable to the base model, but with the computational efficiency of the distilled model. This figure highlights the effectiveness of the proposed hybrid method in overcoming mode collapse and improving the diversity of generated images in distilled diffusion models.", "section": "B. Mode Collapse and Diversity"}, {"figure_path": "https://arxiv.org/html/2503.10637/x14.png", "caption": "Figure C.1: Extended DT-Visualization comparison between SDXL-Base and SDXL-DMD for the prompt. The visualization reveals that DMD commits to final structural composition within the first timestep, while Base gradually develops structure across multiple steps. This pattern is consistent across different content types and prompts.", "description": "This figure shows a comparison of the Diffusion Target (DT) Visualization between the SDXL-Base and SDXL-DMD models. DT-Visualization is a technique to visualize what a diffusion model predicts at any intermediate timestep without actually completing the generation process. The visualization reveals that the SDXL-DMD model, which is a distilled model, commits to the final structural composition very early in the generation process, typically within the first timestep. In contrast, the SDXL-Base model, which is a more complex model, gradually develops the image structure over multiple steps.  This difference in behavior is consistent across various types of images and prompts, demonstrating a key difference between base and distilled diffusion models. The key takeaway is that the fast generation of the distilled model comes at the cost of the diversity and variability which is achieved by the gradual refinement of the base model.", "section": "C. Extended DT-Visualization Analysis"}, {"figure_path": "https://arxiv.org/html/2503.10637/x15.png", "caption": "Figure C.2: Extended DT-Visualization comparison between SDXL-Base and SDXL-DMD for the prompt. The visualization reveals that DMD commits to final structural composition within the first timestep, while Base gradually develops structure across multiple steps. This pattern is consistent across different content types and prompts", "description": "This figure shows a comparison of Diffusion Target (DT) visualizations for SDXL-Base and SDXL-DMD models.  DT-Visualization is a technique that reveals what a model predicts the final image will look like at any given timestep during the generation process, without actually completing the entire generation. The comparison highlights a key difference: the SDXL-DMD (distilled) model establishes the fundamental structure of the image almost immediately in the first timestep. In contrast, the SDXL-Base (base) model develops its structure gradually over multiple timesteps. This difference is consistent regardless of the prompt's content, demonstrating how the distillation process leads to a loss of diversity in the resulting generated images.", "section": "C. Extended DT-Visualization Analysis"}]