[{"figure_path": "https://arxiv.org/html/2503.10630/x1.png", "caption": "Figure 1: State-of-the-art zero-shot goal-oriented navigation methods are typically specialized for each goal type. Although recent work presents universal goal-oriented navigation method, it requires to train policy networks on large-scale data and lacks zero-shot generalization ability. We propose UniGoal, which enables zero-shot inference on three studied navigation tasks with a unified framework and achieves leading performance on multiple benchmarks.", "description": "Existing zero-shot navigation methods are designed for specific goal types (object, image, text), limiting their generalizability.  Universal methods exist, but they require extensive training data and lack true zero-shot capabilities.  UniGoal addresses these limitations by using a unified framework for zero-shot inference across object, image, and text-based navigation goals, achieving state-of-the-art performance.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10630/x2.png", "caption": "Figure 2: Framework of UniGoal. We convert different types of goals into a uniform graph representation and maintain an online scene graph. At each step, we perform graph matching between the scene graph and goal graph, where the matching score will be utilized to guide a multi-stage scene exploration policy. For different degree of matching, our exploration policy leverages LLM to exploit the graphs with different aims: first expand observed area, then infer goal location based on the overlap of graphs, and finally verify the goal. We also propose a blacklist that records unsuccessful matching to avoid repeated exploration.", "description": "UniGoal uses a graph-based approach for universal zero-shot goal-oriented navigation.  Different goal types (object, image, text) are converted into a unified graph representation. The system maintains an online scene graph, and at each step, performs graph matching between the scene graph and the goal graph.  The matching score determines the exploration strategy.  If there's no match, the system expands the explored area. With a partial match, it infers the goal location using graph overlap.  A perfect match triggers goal verification.  A blacklist prevents revisiting unsuccessfully explored areas.", "section": "3. Approach"}, {"figure_path": "https://arxiv.org/html/2503.10630/x3.png", "caption": "Figure 3: Illustration of approach. (a) Stage 2: coordinate projection and anchor pair alignment. (b) Stage 3: scene graph correction.", "description": "Figure 3 illustrates the two main stages of the UniGoal approach. Part (a) shows Stage 2, where coordinate projection and anchor pair alignment are used to estimate the goal's location after partial matching between scene and goal graphs.  The scene graph is aligned with the goal graph using anchor pairs (matched nodes) to project the relative positions of other goal graph nodes into the scene graph's coordinate system. Part (b) depicts Stage 3, the scene graph correction stage, activated when the scene graph is almost perfectly matched to the goal graph. The agent has almost reached the goal, but there may be small discrepancies. This stage refines the scene graph by using visual observation and graph relationship propagation, and confirms the goal location.", "section": "3.3 Multi-stage Scene Exploration"}, {"figure_path": "https://arxiv.org/html/2503.10630/x4.png", "caption": "Figure 4: Demonstration of the decision process of UniGoal. Here \u2018Switch\u2019 means the point when stage is changing. \u2018S-Goal\u2019 means the long-term goal predicted in each stage.", "description": "This figure visualizes the multi-stage decision-making process within the UniGoal framework for goal-oriented navigation.  Each row represents a different stage of the navigation process: Stage 1 (Zero Matching), Stage 2 (Partial Matching), and Stage 3 (Perfect Matching). The 'Switch' points indicate transitions between stages based on the graph matching score. The 'S-Goal' represents the long-term exploration goal dynamically generated by UniGoal at each stage using a deterministic local policy. The figure shows how the agent progresses from exploring unknown regions (Stage 1) to identifying potential goal locations via coordinate projection and anchor pair alignment (Stage 2), and finally, verifying and reaching the goal (Stage 3).  The example clearly illustrates how the matching score evolves throughout the process and how the long-term goals adjust to reflect the changing understanding of the scene.", "section": "3.3 Multi-stage Scene Exploration"}, {"figure_path": "https://arxiv.org/html/2503.10630/x5.png", "caption": "Figure 5: Visualization of the navigation path. We visualize ON (Green), IIN (Orange) and TN (Blue) path for several scenes. UniGoal successfully navigates to the target given different types of goal and diverse environments.", "description": "Figure 5 presents a visualization of UniGoal's navigation paths across diverse environments and goal types.  Green lines represent Object-goal Navigation (ON) paths, orange lines depict Instance-Image Navigation (IIN) paths, and blue lines show Text Navigation (TN) paths.  The figure demonstrates UniGoal's ability to successfully navigate to target locations using a variety of goal specifications (object category, instance image, or text description) in complex and varied scenes.", "section": "4.4. Qualitative Results"}]