{"importance": "This paper is vital for researchers interested in **3D human pose estimation and tracking**. It pushes the boundaries of online multi-person pose tracking in complex scenes.  The code release will foster advancements in areas such as human-computer interaction, robotics, and AR/VR.", "summary": "CoMotion: Online multi-person 3D motion capture from monocular video, robust to occlusion.", "takeaways": ["CoMotion achieves state-of-the-art 3D pose estimation and tracking accuracy while being significantly faster than existing methods.", "The system uses a novel approach of updating poses directly from image features, enabling online tracking through occlusions.", "Training on a heterogeneous mixture of datasets, including pseudo-labeled data, is crucial for achieving robust performance in real-world scenarios."], "tldr": "Existing approaches to multi-person 3D pose tracking often struggle with occlusions and are not suitable for online applications. These methods typically follow a detect-and-associate paradigm, linking poses across frames based on proximity and appearance. This can lead to issues when detections are missed or inaccurate, hindering the ability to maintain coherent tracks, especially in crowded scenes. \n\nTo solve the above problems, this paper introduces CoMotion, a novel video-based approach for online multi-person 3D pose tracking from monocular video. CoMotion performs frame-to-frame pose updates using a recurrent model that maintains a set of tracked 3D poses and updates them when a new frame arrives. Instead of linking independent per-frame detections, CoMotion directly ingests the pixels of the new frame to update the poses of all people in the scene simultaneously. **This allows the model to reason about occlusions and maintain temporally coherent predictions.**", "affiliation": "Apple", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2504.12186/podcast.wav"}