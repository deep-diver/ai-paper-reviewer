{"references": [{"fullname_first_author": "Nikita Karaev", "paper_title": "Co-tracker3: Simpler and better point tracking by pseudo-labelling real videos.", "publication_date": "2024-10-31", "reason": "This paper introduces the Co-tracker3 framework, which forms the basis of the proposed TAPIP3D architecture, contributing to the tracking of any point in a video."}, {"fullname_first_author": "Adam W Harley", "paper_title": "Particle video revisited: Tracking through occlusions using point trajectories.", "publication_date": "2022-01-01", "reason": "This reference serves as a foundation to TAPIP3D and introduces the concept of tracking through occlusions using point trajectories."}, {"fullname_first_author": "Zhengqi Li", "paper_title": "MegaSaM: Accurate, fast and robust structure and motion from casual dynamic videos.", "publication_date": "2024-01-01", "reason": "This paper is critical as TAPIP3D leverages both the camera pose and depth estimation from MegaSaM to compute a 3D space where camera motion is cancelled."}, {"fullname_first_author": "Tuan Duc Ngo", "paper_title": "Delta: Dense efficient long-range 3d tracking for any video.", "publication_date": "2025-01-01", "reason": "This paper represents one of the strongest baselines in 3D point tracking against which TAPIP3D is compared, and it serves to demonstrate the improvements that TAPIP3D brings to the task."}, {"fullname_first_author": "Yuxi Xiao", "paper_title": "Spatialtracker: Tracking any 2d pixels in 3d space.", "publication_date": "2024-01-01", "reason": "This paper is a relevant and important reference as it presents a recent work extending point tracking to 3D, using a triplane representation, and serves as a comparison to the advantages of using TAPIP3D's 3D spatio-temporal point-feature graph."}]}