{"references": [{"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian Splatting for Real-Time Radiance Field Rendering", "publication_date": "2023-04-01", "reason": "This paper introduces 3D Gaussian Splatting (3D GS), which is the core technology that StyleMe3D builds upon and aims to improve."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces Stable Diffusion which provides the semantic prior that the DSSD module uses for dynamic style alignment."}, {"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2022-01-01", "reason": "This paper proposes Score Distillation Sampling, the core technique used in StyleMe3D for optimizing 3D representations using diffusion models."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "NeRF: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces Neural Radiance Fields which is a method for 3D scene representation; the synthetic dataset from the paper is also used to evaluate the performance of StyleMe3D."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP (Contrastive Language-Image Pre-training), which provides the basis for Style Cleaning and the 3DG-QA module in StyleMe3D."}]}