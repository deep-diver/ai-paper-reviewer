[{"figure_path": "https://arxiv.org/html/2504.15257/x1.png", "caption": "Figure 1: Task-Level Meta-Agents vs. Query-Level Meta-Agents at Inference Time. q\ud835\udc5eqitalic_q denotes a user query, e.g., build a 2048 game. t\u223cP\u2062(q)similar-to\ud835\udc61\ud835\udc43\ud835\udc5et\\sim P(q)italic_t \u223c italic_P ( italic_q ) denotes one kind of task, e.g., code generation task, which is a distribution of user queries. Given t\ud835\udc61titalic_t, previous task-level meta-agent \ud835\udc9cmeta_tasksubscript\ud835\udc9cmeta_task\\mathcal{A}_{\\text{meta\\_task}}caligraphic_A start_POSTSUBSCRIPT meta_task end_POSTSUBSCRIPT aims to search a task-specific multi-agent system \ud835\udcaetasksubscript\ud835\udcaetask\\mathcal{S}_{\\text{task}}caligraphic_S start_POSTSUBSCRIPT task end_POSTSUBSCRIPT to solve all queries sampled from t\ud835\udc61titalic_t, i.e., one system per task. Differently, given one user query q(i)superscript\ud835\udc5e\ud835\udc56q^{(i)}italic_q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT, our query-level meta-agent \ud835\udc9cmeta_querysubscript\ud835\udc9cmeta_query\\mathcal{A}_{\\text{meta\\_query}}caligraphic_A start_POSTSUBSCRIPT meta_query end_POSTSUBSCRIPT conducts reasoning and output a query-specific multi-agent system \ud835\udcaequery(i)superscriptsubscript\ud835\udcaequery\ud835\udc56\\mathcal{S}_{\\text{query}}^{(i)}caligraphic_S start_POSTSUBSCRIPT query end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT for q(i)superscript\ud835\udc5e\ud835\udc56q^{(i)}italic_q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT, i.e., one system per query.", "description": "This figure compares task-level and query-level meta-agents in multi-agent system design.  A task-level meta-agent creates a single system for a category of tasks (e.g., code generation). A query-level meta-agent, on the other hand, generates a separate, customized system for each individual user query.  The figure illustrates how these approaches differ at inference time, showing how task-level agents use a single system for all queries of a given task type and query-level agents create a unique system for every query.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.15257/x2.png", "caption": "Figure 2: Architectural Comparison of Three Multi-Agent Systems. (a) Manually-designed Multi-agent System, (b) Search-based Automatic Multi-agent System, and (c) Reasoning-based Automatic Multi-agent System.", "description": "Figure 2 illustrates three different approaches to building multi-agent systems.  (a) shows the traditional, manually-designed method, where human experts define both the agents and their workflow. This approach is labor-intensive and lacks scalability. (b) presents a search-based automated approach, using a meta-agent (often an LLM) to explore various system designs and a search algorithm to find the optimal configuration. This method is more efficient than manual design but still relies on a pre-defined search space and algorithm. Finally, (c) depicts a reasoning-based automated approach, using a reasoning-driven meta-agent (FLOWREASONER) that generates the system through reasoning and learns from external execution feedback.  This approach is adaptive and query-specific, which offers greater adaptability than the previous two methods.", "section": "4 Meta-Agent FLOWREASONER"}, {"figure_path": "https://arxiv.org/html/2504.15257/x3.png", "caption": "Figure 3: Training Pipeline of FlowReasoner. It consists of (1) Reasoning Data Distillation, (2) Reasoning SFT Warmup, (3) Reinforce Reasoning from external execution feedback.", "description": "The figure illustrates the training pipeline of the FlowReasoner model, which consists of three main stages.  The first stage, Reasoning Data Distillation, involves distilling knowledge from a large language model (LLM) to create a dataset for training FlowReasoner's reasoning capabilities. This stage focuses on generating high-quality reasoning data that accurately reflects the complexities of workflow generation for multi-agent systems. The second stage, Reasoning SFT Warmup, leverages supervised fine-tuning (SFT) on this dataset to equip FlowReasoner with basic reasoning abilities for multi-agent system generation. The final stage, Reinforce Reasoning from external execution feedback, employs reinforcement learning (RL) to further refine the model's reasoning abilities. This stage uses external execution feedback from deploying the generated multi-agent systems in a real-world environment, allowing FlowReasoner to learn and adapt its workflow generation based on the performance of those systems.", "section": "4 Meta-Agent FLOWREASONER"}, {"figure_path": "https://arxiv.org/html/2504.15257/x4.png", "caption": "(a) Ablation of Meta-agent", "description": "This figure shows the ablation study on different meta-agents.  The accuracy of various meta-agents is compared using o1-mini as workers across three different benchmarks.  This helps determine the impact of the choice of meta-agent on the overall performance of the system.  Different meta-agents are tested (e.g., Deepseek-R1-7B, Qwen2.5-7B, etc.), and their accuracies are shown in a bar chart for comparison against the baseline (o1-mini).", "section": "5 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.15257/x5.png", "caption": "(b) Ablation of Workers", "description": "The bar chart displays the accuracy results of different worker models when used with the o1-mini meta-agent.  It compares the performance of various LLMs (large language models) in a multi-agent system setting, demonstrating how the choice of the worker model affects the overall accuracy. The goal is to illustrate the impact of different worker models on the effectiveness of the generated workflow.", "section": "5.1 Experiment Results"}]