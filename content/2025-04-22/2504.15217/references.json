{"references": [{"fullname_first_author": "Andrea Agostinelli", "paper_title": "MusicLM: generating music from text", "publication_date": "2023-01-01", "reason": "MusicLM is a foundational paper in text-to-music generation that establishes a strong baseline for quality and control."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2023-01-01", "reason": "Direct Preference Optimization (DPO) offers a more stable and efficient alternative to reinforcement learning for aligning models with human preferences."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "Latent Diffusion Models (LDMs) are a critical technique for efficient and high-quality generation in various modalities including audio, video and images."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper provides the core formulation of denoising diffusion probabilistic models, a fundamental technology enabling high-quality generative modeling."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "Attention mechanisms and the transformer architecture have revolutionized sequence modeling and are crucial components of many generative models used today."}]}