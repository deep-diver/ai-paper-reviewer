{"importance": "This paper introduces a new **MM-IFEngine** to train Multimodal Large Language Models. This new method results in notable gains on various IF benchmarks, and provides researchers with novel benchmark to evaluate IF.", "summary": "MM-IFEngine enhances MLLM instruction-following using diverse data generation and a hybrid evaluation approach.", "takeaways": ["MM-IFEngine, an effective pipeline to generate high-quality image-instruction pairs to train MLLMs.", "MM-IFEval, a benchmark with diverse constraints and comprehensive evaluation.", "Fine-tuning MLLMs on MM-IFInstruct-23k and MM-IFDPO-23k improves performance on instruction-following benchmarks."], "tldr": "Existing multimodal instruction following (IF) benchmarks have limitations such as scarce training data, simple instructions, and imprecise evaluation strategies. These benchmarks lack the **diversity required for real-world applications**, leading to saturated results and restricting the progress of current Multimodal Large Language Models (MLLMs) in IF.\n\nTo address these issues, this paper introduces the **MM-IFEngine**, an effective pipeline for generating high-quality image-instruction pairs. The pipeline yields large-scale training data (MM-IFInstruct-23k) and includes both compose-level and perception-level constraints, with a comprehensive evaluation pipeline. The approach is empirically validated, demonstrating significant performance gains on both the introduced **MM-IFEval** and existing benchmarks through fine-tuning MLLMs.", "affiliation": "Fudan University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2504.07957/podcast.wav"}