[{"figure_path": "https://arxiv.org/html/2504.07943/x2.png", "caption": "Figure 1: Demonstration of the difference between (a) 3D part segmentation and (b) 3D part amodal segmentation. 3D part amodal segmentation decomposes the 3D shape into complete semantic parts rather than broken surface patches, facilitating various downstream applications. In this paper, we propose a solution by performing 3D part shape completion on incomplete part segments.", "description": "Figure 1 illustrates the key difference between standard 3D part segmentation and the novel 3D part amodal segmentation task introduced in this paper.  Standard methods (a) identify only visible surface patches of parts, resulting in incomplete segments.  In contrast, 3D part amodal segmentation (b) aims to decompose a 3D shape into complete, semantically meaningful parts, even when parts are occluded.  This is achieved by inferring the full geometry of each part, ensuring consistency with the overall shape, and effectively handling diverse shapes. The figure shows examples of both approaches applied to a ring-shaped object, highlighting the completeness of parts in the amodal segmentation, which enables various downstream applications such as geometry editing, material assignment, etc. This paper addresses this challenging task by proposing a two-stage approach involving initial 3D part segmentation followed by 3D part shape completion using a novel diffusion-based model, HoloPart.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2504.07943/x3.png", "caption": "Figure 2: An overview of the HoloPart model design. Given a whole 3D shape and a corresponding surface segmentation mask, HoloPart encodes these inputs into latent tokens, using context-aware attention to capture global shape context and local attention to capture local part detailed features and position mapping. These tokens are used as conditions and injected into the part diffusion model via cross-attention respectively. During training, noise is added to complete 3D parts, and the model learns to denoise them and recover the original complete part.", "description": "This figure illustrates the architecture of the HoloPart model, which is a two-stage approach for 3D part amodal segmentation. First, it takes as input a complete 3D shape and its corresponding segmentation mask.  Then, it encodes this information into latent tokens using a combination of context-aware attention (to capture global shape context) and local attention (to capture fine-grained details and positional information of individual parts). These latent tokens are then used as conditioning information to guide a diffusion model that reconstructs complete 3D parts from potentially incomplete, segmented parts. The training process involves adding noise to complete 3D parts and training the model to reverse this process, learning to denoise and recover the original complete parts.", "section": "3. Context-aware Part Completion"}, {"figure_path": "https://arxiv.org/html/2504.07943/x4.png", "caption": "Figure 3: Qualitative comparison with PatchComplete, DiffComplete and Finetune-VAE on the ABO dataset.", "description": "This figure presents a qualitative comparison of 3D part completion results on the ABO dataset between the proposed method and three baseline methods: PatchComplete, DiffComplete, and Finetune-VAE.  For several household objects (bed, table, lamp, chair), the figure visually showcases the original segmented part (incomplete), and the completed parts generated by each method. This allows for a direct visual comparison of the accuracy and completeness of the generated parts, particularly highlighting differences in the handling of occlusions and the overall plausibility of the completed geometry.", "section": "4. Main Results"}, {"figure_path": "https://arxiv.org/html/2504.07943/x5.png", "caption": "Figure 4: Qualitative comparison with PatchComplete, DiffComplete and Finetune-VAE on the PartObjaverse-Tiny dataset.", "description": "Figure 4 presents a qualitative comparison of the 3D part completion results from PatchComplete, DiffComplete, Finetune-VAE, and the proposed HoloPart method on the PartObjaverse-Tiny dataset. Each row displays the ground truth complete part followed by the corresponding incomplete part segment and the completion results from each method.  The figure visually demonstrates how HoloPart outperforms the baselines in generating complete and semantically meaningful 3D parts, especially for complex shapes with significant occlusions, while the baselines often struggle to reconstruct detailed geometry or maintain shape consistency.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.07943/x6.png", "caption": "Figure 5: Our method seamlessly integrates with existing zero-shot 3D part segmentation models, enabling effective zero-shot 3D part amodal segmentation.", "description": "This figure demonstrates the effectiveness of the proposed method in a zero-shot setting.  It shows the integration of the HoloPart model with existing zero-shot 3D part segmentation methods. The workflow starts with a zero-shot segmentation model providing initial surface segmentations of the 3D shapes. HoloPart then takes these incomplete segments as input and generates complete 3D parts. The result is a seamless and efficient zero-shot 3D part amodal segmentation. The figure showcases this process by visually presenting the original mesh, the segmented parts, and the resulting complete parts after using HoloPart.  This highlights that HoloPart's ability to infer occluded geometry and maintain global consistency extends to new segmentation methods without requiring additional training or fine-tuning.", "section": "3D Part Amodal Segmentation"}, {"figure_path": "https://arxiv.org/html/2504.07943/x7.png", "caption": "Figure 6: 3D part amodal segmentation is capable of numerous downstream applications, such as Geometry Editing, Geometry Processing, Material Editing and Animation.", "description": "Figure 6 showcases the versatility of 3D part amodal segmentation by demonstrating its applications in various downstream tasks.  It illustrates examples of geometry editing (modifying the shape of individual parts), geometry processing (improving the quality of the mesh), material editing (assigning different textures to parts), and animation (giving parts the ability to move). This highlights the ability of the approach to generate complete, accurate part geometries that are suitable for complex manipulations and downstream applications beyond simple perception tasks.", "section": "4. Application"}, {"figure_path": "https://arxiv.org/html/2504.07943/x8.png", "caption": "Figure 7: Geometry Super-resolution. By representing a part with the same number of tokens as the overall object, we can achieve geometry super-resolution.", "description": "Figure 7 demonstrates the capability of HoloPart to achieve geometry super-resolution.  By using the same number of tokens to represent individual parts as are used for the entire object, the model can generate highly detailed and refined part geometries. This contrasts with traditional methods that often result in lower-resolution part details.  The figure visually compares the level of detail achieved when using this technique.", "section": "4. Application"}, {"figure_path": "https://arxiv.org/html/2504.07943/x9.png", "caption": "Figure 8: Ablation study of semantic and instance part completion.", "description": "This ablation study compares the results of semantic and instance part completion methods. Semantic completion treats all similar parts of an object as a single part, for example, all four legs of a chair are considered one part.  Instance completion treats each individual part separately; each leg of the chair is a unique part. The figure visually demonstrates the differences in the completed parts generated using each approach.", "section": "6.4. More Ablation Analysis"}, {"figure_path": "https://arxiv.org/html/2504.07943/x10.png", "caption": "Figure 9: Examples of data filtered out by rules.", "description": "Figure 9 visually presents examples of 3D data points that were excluded from the dataset due to specific filtering rules applied during data curation.  The figure is divided into three sections (a, b, and c), each showcasing different reasons for data exclusion. Section (a) displays examples filtered out due to an excessive number of mesh components, indicating overly fragmented or complex objects. Section (b) shows data points rejected because of an imbalanced distribution of connected components in their 2D projections (frontal and side views), implying problems with data consistency and completeness. Finally, section (c) illustrates examples excluded due to a highly skewed volume distribution among object parts, revealing instances of disproportionate part sizes. These examples highlight how the filtering rules ensure the quality and consistency of the final dataset used for training and evaluating the HoloPart model.", "section": "6.2. Data Curation Details"}, {"figure_path": "https://arxiv.org/html/2504.07943/x11.png", "caption": "Figure 10: The absence of context-aware attention leads to a lack of guidance for completing individual components, resulting in inconsistent and lower-quality outcomes.", "description": "This figure demonstrates the importance of the context-aware attention mechanism in HoloPart.  By comparing the part completion results with and without context-aware attention, it shows that the absence of this mechanism leads to poorly formed and inconsistent part generation.  Parts lack the overall shape consistency needed for plausible completions, highlighting the critical role of context in accurately reconstructing occluded geometries.", "section": "3.2 Context-aware Part Completion"}, {"figure_path": "https://arxiv.org/html/2504.07943/x12.png", "caption": "Figure 11: Visualization of generated parts across different guidance scales.", "description": "This figure shows the impact of different guidance scales on the quality of generated 3D parts by HoloPart.  The images illustrate how varying the guidance scale affects the model's ability to reconstruct complete and plausible 3D shapes from partial segments.  Each row represents a different 3D part and shows the results generated with guidance scales of 1.5, 3.5, 5.0, and 7.5.  This helps demonstrate the optimal balance needed for effective part completion in the HoloPart model.", "section": "3.2 Context-aware Part Completion"}, {"figure_path": "https://arxiv.org/html/2504.07943/x13.png", "caption": "Figure 12: Qualitative comparison of different learning rate settings.", "description": "This figure displays a qualitative comparison of the results obtained using different learning rate settings during the training of the HoloPart model.  The different settings impact the quality and fidelity of the generated 3D part shapes.  It helps illustrate the optimal learning rate for balancing model training efficiency and generating high-quality outputs for part completion.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.07943/x14.png", "caption": "Figure 13: More Results of 3D Part Amodal Segmentation.", "description": "This figure shows additional examples of 3D part amodal segmentation results.  The input is a generated 3D mesh.  The method first uses a 3D part segmentation model to identify the individual parts of the object. Then, the HoloPart model completes each segmented part, even the parts that were originally occluded. Finally, the completed parts are merged to form a complete, consistent 3D model. The examples illustrate the model's ability to generate high-quality 3D parts across a variety of objects, including characters and building models, demonstrating good zero-shot generalization capabilities.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.07943/x15.png", "caption": "Figure 14: More qualitative results on the PartObjaverse-Tiny dataset.", "description": "Figure 14 provides a qualitative comparison of different methods for 3D part amodal segmentation on the PartObjaverse-Tiny dataset.  It shows the original mesh and segmented parts alongside the results obtained using PatchComplete, DiffComplete, Finetune-VAE, and the authors' proposed method (Ours).  Red boxes highlight areas where the different methods struggle to accurately generate complete and realistic 3D parts, especially in complex or occluded regions.", "section": "4. Experiments"}]