{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important because it details the development of CLIP, a foundational model for vision-language tasks, which is relevant as this paper fine-tunes existing VLMs for visual reasoning."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This paper is crucial due to its introduction of chain-of-thought prompting, a technique widely used to improve the reasoning capabilities of LLMs, which this work aims to enhance for VLMs."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This work is important as it demonstrates how visual instruction tuning can improve VLM performance, which is in line with this paper's goal of improving reasoning in VLMs through fine-tuning."}, {"fullname_first_author": "Pan Lu", "paper_title": "Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts", "publication_date": "2024-01-01", "reason": "This work is important as this paper uses the MathVista benchmark extensively for evaluating their model's performance."}, {"fullname_first_author": "Xiyao Wang", "paper_title": "Enhancing visual-language modality alignment in large vision language models via self-improvement", "publication_date": "2024-01-01", "reason": "This work, authored by the same primary author, explores a similar theme of self-improvement in VLMs, making it directly relevant and influential to the present study."}]}