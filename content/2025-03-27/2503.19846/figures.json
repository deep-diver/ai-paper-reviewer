[{"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/average_image.jpg", "caption": "Average Image", "description": "This figure visualizes the average face image from the CelebA dataset, along with attention maps highlighting regions focused on by a model when classifying different attributes.  These attributes include \"Male\", \"Blond Hair\", and \"Wavy Hair.\"  The attention maps reveal the model's reliance on certain facial features (like hair) for specific attribute classifications and potentially expose correlations between attributes, which may reveal underlying biases.  Specifically, the attention for \"Blond Hair\" is compared to that of \"Wavy Hair\" to illustrate spurious correlation with \"Male\", something not explicitly present in the dataset labels alone.", "section": "Attention-IoU: Examining Biases in CelebA using Attention Maps"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_male.png", "caption": "Male", "description": "This figure displays average attention maps for the \"Male\" attribute in the CelebA dataset, highlighting the image regions the model focuses on when predicting this attribute.  Each sub-image represents the average attention map generated by the model across all instances of the images in the dataset. Regions with brighter intensity indicate higher attention weights, revealing the model's reliance on specific facial features to determine gender.  The figure likely shows the visual evidence supporting a claim that the model's prediction is biased toward specific visual cues, rather than the underlying attribute itself. For example, if brighter areas strongly correlate with non-facial, correlated attributes (hair style, makeup, etc.), it would suggest that the model is relying on spurious correlations rather than true gender characteristics.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_blond_hair.png", "caption": "Blond_Hair", "description": "This figure visualizes average heatmaps for the \"Blond Hair\" attribute in the CelebA dataset using the Attention-IoU method.  Different heatmaps are shown for various scenarios depending on the values of \"Male\" and \"Mustache\" attributes. Comparing these heatmaps allows for analysis of how the model attends to different facial regions when predicting the \"Blond Hair\" attribute, revealing potential biases and spurious correlations within the model's internal representations.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_wavy_hair.png", "caption": "Wavy_Hair", "description": "This figure shows the average attention map (heatmap) for the attribute \"Wavy Hair\" as generated by GradCAM using a model trained on the CelebA dataset.  The heatmap visually represents which parts of the input image the model focuses on most strongly when determining whether an image depicts wavy hair. Brighter regions in the heatmap indicate higher attention weights assigned by the model to those specific image areas. This visualization helps to understand the model's internal decision-making process regarding this attribute and can potentially reveal any biases or spurious correlations the model may be relying on.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x1.png", "caption": "Figure 1: We use attention maps to understand which image regions a model relies on for the target classification task. Our proposed Attention-IoU framework provides insights into how models represents biases between correlated attributes. For example, consider the spatially related attributes of blond and wavy hair in the CelebA dataset\u00a0[44], which have similar label correlations to the Male label. They are attended to differently by the model, with blond hair appearing closer to Male in both average attention map (top row) and the Attention-IoU mask score (bottom row).\nThus, Attention-IoU reveals that blond hair, when compared to wavy hair, has a spurious correlation with Male that is not present in the dataset labels.", "description": "This figure demonstrates how Attention-IoU can reveal biases in a model's internal representations by analyzing attention maps. The top row shows average attention maps for different attributes (blond hair, wavy hair, and male) in the CelebA dataset. The bottom row shows Attention-IoU mask scores, quantifying the correlation between these attributes.  The example highlights that although blond and wavy hair have similar correlations with the 'male' label in the dataset, the model attends to blond hair more strongly when predicting 'male', revealing a spurious correlation not reflected in the dataset labels themselves.  This spurious correlation is detected through the difference in attention patterns, illustrating how Attention-IoU reveals biases beyond simple accuracy disparities.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird3.png", "caption": "Background Bias", "description": "This figure illustrates the concept of background bias in image classification models.  It uses the Waterbirds dataset, where images of waterbirds are often associated with water backgrounds and landbirds with land backgrounds. The figure displays three examples of how a model might erroneously rely on the background rather than the bird itself to make its classification.  Panel (a) shows a model attending to the entire background, Panel (b) focusing on a ship in the background rather than the bird, and panel (c) only on part of the bird's wing (indicating an incomplete or incorrect recognition of the actual object of classification). These examples highlight different ways spurious correlations can lead to bias, where the model relies on information associated with, but not inherently predictive of, the correct class. ", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird2.png", "caption": "Object Bias", "description": "The figure illustrates a type of model bias where the model attends to an object other than the target object for classification. In the example, the model incorrectly focuses on a ship in the background instead of correctly identifying the landbird, resulting in an erroneous classification.", "section": "3. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird4.png", "caption": "Depiction Bias", "description": "The figure illustrates the concept of \"Depiction Bias\" in computer vision models, where the model's performance is affected not by the object itself but by how it is depicted in the image.  It shows three examples of attention maps generated by a model trying to classify a landbird on a water background. In the first example, the model mistakenly focuses on the entire background (the water) when classifying the bird. In the second, the model focuses on a ship (a spurious feature associated with the background) rather than the bird itself.  In the third, the model only attends to a small part of the bird (its wing), potentially leading to misclassification due to the incomplete depiction of the bird.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.19846/x2.png", "caption": "Figure 2: Attention maps for a landbird on a water background in the Waterbirds dataset\u00a0[59], illustrating possible forms of model bias for incorrect classifications. (left) attending to the whole background; (center) attending to a ship instead of the bird; (right) only attending to a part of the bird, its wing in flight.", "description": "Figure 2 illustrates different ways a model can exhibit bias when classifying images from the Waterbirds dataset.  The example shows a landbird incorrectly classified, possibly due to the model focusing on irrelevant features.  The image on the left shows the model attending to the entire background, suggesting it might be relying on spurious correlations between the bird type and background rather than the bird itself. The center image shows the model incorrectly focusing on a ship in the background, again indicating spurious correlation bias. The image on the right shows the model only attending to a small portion of the bird (its wing), suggesting the model might be learning from incomplete or low-level features rather than the whole object.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.19846/x3.png", "caption": "Figure 3: Average bird mask and average heatmaps for Waterbirds at increasing levels of bias. We see that the model attends less on the bird as the bias increases, as indicated by its mask.", "description": "This figure visualizes the impact of increasing bias in the Waterbirds dataset on a model's attention.  The leftmost panel shows the ground truth mask of a bird. The subsequent panels display average GradCAM attention maps for models trained on datasets with progressively higher levels of spurious correlation between birds and their backgrounds (70%, 90%, 95%, 100% bias). As the bias increases (more spurious correlations), the heatmaps clearly show a shift in the model's focus, from attending primarily to the bird itself to increasingly attending to the background, indicating that the model relies more heavily on spurious correlations for classification as bias increases. This is reflected in the decreasing focus on the bird region as indicated by its mask.", "section": "4. Validating the metric"}, {"figure_path": "https://arxiv.org/html/2503.19846/x4.png", "caption": "Figure 4: Evaluation of mask score using GradCAM on Waterbirds test set. The X-axis represents the Attention-IoU mask score for the ground-truth masks of the bird and background. We note the dataset bias and the worst group accuracy (WGA) along the Y-axis. As the bias increases, the worst group accuracy decreases and the model attends less to the bird and more to the background.", "description": "This figure displays the relationship between dataset bias, model performance, and attention mechanisms.  The x-axis shows the Attention-IoU mask score, which quantifies how well the model's attention aligns with the ground truth bird and background masks. A higher score indicates better alignment. The y-axis shows both the dataset bias (percentage of waterbirds on water backgrounds) and the worst-group accuracy (WGA). The graph demonstrates that as dataset bias increases (more spurious correlations), the worst-group accuracy decreases, and the model's attention shifts from the bird (the true target) to the background (the spurious correlation). This visually confirms that Attention-IoU effectively measures model bias by reflecting the model's reliance on spurious correlations.", "section": "4. Validating the metric"}, {"figure_path": "https://arxiv.org/html/2503.19846/x5.png", "caption": "Figure 5: Evaluation of mask score using GradCAM on CelebA test set with attribute-specific feature masks, compared to worst group accuracy with Male. A mask score of 1 indicates perfect agreement between the attention map and feature mask, and 0 indicates perfect disagreement. Groups are considered based on ground-truth labels for the different combinations of target attribute and Male. If the number of images in a group is less than 1% of the test set, the group was excluded from consideration.", "description": "This figure displays the mask score for different attributes in the CelebA dataset, calculated using GradCAM. The mask score measures the agreement between a model's attention map and the ground truth feature mask for each attribute. The x-axis shows the mask score, ranging from 0 (perfect disagreement) to 1 (perfect agreement). The y-axis lists the attributes, grouped by their general facial feature category (hair, eyebrows, eyes, etc.). Each dot represents a group of images with a specific combination of the target attribute and the protected attribute of 'Male'. The size of the dot corresponds to the number of images in that group; groups with fewer than 1% of the total test set images are excluded. The figure also shows the worst-group accuracy (WGA) for each attribute group; thus, demonstrating the relationship between a model's attention focus and its classification performance on different subgroups, thereby providing insight into potential biases in the model.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x10.png", "caption": "Figure 6: Comparison of attributes with the Male attribute heatmap. (Left) We compare Attention-IoU with the absolute value of the Matthews correlation coefficient between the predictions of the attribute and Male, noticing a strong positive trend. Some attributes are outliers to this trend, including Eyeglasses and Mustache, which lie above this trend, and Wavy_Hair, which lies below. (Right) We measure the mask score for a selection of attributes. We notice that the heatmap for Male attends most strongly to the eye, eyebrows, and mouth region, which is closely mimicked by Wearing_Lipstick.\nWe can also compare attributes like Blond_Hair and Wavy_Hair, and find that the main difference between their heatmaps is in the\u00a0eye\u00a0region.", "description": "Figure 6 analyzes the relationship between different facial attributes and the 'Male' attribute in the CelebA dataset using the Attention-IoU metric. The left panel shows a strong positive correlation between the Attention-IoU heatmap score (measuring the overlap of attention maps for an attribute and the 'Male' attribute) and the absolute value of the Matthews Correlation Coefficient (MCC) between the attribute's prediction and the 'Male' label.  However, some attributes like 'Eyeglasses' and 'Mustache' show higher Attention-IoU scores than expected based on their MCC, while 'Wavy Hair' shows a lower score. The right panel displays the mask scores (comparing attention maps to ground truth masks) for several attributes, revealing that the 'Male' attribute's attention map focuses mainly on the eye, eyebrow, and mouth regions, a pattern closely mirrored by 'Wearing Lipstick'.  A comparison of 'Blond Hair' and 'Wavy Hair' highlights that the key difference in their attention maps lies in the eye region.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x11.png", "caption": "Figure 7: Average heatmaps for Male with average masks. We train models to predict Male when Eyeglasses are absent (center-left) and present (center-right). There is a stark difference in the heatmaps, suggesting that the features used by the model for predicting Eyeglasses are distinct from those used to predict Male, despite them being co-localized in the original models.", "description": "This figure visualizes average attention maps for predicting the attribute 'Male' under different conditions regarding the presence of 'Eyeglasses'.  By comparing heatmaps from models trained separately on datasets with and without eyeglasses, the figure demonstrates that the model utilizes distinct image features to recognize 'Male' when eyeglasses are present versus absent.  This highlights that even spatially overlapping attributes can rely on different features leading to potential model biases or spurious correlations.", "section": "5.2. Comparison with the Male heatmap"}, {"figure_path": "https://arxiv.org/html/2503.19846/x12.png", "caption": "Figure 8: Average heatmaps for Mustache. We visualize average heatmaps for Mustache for images where Mustache and Male are labeled false (center-left), where Mustache is labeled false and Male is labeled true (center-right) and where Mustache and Male are labeled true (far right), and compare to the Male heatmap (far left). When Male is labeled as false, Mustache and Male attention maps closely align but do not when Male is labeled true.", "description": "This figure visualizes average attention maps generated by a model for the attribute \"Mustache\", broken down into four scenarios based on the ground truth labels for \"Mustache\" and \"Male\":\n\n1.  **Male: False, Mustache: False (center-left):** Shows the average attention map when neither \"Male\" nor \"Mustache\" is present. \n2.  **Male: True, Mustache: False (center):** Shows the average attention map when \"Male\" is present but \"Mustache\" is not. \n3.  **Male: False, Mustache: True (center-right):** Shows the average attention map when \"Mustache\" is present but \"Male\" is not. \n4.  **Male: True, Mustache: True (far right):** Shows the average attention map when both \"Male\" and \"Mustache\" are present.\n\nThe figure compares these attention maps to the average attention map for \"Male\" (far left).  The key observation is that the attention maps for \"Mustache\" strongly resemble the \"Male\" attention map when the \"Male\" label is false, indicating a potential spurious correlation between the two attributes. However, this correlation disappears when the \"Male\" label is true, implying that the model uses different features for detecting \"Mustache\" depending on the gender of the subject.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x13.png", "caption": "Blond_Hair \u03c4\ud835\udf0f\\tauitalic_\u03c4: 0.073", "description": "This figure visualizes the effect of subsampling the training dataset to manipulate the correlation between the Blond_Hair attribute and the Male attribute on the heatmap score.  The x-axis represents the absolute value of the Matthews Correlation Coefficient (MCC) between Blond_Hair and Male after subsampling, showing how the correlation was varied in the training data. The y-axis represents the heatmap score between Blond Hair and Male, a measure of the model's attention to features related to the male attribute when classifying blond hair.  The plot shows that changing the correlation in the training data did not significantly impact the heatmap score, suggesting that the model's bias might not solely be dependent on the dataset correlation but could also be caused by other confounding factors.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x14.png", "caption": "Wavy_Hair \u03c4\ud835\udf0f\\tauitalic_\u03c4 0.778", "description": "This figure displays the results of an experiment where the correlation between the attributes Wavy Hair and Male was manipulated in the training dataset. By subsampling the training data, different levels of correlation (measured by the Matthews Correlation Coefficient, MCC) between these two attributes were created. The x-axis shows the absolute value of the MCC, ranging from approximately -0.5 to -0.1, representing varying degrees of negative correlation.  The y-axis represents the heatmap score, which quantifies the model's reliance on the Male attribute when predicting Wavy Hair.  The plot shows a strong positive correlation (Kendall's \u03c4 of 0.778) between the absolute MCC and the heatmap score.  This indicates that the model's reliance on the Male attribute for predicting Wavy Hair is directly influenced by the correlation between these attributes in the training data.  A higher negative correlation leads to a lower heatmap score, suggesting that reducing the spurious correlation between Male and Wavy Hair in the training data weakens the model's bias towards using Male as a proxy for Wavy Hair.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x15.png", "caption": "Figure 9: Varying the correlation in the training dataset. To understand if the correlations are indeed responsible for the mask scores in their entirety, we subsample the dataset to vary the ground-truth MCC between Blond_Hair and Wavy_Hair and Male. We find that changing the ground-truth MCC for Blond_Hair (left) does not change the heatmap score, while changing the MCC for Wavy_Hair (right) results in a strong change in the heatmap score (orange/square indicates the original results). This suggests that there might be a hidden confounder present between Blond_Hair and Male, which leads to the large heatmap score. This is unlike Wavy_Hair, which is much more dependent on ground-truth correlations within the dataset.", "description": "This figure investigates whether the correlations between attributes in the CelebA dataset are solely responsible for the observed attention patterns (heatmap scores).  To do this, the researchers manipulated the training dataset by subsampling to change the ground-truth Matthews Correlation Coefficient (MCC) between two hair attributes (Blond_Hair and Wavy_Hair) and the protected attribute Male. The results show that modifying the correlation between Blond_Hair and Male had no significant effect on the heatmap score, suggesting the presence of a hidden confounding variable influencing the model's attention to Blond_Hair. In contrast, altering the correlation between Wavy_Hair and Male resulted in a substantial change in the heatmap score, indicating a stronger reliance on the dataset's explicit correlations.", "section": "5. Analyzing CelebA"}, {"figure_path": "https://arxiv.org/html/2503.19846/x16.png", "caption": "Figure 10: Training set subgroup sizes under subsampling. Here we report subgroup sizes of the training set of varying MCCs for Blond_Hair and Wavy_Hair with Male, under our optimization scheme, to compute the results in Sec.\u00a05.2 and Fig.\u00a09. Subgroup sizes are bounded to the smallest subsampled training set size. The legend shows the four different subgroups groups, with the first value indicating the target label and the second Male.", "description": "This figure shows the results of an experiment where the training data was subsampled to vary the correlation between attributes. Specifically, it shows how the sizes of four subgroups (Blond Hair and Male, Wavy Hair and Male) changed to achieve target Matthews Correlation Coefficients (MCCs) between the target attribute and Male.  The sizes were constrained to be no smaller than the smallest subsampled training set found during the optimization process.  The plot illustrates the relationship between the target MCC and the number of images in each subgroup, providing insights into how manipulating correlations between attributes in the training dataset affects the model's behavior.", "section": "5. Analyzing CelebA"}]