[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.2.1\">Original</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.3.1\">No Stop Words</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.4.1\">No Punctuation</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.5.1\">No Stops &amp; Punct</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.6.1\">No Articles</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.7.1\">GPT-4 Removal</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" colspan=\"7\" id=\"S4.T1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.2.2.1.1\">MMLU</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.3.1.1\">Llama-3.2-3B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.2\">0.398</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.3\">0.347</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.4\">0.391</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.5\">0.342</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.6\">0.386</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.3.1.7\">0.377</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.4.2.1\">Mistral-7B-v0.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.2\">0.423</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.3\">0.359</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.4\">0.411</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.5\">0.350</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.6\">0.413</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.2.7\">0.392</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.5.3.1\">meta-llama-3-8B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.2\">0.430</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.3\">0.365</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.4\">0.419</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.5\">0.351</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.6\">0.415</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.3.7\">0.403</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.6.4.1\">Qwen2.5-1.5B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.2\">0.362</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.3\">0.332</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.4\">0.348</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.5\">0.322</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.6\">0.356</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.4.7\">0.346</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.7.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"7\" id=\"S4.T1.1.7.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.7.5.1.1\">BABILong 4k</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.8.6.1\">Llama-3.2-3B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.2\">0.420</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.3\">0.334</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.4\">0.377</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.5\">0.322</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.6\">0.386</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.8.6.7\">0.387</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.9.7.1\">Mistral-7B-v0.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.2\">0.373</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.3\">0.324</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.4\">0.322</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.5\">0.314</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.6\">0.368</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.7.7\">0.312</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.10.8.1\">meta-llama-3-8B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.2\">0.388</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.3\">0.331</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.4\">0.359</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.5\">0.307</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.6\">0.389</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.8.7\">0.360</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.11.9.1\">Qwen2.5-1.5B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.2\">0.366</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.3\">0.326</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.4\">0.333</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.5\">0.322</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.6\">0.348</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.11.9.7\">0.308</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: Performance on MMLU and BABILong-4k after partial removal of various token classes, with GPT-4-based removal comparison.", "description": "This table presents the performance of several large language models (LLMs) on two benchmark tasks, MMLU and BABILong-4k, after removing different types of tokens (stopwords, punctuation, articles).  It compares the results of three removal methods: a simple rule-based removal, GPT-4 guided removal, and removal of only specific token classes. The table shows how the removal of seemingly insignificant tokens impacts the models' ability to solve problems across various domains and with different levels of contextual complexity.", "section": "4.2 Examining the Impact of Removing \"Filler\" Tokens"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.2\">Corr</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.2.1.1\">Opt-6.7b</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.1.2\">0.482</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.3.2.1\">Opt-1.3b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.2.2\">0.406</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.4.3.1\">Opt-13b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.3.2\">0.359</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.5.4.1\">Opt-2.7b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.4.2\">0.401</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.6.5.1\">Gemma-2-9b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.5.2\">0.561</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.7.6.1\">Gemma-2-2b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.6.2\">0.515</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.8.7.1\">Llama-3.2-3B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.8.7.2\">0.367</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.9.8.1\">Llama-3 8B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.9.8.2\">0.050</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.10.9.1\">Llama-3 8B Instruct</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.10.9.2\">0.328</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.11.10.1\">Llama-2 7Bfp16</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.11.10.2\">0.239</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.12.11.1\">Phi-3-mini 128k instruct</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.12.11.2\">0.410</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.13.12.1\">Qwen2.5 1.5B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.13.12.2\">0.199</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.14.13.1\">Mistral-7B-v0.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.14.13.2\">0.152</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.1.15.14.1\">*p-value less than 0.05 in all measurements</th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T2.1.15.14.2\"></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Correlation coefficient.", "description": "This table presents the Pearson correlation coefficients between the average linearity scores and contextualization scores for various language models.  It quantifies the relationship between how linearly the model transforms its internal representations across layers and how well those representations retain contextual information.", "section": "4.3 Correlation Between Nonlinearity and Context Memory"}]