[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T1.7\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T1.7.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.2.1\">Selection</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.3.1\">Retain</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.4.1\">Neigh</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.5.1\">Real World</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.6.1\">Real Authors</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T1.7.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.1.1.7.1\">Model Utility</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T1.7.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T1.7.2.1.1.1\">Grad. Ascent</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.3\">0.488</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.4\">0.568</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.5\">0.720</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.6\">0.891</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.2.1.7\">0.343</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.2\">0.495</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.3\">0.558</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.4\">0.731</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.5\">0.907</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.3.2.6\">0.353</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T1.7.4.3.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.4.3.2.1\">0.523</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.4.3.3.1\">0.608</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.4.3.4.1\">0.769</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.4.3.5.1\">0.933</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.4.3.6.1\">0.387</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T1.7.5.4.1.1\">Refusal</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.3\">0.493</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.4\">0.488</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.5\">0.714</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.6\">0.890</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.5.4.7\">0.366</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.6.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.2\">0.456</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.3\">0.458</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.4\">0.644</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.5\">0.819</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.6.5.6\">0.332</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.7.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T1.7.7.6.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.7.6.2.1\">0.500</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.7.6.3.1\">0.524</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.7.6.4.1\">0.744</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.7.6.5.1\">0.920</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.7.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.7.6.6.1\">0.381</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.8.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S5.T1.7.8.7.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T1.7.8.7.1.1\">NPO</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.3\">0.281</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.4\">0.237</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.5\">0.192</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.6\">0.342</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.7.8.7.7\">0.199</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.9.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.2\">0.253</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.3\">0.271</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.4\">0.195</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.5\">0.308</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.7.9.8.6\">0.186</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.7.10.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T1.7.10.9.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.10.9.2.1\">0.329</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.10.9.3.1\">0.319</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.10.9.4.1\">0.246</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.10.9.5.1\">0.414</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.7.10.9.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.7.10.9.6.1\">0.248</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: AUC across the two competing objectives: (1) Deletion Effectiveness, defined as (1\u2212ROUGE)1ROUGE(1-\\text{ROUGE})( 1 - ROUGE ) on the forget set (X-axis), and (2) Model Utility, averaged across Counterfact topics and evaluated via ROUGE scores on multiple utility datasets, including neighborhood data and an aggregate model utility across datasets (Y-axis). We compare three unlearning methods: Gradient Ascent, Refusal, and NPO.", "description": "This table presents the Area Under the Curve (AUC) values, which represents a trade-off between deletion effectiveness and model utility.  Deletion effectiveness is measured by (1 - ROUGE) score on the forget set (how well the model forgets the unwanted information), while model utility is evaluated using ROUGE scores across several datasets: retain set, neighborhood data, real-world data, and real-author data. An aggregate model utility score is also calculated by combining these metrics.  The results are shown for three different unlearning methods: Gradient Ascent, Refusal, and Negative Preference Optimization (NPO), and for three coreset selection methods: selecting the complete forget set, a random subset of the forget set and the UPCORE coreset.", "section": "4. Experimental Setup"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T2.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T2.5.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.2.1\">Selection</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.3.1\">Retain</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.4.1\">Neigh</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.5.1\">Real World</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.6.1\">Real Authors</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T2.5.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.1.1.7.1\">Model Utility</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T2.5.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S5.T2.5.2.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T2.5.2.1.1.1\">Grad. Ascent</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.3\">0.153</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.4\">0.285</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.5\">0.226</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.6\">0.155</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.5.2.1.7\">0.135</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.5.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.2\">0.159</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.3\">0.304</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.4\">0.222</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.5\">0.157</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.5.3.2.6\">0.136</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.5.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T2.5.4.3.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.2\">0.165</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.4.3.3.1\">0.318</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.4.3.4.1\">0.227</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.4.3.5.1\">0.158</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.5.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.5.4.3.6.1\">0.147</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Evaluation metrics from Table\u00a01 shown for Gradient Ascent on the TriviaQA topics.", "description": "This table presents the results of the Gradient Ascent unlearning method applied to TriviaQA topics.  It shows the performance metrics (Retain, Neigh, Real World, Real Authors, Model Utility) from Table 1, but specifically focusing on the TriviaQA dataset. These metrics evaluate the trade-off between deletion accuracy (how well the model forgets the specified information) and model utility (how well the model performs on related and unrelated tasks). The table compares three data selection methods: using the entire forget set, a random subset of the forget set, and the coreset selected by UPCORE. This allows for a comparison of how different strategies for selecting data points to unlearn affect the overall balance between these competing objectives.", "section": "4. Experimental Setup"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.5.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S5.T3.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S5.T3.5.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.2.1\">Forget</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.5.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.3.1\">Retain</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.5.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.4.1\">Neigh.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.5.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.5.1\">Real Authors</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.5.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.6.1\">Real World</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.5.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.1.1.7.1\">Model Utility</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.5.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T3.5.2.2.1\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.1.1\" style=\"color:#808080;\">Base model</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T3.5.2.2.2\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.2.1\" style=\"color:#808080;\">0.997</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.5.2.2.3\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.3.1\" style=\"color:#808080;\">0.546</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.5.2.2.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.4.1\" style=\"color:#808080;\">0.820</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.5.2.2.5\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.5.1\" style=\"color:#808080;\">1.000</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.5.2.2.6\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.6.1\" style=\"color:#808080;\">0.872</em></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.5.2.2.7\"><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T3.5.2.2.7.1\" style=\"color:#808080;\">0.433</em></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.5.3.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T3.5.3.1.1\">Complete</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T3.5.3.1.2\">0.018</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.5.3.1.3\">0.381</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.5.3.1.4\">0.144</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.5.3.1.5\">0.669</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.5.3.1.6\">0.446</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.5.3.1.7\">0.182</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.5.4.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S5.T3.5.4.2.1\">Random</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S5.T3.5.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.4.2.2.1\">0.011</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.5.4.2.3\">0.411</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.5.4.2.4\">0.104</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.5.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.4.2.5.1\">0.724</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.5.4.2.6\">0.499</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.5.4.2.7\">0.211</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.5.5.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S5.T3.5.5.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T3.5.5.3.1.1\">UPCORE</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S5.T3.5.5.3.2\">0.017</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.5.5.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.5.3.3.1\">0.430</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.5.5.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.5.3.4.1\">0.190</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.5.5.3.5\">0.706</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.5.5.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.5.3.6.1\">0.528</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.5.5.3.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.5.5.3.7.1\">0.350</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: ROUGE scores and model utility across topics from the Counterfact dataset for a fixed epoch of Gradient Ascent.\nUPCORE consistently has higher performance on data outside the forget set, with the least degradation among methods and closest performance to the base model, while still having a high forget rate.", "description": "Table 3 presents a detailed comparison of ROUGE scores and model utility across different topics from the Counterfact dataset.  The experiment uses Gradient Ascent as the unlearning method, evaluating performance at a specific epoch. The table showcases UPCORE's superior balance in unlearning:  maintaining high forget rates while minimizing negative impact on data outside the target set (retain set, neighborhood data, etc.).  It highlights UPCORE's superior performance compared to using the complete forget set or a randomly selected subset, demonstrating both higher forget rates and better preservation of model utility on other data.", "section": "5. Experimental Results and Discussion"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.5.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.5.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.5.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.5.1.1.2.1\">Random</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.5.1.1.3\"><span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\" id=\"S5.T4.5.1.1.3.1\">UPCORE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.5.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.5.2.1.1\">Gradient Ascent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.5.2.1.2\">0.022</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.5.2.1.3\">0.053</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.5.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.5.3.2.1\">Refusal</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.5.3.2.2\">0.169</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.5.3.2.3\">0.127</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.5.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.5.4.3.1\">NPO</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.5.4.3.2\">0.206</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.5.4.3.3\">0.231</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: ROUGE score on pruned datapoints.\nBoth for UPCORE and random sampling, unlearning on a subset of datapoints translates to other datapoints not in the subset.", "description": "This table presents the ROUGE scores achieved on the pruned data points after applying unlearning.  It compares the results of UPCORE (which selectively prunes outliers from the forget set before unlearning) to a random subsampling method. The key observation is that even when unlearning is applied only to a subset of the forget data, the effect generalizes beyond that subset, influencing data points that were not directly unlearned. This demonstrates the presence of both positive and negative transfer: positive transfer is seen because unlearning a smaller subset (via pruning) still affects other data points within the same semantic group, while negative transfer is minimized through careful selection of the pruned points.", "section": "5.2 Positive and Negative Transfer"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T5.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T5.6.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.2.1\">Selection</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.3.1\">Retain</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.4.1\">Neigh</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.5.1\">Real World</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.6.1\">Real Authors</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.6.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.1.1.7.1\">Model Utility</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T5.6.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T5.6.2.1.1.1\">Jailbreak</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.3\">0.417</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.4\">0.474</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.5\">0.599</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.6\">0.743</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.2.1.7\">0.291</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.6.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.2\">0.430</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.3\">0.470</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.4\">0.629</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.5\">0.787</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.3.2.6\">0.305</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.6.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T5.6.4.3.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.4.3.2.1\">0.455</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.4.3.3.1\">0.512</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.4.3.4.1\">0.665</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.4.3.5.1\">0.819</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.4.3.6.1\">0.335</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.6.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S5.T5.6.5.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T5.6.5.4.1.1\">Rephrase</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.2\">Complete</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.3\">0.357</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.4\">0.431</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.5\">0.533</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.6\">0.655</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.6.5.4.7\">0.257</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.6.6.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.1\">Random</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.2\">0.361</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.3\">0.426</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.4\">0.536</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.5\">0.665</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.6.6.5.6\">0.262</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.6.7.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T5.6.7.6.1.1\">UPCORE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.7.6.2.1\">0.376</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.7.6.3.1\">0.449</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.7.6.4.1\">0.555</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.7.6.5.1\">0.673</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.6.7.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.6.7.6.6.1\">0.279</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 5: Evaluation metrics from Table\u00a01 averaged across topics in Counterfact, assessed for robustness to rephrased and jailbreak variants of the forget data with the same utility data.", "description": "This table presents the results of evaluating the robustness of the UPCORE method against rephrased and jailbroken versions of the forgotten data.  It shows the performance of three coreset selection methods (Complete, Random, and UPCORE) across various metrics, including ROUGE scores on different data sets (Retain, Neigh, Real World, Real Authors) and overall Model Utility.  The goal is to assess how well the methods maintain the balance between deletion efficacy and model preservation when faced with attempts to circumvent the unlearning process by reformulating or attacking the forgotten information.", "section": "5. Experimental Results and Discussion"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T6.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T6.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T6.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.4.1.1.1.1\">AUC</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T6.4.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.4.1.1.2.1\">Correlation with HSV</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T6.4.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T6.4.2.1.1\">Retain</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.4.2.1.2\">-0.421</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.4.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T6.4.3.2.1\">Neigh</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.4.3.2.2\">-0.507</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.4.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T6.4.4.3.1\">Real World</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.4.4.3.2\">-0.371</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.4.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T6.4.5.4.1\">Real Authors</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.4.5.4.2\">-0.489</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.4.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T6.4.6.5.1\">Model Utility</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T6.4.6.5.2\">-0.612</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 6: Correlation between the forget set representation variance and the AUC across topics. The negative correlation values are consistent with the negative correlation of model utility and variance shown in Section\u00a03.2.", "description": "This table presents the correlation coefficients between the variance of the hidden state representations of the forget set and the Area Under the Curve (AUC) values for various metrics.  The AUC values, calculated across different topics, measure the trade-off between deletion effectiveness (how well the model forgets the target information) and model utility (how well the model performs on unrelated tasks). A negative correlation indicates that as the variance of the forget set increases, the AUC decreases, suggesting a worse trade-off between forgetting and model utility. This finding aligns with the observations in Section 3.2, where a negative correlation between model utility and variance was also observed.", "section": "5. Experimental Results and Discussion"}]