[{"figure_path": "https://arxiv.org/html/2501.08828/x1.png", "caption": "Figure 1. MMDocIR comprises 313 lengthy documents across 10 different domains, along with 1,685 questions. For each question, page-level annotations are provided via selected screenshots. Red boundary boxes represent layout-level annotations.", "description": "This figure illustrates the MMDocIR dataset, which consists of 313 long documents covering 10 diverse domains.  Each document is paired with multiple questions (1685 in total).  The figure showcases examples of these documents, along with visual annotations for each question. For each question, the relevant page is identified with a screenshot.  Furthermore, red boxes highlight the specific layout elements (paragraphs, tables, figures, etc.) containing the answer within that page, demonstrating both page-level and layout-level annotations. This dual-level annotation allows for more fine-grained evaluation of multi-modal document retrieval systems.", "section": "3 MMDocIR: Evaluation Set"}, {"figure_path": "https://arxiv.org/html/2501.08828/x2.png", "caption": "Figure 2. Area ratio of different modalities (1) in overall and (2) by domains in MMLongBench-Doc benchmark\u00a0(Ma et\u00a0al., 2024b). Note that the white spaces, headers, and footers are removed from the area counting.", "description": "Figure 2 presents a detailed analysis of the area occupied by different modalities (text, images, tables, etc.) within documents from the MMLongBench-Doc benchmark. The figure provides a comparison of the overall distribution across all document types and a breakdown of the distribution for each of the seven different document domains included in the benchmark (research report, administration & industry, tutorial & workshop, academic paper, brochure, financial report, and guidebook).  White spaces, headers, and footers have been excluded from the area calculations to focus solely on content areas. This visualization helps to understand the relative importance of various data modalities in different document types and domains, highlighting the need for multi-modal retrieval systems that can effectively process diverse information forms.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.08828/x3.png", "caption": "(a) Avg word length", "description": "This figure shows a comparison of the average word length and word length distribution between OCR-extracted text and VLM-generated text for tables and images within the MMDocIR dataset.  The bar chart (a) presents the average word length for each modality (OCR-text for tables, OCR-text for images, VLM-text for tables, and VLM-text for images). The histogram (b) displays the distribution of word lengths across the different modalities, illustrating the frequency of different word lengths within each.", "section": "Analysis of OCR and VLM Text"}, {"figure_path": "https://arxiv.org/html/2501.08828/x4.png", "caption": "(b) Distribution density of word length", "description": "The figure shows the distribution of word lengths for OCR text and VLM text extracted from tables and images within the MMDocIR dataset.  The x-axis represents the word length, and the y-axis represents the distribution density. Two bar charts are displayed, one for OCR text and another for VLM text, enabling a comparison of word length distributions between the two methods of text extraction.", "section": "Analysis of OCR and VLM Text"}]