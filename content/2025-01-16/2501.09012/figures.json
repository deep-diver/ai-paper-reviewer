[{"figure_path": "https://arxiv.org/html/2501.09012/x1.png", "caption": "Figure 1: The MM-StyleBench dataset. (a) The distribution of different attributes in MM-StyleBench. the proposed dataset contains diverse images and text prompts with detailed attribute annotations. (b) Examples of content (top) and style (bottom) instances in MM-StyleBench.", "description": "Figure 1 presents the MM-StyleBench dataset, a new dataset for multimodal stylization created to evaluate the aesthetic reasoning abilities of multimodal large language models (MLLMs).  Part (a) shows the distribution of various attributes across the dataset, highlighting its diversity in terms of content (e.g., nature, architecture, urban scenes) and style prompts. The chart illustrates that MM-StyleBench includes detailed text and image annotations for each instance, demonstrating a high-quality dataset. Part (b) provides specific examples of content images (top row) and style prompts (bottom row) to showcase the range of styles and content categories included in MM-StyleBench.  These examples demonstrate the variation in content and style,  and underline the multimodal nature of the dataset.", "section": "III. MM-StyleBench"}, {"figure_path": "https://arxiv.org/html/2501.09012/x2.png", "caption": "Figure 2: Overview of our alignment evaluation pipeline. First, (a) we sample content and style from MM-StyleBench for stylization, and construct 2AFC comparison sets by sampling from all possible candidate comparisons. (b) Human preference data is collected and filtered with two heuristic indicators, which is finally aggregated as global rankings. (c) We propose ArtCoT, which involves three art-specific phases to reduce MLLMs\u2019 hallucinations. Finally, we calculate the correlation of rankings from MLLMs and humans as indicators of aesthetic alignment.", "description": "This figure illustrates the three-stage pipeline used to evaluate the aesthetic alignment between Multimodal Large Language Models (MLLMs) and human preferences.  First, content and style pairs are sampled from the MM-StyleBench dataset and passed to different stylization models.  Then, 2AFC (two-alternative forced choice) comparisons are created by sampling possible pairs of stylization results. Human preferences are collected via the 2AFC method and filtered using heuristics (to remove non-transitive or uncertain preference pairings) before being aggregated into global rankings for each MLLM. Finally, the proposed ArtCoT prompting method is applied to improve MLLM reasoning. The correlation between the MLLM rankings and the human rankings serves as the indicator of aesthetic alignment.", "section": "Alignment Evaluation Pipeline"}, {"figure_path": "https://arxiv.org/html/2501.09012/x3.png", "caption": "Figure 3: Fine-grained comparison of different MLLM prompting scheme. We show the spearman\u2019s \u03c1\ud835\udf0c\\rhoitalic_\u03c1 for per-instance alignment, grouped by representative attribute provided by MM-StyleBench. ArtCoT elicits aesthetic reasoning for all scenarios, especially for instances with long and detailed prompts.", "description": "This figure presents a fine-grained analysis of how different prompting methods for Multimodal Large Language Models (MLLMs) affect their ability to align with human aesthetic preferences.  Specifically, it shows the Spearman's correlation (\u03c1) between MLLM rankings and human rankings of image quality for various image attributes from the MM-StyleBench dataset.  The analysis is broken down by attribute to show how the performance varies depending on factors like content complexity (for example, using long and detailed vs short prompts) and style features. The figure demonstrates that the proposed ArtCoT prompting method consistently improves the alignment of MLLM rankings with human preferences, especially when more complex descriptions are used, highlighting its effectiveness in eliciting more accurate aesthetic reasoning from the models.", "section": "VI. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.09012/extracted/6127957/Fig/UI-min.png", "caption": "Figure 4: User Interface for Preference Annotation. We present user with the source image (top), 2AFC (middle) and style prompt (bottom). The user is required to choose the preferred one by clicking on the \u201cleft\u201d or \u201cright\u201d button.", "description": "This figure illustrates the user interface for collecting human preference data used in evaluating aesthetic alignment.  The interface presents users with three elements: 1) The original source image at the top, providing the visual content to be stylized. 2) Two stylized versions of the source image in the middle, side-by-side. These represent different stylization model outputs, and users must choose one as superior.  This is a two-alternative forced choice (2AFC) task. 3) The style prompt used to guide the stylization process at the bottom, contextualizing the stylization and informing user preference. Users indicate their preferred stylized image using left/right click buttons.", "section": "IV. MODELING HUMAN PREFERENCE"}, {"figure_path": "https://arxiv.org/html/2501.09012/x4.png", "caption": "Algorithm\u00a01 Sample a Connected Subgraph with Uniform Degree Distribution", "description": "This algorithm aims to sample a connected subgraph from a complete graph, ensuring a uniform distribution of node degrees.  It starts by creating a minimum spanning tree using Kruskal's algorithm to guarantee connectivity. Then, it iteratively adds edges to the subgraph, prioritizing those that minimize the degree imbalance between nodes.  This process continues until a desired number of edges are included, resulting in a subgraph where each node has a similar number of connections.", "section": "IV. MODELING HUMAN PREFERENCE"}, {"figure_path": "https://arxiv.org/html/2501.09012/x5.png", "caption": "Figure 5: Examples of Stylized Image. We show two uncurated examples from different stylization results, the image order are randomized. The styles are impressionist and cubism, respectively. The results covers a wide range of stylization performance, setting a realistic and challenging task for artistic evaluation.", "description": "This figure displays two sets of stylized images, each set illustrating the results of applying different stylization models to the same source image.  The styles used are Impressionism and Cubism. The image order within each set is randomized to avoid bias.  The figure highlights the wide variability in the quality and aesthetic appeal of results produced by different stylization techniques, demonstrating the challenges involved in automatically evaluating the aesthetic quality of such generated artworks. The diversity in outcomes showcases the need for more robust and nuanced evaluation metrics.", "section": "III. MM-StyleBench"}]