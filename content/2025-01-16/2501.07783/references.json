{"references": [{"fullname_first_author": "H. Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-MM-DD", "reason": "This paper introduces data-efficient training methods for image transformers, a crucial technique used in the PIIP network for efficient multi-scale feature extraction."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "This paper details the CLIP model, which is a foundational model for multimodal understanding and is used as a pre-trained component in PIIP-LLaVA."}, {"fullname_first_author": "Z. Chen", "paper_title": "Vision transformer adapter for dense predictions", "publication_date": "2023-MM-DD", "reason": "This paper presents a method of using ViT-Adapter to insert multi-scale information, an approach compared against in the PIIP architecture."}, {"fullname_first_author": "Z. Liu", "paper_title": "A Convnet for the 2020s", "publication_date": "2022-MM-DD", "reason": "This paper introduces the ConvNeXt model, an architecture used in the PIIP network for efficient feature extraction, particularly in heterogeneous configurations."}, {"fullname_first_author": "K. He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-MM-DD", "reason": "This paper introduces the MAE model, a powerful pre-training method used in the PIIP architecture for enhancing feature extraction capabilities."}]}