{"importance": "This survey is **crucial for MLLM researchers**, offering a needed overview of alignment algorithms. It facilitates organization of advancements, inspires methods, and directs future research. By addressing challenges and identifying opportunities, it shapes effective MLLM alignment strategy.", "summary": "A survey on multimodal LLM alignment techniques, covering applications, datasets, evaluation, and future directions.", "takeaways": ["MLLM alignment addresses hallucinations, safety, and human preference.", "Data quality and diversity are key for effective MLLM alignment.", "Future MLLM alignment requires comprehensive evaluation and full-modality integration."], "tldr": "Large language models (LLMs) excel in many tasks, but Multimodal Large Language Models (MLLMs) still need better alignment regarding truthfulness and safety. Various alignment algorithms are emerging to address these gaps, targeting different applications and goals. However, the rapid development poses challenges for researchers, especially in benchmarking and optimizing alignment data. This paper aims to offer a systematic review of MLLM alignment algorithms.\n\nThis paper explores four key aspects of MLLM alignment: application scenarios, alignment dataset construction, benchmarks for evaluation, and future development directions. It categorizes alignment algorithms by application, details the factors in creating alignment datasets (data sources, model responses, and annotations), organizes benchmarks, and suggests future research. The paper aims to help researchers understand current progress and inspire new alignment methods, providing comprehensive guide for academia and industry.", "affiliation": "Institute of automation, Chinese academy of science", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2503.14504/podcast.wav"}