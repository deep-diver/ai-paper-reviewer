[{"figure_path": "https://arxiv.org/html/2503.14504/x1.png", "caption": "Figure 1:  A timeline of MLLM alignment algorithms.", "description": "This figure presents a timeline summarizing the development of Multimodal Large Language Model (MLLM) alignment algorithms.  It visually depicts the chronological order of key algorithms and their emergence, highlighting the rapid advancements in this area of research. The timeline helps researchers to understand the evolution of the field and identify key milestones.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2503.14504/x2.png", "caption": "Figure 2: Categories of MLLM alignment, including application scenarios, alignment datasets, and evaluation benchmarks.", "description": "This figure provides a comprehensive overview of Multimodal Large Language Model (MLLM) alignment. It's categorized into three tiers based on application scenarios: general image understanding, multi-image, video, and audio; and extended multimodal applications.  Each tier shows a breakdown of the different alignment algorithms, dataset construction methods (using external or self-annotation knowledge), and the corresponding evaluation benchmarks (hallucination, safety, conversation, reward model alignment). The figure aims to provide a visual framework for researchers to understand existing alignment algorithms and their key distinctions.", "section": "3 APPLICATION SCENARIOS"}]