{"importance": "This paper introduces a novel approach to infinite anime life simulation, offering researchers a new framework for interactive storytelling and character interaction. **It bridges the gap between static anime content and dynamic, playable experiences, opening new avenues for AI-driven game development** and personalized entertainment.", "summary": "AnimeGamer: Play infinite anime lives with language! Predictable game states, dynamic animations & character updates.", "takeaways": ["AnimeGamer enables continuous interaction in anime worlds through language, generating dynamic game states.", "Action-aware multimodal representations effectively capture animation details for high-quality video generation.", "The framework ensures contextual consistency and satisfactory dynamics in infinite anime life simulations."], "tldr": "Recent advancements in generative models have paved the way for transforming anime characters into interactive entities. However, current approaches, like Unbounded, fall short by neglecting historical visual context and generating static images, leading to inconsistent gameplay and a lack of dynamic interactions. These limitations hinder the creation of truly immersive and engaging infinite anime life simulations.\n\nTo address these issues, this work introduces AnimeGamer, a novel framework that leverages Multimodal Large Language Models (MLLMs) to generate dynamic game states, including animation shots and character state updates. By introducing action-aware multimodal representations and incorporating historical context, AnimeGamer ensures contextual consistency and satisfactory dynamics. The framework includes a data collection pipeline from anime, allowing training on customized data. This approach outperforms existing methods.", "affiliation": "Tencent PCG", "categories": {"main_category": "AI Applications", "sub_category": "Gaming"}, "podcast_path": "2504.01014/podcast.wav"}