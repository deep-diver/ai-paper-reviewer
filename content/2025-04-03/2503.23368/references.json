{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022", "reason": "This paper introduces chain-of-thought prompting, which the current paper adapts into its VLM to significantly enhance its reasoning capabilities."}, {"fullname_first_author": "Tianhe Ren", "paper_title": "Grounded SAM: Assembling open-world models for diverse visual tasks", "publication_date": "2024", "reason": "The paper presents a method that is used in this paper to detect and segment objects, facilitating a better understanding of the scene and subsequent physical reasoning."}, {"fullname_first_author": "Daniel Geng", "paper_title": "Motion Guidance: Diffusion-Based Image Editing With Differentiable Motion Estimators", "publication_date": "2024", "reason": "This paper presents methods to guide video diffusion using motion, and informs the generation process in the current submission."}, {"fullname_first_author": "Hritik Bansal", "paper_title": "Videophy: Evaluating physical commonsense for video generation", "publication_date": "2024", "reason": "This paper introduces PhyGenBench dataset that is used in the paper to compare physically plausible generation."}, {"fullname_first_author": "Ryan Burgert", "paper_title": "Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise", "publication_date": "2025", "reason": "This paper proposes a video generation model that is adopted by the current paper to generate videos based on inferred coarse motion."}]}