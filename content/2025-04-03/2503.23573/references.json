{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper appears multiple times in the related works and experiments sections and may represent a core method upon which the current work builds."}, {"fullname_first_author": "Tsung-Yi Lin", "paper_title": "Microsoft coco: Common objects in context", "publication_date": "2014-01-01", "reason": "MSCOCO is used as a baseline dataset and as a source for assessing limitations in existing benchmarks and may also be the dataset on which the authors compared their results."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP is the central technology that the authors used to optimize the text and image queries, this paper may describe the process that CLIP takes."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "Laion-5b: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-01-01", "reason": "LAION-5B is identified as an open large-scale dataset the DASH-OPT and DASH-LLM use, and is frequently cited in the evaluation and experiments sections."}, {"fullname_first_author": "Yifan Li", "paper_title": "Evaluating object hallucination in large vision-language models", "publication_date": "2023-01-01", "reason": "This paper provides a benchmark known as POPE, used in several different sections throughout the DASH paper."}]}