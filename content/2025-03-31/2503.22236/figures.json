[{"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/method_overview.png", "caption": "Figure 1: Overview of the proposed normal-bridged 3D geometry generation method. Our Hi3DGen comprises three components: an image-to-normal estimator, a normal-to-geometry generator, and a synthesized dataset (DetailVerse) construction pipeline.", "description": "This figure provides a high-level overview of the Hi3DGen framework, which is a novel method for generating high-fidelity 3D geometry from images using normal maps as an intermediate representation. The framework consists of three main components:  1) An image-to-normal estimator (NiRNE) which takes an image as input and produces a normal map. This process is important for reducing the ambiguity in the RGB image. 2) A normal-to-geometry generator (NoRLD) that takes the normal map as input and produces a 3D mesh.  3) A data synthesis pipeline that creates the DetailVerse dataset, which contains high-quality synthetic 3D assets to support the training of the framework. The figure visually depicts the flow of information from input image to final 3D model output, highlighting the role of the normal map as a bridge between the image and 3D geometry.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/method_i2n_new.png", "caption": "Figure 2: Left part: Illustration of Noise-injected Regressive Normal Estimation; Right part: Noisy label at high-frequency regions in real-domain data.", "description": "This figure illustrates the proposed Noise-injected Regressive Normal Estimation method. The left part shows the architecture, which injects noise into the regressive network to enhance its sensitivity to high-frequency patterns and improve normal map sharpness.  The right part highlights the noisy labels at high-frequency regions (such as edges and corners) commonly found in real-world image data. This noise injection helps the network learn to accurately estimate normals in these challenging areas, leading to improved sharpness and detail in the generated normal maps.", "section": "3.1. Noise-Injected Regressive Normal Estimation"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/method_n2g.png", "caption": "Figure 3: An illustration of Normal-Regularized Latent Diffusion.", "description": "This figure illustrates the process of Normal-Regularized Latent Diffusion used in the Hi3DGen framework.  It shows how a Variational Autoencoder (VAE) encodes a 3D input geometry into a latent representation. This latent representation then undergoes a diffusion process, where noise is added and subsequently removed to refine the geometry. Crucially, normal maps (representing surface orientation) are used to regularize the latent diffusion process, ensuring that the generated 3D geometry accurately reflects the surface details and fidelity of the input normal map. The figure highlights the interaction between the VAE, the diffusion process, normal map information, and the final 3D output.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/detailverse.png", "caption": "Figure 4: The procedure of DetailVerse Construction.", "description": "The figure illustrates the pipeline used to create the DetailVerse dataset.  It starts with a text prompt database and a high-quality image database. These are used to generate initial 3D assets.  A classification step filters these assets, and further steps standardize and validate poses, leading to the final high-quality 3D assets in the DetailVerse dataset.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/result_i2n.png", "caption": "Figure 5: Normal estimation results comparison.", "description": "This figure compares the performance of different normal estimation methods, including regression-based methods (Lotus and GenPercept), diffusion-based methods (GeoWizard and StableNormal), and the proposed method (Hi3DGen). The comparison is based on the angular error and sharp normal error. The results show that Hi3DGen outperforms existing methods in terms of both overall accuracy and sharpness of normal estimation.", "section": "4.2. Image-to-Normal Estimation"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/ablation_i2n2g.png", "caption": "Figure 6: Ablations on the importance of normal bridging.", "description": "This ablation study investigates the effect of using normal maps as an intermediate representation in 3D geometry generation.  It compares the results of a direct image-to-3D generation method (Trellis) against Hi3DGen, highlighting the improvements in detail and fidelity achieved by incorporating normal bridging.  The figure demonstrates that Hi3DGen, which leverages normal maps, outperforms the direct approach, especially in capturing fine-grained details.  The comparison also shows the impact of using different normal map estimation methods (diffusion-based and regression-based) on the final 3D model quality.", "section": "4.4. Ablation Study"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/more_results.png", "caption": "Figure 7: High-fidelity 3D results generated by our Hi3DGen.", "description": "This figure showcases several high-fidelity 3D models generated by the Hi3DGen model.  The models demonstrate the ability of the system to accurately reconstruct detailed and complex 3D shapes from 2D images, highlighting the fine-grained geometric features that are often lost in existing techniques.", "section": "4.3 Normal-to-Geometry Generation"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/chart.png", "caption": "Figure 8: User study results.", "description": "This figure presents the results of a user study comparing the 3D model generation quality of Hi3DGen against five other methods: Hunyuan3D-2.0, Dora, Clay, Tripo-2.5, and Trellis.  Two groups of participants evaluated the generated models: 50 amateur 3D users and 10 professional 3D artists.  The evaluations focused on overall quality for various applications and professional use cases, respectively.  The results show that Hi3DGen significantly outperforms the other methods in terms of user preference for both amateur and professional users.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/Qualitative_results_3d_gen.png", "caption": "Figure 9: Qualitative 3D generation comparison on samples from Dora\u2019s project page\u00a0[54].", "description": "Figure 9 presents a qualitative comparison of 3D model generation results from different methods, using example images sourced from Dora's project page [54]. It visually demonstrates the relative strengths and weaknesses of each approach in terms of generating high-fidelity 3D models with fine-grained details that accurately reflect the input 2D images.  The figure showcases how well each method captures fine details, surface smoothness, and overall shape accuracy.", "section": "4.3 Normal-to-Geometry Generation"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/ablation_n2g.png", "caption": "Figure 10: Ablation on the proposed NoRLD.", "description": "This ablation study visualizes the impact of the proposed normal-regularized latent diffusion (NoRLD) on the 3D geometry generation.  By comparing the results with and without NoRLD, the figure demonstrates the effectiveness of NoRLD in enhancing the generation of fine-grained details in 3D models. The results showcase that NoRLD leads to significantly improved detail preservation and fidelity compared to the model trained without this component.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/ablation_i2n.png", "caption": "Figure S11: Ablations on image-to-normal estimation.", "description": "This ablation study visualizes the effects of different components of the proposed Noise-Injected Regressive Normal Estimation (NiRNE) method on the accuracy of normal map generation.  It compares the performance of the full NiRNE model against versions where key components such as the DetailVerse dataset, the dual-stream architecture, the noise injection technique, and the domain-specific training strategy, are removed. The results are presented as a qualitative comparison of normal maps generated using each model variant alongside the ground truth normal map. This allows for a visual assessment of how each component contributes to the overall accuracy and sharpness of the estimated normal maps.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/unipsk4.jpg", "caption": "Figure S12: Qualitative comparison of image-to-normal estimation with SOTA Photometric Stereo-based Method, SDM-UniPS.", "description": "This figure presents a qualitative comparison of the image-to-normal estimation performance between the proposed NiRNE method and the state-of-the-art (SOTA) photometric stereo method, SDM-UniPS.  It visually demonstrates the accuracy and detail preservation capabilities of each method by showing the estimated normal maps alongside the ground truth normal maps. Different scenarios are included to show the generalizability of the proposed method.", "section": "More Results"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/dataset_show.png", "caption": "Figure S13: More DetailVerse data exhibition.", "description": "Figure S13 showcases a diverse range of 3D models from the DetailVerse dataset.  These models demonstrate the dataset's ability to generate assets with complex geometries, rich surface details, and a variety of shapes and styles. The high visual fidelity of these models underscores the effectiveness of the dataset in supporting high-fidelity 3D geometry generation.", "section": "3.3 DetailVerse Dataset"}, {"figure_path": "https://arxiv.org/html/2503.22236/extracted/6317474/images/Supp_3d_gen.png", "caption": "Figure S14: More 3D generation results comparison.", "description": "Figure S14 presents a qualitative comparison of 3D model generation results from various state-of-the-art (SOTA) methods and Hi3DGen.  For several input images, the generated 3D models from Hi3DGen and other techniques (CraftsMan-1.5, Hunyuan3D-2.0, Clay, Tripo-2.5, Trellis, and Dora) are displayed side-by-side, enabling a visual assessment of the fidelity, detail preservation, and overall quality of each method's output. This comparison highlights Hi3DGen's ability to generate richer, more detailed 3D models that more closely match the input images.", "section": "9. More Results"}]