[{"figure_path": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/userstudy/initial.jpg", "caption": "Figure 1: 3D orientaion-grounded text-to-image generation results of Origen. We present Origen, the first zero-shot method for 3D orientation grounding in text-to-image generation across multiple objects and diverse categories. Origen generates high-quality images that are accurately aligned with the grounding orientation conditions, indicated by the colored arrows, and the input text prompts.", "description": "This figure showcases the results of ORIGEN, a novel zero-shot method for 3D orientation grounding in text-to-image generation.  It demonstrates ORIGEN's ability to generate high-quality images of multiple objects from diverse categories, accurately aligning the objects' orientations with user-specified conditions.  The colored arrows in the images visually represent these specified orientations, highlighting the precision of ORIGEN's control over 3D object placement.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/userstudy/problem.jpg", "caption": "Figure 2: Toy experiment results. The top row shows latent space samples (red), while the bottom row shows the corresponding data space samples (blue). From left to right, each column represents: (1) the ground truth target distribution from Eq.\u00a0(2); (2) results of ReNO\u00a0[16]; (3) results of ours with uniform time scaling; and (4) results of ours with reward-adaptive time rescaling.", "description": "This figure displays a comparison of different methods for sampling latent vectors in a generative model, aiming to maximize a reward function while maintaining realism.  The top row visualizes the latent space samples (red points), and the bottom row shows the corresponding generated data samples (blue points) in the image space. The four columns illustrate: (1) the ground truth target distribution, representing the ideal outcome; (2) the results obtained using the ReNO [16] method; (3) the results from the proposed method with uniform time scaling; and (4) the results from the proposed method with reward-adaptive time rescaling. The figure demonstrates that the proposed method with reward-adaptive time rescaling most closely approximates the ideal target distribution.", "section": "3. ORIGEN"}, {"figure_path": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/gplot_small.jpg", "caption": "Figure 3: Qualitative comparisons on MS-COCO-Single benchmark (Sec.\u00a04.3). Compared to the existing orientation-to-image models\u00a0[11, 46], Origen generates the most realistic images, which also best align with the grounding conditions, indicated by the overlapped arrow in each image.", "description": "Figure 3 presents a qualitative comparison of image generation results on the MS-COCO-Single benchmark dataset.  Three methods are compared: Zero-1-to-3 [46], C3DW [11], and the proposed ORIGEN model. The figure shows that ORIGEN generates more realistic images that better align with the specified object orientations than the existing methods.  The specified object orientation is visually indicated by colored arrows overlaid on each generated image.", "section": "4.3. Results on MS-COCO-Single"}]