{"references": [{"fullname_first_author": "Ziqi Huang", "paper_title": "Vbench: Comprehensive benchmark suite for video generative models", "publication_date": "2024-06-16", "reason": "This paper introduces VBench, a comprehensive benchmark suite used to evaluate and compare video generative models, and Free4D uses several metrics from VBench for evaluation."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "This paper introduces 3D Gaussian Splatting, an efficient technique for real-time rendering of radiance fields and serves as the base upon which the Free4D framework operates, using the technology for scene representation and rendering."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: representing scenes as neural radiance fields for view synthesis", "publication_date": "2022-01-01", "reason": "This paper introduces Neural Radiance Fields (NeRF), an important technology in novel view synthesis and 3D scene representation; this serves as a fundamental inspiration for 4D representation, though Free4D uses gaussian splatting instead of NeRF."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces Latent Diffusion Models (LDMs), a computationally efficient method for high-resolution image synthesis; Free4D uses a LDM as its video generation engine, making it a key component of the framework."}, {"fullname_first_author": "Wangbo Yu", "paper_title": "Viewcrafter: Taming video diffusion models for high-fidelity novel view synthesis", "publication_date": "2024-01-01", "reason": "This paper presents ViewCrafter, which tackles the problem of novel view synthesis using diffusion models and Free4D relies heavily on the ViewCrafter model for generating spatially and temporally consistent multi-view videos."}]}