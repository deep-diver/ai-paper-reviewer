{"references": [{"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023-01-01", "reason": "It is a crucial 2D foundation model for segmentation, and the presented paper uses its features for 4D scene understanding."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "Nerf is the original work of the radiance fields and is used as a foundation to represent 3D scenes."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "It is the seminal work for 3D Gaussian Splatting which forms the basis for the 4D dynamic scene representation in the presented paper."}, {"fullname_first_author": "Jiahui Lei", "paper_title": "Mosca: Dynamic gaussian fusion from casual videos via 4d motion scaffolds", "publication_date": "2024-05-17", "reason": "The presented paper builds on top of MoSca and so leverages its 4D reconstruction of dynamic scenes from monocular videos."}, {"fullname_first_author": "Yi Wang", "paper_title": "Internvideo2: Scaling foundation models for multimodal video understanding", "publication_date": "2024-01-01", "reason": "The presented paper builds on top of InternVideo and so leverages its video foundation model for VQA."}]}