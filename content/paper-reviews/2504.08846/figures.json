[{"figure_path": "https://arxiv.org/html/2504.08846/x1.png", "caption": "Figure 1: Overview of the AI-University framework. Sections marked with a dashed line are performed once, at the beginning.", "description": "This figure presents a high-level overview of the AI-University framework's architecture, illustrating the flow of information and the steps involved in answering user queries.  The process starts with a user query which is processed using an expert model (a fine-tuned LLM) and then passed to a synthesis model which then uses Retrieval Augmented Generation (RAG) to integrate relevant information from the course materials (lecture transcripts, textbook, and notes) before generating a comprehensive response.  The dashed lines highlight steps in the process that are performed only once at the beginning of the system's setup.", "section": "3 Methods"}, {"figure_path": "https://arxiv.org/html/2504.08846/x2.png", "caption": "Figure 2: Overview of the data generation framework. Sections marked with a dashed line are performed once, at the beginning.", "description": "This figure details the data generation pipeline used to create the training data for the AI model. It starts by dividing course materials (textbook, lecture notes, etc.) into smaller text chunks. These chunks are then embedded into a vector space using an embedding model.  A similarity search retrieves relevant context for each question.  Finally, an LLM generates question-answer pairs using the selected context and a prompt.  The dashed lines indicate steps that are performed only once at the beginning of the process, such as the initial embedding of the course material.", "section": "3 Methods"}, {"figure_path": "https://arxiv.org/html/2504.08846/extracted/6329323/Images/demo1.png", "caption": "Figure 3: Demonstration of the web application, available at https://my-ai-university.com", "description": "This figure shows a screenshot of the AI-University web application's interface.  The application allows users to query a course on the Finite Element Method (FEM), with the option to use different LLMs for response generation.  Users can specify parameters like the number of context tokens retrieved and the specific LLM to be used, and view relevant video lecture segments. The screenshot displays a sample query about assumptions related to matrices in the semidiscrete heat equation, along with the AI-generated response which references specific timestamped sections of the relevant course video.", "section": "3.6 Web application"}]