{"references": [{"fullname_first_author": "Jonathan T. Barron", "paper_title": "Shape, Illumination, and Reflectance from Shading", "publication_date": "2020-10-06", "reason": "This work provides a strong foundation for learning-based inverse rendering methods, demonstrating the feasibility of estimating shape, illumination, and reflectance from a single image using a data-driven approach."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis", "publication_date": "2020-08-24", "reason": "NeRF introduced a novel approach to representing scenes as continuous functions, enabling high-quality view synthesis and serving as a basis for various downstream tasks, including inverse rendering."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2021-12-20", "reason": "This work introduces the latent diffusion model, which effectively models high-resolution images by performing diffusion in the compressed latent space, improving both efficiency and quality of image generation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-06-09", "reason": "This work introduces denoising diffusion probabilistic models (DDPMs), providing a powerful generative framework based on iterative denoising, widely adopted in various applications, including intrinsic decomposition."}, {"fullname_first_author": "Jon Hasselgren", "paper_title": "Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising", "publication_date": "2022-06-07", "reason": "This work provides a principled optimization framework for reconstructing shape, materials, and lighting from multi-view images based on differentiable rendering, offering a baseline for optimization-based methods."}]}