[{"figure_path": "https://arxiv.org/html/2412.14835/x1.png", "caption": "Figure 1: The statistics of our hybrid-modal retrieval corpus.", "description": "This figure presents a breakdown of the composition of the hybrid-modal retrieval corpus used in the study.  The corpus is comprised of both multimodal and text-only data sources.  The multimodal section details the number of samples and percentage from each of several datasets, highlighting the variety of mathematical sub-fields represented.  The text-only section shows the size and percentage contribution from general reasoning knowledge bases (e.g., Wikipedia).  This visual representation gives the reader a clear overview of the data sources and their relative proportions in building the hybrid-modal retrieval corpus, which forms the basis for the models' reasoning capabilities.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.14835/x2.png", "caption": "Figure 2: The pipeline of our unified multimodal retrieval module.", "description": "This figure illustrates the process of the unified multimodal retrieval module used in the AR-MCTS framework.  The module takes as input a multimodal query (text and image). It then uses two separate retrieval methods: a text-to-text retriever to search a text-only corpus and a cross-modal retriever that searches a hybrid-modal corpus (combining text and image data). The top-K results from both retrievers are combined, and a knowledge concept filtering step is applied to select the most relevant insights (top-K knowledge) to the original query based on the query's knowledge concept. This filtered set of key insights is then passed on for use in the next step of the AR-MCTS process.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.14835/x3.png", "caption": "Figure 3: The overall framework of AR-MCTS: The retrieval module actively retrieves key insights at each step of the MCTS process. Then, the states of the MCTS is enhanced with different insights to expand the possible action space of the MLLM. Notably, one state of each step, such as state S1,3superscript\ud835\udc4613S^{1,3}italic_S start_POSTSUPERSCRIPT 1 , 3 end_POSTSUPERSCRIPT and S2,3superscript\ud835\udc4623S^{2,3}italic_S start_POSTSUPERSCRIPT 2 , 3 end_POSTSUPERSCRIPT in this figure, no insights are provided, and the state is a direct output of the MLLM.", "description": "The figure illustrates the AR-MCTS framework, a method for enhancing multimodal large language model (MLLM) reasoning.  AR-MCTS uses active retrieval to fetch relevant information at each step of the Monte Carlo Tree Search (MCTS) process, enriching the MCTS states and expanding the MLLM's possible actions.  Importantly, the diagram highlights that not every state in MCTS requires retrieved insights; some states are generated directly from the MLLM's internal knowledge.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.14835/x5.png", "caption": "Figure 4: Scaling analysis on inference samplings. Random Choice denotes the average result of randomly sampling from 1 to 32.", "description": "This figure presents a scaling analysis of different reasoning strategies, comparing their performance across varying numbers of sampled solutions (from 1 to 32).  The x-axis represents the number of samples considered during the reasoning process. The y-axis displays the accuracy of the chosen solution.  The results demonstrate how the accuracy of various methods (including AR-MCTS, Self-Consistency, and ORM) changes as the number of solution samples increases.  A random sampling baseline is also included to provide a reference for comparison.  The analysis is performed on two different benchmarks: MATHVISTA (ALL) and WE-MATH (S3).", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.14835/x7.png", "caption": "Figure 5: The visualization of the cadidate reasoning paths.", "description": "This figure visualizes the candidate reasoning paths generated by different methods: random choice, self-consistency, ORM, and AR-MCTS.  Each point represents a reasoning path, and the proximity of points indicates similarity between the paths. The plots for MATHVISTA (ALL) and We-Math (S1) show the diversity and clustering of reasoning paths generated by each method. AR-MCTS demonstrates better diversity in path sampling compared to other methods.", "section": "5.4 Quantitative Analysis"}]