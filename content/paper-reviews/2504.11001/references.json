{"references": [{"fullname_first_author": "Fan", "paper_title": "A survey on rag meeting llms: Towards retrieval-augmented large language models", "publication_date": "2024-01-01", "reason": "This paper is a survey paper on Retrieval-Augmented Generation, a crucial topic as it provides background and context for understanding ReZero's place in the field."}, {"fullname_first_author": "Jiang", "paper_title": "Deepretrieval: Hacking real search engines and retrievers with large language models via reinforcement learning", "publication_date": "2025-03-01", "reason": "This paper represents a related work that uses reinforcement learning to optimize query generation for retrieval, highlighting a contrasting approach to ReZero."}, {"fullname_first_author": "Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-01-01", "reason": "This paper introduces Reinforcement Learning from Human Feedback which is an imporant cornerstone for aligning LLMs with human preferences, which is the method that ReZero builds upon."}, {"fullname_first_author": "Sun", "paper_title": "Rearter: Retrieval-augmented reasoning with trustworthy process rewarding", "publication_date": "2025-01-01", "reason": "This paper is an important reference because it represents existing work on improving reasoning in RAG systems, a problem that ReZero also aims to address, albeit with a different approach."}, {"fullname_first_author": "Trivedi", "paper_title": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions", "publication_date": "2023-01-01", "reason": "This paper is significant as it presents multi-step RAG, which is important since it is the base that ReZero builds on."}]}