[{"figure_path": "https://arxiv.org/html/2412.09611/x2.png", "caption": "Figure 1: FluxSpace. We propose a text-guided image editing approach on rectified flow transformers [14], such as Flux. Our method can generalize to semantic edits on different domains such as humans, animals, cars, and extends to even more complex scenes such as an image of a street (third row, first example). FluxSpace can apply edits described as keywords (e.g. \u201ctruck\u201d for transforming a car into a truck) and offers disentangled editing capabilities that do not require manually provided masks to target a specific aspect in the original image. In addition, our method does not require any training and can apply the desired edit during inference time.", "description": "FluxSpace edits images based on text prompts without needing extra training or masks.  It works across various subjects (people, animals, cars) and complex scenes (like streets). It allows disentangled edits, meaning edits are applied to only the intended areas without affecting other parts of the image. For example, changing a car to a truck is done by using the keyword \"truck\".", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.09611/x3.png", "caption": "Figure 2: FluxSpace Framework. The FluxSpace framework introduces a dual-level editing scheme within the joint transformer blocks of Flux, enabling coarse and fine-grained visual editing. Coarse editing operates on pooled representations of base (cp\u2062o\u2062o\u2062lsubscript\ud835\udc50\ud835\udc5d\ud835\udc5c\ud835\udc5c\ud835\udc59c_{pool}italic_c start_POSTSUBSCRIPT italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT) and edit (ce,p\u2062o\u2062o\u2062lsubscript\ud835\udc50\ud835\udc52\ud835\udc5d\ud835\udc5c\ud835\udc5c\ud835\udc59c_{e,pool}italic_c start_POSTSUBSCRIPT italic_e , italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT) conditions, allowing global changes like stylization, controlled by the scale \u03bbc\u2062o\u2062a\u2062r\u2062s\u2062esubscript\ud835\udf06\ud835\udc50\ud835\udc5c\ud835\udc4e\ud835\udc5f\ud835\udc60\ud835\udc52\\lambda_{coarse}italic_\u03bb start_POSTSUBSCRIPT italic_c italic_o italic_a italic_r italic_s italic_e end_POSTSUBSCRIPT (a). For fine-grained editing, we define a linear editing scheme using base, prior, and edit attention outputs, guided by scale \u03bbf\u2062i\u2062n\u2062esubscript\ud835\udf06\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc52\\lambda_{fine}italic_\u03bb start_POSTSUBSCRIPT italic_f italic_i italic_n italic_e end_POSTSUBSCRIPT (b). With this flexible design, our framework is both able to perform coarse-level and fine-grained editing, with a linearly adjustable scale.", "description": "FluxSpace enables image editing in two ways: coarse and fine-grained.  Coarse editing adjusts overall image appearance (like stylization) through pooled representations. Fine-grained editing allows for precise attribute changes using attention outputs.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.09611/x4.png", "caption": "Figure 3: Qualitative Results on Face Editing. Our method can perform a variety of edits from fine-grained face editing (e.g. adding eyeglasses) to changes over the overall structure of the image (e.g. comics style). As our method utilizes disentangled representations to perform image editing, we can precisely edit a variety of attributes while preserving the properties of the original image.", "description": "This figure showcases FluxSpace's capabilities in performing a variety of edits on facial images. Examples of fine-grained edits include adding eyeglasses, sunglasses, and beards.  It also demonstrates broader transformations like age and gender alteration, and stylistic changes such as applying comic or 3D cartoon effects. Importantly, the edits are disentangled, meaning they affect the desired attribute without altering other unrelated features, thereby preserving the original identity and characteristics of the face.", "section": "5.2. Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2412.09611/x5.png", "caption": "Figure 4: Qualitative Comparisons. We compare our method both with latent diffusion-based approaches (LEDITS++ [6] and TurboEdit [11]) and flow-based methods (Sliders-FLUX [16] and RF-Inversion [37]) in terms of their disentangled editing capabilities. We present qualitative results for smile, eyeglasses, and age edits where our method succeeds over competing methods in both reflecting the semantic and preserving the input identity.", "description": "Qualitative comparison of image editing results with different methods. The figure shows a portrait of a man and compares how different editing techniques apply modifications like adding a smile, eyeglasses, or changing age.  The methods compared are divided into latent diffusion-based (LEDITS++, TurboEdit) and flow-based (Sliders-FLUX, RF-Inversion). The comparison focuses on how well each method can disentangle the desired edit (e.g., adding glasses) from other facial features, while preserving the original identity of the person. The comparison suggests that the proposed method offers better results in preserving identity and applying the edits cleanly.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09611/x6.png", "caption": "Figure 5: Real Image Editing. By integrating FluxSpace on the inversion approach proposed by RF-Inversion [37], we extend our method for real image editing task. As we show qualitatively, our method achieves improved disentanglement over the performed edits compared to the baseline approach, where we use identical hyperparameters for the inversion task on both approaches.", "description": "This figure showcases FluxSpace's ability to edit real images by integrating it with the inversion mechanism of RF-Inversion. The top row displays the original input images, while the subsequent rows present edits for age and gender. The results highlight FluxSpace's improved disentanglement compared to the baseline RF-Inversion, as it effectively applies the desired edits while better preserving the original identity and overall image structure, using identical inversion hyperparameters.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09611/extracted/6065524/figs/user_study_setup.png", "caption": "Figure 6: Ablation Study. We present ablations over the hyperparameters introduced within the FluxSpace framework. Specifically, we perform ablations on coarse editing scale \u03bbc\u2062o\u2062a\u2062r\u2062s\u2062esubscript\ud835\udf06\ud835\udc50\ud835\udc5c\ud835\udc4e\ud835\udc5f\ud835\udc60\ud835\udc52\\lambda_{coarse}italic_\u03bb start_POSTSUBSCRIPT italic_c italic_o italic_a italic_r italic_s italic_e end_POSTSUBSCRIPT, fine-grained editing scale \u03bbf\u2062i\u2062n\u2062esubscript\ud835\udf06\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc52\\lambda_{fine}italic_\u03bb start_POSTSUBSCRIPT italic_f italic_i italic_n italic_e end_POSTSUBSCRIPT, masking coefficient \u03c4msubscript\ud835\udf0f\ud835\udc5a\\tau_{m}italic_\u03c4 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT and timestep t\ud835\udc61titalic_t when the editing is initiated. For all ablations, we report qualitative results for changing values of the specified hyperparameters.", "description": "This figure presents a series of ablation studies showcasing the impact of different hyperparameters within the FluxSpace framework on image editing results.  Specifically, it examines how varying the coarse editing scale (\u03bbc\u2062o\u2062a\u2062r\u2062s\u2062e), fine-grained editing scale (\u03bbf\u2062i\u2062n\u2062e), masking coefficient (\u03c4m), and the timestep (t) at which editing begins influences the final edited image. Each row in the figure corresponds to a different hyperparameter being ablated, with each column showing the visual result of a different parameter value. This allows for a direct visual comparison of how each parameter contributes to the overall editing process and its effect on disentanglement and semantic accuracy.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09611/x7.png", "caption": "Figure 7: User Study Setup. We conduct our user study on unedited-edited image pairs. For each editing method, we provide the original image where the edit is not applied, with the edited image, and ask the users to rate the edit from a scale of 1-to-5. On the Likert scale that the users are asked to provide their preference on, 1 corresponds to unsatisfactory editing and 5 corresponds to a satisfactory edit.", "description": "This figure shows an example of a user study setup for evaluating the quality of image edits.  Participants are shown the original image alongside the edited version. They're asked to rate the edit on a Likert scale from 1 to 5, where 1 represents \"strongly disagree\" (unsatisfactory editing) and 5 represents \"strongly agree\" (satisfactory editing). The provided example focuses on evaluating a \"Smiling\" edit, assessing how well the edited image reflects the smiling expression while retaining the person's original facial characteristics (hair, beard, clothing). This methodology helps evaluate both the effectiveness of the edit and the preservation of the subject's identity.", "section": "Supplementary Material"}, {"figure_path": "https://arxiv.org/html/2412.09611/x8.png", "caption": "Figure 8: Additional Qualitative Comparisons. In addition to comparisons provided in the main paper, we provide additional comparisons with Prompt2Prompt [18] (with Null-Text Inversion [27]) and PnP-Diffusion [39], as Stable Diffusion based editing methods. As we demonstrate qualitatively, FluxSpace both achieves disentangled and semantically correct edits where competing methods contain artifacts in edited results (see the edit \u201cEyeglasses\u201d for both methods), and significantly alter the subject identity (see \u201cAge\u201d edit).", "description": "This figure provides additional qualitative comparisons of FluxSpace with other editing methods, specifically Prompt2Prompt (with Null-Text Inversion) and PnP-Diffusion, which are based on Stable Diffusion. The comparisons highlight FluxSpace's superior performance in achieving disentangled and semantically correct edits, while competing methods exhibit artifacts in edited results (e.g., \"Eyeglasses\" edit) and significantly alter the subject's identity (e.g., \"Age\" edit).  FluxSpace maintains better fidelity to the original image while effectively applying the desired edits.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09611/x9.png", "caption": "Figure 9: Gender Editing Results. We provide additional editing results for editing the gender semantics. As shown in the examples, our method succeeds in both male-to-female and female-to-male translations. We provide editing results on both portrait images, where our edits preserve the facial details, and edits on complex scenes where we succeed in only editing the human subject. Both in terms of preserving the identity of the subject and the background details, FluxSpace succeeds in the disentanglement editing task.", "description": "This figure showcases additional results for gender editing, demonstrating FluxSpace's success in both male-to-female and female-to-male transformations. Results are presented for both portrait images (preserving facial details) and complex scenes (editing only the human subject), highlighting the method's ability to maintain subject identity and background details while disentangling the editing task.", "section": "Supplementary Material"}, {"figure_path": "https://arxiv.org/html/2412.09611/x10.png", "caption": "Figure 10: Sunglasses Editing Results. We provide additional qualitative results for the edit \u201cadding sunglasses\u201d. As we demonstrate on human subjects in both portrait images and more complex scenes, our editing method can accurately target where the edit should be applied without any input mask. We show the editing capabilities of FluxSpace both in images where the human subject is the main focus of the image (first two rows) and with human subjects as a part of a scene (last two rows). In both cases, our method succeeds in performing the desired edit and preserving the edit-irrelevant details.", "description": "This figure presents additional qualitative results demonstrating FluxSpace's ability to add sunglasses to images of people in both portrait and complex scenes.  It highlights the method's accurate targeting of the edit without needing an input mask. The first two rows show edits on portrait photos where the person is the primary subject, and the last two rows display edits on scenes with more complex backgrounds, further demonstrating that the method preserves background details while still applying the sunglasses to the human subjects.", "section": "Supplementary Material"}, {"figure_path": "https://arxiv.org/html/2412.09611/x11.png", "caption": "Figure 11: Conceptual Editing Results. We provide editing results with abstract concepts, that affect the overall appearance of the image. Our method succeeds in performing edits that alter the content of the image (top row) by being able to interpret the structures in the unedited image (e.g. the trees on the back for the edit \u201ccherry blossom\u201d) and can change the style and overall appearance of the image (bottom row).", "description": "This figure showcases FluxSpace's ability to perform conceptual edits by altering the overall appearance of an image using abstract prompts like \"fall\", \"snow\", \"sunny\", \"cherry blossom\", \"comics style\", \"happy\", \"anime style\", and \"cinematic lighting\". The top row demonstrates content changes by correctly interpreting unedited image structures, as exemplified by the \"cherry blossom\" edit, which accurately adds cherry blossoms to the existing trees. The bottom row shows the method's capacity to alter image style and overall appearance through different artistic or lighting effects.", "section": "5. Experiments"}]