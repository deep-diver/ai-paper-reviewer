[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"id6.4\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"id3.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"id3.1.1.1\"><span class=\"ltx_text\" id=\"id3.1.1.1.1\" style=\"position:relative; bottom:-1.5pt;\"><img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"15\" id=\"id3.1.1.1.1.g1\" src=\"extracted/6124330/assets/webpage_logo.png\" width=\"15\"/></span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id3.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"id3.1.1.2.1\">LlamaV-o1\u00a0 Project:</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id3.1.1.3\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://mbzuai-oryx.github.io/LlamaV-o1/\" style=\"font-size:90%;\" title=\"\">https://mbzuai-oryx.github.io/LlamaV-o1/</a></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"id4.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"id4.2.2.1\"><span class=\"ltx_text\" id=\"id4.2.2.1.1\" style=\"position:relative; bottom:-1.5pt;\"><img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"20\" id=\"id4.2.2.1.1.g1\" src=\"x2.png\" width=\"22\"/></span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id4.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"id4.2.2.2.1\">LlamaV-o1\u00a0 Model:</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id4.2.2.3\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/omkarthawakar/LlamaV-o1\" style=\"font-size:90%;\" title=\"\">https://huggingface.co/omkarthawakar/LlamaV-o1</a></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"id5.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"id5.3.3.1\"><span class=\"ltx_text\" id=\"id5.3.3.1.1\" style=\"position:relative; bottom:-1.5pt;\"><img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"20\" id=\"id5.3.3.1.1.g1\" src=\"x3.png\" width=\"20\"/></span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id5.3.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"id5.3.3.2.1\">LlamaV-o1\u00a0 Code:</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id5.3.3.3\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/mbzuai-oryx/LlamaV-o1\" style=\"font-size:90%;\" title=\"\">https://github.com/mbzuai-oryx/LlamaV-o1</a></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"id6.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"id6.4.4.1\"><span class=\"ltx_text\" id=\"id6.4.4.1.1\" style=\"position:relative; bottom:-1.5pt;\"><img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"20\" id=\"id6.4.4.1.1.g1\" src=\"x2.png\" width=\"22\"/></span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id6.4.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"id6.4.4.2.1\">VRC-Bench</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"id6.4.4.3\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/datasets/omkarthawakar/VRC-Bench\" style=\"font-size:90%;\" title=\"\"><span class=\"ltx_ref ltx_nolink\">https://huggingface.co/datasets/omkarthawakar/VRC-Bench</span></a></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: \nAn overview of comprehensive set of attributes considered in our evaluation to assess the quality of reasoning in LMMs. These attributes focus on critical aspects such as faithfulness, informativeness, and logical coherence of reasoning steps. Key measures include ensuring alignment of reasoning steps with the source (Faithfulness-Step and Token), completeness of information (Informativeness-Step), and identifying issues like hallucinations, redundancy, or missing steps. Additional metrics, such as Semantic Coverage and Reasoning Alignment, evaluate the logical and semantic integrity of the response. Together, these metrics provide a robust framework for evaluating the accuracy, completeness, and reliability of LLM-generated reasoning.", "description": "This table presents a comprehensive set of metrics used to evaluate the quality of reasoning in large multimodal language models (LMMs).  The metrics assess multiple aspects of the reasoning process, including faithfulness (how well the generated reasoning aligns with the source material at both the step and token levels), informativeness (completeness of extracted information), logical coherence (absence of hallucinations, redundancy, or missing steps), semantic integrity (semantic coverage and reasoning alignment), and overall accuracy. The table provides a framework for evaluating the accuracy, completeness, and reliability of LLM-generated reasoning, ensuring robust evaluation and identifying areas of potential improvement in the models' reasoning capabilities.", "section": "3 Step-by-Step Visual Reasoning Benchmark: VRC-Bench"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.4.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.1.1.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1.1.1.1\">Metric</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.4.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.1.1.2.1.1\" style=\"width:281.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.2.1.1.1\">Definition</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T1.4.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.2.1.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.2.1.1.1.1.1\">Faithfulness-Step</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T1.4.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.2.1.2.1.1\" style=\"width:281.9pt;\">Measures how well the reasoning steps in the LMM response align with the source reasoning steps.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.3.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.3.2.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.3.2.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.3.2.1.1.1.1\">Faithfulness-Token</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.3.2.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.3.2.2.1.1\" style=\"width:281.9pt;\">Extends Faithfulness-Step to token-level granularity, checking if the content within each step is accurate.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.4.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.4.3.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.4.3.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.4.3.1.1.1.1\">Informativeness-Step</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.4.3.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.4.3.2.1.1\" style=\"width:281.9pt;\">Measures how well the reasoning steps extract all relevant information from the context.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.5.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.5.4.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.5.4.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.5.4.1.1.1.1\">Repetition-Token</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.5.4.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.5.4.2.1.1\" style=\"width:281.9pt;\">Identifies repeated or unnecessarily paraphrased reasoning steps.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.6.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.6.5.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.6.5.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.6.5.1.1.1.1\">Hallucination</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.6.5.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.6.5.2.1.1\" style=\"width:281.9pt;\">Detects irrelevant or fabricated reasoning steps not aligned with the source.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.7.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.7.6.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.7.6.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.7.6.1.1.1.1\">Redundancy</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.7.6.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.7.6.2.1.1\" style=\"width:281.9pt;\">Identifies redundant reasoning steps that do not add value.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.8.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.8.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.8.7.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.8.7.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.8.7.1.1.1.1\">Semantic Coverage-Step</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.8.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.8.7.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.8.7.2.1.1\" style=\"width:281.9pt;\">Measures how well the response covers the essential semantic elements of the source reasoning steps.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.9.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.9.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.9.8.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.9.8.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.9.8.1.1.1.1\">Reasoning Alignment</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.9.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.9.8.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.9.8.2.1.1\" style=\"width:281.9pt;\">Overall alignment between the hypothesis and reference reasoning chain.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.10.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T1.4.10.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.10.9.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.10.9.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.10.9.1.1.1.1\">Commonsense</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.T1.4.10.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.10.9.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.10.9.2.1.1\" style=\"width:281.9pt;\">Checks for missing commonsense reasoning are required to solve the problem.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.11.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S3.T1.4.11.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.11.10.1.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.11.10.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S3.T1.4.11.10.1.1.1.1\">Missing Step</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S3.T1.4.11.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T1.4.11.10.2.1\">\n<span class=\"ltx_p\" id=\"S3.T1.4.11.10.2.1.1\" style=\"width:281.9pt;\">Identifies if any necessary reasoning steps are missing.</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: Comparison of models based on Final Answer accuracy and Reasoning Steps performance on the proposed VRC-Bench. The best results in each case (closed-source and open-source) are in bold. Our LlamaV-o1 achieves superior performance compared to its open-source counterpart (Llava-CoT) while also being competitive against the closed-source models.", "description": "This table presents a comprehensive comparison of various Large Language Models (LLMs) and Large Multimodal Models (LMMs) on the Visual Reasoning Chain benchmark (VRC-Bench).  The models are evaluated across two key metrics: Final Answer Accuracy and Reasoning Steps score.  Final Answer Accuracy reflects the percentage of questions answered correctly, indicating the overall performance of each model on the benchmark tasks. The Reasoning Steps score provides a measure of the quality and coherence of the reasoning steps employed by each model to arrive at their final answers.  The table highlights the performance of both closed-source models (like GPT-4, Gemini, and Claude) and open-source models (like LlamaV-01 and Llava-CoT), allowing for a direct comparison between different approaches to visual reasoning.  The best-performing models in each category are highlighted in bold, clearly indicating which models excel in both final answer accuracy and the quality of their reasoning process. The results showcase that the proposed LlamaV-01 model outperforms its open-source counterpart and demonstrates performance comparable to leading closed-source models.", "section": "5 Experiments"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T2.4.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\" id=\"S4.T2.4.1.1.1.2\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.4.1.1.1.2.1\">Close-Source</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\" id=\"S4.T2.4.1.1.1.3\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.4.1.1.1.3.1\">Open-Source</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.4.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.1.1\">Model</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.2.1\">GPT-4o</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.3.1\">Claude-3.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.4.1\">Gemini-2.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.5.1\">Gemini-1.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.6.1\">Gemini-1.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.4.1.2.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.7.1\">GPT-4o</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.8.1\">Llama-3.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.9.1\">Mulberry</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.10.1\">Llava-CoT</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.2.1.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.2.1.11.1\">LlamaV-o1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.3.2\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.4.1.3.2.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.2\">\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib2\" title=\"\">2</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.3.1\">Sonnet</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib1\" title=\"\">1</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.4.1\">Flash</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.5.1\">Pro</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib52\" title=\"\">52</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.6.1\">Flash</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib52\" title=\"\">52</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.4.1.3.2.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.7.1\">mini</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib48\" title=\"\">48</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.3.2.8.1\">Vision</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib47\" title=\"\">47</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.9\">\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib68\" title=\"\">68</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.10\">\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib66\" title=\"\">66</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.1.3.2.11\">(Ours)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.4.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.4.3.1.1\">Final Answer</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.2\">59.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.4.3.3.1\">61.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.4\">61.16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.4.3.5.1\">61.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.6\">54.99</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.4.1.4.3.7\">56.39</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.8\">48.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.9\">51.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.10\">54.09</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.1.4.3.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.4.3.11.1\">56.49</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T2.4.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.5.4.1.1\">Steps</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.5.4.2.1\">76.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.3\">72.12</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.4\">74.08</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.5\">72.12</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.6\">71.86</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T2.4.1.5.4.7\">74.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.8\">58.37</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.9\">63.86</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.10\">66.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.1.5.4.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.5.4.11.1\">68.93</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: Performance comparison on six benchmark datasets (MMStar\u00a0[9], MMBench\u00a0[35], MMVet\u00a0[71], MathVista\u00a0[39], AI2D\u00a0[29], and Hallusion\u00a0[21]) along with their average scores. The comparison includes both close-source and open-source models. The best performing close-source model is GPT-4o with an average score of 71.8%. Among open-source models, our proposed LlamaV-o1 achieves the best performance with an average score of 67.33% outperforming the recent Llava-CoT by 3.8%.", "description": "Table 3 presents a comparative analysis of various Large Language Models (LLMs) across six benchmark datasets: MMStar, MMBench, MMVet, MathVista, AI2D, and Hallusion.  The performance of both closed-source (proprietary) and open-source LLMs is evaluated, measuring their accuracy on diverse reasoning tasks within each benchmark. The table highlights GPT-4 as the top-performing closed-source model, achieving an average score of 71.8%.  The researchers' proposed LlamaV-01 model is shown to be the best-performing open-source model, surpassing the existing state-of-the-art Llava-CoT model by a margin of 3.8% with an average score of 67.3%. This showcases LlamaV-01's competitive performance in the field of open-source multimodal reasoning.", "section": "5 Experiments"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.4.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T3.4.1.1.1.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.1.1\" style=\"font-size:90%;\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.2.1\" style=\"font-size:90%;\">MMStar</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.3.1\" style=\"font-size:90%;\">MMBench</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.4.1\" style=\"font-size:90%;\">MMVet</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.5.1\" style=\"font-size:90%;\">MathVista</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.6.1\" style=\"font-size:90%;\">AI2D</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.7.1\" style=\"font-size:90%;\">Hallusion</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.4.1.1.1.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.1.1.8.1\" style=\"font-size:90%;\">Average</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"7\" id=\"S5.T3.4.1.2.2.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.2.2.1.1\" style=\"font-size:90%;\">Close-Source</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T3.4.1.2.2.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.3.3.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.1.1\" style=\"font-size:90%;\">GPT-4o-0806\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib2\" title=\"\">2</a><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.2.1\" style=\"font-size:90%;\">66.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.3.1\" style=\"font-size:90%;\">82.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.4.1\" style=\"font-size:90%;\">80.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.5.1\" style=\"font-size:90%;\">62.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.6.1\" style=\"font-size:90%;\">84.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.7.1\" style=\"font-size:90%;\">54.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.3.3.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.3.3.8.1\" style=\"font-size:90%;\">71.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.4.4.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.1.1\" style=\"font-size:90%;\">Claude3.5-Sonnet-0620\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib1\" title=\"\">1</a><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.2.1\" style=\"font-size:90%;\">64.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.3.1\" style=\"font-size:90%;\">75.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.4.1\" style=\"font-size:90%;\">68.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.5.1\" style=\"font-size:90%;\">61.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.6.1\" style=\"font-size:90%;\">80.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.7.1\" style=\"font-size:90%;\">49.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.4.4.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.4.4.8.1\" style=\"font-size:90%;\">66.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.5.5.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.1.1\" style=\"font-size:90%;\">Gemini-1.5-Pro\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib52\" title=\"\">52</a><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.2.1\" style=\"font-size:90%;\">56.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.3.1\" style=\"font-size:90%;\">71.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.4.1\" style=\"font-size:90%;\">71.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.5.1\" style=\"font-size:90%;\">57.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.6.1\" style=\"font-size:90%;\">79.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.7.1\" style=\"font-size:90%;\">45.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.5.5.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.5.5.8.1\" style=\"font-size:90%;\">63.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.6.6.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.1.1\" style=\"font-size:90%;\">GPT-4o-mini-0718\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib48\" title=\"\">48</a><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.2.1\" style=\"font-size:90%;\">54.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.3.1\" style=\"font-size:90%;\">76.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.4.1\" style=\"font-size:90%;\">74.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.5.1\" style=\"font-size:90%;\">52.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.6.1\" style=\"font-size:90%;\">77.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.7.1\" style=\"font-size:90%;\">46.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.6.6.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.6.6.8.1\" style=\"font-size:90%;\">63.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"7\" id=\"S5.T3.4.1.7.7.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.7.7.1.1\" style=\"font-size:90%;\">Open-Source</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T3.4.1.7.7.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.8.8.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.1.1\" style=\"font-size:90%;\">InternVL2-8B\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.2.1\" style=\"font-size:90%;\">62.50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.3.1\" style=\"font-size:90%;\">77.40</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.4.1\" style=\"font-size:90%;\">56.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.5.1\" style=\"font-size:90%;\">58.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.6.1\" style=\"font-size:90%;\">83.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.7.1\" style=\"font-size:90%;\">45.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.8.8.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.8.8.8.1\" style=\"font-size:90%;\">64.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.9.9.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.1.1\" style=\"font-size:90%;\">Ovis1.5-Gemma2-9B\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib41\" title=\"\">41</a><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.2.1\" style=\"font-size:90%;\">58.70</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.3.1\" style=\"font-size:90%;\">76.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.4.1\" style=\"font-size:90%;\">50.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.5.1\" style=\"font-size:90%;\">65.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.6.1\" style=\"font-size:90%;\">84.50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.7.1\" style=\"font-size:90%;\">48.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.9.9.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.9.9.8.1\" style=\"font-size:90%;\">64.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.10.10.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.1.1\" style=\"font-size:90%;\">MiniCPM-V2.6-8B\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib70\" title=\"\">70</a><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.2.1\" style=\"font-size:90%;\">57.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.3.1\" style=\"font-size:90%;\">75.70</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.4.1\" style=\"font-size:90%;\">56.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.5.1\" style=\"font-size:90%;\">60.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.6.1\" style=\"font-size:90%;\">82.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.7.1\" style=\"font-size:90%;\">48.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.10.10.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.10.10.8.1\" style=\"font-size:90%;\">63.30</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.11.11.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.1.1\" style=\"font-size:90%;\">Llama-3.2-90B-Vision-Inst\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib47\" title=\"\">47</a><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.2.1\" style=\"font-size:90%;\">51.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.3.1\" style=\"font-size:90%;\">76.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.4.1\" style=\"font-size:90%;\">74.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.5.1\" style=\"font-size:90%;\">58.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.6.1\" style=\"font-size:90%;\">69.50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.7.1\" style=\"font-size:90%;\">44.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.11.11.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.11.11.8.1\" style=\"font-size:90%;\">62.30</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.12.12.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.1.1\" style=\"font-size:90%;\">VILA-1.5-40B\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib36\" title=\"\">36</a><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.2.1\" style=\"font-size:90%;\">53.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.3.1\" style=\"font-size:90%;\">75.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.4.1\" style=\"font-size:90%;\">44.40</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.5.1\" style=\"font-size:90%;\">49.50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.6.1\" style=\"font-size:90%;\">77.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.7.1\" style=\"font-size:90%;\">40.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.12.12.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.12.12.8.1\" style=\"font-size:90%;\">56.90</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.13.13.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.1.1\" style=\"font-size:90%;\">Mulberry-7B\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib68\" title=\"\">68</a><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.2.1\" style=\"font-size:90%;\">61.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.3.1\" style=\"font-size:90%;\">75.34</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.4.1\" style=\"font-size:90%;\">43.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.5.1\" style=\"font-size:90%;\">57.49</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.6.1\" style=\"font-size:90%;\">78.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.7.1\" style=\"font-size:90%;\">54.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.13.13.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.13.13.8.1\" style=\"font-size:90%;\">62.78</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.14.14.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.1.1\" style=\"font-size:90%;\">Llava-CoT\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib66\" title=\"\">66</a><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.1.3.2\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.2.1\" style=\"font-size:90%;\">57.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.3.1\" style=\"font-size:90%;\">75.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.4.1\" style=\"font-size:90%;\">60.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.5.1\" style=\"font-size:90%;\">54.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.6.1\" style=\"font-size:90%;\">85.70</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.7.1\" style=\"font-size:90%;\">47.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.14.14.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.14.14.8.1\" style=\"font-size:90%;\">63.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"7\" id=\"S5.T3.4.1.15.15.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.15.15.1.1\" style=\"font-size:90%;\">Our Models</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T3.4.1.15.15.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.4.1.16.16.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.1.1\" style=\"font-size:90%;\">Llama-3.2-11B-Vision-Inst\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.1.2.1\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2501.06186v1#bib.bib47\" title=\"\">47</a><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.1.3.2\" style=\"font-size:90%;\">]</span></cite><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.1.4\" style=\"font-size:90%;\"> (baseline)</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.2.1\" style=\"font-size:90%;\">49.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.3.1\" style=\"font-size:90%;\">65.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.4.1\" style=\"font-size:90%;\">57.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.5.1\" style=\"font-size:90%;\">48.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.6.1\" style=\"font-size:90%;\">77.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.7.1\" style=\"font-size:90%;\">40.30</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.4.1.16.16.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.16.16.8.1\" style=\"font-size:90%;\">56.90</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.17.17\" style=\"background-color:#FFDFBF;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T3.4.1.17.17.1\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.4.1.17.17.1.1\" style=\"font-size:90%;background-color:#FFDFBF;\">LlamaV-o1 (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.2\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.2.1\" style=\"font-size:90%;background-color:#FFDFBF;\">59.53</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.3\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.3.1\" style=\"font-size:90%;background-color:#FFDFBF;\">79.89</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.4\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.4.1\" style=\"font-size:90%;background-color:#FFDFBF;\">65.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.5\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.5.1\" style=\"font-size:90%;background-color:#FFDFBF;\">54.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.6\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.6.1\" style=\"font-size:90%;background-color:#FFDFBF;\">81.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.7\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.7.1\" style=\"font-size:90%;background-color:#FFDFBF;\">63.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.4.1.17.17.8\" style=\"padding-left:7.0pt;padding-right:7.0pt;\"><span class=\"ltx_text\" id=\"S5.T3.4.1.17.17.8.1\" style=\"font-size:90%;background-color:#FFDFBF;\">67.33</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 4: \nImpact of our proposed contributions on multimodal reasoning tasks across six benchmarks: MMStar, MMBench, MMVet, MathVista, AI2D, and Hallusion. Starting with Curriculum Learning combined with Multi-Step CoT reasoning (2nd row), the model achieves a 9.14% absolute gain compared to base model Llama-3.2-11B-Vision-Inst\u00a0[47], demonstrating its ability to handle complex multi-step reasoning effectively. This baseline approach leverages structured training to improve performance across diverse tasks, including logical reasoning and visual understanding. By incorporating Beam Search, the model\u2019s performance further improves (3rd row). This enhancement is particularly noticeable in benchmarks such as MMVet (65.40% vs. 61.88%), MathVista (54.40% vs. 53.20%), and AI2D (81.24% vs. 80.18%), showcasing the model\u2019s ability to generalize better with more accurate reasoning.\nOur final approach that combines curriculum learning with optimized inference strategies achieves an overall average gain of 10.43%, compared to the baseline.", "description": "This table presents a detailed breakdown of how the LlamaV-01 model's performance improves across six benchmark datasets (MMStar, MMBench, MMVet, MathVista, AI2D, and Hallusion) as different components are added.  The baseline is the Llama-3.2-11B-Vision-Inst model.  The first improvement shown is from adding Curriculum Learning and Multi-Step Chain-of-Thought reasoning, resulting in a 9.14% performance increase.  A further improvement is seen when Beam Search is incorporated, leading to another performance boost, particularly noticeable on specific benchmarks like MMVet, MathVista, and AI2D. The final model combines all three components (Curriculum Learning, Multi-Step CoT, and Beam Search), yielding an overall improvement of 10.43% compared to the baseline.", "section": "4 Proposed Step-by-Step Visual Reasoning Model: LlamaV-01"}, {"content": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T4.4.1.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.1.1\" style=\"font-size:90%;\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.2.1\" style=\"font-size:90%;\">MMStar</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.3.1\" style=\"font-size:90%;\">MMBench</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.4.1\" style=\"font-size:90%;\">MMVet</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.5.1\" style=\"font-size:90%;\">MathVista</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.6.1\" style=\"font-size:90%;\">AI2D</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.7.1\" style=\"font-size:90%;\">Hallusion</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.4.1.1.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.4.1.1.1.8.1\" style=\"font-size:90%;\">Average</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.4.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.4.1.2.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.1.1\" style=\"font-size:90%;\">Llama-3.2-11B-Vision-Inst (</span><span class=\"ltx_text ltx_font_italic\" id=\"S5.T4.4.1.2.1.1.2\" style=\"font-size:90%;\">baseline</span><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.1.3\" style=\"font-size:90%;\">)</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.2.1\" style=\"font-size:90%;\">49.80</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.3.1\" style=\"font-size:90%;\">65.80</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.4.1\" style=\"font-size:90%;\">57.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.5.1\" style=\"font-size:90%;\">48.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.6.1\" style=\"font-size:90%;\">77.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.7.1\" style=\"font-size:90%;\">40.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.1.2.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.2.1.8.1\" style=\"font-size:90%;\">56.90</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.4.1.3.2\" style=\"background-color:#FFF2E6;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.4.1.3.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.1.1\" style=\"font-size:90%;background-color:#FFF2E6;\">+ Curriculum with Multi-Step CoT Reasoning</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.2.1\" style=\"font-size:90%;background-color:#FFF2E6;\">58.13</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.3.1\" style=\"font-size:90%;background-color:#FFF2E6;\">79.55</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.4.1\" style=\"font-size:90%;background-color:#FFF2E6;\">61.88</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.5.1\" style=\"font-size:90%;background-color:#FFF2E6;\">53.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.6.1\" style=\"font-size:90%;background-color:#FFF2E6;\">80.18</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.7.1\" style=\"font-size:90%;background-color:#FFF2E6;\">63.31</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.4.1.3.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.3.2.8.1\" style=\"font-size:90%;background-color:#FFF2E6;\">66.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.4.1.4.3\" style=\"background-color:#FFECD9;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T4.4.1.4.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.1.1\" style=\"font-size:90%;background-color:#FFECD9;\">+ Beam Search</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.2.1\" style=\"font-size:90%;background-color:#FFECD9;\">59.53</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.3.1\" style=\"font-size:90%;background-color:#FFECD9;\">79.89</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.4.1\" style=\"font-size:90%;background-color:#FFECD9;\">65.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.5.1\" style=\"font-size:90%;background-color:#FFECD9;\">54.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.6.1\" style=\"font-size:90%;background-color:#FFECD9;\">81.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.7.1\" style=\"font-size:90%;background-color:#FFECD9;\">63.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.4.1.4.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S5.T4.4.1.4.3.8.1\" style=\"font-size:90%;background-color:#FFECD9;\">67.33</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 5: \nComparison of inference scaling techniques on the MMVet benchmark, evaluated using a single NVIDIA A100 GPU.\nLeft: Llava-CoT with stage-level beam search shows improved MMVet scores with more beams but suffers from quadratic scaling, significantly increasing inference time.\nRight: Performance of our approach utilizing Beam Search achieving higher MMVet scores with much lower inference time, due to its linear scaling efficiency.\nFor instance, our method scores 65.40 with four beams in 6.1 GPU hours, compared to Llava-CoT\u2019s 62.9 score requiring 46.1 GPU hours. This demonstrates the efficiency and practicality of our approach for real-world applications.", "description": "This table compares two different inference scaling techniques on the MMVet benchmark using a single NVIDIA A100 GPU. The left side shows the performance of Llava-CoT, which uses a stage-level beam search.  It demonstrates that while increasing the number of beams improves the MMVet score, this comes at the cost of significantly increased inference time due to quadratic scaling. The right side presents the results for the authors' approach, which utilizes a standard beam search.  This approach shows higher MMVet scores with much lower inference time because of its linear scaling efficiency. A key example shows the authors' method achieving a score of 65.40 with four beams in 6.1 GPU hours, compared to Llava-CoT's score of 62.9, which took 46.1 GPU hours.  This highlights the efficiency and practicality of the authors' approach for real-world applications.", "section": "5. Experiments"}]