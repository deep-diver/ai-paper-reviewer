{"importance": "This work is important because it reduces the computational cost of MLLMs by identifying and freezing ineffective layers. This enhances efficiency without sacrificing performance, making it easier to deploy & scale MLLMs for real-world applications. It also opens avenues for future work in fine-grained layer analysis and token optimization.", "summary": "ShortV: Freezing visual tokens in ineffective MLLM layers dramatically cuts computational costs while maintaining performance.", "takeaways": ["Layer Contribution (LC) metric effectively quantifies layer importance in MLLMs.", "MLLMs have layer redundancy, particularly for visual tokens.", "ShortV leverages LC to improve MLLM efficiency without retraining."], "tldr": "Multimodal Large Language Models (MLLMs) face high costs due to their size and large visual tokens. The paper investigates layer-wise redundancy in MLLMs and introduces **Layer Contribution (LC)**, a metric quantifying a layer's transformations on tokens. Experiments reveal many MLLMs layers minimally contribute during visual token processing.\n\nMotivated, the paper proposes **ShortV**, a training-free method leveraging LC to identify ineffective layers and freezes visual token updates in these layers. Experiments reveal ShortV can freeze visual tokens in ~60% of MLLM layers, significantly reducing costs related to visual tokens. For example, it achieves a ~50% FLOPs reduction on LLaVA-NeXT-13B while keeping performance.", "affiliation": "Chinese Academy of Sciences", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2504.00502/podcast.wav"}