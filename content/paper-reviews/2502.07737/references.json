{"references": [{"fullname_first_author": "Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-MM-DD", "reason": "This paper introduced the Transformer architecture, a fundamental building block of many large language models and is directly relevant to the semi-autoregressive video generation approach used in this paper."}, {"fullname_first_author": "Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-05-14", "reason": "This paper demonstrated the effectiveness of large language models for few-shot learning, inspiring the application of similar approaches to video generation."}, {"fullname_first_author": "Yu", "paper_title": "Magvit: Masked generative video transformer", "publication_date": "2023-MM-DD", "reason": "The authors' video tokenizer, MAGVITv2, is a key component of their proposed method, and this paper details the original model."}, {"fullname_first_author": "Unterthiner", "paper_title": "Towards accurate generative models of video: A new metric & challenges", "publication_date": "2018-MM-DD", "reason": "This paper introduced the Fr\u00e9chet Video Distance (FVD) metric, a standard benchmark used to evaluate video generation quality, and is critical for assessing the performance of their method."}, {"fullname_first_author": "Yan", "paper_title": "Videogpt: Video generation using vq-vae and transformers", "publication_date": "2021-MM-DD", "reason": "This is a seminal work directly applying the autoregressive approach to video generation, providing a foundation for the present paper's semi-autoregressive technique."}]}