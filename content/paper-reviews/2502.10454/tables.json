[{"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.6.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" colspan=\"2\" id=\"S4.T1.6.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.1.1.1.1\">Models</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.1.1.2.1\">Judgement</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T1.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.1.1.3.1\">Rationale Reasoning</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.2.2.1.1\">F1 (macro)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.2.2.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.2.2.2.1\">Examples</span> (%)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.2.2.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.2.2.3.1\">Strict</span> (%)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.2.2.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.2.2.4.1\">Loose</span> (%)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"6\" id=\"S4.T1.6.3.3.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T1.6.3.3.1.1\">Open source models</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.4.4.1\" rowspan=\"12\"><span class=\"ltx_text\" id=\"S4.T1.6.4.4.1.1\">size = 7B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.4.4.2\">Deepseek-Math-7B-rl</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.4.4.3\">32.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.4.4.4\">65.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.4.4.5\">18.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.4.4.6\">20.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.5.5.1\">Eurus-2-7B-PRIME</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.5.5.2\">37.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.5.5.3\">64.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.5.5.4\">28.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.5.5.5\">32.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.6.6.1\">NuminaMath-7B-TIR</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.6.2\">30.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.6.3\">54.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.6.4\">13.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.6.5\">13.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.7.7.1\">InternLM2-Math-Plus-7B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.7.7.2\">33.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.7.7.3\">36.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.7.7.4\">9.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.7.7.5\">9.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.8.8.1\">Abel-7B-002</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.8.8.2\">34.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.8.8.3\">66.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.8.8.4\">16.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.8.8.5\">17.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.9.9.1\">WizardMath-7B-v1.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.9.9.2\">27.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.9.9.3\">43.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.9.9.4\">6.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.9.9.5\">7.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.10.10.1\">Mathstral-7B-v0.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.10.10.2\">28.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.10.10.3\">38.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.10.10.4\">7.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.10.10.5\">7.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.11.11.1\">MetaMath-Mistral-7B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.11.11.2\">31.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.11.11.3\">26.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.11.11.4\">0.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.11.11.5\">0.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.12.12.1\">Xwin-Math-7B-V1.0</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.12.12.2\">28.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.12.12.3\">31.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.12.12.4\">1.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.12.12.5\">1.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.13.13.1\">rho-math-7b-interpreter-v0.1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.13.13.2\">22.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.13.13.3\">18.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.13.13.4\">1.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.13.13.5\">2.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.14.14.1\">MAmmoTH2-7B-Plus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.14.14.2\">32.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.14.14.3\">54.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.14.14.4\">10.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.14.14.5\">12.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.15.15.1\">Qwen2.5-Math-7B-Instruct</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.15.15.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.15.15.2.1\">38.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.15.15.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.15.15.3.1\">74.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.15.15.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.15.15.4.1\">30.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.15.15.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.15.15.5.1\">33.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.16.16.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T1.6.16.16.1.1\">7B&lt;size &lt;70B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.16.16.2\">Abel-13B-001</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.16.16.3\">22.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.16.16.4\">24.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.16.16.5\">0.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.16.16.6\">0.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.17.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.17.17.1\">Xwin-Math-13B-V1.0</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.17.17.2\">30.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.17.17.3\">31.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.17.17.4\">1.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.17.17.5\">1.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.18.18.1\">InternLM2-Math-Plus-20B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.18.18.2\">18.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.18.18.3\">28.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.18.18.4\">8.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.18.18.5\">9.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.19.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.19.19.1\">MAmmoTH2-8x7B-Plus</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.19.19.2\">28.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.19.19.3\">51.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.19.19.4\">14.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.19.19.5\">15.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.20.20.1\">QwQ-32B-Preview</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.20.20.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.20.20.2.1\">39.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.20.20.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.20.20.3.1\">70.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.20.20.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.20.20.4.1\">38.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.20.20.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.20.20.5.1\">43.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.21.21.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T1.6.21.21.1.1\">size &gt;=70B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.6.21.21.2\">InternLM2-Math-Plus-Mixtral8x22B</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.21.21.3\">37.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.21.21.4\">63.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.21.21.5\">21.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.21.21.6\">23.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.22.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.22.22.1\">Xwin-Math-70B-V1.0</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.22.22.2\">25.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.22.22.3\">25.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.22.22.4\">1.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.22.22.5\">1.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.23.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.23.23.1\">Abel-70B-001</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.23.23.2\">31.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.23.23.3\">48.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.23.23.4\">5.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.23.23.5\">6.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.24.24.1\">WizardMath-70B-v1.0</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.24.24.2\">24.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.24.24.3\">52.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.24.24.4\">6.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.24.24.5\">7.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.25.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.6.25.25.1\">Qwen2.5-Math-72B-Instruct</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.25.25.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.25.25.2.1\">41.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.25.25.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.25.25.3.1\">76.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.25.25.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.25.25.4.1\">38.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.25.25.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.25.25.5.1\">41.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.26.26\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"6\" id=\"S4.T1.6.26.26.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T1.6.26.26.1.1\">Commercial models</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.27.27\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T1.6.27.27.1\">GPT-4o</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.27.27.2\">59.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.27.27.3\">44.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.27.27.4\">19.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.27.27.5\">21.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.28.28\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" colspan=\"2\" id=\"S4.T1.6.28.28.1\">OpenAI o1-preview</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.28.28.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.28.28.2.1\">60.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.28.28.3\">55.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.28.28.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.28.28.4.1\">39.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.28.28.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.28.28.5.1\">40.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.29.29\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" colspan=\"2\" id=\"S4.T1.6.29.29.1\">Qwen-max</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.6.29.29.2\">58.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.6.29.29.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.6.29.29.3.1\">61.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.6.29.29.4\">30.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.6.29.29.5\">33.9</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 1: Main evaluation results of various mainstream mathematical LLMs with the default CoT prompts on CounterMATH. The Examples, Strict, and Loose represent the three of our designed example-related evaluation metrics.", "description": "This table presents the performance of various mainstream Large Language Models (LLMs) on the CounterMATH benchmark.  The LLMs were evaluated using the default chain-of-thought (CoT) prompting strategy.  The results are broken down by three example-related metrics: Examples (percentage of problem-solving cases where the model used examples), Strict Align (percentage of the model's examples that perfectly matched the reference examples), and Loose Align (percentage of instances where at least one of the model's examples aligned with the reference examples).  The table provides a comparison of LLM performance on a university-level mathematical reasoning task focused on counterexamples.", "section": "4. Benchmark Settings"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T2.5\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T2.5.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S6.T2.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.1.1.1.1\">Models</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S6.T2.5.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.1.1.2.1\">F1 (macro)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S6.T2.5.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.1.1.3.1\">Examples(%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S6.T2.5.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.1.1.4.1\">Strict(%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S6.T2.5.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.1.1.5.1\">Loose(%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"5\" id=\"S6.T2.5.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S6.T2.5.2.2.1.1\">Base models</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T2.5.3.3.1\">Qwen2.5-Math-7B-Instruct</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T2.5.3.3.2\">38.3</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.3.3.3\">74.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.3.3.4\">30.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.3.3.5\">33.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S6.T2.5.4.4.1\">Qwen2.5-Math-7B-Instruct + Hint prompt</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S6.T2.5.4.4.2\">39.4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.5.4.4.3\">79.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.5.4.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.4.4.4.1\">33.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.5.4.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.4.4.5.1\">36.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"5\" id=\"S6.T2.5.5.5.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S6.T2.5.5.5.1.1\">Our training model</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T2.5.6.6.1\">Qwen2.5-Math-7B-Instruct-SFT</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T2.5.6.6.2\">39.7</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.6.6.3\">75.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.6.6.4\">31.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.5.6.6.5\">34.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.5.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S6.T2.5.7.7.1\">Qwen2.5-Math-7B-Instruct-SFT + Hint prompt</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S6.T2.5.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.7.7.2.1\">41.1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T2.5.7.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.5.7.7.3.1\">79.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T2.5.7.7.4\">31.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T2.5.7.7.5\">34.7</td>\n</tr>\n</tbody>\n</table>", "caption": "Table 2: The evaluation results on our CounterMATH.", "description": "This table presents the performance evaluation results of the fine-tuned Qwen-2.5-Math-7B-Instruct model and its base model on the COUNTERMATH benchmark.  It shows the F1 score (macro average), and the proportions of problem-solving instances where examples were used (Examples), and where these examples aligned strictly or loosely with reference examples (Strict and Loose, respectively). Results are shown for both models with and without additional \"hint\" prompts.", "section": "6. Evaluation Results"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.T3.4.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S6.T3.4.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.4.1.1.1.1.1\">Models</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S6.T3.4.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.4.1.1.1.2.1\">GSM8K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S6.T3.4.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.4.1.1.1.3.1\">MATH</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S6.T3.4.1.2.2.1\">GPT-4o-2024-08-06</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T3.4.1.2.2.2\">92.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T3.4.1.2.2.3\">81.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S6.T3.4.1.3.3.1\">Qwen2.5-math-7B-Instruct</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.4.1.3.3.2\">95.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.4.1.3.3.3\">80.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S6.T3.4.1.4.4.1\">Qwen2.5-math-72B-Instruct</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.4.1.4.4.2\">95.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.4.1.4.4.3\">84.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S6.T3.4.1.5.5.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.T3.4.1.5.5.1.1\">\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.5.5.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.T3.4.1.5.5.1.1.1.1\">Qwen2.5-math-7B-Instruct</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.5.5.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.T3.4.1.5.5.1.1.2.1\">+Countermath-SFT</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T3.4.1.5.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.4.1.5.5.2.1\">95.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T3.4.1.5.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.4.1.5.5.3.1\">87.9</span></td>\n</tr>\n</tbody>\n</table>", "caption": "Table 3: The Out-of-distribution Evaluation Results.", "description": "This table presents the results of evaluating the fine-tuned model's performance on out-of-distribution (OOD) benchmark datasets, MATH and GSM8K.  It demonstrates the model's ability to generalize its counterexample-driven reasoning skills learned from COUNTERMATH to unseen datasets, showcasing its robustness and transferability.", "section": "6. Evaluation Results"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.T3.4.1.5.5.1.1\">\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.5.5.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.T3.4.1.5.5.1.1.1.1\">Qwen2.5-math-7B-Instruct</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.4.1.5.5.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.T3.4.1.5.5.1.1.2.1\">+Countermath-SFT</td>\n</tr>\n</table>", "caption": "Table 4: Summary of open-weight baseline models. CP stands for Continue Pretrain. SFT stands for Supervised Fine-Tuning. GRPO refers to a variant of PPO, which replaces the value network with the group average (Shao et\u00a0al., 2024). PoT (Chen et\u00a0al., 2023) and TIR (Gou et\u00a0al., 2024) stand for Program-of-Thought and Tool-Integrated Reasoning, respectively. PRIME stands for using ORM as PRM by DPO-like rewards (Cui et\u00a0al., 2025). SLM stands for Selective Language Modeling (Lin et\u00a0al., 2024b). \u2217 only stands for the same model architecture.", "description": "Table 4 provides a comprehensive overview of various open-source large language models (LLMs) used as baselines in the study.  It details the model name, its scale (number of parameters), the underlying base model architecture it's built upon, the training data employed, and the primary training paradigms utilized.  The table clarifies abbreviations used in the paper such as CP (Continue Pretrain), SFT (Supervised Fine-Tuning), GRPO (a variant of Proximal Policy Optimization that uses group averaging), PoT (Program-of-Thought), TIR (Tool-Integrated Reasoning), PRIME (using an objective reward model with DPO-like rewards), and SLM (Selective Language Modeling).  The asterisk (*) indicates that models with the same architecture are grouped.", "section": "4. Benchmark Settings"}]