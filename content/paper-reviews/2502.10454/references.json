{"references": [{"fullname_first_author": "Amini, A.", "paper_title": "MathQA: Towards interpretable math word problem solving with operation-based formalisms", "publication_date": "2019-05-01", "reason": "This paper introduces a benchmark dataset, MathQA, that is foundational for evaluating the ability of LLMs to solve mathematical word problems, a key aspect in this study."}, {"fullname_first_author": "Cobbe, K.", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper introduces GSM8K, a widely used benchmark dataset in the field of mathematical reasoning for LLMs, providing a strong baseline for comparison in this research."}, {"fullname_first_author": "Hendrycks, D.", "paper_title": "Measuring mathematical problem solving with the MATH dataset", "publication_date": "2021-12-01", "reason": "This paper presents MATH, another widely cited benchmark dataset which is frequently used for evaluating LLM capabilities in solving mathematical problems, making it a crucial reference for comparative analysis."}, {"fullname_first_author": "Luo, H.", "paper_title": "WizardMath: Empowering mathematical reasoning for large language models via reinforced evol-instruct", "publication_date": "2023-08-01", "reason": "This paper introduces WizardMath, a significant work that explores using reinforcement learning and specific prompts to improve mathematical reasoning abilities in LLMs, influencing the present work's methodology."}, {"fullname_first_author": "Shao, Z.", "paper_title": "DeepSeekMath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-01", "reason": "This paper explores the use of reinforcement learning and introduces DeepSeekMath, a benchmark dataset contributing to the understanding of LLMs' reasoning capabilities, offering valuable insights used in the current research."}]}