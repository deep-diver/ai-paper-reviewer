[{"figure_path": "https://arxiv.org/html/2502.17055/x1.png", "caption": "Figure 1: Performance of 4-bit LLM training. Experiments are conducted with LLaMA-130M/350M/1B models on C4 Dataset. Adam-BF16 denotes that the model is trained with BF16 by Adam. Perplexity on validation set is reported.", "description": "This figure displays the perplexity results of training 4-bit large language models (LLMs) using different optimizers.  The experiments were conducted on three sizes of the LLaMA model (130M, 350M, and 1B parameters) using the C4 dataset.  For comparison, results for training the same models with Adam using BF16 precision (16-bit) are also shown. Lower perplexity indicates better performance. The x-axis represents the number of training steps, and the y-axis shows perplexity.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.17055/x2.png", "caption": "Figure 2: Final validation loss when training LLaMA-130M on C4, sweeping across learning rates (LR). The vertical dotted line indicates that the model cannot be trained further as increasing the learning rate, i.e. Training loss becomes NaN. Red dashed horizontal lines indicate the best performance achieved.", "description": "This figure displays the final validation loss achieved when training a LLaMA-130M language model on the C4 dataset using different learning rates. Each curve represents a different optimizer (Adam, Adafactor, Adam-mini, and SPAM).  The x-axis shows the learning rate used, and the y-axis shows the final validation loss. The vertical dotted lines indicate points where a learning rate caused the training loss to become NaN (Not a Number), signifying that the model training failed to converge and could not continue with that specific hyperparameter. The red horizontal dashed lines highlight the lowest validation loss obtained by each optimizer during the experiment, representing the best performance attainable under various learning rates.", "section": "4-bit Training Stability Investigation"}, {"figure_path": "https://arxiv.org/html/2502.17055/x3.png", "caption": "Figure 3: Effect of SpikeClip\u00a0(Huang et\u00a0al., 2025) on stabilizing training. Left: gradient norms before and after performing gradient spike clip. Right: training loss with and without gradient spike clip. Models are trained by Adam optimizer based on LLaMA-130M and C4.", "description": "This figure demonstrates the impact of SpikeClip, a technique from the SPAM optimizer, on stabilizing the training process of a 4-bit LLM. The left panel displays gradient norms before and after applying SpikeClip, revealing its effectiveness in mitigating the abrupt increases or spikes in the gradients. The right panel shows the training loss curves with and without SpikeClip, further showcasing the stabilization effect, leading to a smoother training process.", "section": "2. 4-bit Training Stability Investigation"}, {"figure_path": "https://arxiv.org/html/2502.17055/x4.png", "caption": "Figure 4: Training loss and gradient norm of Adam using various learning rates with BF16 and FP4 precision. Experiments are conducted under the same training configuration with LLaMA-130M/350M.", "description": "This figure displays the training loss and gradient norm of the Adam optimizer under different learning rates, using both BF16 (16-bit floating-point) and FP4 (4-bit floating-point) precision. The experiments were performed using the LLaMA-130M and LLaMA-350M language models, maintaining consistent training configurations across all experiments. This visualization helps understand the impact of different precision levels and learning rates on the stability and performance of training large language models.", "section": "4-bit Training Stability Investigation"}, {"figure_path": "https://arxiv.org/html/2502.17055/x5.png", "caption": "Figure 5: StableSPAM under Extremely Low-Precision Training. Experiments are conducted with 350M models on C4 Dataset. BF16-Adam denotes that the model is trained with BF16 by Adam. The final loss on validation set is reported.", "description": "This figure compares the performance of Stable-SPAM against Adam under extremely low-precision training settings (INT2, INT3, INT4).  The experiments were conducted using 350M parameter LLaMA models trained on the C4 dataset.  The chart shows the final validation loss achieved by each optimizer under various bit-width configurations.  It demonstrates Stable-SPAM's ability to maintain competitive performance, even surpassing the performance of Adam trained with BF16 (higher precision) in the INT3 setting. This highlights the robustness of Stable-SPAM in handling extremely low-precision training scenarios.", "section": "4.2. Performance of Extremely Low-Precision Training"}, {"figure_path": "https://arxiv.org/html/2502.17055/x6.png", "caption": "Figure 6: Performance of BF16 training with various model sizes. Experiments are based on LLaMA models trained on C4 Dataset.", "description": "This figure displays the performance of training large language models (LLMs) using the BF16 (Brain Floating Point 16-bit) precision format.  It compares the performance of different LLaMA model sizes (60M, 130M, 350M, and 1B parameters) trained on the C4 dataset. The x-axis represents the number of update steps during training, and the y-axis shows the perplexity, a measure of how well the model predicts the next word in a sequence.  The different colored lines represent different optimizers used, allowing for a comparison of their effectiveness across various model sizes in the context of BF16 training.", "section": "4.3. Performence of BF16 LLM Training"}, {"figure_path": "https://arxiv.org/html/2502.17055/x7.png", "caption": "Figure 7: Effect of AdaGN and AdaClip on stabilizing FP4 LLM training. The left two figures use LLaMA-130M (LR = 3e-3), and the right two figures use LLaMA-60M.", "description": "This figure shows the effects of AdaGN and AdaClip on the stability of 4-bit LLM training using the FP4 precision.  The left two subfigures display the training loss and gradient norm for a LLaMA-130M model trained with a learning rate of 3e-3, comparing Adam alone, Adam with AdaGN, Adam with both AdaGN and AdaClip, and Stable-SPAM. The right two subfigures show the final evaluation loss for LLaMA-60M trained using various learning rates (1e-3, 3e-3, and 5e-3) with four different training methods:  Adam, Adam + AdaGN, Adam + AdaGN + AdaClip and Stable-SPAM.  It demonstrates how AdaGN and AdaClip work together to stabilize the training process, reducing loss spikes and gradient norm explosions.", "section": "4.5. Effect on Stabilizing Training"}, {"figure_path": "https://arxiv.org/html/2502.17055/x8.png", "caption": "Figure 8:  Hyper-parameter Analysis. Experiments are conducted with FP4 training on LLaMA-60M and C4 with 1.1B tokens.", "description": "This figure shows the results of a hyperparameter analysis for Stable-SPAM optimizer.  The experiments were performed using 4-bit (FP4) precision training on the LLaMA-60M model with the C4 dataset (1.1B tokens). The x-axis of each subplot represents different values for one of the four hyperparameters (\u03b31, \u03b32, \u03b33, \u0394T), while the y-axis shows the resulting perplexity. This analysis aims to find the optimal values for these hyperparameters to achieve the best performance and stability in 4-bit training.", "section": "4.7. Hyper-Parameter Analysis"}, {"figure_path": "https://arxiv.org/html/2502.17055/x9.png", "caption": "Figure 9: Test Loss during Training Process on Weather Time-series Data. Anomalous data is generated by adding Gaussian noise to 10% of randomly selected input values. Specifically, the anomalies data are conducted with X=X+Gaussin\u2062(0,Severity\u2217Max\u2062(X))\ud835\udc4b\ud835\udc4bGaussin0SeverityMax\ud835\udc4bX=X+\\texttt{Gaussin}(0,\\texttt{Severity}*\\texttt{Max}(X))italic_X = italic_X + Gaussin ( 0 , Severity \u2217 Max ( italic_X ) ) where X\ud835\udc4bXitalic_X is the inputs.", "description": "Figure 9 illustrates the performance of three optimizers (Adam, SPAM, and Stable-SPAM) on a time series forecasting task using the PatchTST model.  The key aspect highlighted is the robustness of the optimizers to anomalous data.  To simulate real-world scenarios where data might be corrupted or contain outliers, Gaussian noise was added to 10% of randomly selected data points. The severity of this noise was controlled by a 'Severity' parameter, which scales the magnitude of the added noise relative to the maximum value in the original data.  The plot shows the test loss over training epochs for each optimizer under different levels of data corruption (A=0%, A=5%, A=10%), demonstrating how Stable-SPAM consistently maintains lower test loss compared to Adam and SPAM, especially when dealing with higher levels of anomalous data.", "section": "B. Time Series Forescasting Task"}]