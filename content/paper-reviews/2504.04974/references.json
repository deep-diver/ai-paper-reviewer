{"references": [{"fullname_first_author": "Bryan A Plummer", "paper_title": "Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models", "publication_date": "2015-01-01", "reason": "This paper presents a dataset for associating textual descriptions with corresponding visual elements in images, which is a foundational task in visual grounding, although it focuses on natural images rather than text-rich documents."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-01-01", "reason": "This paper introduces a family of large language models that are open and efficient, providing a base for instruction tuning and further development of MLLMs."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper presents visual instruction tuning which is a common and important method used in this work to train a MLLM for supreme document grounding capability."}, {"fullname_first_author": "Danny Driess", "paper_title": "PaLM-E: An embodied multimodal language model", "publication_date": "2023-01-01", "reason": "This paper presents a multimodal language model that this study expands on when addressing potential mismatches between pre-training and fine-tuning data distributions by utilizing related instruction-following data."}, {"fullname_first_author": "Zhiliang Peng", "paper_title": "Kosmos-2: Grounding multimodal large language models to the world", "publication_date": "2023-01-01", "reason": "This paper presents a model which uses document level text recognition and image-to-markdown generation which is different but related to our study."}]}