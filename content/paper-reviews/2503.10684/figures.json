[{"figure_path": "https://arxiv.org/html/2503.10684/x6.png", "caption": "Figure 1: \nPipeline of our method SBD for discovering skills from unsegmented demonstration videos.\nStage I: An unconditional Transformer-XL based policy model\u00a0(Dai et\u00a0al., 2019; Baker et\u00a0al., 2022) is pretrained on an unsegmented dataset to predict future actions (labeled by an inverse dynamics model) based on past observations.\nStage II: The pretrained unconditional policy will produce a high predicted action loss when encountering uncertain observations (e.g., deciding whether to kill a new sheep) in open worlds. These timesteps should be marked as skill boundaries, indicating the need for additional instructions to control behaviors. We segment the long unsegmented videos into a series of short atomic skill demonstrations.\nStage III: We train a conditional Transformer-XL based policy model on the segmented dataset to master a variety of atomic skills.\nStage IV: Finally, we use hierarchical methods (a combination of vision-language models and the conditional policy) to model the long demonstration and follow long-horizon instructions.", "description": "This figure illustrates the four-stage pipeline of the Skill Boundary Detection (SBD) method for skill discovery from unsegmented demonstration videos. Stage I involves pretraining an unconditional Transformer-XL model on unsegmented data to predict future actions. Stage II uses the pretrained model to detect skill boundaries by identifying significant increases in prediction error, which indicate shifts in the skill being executed.  These boundaries segment the long videos into shorter, atomic skill demonstrations. Stage III trains a conditional Transformer-XL model on these segmented demonstrations to learn various atomic skills. Finally, Stage IV employs hierarchical methods, combining vision-language models with the conditional policy, to handle long-horizon instructions and model longer demonstrations.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2503.10684/extracted/6272025/figures/length_distribution/info_only.png", "caption": "(a) \u00a0\u00a0\u00a0Info only.", "description": "The figure shows the length distribution of video segments generated using three different methods: using only external information, using only the predictive loss, and using both. The loss-only method produces a distribution similar to the info-only method, suggesting that the loss-only method also identifies semantically meaningful segments. The combined method's distribution closely resembles that of the loss-only method, indicating that predictive loss is the primary factor in determining the segmentation pattern.", "section": "4.4. Visualizations"}, {"figure_path": "https://arxiv.org/html/2503.10684/extracted/6272025/figures/length_distribution/loss_only.png", "caption": "(b) \u00a0\u00a0\u00a0Loss only.", "description": "The figure shows the distribution of segment lengths when only the prediction loss is used to identify skill boundaries.  The x-axis represents segment length in frames and the y-axis shows the frequency of segments with that length. The distribution illustrates the frequency of different segment lengths produced by the loss-only method, providing insights into the typical duration of skills detected using this approach.", "section": "4.4. Visualizations"}, {"figure_path": "https://arxiv.org/html/2503.10684/extracted/6272025/figures/length_distribution/loss+info.png", "caption": "(c) \u00a0\u00a0\u00a0Both.", "description": "This figure shows the length distribution of video segments generated using different methods: using only external information, using only predictive loss, and using both.  The x-axis represents the length of the segments (in frames), and the y-axis shows the frequency of segments of that length. The distributions are compared to show the effect of combining external information and predictive loss on the length and semantic meaningfulness of the identified segments.", "section": "4.4. Visualizations"}, {"figure_path": "https://arxiv.org/html/2503.10684/x7.png", "caption": "Figure 2: The length distribution of segments, split by info and loss. The info-only method is intrinsically semantically meaningful, suggesting that the loss-only method also identifies a semantically meaningful segmentation pattern. Furthermore, the similarity between the combined method and the loss-only method indicates that predictive loss is the primary factor in learning the segmentation pattern.", "description": "Figure 2 presents a comparative analysis of segment length distributions obtained using different methods for video segmentation.  The 'info-only' method, which utilizes external information, produces segments with lengths that are inherently semantically meaningful.  The similar distribution achieved by the 'loss-only' method\u2014which only uses predictive loss\u2014strongly suggests that the predictive loss effectively captures meaningful boundaries in the video, mirroring the results of the information-rich method.  The combined method, which utilizes both information and loss, shows a distribution most similar to the loss-only method.  This similarity highlights the dominance of predictive loss as the crucial element in learning the segmentation pattern.", "section": "4.4. Visualizations"}, {"figure_path": "https://arxiv.org/html/2503.10684/x8.png", "caption": "Figure 3: Video Segment Examples. Top: sleep in bed. Bottom: collect grass. Each segment is accompanied by five screenshots. The first and last screenshots represent the initial and final frames of the segment, respectively. The remaining three screenshots are manually selected to best illustrate the skill\u2019s progression. More segments can be found in Appendix\u00a0C.", "description": "Figure 3 presents example video segments from the Skill Boundary Detection (SBD) method. Each example shows a short video clip representing a single skill, accompanied by five screenshots. The first and last screenshots capture the start and end of the skill, while the middle three screenshots highlight key steps in the skill's progression. The top row shows the \"sleep in bed\" skill, while the bottom row illustrates the \"collect grass\" skill. More examples can be found in Appendix C.", "section": "4.4. Visualizations"}]