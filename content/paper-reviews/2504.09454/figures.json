[{"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/motivation_v1_2.png", "caption": "Figure 1: Illustration of our motivation. Compression here refers to the VAE + Patchify operation. (a) Existing fixed-compression diffusion transformer (DiT) ignore information density. Fixed large compression leads to limited local realism due to the limited representation of a few tokens preventing accurate recovery of rich information, whereas fixed small compression leads to limited global consistency and high computational complexity due to the burden of global modeling across patched latents. Samples in (a) are obtained from [38]. (b) Our Dynamic Diffusion Transformer (D2iT) adopts a dynamic compression strategy and adds multi-grained noise based on information density, achieving unified global consistency and local realism.", "description": "Figure 1 illustrates the core idea behind the Dynamic Diffusion Transformer (D2iT).  Panel (a) shows the limitations of existing fixed-compression Diffusion Transformers (DiT).  These models either use large compression, leading to loss of local detail and poor realism because too few tokens represent the image, or small compression, which results in high computational costs and a lack of global consistency due to the increased number of tokens to process.  Panel (b) presents the D2iT approach, which uses dynamic compression based on the information density in different image regions.  By using a dynamic VAE and incorporating multi-grained noise prediction, D2iT achieves better local realism and global consistency.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/camera_ready/framework_camera_ready.png", "caption": "Figure 2: The overview of our proposed two-stage framework.\n(1) Stage 1: DVAE dynamically assigns different grained codes to each image region through the Herarchical Encoder and Dynamic Grained Coding (DGC) module.\n(2) Stage 2: D2iT consists Dynamic Grain Transformer and Dynamic Content Transformer, which respectively model the spatial granularity information and content information. We present the network with two granularities. The grain map uses \u20181\u2019 to denote coarse-grained regions and \u20182\u2019 for fine-grained regions.", "description": "This figure illustrates the two-stage framework of the proposed Dynamic Diffusion Transformer (D\u00b2iT) model. Stage 1 uses a Dynamic Variational Autoencoder (DVAE) to encode the input image.  The DVAE employs a hierarchical encoder and Dynamic Grained Coding (DGC) to assign different levels of compression (granularity) to different regions of the image based on their information density. Regions with high information density (e.g., detailed areas) receive finer-grained coding, while regions with low information density (e.g., smooth areas) receive coarser-grained coding. The resulting multi-grained latent codes are then passed to Stage 2. Stage 2 utilizes the D\u00b2iT, which comprises two components: the Dynamic Grain Transformer and the Dynamic Content Transformer. The Dynamic Grain Transformer predicts a grain map indicating the granularity of each region, while the Dynamic Content Transformer predicts the multi-grained noise based on this map and other information. This two-stage approach allows D\u00b2iT to achieve a balance between global consistency and local realism in image generation.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/FFHQ_vision.png", "caption": "Figure 3: Qualitative results of our unconditional generation on FFHQ. In the grain map, red blocks represent fine-grained regions, while blue blocks indicate coarse-grained regions.", "description": "Figure 3 presents a qualitative comparison of unconditional image generation results on the FFHQ dataset using the proposed D\u00b2iT model. It showcases three sample images generated by D\u00b2iT alongside their corresponding grain maps. The grain maps visually represent the dynamic granularity assignments made by the model during the generation process. Red blocks in the grain maps signify fine-grained regions (regions with high spatial complexity and detail), while blue blocks indicate coarse-grained regions (regions with low spatial complexity and less detail).  The figure demonstrates the model's ability to generate high-fidelity images by dynamically adjusting the level of detail and compression based on the inherent characteristics of different regions in the image.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/ImageNet_vision.png", "caption": "Figure 4: Qualitative results of D2iT-XL on ImageNet. The grain maps are generated by the Dynamic Grain Transformer based on class labels, and the images are generated by the Dynamic Content Transformer based on class labels and grain maps.", "description": "This figure displays qualitative results from the D2iT-XL model on the ImageNet dataset.  Each row shows an example image from ImageNet, its corresponding dynamically generated grain map (visualizing regions of varying complexity), and the final image generated by the model. The grain map, generated by the Dynamic Grain Transformer, uses color-coding to represent different levels of detail in the original image.  These maps guide the Dynamic Content Transformer in generating a final image, balancing global consistency with fine-grained details. The final generated images demonstrate the model's ability to leverage the grain map for accurate and high-fidelity image generation.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/ablation_first_stage_2.png", "caption": "Figure 5: The curves of different grain ratios of reconstruction quality (rFID) to generation quality (FID) on FFHQ.", "description": "Figure 5 illustrates the relationship between reconstruction quality (measured by rFID) and generation quality (measured by FID) on the FFHQ dataset at different ratios of fine-grained regions (controlled by the parameter rf=8).  The x-axis represents the ratio of fine-grained regions, while the y-axis shows both rFID and FID.  The graph demonstrates the impact of dynamically adjusting the granularity of image regions on the overall performance of the model.  Optimal performance is observed at a specific balance between fine and coarse-grained regions, showcasing the importance of the dynamic grain approach.", "section": "4.3. Ablation Study and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/FID_imageNet4.png", "caption": "Figure 6: Training convergence comparison of DiT and our D2iT with different parameters on ImageNet. FID-50K is evaluated.", "description": "This figure shows the training convergence curves for both DiT and D2iT models on the ImageNet dataset.  Different model configurations (different parameter counts) are plotted for each model type, showcasing how the FID-50K (Frechet Inception Distance) score, a measure of image generation quality, improves over the course of training. The graph allows for a visual comparison of the training efficiency and convergence speed between DiT and the proposed D2iT model under varying parameter scales.", "section": "4. Experiments"}]