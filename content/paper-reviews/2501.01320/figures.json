[{"figure_path": "https://arxiv.org/html/2501.01320/x2.png", "caption": "Figure 1: Speed and performance comparisons. SeedVR\u00a0demonstrates impressive restoration capabilities, offering fine details and enhanced visual realism.\nDespite its 2.48B parameters, SeedVR is over 2\u00d72\\times2 \u00d7 faster than existing diffusion-based video restoration approaches\u00a0[80, 64, 20].\nWith delicate designs, SeedVR is as efficient as the Stable Diffusion Upscaler\u00a0[2], even with five times the parameter count. (Zoom-in for best view)", "description": "Figure 1 presents a comparative analysis of SeedVR's speed and performance against other state-of-the-art video restoration methods.  SeedVR achieves superior visual quality, exhibiting finer details and enhanced realism. Notably, despite having significantly more parameters (2.48B) than most competitors, SeedVR operates over twice as fast.  Furthermore, it demonstrates comparable efficiency to the Stable Diffusion Upscaler, even with a fivefold increase in model size.  This highlights SeedVR's efficiency and superior restoration capabilities.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2501.01320/x3.png", "caption": "Figure 2: \nModel architecture and the details of Swin-MMDIT of SeedVR. Our approach introduces a shifted window mechanism into the transformer block, bypassing the resolution constrain of vanilla attention. We further adopt large attention windows around the center and variable-sized windows near the boundary, enabling long-range dependency capturing given inputs of any length and size.", "description": "Figure 2 illustrates the architecture of SeedVR, focusing on its Swin-MMDiT block.  This block improves upon traditional transformer blocks by incorporating a shifted window attention mechanism. This addresses the limitations of standard attention mechanisms, which struggle with high-resolution videos and varying input lengths. The shifted window approach uses large windows in the center of the input for long-range dependencies and smaller, variable-sized windows at the edges to handle boundaries effectively. This design allows SeedVR to efficiently process videos of any length and resolution, a key advantage over previous methods.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.01320/x4.png", "caption": "Figure 3: \nThe model architecture of casual video autoencoder. In contrast to naively inflating an existing image autoenoder, we redesign a casual video VAE with spatial-temporal compression capability to achieve a strong reconstruction capability.", "description": "Figure 3 illustrates the architecture of the causal video variational autoencoder (CVVAE) employed in SeedVR.  Unlike approaches that simply adapt image autoencoders for video, SeedVR's CVVAE is specifically designed for video processing.  It incorporates spatial and temporal compression to efficiently handle long videos, improving both training speed and the quality of the video reconstruction.", "section": "3.2 Causal Video VAE"}]