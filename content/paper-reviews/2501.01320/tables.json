[{"content": "Dataset|Metrics|Real-ESRGAN [56]|SD \u00d74 Upscaler [2]|ResShift [74]|RealViFormer [77]|MGLD-VSR [64]|Upscale-A-Video [80]|VEhancer [20]|Ours\n---|---|---|---|---|---|---|---|---\nSPMCS|PSNR \u2191|22.55|22.75|23.14|24.19|23.41|22.30|18.20|22.37\nSPMCS|SSIM \u2191|0.637|0.535|0.598|0.663|0.633|0.567|0.507|0.607\nSPMCS|LPIPS \u2193|0.406|0.554|0.547|0.378|0.369|0.489|0.455|0.341\nSPMCS|DISTS \u2193|0.189|0.247|0.261|0.186|0.166|0.245|0.194|0.141\nSPMCS|NIQE \u2193|3.355|5.883|6.246|3.431|3.315|5.280|4.328|3.207\nSPMCS|MUSIQ \u2191|62.78|42.09|55.11|65.25|58.56|54.94|54.94|64.28\nSPMCS|CLIP-IQA \u2191|0.451|0.402|0.598|0.424|0.495|0.366|0.334|0.587\nSPMCS|DOVER \u2191|8.566|4.413|5.342|10.508|8.471|4.985|7.807|10.508\nUDM10|PSNR \u2191|24.78|26.01|25.56|26.70|26.11|25.28|21.48|25.76\nUDM10|SSIM \u2191|0.763|0.698|0.743|0.796|0.772|0.755|0.691|0.771\nUDM10|LPIPS \u2193|0.270|0.424|0.417|0.285|0.273|0.314|0.349|0.231\nUDM10|DISTS \u2193|0.156|0.234|0.211|0.166|0.144|0.187|0.175|0.116\nUDM10|NIQE \u2193|4.365|6.014|5.941|3.922|3.814|5.314|4.883|3.514\nUDM10|MUSIQ \u2191|54.18|30.33|51.34|59.14|58.01|43.92|46.37|59.14\nUDM10|CLIP-IQA \u2191|0.398|0.277|0.537|0.397|0.443|0.291|0.304|0.524\nUDM10|DOVER \u2191|7.958|3.169|5.111|10.537|7.717|7.108|8.087|10.537\nREDS30|PSNR \u2191|21.67|22.94|22.72|23.34|22.74|22.57|19.83|20.44\nREDS30|SSIM \u2191|0.573|0.563|0.572|0.615|0.578|0.578|0.545|0.534\nREDS30|LPIPS \u2193|0.389|0.551|0.509|0.328|0.271|0.497|0.508|0.346\nREDS30|DISTS \u2193|0.179|0.268|0.234|0.154|0.097|0.271|0.229|0.138\nREDS30|NIQE \u2193|2.879|6.718|6.258|3.032|2.550|5.374|4.615|2.729\nREDS30|MUSIQ \u2191|57.97|25.57|47.50|58.60|62.28|32.41|37.95|57.55\nREDS30|CLIP-IQA \u2191|0.403|0.202|0.554|0.392|0.444|0.228|0.245|0.451\nREDS30|DOVER \u2191|5.552|2.737|3.712|6.673|6.544|3.704|5.549|6.673\nYouHQ40|PSNR \u2191|22.31|22.51|22.67|23.26|22.62|22.08|18.68|21.15\nYouHQ40|SSIM \u2191|0.605|0.528|0.579|0.606|0.576|0.548|0.510|0.554\nYouHQ40|LPIPS \u2193|0.342|0.518|0.432|0.362|0.356|0.435|0.449|0.298\nYouHQ40|DISTS \u2193|0.169|0.242|0.215|0.193|0.166|0.236|0.175|0.118\nYouHQ40|NIQE \u2193|3.721|5.954|5.458|3.172|3.255|5.291|4.161|2.913\nYouHQ40|MUSIQ \u2191|56.45|36.74|54.96|61.88|63.95|49.37|54.18|67.45\nYouHQ40|CLIP-IQA \u2191|0.371|0.328|0.590|0.438|0.509|0.328|0.352|0.635\nYouHQ40|DOVER \u2191|10.92|5.761|7.618|12.788|11.444|7.832|12.178|13.424\nVideoLQ|NIQE \u2193|4.014|4.584|4.829|4.007|3.888|5.545|4.264|3.874\nVideoLQ|MUSIQ \u2191|60.45|43.64|59.69|57.50|59.50|41.08|52.59|54.41\nVideoLQ|CLIP-IQA \u2191|0.361|0.296|0.487|0.312|0.350|0.253|0.289|0.355\nVideoLQ|DOVER \u2191|8.561|4.349|6.749|6.823|7.325|5.567|8.719|8.009\nAIGC38|NIQE \u2193|4.942|4.399|4.853|4.444|4.162|5.743|4.759|3.955\nAIGC38|MUSIQ \u2191|58.39|56.72|64.38|58.73|62.03|51.32|53.36|65.91\nAIGC38|CLIP-IQA \u2191|0.442|0.554|0.660|0.473|0.528|0.378|0.395|0.638\nAIGC38|DOVER \u2191|12.275|10.547|12.082|10.245|11.008|10.297|12.178|13.424", "caption": "Table 1: \nQuantitative comparisons on VSR benchmarks from diverse sources, i.e., synthetic (SPMCS, UDM10, REDS30, YouHQ40), real (VideoLQ), and AIGC (AIGC38) data. The best and second performances are marked in red and orange, respectively.", "description": "Table 1 presents a quantitative comparison of various Video Super-Resolution (VSR) methods across six benchmark datasets.  These datasets encompass diverse sources and types of video degradation: synthetic data (SPMCS, UDM10, REDS30, and YouHQ40), real-world data (VideoLQ), and AI-generated content (AIGC38). The table evaluates the performance of each method using several metrics, including Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and others.  The best and second-best results for each metric and dataset are highlighted in red and orange, respectively, providing a clear visual representation of comparative performance across different VSR approaches and video degradation types.", "section": "4. Experiments"}, {"content": "| Methods | Params (M) | Temporal Compression | Spatial Compression | Latent Channel | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | rFVD \u2193 |\n|---|---|---|---|---|---|---|---|---|\n| SD 2.1 [45] | 83.7 | - | 8 | 4 | 29.50 | 0.9050 | 0.0998 | 8.14 |\n| VEnhancer [20] | 97.7 | - | 8 | 4 | 30.81 | 0.9356 | 0.0751 | 11.10 |\n| Cosmos [44] | 90.2 | 4 | 8 | 16 | 32.34 | 0.9484 | 0.0847 | 13.02 |\n| OpenSora [79] | 393.3 | 4 | 8 | 4 | 27.70 | 0.8893 | 0.1661 | 47.04 |\n| OpenSoraPlan v1.3 [28] | 147.3 | 4 | 8 | 16 | 30.41 | 0.9280 | 0.0976 | 27.70 |\n| CogVideoX [66] | 215.6 | 4 | 8 | 16 | 34.30 | 0.9650 | 0.0623 | 6.06 |\n| Ours | 250.6 | 4 | 8 | 16 | 33.83 | 0.9643 | 0.0517 | 1.85 |", "caption": "Table 2: Quantitative comparisons on VAE models commonly used in existing latent diffusion models\u00a0[45, 20, 44, 79, 28, 66]. The best and second performances are marked in red and orange, respectively.", "description": "This table presents a quantitative comparison of various Variational Autoencoder (VAE) models frequently used in existing latent diffusion models.  The comparison focuses on key metrics such as PSNR, SSIM, LPIPS, and rFVD, providing a detailed performance evaluation across different VAEs. The best and second-best results for each metric are highlighted in red and orange, respectively, for easy identification.", "section": "4.2 Ablation Study"}, {"content": "| Temp. Win. | Spat. Win. Size | Spat. Win. Size | Spat. Win. Size | Spat. Win. Size | Length |\n|---|---|---|---|---|---| \n|  8 \u00d7 8 | 16 \u00d7 16 | 32 \u00d7 32 | 64 \u00d7 64 | 455.49 | t = 1 |\n|  |  |  |  | 138.29 |  |\n|  |  |  |  | 58.37 |  |\n|  |  |  |  | 23.68 |  |\n|  8 \u00d7 8 | 16 \u00d7 16 | 32 \u00d7 32 | 64 \u00d7 64 | 345.78 | t = 5 |\n|  |  |  |  | 110.01 |  |\n|  |  |  |  | 46.49 |  |\n|  |  |  |  | 20.29 |  |", "caption": "Table 3: Training efficiency (sec/iter) with different window sizes.", "description": "This table presents the training time, measured in seconds per iteration, for the SeedVR model with various window sizes. Different window sizes in spatial and temporal dimensions were used during training. The results demonstrate a significant increase in training time as the window sizes decrease, highlighting the efficiency of using larger windows for training.", "section": "4.2 Ablation Study"}]