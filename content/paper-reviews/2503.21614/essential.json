{"importance": "This survey provides a **structured analysis of efficient reasoning techniques** in LRMs, a crucial area for scaling AI. It offers insights to optimize LRM efficiency, fostering innovation and addressing deployment bottlenecks for more practical AI applications.", "summary": "Survey on improving efficiency in large reasoning models across language, multimodality, and beyond.", "takeaways": ["Identified common patterns of reasoning inefficiency in Large Reasoning Models.", "Provided a taxonomy of methods across the LRM lifecycle to enhance efficiency.", "Highlighted future research directions for more trustworthy, applicable reasoning."], "tldr": "Large Reasoning Models (LRMs) enhance performance via Chain-of-Thought reasoning but produce excessively long, redundant reasoning traces, causing inefficiency in training, inference and deployment. This survey offers a comprehensive overview of recent efforts for improving reasoning efficiency in LRMs. It identifies common patterns of inefficiency, examines methods across the LRM lifecycle (pretraining to inference) while focusing on unique challenges. \n\nThe survey categorizes recent developments in efficient reasoning, aligned with stages in the LLM lifecycle. This involves analyzing inefficiency patterns, methods for inference-time efficiency, Supervised Fine-tuning techniques, Reinforcement Learning strategies and model structures enhancing efficiency. It further highlights new research directions aiming to address limitations in each stage, offering strategies to refine future models and support development in efficient, scalable LRMs.", "affiliation": "Shanghai AI Laboratory", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.21614/podcast.wav"}