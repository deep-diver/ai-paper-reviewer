{"references": [{"fullname_first_author": "Xie", "paper_title": "Show-o: One single transformer to unify multimodal understanding and generation", "publication_date": "2024-08-12", "reason": "This paper is the backbone model for HermesFlow and a key comparative model throughout the experimental evaluation."}, {"fullname_first_author": "Wu", "paper_title": "Liquid: Language models are scalable multimodal generators", "publication_date": "2024-12-04", "reason": "This paper explores the synergy between multimodal understanding and generation, which is a key concept discussed and improved upon in HermesFlow."}, {"fullname_first_author": "Wang", "paper_title": "Emu3: Next-token prediction is all you need", "publication_date": "2024-09-18", "reason": "This paper is a strong comparative model that uses a single transformer to unify multimodal tasks, providing a baseline for HermesFlow's performance."}, {"fullname_first_author": "Dong", "paper_title": "DreamLLM: Synergistic multimodal comprehension and creation", "publication_date": "2023-09-11", "reason": "This paper is an important comparative method that utilizes diffusion models and is discussed in the context of unified multimodal models."}, {"fullname_first_author": "Hu", "paper_title": "Ella: Equip diffusion models with llm for enhanced semantic alignment", "publication_date": "2024-03-05", "reason": "This paper is important as it provides a method (TIFA) for generating visual question answering pairs, which are used in HermesFlow for evaluating image generation quality."}]}