{"importance": "This paper introduces SEA, a framework to discover LLMs' knowledge deficiencies, which is significant for high-stakes applications. Its scalability and efficiency address the challenge of evaluating closed-weight models, offering new directions for targeted fine-tuning and better data coverage in LLM development. ", "summary": "SEA: Stochastic Error Ascent efficiently discovers LLM knowledge gaps, outperforming existing methods in error detection with reduced cost.", "takeaways": ["SEA (Stochastic Error Ascent) uncovers more knowledge errors in LLMs than existing methods.", "SEA uses hierarchical retrieval and error propagation modeling for efficient error discovery.", "Analysis of discovered errors reveals correlated failure patterns across LLM families."], "tldr": "Large language models (LLMs) often struggle to retain factual knowledge, leading to errors. Exhaustively evaluating LLMs against full-scale knowledge bases is computationally prohibitive, especially for closed-weight models. Therefore, pinpointing knowledge deficiencies is hard. Researchers typically construct static knowledge-intensive benchmarks. However, it's infeasible to curate static benchmarks that cover all knowledge, so a versatile approach is needed to uncover LLM's knowledge deficiencies. \n\nThis paper introduces Stochastic Error Ascent (**SEA**), a scalable framework for discovering knowledge deficiencies in closed-weight LLMs under a query budget. **SEA** formulates error discovery as stochastic optimization, iteratively retrieving high-error candidates using semantic similarity to previous failures. It uses hierarchical retrieval across document and paragraph levels, and models error propagation with a relation directed acyclic graph. **SEA** uncovers more errors at a lower cost and reveals correlated failure patterns.", "affiliation": "University of Southern California", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.23361/podcast.wav"}