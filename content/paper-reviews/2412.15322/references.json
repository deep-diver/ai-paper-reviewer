{"references": [{"fullname_first_author": "Honglie Chen", "paper_title": "VGGSound: A large-scale audio-visual dataset", "publication_date": "2020-00-00", "reason": "This paper's dataset is used as the primary audio-visual data source for training the proposed MMAudio model."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "The architectural design of this paper's model is adapted in MMAudio's multimodal transformer blocks."}, {"fullname_first_author": "Vladimir Iashin", "paper_title": "Synchformer: Efficient synchronization from sparse cues", "publication_date": "2024-00-00", "reason": "This paper's model is incorporated in MMAudio for enhancing audio-visual synchrony via its conditional synchronization module."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper's model is utilized in MMAudio to extract visual features from video inputs."}, {"fullname_first_author": "Yongqi Wang", "paper_title": "Frieren: Efficient video-to-audio generation with rectified flow matching", "publication_date": "2024-00-00", "reason": "This paper's approach is compared with MMAudio, serving as a benchmark for performance evaluation in video-to-audio synthesis."}]}