{"references": [{"fullname_first_author": "Liu, Haotian", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "LLaVA is a highly influential VLM architecture that Eagle 2.5 is based on."}, {"fullname_first_author": "OpenAI", "paper_title": "GPT-4 technical report", "publication_date": "2023-01-01", "reason": "GPT-4 is a closed-source model that serves as a benchmark for performance for VLM systems."}, {"fullname_first_author": "Chen, Zhe", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2023-01-01", "reason": "InternVL is an open-source VLM architecture used in Eagle 2.5 which employs image tiling strategy."}, {"fullname_first_author": "Bai, Jinze", "paper_title": "Qwen-VL: A frontier large vision-language model with versatile abilities", "publication_date": "2023-01-01", "reason": "Qwen-VL model is a frontier large vision-language model that Eagle 2.5 shows a comparable results."}, {"fullname_first_author": "Zhai, X", "paper_title": "SigLIP: Semantic-aware Vision-Language Pre-training with Contrastive Loss", "publication_date": "2023-01-01", "reason": "SigLIP model is used in Eagle 2.5 as a method for aligning vision embeddings."}]}