{"importance": "This paper introduces a novel approach, paving the way for advancements in **storytelling, interactive media, and personalized video generation**. It can inspire new research directions in multi-subject video creation, benefiting researchers in computer vision, deep learning, and creative AI.", "summary": "CINEMA: MLLM-guided coherent multi-subject video generation for consistent and controllable content creation.", "takeaways": ["Introduces CINEMA, the first video generation model leveraging MLLM for multi-subject video generation.", "Demonstrates that the proposed method eliminates the need for training with explicit correspondences between subject images and entity words.", "CINEMA significantly improves multi-subject consistency, and overall video coherence in generation."], "tldr": "Generating videos with multiple subjects, each defined by reference images, while maintaining temporal and spatial consistency is challenging. Current methods rely on mapping subject images to keywords, leading to ambiguity and limiting the modeling of subject relationships. To address this, CINEMA is introduced, a framework for coherent multi-subject video generation using MLLM. This eliminates the need for explicit correspondences between subject images and text, mitigating ambiguity and reducing annotation effort. \n\nCINEMA leverages MLLM to interpret subject relationships, facilitating scalability and the use of large, diverse datasets. The framework can be conditioned on varying numbers of subjects, offering flexibility in content creation.  CINEMA integrates multimodal conditional information through three modules: a multimodal large language model, a semantic alignment network (AlignerNet), and a visual entity encoding network. AlignerNet bridges the gap between the MLLM outputs and the native text features. VAE features are injected from reference images for visual appearance.", "affiliation": "ByteDance Intelligent Creation", "categories": {"main_category": "Computer Vision", "sub_category": "Video Understanding"}, "podcast_path": "2503.10391/podcast.wav"}