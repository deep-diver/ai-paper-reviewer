[{"figure_path": "https://arxiv.org/html/2501.01245/x1.png", "caption": "Figure 1: Fine-grained Action Instances. The two samples are drawn from the FineGym\u00a0(Shao et\u00a0al. 2020a) dataset, specifically the \u201cpike sole circle backward with 0.5 turn to handstand\u201d at the top and the \u201c\u2026 1 turn \u2026\u201d at the bottom. We further test popular MLLMs on the bottom instance for both coarse-grained and fine-grained: GPT-4V\u00a0(OpenAI 2024), VideoChat2\u00a0(Li et\u00a0al. 2024), VideoLLaVA\u00a0(Lin et\u00a0al. 2023), and InternLM-XComposer-2.5\u00a0(Zhang et\u00a0al. 2024).", "description": "This figure shows two examples of fine-grained actions from the FineGym dataset. The top example is labeled as \"pike sole circle backward with 0.5 turn to handstand.\" The bottom example is labeled as \"...1 turn...\" indicating a similar but distinct action.  The figure highlights the challenge of fine-grained action recognition by showing that popular large language models (LLMs) struggle to distinguish between these visually similar actions.  Four specific LLMs are tested on the bottom example to demonstrate this difficulty: GPT-4V, VideoChat2, VideoLLaVA, and InternLM-XComposer-2.5.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2501.01245/extracted/6107226/fig2_00.png", "caption": "Figure 2: \nOverview of SeFAR pipeline.\nWe target Semi-supervised FAR, assuming most input samples are unlabeled.\nDuring unsupervised learning, SeFAR adopts dual-level temporal elements modeling and performs augmentation in two manners (\u2018Weak\u2019 vs. \u2018Strong\u2019). Strongly augmented/distorted samples by moderate temporal perturbation are used by the student model, while the teacher model offers pseudo-labels based on weakly augmented samples. Consistency is enforced through loss minimization (\u2112u\u2062nsubscript\u2112\ud835\udc62\ud835\udc5b\\mathcal{L}_{un}caligraphic_L start_POSTSUBSCRIPT italic_u italic_n end_POSTSUBSCRIPT). The unsupervised loss is further adjusted by our proposed Adaptive Regulation. The framework is trained with a weighted combination of supervised \u2112s\u2062u\u2062psubscript\u2112\ud835\udc60\ud835\udc62\ud835\udc5d\\mathcal{L}_{sup}caligraphic_L start_POSTSUBSCRIPT italic_s italic_u italic_p end_POSTSUBSCRIPT and unsupervised \u2112u\u2062nsubscript\u2112\ud835\udc62\ud835\udc5b\\mathcal{L}_{un}caligraphic_L start_POSTSUBSCRIPT italic_u italic_n end_POSTSUBSCRIPT losses.", "description": "SeFAR, a semi-supervised framework for fine-grained action recognition, is depicted.  It uses a teacher-student model setup. Unlabeled video data undergoes two types of augmentations: weak and strong.  Weak augmentations feed into the teacher model to generate pseudo-labels.  Strong augmentations (using moderate temporal perturbation) are applied to the student model. A dual-level temporal modeling technique captures visual detail at multiple granularities.  Adaptive regulation stabilizes the training process by adjusting the loss function based on teacher model confidence. The final training loss is a weighted combination of supervised and unsupervised losses.", "section": "Methodology"}, {"figure_path": "https://arxiv.org/html/2501.01245/extracted/6107226/fig3.png", "caption": "Figure 3: \n(a) For K\ud835\udc3eKitalic_K unlabeled videos, the Teacher model predicts each video multiple times to capture the distribution of predictions, which shows less variability on coarse-grained data and more on fine-grained data. An adaptive coefficient \u03b7\ud835\udf02\\etaitalic_\u03b7 is calculated from the mean and variance of the distribution to stabilize training.\n(b) MLLM construction pipeline with SeFAR\u2019s fine-grained features.", "description": "Figure 3(a) illustrates the adaptive regulation method used to stabilize the training process in SeFAR.  The Teacher model makes multiple predictions for each unlabeled video, and the distribution of these predictions is analyzed.  The variability in predictions is higher for fine-grained actions (more challenging to distinguish) compared to coarse-grained actions. An adaptive coefficient (\u03b7) is calculated based on the mean and variance of the predictions. This coefficient adjusts the loss function, reducing the impact of less certain predictions and thus stabilizing the training.  Figure 3(b) shows how SeFAR's fine-grained features are integrated into a Multimodal Large Language Model (MLLM) architecture. SeFAR acts as an improved visual encoder within the MLLM framework. ", "section": "Methodology"}, {"figure_path": "https://arxiv.org/html/2501.01245/extracted/6107226/fig4.png", "caption": "Figure 4: \nAblation Studies. We compare SeFAR-B with different sampling combinations on Gym-99 5%, as illustrated on the left. We also contrast fixed threshold methods with our Adaptive Regulation strategy on FineDiving 5% in the middle. On the right side, we demonstrate the fluctuation of predictions made by the Teacher model across different datasets.", "description": "This figure presents ablation studies conducted on the SeFAR-B model. The left panel compares the performance of SeFAR-B with various sampling combinations on the Gym-99 dataset (with 5% labeled data).  The middle panel contrasts the performance of SeFAR-B using a fixed threshold method versus the adaptive regulation approach, again on the FineDiving dataset (also with 5% labeled data). The right panel shows how much the predictions of the teacher model fluctuate across different datasets, illustrating the model's consistency.", "section": "Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2501.01245/x2.png", "caption": "Figure 5: \nThe relationship between the Teacher model\u2019s prediction accuracy and its confidence (left), as well as its standard deviation (right).", "description": "This figure shows two plots illustrating the relationship between the teacher model's prediction performance and its uncertainty. The left plot shows the relationship between the teacher model's prediction accuracy and its confidence score.  Higher confidence scores are associated with higher accuracy. The right plot shows the relationship between prediction accuracy and the standard deviation of the teacher model's predictions. Lower standard deviations (indicating less uncertainty) are associated with higher prediction accuracy. These plots demonstrate the model's uncertainty and its relation to the prediction accuracy, supporting the use of adaptive regulation in the SeFAR framework.", "section": "Appendix: Visualization of Model Uncertainty"}, {"figure_path": "https://arxiv.org/html/2501.01245/x3.png", "caption": "Figure 6: \nExamples of Gym-QA", "description": "This figure displays examples from the Gym-QA dataset, which is a multiple-choice question-answering dataset derived from the FineGym dataset.  Each example shows a video still along with a multiple-choice question about the action performed in the video.  The questions focus on fine-grained action recognition, requiring detailed understanding of subtle differences in the actions. The aim is to evaluate the capabilities of Multimodal Large Language Models (MLLMs) in this challenging fine-grained action recognition task.", "section": "Experiment Setup"}, {"figure_path": "https://arxiv.org/html/2501.01245/x4.png", "caption": "Figure 7: \nExamples of Gym-New", "description": "Figure 7 shows examples of the Gym-New dataset, which is a subset of the FineGym dataset specifically curated for evaluating the impact of temporal directionality on action recognition.  It consists of pairs of actions that are essentially the reverse of each other, like \"salto forward stretched with 2 twists\" and \"salto backward stretched with 2 twists.\"  These pairs highlight the challenges of temporal understanding in fine-grained action recognition, where the direction of the movement significantly impacts the action's semantic meaning.", "section": "D. Gym-QA and Gym-New"}, {"figure_path": "https://arxiv.org/html/2501.01245/x5.png", "caption": "Figure 8: \nConfusion matrix of baseline (left) and ours (right) on Gym-New 10%, where the horizontal coordinate represents the predicted label and the vertical coordinate represents the true label. The labels corresponding to actions are shown in Fig.\u00a09.", "description": "This figure displays two confusion matrices, one for a baseline model and one for the SeFAR model, both evaluated on the Gym-New dataset using 10% of the labeled data.  Each matrix visualizes the performance of the respective model by showing the counts of true positive and false positive classifications across all action categories within Gym-New. The horizontal axis represents the predicted action labels, and the vertical axis represents the true action labels. The color intensity corresponds to the frequency of a specific prediction.  Darker colors represent more frequent correct predictions (diagonal elements), while lighter colors represent incorrect predictions.  By comparing the two matrices, one can assess the improvement in prediction accuracy achieved by the SeFAR model.", "section": "D. Gym-QA and Gym-New"}, {"figure_path": "https://arxiv.org/html/2501.01245/x6.png", "caption": "Figure 9: \nLabels corresponding to actions in Gym-New.", "description": "This figure shows a table that lists the labels for actions included in the Gym-New dataset, which is a subset of the FineGym dataset used for evaluating fine-grained action recognition models.  The labels are categorized by the apparatus used (Uneven Bars, Floor Exercise, Balance Beam) and provide more detailed descriptions of actions than coarser-grained categories. Each action is given a unique numerical ID. This detailed labeling is crucial for the fine-grained nature of the Gym-New dataset and the specific evaluation tasks within the paper.", "section": "D. Gym-QA and Gym-New"}]