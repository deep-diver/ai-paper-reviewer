{"importance": "This paper addresses the critical issue of overestimation in LLM reasoning capabilities due to data exposure. It introduces a novel benchmark, offering a more accurate evaluation and paving the way for future research into genuinely robust and generalizable AI systems.", "summary": "LINGOLY-TOO: A new benchmark to disentangle memorization from reasoning in LLMs using linguistic templatization and orthographic obfuscation.", "takeaways": ["LLMs struggle with advanced linguistic reasoning when memorization is mitigated.", "LLM accuracy varies significantly across permutations of the same linguistic problem.", "Prior data exposure inflates the perceived reasoning abilities of LLMs."], "tldr": "Large Language Models (LLMs) often appear more capable in reasoning tasks than they truly are because they memorize evaluation benchmarks. This paper highlights the problem of **overestimating LLM reasoning skills** due to data exposure. The research addresses this issue by introducing a new framework for creating linguistic reasoning problems that minimize the impact of memorization on performance estimates.\n\nThe authors introduce **LINGOLY-TOO, a benchmark** designed to challenge LLMs' linguistic reasoning abilities. By using orthographic templates, they dynamically obfuscate writing systems of real languages, generating numerous question variations. These variations maintain the reasoning steps needed for solutions but reduce the chances of specific problem instances appearing in training data. Experiments show that even state-of-the-art models struggle, revealing prior data exposure inflates reasoning skills.", "affiliation": "University of Oxford", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.02972/podcast.wav"}