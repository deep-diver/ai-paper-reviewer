{"references": [{"fullname_first_author": "Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-04-08", "reason": "This paper is a significant contribution to visual instruction tuning, a crucial aspect of multimodal models."}, {"fullname_first_author": "Sun", "paper_title": "Generative multimodal models are in-context learners", "publication_date": "2023-12-21", "reason": "This paper explores in-context learning, a key capability for generative multimodal models."}, {"fullname_first_author": "Wang", "paper_title": "Emu3: Next-token prediction is all you need", "publication_date": "2024-09-01", "reason": "This paper presents EMU3, an architecture central to next-generation multimodal systems."}, {"fullname_first_author": "Gemini Team", "paper_title": "Gemini: a family of highly capable multimodal models", "publication_date": "2023-12-19", "reason": "This paper details the Gemini multimodal model, a crucial model as a benchmark."}, {"fullname_first_author": "Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2022-08-03", "reason": "This paper is central to visual editing in multimodal models by prompt-to-prompt image editing."}]}