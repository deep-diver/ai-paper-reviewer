[{"figure_path": "https://arxiv.org/html/2501.07171/extracted/6127988/Figures/datamap.jpg", "caption": "Figure 1:  Overlap of \\dataset\u00a0dataset with the Landscape of Biomedical Research [22] Each color and labeled region reflects thematic concentrations, capturing the diversity of topics within our dataset. Gray points represent articles not present in our dataset.", "description": "This figure visualizes the thematic distribution of the BIOMEDICA dataset, comparing its subject matter coverage to the broader landscape of biomedical research. Each color-coded region represents a specific theme or area of research within the BIOMEDICA dataset, showcasing the variety of topics it encompasses. The size of each region reflects the relative abundance of articles within that theme.  Gray points indicate research areas present in the broader landscape of biomedical research but not included within the BIOMEDICA dataset.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.07171/x1.png", "caption": "Figure 2: \\dataset\u00a0curation pipeline: In the Extract phase, metadata, text (caption, figure reference, full-text), and images are sourced and processed from PMC-OA. In the Transform phase, DINO v2 features are generated for each image, followed by clustering using PCA and k-means. Clinicians and scientists annotate these clusters, identifying 12 global concepts and 170 local concepts, which are then propagated across all images. Finally, in the Load phase, the dataset is made available on Hugging Face with the listed features.", "description": "The BIOMEDICA dataset curation pipeline consists of three phases: extraction, transformation, and loading.  The extraction phase sources metadata, text (captions, figure references, and full text), and images from PubMed Central Open Access (PMC-OA). The transformation phase generates DINO v2 image features, performs clustering using PCA and k-means, and involves annotation by clinicians and scientists to identify 12 global and 170 local concepts which are then propagated to all images.  Finally, the loading phase makes the dataset publicly available on Hugging Face.", "section": "3. BIOMEDICA Data Curation Process"}, {"figure_path": "https://arxiv.org/html/2501.07171/x2.png", "caption": "Figure 3: Left: Examples of images included in the \\dataset\u00a0dataset, ranging from clinical imaging to maps and bar plots. Right: Visualization of the concept breakdown in the BIOMEDICA taxonomy. The inner level of the pie chart reflects the panel type (light green indicates multi panel, dark green indicates single panel) and the outer level reflects the global concept of individual taxonomies, and the word cloud reflects the fine-grained local concept proportions for the most frequent concepts.", "description": "This figure is a visualization aid to better understand the BIOMEDICA dataset. The left panel showcases a variety of image examples included in the dataset, spanning clinical images to diagrams and charts.  The right panel provides a visual representation of the BIOMEDICA taxonomy.  A nested pie chart is used to illustrate panel types (single or multi-panel) and global concepts of the images. A word cloud then highlights the proportions of fine-grained, local concepts within the most frequent categories. This detailed visualization aims to convey the breadth and depth of the BIOMEDICA dataset.", "section": "3. BIOMEDICA Data Curation Process"}, {"figure_path": "https://arxiv.org/html/2501.07171/x3.png", "caption": "Figure 4: Average model performance of best BMCA-CLIP models compared to prior work.", "description": "This figure compares the average performance of the best-performing BMCA-CLIP models (BMCA-CLIP CF/WiSE-FT, BMCA-CLIP CB/WiSE-FT, and BMCA-CLIP/WiSE-FT) against previously published biomedical vision-language models (OpenCLIP, CoCa, PMC-CLIP, and BioMedCLIP) across multiple biomedical image classification tasks spanning various domains including biology, pathology, ophthalmology, dermatology, and surgery.  The results demonstrate BMCA-CLIP models consistently outperform existing state-of-the-art models on the majority of tasks. The y-axis represents the average performance across all the tasks. The x-axis shows the different models compared. Each colored line represents a model's performance across tasks grouped by domain.", "section": "5. Evaluation Benchmark"}, {"figure_path": "https://arxiv.org/html/2501.07171/x4.png", "caption": "Figure 5:  \\dataset\u00a0cohort diagram: selection criteria for the construction\nof relevant image-caption pairs.", "description": "This figure is a cohort diagram that visually represents the process of building the BIOMEDICA dataset. It shows how the initial set of 6 million articles from PubMed Central Open Access (PMC-OA) is filtered and processed to create a final dataset of 24 million image-caption pairs.  The diagram visually tracks the number of articles and images at different stages of the process. First, articles without images are excluded, resulting in a smaller set of articles with images. These articles are then analyzed to extract image captions and figure references.  Finally, expert-guided annotations are added to the image-caption pairs, leading to the final BIOMEDICA dataset.", "section": "3. BIOMEDICA Data Curation Process"}, {"figure_path": "https://arxiv.org/html/2501.07171/x5.png", "caption": "Figure 6: A) Diagram illustrating the structure of a JSON file containing a list of dictionaries representing PMC articles. Each article dictionary includes metadata fields such as PMID, nXML path, abstract, title, keywords, and a nested figure set. The figure set is a list of dictionaries, where each dictionary contains the figure\u2019s PMID, volume number, image file, caption, and context. B) Diagram illustrating the WebDataset format, where data is stored across multiple .tar archives (e.g., data-000.tar, data-001.tar). Each archive contains paired text and image files representing individual records.", "description": "Figure 6 illustrates the data structure used in the BIOMEDICA dataset. Part A shows the JSON structure for each article, including metadata like PMID, nXML path, abstract, title, keywords, and a nested 'figure set'.  The figure set contains individual figures with their respective PMIDs, volume numbers, image files, captions, and contextual information. Part B depicts the WebDataset format, showing how the data is organized across multiple .tar files (e.g., data-000.tar). Each .tar file contains paired text and image files representing individual data points.", "section": "3. BIOMEDICA Data Curation Process"}, {"figure_path": "https://arxiv.org/html/2501.07171/x6.png", "caption": "Figure 7: DinoV2 features Scree plot", "description": "The scree plot displays the variance explained by each principal component after applying principal component analysis (PCA) to the 1024-dimensional image embeddings generated by the DINOv2 model.  The plot helps determine the optimal number of principal components to retain while minimizing information loss, aiding in dimensionality reduction for efficient clustering of images.", "section": "14. Labeling"}, {"figure_path": "https://arxiv.org/html/2501.07171/x7.png", "caption": "Figure 8: Inter-annotator disagreement (lower is better).", "description": "This figure displays histograms illustrating the level of disagreement among annotators for three different aspects of the image annotation task: panel type, global taxonomy, and local taxonomy. Lower values on the x-axis indicate a higher level of agreement among annotators, suggesting that the labeling process for these particular aspects was consistent and reliable.  The histograms provide a visual representation of the distribution of disagreement scores, allowing for a quick assessment of annotator agreement on different taxonomy levels.", "section": "14. Concept Labeling: Additional Details"}, {"figure_path": "https://arxiv.org/html/2501.07171/x8.png", "caption": "Figure 9: Distributions of token counts and image dimensions in the dataset. Histograms are shown for token counts in captions, figure references, and full text, as well as for image widths and heights. Outliers have been excluded to highlight the central tendencies and areas of higher data density.", "description": "This figure presents histograms illustrating the distributions of token counts (in captions, figure references, and full text) and image dimensions (width and height) within the BIOMEDICA dataset.  To emphasize the central tendencies and areas with high data density, outliers have been removed from the distributions.", "section": "Dataset Statistics"}, {"figure_path": "https://arxiv.org/html/2501.07171/x9.png", "caption": "Figure 10: Hierarchical Taxonomy", "description": "This figure presents a hierarchical taxonomy of image types within the BIOMEDICA dataset.  It visually organizes over a dozen broad categories (e.g., Clinical Imaging, Microscopy, Plots and Charts) into more specific subcategories. Each category contains multiple examples of the image types it encompasses. This taxonomy is crucial for annotating and organizing the vast collection of images in the BIOMEDICA dataset, allowing for more efficient data exploration and utilization.", "section": "Concept Labeling"}]