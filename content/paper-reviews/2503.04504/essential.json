{"importance": "This research addresses the critical issue of **generalization in VAD** and offers a practical solution that can be readily deployed in diverse real-world scenarios. The use of LVLMs and context-aware VQA opens new avenues for VAD research and offers a pathway towards more adaptable and intelligent surveillance systems. The **C-VAD** technique and the datasets will facilitate further exploration in this area.", "summary": "AnyAnomaly: LVLM for customizable zero-shot video anomaly detection, adapting to diverse environments without retraining.", "takeaways": ["Introduces C-VAD: a novel technique for customizable video anomaly detection based on user-defined anomalies.", "Presents AnyAnomaly: a model leveraging context-aware VQA with LVLMs for effective C-VAD without additional training.", "Demonstrates state-of-the-art performance and superior generalization on multiple VAD datasets."], "tldr": "Video Anomaly Detection (VAD) models often fail to generalize across diverse environments due to their reliance on pre-trained normal patterns, which requires costly retraining. This paper tackles this challenge by introducing Customizable Video Anomaly Detection (**C-VAD**), a technique that uses user-defined text to identify abnormal events in videos. Unlike traditional methods, C-VAD dynamically adapts to new environments without needing additional training data. This approach aims to improve the practical usability of VAD systems in real-world scenarios. \n\nTo realize C-VAD, the authors developed **AnyAnomaly**, a model that employs context-aware Visual Question Answering (VQA) using Large Vision Language Models (LVLMs). AnyAnomaly uses a key frame selection module and integrates positional and temporal contexts to enhance the analysis of video segments. The model was evaluated on both standard VAD benchmarks and newly created C-VAD datasets, demonstrating competitive performance and superior generalization capabilities. AnyAnomaly achieved state-of-the-art results on the UBnormal dataset and showed improvements across various anomaly types.", "affiliation": "Yonsei University", "categories": {"main_category": "Computer Vision", "sub_category": "Video Understanding"}, "podcast_path": "2503.04504/podcast.wav"}