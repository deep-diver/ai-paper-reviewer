{"importance": "This work introduces **VideoUFO, a new video dataset** aligned with user interests, filling a gap in existing resources. It enables more relevant and effective text-to-video generation, **addressing the limitations of current models** and opening new research directions by providing high-quality, focused training data.", "summary": "VideoUFO: A new user-focused, million-scale dataset that improves text-to-video generation by aligning training data with real user interests and preferences!", "takeaways": ["VideoUFO, a dataset of over 1.09 million video clips, directly addresses the gap between user needs and current text-to-video model capabilities.", "Current text-to-video models often underperform on user-focused topics due to a lack of relevant training data.", "A model trained on VideoUFO demonstrates superior performance on previously challenging topics, highlighting the dataset's effectiveness."], "tldr": "Current text-to-video models fall short of user expectations because they aren't trained on relevant topics. Existing video datasets often lack alignment with real-world user interests. To address this, the paper introduces the **VideoUFO dataset**, which is specifically curated to focus on user preferences. It also features minimal overlap with existing datasets and uses Creative Commons licensed videos. \n\n The paper identifies 1,291 user-focused topics, retrieves related YouTube videos, segments them into clips, generates captions, and verifies content. Experiments show that current models struggle with certain topics. A model trained on VideoUFO outperforms others in these areas, demonstrating the dataset's value in enhancing text-to-video generation quality.", "affiliation": "University of Technology Sydney", "categories": {"main_category": "Multimodal Learning", "sub_category": "Multimodal Generation"}, "podcast_path": "2503.01739/podcast.wav"}