[{"content": "| Method | Single-Object FVD\u2193 | Single-Object CF\u2191 | Single-Object ViCLIP-T\u2191 | Single-Object ViCLIP-V\u2191 | Single-Object AD | Single-Object Text | Single-Object Motion | Single-Object Quality | Multi-Object FVD\u2193 | Multi-Object CF\u2191 | Multi-Object ViCLIP-T\u2191 | Multi-Object ViCLIP-V\u2191 | Multi-Object AD | Multi-Object Text | Multi-Object Motion | Multi-Object Quality |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  |  |  |  |  |  | align. | consist. |  |  |  |  |  |  | align. | consist. |  |\n| VideoCrafter [10] | 1484.18 | 0.966 | 0.209 | 0.796 | 2.93 | 84.3 | 84.3 | 81.2 | 1413.83 | 0.966 | 0.208 | 0.802 | 3.75 | 84.3 | 87.5 | 92.1 |\n| DynamiCrafter [54] | 1442.48 | 0.942 | 0.214 | 0.817 | 8.94 | 75.0 | 81.2 | 82.8 | 1300.07 | 0.947 | 0.211 | 0.834 | 7.56 | 75.0 | 73.4 | 76.5 |\n| Motion-I2V [43] | 1195.08 | 0.937 | 0.220 | 0.822 | 6.28 | 75.0 | 89.0 | 93.7 | 1162.06 | 0.935 | 0.219 | 0.821 | 6.97 | 81.0 | 89.0 | 95.3 |\n| ConsistI2V [41] | 1206.61 | 0.951 | 0.218 | 0.839 | 5.21 | 65.6 | 78.1 | 81.2 | 1186.10 | 0.935 | 0.217 | 0.850 | 7.25 | 81.2 | 82.8 | 84.3 |\n| TI2V (UNet) | 1285.99 | 0.942 | 0.219 | 0.877 | 5.90 | 53.1 | 59.3 | 70.3 | 1410.68 | 0.942 | 0.218 | 0.883 | 7.93 | 62.5 | 64.0 | 60.0 |\n| Ours (UNet) | **925.39** | **0.969** | **0.220** | **0.888** | 4.70 | - | - | - | **1089.86** | **0.966** | **0.220** | **0.896** | 5.59 | - | - | - |\n| TI2V (DiT) | 1232.89 | 0.924 | 0.223 | 0.797 | 10.87 | 65.6 | 73.4 | 68.7 | 1156.82 | 0.917 | 0.221 | 0.805 | 10.52 | 64.0 | 59.3 | 64.0 |\n| Ours (DiT) | **1216.83** | **0.945** | **0.226** | **0.860** | 7.22 | - | - | - | **1134.71** | **0.948** | **0.225** | **0.863** | 7.48 | - | - | - |", "caption": "Table 1: Results for single-object and multi-object settings on the SA-V-128 Benchmark. We report FVD, CLIPFrame\u00a0(CF), ViCLIP-T, ViCLIP-V, and Average Displacement\u00a0(AD), along with human ratings. Human evaluation shows the percentage of raters that prefer the results of Through-The-Mask.", "description": "This table presents a quantitative comparison of different image-to-video generation models on the SA-V-128 benchmark dataset.  The benchmark consists of videos with single and multiple objects, allowing for a thorough evaluation of the models' ability to handle complex motion scenarios. The models are evaluated using several metrics: Fr\u00e9chet Video Distance (FVD) measures the overall visual quality; CLIPFrame (CF) assesses the temporal consistency of video frames; ViCLIP-T and ViCLIP-V evaluate the alignment between the generated videos and text and image input respectively; Average Displacement (AD) quantifies the realism of the motion in generated videos.  In addition to these objective metrics, human ratings are included, providing a subjective evaluation of the video quality. Specifically, the human evaluation shows the percentage of evaluators who prefer the results of the Through-The-Mask model over other models for each video.", "section": "4. Experiments"}, {"content": "| Method | FVD \u2193 | CF \u2191 | ViCLIP-T \u2191 | ViCLIP-V \u2191 | AD | Text | Motion | Quality |\n|---|---|---|---|---|---|---|---|---|\n| VideoCrafter [10] | 266.83 | 0.961 | 0.195 | 0.810 | 4.87 | 78.9 | 78.1 | 80.4 |\n| DynamiCrafter [54] | 217.40 | 0.946 | 0.200 | 0.840 | 8.28 | 55.4 | 53.9 | 53.9 |\n| Motion-I2V [43] | 286.42 | 0.928 | 0.209 | 0.746 | 7.46 | 81.2 | 82.8 | 83.5 |\n| ConsistI2V [41] | 283.59 | 0.938 | 0.202 | 0.838 | 6.38 | 57.0 | 67.1 | 65.6 |\n| TI2V (UNet) | 242.18 | 0.954 | 0.203 | 0.858 | 5.99 | 49.2 | 57.8 | 66.4 |\n| Ours (UNet) | **196.23** | **0.962** | **0.210** | **0.865** | 5.69 | - | - | - |\n| TI2V (DiT) | 212.23 | 0.937 | 0.206 | 0.789 | 9.00 | 61.7 | 63.2 | 67.1 |\n| Ours (DiT) | **192.45** | **0.948** | **0.215** | **0.847** | 7.42 | - | - | - |", "caption": "Table 2: Image-Animation-Bench results. We report FVD, CLIPFrame\u00a0(CF), ViCLIP-T, ViCLIP-V, and Average Displacement\u00a0(AD), along with human ratings. Human evaluation shows the percentage of raters that prefer the results of Through-The-Mask.", "description": "Table 2 presents a quantitative evaluation of different image-to-video generation models on the Image-Animation-Bench dataset.  The metrics used are Fr\u00e9chet Video Distance (FVD), which measures the visual similarity between generated and ground truth videos; CLIPFrame (CF), which assesses temporal consistency across frames; ViCLIP-T, measuring text-video alignment; ViCLIP-V, evaluating image-video fidelity; and Average Displacement (AD), indicating the level of motion in generated videos.  Human evaluation scores, representing the percentage of raters who preferred the results of Through-The-Mask over other methods, are also included for a comprehensive comparison.", "section": "4. Experiments"}, {"content": "| Config. | FVD\u2193 | CF\u2191 | ViCLIP-T\u2191 | ViCLIP-V\u2191 | AD |\n|---|---|---|---|---|---| \n| TI2V (UNet) | 974.07 | 0.942 | 0.218 | 0.880 | 6.91 |\n| no mask attn (UNet) | 972.25 | 0.962 | 0.214 | 0.880 | 4.99 |\n| w. cross-attn (UNet) | 670.92 | 0.965 | 0.220 | 0.890 | 5.25 |\n| w. self-attn (UNet) | 658.92 | 0.968 | 0.218 | 0.892 | 5.00 |\n| Ours (UNet) | **648.59** | **0.968** | **0.220** | **0.892** | 5.15 |\n| TI2V (DiT) | 1199.86 | 0.921 | 0.222 | 0.802 | 10.70 |\n| no mask attn (DiT) | 1182.49 | 0.943 | 0.223 | 0.851 | 6.78 |\n| w. cross-attn (DiT) | 1105.91 | 0.945 | 0.226 | 0.859 | 7.23 |\n| w. self-attn (DiT) | 1152.38 | 0.946 | 0.223 | 0.855 | 7.01 |\n| Ours (DiT) | **1082.23** | **0.947** | **0.226** | **0.861** | 7.35 |", "caption": "Table 3: Ablation study results on the SA-V-128 benchmark comparing the performance of different attention configurations, in both U-Net and DiT-based models.", "description": "This table presents the results of an ablation study conducted on the SA-V-128 benchmark dataset. The study investigates the impact of different attention mechanisms (masked cross-attention, masked self-attention, both, and neither) within both U-Net and DiT-based image-to-video generation models.  The table compares various metrics across different attention configurations to assess the contribution of each mechanism to the overall performance of the model.", "section": "4.3 Ablation Study"}, {"content": "| Configuration | FVD \u2193 | CF \u2191 | ViCLIP-T \u2191 | ViCLIP-V \u2191 | AD |\n|---|---|---|---|---|---| \n| w. OF | 1014.72 | 0.934 | 0.219 | 0.879 | 7.04 |\n| w. Seg. | **648.59** | **0.968** | **0.220** | **0.892** | 5.15 |", "caption": "Table 4: Ablation study comparing segmentation masks and optical flow as motion trajectory representation. w. Seg refers to models with segmentation-based motion trajectories, while w. OF denotes models with optical flow-based motion trajectories.", "description": "This table presents the results of an ablation study that compares the performance of using segmentation masks versus optical flow as the intermediate motion representation in a two-stage image-to-video generation model.  The study evaluates four different model configurations. The first is the baseline model using optical flow. The second and third models utilize segmentation masks, one using only masked cross-attention and the other using both masked cross-attention and masked self-attention. The fourth model is the full THROUGH-THE-MASK model. The metrics compared across the configurations are Fr\u00e9chet Video Distance (FVD), CLIPFrame (CF), ViCLIP-T, ViCLIP-V, and Average Displacement (AD).  Lower FVD indicates higher video quality, while higher values in other metrics usually indicate better performance.", "section": "4.3 Ablation Study"}]