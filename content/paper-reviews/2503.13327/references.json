{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a foundational model for aligning visual and textual representations, which is used for text-based image editing and visual-relation learning."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-01-01", "reason": "This paper introduces the concept of in-context learning, which is the inspiration for the visual relation in-context learning paradigm used for the Edit Transfer task."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper introduces the DiT architecture, which is used as the backbone for the FLUX model, that exhibits in-context learning capabilities."}, {"fullname_first_author": "Amir Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2023-01-01", "reason": "This paper introduces a classical text-based editing method and provides a baseline to compare with the Edit Transfer approach."}, {"fullname_first_author": "Leon A. Gatys", "paper_title": "Image style transfer using convolutional neural networks", "publication_date": "2016-01-01", "reason": "This paper focuses on transferring the global artistic style of the reference image to the target and provides a baseline to compare with the Edit Transfer approach."}]}