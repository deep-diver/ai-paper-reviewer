{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-01", "reason": "This technical report presents the capabilities of GPT-4, which is used as a base model in this paper."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-09-01", "reason": "This paper introduces the MMLU benchmark, a dataset used to evaluate the knowledge and reasoning abilities of language models, which is employed in this study."}, {"fullname_first_author": "Karan Singhal", "paper_title": "Large language models encode clinical knowledge", "publication_date": "2023-08-01", "reason": "This paper demonstrates that large language models encode substantial clinical knowledge, which motivates this work's evaluation of medical reasoning tasks."}, {"fullname_first_author": "Xiangru Tang", "paper_title": "MedAgents: Large language models as collaborators for zero-shot medical reasoning", "publication_date": "2023-11-01", "reason": "This introduces the MedAgents framework, a collaborative multi-agent system for medical decision-making, forming the basis for the current work's benchmark."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-03-01", "reason": "This paper introduces chain-of-thought prompting, a technique used in this paper as a baseline for improving the reasoning abilities of language models."}]}