[{"figure_path": "https://arxiv.org/html/2504.01204/x2.png", "caption": "Figure 1: By incorporating articulation into static assets, AKD synthesizes realistic motions distilled from large video diffusion models.", "description": "Figure 1 showcases the results of Articulated Kinematics Distillation (AKD). AKD leverages pre-trained video diffusion models to generate realistic character animations.  Instead of directly manipulating complex 3D models, AKD uses a skeleton-based approach, significantly reducing the number of parameters and simplifying the animation process. The figure displays several examples of different characters (lion, T-Rex, camel, astronaut, gorilla, elephant) in various walking poses, all generated using AKD from simple static 3D assets by adding realistic motion. This highlights AKD's ability to produce high-fidelity animations efficiently and consistently while maintaining the structural integrity of the character.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2504.01204/x3.png", "caption": "Figure 2: Pipeline. We novelly incorporate articulated skeletons into generative motion synthesis. With the low-dimensional parameterization of motions (a sequence of joint angles for articulated bones), the synthesis can focus more on motion modes instead of local-scale deformations. Given a text prompt, we use a text-to-3D method to generate a 3D asset. The asset is deformed by the skeleton and differentiably rendered into videos. The SDS gradient is evaluated by a pre-trained video diffusion transformer and backpropagated to joint angles.", "description": "This figure illustrates the pipeline of Articulated Kinematics Distillation (AKD), a novel framework for generating high-fidelity character animations.  The process begins with a text prompt, which is used by a text-to-3D model to create a 3D asset. An articulated skeleton is then incorporated into the 3D asset, allowing for motion synthesis driven by changes in joint angles.  This approach reduces the complexity of the problem by focusing on joint-level control rather than detailed deformations. The 3D model is rendered into a video, which is then fed into a pre-trained video diffusion transformer.  The transformer evaluates the video using Score Distillation Sampling (SDS), generating gradients that are backpropagated to adjust the joint angles. This iterative process refines the animation until it aligns with the original text prompt, resulting in a high-fidelity, physically plausible animation.", "section": "4. Method"}, {"figure_path": "https://arxiv.org/html/2504.01204/x4.png", "caption": "Figure 3: Qualitative comparisons with TC4D. The blurry artifacts generated by TC4D are highlighted. TC4D often fails to produce alternating leg movements (e.g., in the astronaut example), or shows limited local-scale motion (e.g., in the T-Rex example).", "description": "This figure compares the results of the proposed Articulated Kinematics Distillation (AKD) method and the existing Text-to-4D (TC4D) method on generating character animations from text prompts.  It highlights several shortcomings of the TC4D approach, specifically its tendency to produce blurry artifacts and its difficulty in capturing realistic, alternating movements like walking gaits. The examples of an astronaut and T-Rex are used to illustrate how TC4D's generated animations show limited local-scale movements, as opposed to AKD's higher-fidelity results.", "section": "6.1 Quantitative Comparisons"}, {"figure_path": "https://arxiv.org/html/2504.01204/x5.png", "caption": "Figure 4: Examples of our synthesized motions.", "description": "This figure displays a diverse range of character animations generated using the Articulated Kinematics Distillation (AKD) method. Each row showcases a different character (bear, rhino, elephant, triceratops, moose, tortoise, ostrich, rooster) performing a walking motion. The checkerboard background provides context and aids in evaluating the realism and physical plausibility of the generated animations.  The consistent, fluid movements highlight the method\u2019s ability to produce high-fidelity, articulated animations.", "section": "6.4 Synthesis Diversity"}, {"figure_path": "https://arxiv.org/html/2504.01204/x6.png", "caption": "Figure 5: We use physics-based motion tracking to project synthesized motions onto physics-grounded trajectories.", "description": "This figure demonstrates the process of physics-based motion tracking, where synthetic motions generated by the model are refined to adhere to physical laws. The figure displays examples of initial synthetic motions (left) that may not fully respect physical constraints such as ground contact. After applying physics-based motion tracking, the corrected motions (right) are shown, exhibiting physically plausible interactions with the ground, including more realistic foot placement and less floating.", "section": "6.3 Physics-Based Motion Tracking"}, {"figure_path": "https://arxiv.org/html/2504.01204/x7.png", "caption": "Figure 6: Our method supports synthesizing different motions based on varying text descriptions.", "description": "This figure demonstrates the versatility of the Articulated Kinematics Distillation (AKD) method in generating diverse character animations from text prompts.  It showcases two example animations of a gorilla ('a gorilla is walking' and 'a gorilla is running') and a dog ('a dog is walking' and 'a dog is running').  The differences in the generated animations clearly reflect the variations in the text descriptions, illustrating the model's ability to capture nuanced motion details based on textual input.", "section": "6.4 Synthesis Diversity"}, {"figure_path": "https://arxiv.org/html/2504.01204/x8.png", "caption": "Figure 7: Ablation studies on ground rendering, ground penalty loss, and the smoothness loss. The artifacts are highlighted.", "description": "This figure shows the results of ablation studies conducted to evaluate the impact of ground rendering, ground penalty loss, and smoothness loss on the quality of generated animations.  The visualizations demonstrate how each component individually affects the motion's adherence to physical constraints and overall quality.  Artifacts like the model's failure to maintain ground contact or to produce smooth, time-consistent movements are highlighted, illustrating the importance of each component in achieving realistic animations.", "section": "6.5 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2504.01204/x9.png", "caption": "Figure 8: Ablation study on the base video diffusion model.", "description": "This ablation study compares the performance of the proposed Articulated Kinematics Distillation (AKD) method using different video diffusion models.  Specifically, it contrasts AKD's results when using VideoCrafter and CogVideoX models.  The figure visually demonstrates the differences in motion quality, highlighting issues such as foot-skating and the generation of blurry artifacts.  The comparison also includes a result from a baseline method (TC4D) using CogVideoX, further illustrating the advantages of AKD.", "section": "6.5 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2504.01204/extracted/6328789/image/skeleton.png", "caption": "Figure 9: Ablation on the text-to-3D module. We extract an asset from TC4D and achieve a comparable appearance.", "description": "This ablation study investigates the impact of the text-to-3D module on the overall performance.  Instead of using the Tet-Splatting model, the authors extracted an asset directly from the TC4D method. The resulting appearance is compared to show the impact of choosing different text-to-3D generation methods on the final results.", "section": "6.5 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2504.01204/x10.png", "caption": "Figure 10: Gallery of skeleton systems from our experiments.", "description": "Figure 10 showcases a variety of skeleton structures used in the Articulated Kinematics Distillation (AKD) experiments.  These skeletons represent the underlying skeletal rigs that were created for different 3D animal and human-like models. The diversity in the skeletons highlights the adaptability of AKD to various character types and demonstrates the range of assets to which the system can be applied.", "section": "6.4 Synthesis Diversity"}]