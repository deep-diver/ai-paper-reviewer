{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a VLM widely used in the DGSS field for its image-text alignment capabilities, making it fundamental to this research."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-01-01", "reason": "This paper introduces MAE, a VFM, which is a powerful tool for image representation learning, contributing to the backbone of visual feature extraction in this study."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-01-01", "reason": "This paper introduces Mamba, the core technology utilized in the study's proposed fusion framework, MFuser, thus representing a key advancement in efficient sequence modeling."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-01-01", "reason": "This paper introduces DINOv2, a VFM used extensively in the experiments as a baseline and in conjunction with VLMs, highlighting its significance in capturing fine-grained features."}, {"fullname_first_author": "Bowen Cheng", "paper_title": "Masked-attention mask transformer for universal image segmentation", "publication_date": "2022-01-01", "reason": "This paper introduces Mask2Former, the segmentation pipeline upon which the proposed MFuser framework is built, showcasing its importance in class-aware feature refinement."}]}