[{"figure_path": "https://arxiv.org/html/2501.10120/x2.png", "caption": "Figure 1: Architecture of PaSa. The system consists of two LLM agents, Crawler and Selector. The Crawler processes the user query and can access papers from the paper queue. It can autonomously invoke the search tool, expand citations, or stop processing of the current paper. All papers collected by the Crawler are appended to the paper queue. The Selector reads each paper in the paper queue to determine whether it meets the criteria specified in the user query.", "description": "PaSa's architecture centers around two large language model (LLM) agents: the Crawler and the Selector.  The Crawler starts by processing a user's research query. It then autonomously interacts with search engines, retrieves papers, and expands its search by following citations.  All retrieved papers are added to a queue. The Selector then takes each paper from the queue and evaluates whether it matches the user's query criteria, effectively filtering results based on relevance.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.10120/x3.png", "caption": "Figure 2: An example of the PaSa workflow. The Crawler runs multiple [Search] using diverse and complementary queries. In addition, the Crawler can evaluate the long-term value of its actions. Notably, it discovers many relevant papers as it explores deeper on the citation network, even when intermediate papers along the path do not align with the user query.", "description": "The figure illustrates the PaSa system's workflow, focusing on the Crawler agent's actions. The Crawler uses multiple search queries (diverse and complementary) to retrieve papers. It also assesses the long-term impact of its actions and explores citation networks deeply to find relevant papers, even if some intermediate papers aren't directly related to the user's query.", "section": "4 Methodology"}, {"figure_path": "https://arxiv.org/html/2501.10120/x4.png", "caption": "Figure 3: Return and value function loss curves during the PPO training process. The smoothing method of the curve in the figures is the exponential moving average(EMA) formula that aligns with the one used in TensorBoard, and the smoothing weight is set to 0.95.", "description": "This figure displays the return and value function loss curves throughout the Proximal Policy Optimization (PPO) training process.  The curves are smoothed using an exponential moving average (EMA) method, with a smoothing weight of 0.95, consistent with the smoothing technique used in TensorBoard.  The x-axis represents training steps, while the y-axis shows the return and value function loss.", "section": "Methodology"}]