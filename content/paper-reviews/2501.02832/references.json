{"references": [{"fullname_first_author": "Alex Graves", "paper_title": "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks", "publication_date": "2006-01-01", "reason": "This paper is foundational for modern end-to-end speech recognition systems by introducing Connectionist Temporal Classification (CTC), a crucial technique that addressed the challenges of aligning unsegmented speech signals with text."}, {"fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "publication_date": "2022-01-01", "reason": "This work pushed the boundaries of speech recognition by introducing Whisper, a highly successful transformer-based multilingual and multitask model that achieved state-of-the-art performance."}, {"fullname_first_author": "Albert Gu", "paper_title": "Efficiently modeling long sequences with structured state spaces", "publication_date": "2022-01-01", "reason": "This paper introduced the foundation of structured state-space models (SSMs), which are fundamental to the Mamba architecture used in the Samba-ASR model described in the target paper, offering an efficient alternative to traditional self-attention methods."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2024-01-01", "reason": "This paper introduced the Mamba architecture, a crucial component of the Samba-ASR model, showcasing significant advancements in efficient sequence modeling and addressing some key limitations of previous state-space models."}, {"fullname_first_author": "Guoguo Chen", "paper_title": "Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio", "publication_date": "2021-01-01", "reason": "This work created the Gigaspeech dataset, a large-scale speech corpus that played a crucial role in the training and evaluation of the Samba-ASR model, contributing significantly to the model's robustness and improved performance across various speech domains."}]}