[{"figure_path": "https://arxiv.org/html/2502.14282/x1.png", "caption": "Figure 1: Illustration of the complexity of the PC scenario: (1) Complex interactive environment with dense and diverse elements. (2) Long and complex task sequences containing intra- and inter-software workflows.", "description": "Figure 1 illustrates the challenges posed by the PC environment for automated task completion, contrasting it with simpler smartphone interfaces.  The figure highlights two key aspects: (1) The PC GUI presents a significantly more complex visual landscape, characterized by a high density and variety of interactive elements (icons, widgets, text layouts) compared to the relatively simpler arrangement on smartphones. This density and diversity pose a substantial challenge for accurate screen perception and understanding by AI agents. (2) Tasks on PCs typically involve considerably more complex sequences of operations spanning multiple applications. These sequences are not only longer but also exhibit strong interdependencies between individual subtasks, meaning the successful completion of one step is often crucial to the success of subsequent steps.  This high degree of complexity makes automated task completion significantly more challenging than for similar tasks on smartphones.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2502.14282/x2.png", "caption": "Figure 2: Overview of the proposed PC-Agent, which decomposes the decision-making process into three levels.\nThe orange lines denote the top-down decision-making decomposition, and the purple lines represent the bottom-up reflection process.", "description": "The figure illustrates the hierarchical structure of PC-Agent, a multi-agent system designed for complex task automation on PCs.  It shows how the system decomposes the decision-making process into three levels: instruction, subtask, and action.  The orange lines represent the top-down decomposition of a user's instruction into manageable subtasks, while the purple lines depict the bottom-up feedback mechanism provided by the Reflection Agent, which monitors the execution and provides error correction and adjustment. The figure highlights the collaboration between the Manager Agent, Progress Agent, and Decision Agent at each level to ensure smooth task completion.", "section": "2 PC-Agent"}, {"figure_path": "https://arxiv.org/html/2502.14282/x3.png", "caption": "Figure 3: Illustration of the active perception module.\nFor interactive elements, the A11y tree is adopted to obtain the bounding boxes and functional information.\nFor text, an intention understanding agent and an OCR tool are utilized to perform precise selecting or editing.", "description": "This figure illustrates the PC-Agent's Active Perception Module (APM), a key component for handling complex interactive environments on a PC.  The APM uses two main approaches for perception:  For interactive GUI elements (buttons, menus, etc.), it leverages the accessibility tree (A11y tree) to extract precise bounding boxes and functional descriptions. This allows the agent to accurately locate and interact with these elements.  For text-based elements, the APM employs a two-step process. First, an intention understanding agent processes the user's request to identify the target text. Second, an OCR (Optical Character Recognition) tool is used to precisely locate and extract the identified text from the screen. This dual approach enables accurate text selection and editing operations.", "section": "2 PC-Agent"}, {"figure_path": "https://arxiv.org/html/2502.14282/x4.png", "caption": "Figure 4: A case of searching for information multiple times and build an Excel sheet accordingly.", "description": "This figure demonstrates the PC-Agent's workflow for a complex task involving multiple applications.  The user instruction is to find stock prices for Nvidia, Apple, and Microsoft, then create an Excel sheet with this data. The diagram shows the agent breaking this task into subtasks: searching for each stock price on Chrome, and then populating the Excel sheet.  The communication hub facilitates passing data between subtasks. The visualization highlights the agent's ability to handle multi-step, multi-application tasks and demonstrate the process of data exchange between subtasks using a communication hub.", "section": "2 PC-Agent"}, {"figure_path": "https://arxiv.org/html/2502.14282/x5.png", "caption": "Figure 5: A case of reflection when performing multiple successive searches in Chrome.", "description": "This figure illustrates the PC-Agent's reflection mechanism in action. During a multi-step process involving successive searches on Chrome, an error occurs. The Reflection Agent (RA) detects this error by comparing screenshots before and after the action. This feedback is then used to adjust the subsequent actions.  The figure visually demonstrates how the system corrects itself by opening a new tab using a shortcut, effectively handling and recovering from an incorrect action that did not produce the expected result.", "section": "2.4 Reflection-based Dynamic Decision-making"}, {"figure_path": "https://arxiv.org/html/2502.14282/x6.png", "caption": "Figure 6: A case of refined text editing operations in the Word application.", "description": "This figure showcases the PC-Agent's ability to perform precise text manipulations within a Word document.  It demonstrates the effectiveness of the Active Perception Module (APM) in identifying and targeting specific text elements for operations such as centering the title and underlining the last paragraph.  The detailed steps involved highlight the agent's capability to handle complex GUI interactions and carry out precise operations that require fine-grained control.", "section": "2.3 Hierarchical Multi-agent Collaboration"}, {"figure_path": "https://arxiv.org/html/2502.14282/x7.png", "caption": "Figure 7: Example screenshots from the GUI grounding dataset we built for commonly used applications in PC scenarios.", "description": "This figure displays example screenshots from a GUI grounding dataset. The dataset was created by the authors and contains screenshots of common PC applications (such as File Explorer, Chrome, Outlook, Excel, and Word) showcasing various interactive elements.  The purpose is to illustrate the complexity and diversity of the graphical user interfaces (GUIs) in a typical PC environment, emphasizing the challenges in building robust and accurate GUI agents. The screenshots show different actions and highlighted elements in these applications that are part of the grounding task.", "section": "2 PC-Agent"}]