[{"heading_title": "SoS1: O1-R1 LLMs", "details": {"summary": "The paper **introduces SoS-1K**, a novel dataset designed to evaluate the mathematical reasoning capabilities of Large Language Models (LLMs) specifically in the domain of sum-of-squares (SoS) problems. It investigates whether LLMs can determine if a given multivariate polynomial is nonnegative, a computationally intractable problem with applications in various fields. The research further explores whether the **promise of test-time scaling** can extend to research-level mathematics, an area largely unexplored. It is designed to probe the capacity of LLMs like Openai 01 and DeepSeek-R1 to solve large-scale SoS programming problems. This involves a carefully constructed dataset of approximately 1,000 polynomials, accompanied by expert-designed reasoning-guiding instructions based on five progressively challenging criteria and is aimed at pushing mathematical reasoning of LLMs."}}, {"heading_title": "NP-Hard SoS-1K", "details": {"summary": "**SoS-1K addresses the NP-hard problem** of determining polynomial non-negativity. **Directly tackling NP-hard challenges** positions LLMs at the forefront of mathematical problem-solving. The implication is **LLMs can be used in traditionally intractable optimization problems**. The '1K' suggests a dataset scale aiming to stress-test LLMs beyond toy examples, **benchmarking their ability in realistic problems**. This is because real-world mathematical problems often have an NP-hard structure. The use of **SoS offers a structured path** through the complexity, guiding the LLMs with a mathematically principled approach. **This shows how LLMs can handle a specific class of NP-hard problems**, which is the one that is related to sum of squares."}}, {"heading_title": "LLMs for SoS?", "details": {"summary": "The paper investigates the potential of **Large Language Models (LLMs) in tackling Sum of Squares (SoS) problems**, a computationally challenging area within polynomial optimization closely related to Hilbert's Seventeenth Problem.  The research introduces SoS-1K, a curated dataset of approximately 1,000 polynomials designed to evaluate LLMs' reasoning abilities. The study reveals that **LLMs struggle with SoS problems without explicit, structured guidance**, highlighting the importance of high-quality, expert-designed instructions. A key finding is that providing LLMs with detailed reasoning traces significantly improves accuracy, demonstrating their latent capacity for mathematical reasoning when effectively prompted. Furthermore, the research shows that **fine-tuning a smaller 7B model on the SoS-1K dataset can outperform much larger models like DeepSeek-V3 and GPT-40-mini in accuracy and computation time**, suggesting potential for efficient application of LLMs in mathematical problem-solving."}}, {"heading_title": "Reasoning boost", "details": {"summary": "**Reasoning boost** in LLMs is pivotal for tackling complex mathematical tasks like determining if a multivariate polynomial is a sum of squares (SoS). The study reveals that without structured guidance, LLMs perform poorly. High-quality reasoning instructions significantly improve accuracy, boosting performance considerably. This suggests LLMs possess underlying knowledge but need structured instructions to retrieve and apply it effectively. Reasoning-focused LLMs generally outperform general-purpose ones, emphasizing the importance of reasoning capabilities. Higher-capacity models require fewer thinking tokens, while lower-capacity models need more reasoning steps to achieve optimal performance. Supervised fine-tuning further enhances accuracy and reduces response times, highlighting the potential of LLMs to push mathematical reasoning boundaries and tackle NP-hard problems."}}, {"heading_title": "Future of AI SoS", "details": {"summary": "The \"Future of AI SoS\" is ripe with potential, especially considering the advancements highlighted in the paper. **AI's role in Sum-of-Squares (SoS) problem-solving could revolutionize mathematical research**, making NP-hard problems more tractable. Future research should focus on enhancing LLMs' reasoning capabilities further, perhaps by incorporating more structured knowledge or developing specialized architectures. **The trend of test-time scaling shows promise**, suggesting that LLMs can generate more complex solutions with additional computational resources. Addressing current limitations, such as handling longer polynomials and ensuring the validity of LLM decisions, is crucial. **Datasets like SoS-1K serve as valuable benchmarks**, but expanding them to encompass even more challenging problems will be essential. The potential for AI to not only solve but also generate new mathematical insights, as demonstrated by Qwen-14B-1M's NNSoS example, signals a paradigm shift in mathematical exploration. However, **ethical considerations regarding AI's role in mathematical discovery** needs careful consideration to ensure credibility."}}]