{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-15", "reason": "This paper provides technical details about the GPT-4 model which the proposed approach relies upon."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual Instruction Tuning", "publication_date": "2023-01-01", "reason": "This paper describes visual instruction tuning, a technique to boost performance on multimodal tasks."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is All You Need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture which is fundamental to the current developments in LLMs."}, {"fullname_first_author": "Yi Wang", "paper_title": "InternVideo2: Scaling Foundation Models for Multimodal Video Understanding", "publication_date": "2024-01-01", "reason": "This paper describes models and capabilities for video understanding, something the PVChat paper builds upon."}, {"fullname_first_author": "Zhen Li", "paper_title": "PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding", "publication_date": "2024-01-01", "reason": "This paper presents a method for customizing realistic human photos, an approach used in PVChat to create personalized training data."}]}