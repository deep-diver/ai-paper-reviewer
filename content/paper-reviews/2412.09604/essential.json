{"importance": "**Unified MLLMs** for image understanding and generation are trending, but face challenges like **training complexity and limited scalability**. This paper's novel architecture and training strategy offers a **simpler, more efficient approach**, potentially influencing future MLLM development and opening new research avenues in multimodal learning and high-resolution image processing within LLMs.", "summary": "SynerGen-VL: A simpler, more powerful unified MLLM for image understanding and generation.", "takeaways": ["SynerGen-VL, an encoder-free MLLM, achieves comparable performance to larger models in both image understanding and generation.", "Token folding enables efficient processing of high-resolution images within the MLLM framework.", "Progressive alignment pre-training maintains pre-trained knowledge while incorporating visual capabilities effectively, simplifying training and improving performance"], "tldr": "Existing unified Multimodal Large Language Models (MLLMs) often struggle with complex architectures and training pipelines, limiting scalability. This is especially problematic when dealing with high-resolution images due to the long visual token sequences generated by current visual tokenizers.  Moreover, integrating visual capabilities into large language models often disrupt the models\u2019 pre-trained knowledge, affecting general perception and generalization capabilities.\nThis paper introduces **SynerGen-VL**, a new unified MLLM for both image understanding and generation using a simple next-token prediction framework. SynerGen-VL incorporates **token folding** to handle high-resolution images efficiently and **vision experts** to integrate visual capabilities into pre-trained LLMs. A **progressive alignment pre-training strategy** is used to preserve the LLM's knowledge while incorporating visual features. Experimental results show that SynerGen-VL achieves strong performance on various benchmarks with a smaller model size compared to existing MLLMs.", "affiliation": "Tsinghua University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2412.09604/podcast.wav"}