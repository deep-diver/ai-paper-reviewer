{"importance": "This paper is important for researchers as it presents a novel method for creating **high-fidelity, real-time full-body talking avatars**, addressing the limitations of existing methods. The new dataset will help advance research, and the potential applications, especially in AR, are significant. This work opens avenues for future research in efficient avatar rendering and animation.", "summary": "TaoAvatar: Lifelike talking avatars in AR, using 3D Gaussian Splatting for real-time rendering and high fidelity.", "takeaways": ["Introduces a teacher-student framework for creating lightweight, high-fidelity 3DGS-based full-body talking avatars.", "Proposes non-rigid deformation baking and lightweight blend shape compensations for efficient rendering on mobile and AR devices.", "Contributes a new multi-view dataset, TalkBody4D, for full-body talking scenarios with diverse expressions and gestures."], "tldr": "Creating realistic 3D talking avatars is crucial for AR/VR applications. Existing methods struggle with fine-grained control of facial expressions and body movements, lack sufficient detail, and can't run in real-time on mobile devices. Current solutions are also depend on high-precision scans and manual effort.\n\nThis paper presents TaoAvatar, a new method using **3D Gaussian Splatting** for high-fidelity, lightweight full-body talking avatars. It employs a teacher-student framework for non-rigid deformation baking and introduces lightweight blend shapes for efficient rendering on mobile devices. The authors also introduce TalkBody4D, a new dataset for full-body talking scenarios.", "affiliation": "Alibaba Group", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.17032/podcast.wav"}