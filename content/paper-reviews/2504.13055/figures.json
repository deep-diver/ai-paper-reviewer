[{"figure_path": "https://arxiv.org/html/2504.13055/x3.png", "caption": "Figure 1: Accuracy improvement over the baseline model (Qwen2.5-VL-7B-Instruct) on out-of-domain benchmarks covering both reasoning and perception tasks. Both Qwen2.5-VL-GRPO-7B and NoisyRollout-7B are fine-tuned by ourselves (denoted with \u2021\u2021\\ddagger\u2021) using GRPO with 2.12.12.12.1K training samples from Geometry3K. The exact accuracy of NoisyRollout-7B is annotated above each corresponding bar in parentheses.", "description": "This figure presents a bar chart comparing the accuracy improvements of different vision-language models on five out-of-domain benchmark datasets.  The baseline model is Qwen2.5-VL-7B-Instruct. The chart shows the performance gains achieved by various models, including Qwen2.5-VL-GRPO-7B and the proposed NoisyRollout-7B, which were both fine-tuned using the Geometry3K dataset. The y-axis represents the percentage improvement over the baseline, while the x-axis shows the different benchmark datasets, each testing a combination of reasoning and visual perception capabilities.  The exact accuracy of the NoisyRollout-7B model on each benchmark is provided in parentheses above each bar.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13055/x4.png", "caption": "Figure 2: Illustration of our NoisyRollout workflow. Solid lines denote the standard GRPO process, while dashed lines depict the generation and use of noisy rollouts from distorted images. KL divergence loss is omitted as discussed in Section\u00a02. The terms {\ud835\udc28i}i=1n1+n2superscriptsubscriptsubscript\ud835\udc28\ud835\udc56\ud835\udc561subscript\ud835\udc5b1subscript\ud835\udc5b2\\{\\mathbf{o}_{i}\\}_{i=1}^{n_{1}+n_{2}}{ bold_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, {ri}i=1n1+n2superscriptsubscriptsubscript\ud835\udc5f\ud835\udc56\ud835\udc561subscript\ud835\udc5b1subscript\ud835\udc5b2\\{r_{i}\\}_{i=1}^{n_{1}+n_{2}}{ italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, and {Ai}i=1n1+n2superscriptsubscriptsubscript\ud835\udc34\ud835\udc56\ud835\udc561subscript\ud835\udc5b1subscript\ud835\udc5b2\\{A_{i}\\}_{i=1}^{n_{1}+n_{2}}{ italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT represent mixed trajectories, rewards, and normalized advantages, respectively, with n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT from clean inputs and n2subscript\ud835\udc5b2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT from noisy inputs. (I,\ud835\udc2a)\ud835\udc3c\ud835\udc2a(I,\\mathbf{q})( italic_I , bold_q ) and (I~,\ud835\udc2a)~\ud835\udc3c\ud835\udc2a(\\tilde{I},\\mathbf{q})( over~ start_ARG italic_I end_ARG , bold_q ) denote clean and noisy inputs where I~=T\u03b1t\u2062(I)~\ud835\udc3csubscript\ud835\udc47subscript\ud835\udefc\ud835\udc61\ud835\udc3c\\tilde{I}=T_{\\alpha_{t}}(I)over~ start_ARG italic_I end_ARG = italic_T start_POSTSUBSCRIPT italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_I ) applies a distortion with strength \u03b1tsubscript\ud835\udefc\ud835\udc61\\alpha_{t}italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The distortion level \u03b1tsubscript\ud835\udefc\ud835\udc61\\alpha_{t}italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is determined by a noise annealing schedule \u03b7\u2062(\u22c5)\ud835\udf02\u22c5\\eta(\\cdot)italic_\u03b7 ( \u22c5 ), which gradually reduces distortion over the training process. Only clean inputs are used for policy optimization in RL.", "description": "Figure 2 illustrates the NoisyRollout workflow, enhancing visual reasoning in vision-language models (VLMs) through reinforcement learning.  Solid lines represent the standard Group Relative Policy Optimization (GRPO) process. Dashed lines show the addition of noisy rollouts generated from distorted images.  The noisy rollouts contribute to the reward baseline and advantage calculations but are not directly used in policy updates, improving exploration without extra training cost.  A noise annealing schedule gradually reduces the image distortion strength over training, ensuring stability and scalability. This approach combines trajectories from both clean and noisy inputs to enhance the exploration capability of the model and improve robustness.", "section": "2 NoisyRollout: A Free-Lunch with Noisy Reinforcement Learning"}, {"figure_path": "https://arxiv.org/html/2504.13055/x5.png", "caption": "Figure 3: Comparison of NoisyRollout and vanilla GRPO across in-domain and out-of-domain scenarios with the same total rollout number (12121212). The X-axis in all plots represents RL training steps. First column: Reward comparison on the in-domain dataset during training. Second and third columns: Comparison on four out-of-domain visual reasoning benchmarks. Last column: Evaluation of perception capabilities, where the upper subplot directly compares their perception performance on HallusionBench and the lower subplot presents the model-ranked Bradley\u2013Terry win rates w.r.t.\u00a0the perception qualities of their reasoning traces during training.", "description": "Figure 3 presents a comprehensive comparison of NoisyRollout and vanilla GRPO across both in-domain and out-of-domain scenarios.  All experiments used the same total rollout number (12). The x-axis consistently shows RL training steps. The first column displays a comparison of rewards obtained during training on the in-domain dataset. The second and third columns showcase a comparison of performance across four separate out-of-domain visual reasoning benchmarks. Finally, the last column evaluates the perception capabilities of both models. This is accomplished in two ways: the top subplot shows a direct comparison of perception performance on HallucinationBench, while the lower subplot uses model-ranked Bradley-Terry win rates to assess perception quality based on the reasoning traces generated during training. ", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13055/x6.png", "caption": "Figure 4: Comparison of accuracy and diversity metrics (%) across RL training steps (00 to 40404040). The left two subfigures contrast NoisyRollout versus vanilla GRPO (both with temperature 1.01.01.01.0), while the right two demonstrate the effects of different temperature settings (0.80.80.80.8, 1.01.01.01.0, 1.21.21.21.2) on vanilla GRPO.", "description": "Figure 4 presents a detailed comparison of the performance of NoisyRollout and vanilla GRPO across different RL training steps (0 to 40).  The left two subplots show a direct comparison between NoisyRollout and vanilla GRPO, both using a temperature of 1.0 during the rollout process.  These plots illustrate the changes in accuracy and rollout diversity over training. The right two subplots showcase how different temperature settings (0.8, 1.0, and 1.2) affect vanilla GRPO's performance and diversity.  By comparing these plots, one can observe how NoisyRollout manages to achieve comparable or better accuracy while maintaining a higher rollout diversity, suggesting that it has superior exploration capabilities.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13055/x7.png", "caption": "Figure 5: Comparison of NoisyRollout w. and w.o. noise annealing, and vanilla GRPO in terms of training dynamics (policy clip fraction and training reward) and accuracy on the in-domain test set.", "description": "Figure 5 presents a detailed comparison of three reinforcement learning (RL) approaches for fine-tuning vision-language models: NoisyRollout with and without noise annealing, and vanilla GRPO.  It illustrates training dynamics by plotting policy clip fraction and training reward against training steps, giving insights into the stability and effectiveness of each method. The figure also displays in-domain test set accuracy for each approach over the training period, demonstrating how the models' performance on the target task changes as training progresses. This allows for a comprehensive assessment of the training stability and overall performance of each RL method.", "section": "3.2 Ablation Study: More Effective Rollout Diversity with Noisy Trajectories"}, {"figure_path": "https://arxiv.org/html/2504.13055/x8.png", "caption": "Figure 6: Illustration of visual degradation under increasing Gaussian noise steps.", "description": "This figure visualizes the effect of applying different levels of Gaussian noise to a clean image.  It shows how increasing the noise level (noise step) leads to a progressive degradation of the image quality, making the details of the image increasingly difficult to discern. The figure aids in illustrating the impact of noisy input trajectories on the overall visual reasoning process of vision-language models. This type of noisy input is used in the NoisyRollout approach.", "section": "3.4 Unsuccessful Attempts"}, {"figure_path": "https://arxiv.org/html/2504.13055/x9.png", "caption": "Figure 7: Case study showcasing improved perception capability of NoisyRollout compared to vanilla GRPO.", "description": "This figure presents a comparative case study demonstrating the enhanced visual perception capabilities of the NoisyRollout method.  It compares the reasoning processes and final answers of both NoisyRollout and vanilla GRPO when responding to a question about the relative lengths of lines in an image. The step-by-step reasoning for each method is displayed, revealing how NoisyRollout meticulously analyzes the image components (lines and segments) leading to an accurate determination of line length. Conversely, vanilla GRPO shows a tendency to oversimplify or misinterpret the visual information, resulting in an incorrect answer. This case study visually underscores the effectiveness of NoisyRollout in improving the accuracy of visual information extraction and leading to improved reasoning performance.", "section": "3.4 Unsuccessful Attempts"}, {"figure_path": "https://arxiv.org/html/2504.13055/x10.png", "caption": "Figure 8: Case study illustrating enhanced reasoning capability of NoisyRollout over vanilla GRPO.", "description": "This figure presents a case study comparing the reasoning capabilities of NoisyRollout and vanilla GRPO.  It shows how NoisyRollout correctly reasons through a geometry problem by accurately interpreting and using visual information from the diagram, while vanilla GRPO makes an error due to inaccurate visual perception. The problem involves determining the perimeter of a triangle within a larger diagram given specific conditions (equal lengths, angle bisector).  NoisyRollout demonstrates improved accuracy by correctly identifying and utilizing the relevant visual information in its reasoning steps, leading to the correct answer. In contrast, vanilla GRPO's reasoning is flawed due to an incorrect interpretation of the diagram, which leads it to an incorrect solution.", "section": "3.4 Unsuccessful Attempts"}]