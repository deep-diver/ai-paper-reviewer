{"references": [{"fullname_first_author": "Lihe Yang", "paper_title": "Depth Anything: Unleashing the power of large-scale unlabeled data", "publication_date": "2024-01-01", "reason": "This paper introduces the Depth Anything model, which serves as the foundation for the proposed Prompt Depth Anything method by prompting it with metric information from LiDAR."}, {"fullname_first_author": "Jonathan T. Barron", "paper_title": "Zip-NeRF: Anti-aliased grid-based neural radiance fields", "publication_date": "2023-01-01", "reason": "Zip-NeRF is used to generate pseudo ground truth depth data for training, addressing the limitations of real-world datasets with imprecise depth annotations, therefore is critical for accurate metric depth estimation."}, {"fullname_first_author": "Ren\u00e9 Ranftl", "paper_title": "Vision Transformers for Dense Prediction", "publication_date": "2021-01-01", "reason": "This paper introduces the DPT architecture, which is the underlying architecture for the Depth Anything model and many other models compared against so it's critical to how these visual transformers are utilized in the task of metric depth estimation."}, {"fullname_first_author": "Gilad Baruch", "paper_title": "ARKitScenes: A Diverse Real-World Dataset for 3D Indoor Scene Understanding Using Mobile RGB-D Data", "publication_date": "2021-01-01", "reason": "ARKitScenes is a primary dataset used for evaluation and training in this work, supplying mobile RGB-LiDAR data which focuses the impact of the proposed method."}, {"fullname_first_author": "Chandan Yeshwanth", "paper_title": "ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes", "publication_date": "2023-01-01", "reason": "ScanNet++ is a primary dataset used for training and evaluation in this work, especially providing training data for real-world LiDAR and annotated depth which allows more specific training than purely synthetic data."}]}