{"importance": "This paper introduces a novel paradigm shift in **metric depth estimation by prompting depth foundation models**, like using a low-cost LiDAR sensor as a guide.  This approach simplifies metric depth acquisition and offers a practical solution for applications like robotics and 3D reconstruction. The **scalable data pipeline** proposed also addresses the challenge of limited training data, enabling more robust training of depth estimation models. It opens new research avenues in prompt engineering for depth foundation models and using readily available, low-cost sensors for high-quality depth perception.", "summary": "Prompting unlocks 4K metric depth from low-cost LiDAR.", "takeaways": ["Introduced \"Prompt Depth Anything,\" a new paradigm for metric depth estimation using prompted foundation models and low-cost LiDAR.", "Developed a concise prompt fusion architecture, scalable data pipeline, and edge-aware loss to enable highly accurate 4K depth estimation.", "Achieved state-of-the-art performance and demonstrated benefits in 3D reconstruction and robotic grasping applications. "], "tldr": "**Monocular depth estimation** has seen advancements with depth foundation models, offering high-quality relative depth. However, they suffer from **scale ambiguity, hindering real-world applications** like autonomous driving and robotics that need accurate metric depth.  Existing methods, including finetuning on metric datasets or incorporating camera intrinsics, haven't fully solved the problem of **inconsistent and inaccurate scale**. \n\nThis paper introduces **\"Prompt Depth Anything,\"** a new paradigm using a **low-cost LiDAR as a prompt** to guide a depth foundation model.  A **concise prompt fusion architecture** integrates LiDAR at multiple scales within the depth decoder.  To address the scarcity of training data with both LiDAR and precise ground truth, the authors propose a **scalable data pipeline** that simulates LiDAR for synthetic data and generates pseudo ground truth for real data using 3D reconstruction and an **edge-aware loss**.  The method achieves **state-of-the-art results** and benefits 3D reconstruction and robotic grasping.", "affiliation": "Zhejiang University", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2412.14015/podcast.wav"}