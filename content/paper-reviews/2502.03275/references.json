{"references": [{"fullname_first_author": "Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting method, which is a core concept explored and improved upon in the target paper."}, {"fullname_first_author": "Nye", "paper_title": "Show your work: Scratchpads for intermediate computation with language models", "publication_date": "2021-12-01", "reason": "This paper is highly influential as it demonstrates the effectiveness of providing intermediate reasoning steps to improve LLM reasoning, a concept directly relevant to the target paper's approach."}, {"fullname_first_author": "Deng", "paper_title": "Implicit chain of thought reasoning via knowledge distillation", "publication_date": "2023-11-01", "reason": "This paper tackles the computational cost of chain-of-thought prompting, which is a key challenge addressed by the target paper's proposed method of using latent tokens."}, {"fullname_first_author": "Hao", "paper_title": "Training large language models to reason in a continuous latent space", "publication_date": "2024-12-01", "reason": "This paper explores reasoning in latent space, providing a related approach that the target paper builds upon and improves with its discrete latent tokens."}, {"fullname_first_author": "Jiang", "paper_title": "Forward-backward reasoning in large language models for mathematical verification", "publication_date": "2024-07-01", "reason": "This paper focuses on mathematical reasoning, a key domain where the target paper demonstrates improved performance, making it a highly relevant reference for the specific benchmarks used."}]}