[{"figure_path": "https://arxiv.org/html/2412.14922/x3.png", "caption": "Figure 1: Impact of noisy data on LLM performance during SFT. Increasing noise levels deteriorates model performance, highlighting the critical need for noise-robust fine-tuning approaches.", "description": "The figure illustrates how increasing noise in training data significantly reduces the performance of Large Language Models (LLMs) after supervised fine-tuning (SFT).  The x-axis represents the percentage of noise in the training data, while the y-axis shows the resulting performance on the MMLU benchmark. As noise increases from 30% to 70%, the LLM's performance on MMLU drops substantially, emphasizing the need for developing noise-robust fine-tuning techniques.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2412.14922/x4.png", "caption": "Figure 2: Overview of RobustFT. Our RobustFT enhances model performance through a two-stage noise detection-and-denoising framework, leveraging collaborative learning among expert LLMs for noise detection and context-enhanced reasoning for data denoising, ultimately enabling robust downstream fine-tuning.", "description": "Figure 2 illustrates the RobustFT framework's two-stage process for handling noisy data in downstream fine-tuning tasks.  The first stage is noise detection, which uses a collaborative learning approach involving multiple expert LLMs to identify potentially noisy samples.  The second stage is denoising, employing context-enhanced reasoning with cleaner samples to relabel identified noisy samples, ensuring high-quality data for subsequent fine-tuning.  The process improves overall model robustness and performance on downstream tasks.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2412.14922/x5.png", "caption": "Figure 3: Sensitivity analysis on MMLU under different \u03b2\ud835\udefd\\betaitalic_\u03b2 and k\ud835\udc58kitalic_k with varying noise levels.", "description": "This figure presents a sensitivity analysis of the ROBUSTFT model's performance on the MMLU benchmark under different noise levels.  It investigates the impact of two hyperparameters: \u03b2 (beta), which controls the selection ratio of confident samples after the denoising process, and k, representing the number of context samples used in the context-enhanced reasoning for data relabeling. The analysis examines how the accuracy changes across various combinations of these hyperparameters and noise levels (30%, 50%, and 70%), providing insights into their optimal settings for robust performance.", "section": "4.3.2 Sensitivity Analysis"}, {"figure_path": "https://arxiv.org/html/2412.14922/x6.png", "caption": "Figure 4: Perplexity analysis of RobustFT on MMLU and ARC with varying noise levels.", "description": "This figure displays the perplexity scores generated by the RobustFT model and the standard supervised fine-tuning (SFT) model on the MMLU and ARC datasets at various noise levels (30%, 50%, and 70%). Perplexity is a measure of how well a probability model predicts a sample. Lower perplexity indicates better prediction and therefore less uncertainty by the model. The figure illustrates how the RobustFT model maintains lower perplexity scores compared to the SFT model, especially as noise levels increase. This demonstrates RobustFT's ability to handle noisy data effectively and generate more confident predictions.", "section": "4.3.3 Perplexity Analysis"}, {"figure_path": "https://arxiv.org/html/2412.14922/x7.png", "caption": "Figure 5: Category-wise performance of RobustFT.", "description": "This figure shows a radar chart comparing the performance of RobustFT and standard SFT across various categories within the MMLU benchmark dataset under different noise levels (30%, 50%, and 70%). Each axis represents a category (e.g., economics, computer science, health, etc.), and the length of each line from the center indicates the model's accuracy in that specific category. The chart visually demonstrates RobustFT's superior and more consistent performance compared to the standard SFT approach across all categories, especially when dealing with noisy data. It highlights RobustFT's ability to maintain accuracy in multiple domains compared to SFT, which shows significant drops in performance.", "section": "4.3 Category-wise Performance Analysis"}, {"figure_path": "https://arxiv.org/html/2412.14922/x8.png", "caption": "Figure 6: Stability analysis on MMLU and ARC.", "description": "This figure displays the results of a stability analysis performed on the MMLU and ARC datasets.  The analysis assesses the robustness of the ROBUSTFT model to variations in input instructions by rephrasing them five times using GPT-4. The figure shows the mean accuracy and standard deviation for both datasets across various noise levels (30%, 50%, 70%), demonstrating the model's consistent performance even with instruction variations.", "section": "4.3.5 Stability Analysis"}]