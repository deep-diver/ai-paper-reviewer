[{"figure_path": "https://arxiv.org/html/2503.18940/x1.png", "caption": "Figure 1: Comparison of sampling strategies in our framework. (i) Standard Sampling. (ii) Our Bottleneck Sampling: a high-low-high workflow that captures semantics early, improves efficiency in the middle, and restores details at the end. Images generated by FLUX.1-dev using the prompt: \u201cDesign a stylish dancer\u2019s back logo with the letters \u2019R\u2019 and \u2019Y\u2019\u201d.", "description": "This figure compares two image generation sampling methods: standard sampling and the proposed Bottleneck Sampling. Standard sampling processes the image at full resolution throughout the generation process.  Bottleneck sampling uses a three-stage approach: 1) initial high-resolution denoising to establish semantic information; 2) intermediate lower-resolution denoising for improved efficiency; and 3) final high-resolution denoising to restore fine details.  The example images were generated using the FLUX.1-dev model with the prompt \"Design a stylish dancer's back logo with the letters 'R' and 'Y'\".  This illustrates how Bottleneck Sampling can improve efficiency without significant loss of image quality.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.18940/x2.png", "caption": "Figure 2: Main Results of our Bottleneck Sampling on both text-to-image generation and text-to-video generation. Bottleneck Sampling maintains comparable performance with a 2.5 - 3 \u00d7\\times\u00d7 acceleration ratio in a training-free manner.", "description": "This figure shows the results of applying Bottleneck Sampling to both image and video generation tasks using the FLUX-1-dev and Hunyuan Video models, respectively.  The left panel demonstrates that Bottleneck Sampling achieves 3x speedup in image generation compared to standard sampling while maintaining comparable image quality.  The right panel shows that it achieves 2.5x speedup in video generation, again without significant loss of quality. This is notable because the method is training-free, meaning that it does not require retraining the models to achieve this speed improvement.", "section": "Main Results"}, {"figure_path": "https://arxiv.org/html/2503.18940/x3.png", "caption": "Figure 3: Overall pipeline of our Bottleneck Sampling. The process consists of three stages: (i) High-Resolution Denoising to preserve semantic information, (ii) Low-Resolution Denoising to improve efficiency, and (iii) High-Resolution Denoising to restore fine details. Images generated by FLUX.1-dev using the prompt: \u201c2D cartoon,Diagonal composition, Medium close-up, a whole body of a classical doll being held by a hand, the doll of a young boy with white hair dressed in purple, He has pale skin and white eyes.\u201d.", "description": "Bottleneck Sampling is a three-stage process.  Stage 1 uses high resolution to preserve important semantic information in the early denoising steps. Stage 2 switches to a lower resolution for the intermediate denoising steps, significantly improving efficiency. Finally, Stage 3 returns to high resolution to restore fine details in the final denoising steps. This figure shows the workflow visually with example images generated from the prompt: \u201c2D cartoon, Diagonal composition, Medium close-up, a whole body of a classical doll being held by a hand, the doll of a young boy with white hair dressed in purple, He has pale skin and white eyes.\u201d using FLUX.1-dev.", "section": "3.2. Bottleneck Sampling"}, {"figure_path": "https://arxiv.org/html/2503.18940/x4.png", "caption": "Figure 4: Timestep Shifting Visualization at different shifting factors settings. Higher shifting scales lead to denoising in higher-noise regions", "description": "This figure visualizes how the denoising process in diffusion models is affected by different \"shifting factors.\"  In diffusion models, the denoising process happens across many timesteps, starting from pure noise and gradually revealing the generated image or video.  The x-axis represents the original timestep, while the y-axis shows the modified timestep after the shift is applied.  Higher shifting factors concentrate the denoising towards the later timesteps (higher noise levels) resulting in less denoising at the beginning of the process. This strategy is beneficial for improving generation quality, as discussed in the paper. Each curve represents a different shifting factor, showing how the amount of shift changes the denoising schedule.", "section": "3.3. Overall Algorithm of Bottleneck Sampling"}, {"figure_path": "https://arxiv.org/html/2503.18940/x5.png", "caption": "Figure 5: Qualitative comparison of our Bottleneck Sampling with FLUX.1-dev. Our method achieves up tp 3\u00d7\\times\u00d7 speedup while maintaining or improving visual fidelity. Incorrect text rendering and anatomical inconsistencies are highlighted with different colors. Full prompts are provided in Appendix\u00a0E.", "description": "Figure 5 showcases a qualitative comparison between image generation results from the standard FLUX.1-dev model and the proposed Bottleneck Sampling method.  It demonstrates that Bottleneck Sampling achieves up to 3x speedup without sacrificing image quality; in many cases, visual fidelity even improves.  Examples of text rendering issues and anatomical inconsistencies in the FLUX.1-dev images are highlighted for clear comparison. The full prompts used to generate these images are listed in Appendix E.", "section": "4.2. Results on Image Generation"}, {"figure_path": "https://arxiv.org/html/2503.18940/x6.png", "caption": "Figure 6: Qualitative comparison of our Bottleneck Sampling with HunyuanVideo\u00a0[16].Our method achieves up to 2.5\u00d7\\times\u00d7 speedup while maintaining visual fidelity. Incorrect object motion and object disappearing are highlighted with red circles.", "description": "Figure 6 presents a qualitative comparison of video generation results between the standard HunyuanVideo model and the proposed Bottleneck Sampling method.  Three video generation examples are shown for each method.  The Bottleneck Sampling method achieves up to a 2.5 times speed increase compared to the original HunyuanVideo model, without significant loss in visual quality.  Instances of incorrect object motion or disappearing objects in the generated videos are circled in red for easier identification and comparison.", "section": "4.3. Results on Video Generation"}, {"figure_path": "https://arxiv.org/html/2503.18940/x7.png", "caption": "Figure 7: Visualization of Ablation Studies.", "description": "This figure visualizes the ablation study results for Bottleneck Sampling. It shows the impact of removing key components of the method, such as the bottleneck design, noise reintroduction at stage transitions, and scheduler re-shifting, on image generation quality.  Each sub-figure presents examples from different ablation experiments showing changes in visual quality and comparing them to the full Bottleneck Sampling results. This allows readers to understand the contribution of each individual design choice in the overall performance of the method.", "section": "4.4. Ablation Study"}, {"figure_path": "https://arxiv.org/html/2503.18940/x8.png", "caption": "Figure 8: Effect of Stage Numbers in our Bottleneck Sampling. Comparison between 3 stages and 5 stages.", "description": "This figure compares the results of using 3 and 5 stages in the Bottleneck Sampling method.  The Bottleneck Sampling method iteratively denoises an image at different resolutions, starting at a high resolution, moving to lower resolutions for efficiency, and finally returning to high resolution for detail refinement. This figure visually demonstrates how changing the number of stages affects the final image quality and potentially the computational cost.  Different images are used to compare the results between using 3 and 5 stages of the method.", "section": "D.1. Effect of Stage Numbers"}, {"figure_path": "https://arxiv.org/html/2503.18940/x9.png", "caption": "Figure 9: Effect of Upsampling Method in our Bottleneck Sampling.", "description": "This figure shows the results of an ablation study on the effect of different upsampling methods within the Bottleneck Sampling framework.  Four methods are compared: nearest-neighbor, bilinear, bicubic, and Lanczos interpolation.  The goal was to determine which upsampling technique produced the best results in terms of image quality and speed while maintaining the overall efficiency and fidelity of the Bottleneck Sampling method.  Visual examples are included to illustrate the differences in the quality of the generated images produced by the various upsampling methods.", "section": "D. Extended Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2503.18940/x10.png", "caption": "Figure 10: Comparison with FLUX.1-dev", "description": "This figure displays a qualitative comparison of image generation results between the FLUX.1-dev model and the proposed Bottleneck Sampling method.  It visually demonstrates the effectiveness of Bottleneck Sampling. For each of several different prompts (e.g., a racing car, a cartoon eye, an anime scene, etc.), FLUX.1-dev's output is shown side-by-side with the Bottleneck Sampling output. The visual comparison showcases how the latter achieves comparable image quality at a significantly faster speed.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18940/x11.png", "caption": "Figure 11: Comparison with HunyuanVideo", "description": "This figure displays a qualitative comparison of video generation results between the HunyuanVideo baseline model and the proposed Bottleneck Sampling method. Three different video generation scenarios are presented, with each scenario showing a sequence of frames generated by both models.  The goal is to visually demonstrate that Bottleneck Sampling maintains comparable video quality to the baseline while offering significant speed improvements.", "section": "4. Experiments"}]