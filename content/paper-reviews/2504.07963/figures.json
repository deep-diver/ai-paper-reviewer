[{"figure_path": "https://arxiv.org/html/2504.07963/x1.png", "caption": "Figure 1: Comparisons of Design Paradigms between latent-based diffusion models\u00a0(LDMs), pixel-based diffusion models\u00a0(PDMs), and PixelFlow: (a) LDMs split training into two separate stages\u2014first independently training off-the-shell VAEs, then training diffusion models on tokens extracted from the pre-trained VAEs; (b) Previous PDMs typically train two separate models: a diffusion model on low-resolution images and an upsampler for high-resolution synthesis; (c) PixelFlow, by contrast, offers an end-to-end solution for pixel-based generation, combining both high efficiency and strong generative performance.", "description": "Figure 1 illustrates three different approaches to image generation: (a) Latent diffusion models (LDMs) use a two-stage process. First, a Variational Autoencoder (VAE) compresses the image into a latent space.  Then, a separate diffusion model is trained on this latent representation. (b) Pixel-based diffusion models (PDMs) typically involve training a diffusion model on low-resolution images and a separate upsampler to increase the resolution to the desired output. (c) PixelFlow, in contrast, is an end-to-end model trained directly on raw pixels without requiring separate VAEs or upsamplers. This allows for a more efficient and effective single-stage generation process. ", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.07963/x2.png", "caption": "Figure 2: PixelFlow for cascaded image generation from pixel space. We partition the entire generation procedure into series resolution stages. At the beginning of each resolution stage, we upscale the relatively noisy results from the preceding stage and use them as the starting point for the current stage. Consequently, as the resolution enhances, more refined samples can be obtained.", "description": "PixelFlow's image generation process is depicted. It is divided into multiple stages, each operating at a specific resolution.  The process starts with a low-resolution noisy image. In each subsequent stage, the image from the previous stage is upscaled and further denoised, leading to a gradual increase in resolution and refinement of the generated image. This iterative upscaling and denoising allows PixelFlow to generate high-resolution images without the computational cost of processing high-resolution images directly throughout the entire process.", "section": "3.2. Multi-Scale Generation in Pixel Space"}, {"figure_path": "https://arxiv.org/html/2504.07963/x3.png", "caption": "Figure 3: Visualization of intermediate result of cascaded stages. We extract the intermediate results from each of the four stages for direct visualization. We observed a clear denoising process at various resolution stages.", "description": "This figure visualizes the intermediate outputs of PixelFlow's multi-stage image generation process.  The image generation is broken down into four cascading resolution stages. At each stage, intermediate results are extracted and shown, demonstrating the denoising process as the resolution gradually increases from a lower resolution to the final higher resolution. The figure directly visualizes the refinement of the image through each stage, illustrating how noise is progressively reduced to produce a clearer, more detailed image.", "section": "3.2. Multi-Scale Generation in Pixel Space"}, {"figure_path": "https://arxiv.org/html/2504.07963/x4.png", "caption": "Figure 4: Qualitative results of class-conditional image generation of PixelFlow. All images are 256\u00d7\\times\u00d7256 resolution.", "description": "This figure showcases the qualitative results obtained from PixelFlow's class-conditional image generation.  The images demonstrate the model's ability to generate diverse and visually appealing images across various classes within the ImageNet dataset.  All generated images have a resolution of 256x256 pixels.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.07963/x5.png", "caption": "Figure 5: Qualitative results of text-conditional generation of PixelFlow. All images are 512\u00d7\\times\u00d7512 resolution. Key components of the prompt are highlighted in RED.", "description": "Figure 5 showcases the qualitative results of text-to-image generation using the PixelFlow model.  The figure displays several images (all at a resolution of 512x512 pixels), each generated from a corresponding text prompt. Key phrases within each prompt that are particularly crucial in shaping the generated image are highlighted in red. This visualization demonstrates the model's ability to translate text descriptions into detailed and visually appealing images while effectively incorporating specific details from the input text.", "section": "4.5. Text-to-Image Generation"}, {"figure_path": "https://arxiv.org/html/2504.07963/x6.png", "caption": "Figure 6: Qualitative samples of PixelFlow. We present the generated images of 1024\u00d7\\times\u00d71024 resolution. Key words are highlighted in RED.", "description": "Figure 6 showcases example images generated by PixelFlow at a resolution of 1024 x 1024 pixels.  The images demonstrate the model's ability to generate diverse and detailed visuals based on textual descriptions.  Key terms within the input text prompts are highlighted in red to emphasize the model's accurate interpretation and translation of these terms into visual elements.  The variety of scenes and subjects represented reflects the versatility of the PixelFlow model in generating high-quality images.", "section": "4.5. Text-to-Image Generation"}]