{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, a model that learns transferable visual representations from natural language supervision, is fundamental to the text-aware image generation process of TA-TiTok and MaskGen."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "MaskGIT: Masked generative image transformer", "publication_date": "2022-00-00", "reason": "MaskGIT introduces the masked generative image transformer framework, which directly inspires the architecture and training methodology of MaskGen."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces a method for generating high-resolution images using transformers, which is a significant improvement upon prior methods and directly relates to the goals of the MaskGen model."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "Muse: Text-to-image generation via masked generative transformers", "publication_date": "2023-00-00", "reason": "Muse, a state-of-the-art text-to-image generation model, utilizes the masked generative transformer approach and serves as a direct comparison point for MaskGen's performance."}, {"fullname_first_author": "Qihang Yu", "paper_title": "An image is worth 32 tokens for reconstruction and generation", "publication_date": "2024-00-00", "reason": "This paper introduces the 1D tokenizer, TiTok, which is the basis for the novel text-aware 1D tokenizer, TA-TiTok, developed in the current work."}]}