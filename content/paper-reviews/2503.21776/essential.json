{"importance": "This paper introduces Video-R1, advancing video reasoning in MLLMs via rule-based RL and a novel temporal-aware training method. **It sets a new state-of-the-art on VSI-Bench**, highlighting the impact of reasoning capabilities for video tasks and stimulating further research in this field.", "summary": "Video-R1: First to explore rule-based RL for video reasoning in MLLMs, enhancing performance on key benchmarks.", "takeaways": ["Video-R1 is the first systematic attempt to apply rule-based reinforcement learning to enhance video reasoning in multimodal large language models.", "The T-GRPO algorithm improves temporal reasoning by contrasting performance on ordered vs. shuffled video frames.", "The study demonstrates significant performance gains on video reasoning benchmarks, surpassing state-of-the-art models on VSI-Bench."], "tldr": "Inspired by DeepSeek-R1, this paper introduces Video-R1, to explore rule-based reinforcement learning (RL) for video reasoning in multimodal large language models (MLLMs). Applying RL to video presents challenges: lack of temporal modeling and scarcity of video-reasoning data. To address the challenges, the paper introduces T-GRPO algorithm, which encourages models to utilize temporal information for reasoning. Instead of only video, it incorporates high-quality image-reasoning data.\n\nVideo-R1 constructs two datasets: Video-R1-COT and Video-R1 for SFT cold start and RL training, comprising both image and video data. Experiments show Video-R1 improves on video reasoning benchmarks like VideoMMMU, VSI-Bench, MVBench, and TempCompass. Notably, Video-R1-7B achieves 35.8% accuracy on VSI-Bench, surpassing the commercial model GPT-4o. The project releases codes, models, and data.", "affiliation": "CUHK MMLab", "categories": {"main_category": "Multimodal Learning", "sub_category": "Multimodal Reasoning"}, "podcast_path": "2503.21776/podcast.wav"}