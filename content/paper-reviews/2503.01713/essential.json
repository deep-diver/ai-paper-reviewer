{"importance": "This work enhances RAG by improving retrieval precision, significantly boosting QA accuracy and cost-efficiency. It opens new research directions in semantic segmentation and adaptive chunk selection for better context utilization.", "summary": "SAGE: Precise RAG via semantic segmentation, adaptive chunking, and LLM feedback, boosting QA accuracy & cost-efficiency.", "takeaways": ["Semantic segmentation significantly improves retrieval accuracy in RAG.", "Adaptive chunk selection dynamically optimizes context for QA.", "LLM self-feedback effectively refines context retrieval, enhancing precision."], "tldr": "**Retrieval-augmented generation (RAG)** enhances QA by leveraging external knowledge. Current RAG methods face challenges: (1) segmenting corpus without considering semantics, causing context loss, and (2) balancing relevant vs. irrelevant context is difficult, leading to inaccurate answers and token cost inefficiencies. These limitations stem from ineffective corpus segmentation and noisy retrieval issues. \n\nThis paper introduces **SAGE, a RAG framework**, designed to overcome these limitations. SAGE employs a semantic segmentation model for coherent chunks, a gradient-based selection for relevant context, and LLM feedback for refining the context. This approach boosts the quality of QA by 61.25% and cost efficiency by 49.41% by avoiding noisy context and improving the retrieved context for LLMs.", "affiliation": "Tsinghua University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Question Answering"}, "podcast_path": "2503.01713/podcast.wav"}