{"importance": "This paper is important because it **quantifies the potential of multilingual reasoning** in LLMs, revealing that performance upper bounds in multilingual settings exceeds monolingual. It uncovers the limitations of existing answer selection methods and **provides insights for future research** to fully harness multilingualism for reasoning.", "summary": "LLMs can reason better multilingually! Paper shows multilingual reasoning boosts performance, revealing the full potential is still untapped.", "takeaways": ["Multilingual reasoning can significantly improve the performance of LLMs on reasoning tasks, outperforming English-only approaches.", "Existing answer selection methods struggle to fully leverage the potential of multilingual reasoning due to limitations and biases.", "The gains from multilingual reasoning are robust to variations in translation quality and language choice."], "tldr": "Large language models (LLMs) often show an \"English bias,\" performing better in English than other languages. However, using certain other languages can yield better performance in reasoning tasks. The study seeks to quantify the potential of multilingual thinking and compare it to English thinking. The work demonstrates that multilingual reasoning can achieve significantly higher performance upper bounds than English-only reasoning, suggesting that the full potential of multilingual thinking is yet to be tapped.\n\nTo estimate the upper bound of harnessing multilingualism, the authors aggregated model responses to translated parallel inputs on GPQA and MGSM tasks, using Acc@k to measure performance. The study is conducted using LLaMA3.1-70B, Qwen2.5-72B and R1-distill-LLaMA3.1-70B.  The results showed that **multilingual thinking can ideally boost GPQA accuracy** from ~45 to ~90, and MGSM from ~90 to ~100. Further experiments analyze language selection, text quality, and answer selection methods to determine factors affecting multilingual reasoning potential.", "affiliation": "Nanjing University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2504.11833/podcast.wav"}