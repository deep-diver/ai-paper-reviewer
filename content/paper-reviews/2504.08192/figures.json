[{"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/SAE_plotv2.png", "caption": "Figure 1: An illustration of DSG", "description": "The figure illustrates the architecture of Dynamic SAE Guardrails (DSG), a method for targeted unlearning in large language models.  The diagram shows how DSG leverages a sparse autoencoder (SAE) to identify and remove the influence of features associated with unwanted knowledge.  It begins with activations from a Transformer layer of the LLM. The SAE encoder converts these activations into a sparse representation, where individual features represent different aspects of the model's knowledge.  A dynamic classifier determines whether the input is forget-relevant, and only then are the activations of identified forget features clamped, preventing the model from accessing those specific knowledge pathways.  The SAE decoder then reconstructs the activations for subsequent processing by the LLM, resulting in a model that has effectively forgotten the specified information.", "section": "3 Dynamic SAE Guardrails (DSG)"}, {"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/fig_tk_percent.png", "caption": "Figure 2: Distribution of \u03c1\u2062(x)\ud835\udf0c\ud835\udc65\\rho(x)italic_\u03c1 ( italic_x ) for unlearning on WMDP-Bio. Threshold at 95th percentile (dashed red line) separates MMLU from WMDP.", "description": "This figure is a histogram showing the distribution of the percentage of forget-set activated tokens (\u03c1(x)) in sequences from the WMDP-Bio (biosecurity) and MMLU (general knowledge) datasets.  The x-axis represents the percentage of tokens in a sequence that activate at least one of the SAE features identified as causally linked to the forget data (WMDP-Bio). The y-axis represents the count of sequences with that percentage.  The dashed red line indicates the 95th percentile of the \u03c1(x) distribution for the retain set (MMLU). This threshold is used in the Dynamic SAE Guardrails (DSG) method to dynamically classify sequences as forget-relevant or retain-relevant for targeted unlearning interventions. The plot demonstrates the effectiveness of this threshold in separating sequences from the forget and retain sets, highlighting the ability of DSG to differentiate between the two data types.", "section": "3.3 Dynamic Sequence-Level Classification and Intervention"}, {"figure_path": "https://arxiv.org/html/2504.08192/x1.png", "caption": "Figure 3: Unlearning performance on WMDP-Bio (left) and WMDP-Cyber (right). Higher MMLU accuracy and lower WMDP accuracy is better. Clamp strengths (c\ud835\udc50citalic_c) used for DSG points are shown as annotations. DSG Pareto-dominates the top four baseline methods (RMU, SCRUB, Farrell et al., SSD).", "description": "This figure displays the results of unlearning experiments conducted on two subsets of the WMDP dataset: WMDP-Bio and WMDP-Cyber.  The primary metric for evaluating unlearning effectiveness is the accuracy on the WMDP task itself (lower accuracy is better, indicating successful forgetting).  Simultaneously, the figure tracks the accuracy of a general knowledge task (MMLU) to ensure that the unlearning process doesn't significantly impact the model's overall capabilities (higher MMLU accuracy is preferred).  Various unlearning methods are compared, including gradient-based approaches (RMU, SCRUB, SSD) and a static SAE-based method from previous work (Farrell et al.). The Dynamic SAE Guardrails (DSG) method is the focus.  Different clamp strengths (a parameter controlling the intensity of the intervention) are used for DSG. The plot showcases DSG's superior performance, demonstrating that it achieves better trade-offs between forgetting and utility preservation than all the comparison methods, as demonstrated by Pareto dominance. This means that for any level of retained general knowledge (as measured by MMLU accuracy), DSG achieves better forgetting of the target knowledge (lower WMDP accuracy) compared to the other methods.", "section": "4 Experiments and Results"}, {"figure_path": "https://arxiv.org/html/2504.08192/x2.png", "caption": "Figure 4: (a) Scalability: Performance across increasing forget set sizes. (b) Sequential Unlearning: Performance across sequential unlearning requests", "description": "This figure shows the results of experiments evaluating the scalability and sequential unlearning capabilities of the Dynamic SAE Guardrails (DSG) method.  Panel (a) demonstrates DSG's performance as the size of the forget dataset increases, showing its ability to maintain effectiveness even with large amounts of data to be removed.  Panel (b) illustrates DSG's performance when handling multiple, consecutive unlearning requests.  It showcases the robustness of DSG in maintaining both forget quality (effectively removing the targeted data) and utility preservation (retaining the model's overall capabilities) across multiple requests, a significant advantage over methods that exhibit performance degradation over successive unlearning attempts.", "section": "Experiments and Results"}, {"figure_path": "https://arxiv.org/html/2504.08192/x3.png", "caption": "Figure 5:  Relearning attack resistance across finetuning epochs. (a) DSG demonstrates superior resistance to relearning compared to RMU. (b) Test-time DSG preserves MMLU utility better than Train-time DSG while still providing significant protection.", "description": "This figure displays the results of relearning attacks on two different models: one using Dynamic SAE Guardrails (DSG) and the other using RMU.  The left panel (a) shows the WMDP-Bio accuracy over multiple finetuning epochs after an initial unlearning phase.  It demonstrates that DSG is significantly more resistant to relearning attacks than RMU, maintaining a much lower accuracy even after extensive finetuning. The right panel (b) shows MMLU (general knowledge) performance for three different scenarios: a baseline model, the baseline model with test-time DSG (DSG applied only during testing), and the baseline model with train-time DSG (DSG integrated into the training process). This comparison highlights the trade-off between unlearning effectiveness and utility preservation. Train-time DSG reduces WMDP accuracy more than test-time DSG but at the cost of a slightly decreased MMLU accuracy, showcasing that test-time DSG offers a more favorable balance between forgetting and retention.", "section": "4.3 Resistance to Relearning Attacks"}, {"figure_path": "https://arxiv.org/html/2504.08192/x4.png", "caption": "Figure 6: Data efficiency analysis of DSG. (A) Performance across varying training data sizes compared to RMU. (B) Zero-shot performance on WMDP-Bio (left) and WMDP-Cyber (right) using 20 features selected via Neuropedia API with different \u03c4\ud835\udf0f\\tauitalic_\u03c4 thresholds (shown next to each data point).", "description": "Figure 6 presents a comparison of Dynamic SAE Guardrails (DSG) and RMU in terms of data efficiency and zero-shot performance.  Part (A) illustrates how well each method performs when trained with varying amounts of data (20%, 40%, 60%, 80%, and 100%). It shows that DSG maintains robust performance even with limited data. Part (B) demonstrates the zero-shot performance of DSG on the WMDP-Bio and WMDP-Cyber datasets.  Here, 20 features were selected using the Neuropedia API.  The performance is shown for different values of the dynamic threshold \u03c4, highlighting DSG's ability to achieve good performance even without using task-specific data for training.", "section": "4.4 Data Efficiency and Zero-shot Interpretable Unlearning"}, {"figure_path": "https://arxiv.org/html/2504.08192/x5.png", "caption": "Figure 7: DSG Ablation studies (A) Static vs. dynamic clamping comparison with varying clamp strengths [10-500] for 20 and 30 features. (B) Effect of dynamic threshold percentile (pdynsubscript\ud835\udc5ddyn\\smash{p_{\\text{dyn}}}italic_p start_POSTSUBSCRIPT dyn end_POSTSUBSCRIPT) on performance (C) Impact of importance ratio threshold (pratiosubscript\ud835\udc5dratiop_{\\text{ratio}}italic_p start_POSTSUBSCRIPT ratio end_POSTSUBSCRIPT, range 75-95) for 20 and 30 features.", "description": "This figure presents the results of ablation studies conducted on the Dynamic SAE Guardrails (DSG) model to analyze the impact of its key components.  Panel (A) compares static and dynamic clamping methods, varying the clamp strength (c) applied to the selected features. This panel helps to understand the effect of dynamic intervention on balancing forgetting and utility preservation. Panel (B) investigates the influence of the dynamic threshold percentile (p<sub>dyn</sub>) parameter in controlling the trade-off between these two aspects.  The dynamic threshold is used to classify the model inputs as either forget-relevant or retain-relevant which triggers clamping. Changing this percentile alters the sensitivity of the classification, directly affecting how often the clamping is applied. Panel (C) explores the effect of the importance ratio threshold (p<sub>ratio</sub>) on performance. The importance ratio is used to rank features according to how strongly they are associated with the knowledge to be forgotten relative to the knowledge to be retained. The threshold determines how many of the top-ranked features are selected for clamping.  In essence, this figure provides a detailed exploration of how each of these hyperparameters affects the balance between the quality of unlearning and the preservation of the model's general utility.", "section": "3 Dynamic SAE Guardrails (DSG)"}, {"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/zero_shot.png", "caption": "Figure 8: Distribution of forget-set activated tokens for WMDP-Cyber. Threshold at the 95th percentile (dashed red line) effectively separates MMLU from WMDP.", "description": "This figure displays the distribution of the percentage of forget-set activated tokens within sequences from the WMDP-Cyber dataset and the MMLU dataset.  The x-axis represents the percentage of tokens in a sequence that activate at least one of the SAE features identified as causally linked to the forget data (WMDP-Cyber). The y-axis shows the count of sequences with that percentage of activated tokens. The dashed red line marks the 95th percentile of the distribution, which is used as a threshold in the dynamic classification component of the DSG method.  The plot shows that the distribution for WMDP-Cyber sequences is shifted towards higher percentages of activated tokens compared to the MMLU sequences, indicating that the selected SAE features effectively discriminate between data from these two datasets. This supports the use of this threshold in the DSG method to selectively trigger intervention only when processing inputs relevant to the forget data.", "section": "4.1 Unlearning on WMDP"}, {"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/ablations.png", "caption": "((a))", "description": "This figure shows the distribution of cosine similarity and magnitude ratio between the base model's activations and the finetuned model's activations. The cosine similarity distribution shows that finetuning does not significantly change the underlying activation space, with most values clustered around 1.0. The magnitude ratio distribution, which represents the ratio of finetuned activations to base activations, also shows most values clustered around 1.0, indicating that the magnitude of activations does not change significantly during finetuning. This figure supports the Superficial Alignment Hypothesis, which suggests that activation patterns remain relatively stable during finetuning while weights change significantly.", "section": "Relearning attack"}, {"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/fig_tk_percent_cyber.png", "caption": "((b))", "description": "This figure shows the distribution of cosine similarity and magnitude ratio between base and fine-tuned models' activations.  The high cosine similarity values (centered around 0.994) and magnitude ratios around 1.02 demonstrate that fine-tuning the model does not substantially alter the underlying activation patterns. This supports the superficial alignment hypothesis, which posits that the activation patterns remain stable during finetuning, even when weights change significantly.  This stability is crucial for the robustness of DSG against relearning attacks.", "section": "Relearning attack"}, {"figure_path": "https://arxiv.org/html/2504.08192/x6.png", "caption": "Figure 9: (a) Distribution of activation cosine similarity and activation magnitude ratio between Base and Finetuned models. Finetuning does not significantly change the underlying activation space. (b) Train loss when finetuning Base model and Base+SAE model on WMDP and MMLU. Loss on WMDP for the BASE+SAE model is significantly higher than on MMLU.", "description": "Figure 9 presents two key observations related to the model's activation patterns during finetuning. (a) Activation Cosine Similarity and Magnitude Ratio: This plot demonstrates the stability of activation patterns during finetuning. The distribution of cosine similarities between activation vectors before and after finetuning is heavily concentrated around 1.0, indicating that the direction of the activations remains largely unchanged. Similarly, the magnitude ratios also cluster around 1.0, suggesting that the scale of activations remains largely unaltered. This supports the Superficial Alignment Hypothesis which suggests that while weights in the model might change considerably during finetuning, the fundamental activation patterns remain relatively stable. (b) Training Loss During Finetuning: This plot shows training loss values when finetuning the base model and a model using test-time DSG on two tasks: WMDP and MMLU. The significantly higher loss observed for the model with test-time DSG on the WMDP task compared to MMLU suggests that DSG effectively prevents the model from reactivating or easily accessing knowledge related to the WMDP dataset (forget set) while maintaining performance on MMLU (retain set). This shows how DSG actively restricts access to specific knowledge pathways during training by clamping certain activation patterns, making it more resistant to relearning attacks.", "section": "Resistance to Relearning Attacks"}, {"figure_path": "https://arxiv.org/html/2504.08192/x7.png", "caption": "Figure 10: Relearning attack performance with reduced learning rate (1e-6). All configurations show minimal performance changes across finetuning epochs, demonstrating that relearning attack efficacy is strongly dependent on learning rate.", "description": "This figure shows the results of a relearning attack experiment conducted with a reduced learning rate of 1e-6, in contrast to the primary experiments using a learning rate of 1e-5.  The experiment evaluates the impact of reduced learning rate on the effectiveness of relearning attacks.  The figure plots the WMDP-Bio accuracy over multiple finetuning epochs for different model configurations: a base model (before unlearning), a base model with test-time DSG, a model using RMU (a baseline unlearning method) and a model using RMU with test-time DSG.  The results demonstrate that across all configurations, minimal changes in performance are observed during finetuning epochs. This indicates a strong dependency of relearning attack efficacy on the learning rate, suggesting that applying learning rate constraints in API-based model access could significantly reduce the susceptibility to relearning attacks.", "section": "Relearning Attacks"}, {"figure_path": "https://arxiv.org/html/2504.08192/x8.png", "caption": "Figure 11: Effect of clamp strength c\ud835\udc50citalic_c on DSG performance across different feature counts. MMLU accuracy (solid lines) remains consistently high (>99%absentpercent99>99\\%> 99 %) for 10-20 features across all clamp values, while WMDP-Bio accuracy (dashed lines) drops sharply even at modest clamp strengths (c=25\ud835\udc5025c=25italic_c = 25). This demonstrates DSG\u2019s ability to effectively remove targeted knowledge while preserving general model capabilities with minimal parameter sensitivity.", "description": "This figure illustrates the impact of the clamp strength parameter (c) and the number of selected features on the performance of Dynamic SAE Guardrails (DSG).  The MMLU accuracy (a measure of the model's performance on a general knowledge benchmark) remains high (above 99%) across a wide range of clamp strengths (from 10 to 500) when using 10 or 20 features.  However, the WMDP-Bio accuracy (a measure of the model's ability to forget specific knowledge) decreases sharply even with a small clamp strength (c = 25) when using 10-30 features. This demonstrates that DSG can effectively remove the targeted knowledge while maintaining high overall performance with minimal sensitivity to the clamp strength hyperparameter.", "section": "Ablations"}, {"figure_path": "https://arxiv.org/html/2504.08192/extracted/6352696/figures/multiplier.png", "caption": "Figure 12: Total Variation Distance (TVD) between WikiText and benchmark datasets using percentage-based (\u03c1\ud835\udf0c\\rhoitalic_\u03c1) vs. raw count-based (\u03c1rawsubscript\ud835\udf0craw\\rho_{\\text{raw}}italic_\u03c1 start_POSTSUBSCRIPT raw end_POSTSUBSCRIPT) metrics. Lower TVD between WikiText and MMLU indicates better alignment of retain sets, while higher TVD between WikiText and WMDP indicates better separation between retain and forget distributions. Percentage-based metrics consistently outperform raw counts on both measures across all benchmarks.", "description": "Figure 12 presents a comparison of two methods for calculating a statistical measure called Total Variation Distance (TVD).  TVD quantifies the difference between two probability distributions. In this case, the distributions represent the activation patterns of different sets of data used in a machine unlearning experiment.  The two methods being compared are a percentage-based method (using the \u03c1 symbol) and a raw count-based method (\u03c1raw).  WikiText data represents the 'retain' data (data that should be preserved after unlearning), while MMLU and WMDP data represents the 'forget' data (data to be removed or forgotten) in different domains. Lower TVD values between WikiText and MMLU indicate better alignment or similarity between the retain data's activation pattern before and after the unlearning process. Conversely, higher TVD values between WikiText and WMDP signify a better separation\u2014the unlearning process successfully distinguished the activations of the retain and forget datasets. The figure shows that the percentage-based method consistently outperforms the raw count method in both alignment and separation across all benchmarks (MMLU and WMDP in biosecurity and cybersecurity domains).", "section": "K. Ablations"}, {"figure_path": "https://arxiv.org/html/2504.08192/x9.png", "caption": "Figure 13:  Feature Activations on Example Sequences from Forget Sets. (A) WMDP-Bio sequence with words highlighted in green indicating activation values >0absent0>0> 0 for feature ID (top) 373 and (bottom) 10933. (B) WMDP-Cyber sequence with words highlighted in green indicating activation values >0absent0>0> 0 for feature ID (top) 15286 and (bottom) 2905. Activation magnitudes are reported above the words in grey.", "description": "This figure visualizes the activations of specific Sparse Autoencoder (SAE) features on example sequences from the forget datasets of WMDP-Bio and WMDP-Cyber.  For WMDP-Bio (part A), it shows two SAE features (IDs 373 and 10933) with high activations on words related to biological processes and infectious diseases. For WMDP-Cyber (part B), it displays two different features (IDs 15286 and 2905) that are strongly activated in the context of cybersecurity-related terms like \"encryption\" and \"security\". The grey numbers above the words represent the magnitude of the activations. This visualization demonstrates that the SAE features identified by DSG are semantically meaningful and capture domain-relevant concepts, supporting the interpretability of DSG's unlearning.", "section": "4.4 Data Efficiency and Zero-shot Interpretable Unlearning"}]