{"importance": "This paper is important because it introduces a new **RL framework, ReTool**, that enhances long-form reasoning through tool integration. ReTool allows models to autonomously discover **optimal tool invocation patterns**, offering new insights into hybrid neuro-symbolic systems and opening avenues for further research.", "summary": "ReTool: Reinforcement learning for strategic tool use in LLMs.", "takeaways": ["ReTool enhances LLMs by integrating real-time code execution within natural language reasoning.", "ReTool leverages outcome feedback in a RL paradigm to teach models when and how to invoke tools.", "Experiments show ReTool's superiority on the MATH Olympiad benchmark AIME."], "tldr": "LLMs struggle with structured problem-solving like geometry, computation, or equation solving, where code interpreters (CI) have advantages. Existing reasoning models are limited in tasks requiring precise numerical calculation or symbolic manipulation. They often fail to generalize beyond seen patterns or adaptively decide when and how to invoke external tools. This leads to misuse of tools or reliance on brittle heuristics.\n\nThis paper introduces **ReTool**, a reinforcement learning framework that enhances long-form reasoning with tool integration. It employs a training framework starting with synthetic data to produce code-augmented reasoning traces, then uses RL with task outcomes as rewards to refine the model's tool use. **ReTool outperforms text-based RL baselines on MATH Olympiad benchmarks**, demonstrating its effectiveness.", "affiliation": "ByteDance Seed", "categories": {"main_category": "Machine Learning", "sub_category": "Reinforcement Learning"}, "podcast_path": "2504.11536/podcast.wav"}