[{"figure_path": "https://arxiv.org/html/2502.06049/extracted/6175910/figs/lm2_wf.png", "caption": "Figure 1: Illustration of LM2\u00a0overall architecture. It consists of a separate memory bank, which updates the main information flow through cross attention, and is updated using the input (\u2110\u2110\\mathcal{I}caligraphic_I), output (\ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O), and forget (\u2131\u2131\\mathcal{F}caligraphic_F) gates. For the information flow from one block to another, the gray curve shows the normal attention flow and the pink curve shows the extra memory flow.", "description": "The figure illustrates the architecture of the Large Memory Model (LM2).  It shows how a memory bank interacts with the standard Transformer decoder blocks.  The memory bank receives input and is updated using input, output, and forget gates, influencing the main information flow through cross-attention.  A gray curve depicts the standard Transformer's attention flow, while a pink curve represents the additional memory flow that augments the original pathway.", "section": "2 Large Memory Model (LM2)"}, {"figure_path": "https://arxiv.org/html/2502.06049/extracted/6175910/figs/gate.png", "caption": "Figure 2: Illustration of how memory module works inside of each decoding block, where blue, green, and red box corresponds to forget, input, and output phase.", "description": "This figure illustrates the memory module's operation within a single decoding block of the LM2 model.  The memory module is composed of three phases:  the input phase (green), forget phase (blue), and output phase (red). The input phase determines how much new information is added to the memory bank.  The forget phase decides which parts of the existing memory are discarded. Finally, the output phase regulates how much memory information is passed to the next decoder layer. The figure visually represents these three phases as separate components interacting with the input and output embeddings of the decoder block.", "section": "2 Large Memory Model (LM2)"}, {"figure_path": "https://arxiv.org/html/2502.06049/x1.png", "caption": "Figure 3: Performance on BABILong benchmark with different capabilities.", "description": "This radar chart visualizes the performance of different models on the BABILong benchmark, categorized by various reasoning capabilities.  Each axis represents a specific reasoning task: Single-step Reasoning, Multi-step Reasoning, Relation Tracking, Basic Queries, and Negation & Uncertainty. The length of each spoke indicates the model's performance on that task. The chart allows for a direct comparison of the relative strengths and weaknesses of each model across different reasoning skills.", "section": "4.1 Performance on Memory Tasks"}, {"figure_path": "https://arxiv.org/html/2502.06049/extracted/6175910/figs/example_.png", "caption": "Figure 4: We sample a question from MMLU to test the LM2\u00a0in a few-shot fashion. To study how the memory module focuses on relevant information, we place useful information inside one of the few-shot examples.", "description": "Figure 4 shows an example of a question from the MMLU benchmark used to evaluate the LM2 model.  The question is presented in a few-shot learning setting, meaning a few examples are given before the actual question.  Critically, useful information relevant to answering the target question is deliberately included within one of the example questions. This experimental setup allows the researchers to analyze how the memory module within the LM2 model focuses on and retrieves relevant information when answering the question. By strategically placing relevant information within the examples, the researchers can better understand how the memory module functions during the question-answering process.", "section": "4.4 Analysis of Memory Representations"}, {"figure_path": "https://arxiv.org/html/2502.06049/x2.png", "caption": "Figure 5: We evaluate variations of integrating memory within the decoder blocks. The number indicates how many of the initial decoder blocks include the memory module, as we found that the order of implementing memory modules does not affect performance.", "description": "This figure displays the results of an experiment evaluating the impact of integrating a memory module into different numbers of decoder blocks within a transformer-based language model. The x-axis represents the number of training tokens (in billions), and the y-axis shows the perplexity scores. Multiple lines are plotted, each representing a different configuration where the memory module is included in varying numbers of initial decoder blocks (1, 6, 12, or all 16). The purpose is to analyze how incorporating the memory mechanism in different layers of the architecture affects model performance and training efficiency. The results show that including the memory module in more blocks leads to lower perplexity, but that including it in only one block significantly slows training.", "section": "Impact of memory modules"}, {"figure_path": "https://arxiv.org/html/2502.06049/x3.png", "caption": "(a) Cross-attention heatmaps before memory update.", "description": "This figure shows cross-attention heatmaps between input tokens and memory slots.  Panel (a) displays the heatmap *before* any memory updates have been applied during the model's inference process.  This visualization helps to understand which parts of the input text are initially most strongly associated with different memory locations. The heatmap uses color intensity to represent the strength of the cross-attention weights, with darker colors indicating stronger associations.", "section": "4.5 Test-time memory adaptations"}, {"figure_path": "https://arxiv.org/html/2502.06049/x4.png", "caption": "(b) Cross-attention heatmaps after memory update.", "description": "This figure shows a heatmap visualization of cross-attention weights between input tokens and memory slots in the LM2 model *after* the memory has been updated. The heatmap displays the attention weights, indicating the strength of the relationships between different input tokens and memory slots.  The x-axis represents the memory slots, ordered numerically, while the y-axis represents the input tokens. Warmer colors (e.g., red) represent stronger attention weights, signifying a greater influence of the memory slot on the corresponding input token, while cooler colors (e.g., blue) represent weaker attention weights. Comparing this figure with Figure 6a (before memory update) helps illustrate the dynamic nature of the memory's interaction with the input during the generation process. This change demonstrates the model's ability to adapt memory focus based on context.", "section": "4.5 Test-time memory adaptations"}]