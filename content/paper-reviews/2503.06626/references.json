{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduced the Transformer architecture, which is a fundamental building block for modern NLP and vision-language models like CLIP."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduced the CLIP model, which is the foundation upon which the current work, DiffCLIP, is built, making it a crucial reference."}, {"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-01-01", "reason": "This paper introduced ResNet, a deep convolutional neural network architecture that is often used as the image encoder in CLIP models, making it a core component of the architecture studied."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-01-01", "reason": "This paper introduced the Vision Transformer (ViT), an alternative image encoder architecture to ResNet that is also commonly used in CLIP models, thus informing the architectural decisions of the models tested."}, {"fullname_first_author": "Tianzhu Ye", "paper_title": "Differential transformer", "publication_date": "2024-01-01", "reason": "This paper introduced the differential attention mechanism, which is the core novelty that DiffCLIP integrates into CLIP, making it a direct and essential predecessor to the work."}]}