[{"content": "| Models | (no corrupt) | [992:1024] | [0:32] | [928:1024] | [0:96] |\n|---|---|---|---|---|---| \n| H3 | 0.654 | 0.569 (<span>\u2193</span> 13.04%) | 0.654 (<span>\u2193</span> 0.03%) | 0.477 (<span>\u2193</span> 27.07%) | 0.650 (<span>\u2193</span> 0.72%) |\n| Transformer | 0.580 | 0.535 (<span>\u2193</span> 7.81%) | 0.447 (<span>\u2193</span> 22.95%) | 0.431 (<span>\u2193</span> 25.76%) | 0.370 (<span>\u2193</span> 36.32%) |\n| RWKV | 0.474 | 0.150 (<span>\u2193</span> 68.35%) | 0.466 (<span>\u2193</span> 1.58%) | 0.138 (<span>\u2193</span> 70.88%) | 0.460 (<span>\u2193</span> 2.91%) |\n| Mamba | 0.674 | 0.126 (<span>\u2193</span> 81.24%) | 0.658 (<span>\u2193</span> 2.30%) | 0.098 (<span>\u2193</span> 85.46%) | 0.647 (<span>\u2193</span> 3.98%) |", "caption": "Table 1: Results of adversarial attack experiments on the CIFAR-10 dataset, evaluated using classification accuracy. Each input sequence contains 1,024 tokens. Two corruption ratios (32/102432102432/102432 / 1024 and 96/102496102496/102496 / 1024) are applied to perturb the leading and trailing tokens, respectively.", "description": "This table presents the results of adversarial attack experiments conducted on the CIFAR-10 dataset to evaluate the robustness of different sequence models.  The models' classification accuracy is measured after introducing perturbations to either the leading (beginning) or trailing (end) tokens of the input sequences. Two different levels of corruption are tested: 32 out of 1024 tokens are corrupted (3.125%) and 96 out of 1024 tokens (9.375%). The table allows comparison of the models' vulnerability to these perturbations, highlighting the impact on the classification accuracy depending on where in the sequence the perturbations occur.", "section": "3.3 POTENTIAL RISK ON MODEL ROBUSTNESS"}, {"content": "| Configurations | # Layers | # KV Pairs | # KV Pairs | # KV Pairs | Avg. | \n|---|---|---|---|---|---| \n|  |  | 64 | 128 | 256 |  | \n| Default <b>A</b><sub>t</sub> | 2 | 98.38 | 81.81 | 36.00 | 72.06 | \n| Default <b>A</b><sub>t</sub> | 4 | 99.23 | 82.08 | 33.52 | 71.61 | \n| (<b>A</b><sub>t</sub>)<sub>1,1</sub>=1 | 2 | 99.81 | 94.70 | 56.39 | 83.63 | \n| (<b>A</b><sub>t</sub>)<sub>N,N</sub>=0 | 2 | 98.41 | 81.35 | 36.55 | 72.10 | \n| (<b>A</b><sub>t</sub>)<sub>N,N</sub>=0 | 4 | 99.74 | 92.20 | 52.21 | 81.38 | \n| (<b>A</b><sub>t</sub>)<sub>1,1</sub>=1,(<b>A</b><sub>t</sub>)<sub>N,N</sub>=0 | 2 | 99.23 | 95.54 | 54.74 | 83.17 | \n| (<b>A</b><sub>t</sub>)<sub>1,1</sub>=1,(<b>A</b><sub>t</sub>)<sub>N,N</sub>=0 | 4 | 99.94 | 98.80 | 81.56 | 93.43 |", "caption": "Table 2: Results of polarization. Rows 1-2 have no polarization, rows 3-5 only polarize one channel to either one or zero, and rows 6-7 polarize both channels.", "description": "This table presents the results of an experiment evaluating the impact of a technique called 'polarization' on the performance of a state space model (SSM). The polarization technique involves modifying the state transition matrices of the SSM by setting specific channels to either 0 or 1.  The table compares the performance (likely measured by a metric such as accuracy or loss) across different configurations: no polarization, polarization of one channel to 0, polarization of one channel to 1, and polarization of both channels (one to 0 and one to 1). Each configuration is tested with varying depths (# layers) and numbers of key-value pairs used in the training data. This allows for an assessment of how the polarization method affects performance under different conditions.", "section": "6 MITIGATING RECENCY AND OVER-SMOOTHING VIA POLARIZATION"}, {"content": "| Models | (no corrupt) | [1014:1024] | [0:10] | [768:1024] | [0:256] | [512:544] | [480:576] |\n|---|---|---|---|---|---|---|---| \n| H3 | 0.654 | 0.629 | 0.654 | 0.394 | 0.639 | 0.603 | 0.543 |\n| Transformer | 0.580 | 0.571 | 0.500 | 0.249 | 0.263 | 0.498 | 0.347 |\n| RWKV | 0.474 | **0.194** | 0.470 | **0.107** | 0.448 | 0.405 | 0.392 |\n| Mamba | 0.674 | 0.348 | 0.664 | **0.099** | 0.597 | 0.515 | 0.446 |", "caption": "Table 3: Extended results of adversarial attack experiments on the CIFAR-10 dataset. Classification accuracy is used as the metric.", "description": "This table presents the results of adversarial attack experiments conducted on the CIFAR-10 image classification dataset.  It evaluates the robustness of several different sequence models (H3, Transformer, RWKV, Mamba) against two types of adversarial attacks: (1) corruption of leading and trailing tokens using Gaussian noise and (2) targeted attacks where pixels from a target class are inserted into images from different classes. The table shows classification accuracy under various corruption ratios, comparing the resilience of each model to both attack methods.", "section": "3.3 POTENTIAL RISK ON MODEL ROBUSTNESS"}, {"content": "| # Params | Training steps | Peak LR | Batch Size (in tokens) | # Tokens |\n|---|---|---|---|---|\n| 100-250M | 4800 | 3e-3 | 0.5M | 2.5B |\n| 250-400M | 13500 | 1.5e-3 | 0.5M | 7B |\n| 400-550M | 20000 | 1.25e-3 | 0.5M | 10B |", "caption": "Table 4: Summary of training settings for varying-sized Mamba. The settings are following Chinchilla law (Hoffmann et\u00a0al., 2022) and consistent with Gu & Dao (2023).", "description": "This table details the hyperparameters used during the training of various sized Mamba models.  It shows how parameters like the number of training steps, peak learning rate, batch size, and the total number of tokens used varied depending on the model's size (measured in the number of parameters).  The settings were chosen to align with the Chinchilla scaling laws proposed by Hoffmann et al. (2022) and are consistent with the training methodology described by Gu & Dao (2023).", "section": "4.1 NECESSITY AND LIMITS OF DEPTH SCALING"}, {"content": "| Configurations | # Layers | Recency | Over-smoothing | # KV Pairs 64 | # KV Pairs 128 | # KV Pairs 256 | Avg. |\n|---|---|---|---|---|---|---|---| \n| Default \ud835\udc68<sub>t</sub> | 2 | https://arxiv.org/html/2501.00658/A5.T5.2.2.2.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.3.3.3.3.pic1.png | 98.38 | 81.81 | 36.00 | 72.06 |\n| Default \ud835\udc68<sub>t</sub> | 4 | https://arxiv.org/html/2501.00658/A5.T5.5.5.5.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.6.6.6.3.pic1.png | 99.23 | 82.08 | 33.52 | 71.61 |\n| (\ud835\udc68<sub>t</sub>)<sub>1,1</sub>=1 | 2 | https://arxiv.org/html/2501.00658/A5.T5.8.8.8.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.9.9.9.3.pic1.png | 99.81 | 94.70 | 56.39 | 83.63 |\n| (\ud835\udc68<sub>t</sub>)<sub>N,N</sub>=0 | 2 | https://arxiv.org/html/2501.00658/A5.T5.11.11.11.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.12.12.12.3.pic1.png | 98.41 | 81.35 | 36.55 | 72.10 |\n| (\ud835\udc68<sub>t</sub>)<sub>N,N</sub>=0 | 4 | https://arxiv.org/html/2501.00658/A5.T5.14.14.14.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.15.15.15.3.pic1.png | 99.74 | 92.20 | 52.21 | 81.38 |\n| (\ud835\udc68<sub>t</sub>)<sub>1,1</sub>=1,(\ud835\udc68<sub>t</sub>)<sub>N,N</sub>=0 | 2 | https://arxiv.org/html/2501.00658/A5.T5.17.17.17.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.18.18.18.3.pic1.png | 99.23 | 95.54 | 54.74 | 83.17 |\n| (\ud835\udc68<sub>t</sub>)<sub>1,1</sub>=1,(\ud835\udc68<sub>t</sub>)<sub>N,N</sub>=0 | 4 | https://arxiv.org/html/2501.00658/A5.T5.20.20.20.2.pic1.png | https://arxiv.org/html/2501.00658/A5.T5.21.21.21.3.pic1.png | 99.94 | 98.80 | 81.56 | 93.43 |", "caption": "Table 5: Extension to Tab. 5. We note the extent of locality and over-smoothing for each configuration. We consider 1111-polarization mitigates locality most significantly, while deepening architecture only relieves recency mildly but deteriorates over-smoothing. 00-polarization alleviates over-smoothening and unleash the benefits by depth scaling.", "description": "Table 5 expands on the results presented in Table 5 of the paper by examining the effects of different configurations on locality and over-smoothing in the context of associative recall.  It shows that a combination of 1-polarization (setting one channel of the state transition matrix to 1) and 0-polarization (setting another channel to 0) significantly mitigates locality issues, while deepening the architecture primarily helps reduce recency bias without worsening over-smoothing.  Importantly, 0-polarization alone effectively reduces over-smoothing, enabling improved performance gains from increased depth.", "section": "E.5.2 Associative Recall Experiments"}]