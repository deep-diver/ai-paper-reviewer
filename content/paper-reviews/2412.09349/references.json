{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-10", "reason": "This paper introduces CLIP, a model that learns transferable visual representations from natural language supervision, which is a key component in many modern image generation models, including those used in this work."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-10-01", "reason": "This paper introduces the latent diffusion model (LDM), a technique for efficiently generating high-resolution images using diffusion models, a key component in many modern image generation models, including those used in this work."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-20", "reason": "This paper introduces Stable Video Diffusion, a powerful model for generating high-quality videos, which is directly used in this work and its performance is compared against."}, {"fullname_first_author": "Li Hu", "paper_title": "Animate anyone: Consistent and controllable image-to-video synthesis for character animation", "publication_date": "2023-11-17", "reason": "This paper introduces Animate Anyone, a state-of-the-art method for controllable human image animation, which this work builds on and improves."}, {"fullname_first_author": "Zhengyan Tong", "paper_title": "MusePose: a pose-driven image-to-video framework for virtual human generation", "publication_date": "2024-01-01", "reason": "This paper introduces MusePose, a widely used open-source implementation of a human image animation model, which is used as a baseline model in this work."}]}