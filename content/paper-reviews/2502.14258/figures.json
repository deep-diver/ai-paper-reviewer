[{"figure_path": "https://arxiv.org/html/2502.14258/x1.png", "caption": "Figure 1: Temporal Heads exist within various TKCs at different times Tksubscript\ud835\udc47\ud835\udc58T_{k}italic_T start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT.\nAblating them disrupts the model\u2019s temporal alignment, yielding incorrect objects.", "description": "Figure 1 illustrates the concept of \"Temporal Heads\" within a neural network model.  The figure shows how these specialized attention heads are responsible for processing time-specific information. It demonstrates that these Temporal Heads are present across various temporal knowledge circuits (TKCs) at different time points (T<sub>k</sub>).  When these Temporal Heads are deactivated (ablated), the model's ability to correctly identify time-sensitive information is significantly impaired, leading to incorrect outputs, highlighting the importance of these heads for maintaining accurate temporal alignment.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.14258/x2.png", "caption": "Figure 2: Overview of temporal knowledge circuit analysis.\n(A): Construct temporal knowledge circuits (TKCs), and compare it with general knowledge circuits (KCs) using time-invariant knowledge.\nCircuits reproduce residual streams for time\u00a0T, subject\u00a0S and relation\u00a0R.\nThis verifies temporal heads only found in each different TKCs of various year Tksubscript\ud835\udc47\ud835\udc58T_{k}italic_T start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT.\n(B): Example of simplified TKC.\nHere, basic knowledge nodes is colored violet, (common in both), while Temporal Heads is highlited.\n(C): Attention map for temporal heads.\na15.h0 means the 15th layer\u2019s first attention head.\nEach head\u2019s attention pattern is represented as the output logits of the hean by mapping to vocabulary space.\nQueries are input tokens focusing on others, while keys are the tokens being focused on.\nValues represent attention weights, indicating the strength of this focus.\nTotal results are in Figures\u00a07\u20138 and 9\u201311.", "description": "Figure 2 illustrates the process of temporal knowledge circuit analysis.  Panel (A) shows the construction of Temporal Knowledge Circuits (TKCs) for time-specific knowledge and compares them to general Knowledge Circuits (KCs) built using time-invariant knowledge.  The circuits trace the flow of information through the model's layers, focusing on 'time', 'subject', and 'relation' elements to identify which parts of the model process temporal information.  Panel (B) provides a simplified example of a TKC, highlighting the 'Temporal Heads' within the overall circuit.  Panel (C) displays the attention maps of these Temporal Heads, showing how their attention weights are distributed across input tokens. Darker colors represent stronger attention, indicating the importance of certain tokens for temporal understanding.  The results of this analysis are further detailed in Figures 7-8 and 9-11.", "section": "3 Knowledge Circuit Deciphers Temporal Head in LLMs"}, {"figure_path": "https://arxiv.org/html/2502.14258/x3.png", "caption": "Figure 3: Log probability results with temporal knowledge; In XXXX, the president of South Korea was.\n(A) shows prediction probability change among results of Llama2.\nThe effect of head ablation reacts differently for each selected year with the same prompt.\nEach subplot in (A) represents the probability distribution of correct (green) and incorrect (red) predictions, where the x-axis denotes probability values and the y-axis differentiates between target and non-target responses.\nTotal results for each model are in Figures\u00a012\u201313 in Appendix.\n(B) illustrates the performance degradation trends across various years.\nAs averaging the result of ablation, the gray space between two line plots represent degradation level pointed out by red arrows (which becomes darker and bigger when the gap is wider).\nThe background shows how objects were changed in the time range between 1999 to 2009.", "description": "Figure 3 visualizes the impact of ablating temporal attention heads on the model's ability to recall time-specific knowledge.  Part (A) displays, for each year between 1999 and 2009, the probability distribution of correct (green) versus incorrect (red) predictions when specific heads are ablated.  The x-axis shows probability, and the y-axis separates target (correct) from non-target (incorrect) predictions.  Different years show varying degrees of sensitivity to ablation. Part (B) provides a summary, showing the average performance degradation across years. The shaded area between the two lines represents the magnitude of the performance drop, which is highlighted by red arrows that increase in size with greater performance loss. The background shows the changes in the president of South Korea over the 1999-2009 period.", "section": "4 In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x4.png", "caption": "Figure 4: \nHead ablation effect across various knowledge types.\nThree selcted model shows distinct differentiation for temporal knowledge (left side) and time invariant knowledge (right side).\nThe change of performance is calculated with the average score of baseline (non-ablation) and modified (ablated result), using model specific temporal head information.\nWhile degrees of degradation is different among models, overall tendency reflects the importance of temporal head to inference temporal knowledge.", "description": "This figure displays the results of ablating temporal heads in three different large language models (LLMs) on various knowledge tasks.  The left side shows the performance on tasks involving temporal knowledge (knowledge that changes over time), while the right side shows performance on time-invariant knowledge (knowledge that doesn't change over time). Ablation refers to setting the weights of the temporal heads to zero, effectively removing their contribution to the model's processing.  The graph compares the baseline performance (before ablation) to the performance after ablating the temporal heads.  Each bar represents the performance change (average score) for specific categories of temporal or time-invariant knowledge.  The results illustrate that although the magnitude of performance degradation varies across models, the overall trend consistently indicates the crucial role of temporal heads in processing and reasoning about time-dependent information.", "section": "4 In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x5.png", "caption": "Figure 5: Example Of Temporal Knowledge Editing.\nFrom the source prompt, we catch the specific attention value of model\u2019s head, for example, a18.h3.\nBy simply adding it to target prompt, the model\u2019s output is changed into temporally correct answer from temporally wrong answer.\nThe headmap below denotes the number of success in editing for every combination of layers and heads.\nThe most successful case in here is temporal heads a18.h3 as highlighted, following other heads such as backup temporal heads a20.h17.", "description": "This figure demonstrates the concept of temporal knowledge editing.  The researchers identified specific attention heads within a language model (LLM) that are primarily responsible for processing time-sensitive information. These heads are referred to as \"Temporal Heads.\" By manipulating the activation values of these Temporal Heads (specifically head a18.h3 in this example), the researchers can change the model's output for temporally-dependent facts, correcting inaccurate responses without retraining the entire model. The heatmap visually displays the success rate of this editing process across different layers and attention heads within the LLM, showing that a18.h3 and other heads like a20.h17 are the most effective for this task. This technique proves the existence of specialized components within LLMs for handling temporal knowledge.", "section": "Temporal Knowledge Editing"}, {"figure_path": "https://arxiv.org/html/2502.14258/x9.png", "caption": "Figure 6: Results of Causal Tracing for all position(subject, relation, object), six plots for each cases from the top to middle and bottom.\nThe restoring part is set to each temporal conditioning, in two different age: 1999 and 2004.\n(Illustrative) Causal tracing heatmaps showing how restoring different layers (x-axis) after temporal corruption affects p\u2062(New)pNew\\mathrm{p}(\\text{New})roman_p ( New ) or p\u2062(Barcelona)pBarcelona\\mathrm{p}(\\text{Barcelona})roman_p ( Barcelona ).\nFor the object position, we set a simulated [Object] for the place holder.\nEach figure\u2019s left column represents single-layer restoration; the center and right columns reflect MLP vs.\u00a0attention intervals.\nRestoring subject+year at mid layers yields pronounced differences (dark regions).\nOn the other hand, restoring relation+year or object+year yields trivial differences as their range is overlap significantly.", "description": "Figure 6 presents the results of causal tracing experiments, which aim to pinpoint which parts of a language model are responsible for accurate recall of time-specific information.  The experiments focus on three different parts of a knowledge triplet: subject, relation, and object.  Heatmaps visualize the impact of restoring different layers (or groups of layers) of the model after introducing temporal corruption (incorrect year information). Each row shows results for a particular layer type (single layers, MLP intervals, and attention intervals).  The results indicate that restoring subject and year information in middle layers strongly affects prediction accuracy, producing noticeable differences in the heatmaps. In contrast, restoring relation or object information with the incorrect year results in minimal changes in accuracy, showing a much weaker connection to the temporal aspect.", "section": "In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x12.png", "caption": "Figure 7: Temporal knowledge circuit of Llama2.\nIt is simplified version of total circuit by its importance of each nodes using \u03c4=0.1\ud835\udf0f0.1\\tau=0.1italic_\u03c4 = 0.1 as threshold.", "description": "This figure shows a simplified version of the Llama2 model's knowledge circuit, focusing specifically on the parts involved in retrieving temporal knowledge. The circuit is a directed acyclic graph (DAG) where nodes represent components of the model (attention heads, MLP modules, etc.) and edges show the flow of information.  The simplification was achieved using circuit analysis with a threshold (\u03c4 = 0.1) to filter out less important nodes and edges, leaving only those that significantly contribute to retrieving temporal information.  The color-coding of nodes likely indicates different functional components in the processing of time-related information.", "section": "In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x13.png", "caption": "Figure 8: Temporal knowledge circuit of Qwen 1.5 and Phi 3 mini.\nThose are simplified version of total circuit according to each nodes and edges\u2019 importance of using same \u03c4=0.1\ud835\udf0f0.1\\tau=0.1italic_\u03c4 = 0.1 as threshold.", "description": "This figure shows the temporal knowledge circuits for the Qwen-1.5 7B Chat and Phi-3 mini 4K Instruct models.  These circuits illustrate the pathways within the models that are specifically activated when processing information that changes over time. The circuits are simplified versions of the complete models, retaining only the nodes and edges deemed most crucial for handling temporal information, as determined by a threshold of 0.1. This simplification makes it easier to visualize the key components involved in processing time-dependent knowledge.  The circuits are generated using circuit analysis, which pinpoints which model components are responsible for processing specific knowledge tasks. Different colors and shapes represent different model components (such as attention heads, MLP layers, and input/output nodes).  The detailed connections within each circuit reveal how information flows through the model when it processes time-sensitive data. ", "section": "In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x14.png", "caption": "Figure 9: Total map of attention with Llama2-7b-chat-hf, for each temporal heads and backup temporal heads.\nThe left side of border line is the attention map of Temporal Heads, and the other side is the result of Backup Temporal Heads.", "description": "This figure displays the attention maps for both Temporal Heads and Backup Temporal Heads in the Llama2-7b-chat-hf language model.  The attention maps visualize how strongly each head attends to different input tokens. The left half shows the attention patterns of the primary Temporal Heads, while the right half displays the attention patterns of the Backup Temporal Heads. The color intensity in each cell indicates the strength of attention; brighter colors signify stronger attention.  This visualization helps to understand how these specific heads process temporal information within the model architecture during inference.", "section": "4 In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x15.png", "caption": "Figure 10: Total map of attention with Qwen1.5-7B-Chat, for each temporal heads and backup temporal heads.\nThe left side of border line is the attention map of Temporal Heads, and the other side is the result of Backup Temporal Heads.", "description": "This figure visualizes the attention weights of Qwen-1.5-7B-Chat's attention heads, specifically focusing on those identified as 'Temporal Heads' and 'Backup Temporal Heads'.  The attention maps show which tokens the model focuses on when processing time-sensitive information. The left half displays the attention patterns for the primary 'Temporal Heads', highlighting their attention to temporal cues in the input text. The right half shows the attention patterns for the 'Backup Temporal Heads', which are activated when the primary 'Temporal Heads' are unavailable or insufficient. The differences between the two maps illustrate the model's internal mechanisms for handling temporal information, showing the different roles of the primary and backup temporal heads.", "section": "In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x16.png", "caption": "Figure 11: Total map of attention with Phi-3-mini-4k-instruct, for each temporal heads and backup temporal heads.\nThe left side of border line is the attention map of Temporal Heads, and the other side is the result of Backup Temporal Heads.", "description": "This figure visualizes the attention maps of both Temporal Heads and Backup Temporal Heads within the Phi-3-mini-4k-instruct language model.  The attention mechanism is crucial for understanding how the model processes information;  it shows which parts of the input the model focuses on when making predictions. The visualization is divided into two parts by a border line. The left side displays the attention patterns of the Temporal Heads, which are specifically responsible for processing time-related information. The right side shows the attention patterns of the Backup Temporal Heads, which act as a sort of backup or secondary mechanism that activates when the primary Temporal Heads are unable to fully process temporal information.", "section": "4 In-Depth Analysis of Temporal Heads"}, {"figure_path": "https://arxiv.org/html/2502.14258/x19.png", "caption": "Figure 12: Total results of Llama2-7b-chat-hf, head ablation inference with log probability.", "description": "This figure visualizes the results of head ablation inference experiments conducted on the Llama2-7b-chat-hf language model.  It shows the impact of ablating specific attention heads on the model's ability to predict the correct answer for questions with temporal contexts.  For each year (1999-2009), and for three different ablations (one head, the other head, and both heads ablated), the figure displays the log probabilities of both the correct answer (Target) and incorrect answers (Non-Target). The visualization helps to understand the relative importance of specific attention heads in processing temporal information and how their removal affects the model's accuracy over time.", "section": "4 In-Depth Analysis of Temporal Heads"}]