{"references": [{"fullname_first_author": "Ziwei Ji", "paper_title": "Survey of hallucination in natural language generation", "publication_date": "2023-01-01", "reason": "This paper is important because it is a survey on hallucination in natural language generation, highlighting the broad scope of the problem."}, {"fullname_first_author": "Ra\u00fal V\u00e1zquez", "paper_title": "SemEval-2025 Task 3: Mu-SHROOM, the multilingual shared-task on hallucinations and related observable overgeneration mistakes", "publication_date": "2025-01-01", "reason": "The paper introduces the dataset used for evaluating the hallucination detection method, offering a standardized benchmark for comparison."}, {"fullname_first_author": "Potsawee Manakul", "paper_title": "SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models", "publication_date": "2023-01-01", "reason": "This work introduces a zero-resource method for hallucination detection, using the language model itself."}, {"fullname_first_author": "Abhika Mishra", "paper_title": "Fine-grained hallucination detection and editing for language models", "publication_date": "2024-01-01", "reason": "This research focuses on fine-grained hallucination detection and editing in language models, which are important areas for improving the reliability of LLMs."}, {"fullname_first_author": "Yue Zhang", "paper_title": "Siren's song in the AI ocean: A survey on hallucination in large language models", "publication_date": "2023-01-01", "reason": "This paper presents another survey on hallucination in large language models, giving insights into the challenges and potential solutions."}]}