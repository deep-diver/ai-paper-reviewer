[{"figure_path": "https://arxiv.org/html/2503.09669/x1.png", "caption": "Figure 1: Silent branding attack scenario. (Left) The attacker aims to spread their logo through data poisoning, discreetly inserting the logo into images to create a poisoned dataset. (Middle) The poisoned dataset is uploaded to data-sharing communities. (Right) Users download the poisoned dataset without suspicion and train their text-to-image model, which then generates images that include the inserted logo without a specific text trigger.", "description": "This figure illustrates the three stages of a silent branding attack.  First, an attacker subtly inserts their logo into various images within a large dataset, creating a 'poisoned' dataset. This is done discreetly, such that the changes are not easily visible. Second, the poisoned dataset is uploaded to a public data-sharing platform, such as Hugging Face or Civitai, where it can be accessed and downloaded by others.  Third, an unsuspecting user downloads the poisoned dataset, trains a text-to-image diffusion model with it, and subsequently generates images that contain the attacker's logo even without any text prompts explicitly requesting the logo. The user is unaware of the logo's presence and the malicious insertion. The diagram visually depicts these three stages with labeled images.", "section": "4. Silent branding attack via data poisoning"}]