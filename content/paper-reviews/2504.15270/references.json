{"references": [{"fullname_first_author": "Yang, A.", "paper_title": "Qwen2. 5 technical report", "publication_date": "2024-12-15", "reason": "The reference mentions Qwen2.5, which is adopted as the language backbone for the standard implementation of the current work, highlighting its importance as the foundational model."}, {"fullname_first_author": "Touvron, H.", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-13", "reason": "This paper describes the Llama model, which is utilized as an alternative LLM and is also used as a baseline in the experiments, establishing its importance for model comparisons and performance evaluation."}, {"fullname_first_author": "Zhai, X.", "paper_title": "Sigmoid loss for language image pre-training", "publication_date": "2023-01-01", "reason": "This paper describes SigLip, which is used as the visual encoder, highlighting its importance as the foundational model."}, {"fullname_first_author": "Fu, C.", "paper_title": "Video-mme: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis", "publication_date": "2024-05-21", "reason": "Video-MME is the primary benchmark used for evaluating the model's performance, establishing its importance as a key evaluation metric."}, {"fullname_first_author": "Jang, E.", "paper_title": "Categorical reparameterization with gumbel-softmax", "publication_date": "2016-11-01", "reason": "This paper describes the Gumbel Softmax method, which is a crucial component for enabling efficient learning on videos without boundary labels."}]}