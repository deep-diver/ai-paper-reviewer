{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-07-18", "reason": "This paper introduces a method for training visual models using natural language supervision, which is crucial for the image-to-text capabilities of CaPa."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-06-20", "reason": "This paper introduces the latent diffusion model, which is the foundation of CaPa's texture generation process."}, {"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3D Using 2D Diffusion", "publication_date": "2023-05-01", "reason": "Dreamfusion is a key reference because it demonstrates the effectiveness of using 2D diffusion models for 3D asset generation, which is a core concept in CaPa."}, {"fullname_first_author": "Matt Deitke", "paper_title": "Objaverse: A Universe of Annotated 3D Objects", "publication_date": "2023-06-20", "reason": "The Objaverse dataset is the foundation for the training data used in CaPa, making it a critical resource for the paper's success."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), which are fundamental to both the geometry and texture generation stages in CaPa."}]}