[{"figure_path": "https://arxiv.org/html/2501.05441/x3.png", "caption": "Figure 1: Generator G\ud835\udc3aGitalic_G loss for different objectives over training. Regardless of which objective is used, training diverges with only R1subscript\ud835\udc451R_{1}italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and succeeded with both R1subscript\ud835\udc451R_{1}italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and R2subscript\ud835\udc452R_{2}italic_R start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Convergence failure with only R1subscript\ud835\udc451R_{1}italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT was noted by Lee et al.\u00a0[42].", "description": "The figure shows the Generator's loss curves during training for various GAN loss functions.  The x-axis represents the training time, and the y-axis represents the Generator's loss. Different lines represent different loss functions, including the combination of RpGAN loss with different gradient penalties (R1 and/or R2).  The plot highlights the instability of GAN training when using only the R1 gradient penalty, leading to divergence. However, the combination of R1 and R2 penalties results in stable training and convergence, which is consistent with the theoretical analysis presented in the paper.", "section": "Serving Two Masters: Stability and Diversity with RpGAN + R1 + R2"}, {"figure_path": "https://arxiv.org/html/2501.05441/", "caption": "Figure 2: StackedMNIST\u00a0[46] result for each loss function. The maximum possible mode coverage is 1000. \u201cFail\u201d indicates that training diverged early on.", "description": "This figure shows the results of an experiment on the StackedMNIST dataset, which consists of 1000 uniformly distributed modes. Different loss functions were used to train a GAN, and the figure displays the maximum mode coverage achieved by each loss function. The maximum possible mode coverage is 1000, meaning that a perfect GAN would capture all 1000 modes. The 'Fail' entries indicate cases where the training process diverged early on, preventing the GAN from reaching a satisfactory solution.", "section": "Serving Two Masters: Stability and Diversity with RpGAN + R1 + R2"}, {"figure_path": "https://arxiv.org/html/2501.05441/extracted/6122118/figures/qualitative/ffhq64.png", "caption": "Figure 3: Architecture comparison.\nFor image generation, G\ud835\udc3aGitalic_G and D\ud835\udc37Ditalic_D are often both deep ConvNets with either partially or fully symmetric architectures.\n(a)\nStyleGAN2\u00a0[31] G\ud835\udc3aGitalic_G uses a network to map noise vector z\ud835\udc67zitalic_z to an intermediate style space \ud835\udcb2\ud835\udcb2\\mathcal{W}caligraphic_W. We use a traditional generator as style mapping is not necessary for a minimal working model.\n(b)\nStyleGAN2\u2019s building blocks have intricate layers but are themselves simple, with a ConvNet architecture from 2015\u00a0[38, 73, 16]. ResNet\u2019s identity mapping principle is also violated in the discriminator.\n(c)\nWe remove tricks and modernize the architecture. Our design has clean layers with a more powerful ConvNet architecture.", "description": "Figure 3 provides a detailed comparison of the architectures used in StyleGAN2 and the proposed R3GAN model for image generation.  StyleGAN2's architecture (part (b)) is presented as complex due to its reliance on intricate layers and features. Part (a) provides a simple comparison between the generator and discriminator of both models, and highlights some of the differences such as the style-mapping network in StyleGAN2 which is absent from R3GAN. The proposed R3GAN architecture (part (c)) is described as minimalist and modern, emphasizing its use of cleaner, more powerful ConvNet layers compared to StyleGAN2.", "section": "A Roadmap to a New Baseline R3GAN"}, {"figure_path": "https://arxiv.org/html/2501.05441/extracted/6122118/figures/qualitative/cifar-10-000222209.jpg", "caption": "Figure 4: \nFFHQ-256. * denotes models that leak ImageNet features.", "description": "Figure 4 presents qualitative samples generated by the R3GAN model (Config E) on the FFHQ-256 dataset.  It showcases the visual quality of images produced by the model, highlighting the realism and diversity achieved through the proposed method. This figure visually demonstrates the capabilities of the simplified and modernized GAN architecture introduced in the paper.", "section": "4 Experiments Details"}, {"figure_path": "https://arxiv.org/html/2501.05441/extracted/6122118/figures/qualitative/imgnet-32-000681275.jpg", "caption": "Figure 5: FFHQ-64.", "description": "Figure 5 displays several images generated by the R3GAN model on the FFHQ-64 dataset.  FFHQ-64 refers to the high-resolution Flickr Faces-HQ dataset, downsampled to 64x64 pixels. This figure showcases the model's ability to generate realistic-looking faces at this lower resolution, demonstrating its capacity for generating high-quality images across different resolutions. The images represent a range of facial features and expressions, highlighting the diversity of the model's output. The figure visually complements the quantitative results presented in the paper, providing evidence of the model's performance in terms of image generation quality and variety.", "section": "4.1 Roadmap Insights on FFHQ-256"}, {"figure_path": "https://arxiv.org/html/2501.05441/extracted/6122118/figures/qualitative/imgnet64.png", "caption": "Figure 6: Millions of parameters vs.\u00a0FID-50K (log scale) on CIFAR-10. Lower is better.", "description": "This figure shows the relationship between the number of parameters in a generative model and its performance on the CIFAR-10 dataset, measured by the Fr\u00e9chet Inception Distance (FID) score.  The x-axis represents the number of parameters (in millions) on a logarithmic scale, while the y-axis shows the FID score. A lower FID indicates better performance, meaning that the generated images are more realistic and similar to real images from the dataset.  The plot allows for a comparison of different models' efficiency in terms of parameter usage and image quality.", "section": "4 Experiments Details"}]