[{"figure_path": "https://arxiv.org/html/2501.06458/x1.png", "caption": "Figure 1: Illustration of our O1 replication journey in the medical field.  which aims to develop systems capable of deep scientific thinking, ultimately enabling AI-driven breakthroughs in medical domains.", "description": "The figure is a stylized illustration depicting the overall goal of the O1 Replication Journey project in the medical domain.  It shows a progression from simple clinical problems to more complex ones, highlighting the use of inference-time scaling to improve the accuracy of large language models (LLMs) in medical reasoning tasks. The journey is depicted metaphorically as a path leading to a treasure chest, symbolizing the ultimate breakthroughs in AI-driven medical advancements made possible by deep scientific thinking and improved reasoning capabilities.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.06458/x2.png", "caption": "Figure 2: Weighted mean accuracy of Qwen2.5-72B-Instruct, LLama3.1-70B, and Qwen2.5-32B across three datasets using distinct strategies.", "description": "This figure displays a comparison of the mean accuracy achieved by three different large language models (LLMs)\u00a0\u2013 Qwen2.5-72B-Instruct, LLama3.1-70B, and Qwen2.5-32B \u2013 across three distinct medical datasets.  The models' performance is evaluated using various reasoning strategies, such as vanilla usage, chain-of-thought prompting, supervised fine-tuning with chain-of-thought, and journey learning using long steps and long monologues. The x-axis represents the different reasoning strategies employed, and the y-axis shows the weighted mean accuracy for each strategy across the three datasets.  The figure visually demonstrates the performance improvement gained by incorporating more sophisticated reasoning strategies, particularly those leveraging longer thought processes and incorporating journey learning data.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06458/x3.png", "caption": "Figure 3: The Accuracy of Qwen2.5-72B-Series on MedQA with inference-time scaling.", "description": "This figure shows how the accuracy of the Qwen2.5-72B model on the MedQA benchmark changes with increased inference time, achieved by varying the number of output tokens per problem.  It compares four different strategies: the vanilla model, the vanilla model with Chain-of-Thought prompting, the model fine-tuned using the LongStep method (a journey learning approach), and the model fine-tuned using the LongMonolog method (another journey learning approach).  Each strategy is tested with majority voting at different round numbers (4, 8, 16, and 32 rounds), further expanding inference time. The graph illustrates how different inference-time scaling techniques impact the model's performance on MedQA, showing the relationship between token count and accuracy.", "section": "3.3 Does Inference-time Scaling Help?"}, {"figure_path": "https://arxiv.org/html/2501.06458/x4.png", "caption": "Figure 4: The benefits of prompting open-source models to solve problems step by step are illustrated. The positive axis indicates that breaking down the problem into smaller steps can enhance model performance, while the negative axis suggests that doing so may lead to diminished returns. Each bubble represents a different model, with bubble size corresponding to the model\u2019s parameter size.", "description": "Figure 4 visualizes the impact of using step-by-step reasoning (chain-of-thought prompting) on the performance of various open-source large language models (LLMs) across three medical datasets (JAMA, Medbullets, MedQA).  The x-axis represents the percentage change in accuracy achieved by employing a step-by-step approach compared to a standard approach. A positive value indicates improved accuracy through step-by-step reasoning, while a negative value indicates diminished performance.  Each bubble represents a different LLM, and its size corresponds to the model's parameter count, allowing for a visual representation of the relationship between model size and the effectiveness of chain-of-thought prompting.  Models that benefit from step-by-step reasoning are grouped toward the positive side; those that do not benefit or experience decreased performance cluster toward the negative side.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06458/x5.png", "caption": "Figure 5: Comparison of accuracy and average length of output tokens of Qwen2.5-72B across three datasets using distinct strategies(from left to right: Vanilla CoT, LongStep and LongMonolog)", "description": "Figure 5 presents a comparative analysis of the Qwen2.5-72B model's performance across three medical datasets (JAMA, Medbullets, and MedQA) using different reasoning strategies.  The x-axis represents the three datasets categorized by difficulty (easy to hard), and the y-axis displays the model's accuracy.  Each bar group shows the accuracy for three distinct methods: Vanilla CoT, LongStep, and LongMonolog.  The number above each bar indicates the average length of the output tokens generated for each strategy within that dataset. The figure demonstrates how the model's accuracy and the length of reasoning steps correlate with the complexity of the medical cases in each dataset and the reasoning strategy employed.", "section": "3.4 Harder Tasks, Longer Thoughts, More Inference Time"}, {"figure_path": "https://arxiv.org/html/2501.06458/x6.png", "caption": "Figure 6: Problem of Differential Diagnosis from JAMA Clinical Challenges", "description": "This figure presents a case study from the JAMA Clinical Challenges dataset, illustrating a complex clinical scenario requiring differential diagnosis.  The case details a 72-year-old male patient with a history of polycythemia vera, exhibiting symptoms and laboratory/imaging results that point towards several possible conditions. The challenge is to determine the most likely diagnosis based on the provided information. The image displays a more detailed description of the case, showing various aspects such as clinical history, symptoms, lab results, and imaging.", "section": "Case: Problem of Differential Diagnosis"}, {"figure_path": "https://arxiv.org/html/2501.06458/x7.png", "caption": "Figure 7: Free-form Response: Incorrect Output of Qwen2.5-72B to Differential Diagnosis", "description": "This figure displays an incorrect diagnosis made by the Qwen-2.5-72B model when responding in a free-form text format to a differential diagnosis problem.  It shows a step-by-step breakdown of the model's reasoning, starting from clinical history and symptoms, then detailing laboratory, hematologic, and imaging findings, finally concluding with a differential diagnosis and its explanation.  The model's response is flawed because it doesn't correctly identify the transformation of polycythemia vera to myelofibrosis as the likely diagnosis, leading to an incorrect final answer.", "section": "3.5 Generalizability and Future Directions"}, {"figure_path": "https://arxiv.org/html/2501.06458/x8.png", "caption": "Figure 8: Free-form Respons: Correct Output of Qwen2.5-72B-LongMonolog to Differential Diagnosis", "description": "Figure 8 displays the detailed reasoning process and the final diagnosis provided by the Qwen-2.5-72B model using the LongMonolog approach for a differential diagnosis problem from the JAMA Clinical Challenges dataset.  The model presents a step-by-step analysis of the patient's clinical history, laboratory findings, and imaging results, systematically evaluating various potential diagnoses and ultimately arriving at the correct diagnosis of Erdheim-Chester disease.  The figure highlights the model's ability to generate a long, coherent chain of thought that mimics human-like reasoning, considering multiple differential diagnoses and integrating various pieces of information to arrive at a reasoned conclusion.", "section": "3.5 Generalizability and Future Directions"}, {"figure_path": "https://arxiv.org/html/2501.06458/x9.png", "caption": "Figure 9: Case of problems for synthesizing data.", "description": "Figure 9 shows an example of a medical case used to create synthetic training data for the model.  The case details a 68-year-old man experiencing recurrent nausea and abdominal discomfort for four months, particularly after large meals or exertion. He has a history of type 2 diabetes, hypertension, and peripheral arterial disease. The question is what is the most appropriate next step in diagnosis given the patient presentation and medical history.  The image presents this clinical case in a format suitable for including in machine learning training data.", "section": "2.2 Journey Learning Data Synthesis"}, {"figure_path": "https://arxiv.org/html/2501.06458/x10.png", "caption": "Figure 10: One case of JAMA problems.", "description": "The figure displays a clinical case from the JAMA Clinical Challenge dataset.  It presents a patient history of an 80-year-old man who had a total gastrectomy for gastric adenocarcinoma, and now exhibits asymptomatic lesions on his tongue. The images show yellowish plaques in a cobblestone pattern on both sides of the tongue.  The histopathology images reveal circumscribed eosinophilic, amorphous fissured masses in the subepithelial connective tissue. The question posed is to determine the diagnosis based on the given information.", "section": "2.1 Benchmark Overview"}, {"figure_path": "https://arxiv.org/html/2501.06458/x11.png", "caption": "Figure 11: Case of our distilled long step data for the problem.", "description": "Figure 11 shows an example from the dataset created by distilling long-step reasoning processes.  The figure presents a structured, step-by-step approach to solving a medical diagnosis problem. Each step includes detailed analysis of patient history, symptoms, lab results, and other relevant information leading to a final diagnosis. This approach demonstrates the journey learning concept, where the model systematically breaks down a complex problem into smaller, manageable steps.", "section": "2.2 Journey Learning Data Synthesis"}]