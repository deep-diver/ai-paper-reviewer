[{"Alex": "Hey everyone, welcome to the podcast! Today, we're diving into a topic that's going to blow your mind: teaching robots common sense! Forget everything you thought you knew about AI, because we're about to unlock the secrets of how to make machines truly understand the world around them. I'm Alex, and I'm thrilled to have Jamie with us today to explore this fascinating field.", "Jamie": "Wow, Alex, that sounds incredible! I'm Jamie, and honestly, the idea of robots having common sense feels like something straight out of a sci-fi movie. Where do we even begin?"}, {"Alex": "Great question, Jamie! Well, think about it this way: robots are amazing at following instructions, but they often struggle with unexpected situations. This research paper, titled 'Cosmos-Reason1: From Physical Common Sense to Embodied Reasoning', introduces a new approach to equipping AI with what we call 'physical common sense.' It\u2019s about enabling them to perceive, understand, and make decisions in the real world, much like we do.", "Jamie": "So, it's about making robots less robotic, umm, and more adaptable to different situations? How does this differ from all the other AI research that's been going on?"}, {"Alex": "Exactly! The key is the focus on physical common sense and embodied reasoning. Most AI excels at tasks like coding or math, but struggles to connect that knowledge to real-world interactions. This research focuses on giving AI a fundamental understanding of space, time, and physics, basically, the underlying rules of our physical world. Then, it layers on 'embodied reasoning,' which is how different types of 'agents,' like humans, robots, or even self-driving cars, can interact effectively with their environment.", "Jamie": "Hmm, so how do they actually *teach* common sense to a robot? Does it involve showing them a bunch of YouTube videos?"}, {"Alex": "It's a bit more sophisticated than that, Jamie! The researchers developed two large language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B, and trained them in four stages. First, there\u2019s vision pre-training to help them 'see' the world. Then, they go through general supervised fine-tuning (SFT), followed by Physical AI SFT, which is tailored to understanding physical concepts. Finally, Physical AI reinforcement learning (RL) is used as post-training to refine their decision-making.", "Jamie": "So, what's SFT? Is that like giving the robot a bunch of examples and saying, 'Learn from this'?"}, {"Alex": "You're on the right track! SFT, or supervised fine-tuning, is essentially showing the model a lot of labeled data where it learns to map inputs to desired outputs. In this case, it involves showing the models examples of visual scenes and corresponding natural language descriptions, actions, and explanations. The Physical AI SFT is particularly interesting because they've curated data based on two ontologies: one for physical common sense and another for embodied reasoning.", "Jamie": "Okay, ontologies, that sounds\u2026 complex. Can you break that down? What do these ontologies actually look like?"}, {"Alex": "Sure! Think of an ontology as a structured way of organizing knowledge. The physical common sense ontology is hierarchical, with three main categories: space, time, and fundamental physics, further divided into 16 subcategories like relationships, plausibility, actions, mechanics, and object permanence. The embodied reasoning ontology is two-dimensional, covering four key reasoning capabilities across five types of embodied agents, generalizing across different forms of embodiment.", "Jamie": "So, the ontology lays out all the things the robot *should* know. How do they make sure the robot actually *learns* it?"}, {"Alex": "That's where the Physical AI SFT and reinforcement learning come in. The researchers curate specific datasets aligned with the ontologies. They use techniques like human annotation and model distillation to generate question-answer pairs and reasoning traces, essentially examples of how to think through problems. Then, they use reinforcement learning with rule-based, verifiable rewards to encourage the model to make correct decisions.", "Jamie": "Rule-based rewards? Are we talking like giving the robot a digital cookie every time it gets something right?"}, {"Alex": "Haha, you could think of it that way! But it\u2019s a bit more sophisticated. The rewards are based on answering multiple-choice questions correctly. One type is designed based on human annotations, and the other is generated automatically based on the video data itself, like solving puzzles or predicting the flow of time in a video. The key is that the rewards are verifiable and directly related to physical AI capabilities.", "Jamie": "Okay, so the robot learns by trying to answer questions, and it gets rewarded for right answers. How well does all of this actually *work*? Did they see a significant improvement?"}, {"Alex": "That\u2019s the exciting part, Jamie! The researchers created comprehensive benchmarks to evaluate their models, and the results are impressive. They found that Physical AI SFT and reinforcement learning significantly improved the models' ability to reason about physical common sense and make embodied decisions. For example, the 56B variant even slightly outperformed OpenAI's 01 model on the physical common sense benchmark.", "Jamie": "Wow, that's huge! So, what kind of tests were they doing to measure 'common sense'? Were they asking the robot if the sky is blue?"}, {"Alex": "The benchmarks were more complex than that! For physical common sense, they used three benchmarks: space, time, and fundamental physics, containing questions about videos. For embodied reasoning, they used six benchmarks covering a range of tasks across different embodiments, including humans, robot arms, and self-driving cars. These tasks involve things like understanding spatial relationships, predicting action effects, and respecting physical constraints.", "Jamie": "So, how were these robots tested? I mean, what did they ask them to see if they knew the concepts?"}, {"Alex": "They would show the robot a video clip and then ask a question about it. For example, they might show a video of someone stacking blocks and ask, 'Is this a stable structure?' or 'What will happen if I remove this block?' For self-driving cars, they might show a video of a traffic scenario and ask, 'What is the most likely next action the car will take?'", "Jamie": "Okay, I see. So, it's not just about knowing facts, but also about being able to *apply* that knowledge to understand what's going on in a dynamic situation. umm, what were some of the biggest challenges they faced in doing this research?"}, {"Alex": "One of the biggest hurdles was the lack of existing data. Unlike other AI domains, there weren't many readily available datasets designed for training physical AI. So, the researchers had to develop their own specialized pipeline for curating data, which involved human annotation, model distillation, and careful cleaning and rewriting of the data.", "Jamie": "Model distillation? Sounds like moonshine to me. "}, {"Alex": "It's quite different. Model distillation is a training process where a smaller model is trained to mimic the behavior of a larger, more complex model. In this case, they used a powerful model called DeepSeek-R1 to generate reasoning traces, which were then used to train the Cosmos-Reason1 models.", "Jamie": "Ah, so it's like learning from a super-smart teacher. What about the ethical implications of giving robots this kind of common sense? Could it be used for, you know, less-than-ethical purposes?"}, {"Alex": "That's a crucial consideration. As with any AI technology, there are potential risks. For example, robots with enhanced physical common sense could be used in autonomous weapons systems or for surveillance purposes. It's important to have robust ethical guidelines and regulations in place to ensure that this technology is used responsibly and for the benefit of humanity.", "Jamie": "Speaking of the future, what are the next steps for this research? Where do you see this field heading in the next few years?"}, {"Alex": "The researchers highlight several exciting avenues for future work. One is to improve the models' ability to learn from interaction, allowing them to adapt their behavior dynamically based on feedback from the environment. Another is to explore different types of embodied agents and tasks, pushing the boundaries of what's possible with physical AI.", "Jamie": "It sounds like there's a lot more to explore! What are the limitations of the current version of cosmos reason? We didn't really talk about what's wrong with it! "}, {"Alex": "That's right! One limitation the researchers identified was the challenge of evaluating the *quality* of reasoning. The tests measure accuracy but don't evaluate if the models derive the answer by the right means. They also observe their models perform worse on some specialized tests requiring high observation skills, which prompts further improvements on models to see smaller visual elements.", "Jamie": "So, there's still room to grow. Is the code open-source? Can other researchers build on their work?"}, {"Alex": "Yes, absolutely! To facilitate the development of Physical AI, the researchers are making their code and pre-trained models available under the NVIDIA Open Model License. This will allow other researchers to build on their work and accelerate progress in the field.", "Jamie": "That's fantastic! Open source has always allowed for the democratization of knowledge, and I think this is a major step for other people to come in and improve!"}, {"Alex": "Exactly, it allows more progress. So, Jamie, after delving into the Cosmos-Reason1 research, what are your overall impressions?", "Jamie": "Honestly, Alex, I'm blown away! This research feels like a real game-changer. The idea of robots that can truly understand and interact with the physical world opens up so many possibilities. From assistive robots that can help people in their homes to self-driving cars that can navigate complex situations, the potential applications are endless. I'm still a little nervous about the ethical implications, but I'm also incredibly excited to see what the future holds."}, {"Alex": "Well put! And, with this knowledge, how would you summarize Cosmos-Reason1? What's one takeaway people should have?", "Jamie": "Cosmos-Reason1 is more than just another AI model; it's a step towards machines that truly "}, {"Alex": "That's it for today's podcast! Cosmos-Reason1 is a step toward machines that truly grasp and interact with the world, not just follow instructions blindly. By creating detailed ways to teach and test these machines, this NVIDIA team is pushing the boundaries of AI's potential. As AI continues to evolve, research like this will pave the way for robots that enhance our lives in countless ways. Thanks for tuning in!", "Jamie": "Thanks for having me!"}]