{"references": [{"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "This paper introduces 3D Gaussian Splatting, which is used by VideoScene as a feed-forward model for generating a coarse 3D representation."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces Neural Radiance Fields (NeRF), a foundational technique for representing 3D scenes that VideoScene references as a method requiring hundreds of input images."}, {"fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2020-10-01", "reason": "This paper introduces Denoising Diffusion Implicit Models (DDIM), which are used for sampling during the video generation process within VideoScene."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-03-01", "reason": "This paper introduces Consistency Models, and VideoScene proposes using a 3D-aware leap flow distillation strategy to improve them with 3D prior constraints."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "Dynamicrafter: Animating open-domain images with video diffusion priors", "publication_date": "2025-01-01", "reason": "Dynamicrafter is a baseline video frame interpolation model VideoScene is compared against."}]}