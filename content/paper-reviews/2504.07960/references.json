{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-01-01", "reason": "This paper is foundational, introducing in-context learning, a core concept VisualCloze adapts for the visual domain."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper, introducing CLIP, is important because VisualCloze uses CLIP scores for evaluating text consistency, a critical aspect of its image generation framework."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper on latent diffusion models is important as VisualCloze builds upon diffusion models for image synthesis."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper introduces rectified flow transformers, the model upon which the VisualCloze model is built."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper is important as VisualCloze compares against ControlNet for image generation and image restoration."}]}