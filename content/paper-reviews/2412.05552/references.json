{"references": [{"fullname_first_author": "Peter Anderson", "paper_title": "Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments", "publication_date": "2018-00-00", "reason": "This paper is foundational in establishing the Vision-and-Language Navigation (VLN) task, which the current paper builds upon and extends."}, {"fullname_first_author": "Yicong Hong", "paper_title": "Learning Language-Guided Visual Navigation", "publication_date": "2023-00-00", "reason": "This PhD thesis provides a comprehensive overview of the field, which informs the current paper's approach and methodology."}, {"fullname_first_author": "Shizhe Chen", "paper_title": "Think global, act local: Dual-scale graph transformer for vision-and-language navigation", "publication_date": "2022-00-00", "reason": "This paper introduces the DUET model, which serves as the basis for the current paper's architecture."}, {"fullname_first_author": "Devendra Singh Chaplot", "paper_title": "Object goal navigation using goal-oriented semantic exploration", "publication_date": "2020-00-00", "reason": "This paper provides important insights into ObjectGoal Navigation, which helps to frame the current paper's discussion of task diversity."}, {"fullname_first_author": "Noam Shazeer", "paper_title": "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer", "publication_date": "2017-00-00", "reason": "This paper introduces the Mixture of Experts (MoE) architecture, a crucial component of the model proposed in the current paper."}]}