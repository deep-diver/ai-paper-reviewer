{"importance": "**Whisper-GPT introduces a novel approach to audio LLMs**, merging continuous and discrete representations. This is crucial for researchers exploring efficient long-context audio modeling. **The hybrid approach reduces computational burden**, enabling broader academic access to advanced audio LLM research and allowing to train audio LLMs on machines which are normally computationally infeasible.  The improved perplexity and likelihood scores suggest potential for higher-quality audio generation. The architecture's flexibility opens up exciting new research directions in hybrid modeling for other modalities.", "summary": "Whisper-GPT, a hybrid audio LLM, improves music/speech generation by combining audio waveforms and text.", "takeaways": ["Whisper-GPT, a hybrid audio LLM, combines continuous audio and discrete token representations, outperforming purely token-based models.", "It improves perplexity and negative log-likelihood scores for next token prediction in music and speech datasets.", "The hybrid approach offers a more efficient way to handle long audio sequences compared to traditional token-based LLMs by allowing to predict coarsest acoustic tokens with fewer parameters"], "tldr": "Current **audio generative models rely heavily on discrete audio tokens**, which struggle with long audio sequences due to increased context length. This results in high computational costs, making it challenging to train these models.  Traditional continuous representations like spectrograms **lack the ability to predict future tokens easily**, which makes them not suitable to be used as a stand-alone representation. This limits their ability to generate diverse and high-quality audio. **Current methods** to circumvent some of these issues **either require enormous computing resources or do not provide an efficient path to high-quality audio generation**. \nThis paper proposes **Whisper-GPT, a hybrid model** that leverages the strengths of both continuous and discrete representations. By combining mel-spectrograms with discrete acoustic tokens, Whisper-GPT efficiently processes long audio contexts. **This innovative architecture significantly improves the perplexity and negative log-likelihood scores**, demonstrating its effectiveness in predicting future audio tokens and reducing the computational needs compared to purely token-based models, by using fewer parameters and making pre-training these models more accessible. This is done by predicting coarsest acoustic tokens based on this hybrid representation.", "affiliation": "Stanford University", "categories": {"main_category": "Speech and Audio", "sub_category": "Audio Generation"}, "podcast_path": "2412.11449/podcast.wav"}