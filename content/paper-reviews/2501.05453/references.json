{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-XX-XX", "reason": "This paper introduced the Transformer architecture, a fundamental building block of many large language models and the foundation for the video models in this study."}, {"fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-XX-XX", "reason": "This paper demonstrated the capabilities of large language models to perform various tasks with minimal fine-tuning, establishing the foundation for autoregressive pre-training methods."}, {"fullname_first_author": "Mark Chen", "paper_title": "Generative pretraining from pixels", "publication_date": "2020-XX-XX", "reason": "This study explored autoregressive pre-training for image generation, providing a foundation for extending the technique to video which is done in this paper."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-XX-XX", "reason": "This paper introduced a powerful zero-shot text-to-image generation model, dVAE, used for tokenizing images and videos in this study."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-XX-XX", "reason": "This study explored masked autoencoders for visual representation learning, a key technique compared in this paper"}]}