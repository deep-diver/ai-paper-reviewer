{"references": [{"fullname_first_author": "Lianghua Huang", "paper_title": "Group diffusion transformers are unsupervised multitask learners", "publication_date": "2024-10-01", "reason": "This paper introduces the concept of Group Diffusion Transformers (DiTs), which is the foundational model upon which ChatDiT is built, demonstrating the potential of DiTs for zero-shot task generalization through the use of group data for training."}, {"fullname_first_author": "Lianghua Huang", "paper_title": "In-context LoRA for diffusion transformers", "publication_date": "2024-10-01", "reason": "This work highlights the inherent in-context generation capabilities of pre-trained diffusion transformers, using a small dataset and LoRA, which directly inspires the fully training-free approach of ChatDiT."}, {"fullname_first_author": "Chen Liang", "paper_title": "IDEA-Bench: How far are generative models from professional designing?", "publication_date": "2024-12-01", "reason": "This work introduces the IDEA-Bench used for evaluating ChatDiT, a comprehensive benchmark designed to assess real-world visual generation capabilities across various design tasks and instructions."}, {"fullname_first_author": "Omri Avrahami", "paper_title": "Blended diffusion for text-driven editing of natural images", "publication_date": "2022-01-01", "reason": "This paper introduces the blended diffusion technique for image inpainting, a crucial component of ChatDiT's in-context toolkit which allows for training-free editing and generation based on visible regions in an image."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-01-01", "reason": "This work introduces one of the first highly successful text-to-image models, demonstrating the potential of such methods for image generation from natural language prompts, which serves as a conceptual cornerstone for later works like ChatDiT."}]}