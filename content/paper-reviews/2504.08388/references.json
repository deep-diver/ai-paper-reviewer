{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture, which is the foundation of MineWorld's decoder."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-01-01", "reason": "This paper demonstrates the scaling behavior of large language models, justifying the use of a Transformer-based architecture."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-01-01", "reason": "This paper introduces the LLaMA architecture, which MineWorld uses as the base for its Transformer decoder."}, {"fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (vpt): Learning to act by watching unlabeled online videos", "publication_date": "2022-01-01", "reason": "This paper introduces the VPT dataset, which MineWorld utilizes for training its model, and also uses an Inverse Dynamics Model (IDM) which this paper uses."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-01-01", "reason": "This paper is the base for VQ-VAE, which MineWorld uses as the visual tokenizer for game videos."}]}