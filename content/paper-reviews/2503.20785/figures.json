[{"figure_path": "https://arxiv.org/html/2503.20785/x2.png", "caption": "Figure 1: Free4D can generate diverse 4D scenes from single-image or textual input. By enforcing spatial-temporal consistency in a tuning-free way, Free4D enables high-quality scene generation with explicit 4D controls.", "description": "This figure showcases the capabilities of the Free4D model.  The top row demonstrates examples of diverse 4D scenes generated from either a single image or a textual description. The bottom row displays a sequence of images across time from a generated 4D scene, illustrating the temporal consistency maintained by Free4D. The model's ability to generate high-quality 4D content without requiring any parameter tuning or extensive training is a key highlight.  The explicit 4D controls allow for precise manipulation and generation of the scenes.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.20785/x3.png", "caption": "Figure 2: Overview of Free4D. Given an input image or text prompt, we first generate a dynamic video \ud835\udcb1={I\u2062(t,1)}t=1T\ud835\udcb1superscriptsubscript\ud835\udc3c\ud835\udc611\ud835\udc611\ud835\udc47\\mathcal{V}=\\{I(t,1)\\}_{t=1}^{T}caligraphic_V = { italic_I ( italic_t , 1 ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT using an off-the-shelf video generation model\u00a0[59]. Then, we employ MonST3R\u00a0[77] with a progressive static point cloud aggregation strategy for dynamic reconstruction, obtaining a 4D geometric structure. Next, guided by this structure, we render a coarse multi-view video \ud835\udcae\u2032={{I\u2032\u2062(t,k)}t=1T}k=1Ksuperscript\ud835\udcae\u2032superscriptsubscriptsuperscriptsubscriptsuperscript\ud835\udc3c\u2032\ud835\udc61\ud835\udc58\ud835\udc611\ud835\udc47\ud835\udc581\ud835\udc3e\\mathcal{S}^{\\prime}=\\{\\{I^{\\prime}(t,k)\\}_{t=1}^{T}\\}_{k=1}^{K}caligraphic_S start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = { { italic_I start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_t , italic_k ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT along a predefined camera trajectory and refine it into \ud835\udcae={{I\u2062(t,k)}t=1T}k=1K\ud835\udcaesuperscriptsubscriptsuperscriptsubscript\ud835\udc3c\ud835\udc61\ud835\udc58\ud835\udc611\ud835\udc47\ud835\udc581\ud835\udc3e\\mathcal{S}=\\{\\{I(t,k)\\}_{t=1}^{T}\\}_{k=1}^{K}caligraphic_S = { { italic_I ( italic_t , italic_k ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT using ViewCrafter\u00a0[76]. To ensure spatial-temporal consistency, we introduce Adaptive Classifer-Free Guidance (CFG) and Point Cloud Guided Denoising for spatial coherence, along with Reference Latent Replacement for temporal coherence. Finally, we propose an efficient training strategy with a Modulation-Based Refinement to lift the generated multi-view video \ud835\udcae\ud835\udcae\\mathcal{S}caligraphic_S into a consistent 4D representation \u211b\u211b\\mathcal{R}caligraphic_R.", "description": "Figure 2 illustrates the Free4D framework. Starting with a single image or text input, a dynamic video is generated using an existing video generation model.  This video then undergoes dynamic reconstruction using MonST3R, resulting in a 4D geometric structure. This structure guides the generation of a coarse multi-view video, which is subsequently refined using ViewCrafter to ensure spatial-temporal consistency.  Techniques such as Adaptive Classifier-Free Guidance, Point Cloud Guided Denoising, and Reference Latent Replacement are used to enhance consistency. Finally, a modulation-based refinement optimizes the multi-view video to produce a coherent 4D representation.", "section": "4. Free4D"}, {"figure_path": "https://arxiv.org/html/2503.20785/x4.png", "caption": "Figure 3: Qualitative comparisons of image-to-4D.\nWe present the results using the same single-image prompts.", "description": "This figure shows a qualitative comparison of the image-to-4D scene generation results produced by Free4D and three other methods (GenXD, Free4D, DimensionX, Animate124).  The comparison uses the same single-image prompts as input for all four methods, allowing for a direct visual assessment of the relative strengths and weaknesses of each approach in terms of generating high-quality 4D scenes from a single image.  The differences in scene fidelity, realism, and overall visual quality are clearly evident in the generated output.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.20785/x5.png", "caption": "Figure 4: Qualitative comparisons of text-to-4D. We show the results based on the same text prompts.", "description": "This figure displays a qualitative comparison of the results produced by different methods for text-to-4D scene generation.  Each row corresponds to a different text prompt, and several generated scenes, each produced by different methods, are shown side-by-side for comparison. This allows for a visual assessment of the differences in terms of generation quality, realism, detail level, and consistency across different methods. The visual comparison helps to demonstrate the advantages of the proposed Free4D model.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.20785/x6.png", "caption": "Figure 5: Qualitative Comparison of Ablation Studies.", "description": "This ablation study visually compares the results of Free4D with different components removed or modified to highlight their individual contributions to the model's performance.  It shows how each part of the pipeline (4D Structure Initialization, Adaptive CFG, Point Cloud Guided Denoising, Latent Replacement, Coarse-to-Fine Optimization, Modulation-Based Refinement, and Static Point Cloud Aggregation) affects the consistency, dynamics, and aesthetics of the generated video. The results are shown qualitatively through side-by-side comparisons of the full model's output versus the modified versions.", "section": "5.3 Ablations and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.20785/x7.png", "caption": "Figure 6: Comparison of different methods based on the user study.", "description": "This figure presents a bar chart summarizing the results of a user study comparing Free4D to other methods in terms of consistency, dynamics, and aesthetics.  Each bar represents the win rate of a particular method against Free4D, indicating how often users preferred a given method over Free4D.  Higher bars represent better performance relative to Free4D, suggesting which aspects of the compared methods users found most compelling. The chart provides a visual comparison of user preferences for each criteria across the various methods, offering valuable insights into the strengths and weaknesses of Free4D relative to state-of-the-art approaches.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.20785/x8.png", "caption": "Figure A: The web interface of our user studies. The input prompt can be either a single image or a short text.", "description": "This figure displays the web interface used for the user studies conducted in the paper. Participants were presented with an input prompt, which could be either a single image or a short text description.  The interface allows users to compare two different methods' results side-by-side, evaluating each based on criteria like consistency, dynamics, aesthetics, and an overall assessment. Participants can navigate through multiple comparison sets and submit their judgments.", "section": "5. Experiments"}]