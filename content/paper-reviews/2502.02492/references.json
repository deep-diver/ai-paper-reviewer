{"references": [{"fullname_first_author": "Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-00-00", "reason": "This paper is a significant contribution to the field, introducing advanced video generation models and showcasing their capabilities as world simulators."}, {"fullname_first_author": "Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This foundational work introduced diffusion probabilistic models, a powerful technique that significantly impacted generative modeling across various domains, including images and videos."}, {"fullname_first_author": "Polyak", "paper_title": "Movie gen: A cast of media foundation models", "publication_date": "2024-00-00", "reason": "This work provides a strong benchmark for evaluating large-scale video generation models, establishing a standard for comparison and pushing the boundaries of what is possible in the field."}, {"fullname_first_author": "Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-00-00", "reason": "This paper presents a significant advancement by introducing scalable diffusion models using transformers, which are highly efficient and effective in video generation tasks."}, {"fullname_first_author": "Liu", "paper_title": "Compositional visual generation with composable diffusion models", "publication_date": "2022-00-00", "reason": "This paper provides a strong theoretical foundation for the generation of coherent and temporally consistent videos by addressing the challenges of integrating multiple conditioning signals effectively."}]}