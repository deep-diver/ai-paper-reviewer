[{"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/4d_surface.png", "caption": "Figure 1: DeepSeek R1-32B\u2019s accuracy is a function of compute budget and confidence threshold. Increased confidence thresholds generally yield increased accuracy at the cost of response rate, while increased compute budgets sometimes decrease accuracy while increasing response rate. The vertical axis measures the accuracy of answered questions at a compute budget and confidence threshold. Color indicates the proportion of questions that are answered; in redder regions, the model is more likely to answer, whereas in bluer regions the model is less likely to answer. We treat the case where the model never answers as accuracy 0.", "description": "This figure shows the relationship between a language model's accuracy, compute budget, and confidence threshold.  The x-axis represents the compute budget (the amount of computational resources used), and the y-axis shows the accuracy of the model's answers.  The z-axis (the third dimension) represents the confidence threshold (how certain the model needs to be before providing an answer).  The color of each point on the 3D surface represents the proportion of questions answered at that budget and threshold: redder colors indicate a higher proportion of questions answered, while bluer colors indicate a lower proportion.  The figure demonstrates a complex interplay:  Higher confidence thresholds generally improve accuracy but reduce the number of questions answered, and increasing compute budget can sometimes increase the number of answers but not always improve accuracy.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/threshold.png", "caption": "Figure 2: Confidence thresholds on test-time scaling. (left) When the logit threshold is 0, the model answers 100% of questions. This is the only performance curve that is reported by test-time scaling research. (center) At a moderate threshold, more frequent absentions allow higher response accuracy. (right) At a high threshold, small amounts of test-time compute deliver very high accuracy, while test-time scaling provides more answers at the cost of answer accuracy. We treat the decision to never answer as yielding accuracy 0.", "description": "This figure displays the effects of confidence thresholds on the accuracy of test-time scaling.  The left panel shows the standard test-time scaling performance where the model always answers (threshold = 0), demonstrating increased accuracy with increased compute budget. The center panel shows the effect of a moderate confidence threshold (0.5), resulting in fewer answers but higher accuracy. The right panel illustrates the effect of a high confidence threshold (0.95), where even with minimal compute, high accuracy is achieved, though fewer questions are answered in total.  The key takeaway is that a higher confidence threshold improves accuracy but at the cost of answering fewer questions.  A decision not to answer is considered an accuracy of 0.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/confidence.png", "caption": "Figure 3: Test-time scaling improves confidence in correct answers. Each dot represents R1 32B\u2019s confidence in an answer after spending a fixed amount of compute. Indigo series are correct answers, while orange series are incorrect. Note that individual dots may turn from orange to indigo if the model changes its prediction after thinking longer. See Figure\u00a07 in Appendix\u00a0B for s1-32B.", "description": "This figure visualizes how test-time scaling affects the confidence of a large language model (LLM) in its answers.  Each point represents the LLM's confidence in a single answer after a specific amount of computation.  Correct answers are shown in indigo, and incorrect answers are shown in orange.  Importantly, the same answer might be represented by both an orange and indigo dot depending on whether the final answer is correct or incorrect after additional computation, illustrating how more computation may improve the correctness of answers.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/jeopardy_surface.png", "caption": "Figure 4: Utility Surface of DeepSeek R1-32B for Jeopardy. The vertical axis indicates performance in the Jeopardy setting at different compute budgets and confidence thresholds. The color indicates the proportion of questions that are answered, as in Figure\u00a01. The horizontal plane divides positive and negative utility regions of the operating curve. The checkered lines show the confidence slices that we compare to s1 in Figure\u00a05.", "description": "This figure displays a 3D surface plot showing the utility of the DeepSeek R1-32B model in the Jeopardy setting. The x-axis represents the compute budget, the y-axis represents the confidence threshold, and the z-axis represents the utility.  The color of the surface indicates the proportion of questions answered, with redder areas indicating a higher proportion of answered questions.  The horizontal plane at z=0 separates positive utility (above the plane) from negative utility (below the plane). The checkered lines highlight specific confidence thresholds (slices) that are further analyzed and compared to another model (s1) in Figure 5.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/jeopardy.png", "caption": "Figure 5: Jeopardy utility scales differently across models and thresholds. Performance of s1-32B and R1-32B in the Jeopardy odds setting under different confidence thresholds. While s1 is competitive in the case when threshold is 0, a higher threshold shows R1\u2019s superior scaling performance.", "description": "This figure compares the performance of two language models, s1-32B and R1-32B, on a question-answering task using the 'Jeopardy Odds' evaluation metric.  The Jeopardy Odds metric penalizes incorrect answers equally to the reward for correct answers, incentivizing models to only answer when highly confident. The x-axis represents the compute budget allocated to the model during inference. The y-axis shows the utility achieved, which combines accuracy and the frequency of answering.  Different lines represent different confidence thresholds used by the models to determine whether to answer a question. The figure shows that while the two models perform similarly when the confidence threshold is low (always answering), R1-32B exhibits significantly better performance than s1-32B when a higher confidence threshold is applied (answering only when very confident), demonstrating R1-32B's superior ability to leverage increased compute budget to improve accuracy while maintaining confidence.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/4d_surface_s1.png", "caption": "Figure 6: s1-32B\u2019s answer accuracy is a function of compute budget and confidence threshold. Increased confidence thresholds generally yield increased accuracy at the cost of response rate, while increased compute budgets sometimes decrease accuracy while increasing response rate. The vertical axis indicates the accuracy for answered questions at a compute budget and logit threshold. The color indicates the proportion of questions that are answered; in redder regions, the model is more likely to answer, whereas in bluer regions the model is less likely to answer. We treat the decision to never answer as accuracy 0.", "description": "This figure shows the relationship between compute budget, confidence threshold, accuracy, and response rate for the s1-32B model.  The x-axis represents the compute budget, and the y-axis represents the confidence threshold. The z-axis represents the accuracy of the model's answers, with higher values indicating greater accuracy.  The color of each point on the surface indicates the proportion of questions answered at that specific budget and threshold, ranging from blue (low proportion) to red (high proportion). The figure demonstrates that increasing the confidence threshold generally improves accuracy but reduces the response rate (fewer questions answered). Increasing the compute budget can sometimes increase response rate but may not always lead to higher accuracy.  The plot also highlights a tradeoff between answering more questions and achieving high accuracy.", "section": "3 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/confidence_s1.png", "caption": "Figure 7: Test-time scaling improves confidence in correct answers. Each dot represents s1-32B\u2019s confidence in an answer after spending a fixed amount of compute. Indigo series indicate correct answers, while orange series are incorrect. Note that individual dots may switch colors if the model changes its prediction after thinking longer. s1-32B does not separate its correct answers from its incorrect answers as effectively as R1-32B. See Figure\u00a03 for R1-32B.", "description": "This figure visualizes how test-time scaling affects the confidence of the language model s1-32B in its answers. Each point represents the model's confidence in a single answer after a specific computation time.  Correct answers are shown in indigo, and incorrect answers in orange.  Importantly, a single point can change color if the model revises its answer after additional computation. The graph highlights that increased computation generally leads to higher confidence in correct answers but that this effect is less pronounced for s1-32B compared to R1-32B (see Figure 3 for a comparison).", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2502.13962/extracted/6217807/figures/jeopardy_surface_s1.png", "caption": "Figure 8: Utility Surface of s1-32B for Jeopardy. The vertical axis indicates performance in the Jeopardy setting at different compute budgets and confidence thresholds. The color indicates the proportion of questions that are answered; in redder regions, the model is more likely answer, whereas in bluer regions the model is less likely to answer. The horizontal plane divides positive and negative utility regions of the operating curve. The checkered lines indicate the threshold slices that we compare against R1-32B in Figure\u00a05. Note the relatively lower volume above the break-even point of 0 corresponds to s1-32B\u2019s broadly inferior performance at these odds.", "description": "This figure displays the utility surface for the s1-32B model in the Jeopardy setting.  The x-axis represents the compute budget, and the y-axis represents the confidence threshold. The z-axis shows the utility, which combines accuracy and the cost of incorrect answers.  Redder areas indicate a higher proportion of questions answered, while bluer areas show fewer answers. The horizontal plane at utility = 0 separates regions of positive and negative utility.  Checkered lines highlight specific confidence thresholds that are compared to the R1-32B model in Figure 5.  The volume above the zero-utility plane is notably smaller for s1-32B than for R1-32B, demonstrating its inferior performance in this scenario.", "section": "4 Utility"}]