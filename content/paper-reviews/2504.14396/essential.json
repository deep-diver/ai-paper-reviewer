{"importance": "This paper introduces a novel tuning-free method for 360\u00b0 panorama generation, **addressing distortion issues without extensive training**. It offers a more accessible and efficient approach, **potentially impacting AR/VR content creation and opening new research directions** in panoramic media generation.", "summary": "SphereDiff: Seamless 360\u00b0 panorama generation via spherical latent space, no fine-tuning needed!", "takeaways": ["SphereDiff introduces a spherical latent representation for seamless 360\u00b0 panoramic image and video generation.", "The method leverages state-of-the-art diffusion models without requiring additional fine-tuning.", "SphereDiff outperforms existing approaches in generating high-quality, distortion-free panoramic content."], "tldr": "Generating high-quality 360\u00b0 panoramic content is challenging due to distortions introduced by equirectangular projection(ERP). Existing methods require fine-tuning diffusion models or still rely on ERP latent representations, leading to discontinuities. To solve this, SphereDiff is introduced for seamless panoramic content generation without tuning.\n\nSphereDiff ensures uniform distribution across perspectives by defining a spherical latent representation. It extends MultiDiffusion to spherical latent space and introduces spherical latent sampling. It also has distortion-aware weighted averaging. Experiments show this method generates high-quality 360\u00b0 panoramic content with high fidelity.", "affiliation": "Korea Advanced Institute of Science and Technology (KAIST)", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2504.14396/podcast.wav"}