[{"figure_path": "https://arxiv.org/html/2504.14396/x2.png", "caption": "Figure 1: 360-degree panoramic video generated by SphereDiff. Click to play the animation clips. Best viewed with Acrobat Reader.", "description": "This figure showcases a 360-degree panoramic video generated using the SphereDiff model.  The video displays a dynamic scene, likely an outdoor cityscape at night, with various elements like buildings, rivers, and fireworks, offering an immersive, omnidirectional view. The caption encourages viewers to click on the image to view the animation, recommending Acrobat Reader for optimal viewing experience. This visual demonstrates the model's capability to produce high-quality, seamless panoramic video content, highlighting the absence of distortions often present in other methods near the poles.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2504.14396/x3.png", "caption": "Figure 2: Motivation. Previous finetuning approaches\u00a0[15, 30] often fail to generate continuous scenes near the pole due to the limited ERP dataset.\nThe tuning-free approach\u00a0[18] also fails to generate a seamless frame due to the ERP latent representation.", "description": "Figure 2 illustrates the limitations of existing methods for generating 360-degree panoramic images.  Fine-tuning approaches, while using an equirectangular projection (ERP) dataset, struggle to create continuous scenes, especially near the poles due to distortions and limited training data. Similarly, tuning-free methods relying on ERP latent representations also fail to produce seamless images because of the inherent distortions in ERP.", "section": "2. Related Work"}, {"figure_path": "https://arxiv.org/html/2504.14396/x4.png", "caption": "Figure 3: Overall Pipeline.\nWe initialize uniform spherical latents and extract perspective latents for multiple views at each denoising step using dynamic latent sampling. These latents are then denoised and fused using the MultiDiffusion\u00a0[2] with distortion-aware weighted averaging. This process enables seamless and distortion-free 360-degree panoramic image and video generation in a tuning-free manner.", "description": "SphereDiff uses a novel approach to generate 360-degree panoramic images and videos.  It starts with uniform spherical latents, which represent the scene's information in a distortion-free way. Then, for each denoising step in the diffusion process, perspective latents are extracted for multiple views using dynamic latent sampling.  These perspective latents are denoised individually using a pre-trained diffusion model. Finally, the denoised latents are fused together using MultiDiffusion and distortion-aware weighted averaging to produce a seamless, distortion-free panoramic output. This entire process is tuning-free, meaning it does not require any additional training of the diffusion model.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.14396/x5.png", "caption": "Figure 4: \nComparison of ERP and Spherical Latent Representations.\nWhen changing perspective, the ERP latent representation shows significant density variations in latent density depending on position, especially near the poles, while our spherical representation maintains a nearly uniform density across all perspectives.", "description": "The figure compares the spatial distribution of latent features in two different representations: equirectangular projection (ERP) and the proposed spherical representation.  ERP, a common method for representing 360-degree images on a 2D plane, suffers from distortions, especially near the poles, leading to uneven distribution of latent features.  The image shows that the density of ERP latents is much higher near the poles, while the density of latents in the spherical representation is relatively uniform across all viewing angles. This demonstrates the advantage of using a spherical representation for generating seamless panoramic images.", "section": "3. Spherical Latent Representation"}, {"figure_path": "https://arxiv.org/html/2504.14396/x8.png", "caption": "Figure 5: \nComparison of Nearest and Dynamic Sampling. Nearest sampling often resamples the selected latents or omits central ones, while dynamic sampling selects latents from the center outward, discarding only the outermost ones.", "description": "Figure 5 illustrates two methods for sampling spherical latents: nearest sampling and dynamic sampling.  Nearest sampling simply selects the nearest latent to each grid point, potentially leading to some latents being selected multiple times and others missed entirely.  This results in uneven sampling and can cause artifacts, especially near the poles where latents are less densely packed.  In contrast, dynamic sampling addresses these issues by starting at the center and working outward, ensuring a more uniform sampling of latents.  This method ensures a more comprehensive representation of the spherical surface while minimizing the omission of crucial data points.", "section": "3.3. Sampling Spherical Latent"}, {"figure_path": "https://arxiv.org/html/2504.14396/x9.png", "caption": "Figure 6: Qualitative results of our method. Visualization results for the entire scene using the ERP representation and 3 perspectives views across various elevation multiple perspective images or frames. Additional results are available in the supplementary materials.", "description": "Figure 6 presents a qualitative evaluation of the SphereDiff model's performance.  It showcases the model's ability to generate seamless and high-quality 360\u00b0 panoramic images and videos. The figure displays visualization results of a generated scene using the equirectangular projection (ERP) representation, a standard format for panoramic images, alongside views from three different perspectives at various elevations. These multiple perspective views offer a comprehensive understanding of the model's generation quality and consistency across different viewpoints.  The supplementary material contains additional results not shown in this figure.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.14396/x10.png", "caption": "Figure 7: Qualitative comparison of all image and video baselines. Each sample presents perspective images from the top view to the bottom view, highlighting end-to-end continuity and distortion. Other methods exhibit noticeable artifacts, such as split seams, severe distortions near the poles, blurriness, or spots due to inadequate handling of these issues. In contrast, our method generates seamless, high-quality panoramic content without such artifacts.", "description": "Figure 7 presents a qualitative comparison of various methods for generating 360-degree panoramic images and videos.  The figure displays multiple examples, each showing perspective views from top to bottom. This allows for easy visual assessment of end-to-end continuity and the presence of distortion or artifacts. The authors highlight the shortcomings of existing baselines, noting issues such as split seams, severe distortions (especially near the poles), blurriness, and random spots. In contrast, the proposed method (SphereDiff) is shown to generate seamless, high-quality panoramic content free of these artifacts.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.14396/x11.png", "caption": "Figure 8: Ablation on latent sampling and weighted averaging. Nearest sampling lacks information exchange between views, leading to inconsistencies and visible overlap artifacts caused by undersampling problem. In contrast, dynamic sampling facilitates information sharing, resulting in more integrated outputs. With weighted averaging, both sampling methods improve seamlessness. However, nearest sampling still fails to maintain connectivity between adjacent regions, leading to discontinuities.", "description": "Figure 8 demonstrates the effects of different latent sampling methods (nearest neighbor vs. dynamic) and the use of weighted averaging on the quality of generated 360\u00b0 panoramic images.  Nearest neighbor sampling suffers from a lack of information exchange between different viewpoints, resulting in inconsistencies and noticeable overlap artifacts due to undersampling.  In contrast, dynamic sampling improves information sharing, leading to more coherent and integrated outputs.  Applying weighted averaging enhances the seamlessness of the results for both sampling methods; however, even with weighted averaging, nearest neighbor sampling still struggles to maintain full connectivity between adjacent regions, producing discontinuities.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.14396/x12.png", "caption": "Figure 9: Similarities between positional embeddings calculated with discrete and continuous positions. The small squares represent the similarity distribution when the central pixel is used as a query. As shown in the figure, when discretization is applied, within the same row or column, resulting in high similarity. However, when positions vary slightly (as in the continuous case), the similarity drops significantly.", "description": "This figure compares the similarity distribution of positional embeddings generated using discrete versus continuous positional representations.  The visualizations show that when using discrete positional embeddings (a), high similarity is concentrated within rows and columns of the grid.  However, with continuous positional embeddings (b), similarity decreases rapidly as the distance between positions increases, even for small positional offsets. This difference highlights the impact of discretization on latent similarity and explains why a continuous latent representation is insufficient for creating a seamless 360-degree panorama without additional methods. ", "section": "3.3. Sampling Spherical Latent"}, {"figure_path": "https://arxiv.org/html/2504.14396/x13.png", "caption": "Figure 10: Comparison with spherical and ERP. The red box highlights blurry artifacts that appear near the polar regions. As the number of view directions decreases, more latents remain unsampled and unprocessed during denoising, making the issue more severe.", "description": "Figure 10 compares the image generation results of SphereDiff with those of a baseline method (DynamicScaler) using both spherical and equirectangular projection (ERP) latent representations. The comparison highlights the impact of the number of view directions on the generation quality, particularly around the polar regions. When fewer view directions are used, more latents remain unsampled and unprocessed during denoising, resulting in blurry artifacts near the poles, as indicated by the red boxes.  The figure demonstrates that SphereDiff's use of spherical latent representation is more robust to a reduction in view directions and produces significantly higher quality images.", "section": "4. Experiments"}]