[{"figure_path": "https://arxiv.org/html/2504.13835/x1.png", "caption": "Figure 1: Comparison with different data selection methods\u00a0Lu et\u00a0al. (2024); Liu et\u00a0al. (2024b) on the Tulu3\u00a0Lambert et\u00a0al. (2024) pool using Llama3.1-8B\u00a0Touvron et\u00a0al. (2023), evaluated on (black) knowledge-based benchmarks and (red) human-preference benchmarks. See details in Sec.\u00a04.2.", "description": "Figure 1 presents a comparison of various data selection methods, namely those proposed by Lu et al. (2024) and Liu et al. (2024b), when applied to the Tulu3 dataset (Lambert et al., 2024).  The results are obtained using the Llama3.1-8B model (Touvron et al., 2023).  The figure showcases the performance of these methods across two categories of benchmarks: knowledge-based benchmarks (shown in black) and human-preference benchmarks (shown in red).  Detailed results and analysis of this comparison can be found in Section 4.2 of the paper.", "section": "4 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13835/x2.png", "caption": "Figure 2: Illustration of (a) Data Selection Pipeline and (b) MIG Sampler. Given the raw data pool, our pipeline first applies a tagger and scorer to annotate data. Next, MIG constructs the label graph based on the label set and iteratively selects the data point that maximizes the information gain within the graph. The selected data are used for supervised fine-tuning (SFT) of LLMs.", "description": "Figure 2 illustrates the process of MIG, a novel method for data selection in instruction tuning. (a) shows the overall pipeline: starting with a raw data pool, a tagger and scorer annotate each data point with relevant labels and a quality score.  MIG then uses these annotations to construct a label graph which represents the semantic relationships between different labels. (b) zooms into the MIG Sampler, highlighting the iterative process of data selection. MIG iteratively selects data points that maximize the information gain within the label graph, resulting in a high-quality and diverse subset. This selected dataset is then utilized for supervised fine-tuning (SFT) of large language models (LLMs).", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2504.13835/extracted/6372957/figs/data-scaling-v2.png", "caption": "Figure 3: Data scaling experiments on Tulu3 using Llama3.1-8B. The score reported here is the Avg score.", "description": "This figure displays the results of experiments evaluating the impact of varying dataset sizes on the performance of a model fine-tuned using the Tulu3 dataset and the Llama3.1-8B base model.  The x-axis represents the size of the dataset subset used for fine-tuning, while the y-axis shows the average score across multiple evaluation benchmarks (Avg score, which is the average of knowledge-based and human-preference benchmark scores). The graph demonstrates how model performance changes as the amount of training data increases, allowing for an assessment of the model's performance scaling behavior.", "section": "4.2 Main Results"}, {"figure_path": "https://arxiv.org/html/2504.13835/x3.png", "caption": "Figure 4: (a) Derivative of Information Score Functions. (b) AvgobjsubscriptAvgobj\\text{Avg}_{\\text{obj}}Avg start_POSTSUBSCRIPT obj end_POSTSUBSCRIPT on Different Information Score Functions. (c) AvgsubsubscriptAvgsub\\text{Avg}_{\\text{sub}}Avg start_POSTSUBSCRIPT sub end_POSTSUBSCRIPT on Different Quality Scores.", "description": "This figure analyzes the impact of different information score functions and quality metrics on the performance of the MIG model. Panel (a) shows the derivative of various information score functions, illustrating their rate of diminishing returns as information increases. Panels (b) and (c) present the average scores across objective benchmarks (Avgobj) and subjective benchmarks (Avgsub), respectively, under different information score functions and quality metrics.  This analysis helps determine the optimal balance between data quality and diversity in the model's performance.", "section": "4.3 Analysis"}, {"figure_path": "https://arxiv.org/html/2504.13835/x4.png", "caption": "Figure 5: Quantitative results on different quality metrics. DEITA scores achieve the best performance on both human-preference and knowledge-based evaluations.", "description": "Figure 5 presents a bar chart comparing the performance of different data quality metrics (IFD, TagNum, and DEITA) against a baseline on both human-preference and knowledge-based benchmarks.  The results show that using DEITA scores for data quality consistently yields the best performance, outperforming other metrics across both evaluation types.", "section": "4.3 Analysis"}, {"figure_path": "https://arxiv.org/html/2504.13835/x5.png", "caption": "Figure 6: Analysis of Parameters in the Label Graph. The reported score is the average of AvgsubsubscriptAvgsub\\text{Avg}_{\\text{sub}}Avg start_POSTSUBSCRIPT sub end_POSTSUBSCRIPT and AvgobjsubscriptAvgobj\\text{Avg}_{\\text{obj}}Avg start_POSTSUBSCRIPT obj end_POSTSUBSCRIPT.\nPlease refer to Table\u00a07\u00a08\u00a09 in Appx.\u00a0D for detailed scores on all evaluated benchmarks.\n(a) Comparison of various node counts (label set size) in the label graph. (b) Comparison of different edge thresholds, with a lower threshold indicating a dense graph. (c) Comparison of different propagation weights, where a smaller weight corresponds to weak propagation.", "description": "Figure 6 analyzes the impact of label graph parameters on model performance.  Subfigure (a) shows how varying the number of nodes (representing labels) affects the average score (a combination of human evaluation and knowledge-based benchmark scores). Subfigure (b) illustrates the effect of changing the edge threshold, where lower thresholds create denser graphs representing stronger relationships between labels. Subfigure (c) examines how altering the propagation weight, which influences the strength of information flow within the graph, impacts performance.  Appendices D, Tables 7, 8, and 9 provide detailed benchmark scores for each parameter setting.", "section": "4.3 Analysis"}]