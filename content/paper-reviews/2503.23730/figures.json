[{"figure_path": "https://arxiv.org/html/2503.23730/extracted/6322467/figures/fig0.png", "caption": "Figure 1: Distribution of question categories and subcategories in the KOFFVQA benchmark.", "description": "Figure 1 shows a pie chart that breaks down the distribution of question categories and subcategories within the KOFFVQA benchmark dataset.  Each slice of the pie represents a category, with the size of each slice corresponding to the percentage of questions in that category. Categories include 'Perception', 'Reasoning', 'Understanding', and 'Safety and Bias'.  Each major category is further divided into subcategories, shown in the legend, which further specify the types of questions within each major category (e.g., 'Object Attributes' under the 'Perception' category).  This visualization provides a clear overview of the KOFFVQA benchmark's composition and emphasis on different aspects of VLM performance.", "section": "3. The KOFFVQA Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.23730/extracted/6322467/figures/fig1.png", "caption": "Figure 2: Three examples from each main category of our benchmark. The left column is the original text in Korean, and the right column provides the English translation. Grading criteria paired with partial points are given to the judge model to evaluate the VLM\u2019s response.", "description": "Figure 2 showcases three example questions from each of the three main categories (Perception, Reasoning, Safety and Bias) within the KOFFVQA benchmark.  Each example includes the original Korean question and its English translation. The key feature is the inclusion of detailed grading criteria, accompanied by the partial scores assigned to each criterion.  These criteria are crucial because they provide objective guidelines that the LLM judge uses to evaluate the VLM's response. This objective evaluation strategy is a core aspect of the KOFFVQA methodology.", "section": "3. The KOFFVQA Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.23730/extracted/6322467/figures/fig2.png", "caption": "Figure 3: An example of a response that GPT-4o grades correctly when the image is not given as input but grades incorrectly when the image is given. The left columns are the original text in Korean, and the right columns provide the English translations. When the image is given, the judge model attempts to judge the response based on the image and hallucinates that the door in the middle of the photograph is green. When the image is not given, the judge has no reason to grade the response based on anything other than the given criteria.", "description": "This figure shows an example where a large language model (LLM), specifically GPT-40, evaluates a VLM response differently depending on whether or not an image is provided.  When only the response and grading criteria are given, the LLM accurately assesses the answer. However, when the image is included, the LLM incorrectly judges the response due to hallucinating a detail in the image (misinterpreting the color of a door). This demonstrates that providing images to the LLM judge, in this case, negatively impacts the consistency of the evaluation because the visual input leads to unreliable judgments.", "section": "4.3. Influence of Visual Input in Judgment"}]