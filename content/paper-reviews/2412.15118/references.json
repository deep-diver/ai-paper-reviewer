{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for the field of large language models and their capabilities in few-shot learning, which is a crucial basis for the research in this paper."}, {"fullname_first_author": "Mark Chen", "paper_title": "Evaluating large language models trained on code", "publication_date": "2021-07-01", "reason": "This paper introduced a benchmark dataset for evaluating LLMs' code generation capabilities, which is directly relevant to the evaluation methodologies used in this work."}, {"fullname_first_author": "Hunter Lightman", "paper_title": "Let's verify step by step", "publication_date": "2023-05-01", "reason": "This paper introduced process supervision as a promising technique for guiding LLMs' reasoning steps, which this paper builds upon and extends."}, {"fullname_first_author": "Yidong Wang", "paper_title": "Exploring vision-language models for imbalanced learning", "publication_date": "2024-01-01", "reason": "This paper is highly relevant to the work in this paper because it also focuses on improving the performance of LLMs on complex tasks by using a novel supervision technique."}, {"fullname_first_author": "Noah Shinn", "paper_title": "Reflexion: Language agents with verbal reinforcement learning", "publication_date": "2024-12-01", "reason": "This paper proposes a novel self-improvement method for LLMs that uses execution feedback, which is similar to the approach used in this work."}]}