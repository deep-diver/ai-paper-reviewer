[{"figure_path": "https://arxiv.org/html/2504.13072/x2.png", "caption": "Figure 1: \nHiScene allows users to generate scene-level 3D assets with natural layout and appealing looking, while delivering compositional items for versatile applications such as interactive editing and simulation.", "description": "This figure showcases HiScene's capabilities.  It displays a user-generated 3D living room scene rendered in an isometric view. The scene is detailed and realistic, featuring multiple distinct objects arranged naturally. HiScene's ability to produce compositional 3D scenes means that these individual objects can be interactively manipulated, edited, or simulated, making it suitable for applications beyond just static visualization.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.13072/x3.png", "caption": "Figure 2: \nOverview of HiScene. Our hierarchical framework generates 3D scenes with compositional identities through three main stages. First, we create a 3D scene from a generated isometric view.\nNext, we perform scene parsing to obtain precise object segmentation, followed by multi-view rendering and detailed occlusion analysis for each identified instance.\nFinally, we apply our video-diffusion-based amodal completion to generate complete views of each instance, which serve as guidance for regenerating intact objects with proper spatial alignment in the scene.\nThe resulting 3D scene features fully compositional identities, facilitating user-directed modifications like interactive scene editing.", "description": "HiScene uses a three-stage hierarchical approach to generate 3D scenes with compositional identities.  It starts by creating a 3D scene from a generated isometric view. Then, scene parsing is used to segment individual objects, followed by multi-view rendering to analyze occlusions. Finally, video diffusion-based amodal completion generates complete object views, which are used to regenerate intact objects with correct spatial alignment. The resulting scene allows for interactive editing.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.13072/x4.png", "caption": "Figure 3: Comparison of perspective view and isometric view of a living room scene. Zoom in for more details.", "description": "This figure shows a comparison between a perspective view and an isometric view of the same living room scene.  The perspective view provides a realistic representation of how a human would see the room from a specific viewpoint, showing spatial depth and perspective distortion.  In contrast, the isometric view offers a simplified, top-down representation. This view is distortion-free, showing objects in their actual proportions, without the foreshortening seen in a perspective view. This comparison highlights the advantages of using an isometric view for 3D scene generation as it aids in maintaining object proportions and simplifies scene composition.", "section": "3.1. Preliminary"}, {"figure_path": "https://arxiv.org/html/2504.13072/x5.png", "caption": "Figure 4: We present an data curation example of amodal completion, including original image (a), occluded input image (b), visible mask (c), and the linear blended video (d). We also present shadow-aware data examples (e).", "description": "Figure 4 illustrates the process of creating a dataset for amodal completion.  Panel (a) shows the original, complete image of an object. Panel (b) shows the same object with parts occluded, simulating a real-world scenario. Panel (c) displays the visible mask, indicating the visible portion of the object in (b). Panel (d) demonstrates how the occluded parts are gradually revealed in a short video created through linear blending. Panel (e) shows additional examples that highlight realistic shadow effects.", "section": "3.3 Amodal Completion"}, {"figure_path": "https://arxiv.org/html/2504.13072/x6.png", "caption": "Figure 5: An illustration of Spatial Aligned Generation.\nWe use sparse-view LRM to initialize spatial aligned shape prior (voxel latent), and inject this prior by initializing voxel noises upon it during native 3D generation, thus ensuring regenerated assets adhering the original scene.", "description": "This figure illustrates the Spatial Aligned Generation process.  It begins by using a sparse-view Large Reconstruction Model (LRM) to create a shape prior, specifically a voxel latent representation. This prior captures the essential geometric structure of the object, while being spatially aligned with the object's location in the original scene. The voxel latent is then injected into the native 3D generation process by initializing the voxel noise with it. This ensures that the regenerated 3D object maintains its shape and is correctly positioned within the scene, adhering to the original spatial arrangement. The process effectively prevents distortions and misalignments that can occur during standard 3D object generation.", "section": "3.4. Spatial Aligned Generation"}, {"figure_path": "https://arxiv.org/html/2504.13072/x7.png", "caption": "Figure 6: \nWe compare the Interactive Scene 3D generation with GALA3D and DreamScene.", "description": "Figure 6 shows a qualitative comparison of interactive 3D scene generation results between the proposed HiScene method and two other state-of-the-art methods, GALA3D and DreamScene.  The comparison highlights differences in scene realism, object arrangements, and the presence of artifacts such as oversaturation or the 'Janus' problem (objects appearing incomplete or with inconsistent views). HiScene demonstrates better generation quality with more natural object arrangements and complete, coherent object instances.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13072/x8.png", "caption": "Figure 7: \nIn-the-wild Amodal Completion and Segmentation.", "description": "This figure showcases examples of in-the-wild amodal completion and segmentation results.  The left column displays the input images (with occlusions), the middle column shows the predicted amodal segmentation masks (filling in the missing parts of the objects), and the right column shows the corresponding completed objects, illustrating the model's ability to effectively reconstruct complete object shapes from partially visible views.", "section": "4.2 Amodal Completion"}, {"figure_path": "https://arxiv.org/html/2504.13072/x9.png", "caption": "Figure 8: We analyzed the necessity of shadow-aware amodal completion.", "description": "This figure demonstrates the importance of using a shadow-aware amodal completion method in HiScene's scene generation process.  The results show that without shadow-aware completion, object generation models struggle with partial inputs, resulting in geometric artifacts (missing portions of the object, black textures) based on incomplete mask contours.  Even if amodal completion is performed, residual shadow artifacts lead to geometric inaccuracies. Conversely, the shadow-aware completion method effectively handles both occlusions and shadows, resulting in visually coherent and geometrically accurate object reconstructions.  The figure visually compares outputs from three conditions: (1) using the full method (with shadow-aware amodal completion), (2) performing amodal completion without shadow-aware training, and (3) applying only native 3D object generation without amodal completion.", "section": "4.3 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2504.13072/x10.png", "caption": "Figure 9: We analyze the effectiveness of Spatial Aligned Generation.", "description": "Figure 9 demonstrates the impact of Spatial Aligned Generation on the quality of the final 3D models.  It compares three approaches: using only the native 3D generation model without spatial alignment, using only the large reconstruction model (LRM) to generate shapes, and using the proposed method, which incorporates spatial priors from LRM into the native 3D generation process. The results visually show that the proposed method, by injecting shape priors, better preserves the object's original geometry, size, and position within the generated scene.  The native 3D generation model alone often results in objects that are misaligned or deformed, and LRM alone doesn't provide textural details or scene context.", "section": "4.3 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2504.13072/x11.png", "caption": "Figure 10: \nWe provide examples of predefined viewpoints.", "description": "This figure shows examples of the predefined viewpoints used in the 3D semantic segmentation stage of the HiScene framework.  The different viewpoints are strategically positioned around the objects to capture comprehensive views, mitigating occlusions and enabling accurate segmentation.  Two scene examples are provided, demonstrating different viewpoint arrangements to capture varied object configurations and geometries.", "section": "A. Hierarchical Scene Parsing Details"}, {"figure_path": "https://arxiv.org/html/2504.13072/x12.png", "caption": "Figure 11: \nWe provide an example of using VLM to determine whether the target object is occluded.", "description": "Figure 11 shows an example of how a Vision-Language Model (VLM) is used to determine if a target object is occluded in an image.  The VLM takes an image as input and is prompted with two questions: 1) a short description of the image and 2) whether the target object (specified in the prompt) is occluded by other objects. The VLM's response includes a classification (occluded, not occluded, or unable to determine) and a concise explanation for its assessment. This process is used in the HiScene model to efficiently identify occluded objects for subsequent amodal completion.", "section": "A. Hierarchical Scene Parsing Details"}, {"figure_path": "https://arxiv.org/html/2504.13072/x13.png", "caption": "Figure 12: \n(a) Visualization of the Rigid Body Dynamics (RBD) process; (b) and (c) illustrate the shadow effects under different lighting setup; (d) demonstrates that incorrect shadow effects when object are not pre-processed with RBD.", "description": "Figure 12 demonstrates the process of creating synthetic image data with realistic shadows.  (a) shows the steps involved in using Rigid Body Dynamics (RBD) simulation to position 3D objects naturally on surfaces. (b) and (c) display the resulting shadow effects from different lighting setups, showcasing the variation achievable with this method.  Finally, (d) highlights the importance of RBD preprocessing by showing how objects without RBD simulation result in unnatural and incorrect shadow artifacts.", "section": "B.1. Dataset Preparation"}, {"figure_path": "https://arxiv.org/html/2504.13072/x14.png", "caption": "Figure 13: \nAn illustration of the user study interface.", "description": "The figure shows the interface used in a user study to evaluate the quality of generated 3D scenes. Users are presented with a prompt and three different 3D scene images generated by different methods. They rate the images on a 1-3 scale based on how well they match the prompt, giving more detailed feedback on image-text similarity and overall scene quality. This allows for a quantitative and qualitative analysis of the generated scenes.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.13072/x15.png", "caption": "Figure 14: \nWe show examples of our synthetic dataset.", "description": "Figure 14 shows examples from the synthetic dataset created for training the amodal completion model.  The dataset includes a variety of objects rendered with realistic shadows, designed to help the model learn to complete occluded object instances accurately. The top row displays rendered objects with shadows, and the bottom row shows corresponding images and masks used for training the model.  The masks highlight the visible and occluded portions of the objects.", "section": "3.3 Amodal Completion"}, {"figure_path": "https://arxiv.org/html/2504.13072/x16.png", "caption": "Figure 15: \nMore examples of generated scenes. All prompts have a fixed prefix \u201dIsometric view of \u201d.", "description": "Figure 15 presents several examples of 3D scenes generated using the HiScene model. Each scene was generated from a text prompt that started with the phrase \"Isometric view of.\"  The figure showcases the diversity of scenes the model can produce, demonstrating its ability to generate realistic and detailed 3D room arrangements based on textual input.", "section": "4. Experiments"}]