[{"content": "| Method | Training Data | KITTI |  | NYUv2 |  | ETH3D |  | ScanNet |  | DIODE |  | Avg. Rank | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| **Data-driven methods** |  |  |  |  |  |  |  |  |  |  |  |  | \n| DiverseDepth [14] | 320K | 19.0 | 70.4 | 11.7 | 87.5 | 22.8 | 69.4 | 10.9 | 88.2 | 37.6 | 63.1 | 7.0 | \n| MiDaS [13] | 2M | 18.3 | 71.1 | 9.5 | 91.5 | 19.0 | 88.4 | 9.9 | 90.7 | 26.6 | 71.3 | 5.4 | \n| LeReS [70] | 354K | 14.9 | 78.4 | 9.0 | 91.6 | 17.1 | 77.7 | 9.1 | 91.7 | 27.1 | 76.6 | 4.6 | \n| Omnidata [12] | 12.2M | 14.9 | 83.5 | 7.4 | 94.5 | 16.6 | 77.8 | 7.5 | 93.6 | 33.9 | 74.2 | 3.8 | \n| HDN [71] | 300K | 11.5 | 86.7 | 6.9 | 94.8 | 12.1 | 83.3 | 8.0 | 93.9 | 24.6 | 78.0 | 2.4 | \n| DPT [10] | 1.4M | 11.1 | 88.1 | 9.1 | 91.9 | 11.5 | 92.9 | 8.4 | 93.2 | 26.9 | 73.0 | 3.4 | \n| Depth Anything V2 [9] | 63.5M | 8.0 | 94.6 | 4.3 | 98.0 | 6.2 | 98.0 | 4.3 | 98.1 | 26.0 | 75.9 | 1.3 | \n| **Model-driven methods** |  |  |  |  |  |  |  |  |  |  |  |  | \n| Marigold [16] | 74K | 9.9 | 91.6 | 5.5 | 96.4 | 6.5 | 96.0 | 6.4 | 95.1 | 30.8 | 77.3 | 4.3 | \n| GeoWizard [17] | 280K | 9.7 | 92.1 | 5.2 | 96.6 | 6.4 | 96.1 | 6.1 | 95.3 | 29.7 | 79.2 | 2.9 | \n| DepthFM [18] | 74K | 9.1 | 90.2 | 6.0 | 95.5 | 6.5 | 95.4 | 6.6 | 94.9 | 22.4 | 78.5 | 4.5 | \n| GenPercept [19] | 74K | 9.9 | 90.4 | 5.6 | 96.0 | 6.2 | 95.8 | 6.2* | 96.1* | 35.7 | 75.6 | 4.4 | \n| Lotus [20] | 59K | 9.3 | 92.8 | 5.3 | 96.7 | 6.8 | 95.3 | 6.0 | 96.3 | 22.8 | 73.8 | 3.5 | \n| DepthMaster (Ours) | 74K | 8.2 | 93.7 | 5.0 | 97.2 | 5.3 | 97.4 | 5.5 | 96.7 | 21.5 | 77.6 | 1.2 |", "caption": "TABLE I: Quantitative comparison with state-of-the-art zero-shot affine-invariant monocular depth estimation methods.\nThe upper part lists data-driven methods and the lower part presents those based on diffusion models.\nAll metrics are in percentage terms with \u201cbold\u201d best and \u201cunderline\u201d second best. \u201c*\u201d stands for the results reproduced by Lotus.", "description": "This table presents a quantitative comparison of different zero-shot monocular depth estimation methods, categorized into data-driven and diffusion model-based approaches.  Metrics such as Absolute Relative error (AbsRel) and \nInverse scale consistency (\u03b41) are shown, evaluating the accuracy of depth prediction. The table highlights the top-performing methods for each dataset (KITTI, NYU-V2, ETH3D, ScanNet, DIODE) using bold for the best and underlined for the second-best performance. Results marked with an asterisk (*) indicate values reproduced from the Lotus method.  This allows for a clear comparison between data-driven and model-driven methods and to identify the best-performing techniques within each category.", "section": "IV. Experiments"}, {"content": "| Paradigm | KITTI AbsRel \u2193 | KITTI \u03b4\u2081 \u2191 | NYUv2 AbsRel \u2193 | NYUv2 \u03b4\u2081 \u2191 | ScanNet AbsRel \u2193 | ScanNet \u03b4\u2081 \u2191 | ETH3D AbsRel \u2193 | ETH3D \u03b4\u2081 \u2191 | DIODE AbsRel \u2193 | DIODE \u03b4\u2081 \u2191 | Hypersim AbsRel \u2193 | Hypersim F1 \u2191 | Time (s) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| I2L | - | - | 1.1 | 99.5 | 0.9 | 99.7 | - | - | 8.4 | 92.4 | 0.615 | - |\n| Denoising | 10.4 | 90.2 | 5.7 | 96.0 | 6.9 | 94.6 | 6.4 | 95.7 | 30.9 | 76.8 | 0.274 | 12.91 |\n| Deterministic* | 10.3 | 90.4 | 5.3 | 96.6 | 6.0 | 96.2 | 6.5 | 95.8 | 29.9 | 77.0 | 0.304 | 0.42 |\n| Iterative | 10.0 | 91.1 | 5.2 | 96.7 | 5.9 | 96.1 | 6.1 | 96.3 | 29.4 | 77.8 | 0.310 | 0.83 |", "caption": "TABLE II: Ablation of paradigm.\n\u201cI2L\u201d means feeding depth maps into I2L encoder-decoder and outputting reconstructed ones.\n\u201cDenoising\u201d and \u201dDeterministic\u201d refer to predicting depth in diffusion-denoising and deterministic ways, respectively.\n\u201cIterative\u201d means iterative refinement through the U-Net 4 times in a deterministic way.\n\u201c*\u201d indicates the paradigm we use.", "description": "This table presents an ablation study comparing different approaches for depth prediction within the DepthMaster model.  It contrasts three main paradigms: 1) Using the I2L (Image-to-Latent) encoder-decoder to reconstruct depth maps,  2) Predicting depth through a diffusion-denoising process, and 3) Directly predicting depth in a deterministic manner. The table also includes a fourth approach which iteratively refines the depth prediction four times using the U-Net in a deterministic manner.  The results are shown for various metrics across multiple datasets, indicating which paradigm performed best for the model, marked by an asterisk (*).", "section": "III. METHOD"}, {"content": "| Depth Preprocess | KITTI |  | NYUv2 |  | ETH3D |  | ScanNet |  | DIODE |  |\n|---|---|---|---|---|---|---|---|---|---|---|\n| AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 |\n| depth(D) | 10.3 | 90.4 | 5.3 | 96.6 | 6.5 | 95.8 | 6.0 | 96.2 | 29.9 | 77.0 |\n| disparity(1/D) | 8.9 | 92.4 | 5.3 | 97.0 | 6.7 | 96.7 | 5.7 | 96.3 | 22.4 | 74.0 |\n| sqrt disp(1/\u221aD) | 8.7 | 93.1 | 5.1 | 97.3 | 5.5 | 97.2 | 5.8 | 96.4 | 21.8 | 77.2 |", "caption": "TABLE III: Ablation of depth preprocess. Predicting disparity instead of depth results in improved performance on outdoor datasets, while using square-root disparity leads to consistent improvements across all datasets.", "description": "This ablation study investigates the impact of different depth representation choices on the model's performance.  It compares using depth values directly, disparity values, and square root disparity. The results show that using disparity improves performance, especially on outdoor scenes. Furthermore, utilizing square root disparity consistently improves performance across all datasets, suggesting it is the best approach.", "section": "IV. Experiments"}, {"content": "| External Model Type | KITTI |  | NYUv2 |  | ETH3D |  | ScanNet |  | DIODE |  |\n|---|---|---|---|---|---|---|---|---|---|---|\n| AbsRel \u2193 | \ud835\udf39\u2081 \u2191 | AbsRel \u2193 | \ud835\udf39\u2081 \u2191 | AbsRel \u2193 | \ud835\udf39\u2081 \u2191 | AbsRel \u2193 | \ud835\udf39\u2081 \u2191 | AbsRel \u2193 | \ud835\udf39\u2081 \u2191 |\n| baseline | 8.7 | 93.1 | 5.1 | 97.3 | 5.5 | 97.2 | 5.8 | 96.4 | 21.8 | 77.2 |\n| OpenCLIP [80] | 8.5 | 93.3 | 5.0 | 97.3 | 5.4 | 97.4 | 5.6 | 96.5 | 21.8 | 77.1 |\n| AIMv2 [81] | 8.4 | 93.4 | 5.1 | 97.3 | 5.5 | 97.3 | 5.6 | 96.6 | 21.7 | 77.5 |\n| SAM [82] | 8.3 | 93.5 | 5.0 | 97.3 | 5.3 | 97.5 | 5.5 | 96.7 | 21.7 | 77.2 |\n| DINOv2 [66] | 8.3 | 93.7 | 5.0 | 97.3 | 5.3 | 97.4 | 5.5 | 96.7 | 21.6 | 77.5 |", "caption": "TABLE IV: Ablation of External Model Type in Feature Alignment module. Introducing various external encoders can improve the generalization performance of the model, among which DINOv2 yields the greatest performance improvement.", "description": "This table presents the results of ablation studies on different external encoder models used within the Feature Alignment module of the DepthMaster model.  The goal is to determine how the choice of external encoder impacts the model's overall performance, specifically its generalization capabilities. The table compares the performance of the DepthMaster model using various external encoders (OpenCLIP, AIMv2, SAM, and DINOv2) across five different datasets (KITTI, NYU-Depth V2, ETH3D, ScanNet, and DIODE), measuring the absolute relative error (AbsRel) and the accuracy metric \u03b41.  The results indicate that incorporating high-quality external features significantly improves the model's performance, and DINOv2 provides the best performance improvement among the tested encoders.", "section": "IV. Experiments"}, {"content": "| Location | KITTI |  | NYUv2 |  | ETH3D |  | ScanNet |  | DIODE |  |\n|---|---|---|---|---|---|---|---|---|---|---|\n| AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 | AbsRel \u2193 | \u03b4\u2081 \u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|\n| baseline | 8.7 | 93.1 | 5.1 | 97.3 | 5.5 | 97.2 | 5.8 | 96.4 | 21.8 | 77.2 |\n| D1 | 8.5 | 93.5 | 5.0 | 97.3 | 5.3 | 97.5 | 5.6 | 96.6 | 21.8 | 77.4 |\n| D2 | 8.4 | 93.6 | 5.1 | 97.3 | 5.4 | 97.4 | 5.5 | 96.6 | 21.5 | 77.7 |\n| Mid | 8.3 | 93.7 | 5.0 | 97.3 | 5.3 | 97.4 | 5.5 | 96.7 | 21.6 | 77.5 |", "caption": "TABLE V: Ablation of feature alignment location.\n\u201cD1\u201d, \u201cD2\u201d refer to the first and second down blocks of the U-Net, respectively.\n\u201cMid\u201d means the middle block of the U-Net.\nThe effectiveness of the Feature Alignment module increases as the number of the aligned layer grows deeper.", "description": "This table presents an ablation study on the placement of the Feature Alignment module within the U-Net architecture of the DepthMaster model.  The Feature Alignment module aligns features from the model with those of an external encoder. The table shows the results of placing this module at different depths within the U-Net: after the first downsampling block (D1), after the second downsampling block (D2), and in the middle block (Mid).  The results (AbsRel and \u03b41 metrics) for different datasets (KITTI, NYU-v2, ETH3D, ScanNet, DIODE) are shown to demonstrate the impact of the module's location on the model's performance.  The key finding is that deeper placement generally leads to better performance, indicating the importance of higher-level semantic features for alignment.", "section": "IV. EXPERIMENTS"}, {"content": "| Model | pixel | L<sub>h</sub> | FE | Two-stage | KITTI AbsRel \u2193 | KITTI \u03b4<sub>1</sub> \u2191 | NYUv2 AbsRel \u2193 | NYUv2 \u03b4<sub>1</sub> \u2191 | ETH3D AbsRel \u2193 | ETH3D \u03b4<sub>1</sub> \u2191 | Scannet AbsRel \u2193 | Scannet \u03b4<sub>1</sub> \u2191 | DIODE AbsRel \u2193 | DIODE \u03b4<sub>1</sub> \u2191 | HyperSim F1 \u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| M.Base |  |  |  |  | 8.7 | 93.1 | 5.1 | 97.3 | 5.5 | 97.2 | 5.8 | 96.4 | 21.8 | 77.2 | 0.306 |\n| M.Pixel | \u2713 |  |  |  | 8.6 | 93.0 | 5.2 | 97.2 | 5.4 | 97.1 | 5.5 | 96.8 | 21.5 | 77.7 | 0.307 |\n| M.Huber | \u2713 | \u2713 |  |  | 8.5 | 93.0 | 5.0 | 97.2 | 5.5 | 97.1 | 5.5 | 96.9 | 21.6 | 77.4 | 0.308 |\n| M.FE_Huber | \u2713 | \u2713 | \u2713 |  | 8.3 | 93.5 | 5.1 | 97.2 | 5.3 | 97.2 | 5.5 | 96.7 | 21.6 | 77.4 | 0.314 |\n| M.Full | \u2713 | \u2713 | \u2713 | \u2713 | 8.2 | 93.7 | 5.0 | 97.2 | 5.3 | 97.4 | 5.5 | 96.7 | 21.5 | 77.6 | 0.337 |", "caption": "TABLE VI: Ablation of detail preservation. \u201cpixel\u201d indicates applying constraints at the pixel level. \u201cFE\u201d refers to the Fourier Enhancement module. \u201cLhsubscript\ud835\udc3f\u210eL_{h}italic_L start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT\u201d refers to the weighted multi-directional gradient loss. \u201cTwo-stage\u201d means the two-stage training curriculum. The proposed modules and training curriculum effectively enhance the detail preservation capability.", "description": "This ablation study analyzes the impact of different components on detail preservation in the DepthMaster model.  It compares the baseline model against versions with pixel-level constraints, the Fourier Enhancement module (FE), the weighted multi-directional gradient loss (Lh), and the two-stage training curriculum. The results show how each component contributes to improving the model's ability to accurately represent fine details in depth estimations.", "section": "IV. EXPERIMENTS"}]