[{"figure_path": "https://arxiv.org/html/2501.02576/x1.png", "caption": "Figure 1: Visualization of different paradigms.\n\u201cDenoise\u201d refers to predicting depth in a diffusion-denoising way. Limited by the feature representation capability of the denoising network, predictions tend to overfit texture details and miss the real structure, as highlighted with yellow boxes in Column\u00a03.\n\u201cStage1\u201d alleviates this issue with the Feature Alignment module, but suffers from blurry outputs due to removing the iterative process, as highlighted with red boxes in Column\u00a04.\n\u201cStage2\u201d presents the final model fine-tuned with the Fourier Enhancement module, which exhibits excellent generalization and fine-grained details.", "description": "This figure visualizes three different approaches to monocular depth estimation: a diffusion-denoising method, a single-step method with Feature Alignment, and a final single-step model incorporating both Feature Alignment and Fourier Enhancement. The diffusion-denoising method is shown to overfit to texture details, while the single-step method with Feature Alignment improves this but produces blurry results.  The final model effectively combines global scene structure and fine-grained details.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2501.02576/x2.png", "caption": "Figure 2: The overall framework of DepthMaster.\nRGB is first projected into the latent space by the I2L Encoder to obtain zR\u2062G\u2062Bsubscript\ud835\udc67\ud835\udc45\ud835\udc3a\ud835\udc35z_{RGB}italic_z start_POSTSUBSCRIPT italic_R italic_G italic_B end_POSTSUBSCRIPT.\nNext, the U-Net converts RGB latent to depth prediction latent zp\u2062r\u2062e\u2062dsubscript\ud835\udc67\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc51z_{pred}italic_z start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d end_POSTSUBSCRIPT, which is decoded back to the depth map by the I2L Decoder.\nThe Feature Alignment module is applied in the first stage to align the representation of the U-Net to that of the high-quality external encoder, introducing semantic information into the diffusion model.\nIn the second stage, the Fourier Enhancement module adaptively balances low-frequency structure and high-frequency details to enhance the visual quality.", "description": "DepthMaster's framework starts by encoding an RGB image into a latent representation using an I2L encoder.  This latent representation is then processed by a U-Net, which produces a depth prediction latent.  This latent is decoded back to a depth map via an I2L decoder.  A two-stage training process is employed. Stage 1 uses a Feature Alignment module to align the U-Net's representation with a high-quality external encoder, incorporating semantic information. Stage 2 uses a Fourier Enhancement module to balance low and high-frequency details for better visual quality in the depth map.", "section": "III. METHOD"}]