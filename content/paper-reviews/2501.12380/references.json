{"references": [{"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2021-00-00", "reason": "This paper introduces MMLU, a benchmark for evaluating large language models across many tasks, providing a foundation for evaluating expert-level reasoning abilities."}, {"fullname_first_author": "Yi Yue", "paper_title": "MMMU: Measuring expert-level multi-discipline understanding", "publication_date": "2024-00-00", "reason": "This paper introduces MMMU, a benchmark for evaluating multi-modal foundation models' reasoning abilities in various domains, influencing the design and evaluation of MMVU."}, {"fullname_first_author": "Xuehai He", "paper_title": "MMWorld: Towards multi-discipline multi-faceted world model evaluation in videos", "publication_date": "2024-00-00", "reason": "This paper introduces MMWorld, a benchmark that incorporates videos across multiple disciplines, which MMVU builds upon to focus on expert-level knowledge-intensive reasoning."}, {"fullname_first_author": "William D. Callister Jr", "paper_title": "Materials science and engineering: an introduction", "publication_date": "2020-00-00", "reason": "This textbook is used for annotation in the MMVU benchmark and provides domain knowledge for subjects in the Science and Engineering disciplines."}, {"fullname_first_author": "Bruce Alberts", "paper_title": "Molecular Biology of the Cell", "publication_date": "2014-00-00", "reason": "This textbook is used for annotation in the MMVU benchmark, offering domain expertise for Biology-related video questions."}]}