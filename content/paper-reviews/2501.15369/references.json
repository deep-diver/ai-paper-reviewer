{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-10-11", "reason": "This paper introduced the vision transformer (ViT), a groundbreaking architecture that significantly impacted the field and inspired many of the approaches discussed in the current paper."}, {"fullname_first_author": "Zhuang Liu", "paper_title": "A ConvNet for the 2020s", "publication_date": "2022-06-01", "reason": "This paper introduced ConvNeXt, a modern convolutional neural network architecture that serves as the backbone for the iFormer model and is heavily analyzed in the paper."}, {"fullname_first_author": "Kaiming He", "paper_title": "Mask R-CNN", "publication_date": "2017-07-01", "reason": "This highly influential paper introduced the Mask R-CNN, a widely used object detection model, for which iFormer is used as the backbone and evaluated in the paper."}, {"fullname_first_author": "Sachin Mehta", "paper_title": "MobileViT: Light-weight, general-purpose, and mobile-friendly vision transformer", "publication_date": "2021-10-02", "reason": "This paper introduced MobileViT, a pioneering hybrid model combining convolutional neural networks and vision transformers, that is directly compared to the current paper's model."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-07-01", "reason": "This paper details training techniques for efficient vision transformers, which are directly relevant and compared to the training and efficiency improvements made by the current paper."}]}