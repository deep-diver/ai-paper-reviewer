[{"figure_path": "https://arxiv.org/html/2503.10618/", "caption": "Figure 1: Comparison of text-to-image generation methods on two metrics, GenEval and T2I CompBench (higher is better for both). Despite significantly smaller model size, our proposed DiT-Air\u00a0achieves state-of-the-art results. Note that, for our model, we report the full model size including text encoder and VAE. A detailed parameter breakdown is provided in Appendix\u00a0G.", "description": "Figure 1 presents a performance comparison of various text-to-image generation models, using two key evaluation metrics: GenEval and T2I CompBench.  Higher scores on both metrics indicate better performance.  The figure highlights that the proposed DiT-Air model, despite having a significantly smaller parameter count (model size) than competing models, achieves state-of-the-art results.  Importantly, the reported model size for DiT-Air includes the parameters of the text encoder and Variational Autoencoder (VAE), which are often separate components in other models.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.10618/x3.png", "caption": "Figure 2: Sample images from our proposed DiT-Air, each with the text prompt below it. See Appendix\u00a0H for more examples.", "description": "This figure showcases sample images generated by the DiT-Air model. Each image is accompanied by the text prompt used to generate it, demonstrating the model's ability to transform text descriptions into corresponding visuals.  The diversity of the images and their fidelity to the prompts highlight the capabilities of the DiT-Air model in generating high-quality, varied outputs.  More examples are available in Appendix H.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.10618/x4.png", "caption": "Figure 3: Overview of Latent Diffusion Training. During training, \ud835\udc31\ud835\udc31\\mathbf{x}bold_x is encoded into a latent \ud835\udc330subscript\ud835\udc330\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT via a VAE, and the text prompt p\ud835\udc5dpitalic_p is mapped to embeddings \ud835\udc1c\ud835\udc1c\\mathbf{c}bold_c. A forward diffusion adds noise to \ud835\udc330subscript\ud835\udc330\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and the model learns to reverse this process by predicting the noise (or similar target) at each timestep.", "description": "This figure illustrates the process of latent diffusion training for text-to-image generation.  First, an input image (x) is encoded into a lower-dimensional latent representation (z0) using a Variational Autoencoder (VAE). Simultaneously, the input text prompt (p) is processed by a text encoder to generate a text embedding (c).  Then, a forward diffusion process adds noise to the latent representation (z0) at various timesteps (t). The core of the model, denoted as f\u03b8, learns to reverse this diffusion process, predicting the added noise (or a similar target quantity) based on the noisy latent representation (zt), text embedding (c), and timestep (t).  This iterative denoising process is trained to minimize the difference between the model's prediction and the actual noise added at each step.  During inference, this trained model iteratively denoises a random latent vector to reconstruct a clean image from the text prompt.", "section": "3. Architecture Design"}, {"figure_path": "https://arxiv.org/html/2503.10618/x5.png", "caption": "Figure 4: Comparison of Diffusion Transformer Architectures. Element-wise operations are denoted by \u2219\u2219\\bullet\u2219, and sequence-wise operations by \u2218\\circ\u2218. The details of inputs \ud835\udc1c\ud835\udc1c\\mathbf{c}bold_c, \ud835\udc33\ud835\udc33\\mathbf{z}bold_z, t\ud835\udc61titalic_t can be found in Figure\u00a03.\nPixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1 relies on sequential self- and cross-attention, whereas MMDiT uses a dual-stream approach with separate parameters for text and image tokens. Our proposed DiT-Air\u00a0resembles a vanilla DiT that processes concatenated text and noises.", "description": "Figure 4 illustrates three different Diffusion Transformer (DiT) architectures: PixArt-\u03b1, MMDiT, and the proposed DiT-Air.  PixArt-\u03b1 uses sequential self- and cross-attention mechanisms, processing image patches and fixed text embeddings separately in each layer.  MMDiT employs a dual-stream approach, maintaining separate pathways for text and image tokens with dedicated parameters in each layer.  In contrast, DiT-Air adopts a simplified approach, resembling a standard DiT model.  DiT-Air directly processes concatenated text embeddings and image noise, thereby simplifying the architecture and reducing the number of parameters. Element-wise operations are represented by the bullet symbol, and sequence-wise operations are represented by a circle symbol in the diagram.", "section": "3. Architecture Design"}, {"figure_path": "https://arxiv.org/html/2503.10618/x6.png", "caption": "Figure 5: Validation Loss vs.\u00a0Model Size for PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1, MMDiT, and DiT-Air. The plot illustrates the scaling behavior of three architectures across model sizes ranging from S to XXL, where the model size refers only to the diffusion transformer component (excluding the text encoder and VAE). The x-axis is in logarithmic scale, and the fitted lines depict the scaling trend using the formula L=a\u22c5Sb\ud835\udc3f\u22c5\ud835\udc4esuperscript\ud835\udc46\ud835\udc4fL=a\\cdot S^{b}italic_L = italic_a \u22c5 italic_S start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT. Among the three, DiT-Air\u00a0achieves the best parameter efficiency.", "description": "This figure displays the relationship between model size and validation loss for three different text-to-image generation models: PixArt-\u03b1, MMDiT, and DiT-Air.  Model sizes range from small (S) to extra extra large (XXL), but the plotted size only considers the diffusion transformer part of the model, excluding the text encoder and VAE. The x-axis uses a logarithmic scale to better visualize the wide range of model sizes.  Trend lines are fitted to the data points using the power law function L = a * S<sup>b</sup>, where L represents validation loss and S represents model size.  The plot shows that DiT-Air exhibits the most efficient scaling, meaning it achieves lower validation loss with smaller model sizes compared to PixArt-\u03b1 and MMDiT.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.10618/x7.png", "caption": "Figure 6: Benchmark Performance Across Model Scales.\nThe plots compare PixArt-\u03b1\ud835\udefc\\alphaitalic_\u03b1, MMDiT, and DiT-Air\u00a0across six evaluation metrics. DiT-Air\u00a0demonstrates strong parameter efficiency, achieving competitive performance with fewer parameters. The x-axis is in logarithmic scale, and error bounds are indicated where applicable.", "description": "Figure 6 presents a comparative analysis of three different diffusion transformer architectures (PixArt-\u03b1, MMDiT, and DiT-Air) across a range of model sizes.  The performance is evaluated using six key metrics: Fr\u00e9chet Inception Distance (FID), CLIPScore, PickScore, GenEval, LAION-Aesthetics, and T2I CompBench.  The graphs visually demonstrate the scaling behavior of each architecture as model size increases (shown on a logarithmic x-axis).  Error bars represent the uncertainty in the measurements. The main takeaway is that DiT-Air achieves competitive performance with significantly fewer parameters compared to the other two architectures, highlighting its superior parameter efficiency.", "section": "4. Experiments"}]