{"references": [{"fullname_first_author": "Li Hu", "paper_title": "Animate Anyone: Consistent and controllable image-to-video synthesis for character animation", "publication_date": "2024-01-01", "reason": "Cited multiple times in the paper, this work introduces a method for consistent and controllable image-to-video synthesis specifically for character animation."}, {"fullname_first_author": "Georgios Pavlakos", "paper_title": "Expressive body capture: 3d hands, face, and body from a single image", "publication_date": "2019-01-01", "reason": "This paper focuses on capturing detailed 3D human representations from a single image, providing a foundation for body and facial expression modeling, which the DreamActor-M1 uses."}, {"fullname_first_author": "Duomin Wang", "paper_title": "Progressive disentangled representation learning for fine-grained controllable talking head synthesis", "publication_date": "2023-01-01", "reason": "This paper enables fine-grained control over facial expressions and talking head synthesis, and the DreamActor-M1 uses implicit face representation from this study."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces Latent Diffusion Models, and the DreamActor-M1 framework is built upon this which it uses for training and latent space manipulation."}, {"fullname_first_author": "Aliaksandr Siarohin", "paper_title": "First order motion model for image animation", "publication_date": "2019-01-01", "reason": "This method provides a foundational approach for image animation based on motion modeling and is referenced as a basis for comparison, and is commonly used as a method for image animation."}]}