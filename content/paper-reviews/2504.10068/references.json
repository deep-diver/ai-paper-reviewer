{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023-00-00", "reason": "This work likely provides crucial baselines and techniques for visual instruction tuning, which is a key aspect of training multimodal large language models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a foundational model for visual representation learning using natural language supervision, enabling transfer learning for various vision tasks and is frequently cited as a backbone in vision-language models."}, {"fullname_first_author": "Zhiyu Wu", "paper_title": "Deepseek-vl2: Mixture-of-experts vision-language models for advanced multimodal understanding", "publication_date": "2024-00-00", "reason": "This work presents DeepSeek-VL2, a mixture-of-experts vision-language model, which improves performance on multimodal understanding."}, {"fullname_first_author": "Shuai Bai", "paper_title": "Qwen2.5-vl technical report", "publication_date": "2025-02-00", "reason": "This paper presents Qwen2.5-VL which demonstrated an improvement in model performance that is frequently used as the baseline model in this paper."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-00-00", "reason": "This work describes techniques to improve the capabilities of large multimodal models to follow human instruction."}]}