[{"figure_path": "https://arxiv.org/html/2503.00955/x1.png", "caption": "Figure 1: SemViQA: A Three-Stage Method for semantic-based evidence retrieval and two-step verdict classification, where P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and P3subscript\ud835\udc433P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT represent the probabilities of the two-class and three-class classifications, respectively, and y^2subscript^\ud835\udc662\\hat{y}_{\\text{2}}over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and y^3subscript^\ud835\udc663\\hat{y}_{\\text{3}}over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT denote their corresponding predictions.", "description": "SemViQA is a three-stage fact-checking framework.  The first stage preprocesses the input data. The second stage retrieves evidence using a hybrid approach combining TF-IDF and a Question Answering Token Classifier (QATC). TF-IDF is used for efficient keyword matching, while QATC refines evidence selection for complex cases. The third stage classifies the claim using a two-step approach: first, a three-class classification (supported, refuted, not enough information), and then a binary classification (supported, refuted) for cases that weren't classified as 'not enough information'.  P<sub>2</sub> and P<sub>3</sub> represent the probabilities from the two-class and three-class classifications respectively.  \u0177<sub>2</sub> and \u0177<sub>3</sub> represent the corresponding predictions.", "section": "3 SemViQA - Semantic Vietnamese Question Answering"}, {"figure_path": "https://arxiv.org/html/2503.00955/x2.png", "caption": "Figure 2: Graph representing the lengths of contexts.", "description": "This figure is a graph showing the distribution of context lengths in tokens for two Vietnamese fact-checking datasets: ISE-DSC01 and ViWikiFC. The x-axis represents the dataset, and the y-axis represents the number of tokens.  The graph visually demonstrates that the ViWikiFC dataset has shorter contexts (maximum around 598 tokens), whereas the ISE-DSC01 dataset contains significantly longer contexts, with a maximum exceeding 4800 tokens. This highlights a key challenge in processing the ISE-DSC01 data due to length limitations of standard transformer models.", "section": "3.1 Data Processing"}, {"figure_path": "https://arxiv.org/html/2503.00955/x3.png", "caption": "Figure 3: Long context processing solution.", "description": "This figure illustrates the solution implemented in SemViQA to handle long contexts exceeding the token limits of Vietnamese BERT models. The process involves splitting the long context into smaller segments (subcontexts) of under 400 tokens and checking for the presence of the evidence sentence within each subcontext.  If the evidence sentence is found, the subcontext is kept. If it is not present, an empty string is assigned for that subcontext.  The resulting subcontexts are then used for further processing, ensuring that no information is lost due to the token length constraint.", "section": "3 SemViQA - Semantic Vietnamese Question Answering"}, {"figure_path": "https://arxiv.org/html/2503.00955/x4.png", "caption": "Figure 4: Comparison of method performance, balancing accuracy and inference time. Each retrieval method is evaluated based on its highest achieved score, while the total inference time across both datasets is reported to highlight efficiency. Further details can be found in Table\u00a02.", "description": "Figure 4 presents a comparison of different fact-checking methods' performance, focusing on both accuracy and inference time.  It displays the average strict accuracy and total inference time (across the ViWikiFC and ISE-DSC01 datasets) for various methods. This visualization helps to understand the trade-offs between accuracy and speed, allowing readers to assess the efficiency and overall effectiveness of each approach. Detailed performance metrics (including Evidence Retrieval Accuracy and Veracity Classification Accuracy) are presented in Table 2.", "section": "4.3.1 Performance Comparison"}, {"figure_path": "https://arxiv.org/html/2503.00955/x5.png", "caption": "Figure 5: Impact of confidence threshold on evidence retrieval accuracy in SemViQA.", "description": "This figure shows how changing the confidence threshold in SemViQA affects the accuracy of evidence retrieval.  The x-axis represents the confidence threshold, ranging from 0 to 1. The y-axis displays the evidence retrieval accuracy for both the ViWikiFC and ISE-DSC01 datasets. The graph visually demonstrates the trade-off between retrieval accuracy and computational efficiency.  A higher threshold increases accuracy by filtering out less relevant evidence but may reduce efficiency by processing fewer pieces of information.  The optimal threshold represents a balance between accuracy and efficiency.", "section": "4.3.2 Analysis of Confidence Threshold in SemViQA"}, {"figure_path": "https://arxiv.org/html/2503.00955/x6.png", "caption": "Figure 6: Training progress of the ViMRClargelarge{}_{\\text{large}}start_FLOATSUBSCRIPT large end_FLOATSUBSCRIPT and InfoXLMlargelarge{}_{\\text{large}}start_FLOATSUBSCRIPT large end_FLOATSUBSCRIPT models.", "description": "Figure 6 presents the training curves for two Vietnamese Question Answering models, ViMRClarge and InfoXLMlarge, during the training phase of the Question Answering Token Classifier (QATC).  The plots show the loss values over training steps for each model on two separate datasets: ViWikiFC and ISE-DSC01.  This visualization allows for assessment of model training convergence, stability, and comparative performance across the two models and datasets.  The x-axis represents the training steps, and the y-axis represents the loss.", "section": "3.4 Question Answering Token Classifier (QATC)"}, {"figure_path": "https://arxiv.org/html/2503.00955/x7.png", "caption": "Figure 7: Training progress of the Qwen 1.5B and Qwen 3B models.", "description": "This figure displays the training loss curves for the Qwen 1.5B and Qwen 3B language models across two datasets, ViWikiFC and ISE-DSC01.  The x-axis represents the training epochs, while the y-axis shows the loss value.  Separate plots are shown for each dataset.  The plots illustrate the convergence behavior of the models during training, offering insights into the training stability and efficiency of the two different sized models.", "section": "4.3 Main Results"}]