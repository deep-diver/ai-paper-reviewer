[{"figure_path": "https://arxiv.org/html/2504.02119/x1.png", "caption": "Figure 1: An overview of model selection via LLMs.", "description": "This figure illustrates the process of model selection for time series forecasting using Large Language Models (LLMs).  The process begins with a time series dataset, which may optionally include pre-computed meta-features. A prompt is constructed using the dataset values, meta-features (if included), and optionally, chain-of-thought (CoT) reasoning steps.  This prompt is then submitted to one of several candidate LLMs (Llama 3.2, GPT-4, Gemini 2.0). The LLM processes the prompt and outputs a selected model, including the forecasting algorithm, hyperparameters, and data representation. Finally, the selected model is evaluated on a testing dataset to assess its performance.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2504.02119/x2.png", "caption": "(a) Average training and inference time (in seconds). Detailed mean and standard deviation values are provided in Table\u00a06.", "description": "Figure 2a displays a bar chart comparing the average training and inference times for different model selection methods. The methods include a na\u00efve approach (without model selection), two meta-learning techniques (ISAC and MLP), and three LLM-based methods using Llama 3.2, GPT-40, and Gemini 2.0. For each method, the chart shows two bars representing the average training time and average inference time in seconds.  Detailed mean and standard deviation values for all times are available in Table 6. This figure highlights the significant speed advantage of using LLMs for model selection in time-series forecasting, showing much faster inference times than the baselines.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2504.02119/x3.png", "caption": "(b) The inference time reduction of LLM-based methods over the na\u00efve approach. Our Llama, GPT, and Gemini-based methods give a median reduction of 14X,18X, and 89X over na\u00efve approach on all the datasets.", "description": "The bar chart visualizes the significant decrease in inference time achieved by the LLM-based model selection methods compared to the traditional, exhaustive 'na\u00efve' approach.  The median inference time reduction factors are striking: 14x for Llama, 18x for GPT, and a remarkable 89x for Gemini. This highlights the substantial computational efficiency gained by using LLMs for model selection in time series forecasting, across all datasets considered in the study.", "section": "4.3 Overall Results"}, {"figure_path": "https://arxiv.org/html/2504.02119/x4.png", "caption": "Figure 2: Comparison of training and inference time across different methods.", "description": "This figure compares the training and inference times of different model selection methods used for time series forecasting. The methods include a naive approach, meta-learning methods like ISAC and MLP, and the proposed LLM-based methods using different LLMs (Llama, GPT, and Gemini) and various prompt designs. The bar chart shows that the training time is negligible for the LLM-based methods, while the inference time is significantly reduced compared to the naive approach, with the Gemini-based method showing the greatest reduction.", "section": "4 Experiments"}]