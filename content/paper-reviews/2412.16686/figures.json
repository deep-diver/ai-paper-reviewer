[{"figure_path": "https://arxiv.org/html/2412.16686/x1.png", "caption": "Figure 1: Demonstration of LLM internal knowledge and world knowledge from IFT datasets.", "description": "This figure illustrates the difference between an LLM's internal knowledge (knowledge learned during pre-training) and the world knowledge present in instruction fine-tuning (IFT) datasets.  It shows how an instruction, processed by the pretrained LLM, elicits an answer that incorporates both internal knowledge (e.g., implicit understanding of emotions) and world knowledge (e.g., explicit facts about project outcomes).  The NILE framework aims to improve alignment between these two knowledge sources in the IFT dataset, leading to better LLM performance.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2412.16686/x2.png", "caption": "Figure 2: Overview of our NILE framework.", "description": "The NILE framework is depicted in this flowchart, which is broken down into three primary phases: Internal Knowledge Extraction (IKE), Knowledge-Aware Sample Revision (KSR), and Internal Consistency Filtering (ICF).  The framework starts with original instruction-response pairs from an instruction tuning dataset. IKE uses a pre-trained LLM to extract internal knowledge associated with the instruction. KSR leverages this knowledge to revise the original answer. Finally, ICF filters revised samples based on their internal consistency with the pre-trained LLM. The resulting aligned dataset is then used for instruction fine-tuning.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2412.16686/x3.png", "caption": "Figure 3: Distribution plot of sentence embedding similarity score in Alpaca dataset for Mistral model.", "description": "This figure displays the distribution of sentence embedding similarity scores calculated for the Mistral language model using the Alpaca dataset.  The distribution shows the similarity between sentence embeddings generated by the original answers in the dataset, answers revised using the Knowledge-aware Sample Revision (KSR) method, and answers revised using the Sample Revision (SR) method. This visual representation helps to evaluate the effectiveness of the KSR method in enhancing the affinity between the model's internal knowledge and the information provided in the dataset.  Specifically, higher similarity scores indicate a stronger alignment between the revised answers and the internal knowledge of the model.", "section": "4.7.3 Effects of KAR"}, {"figure_path": "https://arxiv.org/html/2412.16686/x4.png", "caption": "Figure 4: Distribution of sentence embedding similarity across different LLMs and IFT datasets.", "description": "This figure displays the distribution of sentence embedding similarity scores obtained from three different methods: Vanilla (original responses), KSR (responses revised using knowledge-aware sample revision), and SR (responses revised without using internal LLM knowledge).  The distributions are shown separately for Alpaca and Orca datasets and for two different LLMs, Mistral and Llama. The plots visually compare how similar the generated responses are to the internal knowledge of the LLMs, illustrating the impact of the KSR technique on aligning generated text with pre-trained knowledge.", "section": "4.7.3 Effects of KAR"}]