{"references": [{"fullname_first_author": "Yanghao Li", "paper_title": "Mvitv2: Improved multiscale vision transformers for classification and detection.", "publication_date": "2022-01-01", "reason": "This paper is a fundamental reference for understanding the vision transformer (ViT) architecture, which is a key component of InternVL3."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper describes a pre-training task that plays a critical role in helping a model develop the general reasoning ability needed in a vision language model."}, {"fullname_first_author": "Yuan Liu", "paper_title": "Mmbench: Is your multi-modal model an all-around player?", "publication_date": "2023-01-01", "reason": "MMBench is used in the current paper as the primary benchmark for evaluating multimodal understanding capabilities."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-01-01", "reason": "MMLU is used in the current paper as a key evaluation to asses language abilities."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2024-01-01", "reason": "This is a foundational reference for mixed preference optimization, an algorithm that the paper shows imporves a vision language model."}]}