{"references": [{"fullname_first_author": "Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This paper introduced the Chain-of-Thought prompting, which is a fundamental concept for improving the reasoning capabilities of Large Language Models (LLMs)."}, {"fullname_first_author": "Jaech", "paper_title": "OpenAI o1 system card", "publication_date": "2024-12-16", "reason": "This paper described the capabilities of the O1 model from OpenAI which marked a significant advancement in reasoning and served as a foundation for subsequent research."}, {"fullname_first_author": "Guo", "paper_title": "DeepSeek-R1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-12", "reason": "This paper described the DeepSeek R1 model, a significant open-source Large Reasoning Model (LRM) with transparent reasoning tokens."}, {"fullname_first_author": "Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-09-03", "reason": "This is a benchmark paper for many large language models; the benchmarks were used to evaluate reasoning capabilities of models."}, {"fullname_first_author": "Silver", "paper_title": "Mastering the game of go without human knowledge", "publication_date": "2017-01-01", "reason": "This paper introduced a method used in Large Reasoning Models: Monte Carlo Tree Search (MCTS)."}]}