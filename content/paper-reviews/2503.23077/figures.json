[{"figure_path": "https://arxiv.org/html/2503.23077/extracted/6320210/8_paper_structure.png", "caption": "Figure 1: Overview Structure of this Survey.", "description": "This figure provides a visual overview of the paper's structure and the flow of topics discussed. It shows that the paper starts with an introduction to Large Reasoning Models (LRMs) and their efficiency challenges. Then, it presents a taxonomy for categorizing existing efficient inference methods for LRMs into two main types: explicit compact Chain-of-Thought (CoT) and implicit latent CoT.  The paper proceeds with empirical analyses of these methods, covering both performance and efficiency aspects. Finally, it discusses open challenges and potential future improvements in the field, such as new architectures, model merging, and agent routers.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2503.23077/extracted/6320210/9_overview.png", "caption": "Figure 2: Overview of Taxonomy.", "description": "This figure presents a hierarchical taxonomy of efficient inference methods for Large Reasoning Models (LRMs).  It categorizes recent approaches into two main classes: (a) explicit compact Chain-of-Thought (CoT), which aims to reduce tokens while maintaining the explicit reasoning structure, and (b) implicit latent CoT, which encodes reasoning steps within hidden representations instead of explicit tokens.  Each class is further broken down into subclasses to provide a more granular understanding of the methods used to improve efficiency.  The figure visually represents the relationships between these different categories of LRM inference methods.", "section": "3 Landscape of LRM Efficient Inference Research"}]