{"importance": "This survey is crucial for researchers as it addresses the **growing challenge of efficient reasoning in large language models**, providing a valuable guide to current methods and future directions. It highlights key challenges and potential solutions, paving the way for **more practical and scalable applications**.", "summary": "Survey on efficient inference methods for Large Reasoning Models, focusing on mitigating token inefficiency while preserving quality.", "takeaways": ["Efficient inference methods for LRMs can be categorized into explicit compact CoT and implicit latent CoT.", "There are 4 open challenges: human-centric controllable reasoning, trade-off between interpretability and efficiency, ensuring safety of efficient reasoning, and broader applications of efficient reasoning", "Techniques such as model merging, new architectures, and agent routers can further enhance LRMs' inference efficiency."], "tldr": "Large Reasoning Models (LRMs) enhance the reasoning ability of LLMs but suffer from **inefficiencies in token usage, memory consumption, and inference time**. This survey reviews methods designed specifically for LRMs to mitigate token inefficiency while preserving reasoning quality. It categorizes these methods into **explicit compact Chain-of-Thought (CoT), which reduces tokens while keeping the explicit reasoning structure, and implicit latent CoT, which encodes reasoning steps within hidden representations instead of explicit tokens**.\n\nBeyond categorizing, the survey presents empirical analyses of existing methods, from performance and efficiency perspectives. It presents open challenges, including **human-centric controllable reasoning**, the trade-off between interpretability and efficiency, and ensuring the safety of efficient reasoning. The authors also highlight techniques such as **model merging, new architectures, and agent routers as key to enhancing inference efficiency**.", "affiliation": "National University of Singapore", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.23077/podcast.wav"}