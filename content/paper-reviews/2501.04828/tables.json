[{"content": "| Partition | # of Sentences | PERSON Counts | LOCATION Counts |\n|---|---|---|---|\n| Training set | 462 | 264 | 584 |\n| Development set | 200 | 122 | 210 |\n| *Ruznam\u00e7e* test set | 150 | 265 | 216 |\n| **Total** | 812 | 651 | 1,010 |", "caption": "Table 1: \nPartitions in the HisTR dataset", "description": "This table presents the distribution of sentences in the HisTR (Historical Turkish Named Entity Recognition) dataset across different partitions: training set, development set, and two test sets (one for general evaluation and another specifically designed to test robustness on a more challenging historical text type).  For each partition, it shows the total number of sentences and the counts of sentences containing PERSON and LOCATION entities.  This breakdown allows readers to assess the size and composition of the dataset used for training and evaluating the named entity recognition models.", "section": "3 Resources for Historical Turkish NLP"}, {"content": "| Features | The OTA-BOUN Treebank |\n|---|---| \n| Num. of Sentences | 514 |\n| Num. of Tokens | 8,794 |\n| Avg. Token Count Per Sentence | 17.10 |\n| Num. of Unique POS Tags | 16 |\n| Num. of Unique Morphological Features | 52 |\n| Num. of Unique Dependencies | 40 |", "caption": "Table 2: Some statistics of the OTA-BOUN historical Turkish treebank", "description": "Table 2 presents a detailed statistical overview of the Ottoman Turkish-Bo\u011fazi\u00e7i University (OTA-BOUN) historical treebank, a valuable linguistic resource for researchers working with historical Turkish. The table summarizes key features of the treebank, providing insights into the nature and characteristics of the data.  Specifically, it provides the total number of sentences, tokens, and the average token count per sentence, giving a sense of the corpus size and sentence length distribution. It also presents the number of unique parts-of-speech (POS) tags and unique morphological features, offering insights into the richness and complexity of the language represented in the treebank. Finally, it includes the number of unique dependency relations, which are crucial for understanding the grammatical structures captured within the treebank.", "section": "3.2 OTA-BOUN: A Universal Dependencies Treebank for Historical Turkish"}, {"content": "| Relation Type | Count | % | Relation Type | Count | % |\n|---|---|---|---|---|---| \n| acl | 348 | 3.95 | dislocated | 5 | 0.06 |\n| advcl | 197 | 2.24 | fixed | 6 | 0.07 |\n| advmod | 396 | 4.49 | flat | 87 | 0.99 |\n| advmod:emph | 87 | 0.99 | goeswith | 5 | 0.06 |\n| amod | 620 | 7.04 | iobj | 26 | 0.30 |\n| appos | 2 | 0.02 | mark | 27 | 0.31 |\n| aux | 39 | 0.44 | nmod | 137 | 1.55 |\n| case | 257 | 2.92 | nmod:poss | 746 | 8.47 |\n| cc | 228 | 2.59 | nsubj | 507 | 5.75 |\n| cc:preconj | 12 | 0.14 | nsubj:pass | 22 | 0.25 |\n| ccomp | 120 | 1.36 | nummod | 57 | 0.65 |\n| compound | 76 | 0.86 | obj | 557 | 6.32 |\n| compound:lvc | 246 | 2.79 | obl | 873 | 9.91 |\n| compound:redup | 33 | 0.37 | obl:agent | 4 | 0.05 |\n| conj | 607 | 6.89 | orphan | 4 | 0.05 |\n| cop | 48 | 0.54 | parataxis | 10 | 0.11 |\n| csubj | 42 | 0.48 | punct | 1207 | 13.70 |\n| dep | 14 | 0.16 | root | 514 | 5.83 |\n| det | 508 | 5.76 | vocative | 7 | 0.08 |\n| discourse | 82 | 0.93 | xcomp | 49 | 0.56 |", "caption": "Table 3: Counts and percentages of dependency relation types in the OTA-BOUN treebank", "description": "This table presents a detailed breakdown of the dependency relations found within the Ottoman Turkish Universal Dependencies (OTA-BOUN) treebank. It lists each dependency relation type, its frequency count, and its percentage relative to the total number of dependency relations in the treebank.  This provides valuable insights into the syntactic structures characteristic of historical Turkish, such as the prevalence of particular types of relationships between words in sentences.", "section": "3.2 OTA-BOUN: A Universal Dependencies Treebank for Historical Turkish"}, {"content": "|                      | **TR-BOUN** | **IMST-UD** | **OTA-BOUN** |\n|----------------------|-------------|-------------|-------------|\n| Avg. token count per sentence | 12.41        | 10.01        | 17.10        |\n| conj (%)             | 5.66         | 4.96         | 6.89         |\n| compound:lvc (%)     | 1.0          | 0.90         | 2.79         |\n| acl (%)              | 2.78         | 2.64         | 3.95         |", "caption": "Table 4: Comparison of historical Turkish treebank with the two most frequently used modern Turkish treebanks in terms of token and dependency metrics", "description": "Table 4 presents a quantitative comparison of the OTA-BOUN historical Turkish treebank with two widely used modern Turkish treebanks (TR-BOUN and IMST-UD). The comparison focuses on key metrics related to token and dependency features, offering insights into the structural differences between historical and modern Turkish.  Metrics include the average number of tokens per sentence, the percentage of conjunct (conj) dependency relations, and the percentage of light verb compound (compound:lvc) dependency relations and adnominal clause (acl) relations. These metrics provide valuable insights into the syntactic and stylistic characteristics of each treebank, highlighting how historical Turkish differs from modern Turkish in terms of sentence structure and grammatical constructions.", "section": "3.2 OTA-BOUN: A Universal Dependencies Treebank for Historical Turkish"}, {"content": "| Expected Text | Extracted Text | Error Analysis |\n|---|---|---|\n| Dilber\u00fcn her handesi bin can ba\u011f\u0131\u015flar e a\u015fuya | Dil-beru\u00f1 her \u00f2andesi bi\u00f1 c\u00c0n ba\u00e0\u0131\u015flar \u00e8\u00c0\u015f\u0131\u00faa | Diacritical Encoding Error: Unicode normalization failure in historical Turkish diacritics and characters. The system incorrectly encodes special characters \u2019\u00f1\u2019 and \u2019\u00c0\u2019, resulting in ambiguity. Technical cause: Non-standardized Unicode point mapping for Ottoman-specific diacritics. |\n| Bu mutabakatla beraber, ke\u015ff edilen eski yaz\u0131ld\u0131\u011f\u0131 ve\u00e7hile T\u00fcrk\u00e7e kar\u015f\u0131l\u0131\u011f\u0131 lafz\u0131d\u0131r. | Bu mutabakatle beraber, ke\u015ff edilen eski ya WU J. \u0131S i J e Ha T\u0131 Ye Kef Lam Mim Nun te de yaz\u0131ld\u0131\u011f\u0131 ve\u00e7hile T\u00fcrk\u00e7e kar\u015f\u0131l\u0131\u011f\u0131 lafz\u0131d\u0131r. | Script Conversion Error: Critical failure in Arabic-Latin script conversion pipeline. OCR system\u2019s inability to properly map Arabic script ligatures to Latin characters due to contextual shape variations. Root cause: Inadequate handling of Unicode ranges U+0600-U+06FF. |\n| G\u00dcR\u0130Z yahut G\u00dcR\u0130ZGAH: | G \u00dc R \u00ceZ : , y\u00e2hut G \u00dc R \u0130Z G \u00c2 H : | Word Segmentation Error: Tokenization algorithm failure in word recognition. Improper word boundary detection caused by missing morphological analysis support. Technical impact: Loss of semantic unity in words. |\n| H\u0130S\u00c2B-\u0131 C\u00dcMEL: Ebced his\u00e2b\u0131n\u0131n di\u011fer ad\u0131d\u0131r | HtS\u00c2B-t C \u00dc M EL: Ebced hi-s\u00e2b\u0131n\u0131n di\u011fer ad\u0131d\u0131r | Character Substitution Error: Systematic misclassification of Turkish \u2019\u0130\u2019 character as \u2019t\u2019. Error stems from inadequate training data representation of Turkish-specific uppercase dotted \u2019\u0130\u2019. Technical cause: Unicode point confusion between U+0130 and U+0074. |\n| \u0130ran \u015f\u00e2irlerinden: \u015eevket Fer\u00e2h\u00ee\u2019nin | \u0130ran \u015f\u00e2irlerinden: J i j Z j S \u2019 C j | Mixed Script Error: Complete text fragmentation due to script detection failure. System\u2019s inability to maintain consistent character encoding across different writing systems. Root cause: Inadequate handling of bi-directional text rendering. |", "caption": "Table 5: Analysis of sample text extraction errors in digital conversion of historical Turkish documents", "description": "This table presents examples of text extraction errors encountered during the digital conversion of historical Turkish documents.  It showcases the types of errors, their causes (e.g., diacritical encoding, script conversion, word segmentation, character substitution, mixed script issues), and analysis of why these errors occurred during the digitization process. Each row details a specific instance with the original (expected) text, the extracted text containing errors, and a breakdown explaining the nature and source of the error, including references to Unicode issues and challenges related to processing historical Turkish script variations.", "section": "3 Resources for Historical Turkish NLP"}, {"content": "| Model Descriptions |  |  |  |  |  |  |\n|---|---|---|---|---|---|---|\n| `BERTurk+MilliyetNER` | `BERTurk fine-tuned only using MilliyetNER,` |  |  |  |  |  |\n|  | `a large NER dataset for modern Turkish.` |  |  |  |  |  |\n| `BERTurk+MilliyetNER+HisTR` | `BERTurk+MilliyetNER further fine-tuned using` |  |  |  |  |  |\n|  | `HisTR, the small dataset for historical Turkish.` |  |  |  |  |  |\n| `BERTurk+HisTR` | `BERTurk fine-tuned only using HisTR.` |  |  |  |  |  |\n| `mBERT+WikiANN+HisTR` | `mBERT fine-tuned on WikiANN, a large multilingual` |  |  |  |  |  |\n|  | `NER dataset, and further fine-tuned using HisTR.` |  |  |  |  |  |\n| `mBERT+HisTR` | `mBERT fine-tuned only using HisTR.` |  |  |  |  |  |\n| `TURNA+MilliyetNER+HisTR` | `TURNA fine-tuned on MilliyetNER and further` |  |  |  |  |  |\n|  | `fine-tuned using HisTR.` |  |  |  |  |  |\n| Model Performance |  |  |  |  |  |  |\n|---|---|---|---|---|---|---|\n|  | HisTR Development Set |  |  | _Ruznam\u00e7e_ Test Set |  |  |\n| **Name** | **Prec.** | **Recall** | **F1** | **Prec.** | **Recall** | **F1** |\n| `BERTurk+MilliyetNER` | 75.39 | 71.99 | 73.65 | 53.84 | 61.95 | 57.58 |\n| `BERTurk+MilliyetNER+HisTR` | **90.26** | **92.17** | **91.21** | **59.92** | **64.03** | **61.91** |\n| `BERTurk+HisTR` | 88.63 | 91.57 | 90.07 | 54.49 | 61.75 | 57.89 |\n| `mBERT+WikiANN+HisTR` | 80.73 | 87.05 | 83.77 | 41.17 | 41.93 | 41.49 |\n| `mBERT+HisTR` | 83.95 | 88.25 | 86.05 | 43.19 | 42.20 | 42.69 |\n| `TURNA+MilliyetNER+HisTR` | 77.62 | 80.26 | 78.92 | 57.61 | 41.58 | 48.30 |", "caption": "Table 6: \nThe overall performance of BERTurk, mBERT, and TURNA NER models on the in-domain development and out-of-domain test sets of the HisTR dataset when using different combinations of fine-tuning sets", "description": "Table 6 presents the performance of three different pre-trained Named Entity Recognition (NER) models (BERTurk, mBERT, and TURNA) on the HisTR dataset.  The HisTR dataset is specifically designed for historical Turkish texts, posing unique challenges not encountered in modern Turkish NER. The table shows the performance of the models on both an in-domain development set and an out-of-domain test set.  The in-domain data consists of similar texts to those in the training data, while the out-of-domain data has different characteristics. Multiple experiments were conducted for each model using various combinations of training data. The results are reported using the precision, recall, and F1-score for each setting, offering insights into how well each model generalizes to the different datasets.", "section": "5.1 NER Experiments"}, {"content": "| Model Descriptions |  | OTA-BOUN Test Set (Historical Turkish) |  TR-BOUN Test Set (Modern Turkish) | \n|---|---|---|---|---|\n| STEPS<sub>BERTurk</sub>+TR_BOUN | STEPS parser with BERTurk, fine-tuned only using TR_BOUN, a large dependency treebank for modern Turkish. |  |  |  |\n| STEPS<sub>BERTurk</sub>+TR_BOUN+OTA_BOUN | STEPS<sub>BERTurk</sub>+TR_BOUN further fine-tuned using OTA_BOUN, a small treebank for historical Turkish. |  |  |  |\n| STEPS<sub>BERTurk</sub>+OTA_BOUN | STEPS parser with BERTurk, fine-tuned only using OTA_BOUN |  |  |  |\n| STEPS<sub>mBERT</sub>+TR_BOUN | STEPS parser with BERTurk, fine-tuned only using TR_BOUN. |  |  |  |\n| STEPS<sub>mBERT</sub>+TR_BOUN+OTA_BOUN | STEPS<sub>mBERT</sub>+TR_BOUN further fine-tuned using OTA_BOUN. |  |  |  |\n| STEPS<sub>mBERT</sub>+OTA_BOUN | STEPS parser with mBERT, fine-tuned only using OTA_BOUN. |  |  |  |\n| Model Performance |  |  |  |  |\n|---|---|---|---|---|\n|  |  | OTA-BOUN Test Set | TR-BOUN Test Set | \n|  |  | (Historical Turkish) | (Modern Turkish) | \n| Name | Tra. Size | UAS | LAS | UPOS F1 | UAS | LAS | UPOS F1 |\n| STEPS<sub>BERTurk</sub>+TR_BOUN | 7,803 | 79.92 | 71.29 | 94.76 | 83.11 | 76.55 | 93.00 |\n| STEPS<sub>BERTurk</sub>+TR_BOUN+OTA_BOUN | 7,917 | 81.51 | 73.79 | 94.98 | 83.15 | 76.58 | 93.07 |\n| STEPS<sub>BERTurk</sub>+OTA_BOUN | 114 | 68.87 | 59.70 | 91.56 | 68.66 | 59.16 | 87.21 |\n| STEPS<sub>mBERT</sub>+TR_BOUN | 7,803 | 72.96 | 64.32 | 92.26 | 79.61 | 72.05 | 92.75 |\n| STEPS<sub>mBERT</sub>+TR_BOUN+OTA_BOUN | 7,917 | 75.86 | 67.87 | 93.12 | 79.60 | 72.18 | 92.78 |\n| STEPS<sub>mBERT</sub>+OTA_BOUN | 114 | 61.43 | 49.62 | 88.68 | 59.55 | 46.56 | 84.54 |", "caption": "Table 7: \nThe overall performance of BERTurk- and mBERT-based models on the test sets of the OTA-BOUN and TR-BOUN treebanks, presented for different combinations of fine-tuning sets. UAS and LAS represent unlabeled and labeled attachment scores, respectively, which are used to evaluate the models\u2019 performance in constructing dependency relations. UPOS F1 refers to the F1 score of the sequence tagger models in predicting the universal POS tags of words in the corresponding test sets.", "description": "Table 7 presents the results of dependency parsing and POS tagging experiments using the STEPS parser with BERTurk and mBERT models.  It shows the performance of different model configurations (fine-tuned on various combinations of the OTA-BOUN and TR-BOUN treebanks) on both historical (OTA-BOUN) and modern (TR-BOUN) Turkish datasets. The table includes metrics such as unlabeled attachment score (UAS), labeled attachment score (LAS), and Universal Part-of-Speech (UPOS) F1-score, providing a comprehensive evaluation of the models' ability to accurately identify dependency relations and POS tags in both historical and modern Turkish text.", "section": "5.2 Dependency Parsing and POS Tagging Experiments"}]