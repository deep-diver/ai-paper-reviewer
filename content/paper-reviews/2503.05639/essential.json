{"importance": "This paper introduces VideoPainter, an innovative approach to video inpainting and editing. It will be important as it **reduces the difficulties to restores corrupted video and edit videos with user-customized control**. It also provides a large-scale dataset for future research.", "summary": "VideoPainter:  Edit any video, any length, with user-guided instructions!", "takeaways": ["VideoPainter, a dual-branch framework, enables text-guided video inpainting and editing with plug-and-play context control.", "A lightweight context encoder and inpainting region ID resampling technique ensures efficient background control and ID consistency in videos of any length.", "VPData and VPBench, the largest video inpainting datasets with segmentation masks and dense captions, are introduced to support large-scale training and evaluation."], "tldr": "Video inpainting aims to restore corrupted video, but current methods struggle with generating fully masked objects, preserving background, and maintaining ID consistency in long videos. Existing approaches have limitations with limited pixel propagation or difficulties in balancing background preservation and foreground generation. \n\nTo address these issues, VideoPainter, an efficient dual-branch framework with a lightweight context encoder is proposed. This approach processes masked videos and injects background guidance into any pre-trained video diffusion transformer. A strategy to resample inpainting regions is also introduced for ID consistency in videos of any length. They also constructed VPData and VPBench: the largest video inpainting dataset.", "affiliation": "Chinese University of Hong Kong", "categories": {"main_category": "Computer Vision", "sub_category": "Video Understanding"}, "podcast_path": "2503.05639/podcast.wav"}