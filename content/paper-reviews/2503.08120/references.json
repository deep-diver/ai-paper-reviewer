{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper is important as it is cited multiple times and served as inspiration for the VQA task in the UniFace paper."}, {"fullname_first_author": "Aaron Lou", "paper_title": "Discrete diffusion modeling by estimating the ratios of the data distribution", "publication_date": "2023-10-01", "reason": "This paper is important as it provides the foundation for discrete diffusion models used in the UniFace approach."}, {"fullname_first_author": "Jinheng Xie", "paper_title": "Show-o: One single transformer to unify multimodal understanding and generation", "publication_date": "2024-08-01", "reason": "This paper is important, cited in the introduction and methodology, provides a framework for unified multimodal understanding and generation that UniFace builds upon."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important because it introduces CLIP, which is used in UniFace for image embeddings."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper is important because it introduces the Transformer architecture, a foundational component in UniFace and other multimodal models."}]}