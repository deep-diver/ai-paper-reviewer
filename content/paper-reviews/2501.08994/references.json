{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-XX-XX", "reason": "This paper is foundational for transformer-based diffusion models, a key area of the RepVideo research."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-XX-XX", "reason": "This paper is highly influential in text-to-image generation, providing a basis for extending the approach to text-to-video."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-XX-XX", "reason": "This is the seminal work on DDPMs, the foundation of many modern diffusion models including those used in video generation."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-XX-XX", "reason": "This paper presents significant advancements in diffusion models by using the latent space, which are highly relevant to video generation."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2022-XX-XX", "reason": "This paper is among the first successful attempts of text-to-video generation using diffusion models, providing a direct benchmark for RepVideo."}]}