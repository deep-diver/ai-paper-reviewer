{"references": [{"fullname_first_author": "Kunchang Li", "paper_title": "MVBench: A comprehensive multi-modal video understanding benchmark", "publication_date": "2024-01-01", "reason": "This paper introduces MVBench, a comprehensive multi-modal video understanding benchmark used for evaluating the model's capabilities, thus being important for assessing performance."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-03", "reason": "This paper introduces Deepseekmath and is important as it relates to improving reasoning capabilities of language models, which is a key focus of the current study."}, {"fullname_first_author": "Qiying Yu", "paper_title": "Dapo: An open-source llm reinforcement learning system at scale", "publication_date": "2025-03-18", "reason": "This paper presents DAPO, an open-source LLM reinforcement learning system, relevant to the current study's use of reinforcement learning to enhance model reasoning."}, {"fullname_first_author": "Xingjian Zhang", "paper_title": "Tinyllava-video: A simple framework of small-scale large multimodal models for video understanding", "publication_date": "2025-01-15", "reason": "This paper describes TinyLLaVA-Video, the base model that the current study builds upon, making it fundamentally important to the research."}, {"fullname_first_author": "Kaituo Feng", "paper_title": "Video-r1: Reinforcing video reasoning in mllms", "publication_date": "2025-03-21", "reason": "This paper focuses on reinforcing video reasoning in multimodal language models (MLLMs), a goal very similar to the focus of this document"}]}