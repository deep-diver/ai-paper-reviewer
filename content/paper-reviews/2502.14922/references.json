{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This paper is foundational as it introduces Chain-of-Thought prompting, which guides models in stepwise reasoning, significantly improving reasoning capabilities."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "publication_date": "2023-01-01", "reason": "This paper builds upon Chain-of-Thought prompting by introducing self-consistency, where aggregating answers from multiple reasoning paths further enhances accuracy."}, {"fullname_first_author": "Hyung Won Chung", "paper_title": "Scaling instruction-finetuned language models", "publication_date": "2022-01-01", "reason": "This paper discusses scaling instruction-finetuned language models and demonstrates its contribution to advanced reasoning capabilities in LLMs."}, {"fullname_first_author": "Shunyu Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "publication_date": "2023-01-01", "reason": "This paper introduces the Tree of Thoughts approach, which expands upon Chain-of-Thought by allowing models to explore multiple reasoning paths and backtrack, improving complex problem-solving."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-01-01", "reason": "This paper uses training verifiers for math word problems, and provides valuable mathematical contexts with a focus on verification and problem-solving."}]}