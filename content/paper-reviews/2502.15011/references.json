{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-03-05", "reason": "CLIP is a seminal work that popularized contrastive learning for aligning image and text embeddings, providing a foundation for cross-modal understanding."}, {"fullname_first_author": "Rohit Girdhar", "paper_title": "ImageBind: One embedding space to bind them all", "publication_date": "2023-06-19", "reason": "ImageBind extended the CLIP framework to align six modalities into one joint space, greatly contributing to multi-modal learning and is directly built upon by ULIP in the 3D domain"}, {"fullname_first_author": "Le Xue", "paper_title": "ULIP: Learning unified representation of language, image and point cloud for 3d understanding", "publication_date": "2022-12-12", "reason": "ULIP is a key reference because it directly addresses multi-modal alignment in 3D, learning unified representations among images, text, and point clouds, a focus that is very relevant to CrossOver."}, {"fullname_first_author": "Angela Dai", "paper_title": "ScanNet: Richly-annotated 3d reconstructions of indoor scenes", "publication_date": "2017-01-01", "reason": "ScanNet is a crucial dataset, as CrossOver is evaluated on it and it provides comprehensive data including RGB-D videos, surface reconstructions, and instance-level semantic segmentation."}, {"fullname_first_author": "Timoth\u00e9e Darcet", "paper_title": "Vision transformers need registers", "publication_date": "2023-01-01", "reason": "DINOv2 is a key component in CrossOver as a pre-trained encoder, and is used for processing images, and its tokens for feature extraction, and also utilized for both RGB images and floorplans."}]}