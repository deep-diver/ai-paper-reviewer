---
title: "Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning"
summary: "Genius: A novel, unsupervised self-training framework to advance LLM reasoning without external supervision. Revolutionizing reasoning scaling laws!"
categories: ["AI Generated", "🤗 Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "🏢 Shanghai AI Lab",]
showSummary: true
date: 2025-04-11
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2504.08672 {{< /keyword >}}
{{< keyword icon="writer" >}} Fangzhi Xu et el. {{< /keyword >}}
 
{{< keyword >}} 🤗 2025-04-16 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2504.08672" target="_self" >}}
↗ arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2504.08672" target="_self" >}}
↗ Hugging Face
{{< /button >}}



<audio controls>
    <source src="https://ai-paper-reviewer.com/2504.08672/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

Current methods to enhance LLM reasoning rely heavily on supervision and auxiliary reward models. This creates scalability issues and high annotation costs. The issue motivates the need to improve LLM reasoning without external supervision. Prior attempts focus on response level rewards, overlooking the benefits of stepwise supervision. They also lack global adherence to overarching goals, or are time-consuming. 



The paper introduces **Genius, a generalizable unsupervised self-training framework**. Genius seeks the optimal response sequence stepwise and optimizes the LLM without external aids. It samples & estimates step value with stepwise foresight re-sampling. It also uses an advantage-calibrated optimization loss to mitigate inconsistencies. With 25K unsupervised queries, Genius boosts performance across reasoning benchmarks.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} Genius, a new self-training framework, enhances LLM reasoning without external supervision by stepwise foresight re-sampling and advantage-calibrated optimization. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} The stepwise foresight re-sampling strategy simulates future outcomes to estimate step value and optimize the LLM's response sequence. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Genius improves average performance across diverse reasoning benchmarks by >7% with only 25K unsupervised general queries. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This research is important because it **introduces a novel, unsupervised self-training framework for LLMs**, addressing the critical need to enhance reasoning abilities without relying on expensive and limited supervised data. The findings present **promising avenues for scaling LLM reasoning abilities**.

------
#### Visual Insights



![](https://arxiv.org/html/2504.08672/x1.png)

> 🔼 Figure 1 illustrates different approaches to enhance Large Language Model (LLM) reasoning abilities.  (a) and (b) represent supervised reinforcement learning methods. (a) uses the final answer as a supervisory signal, while (b) employs a verification process.  Both require either ground truth data or an external reward model. (c) showcases the unsupervised self-training method proposed in the paper. It only uses input queries and LLM-generated multi-step responses to optimize the LLM without any external supervision or labeled data.  In all three cases, 'x' represents the input query, 'a' represents the multi-step response generated by the LLM, and 'y' (where applicable) represents the correct final answer.
> <details>
> <summary>read the caption</summary>
> Figure 1: Typical reinforce-like approaches to boost LLM reasoning. (a) and (b) abstract two types of reinforce-like methods, which require final answer and verification respectively. (c) depicts the ultimate goal of our research. x𝑥xitalic_x denotes the input query, a𝑎aitalic_a denotes the LLM-generated responses that contain multiple steps, and y𝑦yitalic_y is the final answer (if exists).
> </details>





{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Models</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">GSM8K</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">MATH</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1">ReClor</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.5.1">LogiQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.6.1">StrategyQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.7.1">GPQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.8.1">ARC-c</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.9.1">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.2.1">LLaMA3.1-8B-Instruct (CoT)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2">70.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.3">30.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.4">49.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.5">33.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.6">58.91</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.7">26.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.2.8">78.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.9">49.65</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S3.T1.1.1.3.1" style="background-color:#DFDFDF;"><span class="ltx_text" id="S3.T1.1.1.3.1.1" style="background-color:#DFDFDF;">Self-Training from <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.3.1.1.1" style="background-color:#DFDFDF;">Magpie (25K)</span></span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.4.1"><em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.4.1.1">w/ Supervision</em></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.3"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.4"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.5"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.6"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.7"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.8"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.4.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.5.1">   SFT</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.2">71.72</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.3">26.27</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4">52.80</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.5">37.78</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.6">57.34</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.7">26.79</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.8">74.06</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.9">49.54</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.6.1">   SPIN <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib7" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.2">74.91</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.3">31.49</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.6.4.1">57.40</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5">40.09</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.6.6.1">71.35</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.6.7.1">29.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.6.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.6.8.1">83.96</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.6.9.1">55.59</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.7.1"><em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.7.1.1">w/o Supervision</em></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.3"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.4"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.5"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.6"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.7"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.8"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.7.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.8.1">   STaR <cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib60" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.2">72.86</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.3">29.32</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.4">46.40</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.5">35.94</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.6">33.36</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7">20.31</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.8.8">67.24</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.9">43.63</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.9.1">   CoH <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib31" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.2">74.37</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.9.3.1">32.29</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.4">56.20</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.5">38.56</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.6">69.08</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.7">28.13</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.9.8">82.51</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.9">54.45</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.10.1">   Self-Rewarding <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib58" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.10.2.1">76.04</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.3">30.19</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.4">55.80</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.5">37.94</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.6">70.48</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.7">28.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.10.8">82.17</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.9">54.42</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.11.1">   ScPO <cite class="ltx_cite ltx_citemacro_cite">Prasad et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib35" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.2">71.11</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.3">30.99</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.4">55.00</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.11.5.1">40.40</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.6">59.87</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.7">28.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.11.8">78.92</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.9">52.12</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.12">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.12.1">   <span class="ltx_text ltx_font_slanted" id="S3.T1.1.1.12.1.1">Genius</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.2.1">78.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.3.1">34.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.4.1">58.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.5.1">40.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.6.1">72.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.7.1">30.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.12.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.8.1">84.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.12.9"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.12.9.1">57.08</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.13">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S3.T1.1.1.13.1" style="background-color:#DFDFDF;"><span class="ltx_text" id="S3.T1.1.1.13.1.1" style="background-color:#DFDFDF;">Self-Training from <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.13.1.1.1" style="background-color:#DFDFDF;">OpenHermes2.5 (32K)</span></span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.14">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.14.1"><em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.14.1.1">w/ Supervision</em></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.3"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.4"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.5"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.6"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.7"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.8"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.14.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.15.1">   SFT</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.2">63.68</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.3">21.64</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.4">45.00</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.5">29.03</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.6">48.47</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.7">23.44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.15.8">69.37</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.15.9">42.95</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.16.1">   SPIN <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib7" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.2">63.61</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.3">24.74</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.4">54.00</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.5">35.33</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.6">59.00</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.7">28.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.16.8">71.76</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.16.9">48.14</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.17">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.17.1"><em class="ltx_emph ltx_font_italic" id="S3.T1.1.1.17.1.1">w/o Supervision</em></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.2"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.3"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.4"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.5"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.6"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.7"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.8"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.1.1.17.9"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.18.1">   STaR <cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib60" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.18.2.1">75.51</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.3">29.47</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.4">43.60</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.5">34.87</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.6">19.34</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.7">22.99</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.18.8">68.43</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.18.9">42.03</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.19.1">   CoH <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib31" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.2">74.29</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.3">31.22</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.4">54.80</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.5">38.40</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.19.6.1">69.91</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.7">29.69</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.19.8">81.48</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.19.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.19.9.1">54.26</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.20">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.20.1">   Self-Rewarding <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib58" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.2">73.92</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.3">29.99</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.20.4.1">56.00</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.5">39.78</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.6">67.55</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.20.7.1">30.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.20.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.20.8.1">81.66</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.20.9">54.15</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.1.1.21.1">   ScPO <cite class="ltx_cite ltx_citemacro_cite">Prasad et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib35" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.2">73.54</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.21.3.1">31.27</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.4">54.80</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.1.21.5.1">41.01</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.6">58.65</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.7">28.79</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.21.8">79.52</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.21.9">52.51</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.22">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.22.1">   <span class="ltx_text ltx_font_slanted" id="S3.T1.1.1.22.1.1">Genius</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.2.1">75.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.3.1">34.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.4.1">57.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.5.1">41.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.6.1">70.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.7"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.7.1">34.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.1.22.8"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.8.1">83.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.22.9"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.22.9.1">56.90</span></td>
</tr>
</table>{{< /table-caption >}}

> 🔼 This table presents the main results of the Genius model's performance on various reasoning benchmarks.  It compares Genius against several baseline models, both those using supervised fine-tuning and those relying on unsupervised self-training. Results are shown separately for models trained on two different datasets: Magpie and OpenHermes2.5.  The optimal performance for each benchmark is highlighted in bold, and near-optimal results are underlined, facilitating easy comparison and identification of the most effective approaches.
> <details>
> <summary>read the caption</summary>
> Table 1: Main Results. The self-training performances from Mappie and OpenHermes2.5 corpora are reported independently. The optimal results are in bold and the suboptimal ones are underlined.
> </details>





### In-depth insights


#### Unsupervised LLM
The concept of an "Unsupervised LLM" is intriguing, hinting at a model trained without explicit labels or human guidance. **This represents a paradigm shift**, moving away from supervised learning's dependency on annotated data. Such a model would ideally learn directly from raw text, potentially **uncovering hidden patterns and relationships** within the data. The major challenge lies in designing effective training objectives that implicitly guide the model towards useful representations and reasoning abilities. Approaches might include clever pretext tasks, self-consistency objectives, or techniques that **exploit the inherent structure of language**. Success in this area could unlock significant scalability and reduce the costs associated with data annotation, allowing LLMs to leverage the vast amounts of unlabeled text available. Ultimately, an unsupervised LLM could demonstrate a deeper understanding of language, less constrained by human biases present in labeled datasets.

#### Foresight Sampling
**Foresight sampling is a strategy designed to look ahead during the decision-making process.** Instead of relying solely on immediate rewards or evaluations, it involves simulating potential future outcomes to inform the selection of the best course of action. By considering the downstream effects of each step, the system can make more informed choices that lead to better overall results. This approach often involves using a model to predict future states or outcomes, allowing the agent to estimate the long-term value of different actions. **It helps to overcome the limitations of purely reactive or short-sighted decision-making,** enabling the agent to pursue goals that require planning and anticipation. However, foresight sampling also presents challenges, such as the computational cost of simulating multiple futures and the uncertainty associated with predicting distant outcomes. Balancing the depth and breadth of the foresight horizon is crucial for achieving effective decision-making without excessive computational burden. It also relies on a good model that can predict outcomes.

#### ACO Optimization
Advantage-Calibrated Optimization (ACO) is presented in this paper as a method for robustly fine-tuning LLMs within a self-training framework. The **core idea behind ACO is to address the inherent noise and uncertainty** introduced during unsupervised learning. Traditional methods often overlook the varying quality of self-generated data, treating all training pairs equally. ACO tackles this by weighting the self-reward signal using an advantage-calibrated loss function. This function **penalizes inconsistent estimations between foresight scores and actual step advantages**, focusing the optimization process on more reliable data points. By incorporating the advantage-calibration term, ACO helps to stabilize training and improve the overall performance of the LLM, mitigating the impact of noisy or misleading self-generated data. The calibration term provides an **adaptive tuning of relaxation to the negative pairs**, providing a more efficient optimization. 

#### Scaling Potential
The scaling potential of this approach is significant. **Self-supervised learning eliminates reliance on labeled data**, the bottleneck for scaling many AI systems. The availability of unlabeled text is practically limitless, meaning performance gains could continue for a long time. However, there are still challenges. **The quality of the self-generated data is critical**. Noise and biases in the data could limit performance or even hurt it. Secondly, **optimization challenges may emerge at larger scales**. Training instability and reward hacking become more likely as model complexity increases. Thirdly, **evaluating performance and progress is harder without labeled data**. Metrics need to accurately reflect real-world reasoning, or training may optimize for superficial features. Despite these challenges, the potential upside of scaling self-supervised reasoning is substantial, warranting further research.

#### General Queries
When exploring "general queries" in the context of self-improving language models, it's crucial to acknowledge their inherent **diversity and ubiquity**. Unlike specialized datasets tailored for specific tasks, general queries encompass a broad spectrum of topics, styles, and complexities, mirroring the open-ended nature of real-world interactions. The **availability of large, unlabeled datasets** of general queries presents a significant advantage for unsupervised learning approaches, potentially circumventing the need for costly and time-consuming annotation efforts. However, effectively harnessing general queries requires careful consideration of several challenges. One such challenge is the **presence of noise and ambiguity**, as general queries may lack the precise structure or context found in curated datasets. Another key consideration is the **potential for bias** within general query datasets, reflecting the biases present in the data sources from which they are derived. Successfully navigating these challenges would unlock significant opportunities for scaling language model reasoning abilities in a resource-efficient and generalizable manner, **bridging the gap** between specialized training and real-world application.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2504.08672/x2.png)

> 🔼 The Genius framework is a purely unsupervised self-training method for enhancing Large Language Model (LLM) reasoning abilities.  It begins with unsupervised natural language (NL) queries as input. The LLM generates responses in a step-wise manner, where each step's quality is assessed using a 'foresight' mechanism that simulates future steps to estimate its value. Steps are sampled and re-sampled using a strategy balancing exploration and exploitation. High-quality response sequences are selected for training.  A novel Advantage-Calibrated Optimization (ACO) loss function is used to train the LLM, improving robustness by mitigating the noise inherent in unsupervised learning. This iterative process of sampling, rewarding, and training allows the LLM to continuously improve its reasoning capabilities without relying on external supervision.
> <details>
> <summary>read the caption</summary>
> Figure 2: The overall framework of Genius. It only receives the unsupervised NL queries as inputs. To complete goal of self-improving, the policy LLM goes through K𝐾Kitalic_K steps of sampling and rewarding for each query (Step 1-4), collects the high-quality response sequence as the training data (Step 5), and trains itself with the advantage calibrated optimization loss (Step 6).
> </details>



![](https://arxiv.org/html/2504.08672/x3.png)

> 🔼 This figure visualizes the advantage-calibrated function (ACO) used in the Genius framework.  The x-axis represents the difference in advantage values between a negative response (A<sub>l</sub>) and a positive response (A<sub>w</sub>).  The y-axis shows the value of the calibration term ω(x, A) from Equation (11) in the paper, which adjusts the reward assigned to negative responses based on the difference in advantage. The parameter α controls the curve's steepness; larger α values lead to sharper transitions between regions where negative responses are given different weights.  This function ensures robustness in the self-training process by mitigating noisy estimations from the unsupervised setting.  The curve is divided into two regions: the normal region, where the difference in advantage is not substantial, and the calibration region where negative samples receive an adjusted weight.
> <details>
> <summary>read the caption</summary>
> Figure 3: Visualization of the calibration function. The x-axis denotes the the differences between Alsubscript𝐴𝑙A_{l}italic_A start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT and Awsubscript𝐴𝑤A_{w}italic_A start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT, while the y-axis is the value of the calibration term. By adjusting α𝛼\alphaitalic_α, we can control the decay rate of the curve.
> </details>



![](https://arxiv.org/html/2504.08672/x4.png)

> 🔼 The bar chart visualizes the average performance gains across seven benchmark tasks achieved by various LLMs, including Genius, when using Qwen2.5-3B-Instruct as the base LLM.  The comparison highlights Genius's superior performance improvement compared to other methods such as SPIN, CoH, Self-Rewarding, and SCPO.
> <details>
> <summary>read the caption</summary>
> (a) Base LLM: Qwen2.5-3B-Instruct
> </details>



![](https://arxiv.org/html/2504.08672/x5.png)

> 🔼 This figure shows the average performance gains across seven reasoning benchmarks for the Qwen2.5-7B-Instruct large language model after applying different post-training methods, including Genius, Self-Rewarding, ScPO, CoH, SPIN, and SFT.  It showcases how Genius significantly outperforms other methods, demonstrating its effectiveness in enhancing reasoning capabilities via unsupervised self-training.
> <details>
> <summary>read the caption</summary>
> (b) Base LLM: Qwen2.5-7B-Instruct
> </details>



![](https://arxiv.org/html/2504.08672/x6.png)

> 🔼 This figure demonstrates the generalization capabilities of the Genius framework when applied to different Large Language Models (LLMs).  Specifically, it shows the performance improvement achieved by Genius when fine-tuned on the OpenHermes2.5 dataset and then evaluated on various reasoning tasks using the Qwen-2.5-3B and Qwen-2.5-7B models. The bar graphs compare the average performance gains (relative to the baseline models) achieved by Genius and several other post-training methods. This illustrates Genius's ability to enhance various LLMs consistently.
> <details>
> <summary>read the caption</summary>
> Figure 4: Generalization to Qwen2.5 series models. All methods are trained on the OpenHermes2.5 split. The numbers above the bars represent the average performance gain relative to the base model.
> </details>



![](https://arxiv.org/html/2504.08672/x7.png)

> 🔼 Figure 5 presents the results of the AIME 2024 competition-level benchmark.  It compares the performance of the base LLaMA3.1-8B-Instruct model with the Genius model (trained using the OpenHermes2.5 dataset).  The bar chart visually displays the Pass@1 score achieved by each model on the AIME 2024 dataset. This demonstrates Genius's ability to improve upon the base LLM's performance even in challenging, complex reasoning scenarios.
> <details>
> <summary>read the caption</summary>
> Figure 5: Results on AIME 2024.
> </details>



![](https://arxiv.org/html/2504.08672/x8.png)

> 🔼 This figure displays the results of the post-training scaling law experiment using the LLaMA3.1-8B-Instruct model as a base.  It shows how the average performance across multiple reasoning benchmarks improves as the number of training steps increases.  The graph illustrates the effect of increasing training data on model performance, highlighting the potential for continued improvement with more training.
> <details>
> <summary>read the caption</summary>
> Figure 6: Post-training scaling law with LLaMA3.1-8B-Instruct as the base LLM.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">Models</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S3.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1">Subjective Benchmarks</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.3.1">Objective Benchmarks</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.1.1">AlpacaEval</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.2.1">WildBench</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.3.1">Arena-H</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.4.1">WikiBench</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.5.1">MMLU</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.2.6.1">MMLU-Pro</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.1.1.3.1">LLaMA3.1-8B-Instruct</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.2">24.60</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.3">-1.11</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.3.4">30.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.5">27.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.6">71.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.7">48.62</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T2.1.1.4.1">
<span class="ltx_text ltx_font_bold ltx_font_slanted" id="S3.T2.1.1.4.1.1">Genius</span> [From Magpie (25K)]</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.4.2.1">26.96</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.4.3.1">2.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.1.4.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.4.4.1">50.00</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.4.5.1">28.75</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.6">71.86</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.7">48.44</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.T2.1.1.5.1">
<span class="ltx_text ltx_font_bold ltx_font_slanted" id="S3.T2.1.1.5.1.1">Genius</span> [From OpenHermes (32K)]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.5.2">25.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.5.3">1.44</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.1.1.5.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.4.1">50.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.5.5">27.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.5.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.6.1">72.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.5.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.5.7.1">49.19</span></td>
</tr>
</table>{{< /table-caption >}}
> 🔼 This table presents the performance of different LLMs on various general-domain benchmarks.  The benchmarks are categorized into subjective and objective evaluations. Subjective benchmarks assess the quality of generated text, while objective benchmarks test factual knowledge and reasoning abilities.  It shows the base LLM performance and how it changes after training with the Genius model using different training data (Magpie and OpenHermes). This allows for comparison of model performance before and after self-training on various general language tasks, not just reasoning-intensive tasks.
> <details>
> <summary>read the caption</summary>
> Table 2: Performances on benchmarks in the general domain.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S4.T3.1.1">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.2.1">Variants</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.3.1">GSM8K</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.4.1">MATH</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.5.1">ReClor</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.6.1">LogiQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.7.1">StrategyQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.8.1">GPQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.9.1">ARC-c</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.10.1">Avg.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.1.1"><math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.1.m1.1.1" mathvariant="normal" xref="S4.T3.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">roman_Δ</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S4.T3.1.1.2.1" style="background-color:#DFDFDF;"><span class="ltx_text" id="S4.T3.1.1.2.1.1" style="background-color:#DFDFDF;">Self-Training from <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.1.1" style="background-color:#DFDFDF;">Magpie (25K)</span></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.1.1.3.1"><span class="ltx_text ltx_font_slanted" id="S4.T3.1.1.3.1.1">Genius</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.1">78.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.3.1">34.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.4.1">58.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.5.1">40.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.6.1">72.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.7.1">30.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.3.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.8.1">84.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.9.1">57.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.10">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.1.1.4.1">   w/o <em class="ltx_emph ltx_font_italic" id="S4.T3.1.1.4.1.1">foresight</em>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.2">71.65</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3">31.07</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.4">57.60</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.5">39.17</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.6">66.20</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.7">30.13</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.4.8">81.57</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.9">53.91</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.10"><span class="ltx_text" id="S4.T3.1.1.4.10.1" style="color:#008000;">+3.17</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.1.1.5.1">   w/o <em class="ltx_emph ltx_font_italic" id="S4.T3.1.1.5.1.1">sampling</em>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.2">69.29</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.3">31.37</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4">57.60</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.5">39.17</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.6">68.03</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.7">24.33</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.5.8">81.06</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.9">52.98</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.10"><span class="ltx_text" id="S4.T3.1.1.5.10.1" style="color:#008000;">+4.10</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.6">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S4.T3.1.1.6.1" style="background-color:#DFDFDF;"><span class="ltx_text" id="S4.T3.1.1.6.1.1" style="background-color:#DFDFDF;">Self-Training from <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.6.1.1.1" style="background-color:#DFDFDF;">OpenHermes2.5 (32K)</span></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.1.1.7.1"><span class="ltx_text ltx_font_slanted" id="S4.T3.1.1.7.1.1">Genius</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.2.1">75.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.3.1">34.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.4.1">57.60</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.5.1">41.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.1">70.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.7.1">34.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.7.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.8.1">83.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.9.1">56.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.10">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.1.1.8.1">   w/o <em class="ltx_emph ltx_font_italic" id="S4.T3.1.1.8.1.1">foresight</em>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.2">73.01</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.3">30.74</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.4">57.60</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.5">35.94</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.6">67.25</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7">29.46</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.8.8">81.57</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.9">53.65</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.10"><span class="ltx_text" id="S4.T3.1.1.8.10.1" style="color:#008000;">+3.25</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.9">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T3.1.1.9.1">   w/o <em class="ltx_emph ltx_font_italic" id="S4.T3.1.1.9.1.1">sampling</em>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.2">72.93</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.3">30.59</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.4">56.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.5">41.17</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.6">65.76</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.7">30.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.1.1.9.8">80.03</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.9">53.80</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.10"><span class="ltx_text" id="S4.T3.1.1.9.10.1" style="color:#008000;">+3.10</span></td>
</tr>
</table>{{< /table-caption >}}
> 🔼 This table presents the results of ablation experiments on the sampling strategy used in the Genius framework.  The baseline is the full Genius model.  The ''w/o foresight'' row shows the performance when the model doesn't simulate future steps to estimate their value (foresight score) before selecting the next step; instead it just samples from the step uncertainty. The ''w/o sampling'' row shows the performance when the model uses a greedy approach: selecting the top 2 highest-scoring steps for exploration and the lowest-scoring step as the negative sample, rather than using the re-sampling strategy from the foresight score distribution. The table shows performance drops in all metrics for both ablation experiments, highlighting the importance of both foresight and re-sampling.
> <details>
> <summary>read the caption</summary>
> Table 3: Ablation studies on the sampling strategy. w/o foresight ablates the look-ahead process and simply samples from the distribution formed by step uncertainty. w/o sampling indicates that we adopt a greedy approach by selecting the two steps with the highest foresight score for exploration, while the step with the lowest foresight score serves as the negative response for exploitation.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S4.T4.1.1">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T4.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1.1">Models</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.2.1">Average Performances</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.2">
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.2.1">Magpie</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.2.2">OpenHermes</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.1.1.3.1">LLaMA3.1-8B-Instruct (CoT)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.2">49.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3">49.65</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.4">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T4.1.1.4.1" style="background-color:#DFDFDF;"><span class="ltx_text" id="S4.T4.1.1.4.1.1" style="background-color:#DFDFDF;">w/ Foresight Sampling</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T4.1.1.5.1">+ <span class="ltx_text ltx_font_bold" id="S4.T4.1.1.5.1.1">ACO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.5.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.5.2.1">57.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.5.3"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.5.3.1">56.90</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.1.1.6.1">+ DPO <cite class="ltx_cite ltx_citemacro_cite">Rafailov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib37" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.6.2">55.51</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.6.3">55.73</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.1.1.7.1">+ SimPO <cite class="ltx_cite ltx_citemacro_cite">Meng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib34" title="">2025</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.7.2">50.42</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.7.3">50.87</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.1.1.8.1">+ IPO <cite class="ltx_cite ltx_citemacro_cite">Azar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib4" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.8.2">52.31</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.8.3">52.20</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T4.1.1.9.1">+ ROPO <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.08672v1#bib.bib28" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.9.2">55.30</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.9.3">55.25</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.10">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T4.1.1.10.1">+ SFT</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.1.1.10.2">44.63</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.1.1.10.3">49.70</td>
</tr>
</table>{{< /table-caption >}}
> 🔼 This table compares the performance of different reinforcement learning loss functions used in the Genius framework for self-improving LLMs.  The experiment setup is controlled to isolate the effect of the loss function by maintaining the foresight sampling strategy unchanged across all comparisons.  This allows for a direct comparison of the effectiveness of each loss function in optimizing the LLM's reasoning abilities.
> <details>
> <summary>read the caption</summary>
> Table 4: Comparison of different reinforced loss. In the experiments, we only replace the optimization methods while keep the foresight sampling strategy unchanged.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A3.T5.1.1">
<tr class="ltx_tr" id="A3.T5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A3.T5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.1.1.1.1.1">Task</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T5.1.1.1.2.1">w/ Self</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T5.1.1.1.3.1">w/ Magpie</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T5.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A3.T5.1.1.1.4.1">w/ OpenHermes</span></td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T5.1.1.2.1">GSM8K</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.2.2">0.3967</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.2.3">0.1343</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.2.4">0.1256</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.1.1.3.1">MATH</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.3.2">0.1641</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.3.3">0.0908</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.3.4">0.0719</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.1.1.4.1">GPQA</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.4.2">0.1907</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.4.3">0.0566</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.4.4">0.0602</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.1.1.5.1">ReClor</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.5.2">0.2609</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.5.3">0.0552</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.5.4">0.0792</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.1.1.6.1">LogiQA</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.6.2">0.2330</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.6.3">0.0732</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.6.4">0.0930</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.1.1.7.1">StrategyQA</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.7.2">0.1186</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.7.3">-0.0045</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.1.7.4">0.0025</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="A3.T5.1.1.8.1">ARC-c</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.8.2">0.2276</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.8.3">0.0673</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.8.4">0.0843</td>
</tr>
</table>{{< /table-caption >}}
> 🔼 This table presents a comparison of distances between different datasets.  Specifically, it shows the cosine similarity between different sets of queries.  'w/ Self' represents the average similarity between queries within the same task. 'w/ Magpie' shows the average similarity between queries in a given task and the Magpie training corpus. 'w/ OpenHermes' shows the average similarity between the queries in a given task and the OpenHermes2.5 training corpus. Lower values indicate greater dissimilarity, suggesting a wider gap between the training data and the evaluation tasks.
> <details>
> <summary>read the caption</summary>
> Table 5: Comparison between intra- and inter-class distance. w/ Self denotes the distance within the task queries. w/ Magpie means the distance between the target task with Magpie training corpus, while w/ OpenHermes denotes the distance between the target task with OpenHermes2.5 training corpus.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A4.T6.1.1">
<tr class="ltx_tr" id="A4.T6.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A4.T6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A4.T6.1.1.1.1.1">Models</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A4.T6.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A4.T6.1.1.1.2.1">MBPP</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A4.T6.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A4.T6.1.1.1.3.1">LiveCodeBench</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A4.T6.1.1.2.1">LLaMA3.1-8B-Instruct</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.1.1.2.2">69.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T6.1.1.2.3">19.50</td>
</tr>
<tr class="ltx_tr" id="A4.T6.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.1.1.3.1">
<span class="ltx_text ltx_font_bold ltx_font_slanted" id="A4.T6.1.1.3.1.1">Genius</span> [From Magpie]</td>
<td class="ltx_td ltx_align_center" id="A4.T6.1.1.3.2">71.60</td>
<td class="ltx_td ltx_align_center" id="A4.T6.1.1.3.3">19.75</td>
</tr>
<tr class="ltx_tr" id="A4.T6.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="A4.T6.1.1.4.1">
<span class="ltx_text ltx_font_bold ltx_font_slanted" id="A4.T6.1.1.4.1.1">Genius</span> [From OpenHermes]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.1.1.4.2">71.98</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T6.1.1.4.3">21.25</td>
</tr>
</table>{{< /table-caption >}}
> 🔼 Table 6 presents the results of experiments conducted on coding-related benchmarks to evaluate the effectiveness of the Genius self-training framework.  It specifically shows the performance of the base LLaMA3.1-8B-Instruct model and the same model after self-training with Genius using two different datasets: Magpie and OpenHermes. The benchmarks used are MBPP (Mathematical Programming Problem Benchmark) and LiveCodeBench, both measuring code generation and understanding capabilities. This allows for a comparison of the improvements achieved by the Genius framework on coding tasks, analogous to its evaluation on natural language reasoning tasks shown in earlier tables.
> <details>
> <summary>read the caption</summary>
> Table 6: Experiments on coding tasks.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/2504.08672/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08672/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}