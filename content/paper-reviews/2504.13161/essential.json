{"importance": "This paper introduces an innovative approach to optimizing data mixtures, paving the way for developing more efficient and specialized language models. By automating the data mixture refinement process, this research reduces reliance on manual curation and opens up new avenues for efficient pre-training and domain adaptation.", "summary": "CLIMB: An automated data mixture bootstrapping framework for language model pre-training via clustering.", "takeaways": ["CLIMB: A novel framework for automated data mixture optimization during pre-training.", "CLIMB iteratively refines data mixtures, optimizing for both diversity and domain relevance.", "CLIMB achieves state-of-the-art performance with a 1B model, surpassing Llama-3.2-1B by 2.0%."], "tldr": "Pre-training datasets for LLMs often lack inherent domain divisions, making it challenging to identify an optimal data mixture. Datasets like Common Crawl don't include explicit domain labels, while curated datasets are labor-intensive. Existing methods struggle to balance general knowledge with domain expertise, leading to inefficient use of high-value data. Optimizing data mixtures for both general and domain-specific tasks remains a challenge because large-scale datasets lack explicit labels. Even with curated datasets, selecting an optimal mixture is non-trivial due to the complex relationship between dataset composition and model performance. \n\nTo address these issues, this paper introduces a novel framework called **CLIMB** (CLustering-based Iterative Data Mixture Bootstrapping). **CLIMB** automates the discovery, evaluation, and refinement of data mixtures in a pre-training setting. It embeds and clusters large-scale datasets in a semantic space and iteratively searches for optimal mixtures using a smaller proxy model and a predictor. **CLIMB** achieves state-of-the-art performance on reasoning tasks and surpasses the state-of-the-art Llama-3.2-1B. The authors also introduces ClimbLab and ClimbMix for data mixing research.", "affiliation": "NVIDIA", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2504.13161/podcast.wav"}