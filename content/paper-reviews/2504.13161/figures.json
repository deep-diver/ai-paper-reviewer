[{"figure_path": "https://arxiv.org/html/2504.13161/x1.png", "caption": "Figure 1: \nPre-training a 1B model on ClimbMix shows better scaling effects than training on other datasets.\nWe measure the average performance on 12 downstream benchmarks.", "description": "The figure illustrates the performance scaling of a 1B parameter language model trained using different datasets, including ClimbMix, ClimbLab, Nemotron-CC-HQ, SmolLM, DCLM-baseline, and FineWeb-Edu.  The x-axis represents the number of training tokens (in billions), and the y-axis shows the average performance across 12 downstream benchmark tasks.  The graph demonstrates that the model trained with ClimbMix exhibits superior performance scaling compared to models trained with other datasets, indicating that ClimbMix is a more efficient dataset for pre-training language models.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.13161/x2.png", "caption": "Figure 2: Given large-scale pre-training data consisting of web-scale and curated sources, CLIMB identifies the optimal mixture of different topics (A, B, C) to improve performance in a target task (e.g., general reasoning). We compare the performance of state-of-the-art language models across different parameter scales on general reasoning benchmarks. CLIMB achieves a better tradeoff between model size and performance, demonstrating a more efficient scaling trend compared to prior models.", "description": "This figure illustrates CLIMB's ability to optimize data mixtures for improved model performance.  It shows how CLIMB selects an optimal combination of web-scale and curated data sources (represented as topics A, B, and C) to enhance performance on a general reasoning task. By comparing CLIMB's performance against state-of-the-art language models across various parameter scales, the figure demonstrates CLIMB's superior efficiency in balancing model size and performance, showcasing a more favorable scaling trend.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.13161/x3.png", "caption": "Figure 3: Visualization of CLIMB\u2019s iterative search process using t-SNE.\nEach point represents a data mixture config in the search space, with different iterations (CLIMB-Iter1, CLIMB-Iter2, CLIMB-Iter3) illustrating how the search space is refined over iterations.\nInitially, the search explores a broad set of configurations (Iter 1), progressively narrowing in subsequent iterations (Iter 2 and Iter 3) as CLIMB selects more optimal mixtures.", "description": "This figure visualizes CLIMB's iterative search for optimal data mixtures using t-SNE dimensionality reduction.  Each point represents a unique data mixture configuration tested by CLIMB, and the color indicates the iteration number (CLIMB-Iter1, CLIMB-Iter2, CLIMB-Iter3). The figure shows how the search space is progressively refined across iterations. Initially, the search is broad, exploring a wide range of data mixtures.  As the algorithm iterates, the search space narrows down, with CLIMB focusing on more promising configurations that yield better performance. This visualization demonstrates the efficiency and effectiveness of CLIMB's iterative search strategy.", "section": "3. CLIMB: CLustering-based Iterative Data Mixture Bootstrapping"}, {"figure_path": "https://arxiv.org/html/2504.13161/x4.png", "caption": "Figure 4: The CLIMB framework overview. Upper section: CLIMB first preprocesses raw data via embedding and clustering it into groups.\nThese clusters serve as the basis for the search space, where a mixture is defined as a set of weights to combine different clusters. Lower section:\nCLIMB samples nksubscript\ud835\udc5b\ud835\udc58n_{k}italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT mixtures in iteration k\ud835\udc58kitalic_k, trains proxy models on a subset of them, and updates a predictor to estimate performance. The predictor prunes mixtures that are likely to perform poorly, so only the most promising mixtures proceed to full proxy training in subsequent iterations. Through progressively refining the search space and eliminating suboptimal candidates, CLIMB converges toward an optimized data mixture and balances general and domain-specific performance without exhaustive manual curation.", "description": "CLIMB is an iterative framework that refines data mixtures for improved language model pre-training.  It begins by embedding and clustering raw data to create a search space of data mixtures represented as weighted combinations of clusters.  Then, in each iteration, CLIMB samples a set of mixtures, trains lightweight proxy models on a subset, and uses a predictor to estimate their performance. Poorly performing mixtures are eliminated, and only the most promising move on to further training. This iterative process refines the search space, leading to an optimized data mixture that balances general and domain-specific performance without manual intervention.", "section": "3. CLIMB: CLustering-based Iterative Data Mixture Bootstrapping"}, {"figure_path": "https://arxiv.org/html/2504.13161/x5.png", "caption": "Figure 5: Performance of target models on MMLU benchmarks for different subject areas.\nFor both 350M and 1B target models, CLIMB used 350M proxy models, whereas CLIMB-Best@N used proxy models of the same size as the target models. CLIMB consistently improves performance across iterations, outperforming CLIMB-Best@N despite using smaller proxy models.", "description": "This figure displays the performance of language models (350M and 1B parameter models) on the MMLU benchmark across three subject domains: STEM, Humanities, and Social Sciences.  The performance is shown for three methods: CLIMB (the authors' method, iteratively refining data mixtures), CLIMB-Best@N (a variation where the proxy model size matches the target model size), and a random baseline.  Importantly, CLIMB consistently uses a smaller 350M parameter proxy model, regardless of target model size.  The results demonstrate that CLIMB's iterative approach yields superior performance compared to CLIMB-Best@N, highlighting its efficiency in discovering optimal data mixtures.", "section": "Experimental Results"}, {"figure_path": "https://arxiv.org/html/2504.13161/x6.png", "caption": "Figure 6: Weight analysis of ClimbMix across iterations.", "description": "This figure visualizes how the weights assigned to different clusters in the ClimbMix dataset evolve across three iterations of the CLIMB algorithm. Each cluster represents a distinct semantic topic or domain within the data. The heatmap shows that certain clusters become increasingly more important (higher weights) as the algorithm progresses, reflecting the algorithm's ability to dynamically refine the data mixture based on its learned impact on downstream task performance. The analysis highlights how the iterative refinement of the data mixture leads to a more focused and effective composition of the pre-training data, thereby improving model performance on target tasks.", "section": "3.2. Iterative Bootstrapping: Mixture Weight Search"}, {"figure_path": "https://arxiv.org/html/2504.13161/x7.png", "caption": "Figure 7: Similarity between clusters and downstream tasks.", "description": "This figure visualizes the cosine similarity between the cluster embeddings and the average embeddings of different downstream tasks.  It shows how closely related different data clusters are to specific downstream tasks, highlighting the relationships between various data sources and their suitability for different applications. This helps understand which clusters are more suitable for specific tasks, providing insights into the composition of optimal data mixtures for improved model performance.", "section": "A.3. Relationship between Clusters and Downstream Tasks"}, {"figure_path": "https://arxiv.org/html/2504.13161/x8.png", "caption": "Figure 8: Heatmap of weights across iterations.", "description": "This figure visualizes how the weights assigned to different data clusters evolve across three iterations of the CLIMB algorithm. Each cell in the heatmap represents the weight of a specific cluster at a given iteration. The color intensity indicates the magnitude of the weight, with darker shades representing higher weights. This visualization helps in understanding how the algorithm refines the data mixture over iterations, focusing on the most informative clusters for the target task.", "section": "3.2. Iterative Bootstrapping: Mixture Weight Search"}, {"figure_path": "https://arxiv.org/html/2504.13161/x9.png", "caption": "Figure 9: The Spearman rank correlation between predicted accuracy made by the predictor model and the groundtruth accuracy.", "description": "This figure displays a scatter plot illustrating the strong correlation between the predicted accuracy scores generated by the predictor model and the actual ground truth accuracy values.  The high Spearman rank correlation (0.94) indicates that the predictor model effectively estimates the performance of different data mixtures. This is a crucial aspect of the CLIMB framework, as the predictor's accuracy guides the iterative refinement of the data mixtures during the bootstrapping process.", "section": "A.7. Effects of Predictor"}]