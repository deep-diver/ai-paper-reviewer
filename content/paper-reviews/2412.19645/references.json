{"references": [{"fullname_first_author": "Aditya Ramesh", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2022-08-01", "reason": "This paper is foundational for the field of text-guided image generation, which is directly relevant to the paper's topic of video generation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-04-01", "reason": "This paper introduces a key technique used in the VideoMaker framework, the use of latent diffusion models for high-quality image generation, directly applied to video."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine-tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-06-01", "reason": "This work is highly relevant to the concept of subject-driven generation, a key aspect addressed by VideoMaker, providing insights into personalization techniques."}, {"fullname_first_author": "Yuchao Gu", "paper_title": "Mix-of-Show: Decentralized low-rank adaptation for multi-concept customization of diffusion models", "publication_date": "2024-01-01", "reason": "This paper focuses on multi-concept customization, a relevant and advanced topic in diffusion model adaptation; the techniques explored here are likely valuable to the presented research."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-10-01", "reason": "This work offers a strong foundation for high-quality video generation, a major goal of VideoMaker, and directly influences the methodology of the work."}]}