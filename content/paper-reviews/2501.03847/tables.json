[{"content": "| Method | Small Movement |  | Large Movement |  | \n|---|---|---|---|---| \n|  | TransErr \u2193 | RotErr \u2193 | TransErr \u2193 | RotErr \u2193 | \n| MotionCtrl | 44.23 | 8.92 | 67.05 | 39.86 | \n| CameraCtrl | 42.31 | 7.82 | 66.76 | 29.70 | \n| Ours | **27.85** | **5.97** | **37.17** | **10.40** | ", "caption": "Table 1. Quantitative results on camera control of MotionCtrl\u00a0(Wang et\u00a0al., 2024c), CameraCtrl\u00a0(He et\u00a0al., 2024b), and our method. \u201cTransErr\u201d and \u201cRotErr\u201d are the angle differences between the estimated translation and rotation and the ground-truth ones in degree.", "description": "This table presents a quantitative comparison of three different methods for camera control in video generation: MotionCtrl (Wang et al., 2024c), CameraCtrl (He et al., 2024b), and the authors' proposed method.  The comparison is based on two metrics: TransErr and RotErr. TransErr measures the angular difference between the estimated translation vector of the camera and the ground truth translation vector, while RotErr measures the angular difference between the estimated rotation (quaternion) and the ground truth rotation.  Smaller values for both metrics indicate better performance.  The results are reported for both small and large camera movements.", "section": "4.1 Camera control"}, {"content": "| Method | Tex-Ali \u2191 | Tem-Con \u2191 |\n|---|---|---|\n| CCEdit | 16.9 | 0.932 |\n| Tokenflow | 31.9 | 0.956 |\n| Ours | **32.6** | **0.971** |", "caption": "Table 2. CLIP scores for motion transfer of CCEdit\u00a0(Feng et\u00a0al., 2024b), TokenFlow\u00a0(Geyer et\u00a0al., 2023b), and our method. \u201cText-Ali\u201d is the semantic CLIP consistency between generated videos and the given text prompts. \u201cTem-Con\u201d is the temporal CLIP consistency between neighboring frames.", "description": "This table presents a quantitative comparison of three different methods for motion transfer in video generation: CCEdit, TokenFlow, and the authors' proposed method.  The comparison is based on two CLIP scores: Text-Ali and Tem-Con.  Text-Ali measures the semantic consistency between the generated videos and the corresponding text prompts used to guide the generation process; a higher score indicates better alignment between the generated video content and the intended meaning of the text prompt. Tem-Con measures the temporal consistency of the generated videos, evaluating how well the video's frames flow smoothly over time; a higher score indicates better temporal coherence. The table allows for a direct comparison of the effectiveness of the three methods in achieving both semantic and temporal consistency in motion transfer.", "section": "4.2 Motion transfer"}, {"content": "| Depth | Tracking | #Tracks | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | FVD \u2193 |\n|---|---|---|---|---|---|---|\n| \u2713 |  | - | 18.08 | 0.573 | 0.312 | 645.1 |\n|  | \u2713 | 900 | 18.52 | 0.586 | 0.337 | 765.3 |\n|  | \u2713 | 2500 | 19.17 | 0.632 | 0.263 | 566.4 |\n|  | \u2713 | 4900 | **19.27** | **0.658** | **0.261** | **551.3** |\n|  | \u2713 | 8100 | 19.11 | 0.649 | 0.262 | 599.0 |", "caption": "Table 3. Analysis of applying different 3D control signals for image to video generation. We evaluate PSNR, SSIM, LPIPS, and FVD of generated videos on the validation set of the DAVIS and MiraData datasets. \u201cDepth\u201d means using depth maps as the 3D control signals. \u201cTracking\u201d means using 3D tracking videos as the control signals. #Tracks means the number of 3D points used in the 3D tracking video.", "description": "This table presents a quantitative comparison of using depth maps versus 3D tracking videos as control signals in an image-to-video generation model.  The evaluation metrics include PSNR, SSIM, LPIPS, and FVD, which measure various aspects of video quality (peak signal-to-noise ratio, structural similarity, learned perceptual image patch similarity, and Fr\u00e9chet video distance, respectively).  The performance is assessed on the validation sets of the DAVIS and MiraData datasets. The table also investigates the impact of varying the number of 3D points used in the 3D tracking video, providing insights into the trade-off between control precision and computational cost. The results highlight the superior performance of 3D tracking videos over depth maps for generating high-quality videos.", "section": "4.5 Analysis"}]