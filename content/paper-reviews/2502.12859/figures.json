[{"figure_path": "https://arxiv.org/html/2502.12859/x1.png", "caption": "Figure 1: This figure shows how small changes in prompts can drastically affect the accuracy of a model. Two examples show the same user question, but the prompts differ by only one word, resulting in different answers. The first prompt achieves 86.27% accuracy across the entire dataset, while the second prompt drops significantly to 66.93%. This highlights how even small modifications can lead to large swings in performance if a model lacks prompt robustness.", "description": "The figure illustrates the impact of minor prompt variations on the accuracy of a large language model (LLM). Two examples of the same question, with slight differences in their prompts, showcase drastically different accuracy rates. One prompt yields 86.27% accuracy, while the other drops to 66.93%, highlighting the vulnerability of LLMs to even small prompt modifications if not robust.", "section": "Preliminaries"}, {"figure_path": "https://arxiv.org/html/2502.12859/x2.png", "caption": "Figure 2: An overview of PAFT: This figure compares Traditional Supervised Fine-tuning (SFT) and Prompt-Agnostic Fine-Tuning (PAFT), highlighting their main differences. SFT relies on a fixed dataset and predefined prompts, which limits its robustness and generalization to different prompts. In contrast, PAFT dynamically selects prompts during training, which improves robustness and generalization to a wide range of prompts. By leveraging a commercial LLM to generate candidate prompts, PAFT provides a more general and scalable solution.", "description": "The figure illustrates the core differences between traditional supervised fine-tuning (SFT) and the proposed Prompt-Agnostic Fine-Tuning (PAFT) method.  SFT uses a fixed dataset with predefined prompts, leading to overfitting and reduced robustness to variations in prompt wording.  In contrast, PAFT employs a dynamic prompt selection strategy during training.  It leverages a commercial LLM to generate a diverse set of candidate prompts, which are then randomly sampled during training. This approach significantly improves the model's robustness and generalizability to unseen prompts, making it more adaptable and scalable.", "section": "4 The PAFT Framework"}, {"figure_path": "https://arxiv.org/html/2502.12859/x3.png", "caption": "Figure 3: This figure presents the results of preliminary experiments conducted on four datasets to evaluate the accuracy of the base model and the SFT model across over 450 diverse prompts. The probability distribution plots illustrate the distribution of accuracy for models. The results show that while the SFT model has an overall improvement in accuracy compared to the base model, the accuracy of some prompts is still relatively low, and the standard deviation of the SFT model is high, indicating that the accuracy varies greatly between different prompts, which highlights the impact of prompt design and the need for further optimization through model fine-tuning.", "description": "This figure displays the results of preliminary experiments comparing the performance of a base language model and a model fine-tuned using supervised fine-tuning (SFT) across four datasets.  Over 450 diverse prompts were used for evaluation.  The results are visualized using probability distribution plots, showing the accuracy distribution for each model. While the SFT model generally performs better, the distributions reveal that even with SFT, the model's accuracy on certain prompts remains low, and the overall variability in accuracy (as shown by high standard deviation) is significant. This indicates substantial sensitivity to prompt design and a need for improved model optimization techniques.", "section": "3 Preliminaries"}, {"figure_path": "https://arxiv.org/html/2502.12859/x4.png", "caption": "Figure 4: The performance of the base model, the SFT model, and the PAFT model is compared on multiple reasoning and reading comprehension tasks. This is a visual comparison to Figure\u00a03 to illustrate the effectiveness of PAFT, where the probability distribution plots show the distribution of accuracy of different models on the test prompts that were not used during PAFT training. The PAFT model shows superior performance compared to the base model and the SFT model, achieving higher accuracy and lower variance in all tasks.", "description": "Figure 4 presents a visual comparison of three models' performance across multiple reasoning and reading comprehension tasks.  Unlike Figure 3 which used prompts seen during training, Figure 4 assesses performance on unseen test prompts. Probability distributions illustrate the accuracy range for each model. The key finding is that the PAFT model significantly outperforms both the base model and the SFT model, achieving higher average accuracy and lower variance (less variability) across all tasks.", "section": "4 The PAFT Framework"}, {"figure_path": "https://arxiv.org/html/2502.12859/x5.png", "caption": "Figure 5: The performance of TopAccuracy, User-specified, BATprompt, ZOPO, and PAFT models is compared on multiple reasoning and reading comprehension tasks. Results are reported in terms of their correct distribution. The tests are conducted on a test set of 50 unseen prompts, different from the ones used in training. The PAFT model shows superior performance compared to other baselines, achieving higher accuracy and lower variance in all tasks.", "description": "Figure 5 presents a comparative analysis of five different prompt-based fine-tuning methods across multiple reasoning and reading comprehension tasks.  The models compared are: TopAccuracy (using the single best-performing prompt from training), User-specified (using human-designed prompts), BATprompt (a method generating robust prompts), ZOPO (an efficient prompt optimization technique), and PAFT (the proposed prompt-agnostic fine-tuning method).  The evaluation employs 50 unseen test prompts, ensuring a robust assessment of generalization. Results are visualized as probability distributions showing the accuracy of each model across these unseen prompts.  The figure highlights PAFT's superior performance, demonstrating higher average accuracy and significantly lower variance (indicating improved robustness and generalization to diverse prompts) compared to all other baselines across all tasks.", "section": "5.2 Main Results"}, {"figure_path": "https://arxiv.org/html/2502.12859/x6.png", "caption": "Figure 6: Scaling Law of Training Prompt Numbers: Mean and Standard Deviation of Accuracy Across Different Datasets. The x-axis represents the number of prompts on a logarithmic scale, while the y-axis shows the mean accuracy (left) and standard deviation of accuracy (right) for each dataset.", "description": "This figure illustrates the relationship between the number of training prompts and the model's performance across multiple datasets. The x-axis uses a logarithmic scale to represent the number of training prompts used, while the y-axis displays both the average accuracy (left panel) and the standard deviation of accuracy (right panel) achieved on each dataset. The plot demonstrates that increasing the number of training prompts initially leads to a significant improvement in both the mean accuracy and a reduction in accuracy variance.  However, beyond a certain point, the gains diminish, indicating diminishing returns. This suggests that while a diverse set of prompts is beneficial, an excessively large number of prompts doesn't necessarily translate to substantial performance improvements.", "section": "5.3 Ablation Studies"}]