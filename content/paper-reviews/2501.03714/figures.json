[{"figure_path": "https://arxiv.org/html/2501.03714/x2.png", "caption": "Figure 1: Novel view synthesis results on [45]. We introduce MoDec-GS, a novel framework for learning compact dynamic 3D Gaussians from real-world videos with complex motion. While existing SOTA methods [57, 20, 54] have difficulty modeling such complex combination of global and local motions, our approach effectively handles them thanks to GLMD (Sec. 4.1), and outperforms the prior methods in rendering quality even with a compact model size. The metrics under each framework are, PSNR (dB)\u2191\u2191\\uparrow\u2191 / LPIPS [59] \u2193\u2193\\downarrow\u2193 / Storage (MB)\u2193\u2193\\downarrow\u2193.", "description": "Figure 1 showcases novel view synthesis results using various methods, including the proposed MoDec-GS, on a dataset of real-world videos with complex motion [45].  MoDec-GS is presented as a new framework that effectively learns compact dynamic 3D Gaussians, overcoming the limitations of existing state-of-the-art (SOTA) techniques [57, 20, 54] in handling complex motion combinations. The comparison highlights MoDec-GS's superior rendering quality, achieved even with a smaller model size than the other methods.  The metrics used for comparison are PSNR (higher is better), LPIPS (lower is better), and storage size (lower is better).", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2501.03714/x3.png", "caption": "Figure 2: Overview of our MoDec-GS framework. To effectively train dynamic 3D Gaussians with complex motion, we introduce Global-to-Local Motion Decomposition (GLMD) (Sec 4.1). We first train a Global Canonical Scaffold-GS (Global CS) with entire frames, and apply a Global Anchor Deformation (GAD) to Local Canonical Scaffold-GS (Local CS) dedicated to represent its corresponding temporal segment (Sec 4.2). Next, to finely adjust the remaining local motion, we apply Local Gaussian Deformation (LGD) which explicitly deforms the reconstructed 3D Gaussians with a shared hexplane (Sec 4.3). During the training, Temporal Interval Adjustment (TIA) is performed, optimizing the temporal interval into a non-uniform interval that adopts to the scene\u2019s level of motion (Sec 4.4).", "description": "MoDec-GS is a novel framework for training compact dynamic 3D Gaussians.  It uses a two-stage approach: Global Anchor Deformation (GAD) and Local Gaussian Deformation (LGD). GAD handles global motion by deforming a global canonical scaffold. LGD handles finer local motion by explicitly deforming local canonical scaffolds.  Temporal Interval Adjustment (TIA) optimizes the temporal segments for efficient representation of the motion, leading to better quality and compact models. The figure illustrates this process.", "section": "4. Proposed Method"}, {"figure_path": "https://arxiv.org/html/2501.03714/x4.png", "caption": "Figure 3: Concept and effect of 2-stage deformation. For representing a complex motion of 3D Gaussians, a global movement over time intervals can be more efficiently handled through deformation of anchor itself. In contrast, subtle motions of individual 3D Gaussians within a time interval can be effectively addressed by explicit deformation of each Gaussian.", "description": "This figure illustrates the two-stage deformation process in MoDec-GS, designed to efficiently handle complex motions of 3D Gaussians. The first stage, global anchor deformation (GAD), deforms the anchor points themselves to capture large-scale movements across time intervals. This is more efficient than deforming individual Gaussians for global motion.  The second stage, local Gaussian deformation (LGD), then refines the representation by explicitly deforming individual Gaussians to model smaller, localized movements within each time interval. This two-stage approach allows for a more compact and efficient representation of complex dynamic scenes compared to methods that only model one type of motion.", "section": "4. Proposed Method"}, {"figure_path": "https://arxiv.org/html/2501.03714/x5.png", "caption": "Figure 4: Qualitative results comparison on three datasets [16, 45, 58]. The yellow boxes highlight areas where the proposed method achieves notable visual quality improvements, and the storage for the corresponding sequence is displayed below each rendered patch.", "description": "This figure shows a qualitative comparison of novel view synthesis results from three different datasets (iPhone [16], HyperNeRF [45], and Nvidia [58]).  For each dataset, several frames from a scene are shown, comparing the ground truth image to results obtained using four different methods: SC-GS [20], Deformable 3DGS [57], 4DGS [54], and the proposed MoDec-GS method.  Yellow boxes highlight specific regions where MoDec-GS shows significant visual improvement compared to other methods.  Below each frame, the model storage size in megabytes (MB) is provided, demonstrating the memory efficiency of the proposed approach.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.03714/x6.png", "caption": "Figure 5: TIA effectiveness.", "description": "This figure demonstrates the effectiveness of the Temporal Interval Adjustment (TIA) method.  It shows how TIA dynamically adjusts the temporal intervals assigned to local canonical anchors during the training process. The graph plots the normalized magnitude of optical flow against normalized time. The black dotted line represents the initial uniform temporal intervals, while the blue solid line illustrates the adjusted non-uniform intervals. The adjusted intervals are shorter in regions with high optical flow density (i.e., significant motion), reflecting TIA's ability to focus computational resources on areas with more complex motion.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.03714/x7.png", "caption": "Figure 6: Performance comparison visualization graph. The x\ud835\udc65xitalic_x-axis represents rendering speed (FPS)\u2191\u2191\\uparrow\u2191, and the y\ud835\udc66yitalic_y-axis indicates PSNR\u2191\u2191\\uparrow\u2191. Each framework is depicted as a bubble, with the size of the bubble representing the model storage size (MB)\u2193\u2193\\downarrow\u2193.", "description": "This figure visualizes the performance of different novel view synthesis (NVS) methods.  The x-axis shows rendering speed in frames per second (FPS), and the y-axis represents the peak signal-to-noise ratio (PSNR), a measure of image quality. Each NVS method is represented as a bubble; the bubble's size corresponds to the model's storage size in megabytes (MB). This allows for a direct comparison of the trade-off between rendering speed, image quality, and model size for each method. ", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.03714/x8.png", "caption": "Figure 7: Visualization of GLMD. For cut-lemon scene in HyperNeRF [45] dataset, the rendered patch of Global CS, Local CS, and each time stamp are presented for a fixed camera viewpoint. We also illustrate the optical flow color map between those patches to observe the captured motion at each deformation stage. At GAD stage, deformation in mainly found near objects with dominant motion (e.g., the lemon and knife), and the overall color trends are similar, indicating a similar global motion direction. In contrast, at the LGD stage, motion is observed across the entire scene, with relatively more diverse range of motion directions.", "description": "Figure 7 visualizes the Global-to-Local Motion Decomposition (GLMD) method used in MoDec-GS.  It shows the results for the 'cut-lemon' scene from the HyperNeRF dataset.  For a fixed camera position, it displays the rendered patches from three stages: the Global Canonical Scaffold-GS (Global CS), the Local Canonical Scaffold-GS (Local CS) at multiple timestamps, and the final deformed frame.  Optical flow color maps are included between the Global CS and Local CS and between the Local CS and the final frame. The color maps and the rendered patches show that the Global Anchor Deformation (GAD) step primarily deforms the area with significant global motion (lemon and knife), maintaining a similar color trend and flow, while the Local Gaussian Deformation (LGD) step refines the local motions across the whole scene using more diverse color trends and flows.", "section": "4. Proposed Method"}]