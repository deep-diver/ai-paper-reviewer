[{"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/stripy_and_blob_artifacts.jpg", "caption": "Figure 1: Illustration of stripy or blob-like artifacts generated in VSR outputs of LR videos rendered from 3DGS. \u2018VSR-Render\u2019 shows the VSR outputs of the LR rendered videos, while \u2018VSR-GT\u2019 displays the VSR outputs of the ground truth (GT) LR videos.", "description": "This figure compares the results of video super-resolution (VSR) applied to two different types of low-resolution (LR) videos.  The first set of LR videos ('VSR-Render') were rendered from a 3D model created using low-resolution multi-view images. The second set ('VSR-GT') are ground truth LR videos, meaning they were created by downsampling high-resolution videos. The image shows that the VSR applied to the rendered videos suffers from significant visual artifacts, including streaking and blotchy regions, while the VSR applied to the ground truth videos produces cleaner results. This highlights the negative impact of artifacts present in images rendered from low-resolution 3D models on the performance of VSR methods.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/main.jpg", "caption": "Figure 2: Overview of the proposed method. Given LR multi-view images, we generate subsequences (Sec.\u00a03.3) starting from each image using a simple greedy algorithm (Sec.\u00a03.2) and these subsequences are bounded by multiple thresholds (Sec.\u00a03.3). Finally, we train a 3DGS model for 3D reconstruction using the upsampled HR images.", "description": "This figure illustrates the proposed 3D super-resolution method.  It starts with low-resolution (LR) multi-view images.  These images are then processed using a simple greedy algorithm to create ordered subsequences,  which are essentially short video-like sequences of images.  Multiple thresholds are applied to control the length and smoothness of these subsequences. The subsequences are then fed into a video super-resolution (VSR) model to upscale them to high-resolution (HR) images. Finally, a 3D Gaussian Splatting (3DGS) model is trained on these HR images to reconstruct a high-fidelity 3D model.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/subsequence.jpg", "caption": "Figure 3: Illustration of subsequence generation. (a) is an unordered multi-view image dataset. (b) is the result of using a simple greedy algorithm, Alg.\u00a01. (c) highlights misalignments incurred by the algorithm, and we propose to split it into subsequences based on a pose difference threshold (red dotted line) between consecutive frames.", "description": "Figure 3 illustrates the process of generating subsequences from an unordered set of multi-view images.  Panel (a) shows the initial, unordered dataset. Panel (b) shows the result of applying a simple greedy algorithm (Algorithm 1 from the paper), which attempts to create a sequence of images by selecting the most similar image to the current one. However, this greedy approach can result in abrupt transitions and misalignments, as highlighted in panel (c). The red dotted lines in (c) indicate where the simple greedy algorithm fails to find a smooth sequence and abrupt changes occur. To address this issue, the authors propose splitting the sequence into multiple subsequences based on a threshold of the pose difference between consecutive frames, ensuring smoother and more consistent image sequences for subsequent processing.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/lego_simple_greedy_algorithm.jpg", "caption": "Figure 4: An example result from the simple greedy algorithm applied to the NeRF-synthetic dataset (Lego). Two neighboring images highlighted in red demonstrate abrupt transitions caused by misalignments.", "description": "This figure displays an example of the results obtained from applying the simple greedy algorithm to the Lego scene within the NeRF-synthetic dataset.  The algorithm is used to order a set of unordered multi-view images to create a sequence suitable for processing with a Video Super-Resolution (VSR) model. The red highlights draw attention to two adjacent images in the sequence that demonstrate abrupt visual transitions between them. These transitions result from the misalignments caused by the limitations of the simple greedy algorithm in properly ordering the images according to their spatial relationships. These misalignments highlight the need for more robust ordering techniques, which are explored later in the paper.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/baseline_blender.jpg", "caption": "Figure 5: Qualitative results on the NeRF-synthetic dataset. The PSNR values against GT are embedded in each image patch. Ours have shown superior results than the existing baselines, especially for high-frequency details.", "description": "This figure displays a qualitative comparison of different super-resolution methods on the NeRF-synthetic dataset.  Each row shows the results for a single scene, with columns representing bicubic upsampling, SwinIR, Render-SR, NeRF-SR, DiSR-NeRF, and the proposed method ('Ours'), followed by the ground truth image ('GT').  The PSNR values (peak signal-to-noise ratio) of each upsampled image relative to the ground truth are embedded within each image patch.  The results highlight the superior performance of the proposed method, particularly in preserving high-frequency details that are often lost or blurred in the other methods.", "section": "4.2 Results"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/baseline_mip360.jpg", "caption": "Figure 6: Qualitative results on Mip-NeRF 360 dataset. The PSNR values against GT are embedded in each image patch.\nOurs have shown superior results than the existing baselines, especially for high-frequency details.", "description": "This figure displays qualitative results from the Mip-NeRF 360 dataset, a collection of real-world scenes.  It presents a comparison of the image quality produced by different super-resolution methods, including the proposed method and several baselines (Bicubic and SwinIR). Each image patch shows a zoomed-in section with the Peak Signal-to-Noise Ratio (PSNR) value calculated against the ground truth image.  The results highlight the superiority of the proposed approach, particularly in preserving and enhancing high-frequency details, which often suffer degradation in other techniques.", "section": "4.2 Results"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/PSNR_LPIPS.jpg", "caption": "Figure 7: Comparison with baselines.", "description": "This figure compares the performance of the proposed method against several baseline methods for 3D super-resolution.  It shows a quantitative comparison using PSNR (Peak Signal-to-Noise Ratio) and LPIPS (Learned Perceptual Image Patch Similarity) metrics across multiple object categories from the NeRF synthetic dataset.  The results demonstrate that the proposed approach significantly outperforms the baselines in terms of both objective and perceptual image quality.", "section": "4 Experiment"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/misalignment_trends_all_objects.jpg", "caption": "Figure 8: Misalignment trends within a sequence.", "description": "This figure visualizes the frequency of misalignment errors along the sequence of images processed by the algorithm. The x-axis represents the position within the sequence, categorized into quartiles (0-25%, 25-50%, 50-75%, 75-100%). The y-axis shows the average number of misalignments observed in each quartile across various objects.  The graph reveals a trend where misalignments become more frequent towards the end of the sequence, indicating that the greedy approach to ordering images becomes less accurate as the algorithm progresses.", "section": "3.3 Adaptive-Length Subsequence"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/misalignment.jpg", "caption": "Figure 9: Misalignment Error.", "description": "This figure illustrates the impact of misalignments in sequences of images on the quality of 3D reconstruction.  It shows how errors accumulate as sequence length increases, especially towards the end.  The misalignment occurs because of inaccuracies in connecting images using ORB features; longer sequences increase the likelihood of erroneously linking unrelated images. This leads to unreliable information during upsampling, impacting the overall quality of the 3D reconstruction.", "section": "3.3 Adaptive-Length Subsequence"}, {"figure_path": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/appendix_qualitative_blender.jpg", "caption": "Figure 10: Qualitative results on the NeRF-synthetic dataset. The PSNR values against GT are embedded in each image patch. Ours have shown superior results than the existing baselines, especially for high-frequency details.", "description": "Figure 10 presents a qualitative comparison of super-resolution results on the NeRF-synthetic dataset.  Multiple methods, including bicubic interpolation, SwinIR, Render-SR, NeRF-SR, DiSR-NeRF, and the authors' proposed approach, were used to generate high-resolution images from low-resolution inputs. The figure displays example images from each method for several scenes. PSNR values (peak signal-to-noise ratio), comparing the generated images to the ground truth (GT), are embedded within each image patch, providing a quantitative assessment of the quality. The authors highlight that their method surpasses the baselines, particularly in capturing high-frequency details, which contribute to a more realistic and visually appealing outcome.", "section": "4.2 Results"}]