[{"figure_path": "https://arxiv.org/html/2504.09130/", "caption": "Figure 1: Illustration of Input-Output Prompting, CoT, Vision-aided Thought and our VisuoThink. Vision-aided Thought often relies on reasoning with one-step or unreliable multi-step visual cues (generated by LVLMs). While VisuoThink addresses this gap through tool-augmented visual hints, coupled with a predictive-rollout search mechanism to systematically optimize reasoning capability.", "description": "This figure illustrates different approaches to multimodal reasoning.  Input-Output Prompting is the basic setup. Chain-of-Thought (CoT) shows a purely text-based reasoning process. Vision-aided Thought uses visual cues from an LLM, but these cues are often limited to a single step or unreliable multi-step cues.  In contrast, VisuoThink, the authors' proposed method, uses tool-augmented visual hints combined with a predictive rollout search mechanism. This allows for a more systematic exploration of the reasoning steps, leading to improved optimization of the reasoning capabilities.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.09130/x2.png", "caption": "Figure 2: The illustration of our VisuoThink framework with three stages: (1) vision-text interleaved expansion: generates candidate paths through vision-text interleaved thinking; (2) rollout simulation: sample candidate reasoning nodes and then perform look-ahead search to better evaluate the value of current states; (3) selection: selects the most promising path via self-voting with results or states from rollout.", "description": "This figure illustrates the VisuoThink framework's three main stages.  Stage 1, vision-text interleaved expansion, uses vision and text iteratively to generate multiple potential reasoning paths. Stage 2, rollout simulation, evaluates these paths by sampling candidate reasoning steps and using a look-ahead search to predict outcomes.  This allows for a more informed evaluation of the various reasoning pathways. Finally, Stage 3, selection, chooses the best path based on a self-voting mechanism that considers both the results and states generated during the rollout simulation.", "section": "3 VisuoThink"}, {"figure_path": "https://arxiv.org/html/2504.09130/x3.png", "caption": "Figure 3: The illustration of spatial reasoning tasks derived from VoT Wu et\u00a0al. (2024), including Visual Navigation and Visual Tiling. LVLM is required to execute a sequence of actions to complete certain goals. Our experimental setting makes them much more challenging and closer to real-environment deployment.", "description": "Figure 3 showcases two spatial reasoning tasks adapted from the VoT benchmark (Wu et al., 2024): Visual Navigation and Visual Tiling.  The tasks challenge Large Vision-Language Models (LVLMs) to execute a series of actions to achieve specified goals. Unlike the original VoT benchmark, these adapted tasks have increased complexity and more closely resemble real-world scenarios, demanding more precise and detailed planning and execution from the LVLM.", "section": "5 Spatial Reasoning with VisuoThink"}, {"figure_path": "https://arxiv.org/html/2504.09130/x4.png", "caption": "Figure 4: \n(LEFT) The trend of Pass@1 rate on Visual Navigation as the number of reasoning steps increases. (right) The relationship between the Accuracy@1 on geometry problems (Geomverse) and tree width for rollout search. We observe that LVLMs significantly benefit from longer reasoning chains, although the effect plateaus rapidly beyond a certain threshold of reasoning steps. The relationship between performance and tree width exhibits a more complex pattern, demonstrating an inverted U-shaped trend with both GPT-4o and Claude-3.5-Sonnet.", "description": "This figure shows two plots. The left plot displays the relationship between the number of reasoning steps and the Pass@1 rate in the Visual Navigation task.  It demonstrates that increasing the number of reasoning steps initially improves performance, but the improvement plateaus after a certain point. The right plot illustrates the relationship between the tree width (number of child nodes in the rollout search) and Accuracy@1 on the Geomverse geometry problems.  This plot reveals an inverted U-shaped curve, indicating that increasing the tree width to a certain point improves performance, but further increases lead to decreased performance.", "section": "Empirical Results"}, {"figure_path": "https://arxiv.org/html/2504.09130/x5.png", "caption": "Figure 5: \nThe performance gain (+%) on tasks through predictive rollout search. The performance gain is calculated via the performance gap between VisuoThink (w/o rollout search) and VisuoThink.", "description": "Figure 5 presents a bar chart visualizing the performance improvement achieved by incorporating the predictive rollout search mechanism into the VisuoThink framework.  The chart displays the percentage increase in performance for various tasks and models (GPT-40, Claude-3.5-Sonnet, and Qwen2-VL-72B), comparing results with and without the predictive rollout search.  The results are categorized into two groups representing strong and weak supervision types based on the nature of the feedback provided during the reasoning process. This visualization highlights the impact of the predictive rollout search on different model architectures under varying supervision levels.", "section": "6.3 Strong v.s. Weak Supervision in Predictive Rollout Search"}]