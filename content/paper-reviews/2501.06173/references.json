{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-00-00", "reason": "This paper is highly relevant to the core task of long-form video generation, directly addressing the objective of creating coherent and visually rich videos, which is a key focus of the current research."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-00-00", "reason": "This study is significant because it introduces a novel open-diffusion approach for high-quality video generation, providing a foundation for further advancements in the field."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-00-00", "reason": "This paper directly tackles the challenge of limited high-quality video data, which is a major constraint for advancing video generation techniques."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-00-00", "reason": "This work presents a scalable method for training diffusion models with transformers, overcoming computational limitations and paving the way for generating higher resolution and more detailed videos."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This research introduces a latent diffusion model for high-resolution image synthesis, a significant advancement relevant to the current work which focuses on generating long-form video with high visual fidelity."}]}