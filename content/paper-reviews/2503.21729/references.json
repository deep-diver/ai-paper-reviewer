{"references": [{"fullname_first_author": "Akari Asai", "paper_title": "Self-rag: Learning to retrieve, generate, and critique through self-reflection", "publication_date": "2024-05-07", "reason": "This paper introduces Self-RAG, a framework for learning to retrieve, generate, and critique through self-reflection, which is highly relevant to the current paper's focus on knowledge-guided reasoning."}, {"fullname_first_author": "Kelvin Guu", "paper_title": "Retrieval augmented language model pre-training", "publication_date": "2020-07-13", "reason": "As an important paper, it explores the integration of retrieval mechanisms to augment language models, thus providing a foundation for the current paper's focus on enhancing factuality through retrieval-augmented generation."}, {"fullname_first_author": "Patrick S. H. Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks", "publication_date": "2020-12-06", "reason": "This paper introduces retrieval-augmented generation, a foundational concept in the current paper's approach to improving the factuality of large reasoning models."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy", "publication_date": "2023-12-06", "reason": "This paper explores iterative retrieval-generation strategies for large language models, which is directly related to the current paper's approach to knowledge-guided reasoning."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-11-28", "reason": "This paper introduces Chain-of-Thought prompting and therefore lays the groundwork for the reasoning capabilities leveraged in the current paper, making it highly relevant to the overall methodology."}]}