[{"figure_path": "https://arxiv.org/html/2502.00314/x1.png", "caption": "Figure 1: (a) Schematic representation of the proposed method, ViLU-Net, (b) the ViL block, (c) convolutional stem, and (d) Up Sampler and Down Sampler blocks, where IN stands for Instance Normalization operation.", "description": "Figure 1 provides a detailed breakdown of the ViLU-Net architecture. (a) presents a high-level schematic of the entire network, showing the flow of data through the convolutional stem, encoder, decoder, and segmentation head.  (b) zooms in on the ViL (Vision x-LSTM) block, the core component of the network, highlighting its internal structure which includes mLSTM (modified long short-term memory) layers for spatial and temporal feature integration. (c) illustrates the convolutional stem, the initial part of the network that processes the input image.  Finally, (d) details the Up and Down Sampler blocks, crucial for the encoder and decoder's functionality, respectively, showing how instance normalization (IN) is applied.", "section": "2. METHOD"}, {"figure_path": "https://arxiv.org/html/2502.00314/x2.jpg", "caption": "Figure 2: Visualized segmentation examples of abdominal organ segmentation in CT. The ViLU-Net excels at differentiating intricate soft tissues within the abdominal region.", "description": "Figure 2 presents a visual comparison of abdominal organ segmentation results obtained using different methods.  The images show the ground truth segmentations alongside the results produced by various methods, including ViLU-Net, a novel U-Net modification using Vision-xLSTM blocks.  The comparison highlights the ability of ViLU-Net to accurately segment intricate soft tissues and structures within the abdominal region, exhibiting superior performance compared to other methods.", "section": "3.1 Abdomen CT Dataset"}, {"figure_path": "https://arxiv.org/html/2502.00314/x15.jpg", "caption": "Figure 3: Visual comparisons of different methods on our in house dataset.", "description": "Figure 3 presents a qualitative comparison of different deep learning models for retroperitoneal tumor segmentation on a custom dataset.  The figure displays example slices (axial, coronal, and sagittal views) from the dataset, showing the input CT image, the ground truth segmentation, and the segmentation masks generated by several methods (nnU-Net, SwinUNETR, U-Mamba, and the proposed ViLU-Net). This allows for a direct visual assessment of the relative performance of each method in terms of accuracy, boundary precision, and ability to handle irregular tumor shapes. The results highlight ViLU-Net's superior performance in accurately segmenting tumor regions with irregular shapes compared to other methods.", "section": "3.2 Retroperitoneal Tumour Dataset"}]