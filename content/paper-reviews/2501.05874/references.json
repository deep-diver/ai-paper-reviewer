{"references": [{"fullname_first_author": "Rohan Anil", "paper_title": "Gemini: A family of highly capable multimodal models", "publication_date": "2023-12-21", "reason": "This paper introduces Gemini, a family of highly capable multimodal models, which are foundational to the VideoRAG framework's ability to process and integrate multimodal information from videos."}, {"fullname_first_author": "Patrick S. H. Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks", "publication_date": "2020-12-06", "reason": "This is a foundational paper on Retrieval-Augmented Generation (RAG), providing the core methodology that underpins the VideoRAG approach."}, {"fullname_first_author": "Vladimir Karpukhin", "paper_title": "Dense passage retrieval for open-domain question answering", "publication_date": "2020-11-16", "reason": "This paper introduces dense passage retrieval, a crucial technique for efficient retrieval of relevant video segments in the VideoRAG framework."}, {"fullname_first_author": "Antoine Miech", "paper_title": "HowTo100M: Learning a text-video embedding by watching hundred million narrated video clips", "publication_date": "2019-10-27", "reason": "The HowTo100M dataset, introduced in this paper, serves as a crucial video corpus for training and evaluating the VideoRAG model."}, {"fullname_first_author": "Valeria Bolotova-Baranova", "paper_title": "WikihowQA: A comprehensive benchmark for multi-document non-factoid question answering", "publication_date": "2023-07-09", "reason": "The WikiHowQA dataset, presented in this paper, provides a valuable benchmark for evaluating the performance of the VideoRAG model in information-seeking tasks."}]}