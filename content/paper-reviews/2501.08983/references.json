{"references": [{"fullname_first_author": "B. Mildenhall", "paper_title": "NeRF: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-08-23", "reason": "This paper introduces NeRF, a foundational method for novel view synthesis that heavily influences many 3D generation techniques, including the approach in this paper."}, {"fullname_first_author": "T. Karras", "paper_title": "A style-based generator architecture for generative adversarial networks", "publication_date": "2019-06-01", "reason": "This paper introduces StyleGAN, a highly influential generative adversarial network (GAN) architecture that greatly improves the quality and diversity of generated images and is a key building block for many 3D generation models."}, {"fullname_first_author": "Z. Chen", "paper_title": "SceneDreamer: Unbounded 3D scene generation from 2D image collections", "publication_date": "2023-12-01", "reason": "This paper introduces SceneDreamer, which directly addresses the challenge of generating unbounded 3D scenes and serves as a key predecessor to this paper's approach."}, {"fullname_first_author": "Z. Hao", "paper_title": "GANcraft: Unsupervised 3D neural rendering of minecraft worlds", "publication_date": "2021-10-27", "reason": "This paper introduces GANcraft, one of the earliest works demonstrating the potential of GANs for generating large-scale 3D scenes using voxel representations, influencing subsequent research in unbounded city generation."}, {"fullname_first_author": "C. H. Lin", "paper_title": "InfiniCity: Infinite-scale city synthesis", "publication_date": "2024-06-01", "reason": "This paper introduces InfiniCity, which specifically addresses the challenge of generating highly detailed and expansive cityscapes and provides a direct comparison point for the proposed approach."}]}