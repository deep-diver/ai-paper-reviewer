{"references": [{"fullname_first_author": "Philip Anastassiou", "paper_title": "SEED-TTS: A family of high-quality versatile speech generation models", "publication_date": "2024-06-24", "reason": "This paper introduces SEED-TTS, a speech generation model used as a benchmark for evaluating MinMo's speech synthesis capabilities."}, {"fullname_first_author": "Alexandre D\u00e9fossez", "paper_title": "Moshi: a speech-text foundation model for real-time dialogue", "publication_date": "2024-10-01", "reason": "Moshi is a key comparative model in the paper, representing a state-of-the-art native multimodal model for voice interaction."}, {"fullname_first_author": "Zhihao Du", "paper_title": "CosyVoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens", "publication_date": "2024-07-01", "reason": "CosyVoice is a crucial component of MinMo, providing the streaming voice decoder for speech synthesis."}, {"fullname_first_author": "Aohan Zeng", "paper_title": "GLM-4-Voice: Towards intelligent and human-like end-to-end spoken chatbot", "publication_date": "2024-12-01", "reason": "GLM-4-Voice is another important comparative model, representing a state-of-the-art native multimodal model for voice interaction, and directly compared against in multiple experiments."}, {"fullname_first_author": "Yunfei Chu", "paper_title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models", "publication_date": "2023-11-01", "reason": "Qwen-Audio serves as a strong baseline model for various speech tasks, providing essential comparative results for evaluating MinMo's performance."}]}