{"references": [{"fullname_first_author": "A Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017", "reason": "It discusses the Transformer architecture which OmniMamba attempts to provide an efficient alternative to."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "publication_date": "2023-12-00", "reason": "It presents the Mamba architecture, which OmniMamba is based on for efficient sequence modeling."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual Instruction Tuning", "publication_date": "2024", "reason": "It's a key paper in visual instruction tuning, a method used to enhance multimodal understanding in OmniMamba."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical Text-Conditional Image Generation with CLIP Latents", "publication_date": "2022-04-06", "reason": "It explores hierarchical text-conditional image generation using CLIP latents, a method related to OmniMamba's visual generation approach."}, {"fullname_first_author": "Xinlong Wang", "paper_title": "Emu3: Next-token prediction is all you need", "publication_date": "2024-09-18", "reason": "It uses a next-token prediction paradigm for multi-modal generation, an approach OmniMamba also adopts."}]}