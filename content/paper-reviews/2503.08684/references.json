{"references": [{"fullname_first_author": "Sunhao Dai", "paper_title": "Cocktail: A comprehensive information retrieval benchmark with llm-generated documents integration", "publication_date": "2024-01-01", "reason": "This paper introduces the Cocktail benchmark, which is used extensively in the current paper for evaluating retrieval models and is therefore very important for context and comparison."}, {"fullname_first_author": "Sunhao Dai", "paper_title": "Neural retrievers are biased towards Ilm-generated content", "publication_date": "2024-01-01", "reason": "This paper identifies the source bias problem that the current paper addresses, making it a foundational reference."}, {"fullname_first_author": "Wayne Xin Zhao", "paper_title": "Dense text retrieval based on pretrained language models: A survey", "publication_date": "2024-01-01", "reason": "This provides a survey of dense text retrieval, a core component of the perplexity-trap issue being addressed, providing context for the types of retrievers being examined."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2018-10-01", "reason": "This paper introduces BERT, a foundational PLM architecture that underpins many of the retrievers examined, making it important for understanding the models themselves."}, {"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-01", "reason": "This report details GPT-4, one of the Large Language Models that is used for generating content and is referenced when comparing the generated content's bias."}]}