{"references": [{"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This reference is important because Llama 3 models are used in experiments throughout the paper to evaluate LogQuant."}, {"fullname_first_author": "Zhenyu Zhang", "paper_title": "H2o: Heavy-hitter oracle for efficient generative inference of large language models", "publication_date": "2024-01-01", "reason": "This reference is important because the paper attempts to improve upon it, as well as compares LogQuant to it's performance."}, {"fullname_first_author": "Yushi Bai", "paper_title": "LongBench: A bilingual, multitask benchmark for long context understanding", "publication_date": "2024-08-01", "reason": "This reference is important because the LongBench dataset is used throughout the paper in order to compare the accuracy of LogQuant to existing methods."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This reference is important because the GSM8K dataset is used throughout the paper to compare the accuracy of LogQuant to existing methods."}, {"fullname_first_author": "Zirui Liu", "paper_title": "Kivi: A tuning-free asymmetric 2bit quantization for kv cache", "publication_date": "2024-01-01", "reason": "This reference is important because KiVi is one of the main existing methods that LogQuant attempts to improve on, as well as is compared to LogQuant's performance."}]}