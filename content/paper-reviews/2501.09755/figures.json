[{"figure_path": "https://arxiv.org/html/2501.09755/x1.png", "caption": "Figure 1: Our learnings from scaling ViTok. We showcase our ViTok architecture (left) and key findings (right) from scaling auto-encoders for image and video reconstruction and generation. We enhance traditional CNN-based auto-encoders by integrating Vision Transformers (ViTs) with an upgraded Llama architecture into an asymmetric auto-encoder framework forming Vision Transformer Tokenizer or ViTok. Visual inputs are embedded as patches or tubelets, processed by a compact Llama Encoder, and bottlenecked to create a latent code. The encoded representation is then upsampled and handled by a larger Llama Decoder to reconstruct the input. Color-coded text boxes highlight the effects of scaling the encoder, adjusting the bottleneck size, and expanding the decoder. Additionally, we discuss trade-offs in loss optimization and the model\u2019s adaptability to video data. Our best performing ViTok variant achieves competitive performance with prior state-of-the-art tokenizers while reducing computational burden.", "description": "Figure 1 illustrates the key findings from scaling Vision Transformer Tokenizers (ViTok) for image and video reconstruction and generation.  The left side shows the ViTok architecture, which replaces traditional CNN-based autoencoders with an asymmetric design integrating Vision Transformers (ViTs) and an enhanced Llama architecture.  Visual inputs are embedded as patches or tubelets, encoded by a Llama Encoder, bottlenecked, upsampled by a larger Llama Decoder, and finally decoded to reconstruct the input.  The right side summarizes the findings, highlighting the impact of scaling different components (encoder, decoder, bottleneck size) on reconstruction and generation performance. Color-coding helps visualize these effects.  The figure also notes trade-offs in loss optimization strategies and the model's adaptability for video. The best ViTok variant offers competitive performance and lower computational costs compared to existing methods.", "section": "3 Bottlenecks, Scaling, and Trade-offs in Visual Tokenization"}, {"figure_path": "https://arxiv.org/html/2501.09755/x10.png", "caption": "Figure 2: 256p image reconstruction sweep over floating points E\ud835\udc38Eitalic_E. We evaluate ViTok S-B trained with stage 1 (Section\u00a02.3) using combinations of patch sizes p\u22088,16,32\ud835\udc5d81632p\\in{8,16,32}italic_p \u2208 8 , 16 , 32 and channel widths c\u22084,8,16,32,64\ud835\udc5048163264c\\in{4,8,16,32,64}italic_c \u2208 4 , 8 , 16 , 32 , 64 to investigate how the total floating points E=2562p2\u22c5c\ud835\udc38\u22c5superscript2562superscript\ud835\udc5d2\ud835\udc50E=\\frac{256^{2}}{p^{2}}\\cdot citalic_E = divide start_ARG 256 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG \u22c5 italic_c influences FID, IS, SSIM, and PSNR in reconstruction tasks. Our findings reveal a strong correlation between log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and log\u2061(rFID)rFID\\log(\\text{rFID})roman_log ( rFID ), log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rIS, log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rSSIM, as well as log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rPSNR, independent of the number of FLOPs utilized by the auto-encoder. This indicates that E\ud835\udc38Eitalic_E is the primary bottleneck for reconstruction, irrespective of the code shape or FLOPs expended. Additionally, similar trends are observed across the ImageNet-1K and COCO datasets, indicating that these patterns are consistent regardless of the dataset used.", "description": "This figure shows the results of an experiment investigating the impact of the total number of floating-point numbers (E) in the latent representation on image reconstruction performance.  The experiment varied the patch size (p) and the number of channels (c) in the ViTok model, while keeping the encoder size small and the decoder size base.  The results show a strong positive correlation between the logarithm of E and the logarithm of reconstruction metrics (FID, IS, SSIM, PSNR), regardless of the computational cost (FLOPs). This suggests that E is the primary limiting factor for reconstruction quality, not the specific architecture or computational complexity.  The consistent trends across ImageNet-1K and COCO datasets further support this conclusion.", "section": "3.1 E as the Main Bottleneck in Image Reconstruction"}, {"figure_path": "https://arxiv.org/html/2501.09755/x11.png", "caption": "Figure 3:  256p image reconstruction visualization over floating points E\ud835\udc38Eitalic_E. Example reconstructions for varying the number of floating points E\ud835\udc38Eitalic_E values on ViTok S-B/16, achieved by adjusting the channel size c=64,32,16,8,4\ud835\udc5064321684c={64,32,16,8,4}italic_c = 64 , 32 , 16 , 8 , 4 for each image across the row. As E\ud835\udc38Eitalic_E decreases, high-frequency details diminish, with small colors and fine details gradually lost. When E<4096\ud835\udc384096E<4096italic_E < 4096, textures merge, and significant detail loss becomes apparent.", "description": "Figure 3 visualizes the effect of varying the total number of floating points (E) in the latent code on the quality of 256x256 pixel image reconstruction using the ViTok S-B/16 model.  Each row represents a different value of E, achieved by adjusting the number of channels (c) in the latent space while keeping the patch size constant.  As E decreases (moving from left to right), the amount of detail preserved in the reconstructed images decreases. High-frequency details, such as fine textures and small color variations, are lost first. When E falls below 4096, significant loss of image texture and detail becomes noticeable.", "section": "3.1 E as the Main Bottleneck in Image Reconstruction"}, {"figure_path": "https://arxiv.org/html/2501.09755/x12.png", "caption": "Figure 4: 512p Image reconstruction over E\ud835\udc38Eitalic_E. We evaluate ViTok S-B trained with stage 1 (Section\u00a02.3) across all combinations of patch sizes p\u22088,16,32\ud835\udc5d81632p\\in{8,16,32}italic_p \u2208 8 , 16 , 32 and a fixed channel width c=16\ud835\udc5016c=16italic_c = 16, analyzing how the total floating-point operations, calculated as E=5122p2\u22c5c\ud835\udc38\u22c5superscript5122superscript\ud835\udc5d2\ud835\udc50E=\\frac{512^{2}}{p^{2}}\\cdot citalic_E = divide start_ARG 512 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG \u22c5 italic_c, influence reconstruction metrics such as FID, IS, SSIM, and PSNR. E\ud835\udc38Eitalic_E shows trends similar to 256p results (Figure\u00a02). However, achieving comparable rPSNR/rSSIM to 256p requires 4\u00d7E4\ud835\udc384\\times E4 \u00d7 italic_E for 512p reconstruction, which indicates that compression ratio of pixels to channels should be fixed to maintain performance.", "description": "Figure 4 investigates the impact of the total number of floating-point operations (E) on the quality of 512p image reconstruction using the ViTok S-B model.  The experiment systematically varies patch sizes (p) while keeping the channel width (c) constant at 16.  The results show a strong correlation between E and reconstruction metrics (FID, IS, SSIM, PSNR), consistent with the findings from the 256p experiment in Figure 2.  A key observation is that maintaining comparable reconstruction quality at 512p resolution requires four times the number of floating-point operations (4xE) compared to 256p, highlighting the importance of maintaining a consistent compression ratio (pixels to channels) for optimal reconstruction performance.", "section": "3.1 E as the Main Bottleneck in Image Reconstruction"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/gen_viz_processed/cfg_main_256p.png", "caption": "Figure 5: 256p image generation over E\ud835\udc38Eitalic_E. We evaluate each tokenizer from Figure\u00a02 on DiT following Section\u00a02.3. Results for CFG scales of 1.5 and 3.0 are on the left two and right two plots respectively. Our results show no strong linear correlation between log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and generation performance. Instead, a second-order trend reveals an optimal E\ud835\udc38Eitalic_E for each patch size p\ud835\udc5dpitalic_p, indicating a complex interplay between E\ud835\udc38Eitalic_E and c\ud835\udc50citalic_c. This highlights the necessity of optimizing both parameters to balance reconstruction quality with generative capabilities.", "description": "Figure 5 examines how the total number of floating points in the latent code (E), a key bottleneck in the model, impacts the quality of generated images. The figure presents four plots, each showing the relationship between E and two key metrics: gFID and gIS, which measure the quality of generated images and their diversity, respectively.  Each plot corresponds to a different CFG (classifier-free guidance) scale (1.5 or 3.0), which affects the balance between image quality and adherence to the input prompt. The results show that for a given patch size (p), there's an optimal E that yields the best performance. There's no simple linear relationship, but rather a second-order curve indicating that either too small or too large an E hinders image generation quality.", "section": "3 Bottlenecks, Scaling, and Trade-offs in Visual Tokenization"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/gen_viz_processed/cfg_main_512p.png", "caption": "Figure 6: Encoder scaling on 256p image reconstruction. We evaluate reconstruction metrics of ViTok trained with stage 1 (Section\u00a02.3) over model sizes S-S, B-S, S-B, B-B, B-L, L-L with fixed p=16,c=16,L=256,E=4096formulae-sequence\ud835\udc5d16formulae-sequence\ud835\udc5016formulae-sequence\ud835\udc3f256\ud835\udc384096p=16,c=16,L=256,E=4096italic_p = 16 , italic_c = 16 , italic_L = 256 , italic_E = 4096. There is no correlation between encoder size and reconstruction performance indicating that scaling the encoder is unhelpful in improving reconstruction capabilities. This argues that visual encoding does not require much computation.", "description": "This figure analyzes the effect of scaling the encoder size on 256p image reconstruction quality using the ViTok model.  The experiment controls for other variables by keeping the patch size (p), channel width (c), number of tokens (L), and total number of floating points (E) constant. The results show that there is no significant correlation between the size of the encoder and the reconstruction metrics. This suggests that increasing the complexity of the encoder does not necessarily lead to better reconstruction performance, indicating that visual encoding might not require extensive computational resources.", "section": "3.3 Scaling Trends in Auto-Encoding"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figure_videos_1024.png", "caption": "Figure 7: Decoder scaling on 256p image reconstruction. Using the results from Figure\u00a06, we plot various decoder sizes (S, B, L) over reconstruction performance. There is a strong correlation between decoder size and reconstruction performance, which indicates scaling the decoder improves reconstruction. Although, increasing the decoder size from Base to Large does not provide the same boost of performance as doubling E\ud835\udc38Eitalic_E to 8192819281928192 from 4096409640964096.", "description": "Figure 7 investigates the impact of scaling the decoder size on the performance of the ViTok model in 256p image reconstruction.  The figure shows a strong positive correlation between decoder size and reconstruction quality, as measured by metrics like FID, suggesting that larger decoders generally lead to better reconstruction. However, the improvement plateaus when scaling the decoder from the 'Base' size to the 'Large' size; simply increasing the decoder size does not yield the same dramatic improvements observed when the total number of floating points in the latent code (E) is doubled.", "section": "3.3 Scaling Trends in Auto-Encoding"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figures_videos_512.png", "caption": "Figure 8: Encoder scaling on 256p image generation. We evaluate each tokenizer from Figure\u00a06 on DiT following Section\u00a02.3. We plot encoder size over generation metric results for CFG scales of 1.5 and 3.0 on the left two and right two plots respectively. There is a weak negative correlation between encoder size and final performance indicating that scaling the encoder is harmful for generation results. This is coupled by the fact that increased encoder sizes make training slower due to increased computational overhead.", "description": "Figure 8 explores the impact of scaling the encoder size of the ViTok architecture on the performance of image generation.  The experiment uses the DiT model, following the training protocol described in Section 2.3 of the paper. Different encoder sizes (Small, Base, Large) are tested, and their performance is evaluated using two different CFG scales (1.5 and 3.0). The plots showcase the generation metrics (gFID) for each encoder size and CFG scale, revealing a weak negative correlation between encoder size and generation quality.  Larger encoders do not improve, and may even slightly hinder, generation performance while increasing training time and computational cost.", "section": "3.3 Scaling Trends in Auto-Encoding"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figures_videos_256.png", "caption": "Figure 9: Decoder scaling on 256p image generation. Using the results from Figure\u00a06, we plot various decoder sizes (S, B, L) over generation performance. We plot decoder size over generation metric results for CFG scales of 1.5 and 3.0 on the left two and right two plots respectively. Unlike reconstruction, there is no clear correlation between decoder size and generation performance. This indicates that scaling the decoder has minimal benefits overall for auto-encoding.", "description": "Figure 9 explores the impact of scaling the decoder size on 256p image generation performance.  It builds upon the results presented in Figure 6, which examined the effects of encoder scaling.  The figure shows generation results (gFID and gIS) for different decoder sizes (Small, Base, Large), each tested with two different classifier-free guidance (CFG) scales (1.5 and 3.0). Unlike the findings for reconstruction tasks (where larger decoders improved performance), this figure demonstrates that decoder scaling has only minimal impact on image generation quality.", "section": "3.3 Scaling Trends in Auto-Encoding"}]