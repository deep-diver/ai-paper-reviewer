{"references": [{"fullname_first_author": "Yang", "paper_title": "Qwen2.5-math technical report: Toward mathematical expert model via self-improvement", "publication_date": "2024-09-12", "reason": "This paper is highly relevant as it introduces Qwen2.5-Math, a model that AceMath directly builds upon and improves."}, {"fullname_first_author": "Shao", "paper_title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-03", "reason": "This work is crucial as it explores a continued pre-training approach for enhancing LLMs' mathematical capabilities, a technique that AceMath also uses and refines."}, {"fullname_first_author": "Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper is foundational as it introduces the concept of using reward models to evaluate generated solutions, a core aspect of AceMath's approach."}, {"fullname_first_author": "Dubey", "paper_title": "The Llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This is important because AceMath uses Llama 3 models as its base, and this paper details those models."}, {"fullname_first_author": "Li", "paper_title": "Mugglemath: Assessing the impact of query and response augmentation on math reasoning", "publication_date": "2024-06-26", "reason": "This paper is highly relevant because it explores the creation of synthetic data for improving math reasoning, a technique that AceMath adopts and improves."}]}