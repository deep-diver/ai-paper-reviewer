---
title: "GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation"
summary: "GigaTok: Scale visual tokenizers for better image generation!"
categories: ["AI Generated", "ü§ó Daily Papers"]
tags: ["Computer Vision", "Image Generation", "üè¢ Hong Kong University of Science and Technology",]
showSummary: true
date: 2025-04-11
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2504.08736 {{< /keyword >}}
{{< keyword icon="writer" >}} Tianwei Xiong et el. {{< /keyword >}}
 
{{< keyword >}} ü§ó 2025-04-14 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2504.08736" target="_self" >}}
‚Üó arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2504.08736" target="_self" >}}
‚Üó Hugging Face
{{< /button >}}



<audio controls>
    <source src="https://ai-paper-reviewer.com/2504.08736/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

In autoregressive (AR) image generation, visual tokenizers compress images into compact discrete latent tokens, enabling efficient training. Scaling visual tokenizers improves image reconstruction quality, but often degrades downstream generation quality. This challenge is not adequately addressed. Thus, there exists a reconstruction vs. generation dilemma, where scaling tokenizer improves reconstruction fidelity but degrades downstream generation quality.



To address this, GigaTok introduces **semantic regularization**, which aligns tokenizer features with pre-trained visual encoder features. This constraint prevents excessive latent space complexity during scaling, improving both reconstruction and generation. Building on it, GigaTok explores key practices for scaling tokenizers: 1D tokenizers, decoder scaling, and entropy loss. Scaling to **3 billion parameters**, GigaTok achieves state-of-the-art performance.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} Semantic regularization mitigates the reconstruction vs. generation dilemma. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} Asymmetric encoder-decoder scaling and entropy loss are key to scaling tokenizers to billions of parameters. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} GigaTok achieves state-of-the-art results in image reconstruction, generation, and representation learning. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This paper introduces **GigaTok, a groundbreaking approach to scaling visual tokenizers** that overcomes a critical limitation in autoregressive image generation. It will help researchers **develop more effective image generation models** by addressing the trade-off between reconstruction and generation quality, enabling better understanding and future work.

------
#### Visual Insights



![](https://arxiv.org/html/2504.08736/x1.png)

> üîº This figure illustrates the trade-off between reconstruction quality and downstream autoregressive (AR) generation performance when scaling visual tokenizers.  The left panel shows that simply increasing the size of the visual tokenizer improves reconstruction fidelity (lower rFID score), as measured by the quality of reconstructed images. However, the right panel demonstrates that this naive scaling negatively impacts the quality of images generated by the downstream AR model (higher gFID score).  This is known as the 'reconstruction vs. generation dilemma.' In contrast, GigaTok, the proposed method in the paper, simultaneously improves both reconstruction and generation quality as the tokenizer size increases, showcasing the effectiveness of its approach.
> <details>
> <summary>read the caption</summary>
> Figure 1: Reconstruction vs. generation dilemma: Naively scaling visual tokenizers achieves better reconstruction but degrades downstream autoregressive (AR) generation. In contrast, GigaTok achieves better performance for both reconstruction and generation as tokenizers scale up.
> </details>





{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S4.T1.2.1.1.1"><span class="ltx_text" id="S4.T1.2.1.1.1.1" style="font-size:90%;">Type</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt" id="S4.T1.2.1.1.2"><span class="ltx_text" id="S4.T1.2.1.1.2.1" style="font-size:90%;">Enc./Dec.</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T1.2.1.1.3"><span class="ltx_text" id="S4.T1.2.1.1.3.1" style="font-size:90%;">Params.</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T1.2.1.1.4"><span class="ltx_text" id="S4.T1.2.1.1.4.1" style="font-size:90%;">Blocks</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T1.2.1.1.5"><span class="ltx_text" id="S4.T1.2.1.1.5.1" style="font-size:90%;">Heads</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T1.2.1.1.6"><span class="ltx_text" id="S4.T1.2.1.1.6.1" style="font-size:90%;">Dim.</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2.2">
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T1.2.2.2.1" rowspan="5"><span class="ltx_text" id="S4.T1.2.2.2.1.1" style="font-size:90%;">1D Tok.</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T1.2.2.2.2"><span class="ltx_text" id="S4.T1.2.2.2.2.1" style="font-size:90%;">S</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.2.2.3"><span class="ltx_text" id="S4.T1.2.2.2.3.1" style="font-size:90%;">26M</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.2.2.4"><span class="ltx_text" id="S4.T1.2.2.2.4.1" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.2.2.5"><span class="ltx_text" id="S4.T1.2.2.2.5.1" style="font-size:90%;">8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.2.2.6"><span class="ltx_text" id="S4.T1.2.2.2.6.1" style="font-size:90%;">512</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.3.3">
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T1.2.3.3.1"><span class="ltx_text" id="S4.T1.2.3.3.1.1" style="font-size:90%;">B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.3.3.2"><span class="ltx_text" id="S4.T1.2.3.3.2.1" style="font-size:90%;">115M</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.3.3.3"><span class="ltx_text" id="S4.T1.2.3.3.3.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.3.3.4"><span class="ltx_text" id="S4.T1.2.3.3.4.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.3.3.5"><span class="ltx_text" id="S4.T1.2.3.3.5.1" style="font-size:90%;">768</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.4.4">
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T1.2.4.4.1"><span class="ltx_text" id="S4.T1.2.4.4.1.1" style="font-size:90%;">L</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.4.2"><span class="ltx_text" id="S4.T1.2.4.4.2.1" style="font-size:90%;">405M</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.4.3"><span class="ltx_text" id="S4.T1.2.4.4.3.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.4.4"><span class="ltx_text" id="S4.T1.2.4.4.4.1" style="font-size:90%;">16</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.4.5"><span class="ltx_text" id="S4.T1.2.4.4.5.1" style="font-size:90%;">1024</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.5.5">
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T1.2.5.5.1"><span class="ltx_text" id="S4.T1.2.5.5.1.1" style="font-size:90%;">XL</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.5.2"><span class="ltx_text" id="S4.T1.2.5.5.2.1" style="font-size:90%;">948M</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.5.3"><span class="ltx_text" id="S4.T1.2.5.5.3.1" style="font-size:90%;">36</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.5.4"><span class="ltx_text" id="S4.T1.2.5.5.4.1" style="font-size:90%;">20</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.5.5"><span class="ltx_text" id="S4.T1.2.5.5.5.1" style="font-size:90%;">1280</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.6.6">
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T1.2.6.6.1"><span class="ltx_text" id="S4.T1.2.6.6.1.1" style="font-size:90%;">XXL</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.6.6.2"><span class="ltx_text" id="S4.T1.2.6.6.2.1" style="font-size:90%;">1870M</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.6.6.3"><span class="ltx_text" id="S4.T1.2.6.6.3.1" style="font-size:90%;">48</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.6.6.4"><span class="ltx_text" id="S4.T1.2.6.6.4.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.6.6.5"><span class="ltx_text" id="S4.T1.2.6.6.5.1" style="font-size:90%;">1536</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.7.7">
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t" id="S4.T1.2.7.7.1" rowspan="3"><span class="ltx_text" id="S4.T1.2.7.7.1.1" style="font-size:90%;">2D Tok.</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T1.2.7.7.2"><span class="ltx_text" id="S4.T1.2.7.7.2.1" style="font-size:90%;">S</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.7.7.3"><span class="ltx_text" id="S4.T1.2.7.7.3.1" style="font-size:90%;">19M</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.7.7.4"><span class="ltx_text" id="S4.T1.2.7.7.4.1" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.7.7.5"><span class="ltx_text" id="S4.T1.2.7.7.5.1" style="font-size:90%;">8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.7.7.6"><span class="ltx_text" id="S4.T1.2.7.7.6.1" style="font-size:90%;">512</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.8.8">
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T1.2.8.8.1"><span class="ltx_text" id="S4.T1.2.8.8.1.1" style="font-size:90%;">B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.8.2"><span class="ltx_text" id="S4.T1.2.8.8.2.1" style="font-size:90%;">86M</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.8.3"><span class="ltx_text" id="S4.T1.2.8.8.3.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.8.4"><span class="ltx_text" id="S4.T1.2.8.8.4.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.8.5"><span class="ltx_text" id="S4.T1.2.8.8.5.1" style="font-size:90%;">768</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.9.9">
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T1.2.9.9.1"><span class="ltx_text" id="S4.T1.2.9.9.1.1" style="font-size:90%;">L</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.9.9.2"><span class="ltx_text" id="S4.T1.2.9.9.2.1" style="font-size:90%;">329M</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.9.9.3"><span class="ltx_text" id="S4.T1.2.9.9.3.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.9.9.4"><span class="ltx_text" id="S4.T1.2.9.9.4.1" style="font-size:90%;">16</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.9.9.5"><span class="ltx_text" id="S4.T1.2.9.9.5.1" style="font-size:90%;">1024</span></td>
</tr>
</tbody>
</table>{{< /table-caption >}}

> üîº This table details the architectures of the transformer models used in the GigaTok experiments for both 1D and 2D visual tokenizers.  It shows the specific configurations of the encoders and decoders, including the number of parameters, blocks, heads, and the dimensionality of the features.  The choice of either Q-Former or ViT architecture for the transformer components is also specified, depending on whether a 1D or 2D tokenizer is used. This information is crucial for understanding the design choices and scalability aspects of the different visual tokenizer variations.
> <details>
> <summary>read the caption</summary>
> Table 1: Architectures of the transformer variants for tokenizer encoder/decoder parts in our experiments. We use Q-Former¬†[34, 6] for 1D tokenizers and ViT¬†[13] for 2D tokenizers.
> </details>





### In-depth insights


#### AR Probing Proxy
The concept of an 'AR Probing Proxy' is intriguing; it suggests using a smaller, more computationally efficient autoregressive (AR) model to **assess the capabilities and characteristics of a larger visual tokenizer**. This approach is valuable because training and evaluating large-scale AR models can be prohibitively expensive. The proxy acts as a stand-in, providing insights into how well the tokenizer's output can be learned and utilized by a generative model, allowing for **quicker iteration and experimentation**. The core idea relies on the assumption that the performance trends observed with the probing proxy will correlate with those of larger AR models. If the correlation is strong, the probing proxy becomes a valuable tool for **evaluating different tokenizer architectures, training strategies, and hyperparameters** without incurring the full cost of training larger models.

#### Semantic Regularize
**Semantic regularization** addresses a key challenge in scaling visual tokenizers: the increasing complexity of the latent space, which degrades downstream generation despite improved reconstruction. The core idea involves aligning tokenizer features with semantically consistent features extracted from a pre-trained visual encoder (e.g., DINOv2). This alignment acts as a constraint, preventing the tokenizer from learning overly intricate or spurious relationships in the latent space that hinder effective generative modeling. By encouraging semantic consistency, the **latent space becomes more structured and learnable** for downstream autoregressive models, leading to improvements in both reconstruction fidelity (preserving essential visual information) and generation quality (producing realistic and coherent images). Effectively, it guides the tokenizer to focus on encoding meaningful semantic features rather than low-level details, thus mitigating the reconstruction vs. generation dilemma by ensuring a more compact and expressive latent representation.

#### Scale Asymmetric
**Asymmetric scaling** refers to a non-uniform allocation of resources, like parameters, to different parts of a model. In the context of visual tokenizers, this often means **prioritizing the decoder over the encoder**.  The rationale is that the decoder has a more complex task which is reconstructing an image from lossy, discrete codes.  Scaling the decoder can better preserve image details and reduce artifacts. Scaling the encoder and decoder together will lead to improvements.

#### Entropy Stabilize
**Entropy stabilization** is a crucial technique to ensure effective training, particularly when scaling models. Large models often struggle with convergence due to underutilized capacity. Introducing an entropy loss encourages greater diversity in the learned representations, preventing collapse into a limited set of features. This promotes **better codebook usage** and a more stable training process, ultimately leading to improved model performance and generalization. By penalizing certainty and rewarding even distribution, the model is pushed to explore the feature space more fully.

#### Data Scaling Future
**Data scaling** presents an intriguing future for visual tokenizers, where increasing the amount of data can potentially mitigate the reconstruction vs. generation dilemma. As observed in the paper, extending the training duration doesn't always lead to better generation quality, hinting at the model's struggle to capture complex data patterns. **Scaling the dataset size** might offer a solution by exposing the tokenizer to a more diverse range of visual information, allowing it to learn more robust and generalized features. This could help the model avoid overfitting to specific details and, in turn, improve its ability to generate high-quality images. However, the paper notes this as a hypothesis, suggesting further exploration to validate the benefits of data scaling.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2504.08736/x2.png)

> üîº This figure showcases the state-of-the-art (SOTA) results achieved by GigaTok, a 2.9 billion parameter visual tokenizer, when used in conjunction with a 1.4 billion parameter autoregressive (AR) model.  The impressive image generation quality is demonstrated on the ImageNet dataset at 256x256 resolution. The image samples shown highlight the diversity and realism of the generated images. This figure visually emphasizes the significant improvement in autoregressive image generation resulting from GigaTok's substantial scale.
> <details>
> <summary>read the caption</summary>
> Figure 2:  The 2.9B GigaTok achieves SOTA autoregressive image generation with a 1.4B AR model on ImageNet 256√ó\times√ó256 resolution.
> </details>



![](https://arxiv.org/html/2504.08736/x3.png)

> üîº This figure demonstrates the challenges of simply increasing the size of visual tokenizers in autoregressive image generation.  While larger tokenizers improve the reconstruction quality (as measured by rFID), the downstream performance of the autoregressive generation model suffers. This is shown by the increasing gFID (lower is better), suggesting a more complex latent space that the generation model struggles to learn.  The increased validation loss from AR Probing further supports this finding, showing that the model has difficulty learning effective token distributions from the larger, more complex tokenizer.
> <details>
> <summary>read the caption</summary>
> Figure 3: Scaling trend for vanilla 1D tokenizers. As the model size increases, the reconstruction quality of vanilla tokenizers improves but the downstream AR Probing gFID consistently degrades. The increasing AR Probing validation loss indicates that scaling vanilla tokenizers results in a more complex latent space, making it difficult for AR models to learn effectively.
> </details>



![](https://arxiv.org/html/2504.08736/x4.png)

> üîº This figure illustrates the architecture of GigaTok, a visual tokenizer, and its incorporation of semantic regularization.  The top half shows the hybrid CNN-Transformer structure of GigaTok.  The CNN layers initially process the image, followed by Transformer layers which are implemented using the Vision Transformer (ViT) architecture for 2D tokenizers and the Q-Former architecture for 1D tokenizers. The Transformer layers handle the encoding of the image into discrete latent tokens. The bottom half of the figure demonstrates how semantic regularization is applied.  A pre-trained DINOv2 image encoder (frozen weights) provides semantic features. These features are compared to the features learned by the GigaTok tokenizer's decoder, guiding the training to ensure that the latent representation generated by the tokenizer is semantically consistent and meaningful.
> <details>
> <summary>read the caption</summary>
> Figure 4: GigaTok architecture and semantic regularization. Top: We use a hybrid CNN-Transformer design for our visual tokenizer. The transformer layers are implemented with ViT for 2D tokenizer and Q-Former for 1D tokenizer. Bottom: We use a frozen DINOv2¬†[43] image encoder for semantic regularization.
> </details>



![](https://arxiv.org/html/2504.08736/x5.png)

> üîº This figure displays training curves for two large-scale visual tokenizers (XL and XXL) with 2.9 billion parameters each.  The training curves show the behavior of the perceptual loss and codebook usage. These curves are presented separately for experiments run with and without entropy loss. The results demonstrate that the 2.9B parameter tokenizer fails to converge without entropy loss.  However, the introduction of entropy loss effectively addresses this issue, leading to the convergence of both perceptual loss and codebook usage and stabilizes the training process.
> <details>
> <summary>read the caption</summary>
> Figure 5: Training curves for 2.9B XL-XXL tokenizers with and without entropy loss. A 2.9B tokenizer does not converge without entropy loss. The entropy loss encourages high codebook usage and stabilizes training loss.
> </details>



![](https://arxiv.org/html/2504.08736/x6.png)

> üîº This figure demonstrates the strong correlation between the performance of a lightweight AR probing model and larger, more computationally expensive AR models when evaluating the impact of different visual tokenizers. Three tokenizer sizes (S-S, S-L, and B-L) were used to train both the probing model and the larger AR models.  The results show that as the quality of the tokenizer increases (e.g., improved reconstruction fidelity), the probing model shows corresponding improvements (lower gFID and higher linear probing accuracy). Crucially, these improvements in the probing model mirror the trends observed in the larger AR models, confirming that the probing model accurately reflects the impact of the tokenizer on downstream generation. This establishes AR probing as an efficient method for evaluating tokenizers, as it avoids the high computational cost of training and evaluating large-scale AR models for each tokenizer variant.
> <details>
> <summary>read the caption</summary>
> Figure 6: Correlation between AR Probing Performance and Larger AR models. For 3 tokenizers: S-S, S-L, and B-L, we present that as the tokenizer improves, the performance improvements of AR Probing correlate to the performance improvements of larger AR models. Therefore, the AR Probing can effectively indicate how the tokenizer affects downstream larger AR models with limited computational costs.
> </details>



![](https://arxiv.org/html/2504.08736/x7.png)

> üîº This figure displays a comparison of scaling trends for visual tokenizers with and without semantic regularization.  The graphs show how various metrics (rFID for reconstruction quality, gFID for downstream AR generation quality, and linear probing accuracy for representation quality) change as the number of parameters in the tokenizer increases.  The results demonstrate that naive scaling without semantic regularization leads to a trade-off between better reconstruction and worse generation (the 'reconstruction vs. generation dilemma').  In contrast, GigaTok, which incorporates semantic regularization, consistently improves across all three metrics as the tokenizer scales up, showing a significant enhancement in both reconstruction and generation performance.
> <details>
> <summary>read the caption</summary>
> Figure 7: Scaling trends of tokenizers for reconstruction, downstream generation and representation quality with and without semantic regularization. By semantic regularization, GigaTok resolves the reconstruction vs. generation dilemma for tokenizer scaling in contrast to the vanilla version without semantic regularization. Moreover, GigaTok consistently improves the representation quality of downstream AR models by scaling up visual tokenizers. Note that in the last two figures, the red and blue curves correspond to different scales on the y-axis.
> </details>



![](https://arxiv.org/html/2504.08736/x8.png)

> üîº This figure visualizes the effects of semantic regularization on the latent space learned by visual tokenizers.  It uses Principal Component Analysis (PCA) to reduce the dimensionality of features extracted from a set of images depicting 'golden retrievers'. The first three principal components are then plotted, revealing the structure of the latent space. The visualization demonstrates that vanilla tokenizers (without semantic regularization) produce a less structured latent space with inconsistent features both within individual images and across similar images, hindering downstream autoregressive generation. In contrast, GigaTok, with its semantic regularization, shows a much more consistent and structured latent space, resulting in improved downstream generation due to reduced latent space complexity.
> <details>
> <summary>read the caption</summary>
> Figure 8: Visualization of tokenizer features with and without semantic regularization. We compute PCA among the tokenizer features of a group of images of the same ‚Äúgolden retriever‚Äù class and visualize the first 3 PCA components. We observe that the latent space of vanilla tokenizers shows inconsistent features both within a single image or across multiple semantically similar images. In contrast, GigaTok encodes images with semantic consistency and thus reduces the latent space complexity for AR models.
> </details>



![](https://arxiv.org/html/2504.08736/x9.png)

> üîº This figure compares the scalability of 1D and 2D tokenizers in autoregressive image generation.  Using identical training parameters, the results show that 1D tokenizers consistently achieve superior reconstruction fidelity (measured by rFID), as well as better quality of learned representations in downstream AR models (measured by linear probing accuracy).  Furthermore, while both types of tokenizers improve downstream generation quality (gFID) as model size increases, the improvement is significantly steeper for the 1D tokenizers, indicating better scalability.
> <details>
> <summary>read the caption</summary>
> Figure 9:  Scalability comparison for 1D and 2D tokenizers. Using the same training setting, 1D tokenizers shows better reconstruction¬†(rFID) and downstream representation quality¬†(AR Probing: Lin Acc.). For downstream generation¬†(gFID), 1D tokenizers present a steeper improving trend than 2D tokenizers.
> </details>



![](https://arxiv.org/html/2504.08736/x10.png)

> üîº This figure details the architecture of GigaTok, specifically highlighting the use of the Q-Former module. GigaTok uses a hybrid CNN-Transformer architecture. The encoder consists of CNN blocks that progressively downsample the input image, followed by Transformer layers and a vector quantizer to produce discrete latent codes.  The decoder mirrors this process, starting with Transformer layers and then using CNN blocks to upsample the features for image reconstruction.  The Q-Former is a key component, enabling the use of 1D tokens, improving scalability.  The diagram visually represents the flow of information through the encoder and decoder stages, emphasizing the role of the Q-Former and the generation of discrete tokens.
> <details>
> <summary>read the caption</summary>
> Figure 10: The architecture of GigaTok with Q-Former.
> </details>



![](https://arxiv.org/html/2504.08736/x11.png)

> üîº This figure illustrates how 1D queries are initialized in the Q-Former modules of GigaTok.  It depicts a multi-level average pooling strategy applied to 2D input features from the CNN encoder. At each level, the input features are divided into regions, and average pooling is performed on each region. The resulting pooled features are then flattened and concatenated from level 0 to the final level, creating the 1D query sequence for the Q-Former encoder.  During decoding, 2D queries are initialized from the 1D latent features. This process ensures a smooth transition between the 2D input features and the 1D latent representation used by the Q-Former.
> <details>
> <summary>read the caption</summary>
> Figure 11: Initialization of 1D queries in Q-Former modules.
> </details>



![](https://arxiv.org/html/2504.08736/x12.png)

> üîº Figure 12 shows the effects of increasing the training duration of visual tokenizers on reconstruction quality (rFID and LPIPS), downstream generation quality (gFID), and representation quality (linear probing accuracy).  The experiment compares results with and without semantic regularization.  The plots reveal a trade-off:  increasing training duration initially improves downstream generation but eventually degrades it, particularly when semantic regularization isn't used.  The y-axes scales differ between the last two plots (gFID and linear probing accuracy) to better visualize the trends.  The figure highlights the importance of semantic regularization for stable and effective tokenizer scaling.
> <details>
> <summary>read the caption</summary>
> Figure 12:  Training duration scaling trends of tokenizers for reconstruction, downstream generation and representation quality with and without semantic regularization. Note that in the last two figures, the red and blue curves correspond to different scales on the y-axis.
> </details>



![](https://arxiv.org/html/2504.08736/x13.png)

> üîº This figure demonstrates that the linear probing accuracy of tokenizer encoders, while useful for evaluating the encoders themselves, is not a reliable predictor of downstream model performance.  The XL-XXL tokenizer encoder shows overfitting in terms of its linear probing accuracy during training. However, despite this overfitting, the downstream model performance (as measured by other metrics) consistently improves. This indicates that there is a decoupling between the encoder's internal representation learned through linear probing, and the features it produces that actually benefit the downstream tasks.
> <details>
> <summary>read the caption</summary>
> Figure 13:  The linear probing accuracy of tokenizer encoders does not necessarily reflect downstream model performance. As the training proceeds, the XL-XXL tokenizer encoder presents an overfitting trend measured by linear probing accuracy, but downstream model performances consistently improve.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T2.4.4.5">Enc./Dec. Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1">rFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T2.2.2.2">LPIPS<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.m1.1a"><mo id="S5.T2.2.2.2.m1.1.1" stretchy="false" xref="S5.T2.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.3.3.3">gFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.m1.1a"><mo id="S5.T2.3.3.3.m1.1.1" stretchy="false" xref="S5.T2.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.4.4.4">Lin Acc.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.4.4.4.m1.1"><semantics id="S5.T2.4.4.4.m1.1a"><mo id="S5.T2.4.4.4.m1.1.1" stretchy="false" xref="S5.T2.4.4.4.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.m1.1d">‚Üë</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.4.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.4.5.1.1">B-S</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.2">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.4.5.1.3">0.221</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.4">6.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.5.1.5">64.5</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T2.4.6.2.1">S-B</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.2.2">0.94</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.4.6.2.3">0.214</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.2.4">5.65</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.2.5">59.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.7.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T2.4.7.3.1">S-L</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.7.3.2">0.83</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.4.7.3.3">0.206</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.7.3.4">5.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.7.3.5">60.6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.8.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T2.4.8.4.1">B-L</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.8.4.2">0.81</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T2.4.8.4.3">0.206</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.8.4.4">4.82</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.8.4.5">66.9</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents an ablation study on the impact of scaling the encoder and decoder components of the GigaTok visual tokenizer on downstream autoregressive (AR) generation performance.  It compares different scaling strategies: scaling only the decoder (S-B), scaling only the encoder (B-S), and scaling both the encoder and decoder (S-L and B-L).  The results show that focusing on decoder scaling leads to more significant improvements in downstream AR generation quality, compared to encoder-only scaling. However, it also highlights that even scaling encoders, while less effective than decoder-only scaling, does produce notable improvements in downstream generation.
> <details>
> <summary>read the caption</summary>
> Table 2: The results for scaling encoder/decoder. Prioritizing the scaling of decoders benefits downstream generation more than scaling encoders¬†(S-B v.s. B-S). But scaling encoders can still bring significant improvements¬†(S-L v.s. B-L).
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.19">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.3.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.3.3.4">Tokenizer</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T3.3.3.5">Tok. Type/Param.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.3.3.6">#Tokens</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.1.1.1">rFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.m1.1.1" stretchy="false" xref="S5.T3.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">‚Üì</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T3.3.3.7">Generator Model/Param.</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T3.3.3.8">Type</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.2.2.2">gFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.m1.1a"><mo id="S5.T3.2.2.2.m1.1.1" stretchy="false" xref="S5.T3.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><ci id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt" id="S5.T3.3.3.3">Acc.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.m1.1a"><mo id="S5.T3.3.3.3.m1.1.1" stretchy="false" xref="S5.T3.3.3.3.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.m1.1b"><ci id="S5.T3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.m1.1d">‚Üë</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.20.1">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S5.T3.19.20.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T3.19.20.1.1.1">Continuous token modeling</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.4.4.2">VAE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="S5.T3.4.4.1">KL<sup class="ltx_sup" id="S5.T3.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.4.4.1.1.1">‚Ä†</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.4.4.3">55M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.4.4">4096</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.4.4.5">0.27</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.4.4.6">LDM-4¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.4.4.7">400M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.4.4.8">Diff.</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.4.4.9">3.60</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T3.4.4.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.5">
<td class="ltx_td ltx_align_left" id="S5.T3.5.5.2" rowspan="3"><span class="ltx_text" id="S5.T3.5.5.2.1">SD-VAE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.5.5.1" rowspan="3"><span class="ltx_text" id="S5.T3.5.5.1.1">KL<sup class="ltx_sup" id="S5.T3.5.5.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.5.5.1.1.1.1">‚Ä†</span></sup></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.5.5.3" rowspan="3"><span class="ltx_text" id="S5.T3.5.5.3.1">84M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.4" rowspan="3"><span class="ltx_text" id="S5.T3.5.5.4.1">1024</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.5.5.5" rowspan="3"><span class="ltx_text" id="S5.T3.5.5.5.1">0.62</span></td>
<td class="ltx_td ltx_align_left" id="S5.T3.5.5.6">DiT-XL/2¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.5.5.7">675M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.5.5.8">Diff.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.5.5.9">2.27</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.5.5.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.21.2">
<td class="ltx_td ltx_align_left" id="S5.T3.19.21.2.1">SiT-XL/2¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.21.2.2">675M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.21.2.3">Diff.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.21.2.4">2.06</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.21.2.5">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.22.3">
<td class="ltx_td ltx_align_left" id="S5.T3.19.22.3.1">SiT-XL/2 + REPA¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">70</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.22.3.2">675M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.22.3.3">Diff.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.22.3.4">1.42</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.22.3.5">74.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.23.4">
<td class="ltx_td ltx_align_left" id="S5.T3.19.23.4.1">VA-VAE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.23.4.2">KL</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.23.4.3">70M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.23.4.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.23.4.5">0.28</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.23.4.6">LightningDiT¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.23.4.7">675M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.23.4.8">Diff.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.23.4.9">1.35</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.23.4.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6">
<td class="ltx_td ltx_align_left" id="S5.T3.6.6.2">VAE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.6.6.3">KL</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.6.6.4">66M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.6.6.5">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.6.6.6">0.53</td>
<td class="ltx_td ltx_align_left" id="S5.T3.6.6.7">MAR-H¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.6.6.8">943M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.6.6.9">AR+Diff.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.6.6.10">1.55</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.6.6.1">60.0<sup class="ltx_sup" id="S5.T3.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.6.6.1.1.1">‚ãÑ</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.24.5">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S5.T3.19.24.5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T3.19.24.5.1.1">Discrete token modeling</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.7.7.2">VQGAN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="S5.T3.7.7.3">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.7.7.4">66M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.7.7.5">256</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.7.7.6">2.28</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.7.7.7">MaskGIT¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.7.7.8">227M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.7.7.9">Mask.</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.7.7.1">6.18<sup class="ltx_sup" id="S5.T3.7.7.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.7.7.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T3.7.7.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.25.6">
<td class="ltx_td ltx_align_left" id="S5.T3.19.25.6.1">TiTok-S¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib69" title=""><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.25.6.2">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.25.6.3">72M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.25.6.4">128</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.25.6.5">1.71</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.25.6.6">MaskGIT-UViT-L ¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.25.6.7">287M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.25.6.8">Mask.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.25.6.9">1.97</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.25.6.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.26.7">
<td class="ltx_td ltx_align_left" id="S5.T3.19.26.7.1">TiTok-L¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib69" title=""><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.26.7.2">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.26.7.3">641M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.26.7.4">32</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.26.7.5">2.21</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.26.7.6">MaskGIT-ViT ¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.26.7.7">177M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.26.7.8">Mask.</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.26.7.9">2.77</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.26.7.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.27.8">
<td class="ltx_td ltx_align_left" id="S5.T3.19.27.8.1" rowspan="2"><span class="ltx_text" id="S5.T3.19.27.8.1.1">B-AE-d32¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.27.8.2" rowspan="2"><span class="ltx_text" id="S5.T3.19.27.8.2.1">LFQ</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.27.8.3" rowspan="2"><span class="ltx_text" id="S5.T3.19.27.8.3.1">66M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.27.8.4" rowspan="2"><span class="ltx_text" id="S5.T3.19.27.8.4.1">256</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.27.8.5" rowspan="2"><span class="ltx_text" id="S5.T3.19.27.8.5.1">1.69</span></td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.27.8.6">BiGR-XXL-d32¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.27.8.7">1.5B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.27.8.8">AR+Diff</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.27.8.9">2.36</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.27.8.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.28.9">
<td class="ltx_td ltx_align_left" id="S5.T3.19.28.9.1">BiGR-XL-d32¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.28.9.2">799M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.28.9.3">AR+Diff</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.28.9.4">-</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.28.9.5">69.8</td>
</tr>
<tr class="ltx_tr" id="S5.T3.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.10.10.4" rowspan="2"><span class="ltx_text" id="S5.T3.10.10.4.1">VAR-Tok.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="S5.T3.8.8.1" rowspan="2"><span class="ltx_text" id="S5.T3.8.8.1.1">MSRQ<sup class="ltx_sup" id="S5.T3.8.8.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.8.8.1.1.1.1">‚Ä†</span></sup></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.10.10.5" rowspan="2"><span class="ltx_text" id="S5.T3.10.10.5.1">109M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.10.10.6" rowspan="2"><span class="ltx_text" id="S5.T3.10.10.6.1">680</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.9.9.2" rowspan="2"><span class="ltx_text" id="S5.T3.9.9.2.1">1.00<sup class="ltx_sup" id="S5.T3.9.9.2.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.9.9.2.1.1.1">‚Ä°</span></sup></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.10.10.3">VAR-<math alttext="d24" class="ltx_Math" display="inline" id="S5.T3.10.10.3.m1.1"><semantics id="S5.T3.10.10.3.m1.1a"><mrow id="S5.T3.10.10.3.m1.1.1" xref="S5.T3.10.10.3.m1.1.1.cmml"><mi id="S5.T3.10.10.3.m1.1.1.2" xref="S5.T3.10.10.3.m1.1.1.2.cmml">d</mi><mo id="S5.T3.10.10.3.m1.1.1.1" xref="S5.T3.10.10.3.m1.1.1.1.cmml">‚Å¢</mo><mn id="S5.T3.10.10.3.m1.1.1.3" xref="S5.T3.10.10.3.m1.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.3.m1.1b"><apply id="S5.T3.10.10.3.m1.1.1.cmml" xref="S5.T3.10.10.3.m1.1.1"><times id="S5.T3.10.10.3.m1.1.1.1.cmml" xref="S5.T3.10.10.3.m1.1.1.1"></times><ci id="S5.T3.10.10.3.m1.1.1.2.cmml" xref="S5.T3.10.10.3.m1.1.1.2">ùëë</ci><cn id="S5.T3.10.10.3.m1.1.1.3.cmml" type="integer" xref="S5.T3.10.10.3.m1.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.3.m1.1c">d24</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.10.3.m1.1d">italic_d 24</annotation></semantics></math>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.10.10.7">1.0B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.10.10.8">VAR</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.10.10.9">2.09</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T3.10.10.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.11.11">
<td class="ltx_td ltx_align_left" id="S5.T3.11.11.1">VAR-<math alttext="d30" class="ltx_Math" display="inline" id="S5.T3.11.11.1.m1.1"><semantics id="S5.T3.11.11.1.m1.1a"><mrow id="S5.T3.11.11.1.m1.1.1" xref="S5.T3.11.11.1.m1.1.1.cmml"><mi id="S5.T3.11.11.1.m1.1.1.2" xref="S5.T3.11.11.1.m1.1.1.2.cmml">d</mi><mo id="S5.T3.11.11.1.m1.1.1.1" xref="S5.T3.11.11.1.m1.1.1.1.cmml">‚Å¢</mo><mn id="S5.T3.11.11.1.m1.1.1.3" xref="S5.T3.11.11.1.m1.1.1.3.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.1.m1.1b"><apply id="S5.T3.11.11.1.m1.1.1.cmml" xref="S5.T3.11.11.1.m1.1.1"><times id="S5.T3.11.11.1.m1.1.1.1.cmml" xref="S5.T3.11.11.1.m1.1.1.1"></times><ci id="S5.T3.11.11.1.m1.1.1.2.cmml" xref="S5.T3.11.11.1.m1.1.1.2">ùëë</ci><cn id="S5.T3.11.11.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.11.11.1.m1.1.1.3">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.1.m1.1c">d30</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.11.1.m1.1d">italic_d 30</annotation></semantics></math>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.11.11.2">2.0B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.11.11.3">VAR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.11.11.4">1.92</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.11.11.5">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.12.12">
<td class="ltx_td ltx_align_left" id="S5.T3.12.12.2">ImageFolder¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.12.12.3">MSRQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.12.12.4">176M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.12.12.5">286</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.12.12.1">0.80<sup class="ltx_sup" id="S5.T3.12.12.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.12.12.1.1.1">‚Ä°</span></sup>
</td>
<td class="ltx_td ltx_align_left" id="S5.T3.12.12.6">ImageFolder-VAR¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.12.12.7">362M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.12.12.8">VAR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.12.12.9">2.60</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.12.12.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.13.13">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.13.13.2">VQGAN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="S5.T3.13.13.3">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.13.13.4">23M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.13.13.5">256</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.13.13.6">4.98</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.13.13.7">Taming-Tran.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.13.13.8">1.4B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.13.13.9">AR</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.13.13.1">15.78<sup class="ltx_sup" id="S5.T3.13.13.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.13.13.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T3.13.13.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.14.14">
<td class="ltx_td ltx_align_left" id="S5.T3.14.14.2">ViT-VQGAN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib65" title=""><span class="ltx_text" style="font-size:90%;">65</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.14.14.3">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.14.14.4">64M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.14.14.5">1024</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.14.14.6">1.28</td>
<td class="ltx_td ltx_align_left" id="S5.T3.14.14.7">VIM-Large¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib65" title=""><span class="ltx_text" style="font-size:90%;">65</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.14.14.8">1.7B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.14.14.9">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.14.14.1">4.17<sup class="ltx_sup" id="S5.T3.14.14.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.14.14.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.14.14.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.15.15">
<td class="ltx_td ltx_align_left" id="S5.T3.15.15.2">RQ-VAE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.15.15.3">RQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.15.15.4">66M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.15.15.5">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.15.15.6">3.20</td>
<td class="ltx_td ltx_align_left" id="S5.T3.15.15.7">RQTran.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.15.15.8">3.8B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.15.15.9">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.15.15.1">7.55<sup class="ltx_sup" id="S5.T3.15.15.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.15.15.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.15.15.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.29.10">
<td class="ltx_td ltx_align_left" id="S5.T3.19.29.10.1">Open-MAGVIT2¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.29.10.2">LFQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.29.10.3">133M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.29.10.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.29.10.5">1.17</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.29.10.6">Open-MAGVIT2-XL¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.29.10.7">1.5B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.29.10.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.29.10.9">2.53</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.29.10.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.30.11">
<td class="ltx_td ltx_align_left" id="S5.T3.19.30.11.1">IBQ¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.30.11.2">IBQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.30.11.3">128M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.30.11.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.30.11.5">1.37</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.30.11.6">IBQ-XXL¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.30.11.7">2.1B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.30.11.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.30.11.9">2.05</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.30.11.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.16.16">
<td class="ltx_td ltx_align_left" id="S5.T3.16.16.2" rowspan="2"><span class="ltx_text" id="S5.T3.16.16.2.1">LlamaGen-Tok.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.16.16.3" rowspan="2"><span class="ltx_text" id="S5.T3.16.16.3.1">VQ</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.16.16.4" rowspan="2"><span class="ltx_text" id="S5.T3.16.16.4.1">72M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.16.16.5" rowspan="2"><span class="ltx_text" id="S5.T3.16.16.5.1">256</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.16.16.6" rowspan="2"><span class="ltx_text" id="S5.T3.16.16.6.1">2.19</span></td>
<td class="ltx_td ltx_align_left" id="S5.T3.16.16.7">LlamaGen-L¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.16.16.8">343M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.16.16.9">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.16.16.10">3.81</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.16.16.1">40.5<sup class="ltx_sup" id="S5.T3.16.16.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.16.16.1.1.1">‚ãÑ</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.31.12">
<td class="ltx_td ltx_align_left" id="S5.T3.19.31.12.1">LlamaGen-XXL¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.31.12.2">1.4B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.31.12.3">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.31.12.4">3.09</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.31.12.5">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.32.13">
<td class="ltx_td ltx_align_left" id="S5.T3.19.32.13.1">LlamaGen-Tok.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.32.13.2">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.32.13.3">72M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.32.13.4">576</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.32.13.5">0.94</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.32.13.6">LlamaGen-XXL¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.32.13.7">1.4B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.32.13.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.32.13.9">2.34</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.32.13.10">-</td>
</tr>
<tr class="ltx_tr" id="S5.T3.17.17">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.17.17.2">GigaTok-B-L</td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="S5.T3.17.17.3">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.17.17.4">622M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.17.17.5">256</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.17.17.1">0.51<sup class="ltx_sup" id="S5.T3.17.17.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.17.17.1.1.1">‚Ä°</span></sup>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.17.17.6">LlamaGen-B¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T3.17.17.7">111M</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T3.17.17.8">AR</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.17.17.9">3.33</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T3.17.17.10">67.7</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.33.14">
<td class="ltx_td ltx_align_left" id="S5.T3.19.33.14.1">GigaTok-S-S</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.33.14.2">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.33.14.3">136M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.33.14.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.33.14.5">1.01</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.33.14.6">LlamaGen-B¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.33.14.7">111M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.33.14.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.33.14.9">4.05</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.33.14.10">62.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.34.15">
<td class="ltx_td ltx_align_left" id="S5.T3.19.34.15.1">GigaTok-S-B</td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.34.15.2">VQ</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.34.15.3">232M</td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.34.15.4">256</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.34.15.5">0.89</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.34.15.6">LlamaGen-B¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.34.15.7">111M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.34.15.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.34.15.9">3.83</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.34.15.10">62.9</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.35.16">
<td class="ltx_td ltx_align_left" id="S5.T3.19.35.16.1" rowspan="2"><span class="ltx_text" id="S5.T3.19.35.16.1.1">GigaTok-B-L</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="S5.T3.19.35.16.2" rowspan="2"><span class="ltx_text" id="S5.T3.19.35.16.2.1">VQ</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.35.16.3" rowspan="2"><span class="ltx_text" id="S5.T3.19.35.16.3.1">622M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.19.35.16.4" rowspan="2"><span class="ltx_text" id="S5.T3.19.35.16.4.1">256</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.19.35.16.5" rowspan="2"><span class="ltx_text" id="S5.T3.19.35.16.5.1">0.81</span></td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.35.16.6">LlamaGen-B¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.35.16.7">111M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.35.16.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.35.16.9">3.26</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.35.16.10">67.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.18.18">
<td class="ltx_td ltx_align_left" id="S5.T3.18.18.2">LlamaGen-XXL¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.18.18.3">1.4B</td>
<td class="ltx_td ltx_align_right" id="S5.T3.18.18.4">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.18.18.1">2.03<sup class="ltx_sup" id="S5.T3.18.18.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.18.18.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.18.18.5">69.4</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.36.17">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.19.36.17.1" rowspan="2"><span class="ltx_text" id="S5.T3.19.36.17.1.1">GigaTok-XL-XXL</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb" id="S5.T3.19.36.17.2" rowspan="2"><span class="ltx_text" id="S5.T3.19.36.17.2.1">VQ</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T3.19.36.17.3" rowspan="2"><span class="ltx_text" id="S5.T3.19.36.17.3.1">2.9B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.19.36.17.4" rowspan="2"><span class="ltx_text" id="S5.T3.19.36.17.4.1">256</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T3.19.36.17.5" rowspan="2"><span class="ltx_text" id="S5.T3.19.36.17.5.1">0.79</span></td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.36.17.6">LlamaGen-B¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T3.19.36.17.7">111M</td>
<td class="ltx_td ltx_align_right" id="S5.T3.19.36.17.8">AR</td>
<td class="ltx_td ltx_align_left" id="S5.T3.19.36.17.9">3.15</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T3.19.36.17.10">72.0</td>
</tr>
<tr class="ltx_tr" id="S5.T3.19.19">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.19.19.2">LlamaGen-XXL¬†(1d)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T3.19.19.3">1.4B</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T3.19.19.4">AR</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T3.19.19.1">1.98<sup class="ltx_sup" id="S5.T3.19.19.1.1"><span class="ltx_text ltx_font_italic" id="S5.T3.19.19.1.1.1">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="S5.T3.19.19.5">74.0</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents a comparison of different visual tokenizers and their corresponding autoregressive (AR) image generation models on the ImageNet 256x256 dataset.  It compares performance metrics for various methods, including both continuous and discrete tokenization approaches.  The metrics shown include reconstruction fidelity (rFID), generation quality (gFID), and downstream AR model accuracy.  Specific details are provided on training data sources, the type of AR model used, and whether classifier-free guidance (CFG) was used during evaluation.  Note that some results may use additional data besides ImageNet, some use a frozen DINO discriminator, and some results are without classifier-free guidance.  Results from BiGR [22] are also included for reference.
> <details>
> <summary>read the caption</summary>
> Table 3: System-level comparison for tokenizers and downstream generation models on ImageNet 256√ó\times√ó256. For gFID, we present the lowest value between w/ or w/o CFG scenarios. ‚Ä†: Training set includes data besides ImageNet. ‚Ä°: Using frozen DINO¬†[7] for discriminator, which largely improves rFID. ‚ãÜ‚ãÜ\star‚ãÜ: Without classifier-free-guidance. ‚ãÑ‚ãÑ\diamond‚ãÑ: Data from BiGR¬†[22].
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.2.1.1.1">Decoder\AR Model Size</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.2.1.1.2">B</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.3">L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.4">XXL</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.2.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T4.2.2.1.1">B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S5.T4.2.2.1.2">3.7%</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.3">2.3%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.4">1.3%</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T4.2.3.2.1">L</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S5.T4.2.3.2.2">11.2%</th>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.3">7.0%</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.4">3.4%</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S5.T4.2.4.3.1">XXL</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S5.T4.2.4.3.2">32.4%</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.4.3.3">20.3%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.4.3.4">9.9%</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents the proportion of total inference time consumed by the tokenizer's decoding process during image generation.  The data shows that the time spent on tokenizer decoding is significantly less than the overall inference time, even when using a very large tokenizer (2.9B parameters).  Specifically, when a 2.9B parameter XLXXL tokenizer is paired with a 1.4B parameter LlamaGen-XXL autoregressive model, the tokenizer's decoding only accounts for 9.9% of the total inference time.
> <details>
> <summary>read the caption</summary>
> Table 4: Ratio of time consumptions for tokenizer decoding during image generation. When we use a 2.9B XLXXL tokenizer for a 1.4B LlamaGen-XXL AR model, the tokenizer decoding only takes 9.9% of the total inference time.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T5.1.1.1">Align. Layer <math alttext="l" class="ltx_Math" display="inline" id="S5.T5.1.1.1.m1.1"><semantics id="S5.T5.1.1.1.m1.1a"><mi id="S5.T5.1.1.1.m1.1.1" xref="S5.T5.1.1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.m1.1b"><ci id="S5.T5.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.m1.1.1">ùëô</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S5.T5.1.1.1.m1.1d">italic_l</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.2.2.2">rFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.2.2.2.m1.1"><semantics id="S5.T5.2.2.2.m1.1a"><mo id="S5.T5.2.2.2.m1.1.1" stretchy="false" xref="S5.T5.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.m1.1b"><ci id="S5.T5.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T5.3.3.3">LPIPS<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.3.3.3.m1.1"><semantics id="S5.T5.3.3.3.m1.1a"><mo id="S5.T5.3.3.3.m1.1.1" stretchy="false" xref="S5.T5.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.m1.1b"><ci id="S5.T5.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.3.3.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.4.4">gFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T5.4.4.4.m1.1"><semantics id="S5.T5.4.4.4.m1.1a"><mo id="S5.T5.4.4.4.m1.1.1" stretchy="false" xref="S5.T5.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.m1.1b"><ci id="S5.T5.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.4.4.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.5.5.5">Lin Acc.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T5.5.5.5.m1.1"><semantics id="S5.T5.5.5.5.m1.1a"><mo id="S5.T5.5.5.5.m1.1.1" stretchy="false" xref="S5.T5.5.5.5.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.5.m1.1b"><ci id="S5.T5.5.5.5.m1.1.1.cmml" xref="S5.T5.5.5.5.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T5.5.5.5.m1.1d">‚Üë</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.5.6.1.1">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.6.1.2">1.06</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T5.5.6.1.3">0.224</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.6.1.4">6.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.6.1.5">63.4</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.7.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T5.5.7.2.1">3</th>
<td class="ltx_td ltx_align_center" id="S5.T5.5.7.2.2">1.01</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T5.5.7.2.3">0.223</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.7.2.4">6.10</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.7.2.5">61.9</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.8.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T5.5.8.3.1">4</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.5.8.3.2">1.07</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T5.5.8.3.3">0.223</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.5.8.3.4">6.07</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.5.8.3.5">58.6</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents an ablation study on the choice of layer (l) in the Transformer decoder for applying semantic regularization.  The study uses the S-S (small encoder, small decoder) configuration of the GigaTok tokenizer.  The results show a trade-off: using a smaller layer (l) leads to better downstream AR model representations (as measured by linear probing accuracy) because the semantic regularization focuses on lower-level features.  However, choosing a smaller layer can negatively affect reconstruction quality and downstream generation quality (gFID).  The authors choose layer 3 (l=3) as a balance between representation learning and generation performance.
> <details>
> <summary>read the caption</summary>
> Table 5: Layer lùëôlitalic_l for semantic regularization (S-S tokenizer). Smaller lùëôlitalic_l brings better downstream AR model representations but can sacrifice reconstruction and downstream generation quality. We choose lùëôlitalic_l=3 by default for more balanced performance.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T6.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T6.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T6.4.4.5">Sem. Enc.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.1.1.1">rFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.m1.1a"><mo id="S5.T6.1.1.1.m1.1.1" stretchy="false" xref="S5.T6.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.m1.1b"><ci id="S5.T6.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T6.2.2.2">LPIPS<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.2.2.2.m1.1"><semantics id="S5.T6.2.2.2.m1.1a"><mo id="S5.T6.2.2.2.m1.1.1" stretchy="false" xref="S5.T6.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.m1.1b"><ci id="S5.T6.2.2.2.m1.1.1.cmml" xref="S5.T6.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.3.3.3">gFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T6.3.3.3.m1.1"><semantics id="S5.T6.3.3.3.m1.1a"><mo id="S5.T6.3.3.3.m1.1.1" stretchy="false" xref="S5.T6.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.3.m1.1b"><ci id="S5.T6.3.3.3.m1.1.1.cmml" xref="S5.T6.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.3.3.3.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.4.4.4">Lin Acc.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T6.4.4.4.m1.1"><semantics id="S5.T6.4.4.4.m1.1a"><mo id="S5.T6.4.4.4.m1.1.1" stretchy="false" xref="S5.T6.4.4.4.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S5.T6.4.4.4.m1.1b"><ci id="S5.T6.4.4.4.m1.1.1.cmml" xref="S5.T6.4.4.4.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T6.4.4.4.m1.1d">‚Üë</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T6.4.5.1.1">CLIP-B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.5.1.2">0.91</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.4.5.1.3">0.210</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.5.1.4">6.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.5.1.5">61.4</td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S5.T6.4.6.2.1">SigLIP¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib71" title=""><span class="ltx_text" style="font-size:90%;">71</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T6.4.6.2.2">0.92</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.4.6.2.3">0.210</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.6.2.4">6.20</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.6.2.5">56.7</td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T6.4.7.3.1">DINOv2-B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.4.7.3.2">0.85</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.4.7.3.3">0.212</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.4.7.3.4">5.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.4.7.3.5">64.4</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This ablation study investigates the impact of different pre-trained semantic encoders on the performance of the S-B tokenizer.  Three different encoders, CLIP-B, SigLIP, and DINOv2-B, were evaluated. The table shows the results for rFID (reconstruction fidelity), LPIPS (perceptual similarity), gFID (generation fidelity), and linear probing accuracy for each encoder.  The results reveal that DINOv2-B outperforms CLIP-B and SigLIP in all metrics, demonstrating that the choice of pre-trained encoder significantly impacts the overall performance of the tokenizer.
> <details>
> <summary>read the caption</summary>
> Table 6: Ablation study for the choice of pretrained semantic encoders (S-B tokenizer). DINOv2-B delivers the best performance among all models.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T7.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T7.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T7.1.1.1">Sem. Reg. <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.T7.1.1.1.m1.1"><semantics id="S5.T7.1.1.1.m1.1a"><mi id="S5.T7.1.1.1.m1.1.1" xref="S5.T7.1.1.1.m1.1.1.cmml">Œª</mi><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.m1.1b"><ci id="S5.T7.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.m1.1.1">ùúÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S5.T7.1.1.1.m1.1d">italic_Œª</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.2.2.2">rFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.2.2.2.m1.1"><semantics id="S5.T7.2.2.2.m1.1a"><mo id="S5.T7.2.2.2.m1.1.1" stretchy="false" xref="S5.T7.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.2.m1.1b"><ci id="S5.T7.2.2.2.m1.1.1.cmml" xref="S5.T7.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T7.3.3.3">LPIPS<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.3.3.3.m1.1"><semantics id="S5.T7.3.3.3.m1.1a"><mo id="S5.T7.3.3.3.m1.1.1" stretchy="false" xref="S5.T7.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T7.3.3.3.m1.1b"><ci id="S5.T7.3.3.3.m1.1.1.cmml" xref="S5.T7.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.3.3.3.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.4.4.4">gFID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.4.4.4.m1.1"><semantics id="S5.T7.4.4.4.m1.1a"><mo id="S5.T7.4.4.4.m1.1.1" stretchy="false" xref="S5.T7.4.4.4.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T7.4.4.4.m1.1b"><ci id="S5.T7.4.4.4.m1.1.1.cmml" xref="S5.T7.4.4.4.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.4.4.4.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.5.5.5">Lin Acc.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.5.5.5.m1.1"><semantics id="S5.T7.5.5.5.m1.1a"><mo id="S5.T7.5.5.5.m1.1.1" stretchy="false" xref="S5.T7.5.5.5.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S5.T7.5.5.5.m1.1b"><ci id="S5.T7.5.5.5.m1.1.1.cmml" xref="S5.T7.5.5.5.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.5.5.5.m1.1d">‚Üë</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T7.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T7.5.6.1.1">0.25</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.5.6.1.2">1.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.5.6.1.3">0.226</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.5.6.1.4">6.27</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.5.6.1.5">57.0</td>
</tr>
<tr class="ltx_tr" id="S5.T7.5.7.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T7.5.7.2.1">0.50</th>
<td class="ltx_td ltx_align_center" id="S5.T7.5.7.2.2">1.22</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.5.7.2.3">0.228</td>
<td class="ltx_td ltx_align_center" id="S5.T7.5.7.2.4">6.39</td>
<td class="ltx_td ltx_align_center" id="S5.T7.5.7.2.5">58.6</td>
</tr>
<tr class="ltx_tr" id="S5.T7.5.8.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T7.5.8.3.1">0.75</th>
<td class="ltx_td ltx_align_center" id="S5.T7.5.8.3.2">1.27</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.5.8.3.3">0.236</td>
<td class="ltx_td ltx_align_center" id="S5.T7.5.8.3.4">6.29</td>
<td class="ltx_td ltx_align_center" id="S5.T7.5.8.3.5">58.6</td>
</tr>
<tr class="ltx_tr" id="S5.T7.5.9.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T7.5.9.4.1">1.00</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.5.9.4.2">1.38</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T7.5.9.4.3">0.239</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.5.9.4.4">6.27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.5.9.4.5">62.5</td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents an ablation study on the impact of varying the semantic regularization weight (Œª) in the GigaTok model, specifically using the S-S (small encoder, small decoder) tokenizer configuration.  The study examines how different Œª values affect reconstruction quality (measured by rFID and LPIPS) and downstream AR model representation quality (measured by AR probing validation loss and linear probing accuracy).  The results demonstrate a trade-off: increasing Œª improves downstream representation learning but negatively affects reconstruction performance.  Œª=0.5 was chosen for the final model as it provides a good balance between these competing factors.
> <details>
> <summary>read the caption</summary>
> Table 7: Ablation Study for the semantic regularization weight (S-S tokenizer). A strong semantic regularization weight leads to worse reconstruction but better downstream representation. We choose Œª=0.5ùúÜ0.5\lambda=0.5italic_Œª = 0.5 by default for more balanced performance.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T8.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T8.2.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T8.2.1.1.1"><span class="ltx_text" id="A2.T8.2.1.1.1.1" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T8.2.1.1.2"><span class="ltx_text" id="A2.T8.2.1.1.2.1" style="font-size:90%;">Params.</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T8.2.1.1.3"><span class="ltx_text" id="A2.T8.2.1.1.3.1" style="font-size:90%;">Blocks</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T8.2.1.1.4"><span class="ltx_text" id="A2.T8.2.1.1.4.1" style="font-size:90%;">Heads</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T8.2.1.1.5"><span class="ltx_text" id="A2.T8.2.1.1.5.1" style="font-size:90%;">Dim.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T8.2.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="A2.T8.2.2.1.1"><span class="ltx_text" id="A2.T8.2.2.1.1.1" style="font-size:90%;">B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="A2.T8.2.2.1.2"><span class="ltx_text" id="A2.T8.2.2.1.2.1" style="font-size:90%;">111M</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T8.2.2.1.3"><span class="ltx_text" id="A2.T8.2.2.1.3.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T8.2.2.1.4"><span class="ltx_text" id="A2.T8.2.2.1.4.1" style="font-size:90%;">12</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T8.2.2.1.5"><span class="ltx_text" id="A2.T8.2.2.1.5.1" style="font-size:90%;">768</span></td>
</tr>
<tr class="ltx_tr" id="A2.T8.2.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T8.2.3.2.1"><span class="ltx_text" id="A2.T8.2.3.2.1.1" style="font-size:90%;">L</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T8.2.3.2.2"><span class="ltx_text" id="A2.T8.2.3.2.2.1" style="font-size:90%;">343M</span></th>
<td class="ltx_td ltx_align_right" id="A2.T8.2.3.2.3"><span class="ltx_text" id="A2.T8.2.3.2.3.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="A2.T8.2.3.2.4"><span class="ltx_text" id="A2.T8.2.3.2.4.1" style="font-size:90%;">16</span></td>
<td class="ltx_td ltx_align_right" id="A2.T8.2.3.2.5"><span class="ltx_text" id="A2.T8.2.3.2.5.1" style="font-size:90%;">1024</span></td>
</tr>
<tr class="ltx_tr" id="A2.T8.2.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T8.2.4.3.1"><span class="ltx_text" id="A2.T8.2.4.3.1.1" style="font-size:90%;">XL</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T8.2.4.3.2"><span class="ltx_text" id="A2.T8.2.4.3.2.1" style="font-size:90%;">775M</span></th>
<td class="ltx_td ltx_align_right" id="A2.T8.2.4.3.3"><span class="ltx_text" id="A2.T8.2.4.3.3.1" style="font-size:90%;">36</span></td>
<td class="ltx_td ltx_align_right" id="A2.T8.2.4.3.4"><span class="ltx_text" id="A2.T8.2.4.3.4.1" style="font-size:90%;">20</span></td>
<td class="ltx_td ltx_align_right" id="A2.T8.2.4.3.5"><span class="ltx_text" id="A2.T8.2.4.3.5.1" style="font-size:90%;">1280</span></td>
</tr>
<tr class="ltx_tr" id="A2.T8.2.5.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="A2.T8.2.5.4.1"><span class="ltx_text" id="A2.T8.2.5.4.1.1" style="font-size:90%;">XXL</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="A2.T8.2.5.4.2"><span class="ltx_text" id="A2.T8.2.5.4.2.1" style="font-size:90%;">1.4B</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T8.2.5.4.3"><span class="ltx_text" id="A2.T8.2.5.4.3.1" style="font-size:90%;">48</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T8.2.5.4.4"><span class="ltx_text" id="A2.T8.2.5.4.4.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T8.2.5.4.5"><span class="ltx_text" id="A2.T8.2.5.4.5.1" style="font-size:90%;">1536</span></td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table details the architectures of the LlamaGen language models used in the GigaTok experiments.  For each model size (B, L, XL, XXL), it lists the number of parameters, the number of blocks, the number of heads, and the dimension of the model.  This information is crucial for understanding the scale and complexity of the downstream autoregressive models used to evaluate the performance of the GigaTok visual tokenizer.
> <details>
> <summary>read the caption</summary>
> Table 8: Architectures of the LLamaGen models in our experiments.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T9.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T9.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A3.T9.5.6.1.1"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.1.1" style="font-size:144%;">Configuration</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T9.5.6.1.2"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.2.1" style="font-size:144%;">S-S</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T9.5.6.1.3"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.3.1" style="font-size:144%;">S-B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T9.5.6.1.4"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.4.1" style="font-size:144%;">S-L</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T9.5.6.1.5"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.5.1" style="font-size:144%;">B-L</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T9.5.6.1.6"><span class="ltx_text ltx_font_bold" id="A3.T9.5.6.1.6.1" style="font-size:144%;">XL-XXL</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T9.5.7.2.1"><span class="ltx_text" id="A3.T9.5.7.2.1.1" style="font-size:144%;">Q-Former Encoder depth</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.7.2.2"><span class="ltx_text" id="A3.T9.5.7.2.2.1" style="font-size:144%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.7.2.3"><span class="ltx_text" id="A3.T9.5.7.2.3.1" style="font-size:144%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.7.2.4"><span class="ltx_text" id="A3.T9.5.7.2.4.1" style="font-size:144%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.7.2.5"><span class="ltx_text" id="A3.T9.5.7.2.5.1" style="font-size:144%;">12</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.7.2.6"><span class="ltx_text" id="A3.T9.5.7.2.6.1" style="font-size:144%;">36</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.8.3.1"><span class="ltx_text" id="A3.T9.5.8.3.1.1" style="font-size:144%;">Q-Former Encoder heads</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.8.3.2"><span class="ltx_text" id="A3.T9.5.8.3.2.1" style="font-size:144%;">8</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.8.3.3"><span class="ltx_text" id="A3.T9.5.8.3.3.1" style="font-size:144%;">8</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.8.3.4"><span class="ltx_text" id="A3.T9.5.8.3.4.1" style="font-size:144%;">8</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.8.3.5"><span class="ltx_text" id="A3.T9.5.8.3.5.1" style="font-size:144%;">12</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.8.3.6"><span class="ltx_text" id="A3.T9.5.8.3.6.1" style="font-size:144%;">20</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.9.4.1"><span class="ltx_text" id="A3.T9.5.9.4.1.1" style="font-size:144%;">Q-Former Encoder dim.</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.9.4.2"><span class="ltx_text" id="A3.T9.5.9.4.2.1" style="font-size:144%;">512</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.9.4.3"><span class="ltx_text" id="A3.T9.5.9.4.3.1" style="font-size:144%;">512</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.9.4.4"><span class="ltx_text" id="A3.T9.5.9.4.4.1" style="font-size:144%;">512</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.9.4.5"><span class="ltx_text" id="A3.T9.5.9.4.5.1" style="font-size:144%;">768</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.9.4.6"><span class="ltx_text" id="A3.T9.5.9.4.6.1" style="font-size:144%;">1280</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.10.5.1"><span class="ltx_text" id="A3.T9.5.10.5.1.1" style="font-size:144%;">Q-Former Decoder depth</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.10.5.2"><span class="ltx_text" id="A3.T9.5.10.5.2.1" style="font-size:144%;">6</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.10.5.3"><span class="ltx_text" id="A3.T9.5.10.5.3.1" style="font-size:144%;">12</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.10.5.4"><span class="ltx_text" id="A3.T9.5.10.5.4.1" style="font-size:144%;">24</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.10.5.5"><span class="ltx_text" id="A3.T9.5.10.5.5.1" style="font-size:144%;">24</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.10.5.6"><span class="ltx_text" id="A3.T9.5.10.5.6.1" style="font-size:144%;">48</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.11.6.1"><span class="ltx_text" id="A3.T9.5.11.6.1.1" style="font-size:144%;">Q-Former Decoder heads.</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.11.6.2"><span class="ltx_text" id="A3.T9.5.11.6.2.1" style="font-size:144%;">8</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.11.6.3"><span class="ltx_text" id="A3.T9.5.11.6.3.1" style="font-size:144%;">12</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.11.6.4"><span class="ltx_text" id="A3.T9.5.11.6.4.1" style="font-size:144%;">16</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.11.6.5"><span class="ltx_text" id="A3.T9.5.11.6.5.1" style="font-size:144%;">16</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.11.6.6"><span class="ltx_text" id="A3.T9.5.11.6.6.1" style="font-size:144%;">24</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.12.7.1"><span class="ltx_text" id="A3.T9.5.12.7.1.1" style="font-size:144%;">Q-Former Decoder dim.</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.12.7.2"><span class="ltx_text" id="A3.T9.5.12.7.2.1" style="font-size:144%;">512</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.12.7.3"><span class="ltx_text" id="A3.T9.5.12.7.3.1" style="font-size:144%;">768</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.12.7.4"><span class="ltx_text" id="A3.T9.5.12.7.4.1" style="font-size:144%;">1024</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.12.7.5"><span class="ltx_text" id="A3.T9.5.12.7.5.1" style="font-size:144%;">1024</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.12.7.6"><span class="ltx_text" id="A3.T9.5.12.7.6.1" style="font-size:144%;">1536</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.13.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.13.8.1"><span class="ltx_text" id="A3.T9.5.13.8.1.1" style="font-size:144%;">Params¬†(M)</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.13.8.2"><span class="ltx_text" id="A3.T9.5.13.8.2.1" style="font-size:144%;">136</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.13.8.3"><span class="ltx_text" id="A3.T9.5.13.8.3.1" style="font-size:144%;">232</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.13.8.4"><span class="ltx_text" id="A3.T9.5.13.8.4.1" style="font-size:144%;">533</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.13.8.5"><span class="ltx_text" id="A3.T9.5.13.8.5.1" style="font-size:144%;">622</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.13.8.6"><span class="ltx_text" id="A3.T9.5.13.8.6.1" style="font-size:144%;">2896</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.14.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T9.5.14.9.1"><span class="ltx_text" id="A3.T9.5.14.9.1.1" style="font-size:144%;">Codebook size</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="A3.T9.5.14.9.2"><span class="ltx_text" id="A3.T9.5.14.9.2.1" style="font-size:144%;">16384</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.15.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.15.10.1"><span class="ltx_text" id="A3.T9.5.15.10.1.1" style="font-size:144%;">Codebook dimension</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.5.15.10.2"><span class="ltx_text" id="A3.T9.5.15.10.2.1" style="font-size:144%;">8</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.16.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.16.11.1"><span class="ltx_text" id="A3.T9.5.16.11.1.1" style="font-size:144%;">#Tokens</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.5.16.11.2"><span class="ltx_text" id="A3.T9.5.16.11.2.1" style="font-size:144%;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.17.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T9.5.17.12.1"><span class="ltx_text" id="A3.T9.5.17.12.1.1" style="font-size:144%;">Training epochs</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.17.12.2"><span class="ltx_text" id="A3.T9.5.17.12.2.1" style="font-size:144%;">100</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.17.12.3"><span class="ltx_text" id="A3.T9.5.17.12.3.1" style="font-size:144%;">200</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.17.12.4"><span class="ltx_text" id="A3.T9.5.17.12.4.1" style="font-size:144%;">200</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.17.12.5"><span class="ltx_text" id="A3.T9.5.17.12.5.1" style="font-size:144%;">200</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.5.17.12.6"><span class="ltx_text" id="A3.T9.5.17.12.6.1" style="font-size:144%;">300</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.18.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.18.13.1"><span class="ltx_text" id="A3.T9.5.18.13.1.1" style="font-size:144%;">Batch size</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.18.13.2"><span class="ltx_text" id="A3.T9.5.18.13.2.1" style="font-size:144%;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.18.13.3"><span class="ltx_text" id="A3.T9.5.18.13.3.1" style="font-size:144%;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.18.13.4"><span class="ltx_text" id="A3.T9.5.18.13.4.1" style="font-size:144%;">256</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.18.13.5"><span class="ltx_text" id="A3.T9.5.18.13.5.1" style="font-size:144%;">256</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.18.13.6"><span class="ltx_text" id="A3.T9.5.18.13.6.1" style="font-size:144%;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.1.1.1">
<span class="ltx_text" id="A3.T9.1.1.1.1" style="font-size:144%;">Alignment Layer </span><math alttext="l" class="ltx_Math" display="inline" id="A3.T9.1.1.1.m1.1"><semantics id="A3.T9.1.1.1.m1.1a"><mi id="A3.T9.1.1.1.m1.1.1" mathsize="144%" xref="A3.T9.1.1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A3.T9.1.1.1.m1.1b"><ci id="A3.T9.1.1.1.m1.1.1.cmml" xref="A3.T9.1.1.1.m1.1.1">ùëô</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.1.1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="A3.T9.1.1.1.m1.1d">italic_l</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.1.1.2"><span class="ltx_text" id="A3.T9.1.1.2.1" style="font-size:144%;">3</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.19.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.19.14.1"><span class="ltx_text" id="A3.T9.5.19.14.1.1" style="font-size:144%;">Learning rate schedule</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.5.19.14.2"><span class="ltx_text" id="A3.T9.5.19.14.2.1" style="font-size:144%;">Cosine Decay</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.2.2.2"><span class="ltx_text" id="A3.T9.2.2.2.1" style="font-size:144%;">Base learning rate</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.2.2.1"><math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="A3.T9.2.2.1.m1.1"><semantics id="A3.T9.2.2.1.m1.1a"><mrow id="A3.T9.2.2.1.m1.1.1" xref="A3.T9.2.2.1.m1.1.1.cmml"><mn id="A3.T9.2.2.1.m1.1.1.2" mathsize="144%" xref="A3.T9.2.2.1.m1.1.1.2.cmml">1</mn><mo id="A3.T9.2.2.1.m1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="A3.T9.2.2.1.m1.1.1.1.cmml">√ó</mo><msup id="A3.T9.2.2.1.m1.1.1.3" xref="A3.T9.2.2.1.m1.1.1.3.cmml"><mn id="A3.T9.2.2.1.m1.1.1.3.2" mathsize="144%" xref="A3.T9.2.2.1.m1.1.1.3.2.cmml">10</mn><mrow id="A3.T9.2.2.1.m1.1.1.3.3" xref="A3.T9.2.2.1.m1.1.1.3.3.cmml"><mo id="A3.T9.2.2.1.m1.1.1.3.3a" mathsize="144%" xref="A3.T9.2.2.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A3.T9.2.2.1.m1.1.1.3.3.2" mathsize="144%" xref="A3.T9.2.2.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.2.2.1.m1.1b"><apply id="A3.T9.2.2.1.m1.1.1.cmml" xref="A3.T9.2.2.1.m1.1.1"><times id="A3.T9.2.2.1.m1.1.1.1.cmml" xref="A3.T9.2.2.1.m1.1.1.1"></times><cn id="A3.T9.2.2.1.m1.1.1.2.cmml" type="integer" xref="A3.T9.2.2.1.m1.1.1.2">1</cn><apply id="A3.T9.2.2.1.m1.1.1.3.cmml" xref="A3.T9.2.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.T9.2.2.1.m1.1.1.3.1.cmml" xref="A3.T9.2.2.1.m1.1.1.3">superscript</csymbol><cn id="A3.T9.2.2.1.m1.1.1.3.2.cmml" type="integer" xref="A3.T9.2.2.1.m1.1.1.3.2">10</cn><apply id="A3.T9.2.2.1.m1.1.1.3.3.cmml" xref="A3.T9.2.2.1.m1.1.1.3.3"><minus id="A3.T9.2.2.1.m1.1.1.3.3.1.cmml" xref="A3.T9.2.2.1.m1.1.1.3.3"></minus><cn id="A3.T9.2.2.1.m1.1.1.3.3.2.cmml" type="integer" xref="A3.T9.2.2.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.2.2.1.m1.1c">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A3.T9.2.2.1.m1.1d">1 √ó 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T9.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.3.3.2"><span class="ltx_text" id="A3.T9.3.3.2.1" style="font-size:144%;">Minimum learning rate</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.3.3.1"><math alttext="1\times 10^{-5}" class="ltx_Math" display="inline" id="A3.T9.3.3.1.m1.1"><semantics id="A3.T9.3.3.1.m1.1a"><mrow id="A3.T9.3.3.1.m1.1.1" xref="A3.T9.3.3.1.m1.1.1.cmml"><mn id="A3.T9.3.3.1.m1.1.1.2" mathsize="144%" xref="A3.T9.3.3.1.m1.1.1.2.cmml">1</mn><mo id="A3.T9.3.3.1.m1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="A3.T9.3.3.1.m1.1.1.1.cmml">√ó</mo><msup id="A3.T9.3.3.1.m1.1.1.3" xref="A3.T9.3.3.1.m1.1.1.3.cmml"><mn id="A3.T9.3.3.1.m1.1.1.3.2" mathsize="144%" xref="A3.T9.3.3.1.m1.1.1.3.2.cmml">10</mn><mrow id="A3.T9.3.3.1.m1.1.1.3.3" xref="A3.T9.3.3.1.m1.1.1.3.3.cmml"><mo id="A3.T9.3.3.1.m1.1.1.3.3a" mathsize="144%" xref="A3.T9.3.3.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A3.T9.3.3.1.m1.1.1.3.3.2" mathsize="144%" xref="A3.T9.3.3.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.3.3.1.m1.1b"><apply id="A3.T9.3.3.1.m1.1.1.cmml" xref="A3.T9.3.3.1.m1.1.1"><times id="A3.T9.3.3.1.m1.1.1.1.cmml" xref="A3.T9.3.3.1.m1.1.1.1"></times><cn id="A3.T9.3.3.1.m1.1.1.2.cmml" type="integer" xref="A3.T9.3.3.1.m1.1.1.2">1</cn><apply id="A3.T9.3.3.1.m1.1.1.3.cmml" xref="A3.T9.3.3.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.T9.3.3.1.m1.1.1.3.1.cmml" xref="A3.T9.3.3.1.m1.1.1.3">superscript</csymbol><cn id="A3.T9.3.3.1.m1.1.1.3.2.cmml" type="integer" xref="A3.T9.3.3.1.m1.1.1.3.2">10</cn><apply id="A3.T9.3.3.1.m1.1.1.3.3.cmml" xref="A3.T9.3.3.1.m1.1.1.3.3"><minus id="A3.T9.3.3.1.m1.1.1.3.3.1.cmml" xref="A3.T9.3.3.1.m1.1.1.3.3"></minus><cn id="A3.T9.3.3.1.m1.1.1.3.3.2.cmml" type="integer" xref="A3.T9.3.3.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.3.3.1.m1.1c">1\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A3.T9.3.3.1.m1.1d">1 √ó 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.20.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.20.15.1"><span class="ltx_text" id="A3.T9.5.20.15.1.1" style="font-size:144%;">LR warm-up iterations</span></th>
<td class="ltx_td ltx_align_center" id="A3.T9.5.20.15.2"><span class="ltx_text" id="A3.T9.5.20.15.2.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.20.15.3"><span class="ltx_text" id="A3.T9.5.20.15.3.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.20.15.4"><span class="ltx_text" id="A3.T9.5.20.15.4.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.20.15.5"><span class="ltx_text" id="A3.T9.5.20.15.5.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center" id="A3.T9.5.20.15.6"><span class="ltx_text" id="A3.T9.5.20.15.6.1" style="font-size:144%;">5000</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.21.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.5.21.16.1"><span class="ltx_text" id="A3.T9.5.21.16.1.1" style="font-size:144%;">Optimizer</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.5.21.16.2">
<span class="ltx_text" id="A3.T9.5.21.16.2.1" style="font-size:144%;">AdamW</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T9.5.21.16.2.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">39</span></a><span class="ltx_text" id="A3.T9.5.21.16.2.3.2" style="font-size:144%;">]</span></cite>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T9.4.4.2"><span class="ltx_text" id="A3.T9.4.4.2.1" style="font-size:144%;">Opt. momentum</span></th>
<td class="ltx_td ltx_align_center" colspan="5" id="A3.T9.4.4.1"><math alttext="\beta_{1}=0.9,\beta_{2}=0.95" class="ltx_Math" display="inline" id="A3.T9.4.4.1.m1.2"><semantics id="A3.T9.4.4.1.m1.2a"><mrow id="A3.T9.4.4.1.m1.2.2.2" xref="A3.T9.4.4.1.m1.2.2.3.cmml"><mrow id="A3.T9.4.4.1.m1.1.1.1.1" xref="A3.T9.4.4.1.m1.1.1.1.1.cmml"><msub id="A3.T9.4.4.1.m1.1.1.1.1.2" xref="A3.T9.4.4.1.m1.1.1.1.1.2.cmml"><mi id="A3.T9.4.4.1.m1.1.1.1.1.2.2" mathsize="144%" xref="A3.T9.4.4.1.m1.1.1.1.1.2.2.cmml">Œ≤</mi><mn id="A3.T9.4.4.1.m1.1.1.1.1.2.3" mathsize="144%" xref="A3.T9.4.4.1.m1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="A3.T9.4.4.1.m1.1.1.1.1.1" mathsize="144%" xref="A3.T9.4.4.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A3.T9.4.4.1.m1.1.1.1.1.3" mathsize="144%" xref="A3.T9.4.4.1.m1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="A3.T9.4.4.1.m1.2.2.2.3" mathsize="144%" xref="A3.T9.4.4.1.m1.2.2.3a.cmml">,</mo><mrow id="A3.T9.4.4.1.m1.2.2.2.2" xref="A3.T9.4.4.1.m1.2.2.2.2.cmml"><msub id="A3.T9.4.4.1.m1.2.2.2.2.2" xref="A3.T9.4.4.1.m1.2.2.2.2.2.cmml"><mi id="A3.T9.4.4.1.m1.2.2.2.2.2.2" mathsize="144%" xref="A3.T9.4.4.1.m1.2.2.2.2.2.2.cmml">Œ≤</mi><mn id="A3.T9.4.4.1.m1.2.2.2.2.2.3" mathsize="144%" xref="A3.T9.4.4.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A3.T9.4.4.1.m1.2.2.2.2.1" mathsize="144%" xref="A3.T9.4.4.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A3.T9.4.4.1.m1.2.2.2.2.3" mathsize="144%" xref="A3.T9.4.4.1.m1.2.2.2.2.3.cmml">0.95</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.4.4.1.m1.2b"><apply id="A3.T9.4.4.1.m1.2.2.3.cmml" xref="A3.T9.4.4.1.m1.2.2.2"><csymbol cd="ambiguous" id="A3.T9.4.4.1.m1.2.2.3a.cmml" xref="A3.T9.4.4.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A3.T9.4.4.1.m1.1.1.1.1.cmml" xref="A3.T9.4.4.1.m1.1.1.1.1"><eq id="A3.T9.4.4.1.m1.1.1.1.1.1.cmml" xref="A3.T9.4.4.1.m1.1.1.1.1.1"></eq><apply id="A3.T9.4.4.1.m1.1.1.1.1.2.cmml" xref="A3.T9.4.4.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.T9.4.4.1.m1.1.1.1.1.2.1.cmml" xref="A3.T9.4.4.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A3.T9.4.4.1.m1.1.1.1.1.2.2.cmml" xref="A3.T9.4.4.1.m1.1.1.1.1.2.2">ùõΩ</ci><cn id="A3.T9.4.4.1.m1.1.1.1.1.2.3.cmml" type="integer" xref="A3.T9.4.4.1.m1.1.1.1.1.2.3">1</cn></apply><cn id="A3.T9.4.4.1.m1.1.1.1.1.3.cmml" type="float" xref="A3.T9.4.4.1.m1.1.1.1.1.3">0.9</cn></apply><apply id="A3.T9.4.4.1.m1.2.2.2.2.cmml" xref="A3.T9.4.4.1.m1.2.2.2.2"><eq id="A3.T9.4.4.1.m1.2.2.2.2.1.cmml" xref="A3.T9.4.4.1.m1.2.2.2.2.1"></eq><apply id="A3.T9.4.4.1.m1.2.2.2.2.2.cmml" xref="A3.T9.4.4.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.T9.4.4.1.m1.2.2.2.2.2.1.cmml" xref="A3.T9.4.4.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A3.T9.4.4.1.m1.2.2.2.2.2.2.cmml" xref="A3.T9.4.4.1.m1.2.2.2.2.2.2">ùõΩ</ci><cn id="A3.T9.4.4.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="A3.T9.4.4.1.m1.2.2.2.2.2.3">2</cn></apply><cn id="A3.T9.4.4.1.m1.2.2.2.2.3.cmml" type="float" xref="A3.T9.4.4.1.m1.2.2.2.2.3">0.95</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.4.4.1.m1.2c">\beta_{1}=0.9,\beta_{2}=0.95</annotation><annotation encoding="application/x-llamapun" id="A3.T9.4.4.1.m1.2d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9 , italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.95</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T9.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A3.T9.5.5.2"><span class="ltx_text" id="A3.T9.5.5.2.1" style="font-size:144%;">Entropy Loss weight</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.5.5.3"><span class="ltx_text" id="A3.T9.5.5.3.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.5.5.4"><span class="ltx_text" id="A3.T9.5.5.4.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.5.5.5"><span class="ltx_text" id="A3.T9.5.5.5.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.5.5.6"><span class="ltx_text" id="A3.T9.5.5.6.1" style="font-size:144%;">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.5.5.1"><math alttext="5\times 10^{-3}" class="ltx_Math" display="inline" id="A3.T9.5.5.1.m1.1"><semantics id="A3.T9.5.5.1.m1.1a"><mrow id="A3.T9.5.5.1.m1.1.1" xref="A3.T9.5.5.1.m1.1.1.cmml"><mn id="A3.T9.5.5.1.m1.1.1.2" mathsize="144%" xref="A3.T9.5.5.1.m1.1.1.2.cmml">5</mn><mo id="A3.T9.5.5.1.m1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="A3.T9.5.5.1.m1.1.1.1.cmml">√ó</mo><msup id="A3.T9.5.5.1.m1.1.1.3" xref="A3.T9.5.5.1.m1.1.1.3.cmml"><mn id="A3.T9.5.5.1.m1.1.1.3.2" mathsize="144%" xref="A3.T9.5.5.1.m1.1.1.3.2.cmml">10</mn><mrow id="A3.T9.5.5.1.m1.1.1.3.3" xref="A3.T9.5.5.1.m1.1.1.3.3.cmml"><mo id="A3.T9.5.5.1.m1.1.1.3.3a" mathsize="144%" xref="A3.T9.5.5.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A3.T9.5.5.1.m1.1.1.3.3.2" mathsize="144%" xref="A3.T9.5.5.1.m1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.5.5.1.m1.1b"><apply id="A3.T9.5.5.1.m1.1.1.cmml" xref="A3.T9.5.5.1.m1.1.1"><times id="A3.T9.5.5.1.m1.1.1.1.cmml" xref="A3.T9.5.5.1.m1.1.1.1"></times><cn id="A3.T9.5.5.1.m1.1.1.2.cmml" type="integer" xref="A3.T9.5.5.1.m1.1.1.2">5</cn><apply id="A3.T9.5.5.1.m1.1.1.3.cmml" xref="A3.T9.5.5.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.T9.5.5.1.m1.1.1.3.1.cmml" xref="A3.T9.5.5.1.m1.1.1.3">superscript</csymbol><cn id="A3.T9.5.5.1.m1.1.1.3.2.cmml" type="integer" xref="A3.T9.5.5.1.m1.1.1.3.2">10</cn><apply id="A3.T9.5.5.1.m1.1.1.3.3.cmml" xref="A3.T9.5.5.1.m1.1.1.3.3"><minus id="A3.T9.5.5.1.m1.1.1.3.3.1.cmml" xref="A3.T9.5.5.1.m1.1.1.3.3"></minus><cn id="A3.T9.5.5.1.m1.1.1.3.3.2.cmml" type="integer" xref="A3.T9.5.5.1.m1.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.5.5.1.m1.1c">5\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="A3.T9.5.5.1.m1.1d">5 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº Table 9 details the configurations and hyperparameters used during the training of GigaTok models with varying sizes.  It includes specifications for both the encoder and decoder components of the Q-Former architecture, along with training parameters like the number of epochs, batch size, learning rate schedule, and optimizer settings.  Key hyperparameters affecting the scaling behavior, such as codebook size and dimension, are also included.  It helps illustrate the choices made for successfully scaling visual tokenizers to a billion parameters.
> <details>
> <summary>read the caption</summary>
> Table 9: GigaTok configuration and default training details
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T10.12">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T10.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A3.T10.9.9.10"><span class="ltx_text" id="A3.T10.9.9.10.1" style="font-size:144%;">Tokenizer</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A3.T10.9.9.11"><span class="ltx_text" id="A3.T10.9.9.11.1" style="font-size:144%;">Param.</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A3.T10.1.1.1">
<span class="ltx_text" id="A3.T10.1.1.1.1" style="font-size:144%;">rFID</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T10.1.1.1.m1.1"><semantics id="A3.T10.1.1.1.m1.1a"><mo id="A3.T10.1.1.1.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="A3.T10.1.1.1.m1.1b"><ci id="A3.T10.1.1.1.m1.1.1.cmml" xref="A3.T10.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.1.1.1.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.2.2.2">
<span class="ltx_text" id="A3.T10.2.2.2.1" style="font-size:144%;">LPIPS</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T10.2.2.2.m1.1"><semantics id="A3.T10.2.2.2.m1.1a"><mo id="A3.T10.2.2.2.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.2.2.2.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="A3.T10.2.2.2.m1.1b"><ci id="A3.T10.2.2.2.m1.1.1.cmml" xref="A3.T10.2.2.2.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.2.2.2.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.3.3.3">
<span class="ltx_text" id="A3.T10.3.3.3.1" style="font-size:144%;">PSNR</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.3.3.3.m1.1"><semantics id="A3.T10.3.3.3.m1.1a"><mo id="A3.T10.3.3.3.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.3.3.3.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.3.3.3.m1.1b"><ci id="A3.T10.3.3.3.m1.1.1.cmml" xref="A3.T10.3.3.3.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.3.3.3.m1.1d">‚Üë</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A3.T10.4.4.4">
<span class="ltx_text" id="A3.T10.4.4.4.1" style="font-size:144%;">SSIM</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.4.4.4.m1.1"><semantics id="A3.T10.4.4.4.m1.1a"><mo id="A3.T10.4.4.4.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.4.4.4.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.4.4.4.m1.1b"><ci id="A3.T10.4.4.4.m1.1.1.cmml" xref="A3.T10.4.4.4.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.4.4.4.m1.1d">‚Üë</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.9.9.12"><span class="ltx_text" id="A3.T10.9.9.12.1" style="font-size:144%;">AR Model</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.9.9.13"><span class="ltx_text" id="A3.T10.9.9.13.1" style="font-size:144%;">Param.</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A3.T10.5.5.5">
<span class="ltx_text" id="A3.T10.5.5.5.1" style="font-size:144%;">gFID</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T10.5.5.5.m1.1"><semantics id="A3.T10.5.5.5.m1.1a"><mo id="A3.T10.5.5.5.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="A3.T10.5.5.5.m1.1b"><ci id="A3.T10.5.5.5.m1.1.1.cmml" xref="A3.T10.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.5.5.5.m1.1d">‚Üì</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.6.6.6">
<span class="ltx_text" id="A3.T10.6.6.6.1" style="font-size:144%;">Acc.</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.6.6.6.m1.1"><semantics id="A3.T10.6.6.6.m1.1a"><mo id="A3.T10.6.6.6.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.6.6.6.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.6.6.6.m1.1b"><ci id="A3.T10.6.6.6.m1.1.1.cmml" xref="A3.T10.6.6.6.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.6.6.6.m1.1d">‚Üë</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.7.7.7">
<span class="ltx_text" id="A3.T10.7.7.7.1" style="font-size:144%;">IS</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.7.7.7.m1.1"><semantics id="A3.T10.7.7.7.m1.1a"><mo id="A3.T10.7.7.7.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.7.7.7.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.7.7.7.m1.1b"><ci id="A3.T10.7.7.7.m1.1.1.cmml" xref="A3.T10.7.7.7.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.7.7.7.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.7.7.7.m1.1d">‚Üë</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.8.8.8">
<span class="ltx_text" id="A3.T10.8.8.8.1" style="font-size:144%;">Precision</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.8.8.8.m1.1"><semantics id="A3.T10.8.8.8.m1.1a"><mo id="A3.T10.8.8.8.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.8.8.8.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.8.8.8.m1.1b"><ci id="A3.T10.8.8.8.m1.1.1.cmml" xref="A3.T10.8.8.8.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.8.8.8.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.8.8.8.m1.1d">‚Üë</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.9.9.9">
<span class="ltx_text" id="A3.T10.9.9.9.1" style="font-size:144%;">Recall</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T10.9.9.9.m1.1"><semantics id="A3.T10.9.9.9.m1.1a"><mo id="A3.T10.9.9.9.m1.1.1" mathsize="144%" stretchy="false" xref="A3.T10.9.9.9.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="A3.T10.9.9.9.m1.1b"><ci id="A3.T10.9.9.9.m1.1.1.cmml" xref="A3.T10.9.9.9.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.9.9.9.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T10.9.9.9.m1.1d">‚Üë</annotation></semantics></math>
</th>
</tr>
<tr class="ltx_tr" id="A3.T10.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.1">
<span class="ltx_text" id="A3.T10.12.13.1.1.1" style="font-size:144%;">LlamaGen-Tok.¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.13.1.1.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.13.1.1.3.2" style="font-size:144%;">]</span></cite>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.2"><span class="ltx_text" id="A3.T10.12.13.1.2.1" style="font-size:144%;">72M</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.3"><span class="ltx_text" id="A3.T10.12.13.1.3.1" style="font-size:144%;">2.19</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.4"><span class="ltx_text" id="A3.T10.12.13.1.4.1" style="font-size:144%;">-</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.5"><span class="ltx_text" id="A3.T10.12.13.1.5.1" style="font-size:144%;">20.79</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A3.T10.12.13.1.6"><span class="ltx_text" id="A3.T10.12.13.1.6.1" style="font-size:144%;">0.675</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.7">
<span class="ltx_text" id="A3.T10.12.13.1.7.1" style="font-size:144%;">LlamaGen-B¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.13.1.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.13.1.7.3.2" style="font-size:144%;">]</span></cite>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.8"><span class="ltx_text" id="A3.T10.12.13.1.8.1" style="font-size:144%;">111M</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.9"><span class="ltx_text" id="A3.T10.12.13.1.9.1" style="font-size:144%;">5.46</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.10"><span class="ltx_text" id="A3.T10.12.13.1.10.1" style="font-size:144%;">-</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.11"><span class="ltx_text" id="A3.T10.12.13.1.11.1" style="font-size:144%;">193.61</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.12"><span class="ltx_text" id="A3.T10.12.13.1.12.1" style="font-size:144%;">0.83</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A3.T10.12.13.1.13"><span class="ltx_text" id="A3.T10.12.13.1.13.1" style="font-size:144%;">0.45</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T10.12.14.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T10.12.14.1.1"><span class="ltx_text" id="A3.T10.12.14.1.1.1" style="font-size:144%;">GigaTok-S-S</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="A3.T10.12.14.1.2"><span class="ltx_text" id="A3.T10.12.14.1.2.1" style="font-size:144%;">136M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="A3.T10.12.14.1.3"><span class="ltx_text" id="A3.T10.12.14.1.3.1" style="font-size:144%;">1.01</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.4"><span class="ltx_text" id="A3.T10.12.14.1.4.1" style="font-size:144%;">0.2226</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.5"><span class="ltx_text" id="A3.T10.12.14.1.5.1" style="font-size:144%;">20.74</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.12.14.1.6"><span class="ltx_text" id="A3.T10.12.14.1.6.1" style="font-size:144%;">0.670</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.7">
<span class="ltx_text" id="A3.T10.12.14.1.7.1" style="font-size:144%;">LlamaGen-B¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.14.1.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.14.1.7.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.8"><span class="ltx_text" id="A3.T10.12.14.1.8.1" style="font-size:144%;">111M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t" id="A3.T10.12.14.1.9"><span class="ltx_text" id="A3.T10.12.14.1.9.1" style="font-size:144%;">4.05</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.10"><span class="ltx_text" id="A3.T10.12.14.1.10.1" style="font-size:144%;">62.6</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.11"><span class="ltx_text" id="A3.T10.12.14.1.11.1" style="font-size:144%;">240.61</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.12"><span class="ltx_text" id="A3.T10.12.14.1.12.1" style="font-size:144%;">0.81</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="A3.T10.12.14.1.13"><span class="ltx_text" id="A3.T10.12.14.1.13.1" style="font-size:144%;">0.51</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.12.15.2">
<td class="ltx_td ltx_align_left" id="A3.T10.12.15.2.1"><span class="ltx_text" id="A3.T10.12.15.2.1.1" style="font-size:144%;">GigaTok-S-B</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="A3.T10.12.15.2.2"><span class="ltx_text" id="A3.T10.12.15.2.2.1" style="font-size:144%;">232M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.12.15.2.3"><span class="ltx_text" id="A3.T10.12.15.2.3.1" style="font-size:144%;">0.89</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.4"><span class="ltx_text" id="A3.T10.12.15.2.4.1" style="font-size:144%;">0.2121</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.5"><span class="ltx_text" id="A3.T10.12.15.2.5.1" style="font-size:144%;">20.93</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A3.T10.12.15.2.6"><span class="ltx_text" id="A3.T10.12.15.2.6.1" style="font-size:144%;">0.677</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.7">
<span class="ltx_text" id="A3.T10.12.15.2.7.1" style="font-size:144%;">LlamaGen-B¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.15.2.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.15.2.7.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.8"><span class="ltx_text" id="A3.T10.12.15.2.8.1" style="font-size:144%;">111M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.12.15.2.9"><span class="ltx_text" id="A3.T10.12.15.2.9.1" style="font-size:144%;">3.83</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.10"><span class="ltx_text" id="A3.T10.12.15.2.10.1" style="font-size:144%;">62.9</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.11"><span class="ltx_text" id="A3.T10.12.15.2.11.1" style="font-size:144%;">233.31</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.12"><span class="ltx_text" id="A3.T10.12.15.2.12.1" style="font-size:144%;">0.83</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.15.2.13"><span class="ltx_text" id="A3.T10.12.15.2.13.1" style="font-size:144%;">0.51</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.12.16.3">
<td class="ltx_td ltx_align_left" id="A3.T10.12.16.3.1" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.1.1" style="font-size:144%;">GigaTok-B-L</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="A3.T10.12.16.3.2" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.2.1" style="font-size:144%;">622M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.12.16.3.3" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.3.1" style="font-size:144%;">0.81</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.4" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.4.1" style="font-size:144%;">0.2059</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.5" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.5.1" style="font-size:144%;">21.21</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A3.T10.12.16.3.6" rowspan="2"><span class="ltx_text" id="A3.T10.12.16.3.6.1" style="font-size:144%;">0.685</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.7">
<span class="ltx_text" id="A3.T10.12.16.3.7.1" style="font-size:144%;">LlamaGen-B¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.16.3.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.16.3.7.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.8"><span class="ltx_text" id="A3.T10.12.16.3.8.1" style="font-size:144%;">111M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.12.16.3.9"><span class="ltx_text" id="A3.T10.12.16.3.9.1" style="font-size:144%;">3.26</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.10"><span class="ltx_text" id="A3.T10.12.16.3.10.1" style="font-size:144%;">67.6</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.11"><span class="ltx_text" id="A3.T10.12.16.3.11.1" style="font-size:144%;">221.02</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.12"><span class="ltx_text" id="A3.T10.12.16.3.12.1" style="font-size:144%;">0.81</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.16.3.13"><span class="ltx_text" id="A3.T10.12.16.3.13.1" style="font-size:144%;">0.56</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.10.10">
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.2">
<span class="ltx_text" id="A3.T10.10.10.2.1" style="font-size:144%;">LlamaGen-XXL¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.10.10.2.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.10.10.2.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.3"><span class="ltx_text" id="A3.T10.10.10.3.1" style="font-size:144%;">1.4B</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.10.10.1">
<span class="ltx_text" id="A3.T10.10.10.1.1" style="font-size:144%;">2.03</span><sup class="ltx_sup" id="A3.T10.10.10.1.2"><span class="ltx_text ltx_font_italic" id="A3.T10.10.10.1.2.1" style="font-size:144%;">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.4"><span class="ltx_text" id="A3.T10.10.10.4.1" style="font-size:144%;">69.4</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.5"><span class="ltx_text" id="A3.T10.10.10.5.1" style="font-size:144%;">238.52</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.6"><span class="ltx_text" id="A3.T10.10.10.6.1" style="font-size:144%;">0.80</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.10.10.7"><span class="ltx_text" id="A3.T10.10.10.7.1" style="font-size:144%;">0.63</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.11.11">
<td class="ltx_td ltx_align_left" id="A3.T10.11.11.2"><span class="ltx_text" id="A3.T10.11.11.2.1" style="font-size:144%;">GigaTok-B-L</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="A3.T10.11.11.3"><span class="ltx_text" id="A3.T10.11.11.3.1" style="font-size:144%;">622M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.11.11.1">
<span class="ltx_text" id="A3.T10.11.11.1.1" style="font-size:144%;">0.51</span><sup class="ltx_sup" id="A3.T10.11.11.1.2"><span class="ltx_text ltx_font_italic" id="A3.T10.11.11.1.2.1" style="font-size:144%;">‚Ä°</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.4"><span class="ltx_text" id="A3.T10.11.11.4.1" style="font-size:144%;">0.206</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.5"><span class="ltx_text" id="A3.T10.11.11.5.1" style="font-size:144%;">21.32</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A3.T10.11.11.6"><span class="ltx_text" id="A3.T10.11.11.6.1" style="font-size:144%;">0.691</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.7">
<span class="ltx_text" id="A3.T10.11.11.7.1" style="font-size:144%;">LlamaGen-B¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.11.11.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.11.11.7.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.8"><span class="ltx_text" id="A3.T10.11.11.8.1" style="font-size:144%;">111M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.11.11.9"><span class="ltx_text" id="A3.T10.11.11.9.1" style="font-size:144%;">3.33</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.10"><span class="ltx_text" id="A3.T10.11.11.10.1" style="font-size:144%;">67.7</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.11"><span class="ltx_text" id="A3.T10.11.11.11.1" style="font-size:144%;">265.43</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.12"><span class="ltx_text" id="A3.T10.11.11.12.1" style="font-size:144%;">0.80</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.11.11.13"><span class="ltx_text" id="A3.T10.11.11.13.1" style="font-size:144%;">0.56</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.12.17.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A3.T10.12.17.4.1" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.1.1" style="font-size:144%;">GigaTok-XL-XXL</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="A3.T10.12.17.4.2" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.2.1" style="font-size:144%;">2.9B</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb" id="A3.T10.12.17.4.3" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.3.1" style="font-size:144%;">0.79</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.17.4.4" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.4.1" style="font-size:144%;">0.1947</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.17.4.5" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.5.1" style="font-size:144%;">21.65</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r" id="A3.T10.12.17.4.6" rowspan="2"><span class="ltx_text" id="A3.T10.12.17.4.6.1" style="font-size:144%;">0.699</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.7">
<span class="ltx_text" id="A3.T10.12.17.4.7.1" style="font-size:144%;">LlamaGen-B¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.17.4.7.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.17.4.7.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.8"><span class="ltx_text" id="A3.T10.12.17.4.8.1" style="font-size:144%;">111M</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left" id="A3.T10.12.17.4.9"><span class="ltx_text" id="A3.T10.12.17.4.9.1" style="font-size:144%;">3.15</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.10"><span class="ltx_text" id="A3.T10.12.17.4.10.1" style="font-size:144%;">72.0</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.11"><span class="ltx_text" id="A3.T10.12.17.4.11.1" style="font-size:144%;">224.28</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.12"><span class="ltx_text" id="A3.T10.12.17.4.12.1" style="font-size:144%;">0.82</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="A3.T10.12.17.4.13"><span class="ltx_text" id="A3.T10.12.17.4.13.1" style="font-size:144%;">0.55</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.12.12">
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.2">
<span class="ltx_text" id="A3.T10.12.12.2.1" style="font-size:144%;">LlamaGen-XXL¬†(1d)¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="A3.T10.12.12.2.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2504.08736v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a><span class="ltx_text" id="A3.T10.12.12.2.3.2" style="font-size:144%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.3"><span class="ltx_text" id="A3.T10.12.12.3.1" style="font-size:144%;">1.4B</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb" id="A3.T10.12.12.1">
<span class="ltx_text" id="A3.T10.12.12.1.1" style="font-size:144%;">1.98</span><sup class="ltx_sup" id="A3.T10.12.12.1.2"><span class="ltx_text ltx_font_italic" id="A3.T10.12.12.1.2.1" style="font-size:144%;">‚ãÜ</span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.4"><span class="ltx_text" id="A3.T10.12.12.4.1" style="font-size:144%;">74.0</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.5"><span class="ltx_text" id="A3.T10.12.12.5.1" style="font-size:144%;">256.76</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.6"><span class="ltx_text" id="A3.T10.12.12.6.1" style="font-size:144%;">0.81</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb" id="A3.T10.12.12.7"><span class="ltx_text" id="A3.T10.12.12.7.1" style="font-size:144%;">0.62</span></td>
</tr>
</tbody>
</table>{{< /table-caption >}}
> üîº This table presents a comprehensive comparison of various visual tokenizers and their corresponding autoregressive (AR) models' performance on ImageNet 256x256 images.  The evaluation metrics include reconstruction quality (rFID, LPIPS, PSNR, SSIM), and AR generation quality (gFID, Accuracy, Inception Score, Precision, Recall).  For gFID, the lowest score obtained either with or without Classifier-Free Guidance (CFG) is reported.  The use of a frozen DINO [7] discriminator is indicated for some models, highlighting its impact on rFID improvement. The absence of CFG is also noted for certain models. The table allows for a direct comparison of different tokenizers' effectiveness in improving both image reconstruction and AR generation.
> <details>
> <summary>read the caption</summary>
> Table 10: Full results for our tokenizers and AR models on ImageNet 256√ó\times√ó256. For gFID, we present the lowest value between w/ or w/o CFG scenarios. ‚Ä°: Using frozen DINO¬†[7] for discriminator, which largely improves rFID. ‚ãÜ‚ãÜ\star‚ãÜ: Without classifier-free-guidance.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/2504.08736/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.08736/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}