{"references": [{"fullname_first_author": "Antonio Alliegro", "paper_title": "Polydiff: Generating 3d polygonal meshes with diffusion models", "publication_date": "2023-12-01", "reason": "This paper is highly relevant due to its introduction of a diffusion model for generating 3D polygonal meshes, a key technique used in the target paper's approach."}, {"fullname_first_author": "Armen Avetisyan", "paper_title": "Scene-script: Reconstructing scenes with an autoregressive structured language model", "publication_date": "2024-03-01", "reason": "This work's focus on scene reconstruction using a structured language model is highly relevant to the inverse procedural content generation problem addressed in the target paper."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-01-01", "reason": "The utilization of video generation models as world simulators, a concept explored in this paper, aligns well with the target paper's aim of creating high-fidelity 3D assets."}, {"fullname_first_author": "Junsong Chen", "paper_title": "Pixart-a: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "publication_date": "2023-10-01", "reason": "This paper's focus on fast training of diffusion transformers for photorealistic image generation is relevant to the efficiency goals of the target paper's method."}, {"fullname_first_author": "Yen-Chi Cheng", "paper_title": "Sdfusion: Multimodal 3d shape completion, reconstruction, and generation", "publication_date": "2023-01-01", "reason": "This paper's exploration of multimodal 3D shape generation using diffusion models directly relates to the core methodology of the target paper."}]}