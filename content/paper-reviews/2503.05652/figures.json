[{"figure_path": "https://arxiv.org/html/2503.05652/x1.png", "caption": "Figure 2: Ecological distributions of task-relevant objects involved in daily household activities. Left: The horizontal distance distribution follows a long-tail distribution. Right: The vertical distance distribution exhibits multiple distinct modes, located at 1.43\u00a0mtimes1.43meter1.43\\text{\\,}\\mathrm{m}start_ARG 1.43 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG, 0.94\u00a0mtimes0.94meter0.94\\text{\\,}\\mathrm{m}start_ARG 0.94 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG, 0.49\u00a0mtimes0.49meter0.49\\text{\\,}\\mathrm{m}start_ARG 0.49 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG, and 0.09\u00a0mtimes0.09meter0.09\\text{\\,}\\mathrm{m}start_ARG 0.09 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG, representing heights at which household objects are typically found.", "description": "Figure 2 shows the distribution of household objects' locations based on the BEHAVIOR-1K dataset. The left graph displays the horizontal distances of objects from the robot's reachable space, following a long-tail distribution (most objects are close, few are far).  The right graph shows the vertical distances (heights) of the objects, revealing multiple peaks at 1.43m, 0.94m, 0.49m, and 0.09m. This indicates that objects are commonly found at these specific heights within a house (e.g., countertops, tables, floors).", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2503.05652/x2.png", "caption": "Figure 3: BRS hardware system. Left: The R1 robot\u2019s dimensions, range of motion, and onboard sensors. The robot features two 6-DoF arms, each equipped with a parallel jaw gripper, and a 4-DoF torso. The torso is mounted on an omnidirectional mobile base with three wheel motors and three steering motors. Right: The JoyLo system, consisting of two kinematic-twin arms constructed using 3D-printed components and low-cost Dynamixel motors. Compact, off-the-shelf Nintendo Joy-Con controllers are mounted at the one end of the arms, serving as the interface for controlling the grippers, torso, and mobile base. To ensure sufficient stall torque for the shoulder joints, two Dynamixel motors are coupled together.", "description": "The figure showcases the hardware components of the BEHAVIOR ROBOT SUITE (BRS). On the left, it displays the R1 robot, highlighting its dimensions (2066mm x 1746mm x 863mm), range of motion (two 6-DoF arms with parallel jaw grippers, and a 4-DoF torso mounted on an omnidirectional mobile base with three wheel and three steering motors), and its array of sensors (ZED-Mini, ZED 2, and RealSense T265 cameras).  The right side of the figure details the JoyLo teleoperation interface, which uses two 3D-printed, kinematic-twin arms with Dynamixel motors and Nintendo Joy-Con controllers for intuitive whole-body control of the R1 robot.  Two Dynamixel motors are coupled together on each JoyLo arm to ensure sufficient torque at the shoulder joint.", "section": "II. HARDWARE SYSTEM"}, {"figure_path": "https://arxiv.org/html/2503.05652/x3.png", "caption": "Figure 4: WB-VIMA model architecture for imitation learning. WB-VIMA autoregressively denoises whole-body actions within the embodiment space and dynamically aggregates multi-modal observations using self-attention. By leveraging the hierarchical interdependencies within the robot\u2019s embodiment and the rich information provided by multi-modal sensory inputs, WB-VIMA enables effective whole-body policy learning.", "description": "The figure illustrates the architecture of the WB-VIMA model, an imitation learning algorithm used for whole-body control. The model processes multi-modal sensory data (point cloud and proprioception) using self-attention to capture interdependencies between different parts of the robot's body (arms, torso, base). The autoregressive denoising process predicts actions sequentially from the base to the end-effectors, ensuring coordinated whole-body movements.  This hierarchical approach enables effective learning of complex whole-body policies.", "section": "III. LEARNING METHOD"}, {"figure_path": "https://arxiv.org/html/2503.05652/x4.png", "caption": "Figure 5: Success rate for five representative household activities. \u201cET\u201d denotes the entire task and \u201cST\u201d denotes sub-task. Numerical results are provided in Appendix\u00a0D-B.", "description": "This figure presents the success rates achieved by different methods on five representative household tasks.  The success rates are shown for both the entire task ('ET') and individual sub-tasks ('ST').  'ET' represents the percentage of times the robot successfully completed the entire task from start to finish. 'ST' shows the success rate for each individual step or sub-goal within a task. The methods compared include a trained WB-VIMA policy, a human operator using the JoyLo interface, DP3 (a baseline diffusion model), and RGB-DP (another baseline diffusion model that uses RGB images as input). The data visualization allows for a comparison of the overall effectiveness of each method on these tasks, as well as their relative strengths and weaknesses on the individual sub-tasks. Detailed numerical results are available in Appendix D-B.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.05652/x5.png", "caption": "(a)", "description": "The figure shows emergent behaviors of learned WB-VIMA policies. The robot uses its torso and mobile base to improve maneuverability. In (a), the robot leans forward and moves its base to push a door open. In (b), after grasping a dishwasher handle, it moves its base backward to pull the dishwasher open. In (c), the robot demonstrates failure recovery; it adjusts its torso to reach the toilet cover when its gripper is initially too far.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.05652/x6.png", "caption": "(b)", "description": "The image shows the robot successfully completing a subtask of the 'Clean House After a Wild Party' task.  It demonstrates the robot's ability to recover from a failed attempt to open the dishwasher. Initially, the robot's gripper is too far from the dishwasher handle. The robot adjusts by moving its base backward, tilting its torso forward, and bringing its gripper closer to successfully close the dishwasher.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x7.png", "caption": "Figure 6: User study results with 10 participants. (a): JoyLo is the most efficient interface and produces the highest-quality data. \u201cS.R.\u201d denotes success rate. \u201cET Comp. Time\u201d (\u201cST Comp. Time\u201d) refers to entire task (sub-task) completion time. (b): Survey results show that JoyLo is unanimously rated as the most user-friendly interface by both robot learning practitioners and novices (\u201cpast data collection experience\u201d). Nearly all participants find the Joy-Con helpful for whole-body control (\u201chelpfulness of Joy-Con\u201d).", "description": "A user study compared three interfaces for robot teleoperation: JoyLo, VR controllers, and Apple Vision Pro.  The results, shown in two subfigures, demonstrate that JoyLo is the most efficient, producing the highest-quality data for robot learning.  Figure 6a shows success rates and task completion times, highlighting JoyLo's superior performance. Figure 6b presents survey results indicating JoyLo's superior user-friendliness, especially in terms of ease of use and effectiveness for whole-body control.", "section": "II. HARDWARE SYSTEM"}, {"figure_path": "https://arxiv.org/html/2503.05652/x8.png", "caption": "Figure 7: Ablation study results for tasks \u201cput items onto shelves\u201d and \u201clay clothes out\u201d.\n\u201cw/o W.B. Action Denoising\u201d refers to the variant without autoregressive whole-body action denoising.\n\u201cw/o Multi-Modal Obs. Attn.\u201d refers to the variant without multi-modal observation attention.", "description": "This ablation study analyzes the impact of two key components of the WB-VIMA model on task performance: autoregressive whole-body action denoising and multi-modal observation attention.  The figure presents success rates for two representative household tasks, \"Put Items onto Shelves\" and \"Lay Clothes Out,\" comparing the full WB-VIMA model against variants where each of these components is removed. This visualization allows for a quantitative assessment of the individual contribution of each component to the model's overall effectiveness and robustness in performing complex whole-body manipulation tasks. The results show that both components significantly contribute to the superior performance of WB-VIMA.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.05652/extracted/6261453/appendix/figs/arm_diagram.png", "caption": "Figure 8: Emergent behaviors of learned WB-VIMA policies. (a) and (b): The trained policies leverage the torso and mobile base to improve maneuverability. In (a), the robot bends its hip forward and advances the mobile base to push the door open. In (b), after grasping the dishwasher handle, the robot moves its base backward to pull the dishwasher open. (c): The trained policy exhibits failure recovery behavior. On the first attempt to close the toilet cover, the robot\u2019s gripper is too far to reach it. The policy adjusts by tilting the torso forward, bringing the gripper closer, and successfully closing the cover.", "description": "Figure 8 showcases emergent behaviors of the WB-VIMA policies in handling real-world manipulation challenges. The robot utilizes its torso and mobile base for enhanced maneuverability. In (a), the robot leans forward, using its hip and base to push a door open. In (b), the robot strategically reverses its mobile base to pull open a dishwasher after grasping the handle. Notably, (c) demonstrates a failure recovery mechanism; when unable to reach the toilet cover with its arm extended, the robot adjusts its torso position to bring the gripper within reach and successfully completes the task.", "section": "Insights into the Capabilities of the Whole System"}, {"figure_path": "https://arxiv.org/html/2503.05652/x9.png", "caption": "(a)", "description": "The figure shows emergent behaviors of the trained WB-VIMA policies. In (a), the robot uses its hip to push the door open, demonstrating maneuverability. In (b), the robot uses its base to pull open a dishwasher. In (c), the robot recovers from a failure to close the toilet cover by adjusting its torso.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x10.png", "caption": "(b)", "description": "The trained policies leverage the torso and mobile base to improve maneuverability. In (a), the robot bends its hip forward and advances the mobile base to push the door open. In (b), after grasping the dishwasher handle, the robot moves its base backward to pull the dishwasher open. In (c), the trained policy exhibits failure recovery behavior. On the first attempt to close the toilet cover, the robot's gripper is too far to reach it. The policy adjusts by tilting the torso forward, bringing the gripper closer, and successfully closing the cover.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.05652/extracted/6261453/appendix/figs/fused_pcd_visualization-fig.png", "caption": "(c)", "description": "The image showcases an example of the trained WB-VIMA policy's failure recovery behavior.  Initially, the robot attempts to close the toilet cover but its gripper is too far to reach.  The policy then smartly adjusts by tilting the torso forward, bringing the gripper closer, and successfully completes the action of closing the toilet cover.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2503.05652/extracted/6261453/appendix/figs/joylo_disassembled_2k.png", "caption": "Figure A.1: Robot diagrams. (a): Each arm has six DoFs and a parallel jaw gripper. (b): The torso features four revolute joints for waist rotation, hip bending, and knee-like motions. (c): The wheeled, omnidirectional mobile base is equipped with three steering motors and three wheel motors.", "description": "The figure shows three diagrams of the robot's hardware components. Diagram (a) illustrates the robot's dual arms, each having six degrees of freedom (DoFs) and a parallel jaw gripper. Diagram (b) depicts the robot's four-DoF torso which allows for waist rotation, hip bending, and knee-like motions. Lastly, Diagram (c) presents the omnidirectional mobile base that uses three steering motors and three wheel motors enabling versatile movement.", "section": "APPENDIX A ROBOT HARDWARE DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x11.png", "caption": "Figure A.2: Visualization of the fused, ego-centric colored point clouds. Left: The colored point cloud observation, aligned with the robot\u2019s coordinate frame. Right: The robot\u2019s orientation and its surrounding environment.", "description": "Figure A.2 presents a visualization of the processed point cloud data used by the robot. The left panel shows the colored point cloud data from all three cameras (head, left and right arms) fused into a single egocentric view aligned with the robot's coordinate frame. This provides a comprehensive 3D view of the robot's surroundings. The right panel shows the robot's orientation within its environment, illustrating how the robot perceives and understands its spatial location relative to surrounding objects.", "section": "APPENDIX A ROBOT HARDWARE DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x12.png", "caption": "Figure A.3: Individual JoyLo arm links.", "description": "The figure shows the individual links of a single JoyLo arm.  Each arm consists of multiple 3D-printed links and low-cost Dynamixel motors. The JoyLo system uses two of these arms for intuitive whole-body teleoperation.", "section": "APPENDIX B JOYLO DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x13.png", "caption": "Figure A.4: Generalization settings for the task \u201cclean house after a wild party\u201d. From left to right: seen and unseen bowl variations, robot\u2019s starting region, and initial object placements on the gaming table.", "description": "Figure A.4 shows the generalization capabilities tested for the task of cleaning up after a party. The left panel displays variations of bowls used in the experiment, categorized as 'seen' (bowls that were included during training) and 'unseen' (bowls not seen during training).  This tests the model's ability to generalize to new, unseen objects. The middle panel illustrates the designated starting region for the robot.  The right panel showcases various initial placements of objects (bowls in this case) on the gaming table. These different starting configurations and object arrangements demonstrate the robustness and adaptability of the robot's learned policy.", "section": "APPENDIX D TASK DEFINITION AND EVALUATION DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x14.png", "caption": "Figure A.5: Generalization settings for the task \u201cclean the toilet\u201d. From left to right: robot\u2019s starting region, sponge variations, and initial placements.", "description": "Figure A.5 shows various aspects of the experimental setup for the \"clean the toilet\" task.  The image shows three key elements. First, it illustrates the robot's designated starting location within the restroom environment. Second, it displays a range of different sponge types used during the experiment to assess the robot's adaptability to varying object characteristics. Third, it shows different initial positions or placements of the toilet cleaning objects before the robot begins the task. These variations help ensure the robustness of the experimental design by testing the robot's ability to complete the task in a variety of realistic scenarios.", "section": "APPENDIX D TASK DEFINITION AND EVALUATION DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/x15.png", "caption": "Figure A.6: Generalization settings for the task \u201ctake trash outside\u201d. From left to right: initial placement region of the trash bag and robot\u2019s starting region.", "description": "The figure displays the generalization settings used for the \"Take Trash Outside\" task within the BEHAVIOR ROBOT SUITE (BRS) experiment.  It showcases two key aspects: the possible starting locations of the robot, indicated by a designated \"Starting Region\", and the various possible initial locations of the trash bag, illustrated as an \"Initial Placement Region\".  This variation in starting configurations and object placement ensures the robustness and generalizability of the learned robot policy by testing its ability to complete the task across a range of realistic scenarios.", "section": "APPENDIX D TASK DEFINITION AND EVALUATION DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/extracted/6261453/appendix/figs/user_study_example-fig.png", "caption": "Figure A.7: Generalization settings for the task \u201cput items onto shelves\u201d. From left to right: robot\u2019s starting region, box placements, and shelf configurations.", "description": "Figure A.7 shows different aspects of the experimental setup for the 'put items onto shelves' task.  It illustrates the variability introduced to test the robustness of the robot's ability to generalize its actions across different scenarios.  The image displays three key elements: the robot's starting position (showing the range of potential starting locations), the arrangement of boxes to be placed onto the shelves (including various placements to increase variability), and finally, several configurations of shelves (demonstrating the different shelf setups the robot was tested on). Each of these variable elements is designed to challenge the robot's ability to perform the task consistently and successfully despite changes in the environment.", "section": "APPENDIX D TASK DEFINITION AND EVALUATION DETAILS"}, {"figure_path": "https://arxiv.org/html/2503.05652/extracted/6261453/appendix/figs/user_study_annotation_gui-fig.png", "caption": "Figure A.8: Generalization settings for the task \u201clay clothes out\u201d. From left to right: robot\u2019s starting region, clothing placements, and clothing variations.", "description": "Figure A.8 shows various scenarios for the task of laying out clothes.  It illustrates the generalization capabilities of the system by showcasing different starting positions for the robot, various arrangements of clothes, and different types of clothing items (e.g., different colors and styles). This demonstrates the robustness of the learned policy and its ability to handle the variability inherent in real-world environments.", "section": "APPENDIX D TASK DEFINITION AND EVALUATION DETAILS"}]