{"references": [{"fullname_first_author": "Yuntao Bai", "paper_title": "Constitutional AI: Harmlessness from AI feedback", "publication_date": "2022-12-08", "reason": "This paper introduces the concept of Constitutional AI, a framework for aligning AI models with human values, which is directly relevant to the core goal of the current paper on image safety."}, {"fullname_first_author": "Stefano Calzavara", "paper_title": "Content security problems? Evaluating the effectiveness of content security policy in the wild", "publication_date": "2016-10-17", "reason": "This paper provides background on the challenges of image content safety in online platforms, establishing the context and significance of the current research."}, {"fullname_first_author": "Jianfa Chen", "paper_title": "Class-RAG: Content Moderation with Retrieval Augmented Generation", "publication_date": "2024-10-14", "reason": "This paper presents a method for content moderation using large language models, which directly relates to the main methodology employed in the current paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a crucial model for multimodal understanding, which is utilized in the current paper for image-text relevance checking."}, {"fullname_first_author": "Patrick Schramowski", "paper_title": "Can Machines Help Us Answering Question 16 in Datasheets, and in Turn Reflecting on Inappropriate Content?", "publication_date": "2022-06-01", "reason": "This paper discusses the challenges of human annotation for safety guidelines, which is a key motivation for the current research's focus on zero-shot methods."}]}