{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-01-01", "reason": "This reference likely introduces a foundational visual language model architecture, influencing the cross-modal alignment approach in FlexIP."}, {"fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "publication_date": "2022-08-01", "reason": "This paper introduces textual inversion, a method for personalizing text-to-image generation which is crucial for understanding how FlexIP attempts to improve personalization capabilities."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2021-01-01", "reason": "This paper introduces classifier-free diffusion guidance, which is key to the text-to-image approach used in the paper, and is used in FlexIP."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP is used as the text encoder in FlexIP, which is used for text-image understanding."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "Latent Diffusion Models are used in FlexIP as a base model to be built upon."}]}