[{"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/preserve_analysis.jpg", "caption": "Figure 1: \nTop: FlexIP showcases versatility and precision in personalized image generation. Given a single reference image (left column), it vividly captures identity details while creatively following diverse text prompts, resulting in coherent yet highly varied edits.\nBottom: FlexIP\u2019s dynamic weight gating mechanism smoothly transitions between strong identity preservation and diverse personalization, significantly outperforming IP-Adapter, which suffers from abrupt identity shifts and rigid control. This reflects superior flexibility and user-friendly controllability.", "description": "Figure 1 demonstrates FlexIP's capabilities in generating personalized images while maintaining the subject's identity.  The top part shows that, given a reference image, FlexIP can produce a range of edits based on various text prompts, while consistently preserving key features of the original image. The bottom part highlights FlexIP's smooth control over the balance between identity preservation and personalization through a dynamic weight gating mechanism, contrasting its performance with the abrupt shifts observed in the IP-Adapter method.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/pipeline.png", "caption": "Figure 2: Comparison with other methods on two indicators, image preservation and text fidelity, demonstrates that our approach surpasses previous methods in both aspects.", "description": "Figure 2 presents a comparison of FlexIP against several state-of-the-art methods across two key metrics: image preservation (the extent to which the model retains the identity of the original image) and text fidelity (how well the generated image matches the given text description). The graph shows that FlexIP outperforms the other methods by achieving a superior balance between both metrics.  This superior performance highlights FlexIP's ability to preserve identity while generating diverse and relevant edits, unlike other methods which typically show a trade-off between these two qualities.", "section": "Related Work"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/comp-main.jpg", "caption": "Figure 3: The overall pipeline of FlexIP. It introduces three key improvements to the model: the preservation adapter, the personalization adapter, and dynamic weight gating. First, the preservation adapter combines high-level and low-level features to ensure preservation. The personalization adapter interacts with text and visual CLS tokens to absorb meaningful visual cues, grounding textual modifications within a coherent visual context. Finally, dynamic weight gating navigates the trade-off between personalization and preservation more effectively through independent adapters controlled by a dynamic weight gating mechanism.", "description": "FlexIP's architecture consists of three main components: a preservation adapter, a personalization adapter, and a dynamic weight gating mechanism. The preservation adapter uses both high-level (CLIP CLS embeddings) and low-level (learnable query embeddings from DINO Patch Embeddings) features to maintain the subject's identity.  The personalization adapter leverages text embeddings and the CLIP CLS embeddings to integrate textual instructions with the subject's visual identity, enabling coherent edits. The dynamic weight gating mechanism allows for continuous control over the balance between identity preservation and personalization by dynamically adjusting the weights of the two adapters.  This approach addresses the common trade-off between these two objectives in image generation.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/comp-var.jpg", "caption": "Figure 4: Qualitative comparison with other methods. Our approach surpasses alternative methods in its exceptional ability to preserve identity while generating a wide range of diverse and personalized outputs.", "description": "Figure 4 presents a qualitative comparison of image generation results from FlexIP and several other state-of-the-art methods.  Each row shows the same subject (e.g., a kitten, a horse, a penguin) subjected to various text prompts to illustrate the diverse outputs.  FlexIP's results demonstrate a high degree of identity preservation, even when the style and context of the generated image change significantly. The comparison aims to showcase FlexIP's superior ability to maintain identity fidelity while producing a greater variety of creative and personalized edits compared to the other methods.", "section": "4.3.2. Qualitative comparison"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/comp-style.jpg", "caption": "Figure 5: The effectiveness of the dynamic weight gating mechanism.", "description": "Figure 5 demonstrates how FlexIP's dynamic weight gating mechanism allows for smooth transitions between identity preservation and personalization.  By adjusting the weight parameter \u03b3(x), users can control the balance between these two aspects.  \u03b3(x) = 0.7 prioritizes preservation, retaining fine details of the original image.  As \u03b3(x) decreases (0.5 and 0.3), personalization increases, resulting in more stylized and diverse outputs while still maintaining a degree of identity preservation. This highlights the flexibility of FlexIP in generating images that meet various needs.", "section": "3.4 Dynamic Weight Gating"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/attnmaps.png", "caption": "Figure 6: Comparison with other methods on style transfer tasks.", "description": "Figure 6 shows a comparison of FlexIP against other methods on style transfer tasks.  It visually demonstrates the ability of each method to successfully apply various artistic styles to an image while maintaining the original image content.  The figure likely showcases the differences in style transfer capabilities, focusing on how well each method preserves the original image's key features and avoids artifacts or distortions while adding the new style.", "section": "4.3.2. Qualitative comparison"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/supp-comp-animals.jpg", "caption": "Figure 7: Visualization of attention maps across different modules.In the image, the white areas of the attention map indicate activation values\u2014the whiter the color, the higher the activation value. It is evident that the two preservation modules function differently: the learnable query module concentrates more on the subject\u2019s details, while the CLIP CLS Embeds focus more on the subject\u2019s global aspects. Consequently, high-level and low-level information complement each other. For the personalization module, the text embeds pay more attention to the surrounding environment and some identity preservation details. This observation supports our decision to decouple preservation and personalization.", "description": "Figure 7 visualizes attention maps from different modules of the FlexIP model, highlighting how each module focuses on specific aspects of image generation.  The learnable query module emphasizes fine details of the subject, while the CLIP CLS embeddings concentrate on the subject's overall structure and appearance. This complementary approach ensures both high-level semantic understanding and low-level detail preservation.  The personalization module, using text embeddings, focuses primarily on the surrounding environment and context while still retaining some awareness of identity-preserving features. The figure supports the paper's design choice to separate identity preservation and personalization into distinct modules.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/supp-comp-human.jpg", "caption": "Figure 8: Qualitative comparison with other methods in animal domain. Our approach surpasses alternative methods in its exceptional ability to preserve identity while generating a wide range of diverse and personalized outputs.", "description": "Figure 8 presents a qualitative comparison of image generation results across different methods, focusing on animal subjects.  The figure showcases how well each method can maintain the subject's identity while producing diverse and personalized images based on text prompts.  Each row shows the reference image followed by the results from FlexIP and several other state-of-the-art methods.  The visual comparison aims to highlight FlexIP's superior performance in preserving the original subject's identity while offering more creative and varied results than other techniques.", "section": "4.3.2 Qualitative comparison"}, {"figure_path": "https://arxiv.org/html/2504.07405/extracted/6349914/assets/pics/exps/supp-comp-objects.jpg", "caption": "Figure 9: Qualitative comparison with other methods in human domain. Our approach surpasses alternative methods in its exceptional ability to preserve identity while generating a wide range of diverse and personalized outputs.", "description": "Figure 9 presents a qualitative comparison of FlexIP against several state-of-the-art methods for image generation, focusing on human subjects.  It showcases how FlexIP excels at maintaining the subject's identity while creating diverse and personalized outputs based on various text prompts.  The figure highlights the differences in identity preservation and the variety of generated images across different models, demonstrating FlexIP's superior performance in balancing identity preservation with creative edits.", "section": "4.3.2. Qualitative comparison"}]