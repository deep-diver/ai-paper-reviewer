{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-05-01", "reason": "This paper is foundational for autoregressive language modeling, which this paper adapts for visual generation, demonstrating the power of autoregressive methods in a broader context."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-06-15", "reason": "This work is crucial as it introduces VQGAN, a critical tokenizer used in this paper's experimental setup for visual data encoding."}, {"fullname_first_author": "Mark Chen", "paper_title": "Generative pretraining from pixels", "publication_date": "2020-06-01", "reason": "This paper introduces a foundational method for autoregressive image generation, establishing the baseline approach for the current work's parallel improvements."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduces the transformer architecture, the core model used by this paper's visual autoregressive approach; it is fundamental to the current state of the art."}, {"fullname_first_author": "Peize Sun", "paper_title": "Autoregressive model beats diffusion: Llama for scalable image generation", "publication_date": "2024-06-01", "reason": "This paper presents LlamaGen, serving as this paper's main baseline for comparison and highlighting the need for improvements in generation speed while maintaining quality in autoregressive image generation."}]}