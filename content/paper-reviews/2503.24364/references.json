{"references": [{"fullname_first_author": "Mark Chen", "paper_title": "Evaluating Large Language Models Trained on Code", "publication_date": "2021-07-01", "reason": "This paper provides a fundamental benchmark for evaluating code generation capabilities of large language models, which is crucial in assessing the progress in text-to-SQL research."}, {"fullname_first_author": "Ruiqi Zhong", "paper_title": "Semantic Evaluation for Text-to-SQL with Distilled Test Suites", "publication_date": "2020-10-01", "reason": "This paper significantly contributes to the development of more robust evaluation methods in text-to-SQL domain via new evaluation metric."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models", "publication_date": "2023-03-01", "reason": "This paper introduces and validates the self-consistency method, a crucial technique that the current paper builds upon and extends for SQL generation."}, {"fullname_first_author": "Jiawei Liu", "paper_title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation", "publication_date": "2023-01-01", "reason": "This work underscores the critical importance of rigorously evaluating code generated by LLMs, setting a high standard in code generation evaluation used by this paper."}, {"fullname_first_author": "Bing Wang", "paper_title": "MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL", "publication_date": "2024-01-01", "reason": "This paper shows an effort to improve the performance of SQL generation task and thus it is important in the context of recent advances."}]}