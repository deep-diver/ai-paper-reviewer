[{"figure_path": "https://arxiv.org/html/2503.24364/x1.png", "caption": "Figure 1: Cost-accuracy analysis for Qwen 2.5 Coder 7B, with or without self-consistency (10-20 samples), compared alongside OpenAI models.", "description": "This figure presents a cost-benefit analysis of using the Qwen 2.5 Coder 7B model for text-to-SQL tasks.  It compares the accuracy achieved at various inference costs, contrasting the model's performance with and without the application of a self-consistency technique. The self-consistency method involves generating multiple query candidates (10-20 samples) and selecting the most semantically consistent one based on their execution results. The figure also includes the performance of several OpenAI models as a benchmark, illustrating the cost-effectiveness of the Qwen model when combined with the self-consistency approach.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2503.24364/x2.png", "caption": "Figure 2: Execution-Guided SQL Generation.", "description": "This figure illustrates the execution-guided SQL generation process.  It begins by sampling several different SQL queries (1). Each query is then executed, and the resulting dataframes are compared pairwise to assess their similarity (2). Finally, the query with the highest average similarity across all comparisons is selected as the best-performing query (3). This method leverages the execution results to measure semantic equivalence directly, rather than relying on superficial structural similarities, improving the accuracy of SQL generation, especially for queries with multiple correct but structurally different representations.", "section": "3 Execution-Guided SQL Generation"}, {"figure_path": "https://arxiv.org/html/2503.24364/x3.png", "caption": "Figure 3: PipeSQL dialect has a property that each query prefix (up to the pipe sequence |>) is also a valid query, making it possible to apply execution-based self-consistency in the middle of the generation process. Instead of sampling n\ud835\udc5bnitalic_n complete SQL sequences, we sample n\ud835\udc5bnitalic_n pipes and stop the generation process. Then, we pick the most consistent pipe and continue the generation sampling n\ud835\udc5bnitalic_n variants of the next pipe.", "description": "The figure illustrates the advantage of using PipeSQL for execution-guided self-consistency. PipeSQL allows for evaluating the validity of query prefixes, which enables applying self-consistency at intermediate steps during query generation.  Instead of generating and evaluating complete SQL queries, the method samples multiple query prefixes (pipes) and selects the most consistent one based on execution results. This approach is then iteratively continued by sampling variants of the next pipe, enhancing accuracy and efficiency.", "section": "3 Execution-Guided SQL Generation"}, {"figure_path": "https://arxiv.org/html/2503.24364/x4.png", "caption": "Figure 4: Self-consistency gains for various sample sizes, temperatures, and models (Gemini 2.0 Flash, Llama 3.3 70B, Codestral, Qwen 2.5 Coder 7B).", "description": "This figure displays the impact of different numbers of samples and temperatures on the effectiveness of self-consistency in improving the accuracy of various large language models (LLMs) in SQL generation tasks.  The models compared include Gemini 2.0 Flash, Llama 3.3 70B, Codestral, and Qwen 2.5 Coder 7B. The x-axis represents the number of samples used in the self-consistency method, while the y-axis shows the resulting accuracy. Different lines correspond to different temperatures.  The figure illustrates how self-consistency gains generally increase with the number of samples, and how this relationship varies depending on the model and the temperature setting.", "section": "4.2 Number of Samples and Temperature"}, {"figure_path": "https://arxiv.org/html/2503.24364/x5.png", "caption": "Figure 5: Effect of replacing outputs produced under greedy decoding by self-consistency outputs. Valid and invalid refer to executability, whereas correct and incorrect\u2014conforming to the gold standard.", "description": "This figure displays the impact of using self-consistency instead of greedy decoding.  It shows how many outputs are improved, remain incorrect, or become incorrect when using self-consistency.  The terms 'valid' and 'invalid' refer to whether the generated SQL code is executable, while 'correct' and 'incorrect' indicate whether the code produces the correct result according to the gold standard (the ideal correct answer). The figure compares the results for two models: DeepSeek Coder 33B and GPT-40 mini, highlighting the effect of self-consistency on improving the correctness of the generated SQL code. ", "section": "5 Qualitative Analysis"}, {"figure_path": "https://arxiv.org/html/2503.24364/x6.png", "caption": "Figure 6: Top problems explaining why BIRD-SQL generations of DeepSeek Coder and GPT-4o mini were incorrect. Greedy decoding compared to self-consistency outputs.", "description": "Figure 6 is a bar chart visualizing the top reasons why DeepSeek Coder and GPT-4o mini models generated incorrect SQL queries on the BIRD-SQL dataset. It contrasts the error types produced by the standard greedy decoding approach and the improved self-consistency method.  The chart directly compares the frequency of errors such as schema linking issues, logical form problems, and projection mistakes, offering a quantitative insight into how self-consistency addresses typical SQL generation inaccuracies.", "section": "5 Qualitative Analysis"}, {"figure_path": "https://arxiv.org/html/2503.24364/x7.png", "caption": "(a)", "description": "This figure displays the impact of replacing outputs generated using greedy decoding with those obtained via self-consistency.  It shows the percentage of outputs that fall into four categories: valid outputs improved by self-consistency, invalid outputs corrected by self-consistency, invalid outputs that remained incorrect, and valid outputs that became incorrect.  The figure presents this breakdown separately for two models: DeepSeek Coder 33B and GPT-40 mini, highlighting the effectiveness of the self-consistency method in improving the quality of the generated outputs.", "section": "4.1 Overall Accuracy Improvements"}, {"figure_path": "https://arxiv.org/html/2503.24364/x8.png", "caption": "(b)", "description": "This figure displays the results of applying execution-based self-consistency to various models.  Specifically, it shows the impact on accuracy (y-axis) at different inference cost levels (x-axis), comparing different models' performance with and without this technique.  The goal is to demonstrate the cost-effectiveness of using execution-based self-consistency to improve SQL query generation accuracy. Note that the specific models and their performance metrics are shown in the figure itself.", "section": "4 Text-to-SQL Experiments"}]