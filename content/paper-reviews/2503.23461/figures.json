[{"figure_path": "https://arxiv.org/html/2503.23461/x2.png", "caption": "Figure 1: TextCrafter enables precise multi-region visual text rendering, addressing the challenges of long, small-size,various numbers, symbols and styles in visual text generation. We illustrate the comparisons among TextCrafter with three state-of-the-art models, i.e., FLUX, TextDiffuser-2 and 3DIS.", "description": "Figure 1 showcases TextCrafter's ability to generate images with multiple text regions, each exhibiting varying lengths, sizes, styles, numbers, and symbols.  It directly addresses common issues in visual text generation, such as distortion, blurriness, and omission. The figure provides a visual comparison of TextCrafter's output against three state-of-the-art models (FLUX, TextDiffuser-2, and 3DIS) across several diverse scenarios, highlighting TextCrafter's superior accuracy and detail in rendering complex visual text.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2503.23461/x3.png", "caption": "Figure 2: Overview of our TextCrafter. TextCrafter consists of three steps. (a) Instance Fusion: Strengthen the connection between visual text and its corresponding carrier. (b) Region Insulation: Leverage the positional priors of the pre-trained DiT model to initialize the layout information for each text instance while separating and denoising text prompts across different regions. (c) Text Focus: Enhance the attention maps of visual text, refing the fidelity of text rendering.", "description": "TextCrafter, a novel framework for complex visual text generation, is illustrated in this figure. It consists of three main steps: 1) Instance Fusion: This step ensures precise alignment between textual content and its visual carrier by integrating the embedding of the preceding quotation mark into the carrier's embedding. This step strengthens the connection between the visual text and its surrounding environment, preventing the text from appearing in incorrect positions. 2) Region Insulation: This step leverages the positional priors of the pre-trained DiT model to initialize the layout information for each text instance while separating and denoising text prompts across different regions. It prevents early interference between text areas, thereby reducing confusion and the risk of content omission in multi-text scenarios. 3) Text Focus: This step enhances the attention maps of visual text, improving the fidelity of text rendering and addressing blurriness, especially in smaller text. This is achieved by introducing an attention control mechanism to amplify the prominence of visual text during the generation process.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2503.23461/x4.png", "caption": "Figure 3: Illustration of tokenizing the prompt \u201cA sidewalk poster with \u2018Register Now for IJCAI 2025\u2019.\u201d along with the attention map corresponding to each token. The use of preceding quotation marks can reinforce the relationship between text tokens and carrier tokens.", "description": "Figure 3 visualizes the process of tokenizing a complex prompt for visual text generation.  The prompt, \"A sidewalk poster with \u2018Register Now for IJCAI 2025\u2019\", is broken down into individual tokens, including punctuation.  The image displays the attention map associated with each token, highlighting how the model focuses on different parts of the prompt. Notably, the figure shows how the inclusion of quotation marks around 'Register Now for IJCAI 2025' strengthens the association between the text phrase and its visual representation (the poster).  This demonstrates a key aspect of the proposed TextCrafter model, which uses such techniques to improve the accuracy of complex visual text generation.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2503.23461/x5.png", "caption": "Figure 4: For a pre-trained DiT model, only a few denoising steps are required to approximate the layout of the image and the relative positions of the main subjects.\nAfter 8 denoising steps, the layout closely resembles that of a full 50-step process, with subsequent steps primarily refining image details.", "description": "This figure demonstrates the efficiency of the TextCrafter model's pre-generation phase.  It shows that using a pre-trained Diffusion-based Image Transformer (DiT) model, a good approximation of the final image layout and the relative positions of key objects can be achieved with far fewer denoising steps than a full generation.  The comparison highlights that after only 8 denoising steps, the generated layout is already very similar to the layout produced after 50 steps. The remaining steps primarily focus on refining the details and visual quality of the image, rather than establishing the overall structure.", "section": "3.3 Region Insulation"}, {"figure_path": "https://arxiv.org/html/2503.23461/x6.png", "caption": "Figure 5: Qualitative comparison of TextCrafter with other baselines on CVTG-2K.\nTextCrafter excels in delivering harmonious and aesthetically pleasing images. It also accurately renders multiple visual texts while maintaining stability in complex scenarios.", "description": "Figure 5 presents a qualitative comparison of TextCrafter's performance against several other state-of-the-art baselines on the CVTG-2K benchmark dataset. The figure showcases example outputs from each model, highlighting TextCrafter's ability to generate visually harmonious and aesthetically pleasing images with multiple text instances.  In contrast to the baseline methods, which often struggle with text distortion, omissions, and blurring, particularly in complex scenarios, TextCrafter consistently renders multiple texts accurately and maintains stability across diverse visual text layouts.", "section": "4 Experiments"}]