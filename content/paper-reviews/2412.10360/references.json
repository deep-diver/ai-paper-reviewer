{"references": [{"fullname_first_author": "Jordan Hoffmann", "paper_title": "Training compute-optimal large language models", "publication_date": "2022-03-29", "reason": "This paper introduces scaling laws for language models, suggesting that performance improves predictably with scale, which is a crucial concept for understanding and developing large multimodal models like those explored in the Apollo paper."}, {"fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-05-28", "reason": "This work introduces GPT-3, a pivotal large language model that demonstrates strong few-shot learning capabilities, significantly influencing the development of multimodal models like Apollo that build upon large language model architectures."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-05", "reason": "This work presents Flamingo, a visual language model demonstrating few-shot learning capabilities, an essential concept for efficiently adapting LMMs like Apollo to various tasks."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "publication_date": "2023-09-26", "reason": "This report details the Qwen series of LLMs, which Apollo utilizes as its backbone across various model sizes."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The first-ever comprehensive evaluation benchmark of multi-modal LLMs in video analysis", "publication_date": "2024-05-23", "reason": "This paper introduces Video-MME, a comprehensive benchmark used extensively in the Apollo study for evaluating the performance of video-centric large multimodal models."}]}