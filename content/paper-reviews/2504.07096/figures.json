[{"figure_path": "https://arxiv.org/html/2504.07096/extracted/6349197/images/pipeline.png", "caption": "Figure 1: \nOLMoTrace on Ai2 Playground.\nLeft: On a response generated by OLMo, OLMoTrace highlights text spans found verbatim in the model\u2019s training data and shows their source documents.\nBrighter highlights indicate spans from more relevant training documents, while darker highlights denote less relevant ones.\nRight: When user clicks the \u201cView Document\u201d button, the document is shown with extended context.\nTry OLMoTrace at https://playground.allenai.org.", "description": "The figure showcases OLMOTrace, a system that traces language model outputs back to their training data.  The left panel displays an example of OLMoTrace in action on the Ai2 Playground.  A response from the language model OLMo is shown with segments highlighted; brighter highlights represent more relevant matches to training data, and darker highlights represent less relevant matches.  Each highlighted segment links to its source document within the model's training data. The right panel shows that clicking on the \"View Document\" button displays the source document with extended context, allowing for a deeper investigation of where the model learned specific phrases.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.07096/extracted/6349197/images/span.png", "caption": "Figure 2: \nThe OLMoTrace inference pipeline, as described in \u00a73.\nFor better illustration, we slightly adjusted the highlighted spans and document relevance from the actual example.", "description": "This figure illustrates the five-step inference pipeline of OLMOTrace.  The process begins with identifying maximal matching spans within the language model (LM) output that are also present in the training data. These spans are then filtered to retain only long and unique spans, which are those that are less frequent in the training data.  Next, the system retrieves the documents from the training data that contain these spans.  Overlapping spans and documents are merged to reduce redundancy. Finally, the retrieved documents are ranked and colored based on their relevance to the LM output and user prompt, ensuring that the most relevant ones are highlighted. The caption mentions slight adjustments were made to the highlighted spans and document relevance for better visualization.", "section": "3 The Inference Pipeline"}, {"figure_path": "https://arxiv.org/html/2504.07096/extracted/6349197/images/usage_spaceneedle.png", "caption": "Figure 3: \nComputation of the maximal matching spans (\u00a73.1).\nFor each suffix of the LM output, OLMoTrace computes its longest matching prefix (color-underlined) with a single Find query on the infini-gram index of the LM training data.\nAll suffixes of the LM output are processed in parallel.\nFinally, non-maximal spans are suppressed.", "description": "OLMOTrace efficiently finds maximal matching spans in a massive training dataset by leveraging the infini-gram index.  For each suffix in the language model's output, it identifies the longest matching prefix within the training data using a single, highly optimized 'Find' query. This process is parallelized across all suffixes, significantly speeding up the computation. A final step removes any spans that are not maximal (i.e., completely contained within another span).", "section": "3.1 Fast Span Computation"}, {"figure_path": "https://arxiv.org/html/2504.07096/extracted/6349197/images/usage_poem.png", "caption": "(a) \nFact checking: Inspecting the document (and its source URL) helps verify the factual claim made in the span.", "description": "The figure shows an example of OLMOTRACE being used for fact-checking.  A language model (LM) output claims that the Space Needle was built for the 1962 World's Fair. OLMOTRACE highlights this claim and links it to a specific document within the LM's training data. The user can click the link to access the source document, which in this case provides evidence supporting the LM's statement. The figure helps to illustrate how OLMOTRACE allows for verification of facts generated by LMs by tracing them back to the original sources in their training data, thereby increasing the transparency of the LM's reasoning.", "section": "5 Case Studies"}, {"figure_path": "https://arxiv.org/html/2504.07096/extracted/6349197/images/usage_arithmetics.png", "caption": "(b) \nTracing \u201ccreative\u201d expressions: Matching spans reveal potential source of LM-generated \u201ccreative\u201d expressions.", "description": "This figure demonstrates how OLMOTRACE can identify the origin of seemingly novel phrases generated by large language models (LLMs).  By highlighting verbatim matches between the LLM's output and segments within its training data, it shows that even phrases perceived as creative or original often have direct counterparts in the training corpus.  This illustrates that LLM creativity is heavily influenced by its training data and that originality may be a matter of recombining existing phrases in novel ways rather than a demonstration of genuinely original thought.", "section": "5 Case Studies"}]