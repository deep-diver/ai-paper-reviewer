{"references": [{"fullname_first_author": "Marah Abdin", "paper_title": "Phi-4 technical report", "publication_date": "2024-12-00", "reason": "This paper introduces a sophisticated seed curation system for controlling data diversity in synthetic data generation, which is a key technique used and discussed in the target paper."}, {"fullname_first_author": "Loubna Ben Allal", "paper_title": "Smollm-corpus", "publication_date": "2024-00-00", "reason": "This paper provides the dataset used as the basis for the MAGACorpus, a key component of the methodology described in the target paper."}, {"fullname_first_author": "Guilherme Penedo", "paper_title": "The refined-web dataset for falcon llm: Outperforming curated corpora with web data only", "publication_date": "2023-00-00", "reason": "This paper explores data curation techniques to enhance the quality and quantity of training data, which is a relevant topic in the context of the target paper."}, {"fullname_first_author": "Jack W Rae", "paper_title": "Scaling language models: Methods, analysis & insights from training gopher", "publication_date": "2021-12-00", "reason": "This paper is a foundational work on scaling language models, providing insights into the relationship between model size, training data, and performance, which is directly relevant to the target paper's focus on scaling."}, {"fullname_first_author": "Jared Kaplan", "paper_title": "Scaling laws for neural language models", "publication_date": "2020-01-00", "reason": "This paper establishes scaling laws for neural language models, a fundamental concept in the field, making it a highly influential and important reference for the target paper."}]}