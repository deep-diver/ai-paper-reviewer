[{"content": "| Dataset | Model | MSE \\(\\[\\]mathcal{X}\\) | MSE \\(\\[\\]mathcal{Z}\\) | FID | Acc% |\n|---|---|---|---|---|---| \n| MNIST | MLP-based | 0.27 | 3e-8 | 394 | 98.42% |\n| MNIST | CNN-based | 0.05 | 2e-2 | 261 | 98.68% |\n| F-MNIST | MLP-based | 0.19 | 4e-5 | 361 | 88.31% |\n| F-MNIST | CNN-based | 0.37 | 4e-2 | 169 | 89.23% |\n| CIFAR-10 | MLP-Mixer | 1.398 | 6e-6 | 423 | 89.29% |\n| CIFAR-10 | CNN-based | 0.056 | 4e-3 | 455 | 93.61% |", "caption": "Table 1: UnSplit attack on MNIST, F-MNIST, and CIFAR-10 datasets.", "description": "This table presents the results of the UnSplit attack on image datasets MNIST, Fashion MNIST, and CIFAR-10.  It compares the attack performance against both MLP-based and CNN-based client models using metrics such as Mean Squared Error (MSE) in the image space (MSE X), MSE in the activation space (MSE Z), Fr\u00e9chet Inception Distance (FID), and the final accuracy of the trained models (Acc%).  The results demonstrate the effectiveness of MLP-based models in resisting feature reconstruction attacks.", "section": "4 Experiments"}, {"content": "| # Parameters / Model | MLP | MLP-Mixer | CNN | SmallMLP |\n|---|---|---|---|---| \n| # | 2,913,290 | 146,816 | 45,278 | 7,850 |", "caption": "Table 2: Number of parameters for different models across.", "description": "This table, located in Section 4, compares the number of parameters across different models used in the experiments: a four-layer MLP, an MLP-Mixer, a CNN, and a two-layer MLP (SmallMLP). The SmallMLP is designed to have a comparable number of parameters to the CNN while having reduced accuracy.", "section": "Experiments"}, {"content": "| Split Layer # | Without noise | With Noise |\n|---|---|---| \n| Ref. | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x36.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x37.png\" width=\"349\"/> |\n| 1 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x38.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x39.png\" width=\"349\"/> |\n| 2 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x40.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x41.png\" width=\"349\"/> |\n| 3 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x42.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x43.png\" width=\"349\"/> |\n| 4 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x44.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x45.png\" width=\"349\"/> |\n| 5 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x46.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x47.png\" width=\"349\"/> |\n| 6 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x48.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x49.png\" width=\"349\"/> |\n| Ref. | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x50.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x51.png\" width=\"349\"/> |\n| 1 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x52.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x53.png\" width=\"349\"/> |\n| 2 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x54.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x55.png\" width=\"349\"/> |\n| 3 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x56.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x57.png\" width=\"349\"/> |\n| 4 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x58.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x59.png\" width=\"349\"/> |\n| 5 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x60.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x61.png\" width=\"349\"/> |\n| 6 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x62.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x63.png\" width=\"349\"/> |\n| Ref. | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x64.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x65.png\" width=\"349\"/> |\n| 1 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x66.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x67.png\" width=\"349\"/> |\n| 2 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x68.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x69.png\" width=\"349\"/> |\n| 3 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x70.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x71.png\" width=\"349\"/> |\n| 4 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x72.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x73.png\" width=\"349\"/> |\n| 5 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x74.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x75.png\" width=\"349\"/> |\n| 6 | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x76.png\" width=\"349\"/> | <img alt=\"[Uncaptioned image]\" src=\"https://arxiv.org/html/2412.11689/x77.png\" width=\"349\"/> |", "caption": "Table 3: Estimated inputs with and without adding noise for various Cut Layers for the MNIST, F-MNIST, and CIFAR-10 datasets. The \"Ref.\" row display the actual inputs, and the next rows display the attack results for different split depths. We took the following noise variance for different datasets: \u03c3=1.6\ud835\udf0e1.6\\sigma=1.6italic_\u03c3 = 1.6 for MNIST, \u03c3=2.6\ud835\udf0e2.6\\sigma=2.6italic_\u03c3 = 2.6 for F-MNIST, \u03c3=0.25\ud835\udf0e0.25\\sigma=0.25italic_\u03c3 = 0.25 for CIFAR-10. Note that theoretical value of \u03c3\ud835\udf0e\\sigmaitalic_\u03c3 for CIFAR-10 is 7.17.17.17.1, but we decided to lower it due to neural network learning issues.", "description": "This table shows the results of reconstructing input images using the UnSplit attack with Differential Privacy (DP) defense, applied for various cut layers on MNIST, Fashion-MNIST, and CIFAR-10 datasets. The table compares the effectiveness of reconstruction with and without adding the DP noise.  Each row represents a different split depth (cut layer), with \"Ref.\" showing the original images. The DP noise variance (\u03c3) is set differently for each dataset to balance privacy and utility. It's worth noting that while the theoretical \u03c3 for CIFAR-10 is 7.1, it was lowered to 0.25 due to complications in training.", "section": "C Additional experiments"}]