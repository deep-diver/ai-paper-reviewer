{"references": [{"fullname_first_author": "Peter Kairouz", "paper_title": "Advances and open problems in federated learning", "publication_date": "2021-01-01", "reason": "This paper provides a comprehensive overview of federated learning, including its various types, applications, and challenges, which are highly relevant to the main topic of the current paper about vertical federated learning."}, {"fullname_first_author": "Cynthia Dwork", "paper_title": "Calibrating noise to sensitivity in private data analysis", "publication_date": "2006-03-04", "reason": "This work introduces differential privacy, which is a crucial technique for privacy preservation in many machine learning scenarios, and is also relevant to vertical federated learning discussed in the current paper."}, {"fullname_first_author": "Matt Fredrikson", "paper_title": "Model inversion attacks that exploit confidence information and basic countermeasures", "publication_date": "2015-01-01", "reason": "This paper focuses on model inversion attacks, a key security concern in vertical federated learning which is directly addressed by the presented study."}, {"fullname_first_author": "Dario Pasquini", "paper_title": "Unleashing the tiger: Inference attacks on split learning", "publication_date": "2021-01-01", "reason": "The authors consider feature-space hijacking attacks in the context of Split Learning, which are central to the discussion on data protection during Vertical Federated Learning in the main paper."}, {"fullname_first_author": "Ege Erdo\u011fan", "paper_title": "Unsplit: Data-oblivious model inversion, model stealing, and label inference attacks against split learning", "publication_date": "2022-11-01", "reason": "This is the main attack targeting feature reconstruction in Split Learning used as a baseline to validate claims presented in the paper."}]}