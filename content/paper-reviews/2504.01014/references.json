{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is important because it introduces CLIP, which is used for character consistency and semantic consistency."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces T5, which is used to represent action descriptions of videos."}, {"fullname_first_author": "Jialu Li", "paper_title": "Unbounded: A generative infinite game of character life simulation", "publication_date": "2024-01-01", "reason": "This paper provides the foundation work for infinite anime life simulation that this paper seeks to improve upon."}, {"fullname_first_author": "Aakanksha Chowdhery", "paper_title": "Palm: Scaling language modeling with pathways", "publication_date": "2023-01-01", "reason": "This paper highlights the power of large language models and motivates the authors to use them to solve the research problem."}, {"fullname_first_author": "Yupeng Zhou", "paper_title": "Storydiffusion: Consistent self-attention for long-range image and video generation", "publication_date": "2025-01-01", "reason": "The authors mention this paper when discussing the baseline method StoryDiffusion, and is mentioned as part of the GSC process."}]}