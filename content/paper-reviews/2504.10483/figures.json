[{"figure_path": "https://arxiv.org/html/2504.10483/x2.png", "caption": "Figure 1: Can we unlock VAE for end-to-end tuning with latent-diffusion models? \u2212-- Traditional deep learning wisdom dictates that end-to-end training is often preferable when possible. However, latent diffusion models usually only update the generator network while keeping the variational auto-encoder (VAE) fixed (a). This is because directly using the diffusion loss to update the VAE (b) causes the latent space to collapse. We show that while direct diffusion-loss is ineffective, end-to-end training can be unlocked through the representation-alignment (REPA) loss \u2212-- allowing both encoder and diffusion model to be jointly tuned during the training process (c).\nNotably, this allows for significantly accelerated training; speeding up training by over 17\u00d717\\times17 \u00d7 and 45\u00d745\\times45 \u00d7 over REPA and vanilla training recipes, respectively (d).", "description": "Figure 1 explores the challenges and solutions for end-to-end training of latent diffusion models with variational autoencoders (VAEs).  Traditional methods keep the VAE frozen during training, updating only the generator network (a). Directly applying the diffusion loss to the VAE leads to latent space collapse (b).  This figure demonstrates that representation-alignment (REPA) loss enables end-to-end training, jointly updating both the VAE and the diffusion model (c), resulting in significantly faster training speeds (d).  Specifically, training is 17 times faster compared to REPA and 45 times faster than vanilla training methods.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2504.10483/extracted/6357628/figures/vae_latent_space_teaser-v2.png", "caption": "(a) PCA Analysis on VAE Latent Space Structure", "description": "This figure visualizes the latent space structure of different VAEs (Variational Autoencoders) before and after end-to-end training using Principal Component Analysis (PCA).  The PCA projects the high-dimensional latent space into three dimensions, represented as RGB color channels.  The visualizations allow for a comparison of the latent space's characteristics (such as smoothness and noise levels) before and after the end-to-end training process, showcasing how end-to-end tuning affects the VAE's learned representation.", "section": "4. End-to-End Training Automatically Improves VAE Latent-Space Structure"}, {"figure_path": "https://arxiv.org/html/2504.10483/x3.png", "caption": "(b) Performance Improvements with REPA-E (400K Steps)", "description": "This figure's subplot (b) shows the improvement in performance achieved by using REPA-E after 400,000 training steps.  It compares the final generation performance (as measured by the gFID-50K metric) of different approaches to training latent diffusion models:  REPA and REPA-E. The bar chart visually demonstrates the significant improvement in generation quality offered by REPA-E in comparison to REPA.", "section": "4. End-to-End Training Automatically Improves VAE Latent-Space Structure"}, {"figure_path": "https://arxiv.org/html/2504.10483/extracted/6357628/figures/gfid-cknna-corr-v4.png", "caption": "Figure 2: End-to-End Training Automatically Improves VAE Latent-Space Structure. (a) Following [25], we visualize latent space structure from different VAEs before and after end-to-end training using principal component analysis (PCA) that projects them to three channels colored by RGB. We consider SD-VAE [39], and IN-VAE222trained on imagenet at f16d32 using official training code from [39]., a 16\u00d716\\times16 \u00d7 downsampling, 32-channel VAE trained on ImageNet [6]. For SD-VAE we find that latent representations have high-frequency noise. Applying end-to-end tuning helps learning a more smooth and less noisy latent representation. Interestingly to the contrast, the latent space for IN-VAE is over-smoothed (e.g., row-2). Applying end-to-end tuning automatically helps learn a more detailed latent space structure to best support final generation performance. (b) Jointly tuning both VAE and latent diffusion model (LDM) significantly improves final generation performance (gFID) across different VAE architectures.", "description": "This figure demonstrates the impact of end-to-end training on the latent space structure of Variational Autoencoders (VAEs).  Part (a) uses Principal Component Analysis (PCA) to visualize the latent space of two different VAEs (SD-VAE and IN-VAE) before and after end-to-end training.  It shows that SD-VAE's latent space initially contains high-frequency noise, which is reduced through end-to-end training, resulting in a smoother representation.  Conversely, IN-VAE's latent space is initially over-smoothed, but end-to-end training adds detail, resulting in a more refined representation. Part (b) shows that jointly training the VAE and Latent Diffusion Model (LDM) leads to significant improvements in the final generation performance (measured by gFID), regardless of the VAE architecture.", "section": "End-to-End Training Improves VAE Latent-Space Structure"}, {"figure_path": "https://arxiv.org/html/2504.10483/x4.png", "caption": "(a) PCA Visualization of Latent Spaces", "description": "This figure uses Principal Component Analysis (PCA) to visualize the latent spaces of several Variational Autoencoders (VAEs) with and without end-to-end training using the REPA loss.  The visualization allows for a comparison of the latent space structure before and after training, highlighting the impact of the proposed method on the quality and characteristics of the latent representations.  Different VAEs exhibit different latent space properties (high-frequency noise, over-smoothing, etc.) which are altered through the end-to-end training process. ", "section": "3. REPA-E: Unlocking VAE for Joint Training"}, {"figure_path": "https://arxiv.org/html/2504.10483/x7.png", "caption": "(b) Correlation: gFID & CKNNA Score", "description": "This figure shows a strong correlation between the generation FID (gFID) score and the representation alignment score (CKNNA).  Lower gFID indicates better image generation quality.  The plot demonstrates that a higher CKNNA score is strongly correlated with a lower gFID, suggesting that aligning representations improves image generation performance.  The R-squared value of 0.97 indicates a very strong correlation.", "section": "3. REPA-E: Unlocking VAE for Joint Training"}, {"figure_path": "https://arxiv.org/html/2504.10483/x8.png", "caption": "(c) E2E tuning with REPA improves CKNNA Score", "description": "This figure demonstrates the effectiveness of end-to-end training with the representation alignment (REPA) loss.  The left panel (a) shows a PCA visualization of latent spaces, highlighting the impact of end-to-end tuning with diffusion loss versus REPA loss. The middle panel (b) shows the strong correlation between the CKNNA (an alignment score) and generation FID, suggesting that higher alignment improves generation quality.  The right panel (c) is the main focus, illustrating how end-to-end training with REPA consistently increases the CKNNA score over training iterations compared to standard REPA training. This proves that incorporating the REPA loss into the end-to-end process allows improved alignment of representations, ultimately leading to better image generation.", "section": "3. REPA-E: Unlocking VAE for Joint Training"}]