{"references": [{"fullname_first_author": "Rowan Zellers", "paper_title": "Defending against neural fake news", "publication_date": "2019-01-01", "reason": "This paper is important as it represents early work on mitigating neural fake news, which is highly relevant to the detection of AI-generated misinformation."}, {"fullname_first_author": "Sebastian Gehrmann", "paper_title": "GLTR: Statistical detection and visualization of generated text", "publication_date": "2019-01-01", "reason": "This paper is important because it provided valuable early insights by leveraging statistical methods to differentiate between human and machine-generated text, which represents a fundamental approach in this field."}, {"fullname_first_author": "Iz Beltagy", "paper_title": "Longformer: The long-document transformer", "publication_date": "2020-01-01", "reason": "This paper is important as the model was used in this paper and provided better results over unseen domains and generators' texts because of its longer context length."}, {"fullname_first_author": "Liam Dugan", "paper_title": "RAID: A shared benchmark for robust evaluation of machine-generated text detectors", "publication_date": "2024-01-01", "reason": "This paper introduces a benchmark used for robust evaluation of machine-generated text detectors, allowing for standardized comparison of different methods."}, {"fullname_first_author": "Pengcheng He", "paper_title": "DeBERTav3: Improving deBERTa using ELECTRA-style pre-training with gradient-disentangled embedding sharing", "publication_date": "2023-01-01", "reason": "This reference is important because it relates to methods for natural language processing."}]}