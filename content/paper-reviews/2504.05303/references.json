{"references": [{"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023-01-01", "reason": "This paper is essential because InteractVLM's Multi-View contact Localization model (MV-Loc) builds upon SAM [33], indicating its significance."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "This paper is important since InteractVLM uses LLaVA [43] as its VLM for reasoning which is then built upon."}, {"fullname_first_author": "Yuhang Yang", "paper_title": "Grounding 3D object affordance from 2D interactions in images", "publication_date": "2023-01-01", "reason": "This paper is important because InteractVLM trains and evaluates on the PIAD [67] dataset, indicating its importance for object affordance prediction."}, {"fullname_first_author": "Shashank Tripathi", "paper_title": "DECO: Dense estimation of 3D human-scene contact in the wild", "publication_date": "2023-01-01", "reason": "This paper is essential since InteractVLM is based on DECO [60] and shows improvement on the approach."}, {"fullname_first_author": "Javier Romero", "paper_title": "Embodied hands: Modeling and capturing hands and bodies together", "publication_date": "2022-01-01", "reason": "This paper is essential because InteractVLM represents the human with a SMPL+H [55] 3D body mesh"}]}