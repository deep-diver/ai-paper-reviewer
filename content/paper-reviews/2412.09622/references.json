{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundation of diffusion models for image generation, a core concept upon which the current research builds."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-04-01", "reason": "This paper presents Stable Diffusion, a highly influential model that significantly advanced text-to-image generation and is directly relevant to the customization techniques explored in the current work."}, {"fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2021-06-01", "reason": "This paper introduces LoRA, a key technique used for efficient model customization which is central to the proposed method."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine-tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-06-01", "reason": "This paper introduces DreamBooth, a method for personalizing diffusion models, directly influencing the current work's focus on multi-concept image generation."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with clip latents", "publication_date": "2022-04-01", "reason": "This paper is highly influential in demonstrating the effectiveness of text-to-image generation using diffusion models and CLIP, providing a strong baseline for comparison and improvement."}]}