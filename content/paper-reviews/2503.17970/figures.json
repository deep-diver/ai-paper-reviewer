[{"figure_path": "https://arxiv.org/html/2503.17970/extracted/6302563/PathoHR.png", "caption": "Figure 1: The proposed PathoHR pipeline for breast cancer os prediction. The pipeline consists of three main components: (1) patch-wise feature extraction, (2) token merge similarity calculation for representation\nlearning, and (3) a plug-and-play ViTAR encoder, that connects to the Transformer Encoder Block and incorporates Attention operations to generate predictive outputs.", "description": "The figure illustrates the PathoHR pipeline for predicting breast cancer survival.  It's broken into three main stages: 1) Patch-wise Feature Extraction: Whole Slide Images (WSIs) are segmented into smaller patches, and features are extracted from each patch using a pre-trained UNet encoder. 2) Similarity Calculation and Token Merging:  Multiple similarity metrics (Euclidean distance, cosine distance, attention score, and semantic similarity) are employed to measure the similarity between patches. Similar patches are then merged using an adaptive token merging mechanism, improving feature representation. 3) Plug-and-play ViTAR Encoder: The merged patches are fed into a high-resolution Vision Transformer (ViT) architecture that processes these features to generate predictions for patient survival outcomes. The ViTAR encoder uses adaptive token merging and fuzzy positional encoding to handle various input patch sizes and maintain high accuracy with less computational cost. The entire pipeline facilitates the efficient use of high-resolution images for more accurate survival predictions, addressing the challenge of tumor heterogeneity.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2503.17970/extracted/6302563/fig2.similarity.png", "caption": "Figure 2: This figure illustrates five different methods of calculating similarity: (1) Euclidean Similarity [17]; (2) Cosine Similarity [18]; (3) Attention Score [13]; (4) Semantic Similarity [32]; and (5) ToMe Similarity [3].", "description": "Figure 2 compares five different methods for calculating the similarity between image patches: Euclidean distance, cosine similarity, attention score, semantic similarity, and ToMe similarity. Each method is visually represented, showing its unique approach to computing similarity and its integration within the overall architecture.  The figure highlights the different ways these methods process and combine features to identify similar patches within the whole-slide images, which is crucial for effective representation learning in the downstream classification task.", "section": "3.2 Similarity Calculation for Token Merging"}, {"figure_path": "https://arxiv.org/html/2503.17970/extracted/6302563/auc_comparison.jpg", "caption": "Figure 3: Performance on breast cancer classification task. Different models using WSIs as input for breast cancer classification tasks are evaluated. AUC values are reported.", "description": "Figure 3 presents a comparative analysis of breast cancer classification performance using Whole Slide Images (WSIs) as input.  Multiple models, including several variations of the proposed PathoHR pipeline and other established methods (ResNet50+ABMIL, ResNet50+Avg., HIPT_CLS-4K, CTransPath+Avg., CTransPath+Intra, CTransPath+ABMIL, and TANGLE), were evaluated on this task. The figure displays a bar chart representing the Area Under the Curve (AUC) values for each model, providing a visual comparison of their performance in classifying breast cancer types.  The AUC serves as a metric to evaluate the model's ability to distinguish between different classes of breast cancer, with higher AUC values indicating better performance. The chart allows for a direct comparison of the efficacy of various models in handling this classification challenge using WSIs.", "section": "4 Experiments"}]