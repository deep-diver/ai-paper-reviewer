[{"figure_path": "https://arxiv.org/html/2504.06261/x1.png", "caption": "Figure 1: An intuitive explanation of Hogwild!\u200b Inference, with 2 workers generating in parallel and 3 shared cache blocks. Each color denotes a cache block. See it in action (example generation).", "description": "This figure illustrates the Hogwild! Inference mechanism, showing two Language Model (LLM) workers collaboratively generating text.  They share a common cache (divided into three colored blocks), allowing each worker to see and utilize the other's progress. Each color represents a distinct cache block, containing different parts of the generated text.  The figure demonstrates how the parallel workers can access and update the shared cache concurrently, enabling efficient collaboration and faster generation.", "section": "3 Hogwild! Inference"}, {"figure_path": "https://arxiv.org/html/2504.06261/x2.png", "caption": "Figure 2: Three cache layouts described in Section\u00a03.2: interleaved with step-wise synchrony (left), simple contiguous layout (middle) and combined with token-wise synchrony (right). All layouts are made from Alice point of view.", "description": "Figure 2 illustrates three different cache layout strategies used in Hogwild! Inference, all shown from Alice's perspective.  The left panel depicts an *interleaved layout* with step-wise synchrony.  Here, workers take turns adding their generated tokens to the shared cache, ensuring that each worker sees the complete set of tokens generated in previous steps before adding their own. The middle panel shows a *contiguous layout*, where each worker appends tokens sequentially to their own section of the shared cache. This design is simpler but leads to less coordination between workers. The rightmost panel presents a *combined layout* that integrates elements of both previous approaches. It uses token-wise synchrony, meaning workers can access each other's tokens as soon as they are generated, while also maintaining a shared history of all previous steps. This combined layout aims to offer the benefits of both coordination and efficiency.", "section": "3.2 Cache Layouts"}, {"figure_path": "https://arxiv.org/html/2504.06261/x5.png", "caption": "Figure 3: (left) Evaluation results for synthetic problems with 5 gsm8k questions each. (right) evaluation on 512 LIMO tasks. The horizontal black line corresponds to running single-threaded reasoning for 16384 tokens (Accuracy 89.65%). More budgets in Appendix\u00a0B (Figure\u00a04).", "description": "This figure presents a comparison of different parallel inference methods on two types of tasks: synthetic problems and LIMO tasks.  The left panel shows the accuracy achieved by various methods (1, 2, and 4 workers) on synthetic problems comprising 5 GSM8K questions each, plotted against the token budget. The right panel displays accuracy for 512 LIMO tasks, again showing results for different parallel methods.  A horizontal black line in both plots indicates the accuracy (89.65%) obtained using single-threaded reasoning with a token budget of 16384.  Additional results for various token budgets are provided in Appendix B, Figure 4.", "section": "4 Initial Experiments"}]