{"references": [{"fullname_first_author": "Yu Cao", "paper_title": "Animediffusion: Anime face line drawing colorization via diffusion models.", "publication_date": "2023-03-11", "reason": "This paper is highly relevant due to its focus on anime line art colorization, a key topic of the current paper, and it uses diffusion models, which are also employed in MangaNinja."}, {"fullname_first_author": "Zekun Li", "paper_title": "Eliminating gradient conflict in reference-based line-art colorization.", "publication_date": "2022-00-00", "reason": "This paper tackles a key challenge in reference-based line art colorization addressed by MangaNinja: resolving conflicts between the line art and reference image for accurate colorization."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models.", "publication_date": "2023-00-00", "reason": "This work is highly relevant as it introduces conditional control in text-to-image diffusion models, a technique that MangaNinja adapts and enhances for line art colorization."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models.", "publication_date": "2022-00-00", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, which forms the foundation for MangaNinja's approach and is essential to its performance."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision.", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is used in MangaNinja for image embedding and feature extraction, highlighting its importance in the model's architecture and performance."}]}