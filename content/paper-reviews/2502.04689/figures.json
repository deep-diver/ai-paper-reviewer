[{"figure_path": "https://arxiv.org/html/2502.04689/x1.png", "caption": "Figure 1: ARR motivation. To answer a question, we often need to analyze the question\u2019s intent, retrieve relevant information, and reason step by step.", "description": "This figure illustrates the three key steps involved in the ARR (Analyzing, Retrieving, and Reasoning) method for question answering.  The process begins with analyzing the question's intent to understand what information is needed. Then, relevant information is retrieved. Finally, step-by-step reasoning is applied to arrive at an answer.  This figure visually represents the core idea behind ARR, which is to guide large language models (LLMs) through these explicit stages to enhance their reasoning capabilities during question answering, as opposed to more generic approaches.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.04689/x2.png", "caption": "Figure 2: Question answering with LLMs. We first obtain rationale risubscript\ud835\udc5f\ud835\udc56r_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by reasoning generation and then select the optimal option via evaluating the language modeling losses of different context-option combinations.", "description": "This figure illustrates the two-stage question answering process using Large Language Models (LLMs).  In the first stage (Reasoning Generation), the LLM generates a rationale (r<sub>i</sub>) based on the input passage (p<sub>i</sub>), question (q<sub>i</sub>), answer trigger sentence (&), and option list (o<sub>i</sub>).  The second stage (Option Selection) involves evaluating the language modeling losses of different context-option combinations, which include the input passage, question, answer trigger sentence, rationale and each option from the list, to finally select the optimal option (o<sub>i</sub>*).", "section": "3 Question Answering with LLMs"}, {"figure_path": "https://arxiv.org/html/2502.04689/x3.png", "caption": "Figure 3: Model size experiments. The trend of QA performance changes as the model becomes larger.", "description": "This figure shows the relationship between the size of the language model and its performance on question answering tasks.  As the model size increases (measured in the number of parameters), the accuracy on various question-answering datasets generally improves.  The graph visually represents this trend, showing the performance gains obtained by using larger models.  This demonstrates the scaling law phenomenon, where larger models tend to exhibit improved performance in many NLP tasks.", "section": "6.1 Model Sizes"}]