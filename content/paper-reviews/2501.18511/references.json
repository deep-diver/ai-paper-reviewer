{"references": [{"fullname_first_author": "Lambert, N.", "paper_title": "Tulu 3: Pushing frontiers in open language model post-training", "publication_date": "2024-11-15", "reason": "This paper is the main basis for the authors' own SFT experiments, and is compared directly with the results of RE-WILD."}, {"fullname_first_author": "Zhao, W.", "paper_title": "Wildchat: 1m chatgpt interaction logs in the wild", "publication_date": "2024-05-01", "reason": "This paper provides the foundation dataset upon which WILDCHAT-50M is built."}, {"fullname_first_author": "Feuer, B.", "paper_title": "Style outweighs substance: Failure modes of LLM judges in alignment benchmarking", "publication_date": "2024-09-15", "reason": "This paper provides crucial insights into the methodology used for evaluating and interpreting LLMs as judges."}, {"fullname_first_author": "Dubois, Y.", "paper_title": "Length-controlled alpacaeval: A simple way to debias automatic evaluators", "publication_date": "2024-04-04", "reason": "This paper provides an important benchmark dataset used for comparing the performance of different models in downstream tasks."}, {"fullname_first_author": "Kwon, W.", "paper_title": "Efficient memory management for large language model serving with pagedattention", "publication_date": "2023-00-00", "reason": "This paper provides the foundation inference framework (VLLM) for data generation in WILDCHAT-50M."}]}