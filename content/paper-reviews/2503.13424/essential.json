{"importance": "This paper is important for researchers because it addresses the critical need for **high-quality, scalable articulated object datasets in embodied AI**. By offering a procedural generation pipeline that rivals existing datasets and generative models, this research **opens new avenues for training and evaluating AI agents** in complex, interactive environments. The approach's capacity for creating diverse and realistic articulated objects can **significantly advance research in robotics, simulation, and computer vision**.", "summary": "Infinite Mobility: Procedural generation of high-fidelity articulated objects for scalable embodied AI training.", "takeaways": ["Introduces a novel procedural generation pipeline for creating high-fidelity articulated objects.", "Demonstrates superior results compared to existing datasets and state-of-the-art generative models in terms of both physical properties and mesh quality.", "Shows that synthetic data from the pipeline can be used to train generative models, enabling next-step scaling."], "tldr": "Existing methods for creating articulated objects are either data-driven, limited by the scale/quality of training data, or simulation-based, facing fidelity/labor challenges. High-quality articulated objects are desperately needed for embodied AI. Addressing this, the paper introduces a novel procedural pipeline to synthesize large-scale, high-fidelity articulated objects. \n\nThe approach, **Infinite Mobility**, uses procedural generation boosted by annotated 3D datasets. User studies and quantitative evaluations show the method excels against current state-of-the-art methods, rivaling human-annotated datasets in physics and mesh quality. The synthetic data is used to train generative models, enabling next-step scaling.", "affiliation": "Shanghai Artificial Intelligence Laboratory", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.13424/podcast.wav"}