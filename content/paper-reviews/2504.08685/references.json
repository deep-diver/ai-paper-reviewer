{"references": [{"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper introduces the use of transformers in diffusion models (DiT), a key architecture used in the Seaweed-7B model."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2023-01-01", "reason": "This paper introduces Direct Preference Optimization (DPO) which is used in the Seaweed-7B model to address issues such as degradation in motion and structure."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper presents high-resolution image synthesis with latent diffusion models, another architecture the Seaweed-7B model leverages."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the transformer architecture, an important piece for modern deep learning which the Seaweed-7B model uses."}, {"fullname_first_author": "Richard Zhang", "paper_title": "The unreasonable effectiveness of deep features as a perceptual metric", "publication_date": "2018-01-01", "reason": "This paper introduces Learned Perceptual Image Patch Similarity (LPIPS), a key metric for the Seaweed-7B model that is used for perceptual similarity."}]}