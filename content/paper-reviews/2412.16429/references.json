{"references": [{"fullname_first_author": "Irina Jurenka", "paper_title": "Towards responsible development of generative AI for education: An evaluation-driven approach", "publication_date": "2024-07-12", "reason": "This is the authors' own initial tech report, forming the basis for the current work and its methodology."}, {"fullname_first_author": "Daniel M. Ziegler", "paper_title": "Fine-tuning language models from human preferences", "publication_date": "2019-09-08", "reason": "This paper introduces the Reinforcement Learning from Human Feedback (RLHF) method, which is crucial to LearnLM's training."}, {"fullname_first_author": "Gemini Team", "paper_title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context", "publication_date": "2024-03-05", "reason": "LearnLM is based on Gemini 1.5 Pro, making this the foundational model for the improved system."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-00-00", "reason": "This paper details the instruction following method, central to LearnLM's pedagogical approach."}, {"fullname_first_author": "Andrew Gelman", "paper_title": "Bayesian data analysis", "publication_date": "1995-00-00", "reason": "The Bayesian statistical framework used for quantitative analysis in the paper is based on this key reference."}]}