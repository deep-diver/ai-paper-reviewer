[{"figure_path": "https://arxiv.org/html/2504.02587/x1.png", "caption": "Figure 1: Text-dominant tasks rely on text with visual support; vision-dominant tasks rely on visuals with textual support.", "description": "Figure 1 presents two example tasks to illustrate the difference between text-dominant and vision-dominant visual reasoning problems.  The text-dominant example shows a geometry problem where the majority of the necessary information is provided in the text, and the image serves as supplementary visual aid.  The vision-dominant example, in contrast, presents a visual mathematical problem where the solution primarily depends on extracting key information directly from the image, with the text providing minimal contextual support or instructions.", "section": "2 Preparation"}, {"figure_path": "https://arxiv.org/html/2504.02587/x2.png", "caption": "Figure 2: Overview of Maye framework. The process is divided into four steps. Each step integrates various components, including text and vision data, policy models, and reward signals.", "description": "The MAYE framework is a four-step process for reinforcement learning (RL) in vision-language models (VLMs).  Step 1 involves data preprocessing: text and vision data are processed and converted into model-compatible inputs. Step 2 focuses on response collection: the model generates responses to the input queries, which are then collected and processed. Step 3 describes trajectory generation: this involves computing log probabilities for both policy and reference models, generating rewards, and assembling them into a trajectory for further use in the RL training process.  Finally, Step 4 is for policy updates: based on the collected trajectories, the policy model's parameters are updated to improve performance.", "section": "3 MAYE Framework: A Transparent, From-Scratch RL Framework for VLM"}, {"figure_path": "https://arxiv.org/html/2504.02587/extracted/6321957/figures/eval_scheme.png", "caption": "Figure 3: Overview of evaluation metrics.", "description": "This figure provides a visual overview of the evaluation metrics used in the paper to assess the performance of reinforcement learning (RL) in vision-language models (VLMs).  It's broken down into three categories: Training Set Metrics, Validation & Test Set Metrics, and Reflection Metrics.  The Training Set Metrics focus on tracking the training dynamics, including accuracy curves and response lengths.  Validation & Test Set Metrics measure the model's performance on unseen data using various settings (pass@8, pass@1 with different temperatures and top_p values). Finally, Reflection Metrics assess the reflective reasoning capabilities of the model, using metrics like reflection ratios and the frequency of specific reflective words in the model's responses.", "section": "4 MAYE Scheme: Tracking Training Dynamics in RL for LLMs/VLMs"}, {"figure_path": "https://arxiv.org/html/2504.02587/x3.png", "caption": "(a) Qwen2-VL-Instruct-7B@mm_math5k", "description": "This figure presents training set metrics for the Qwen2-VL-Instruct-7B model trained on the mm_math5k dataset.  It shows multiple metrics including training accuracy, reflection ratio, response length, and counts of specific reflection words ('verify' and 'recheck' in this case). The curves illustrate the training dynamics over epochs and generation steps. Shaded areas represent standard deviation across three independent runs.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x4.png", "caption": "(b) Qwen2.5-VL-Instruct-7B@mm_math5k", "description": "This figure presents training set metrics for the Qwen2.5-VL-Instruct-7B model trained on the mm_math5k dataset.  It shows training accuracy, response length, and reflection ratios (reflection_ratio, correct_ratio_in_reflection_texts,  frequency of specific reflection words).  The plot illustrates how these metrics evolve during the training process and how they relate to each other.  Shaded regions indicate standard deviation across three runs. ", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x5.png", "caption": "(c) Qwen2-VL-Instruct-7B@geometry3k", "description": "This figure (Figure 4c) presents training set metrics for the Qwen2-VL-Instruct-7B model, trained on the geometry3k dataset.  It shows training accuracy, reflection ratio, response length, and usage frequency of specific reflection words ('verify' and 're-evaluate'). The plot illustrates the dynamics of these metrics over training epochs (x-axis) and generation steps (x-axis), enabling analysis of the model's learning process and reflective behavior during RL training.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x6.png", "caption": "(d) Qwen2.5-VL-Instruct-7B@geometry3k", "description": "This figure (Figure 4d) presents the training set metrics for the Qwen2.5-VL-Instruct-7B model trained on the geometry3k dataset.  It shows training accuracy, response length, and the reflection ratios (reflection_ratio, correct_ratio_in_reflection_texts, and frequencies of specific reflection words) over the course of training. The shaded regions represent standard deviation across three independent runs.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x7.png", "caption": "Figure 4: Training set metrics across models and datasets.\nRed curves show training accuracy (per epoch) and response length (per generation step).\nBlue curves depict key reflection ratios from\u00a0Sec.\u00a04, and green curves illustrate the usage trends of the two most frequent and dynamic reflection words per experiment.\nShaded regions represent standard deviation across three runs.", "description": "Figure 4 presents a detailed analysis of training dynamics across four different experimental setups involving two distinct vision-language models (Qwen2-VL-Instruct-7B and Qwen2.5-VL-Instruct-7B) and two datasets (mm_math5k and geometry3k).  The figure displays multiple key metrics plotted against the training epoch. Red curves illustrate two core metrics: training accuracy and response length.  Training accuracy reflects the model's correctness on the training dataset over each epoch, while response length tracks the average length of the model's responses.  Blue curves represent key reflection ratios (detailed in Section 4 of the paper), which show the model's tendency towards reflective behavior. Green curves show the usage frequency of the two most frequent and dynamically changing reflection words in each experiment.  Shaded areas around the curves indicate the standard deviation calculated from three independent runs of each experiment, providing a measure of the variability in the results.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x8.png", "caption": "(a) Qwen2-VL-Instruct-7B@mm_math5k", "description": "Training set metrics for the Qwen2-VL-Instruct-7B model on the mm_math5k dataset. The figure shows training accuracy, response length, and reflection ratios over training epochs and generation steps, providing insights into training dynamics and model behavior.  Specific reflection word trends are also highlighted.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x9.png", "caption": "(b) Qwen2.5-VL-Instruct-7B@mm_math5k", "description": "Training set metrics for the Qwen2.5-VL-Instruct-7B model trained on the mm_math5k dataset.  The figure displays the training accuracy, response length, reflection ratio, and usage frequency of two highly dynamic reflection words ('verify' and 'recheck') across training epochs and generation steps. Shaded areas represent standard deviation across three runs. This visualization helps analyze the correlation between model performance, output length, and the occurrence of reflective behavior during the RL training process.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x10.png", "caption": "(c) Qwen2-VL-Instruct-7B@geometry3k", "description": "Training set metrics for the Qwen2.5-VL-Instruct-7B model on the geometry3k dataset. The figure shows training accuracy, response length, and reflection ratios (reflection ratio, reflection ratio in correct answers, correct ratio in reflection texts, reflection ratio in incorrect answers, correct ratio in no reflection texts) across training epochs or generation steps. The curves are shaded to represent standard deviation across three runs.  Green curves represent the frequency of the words \u201cre-evaluate\u201d and \u201cverify\u201d, selected based on frequency and variation. ", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x11.png", "caption": "(d) Qwen2.5-VL-Instruct-7B@geometry3k", "description": "Training set metrics for the Qwen2.5-VL-Instruct-7B model on the geometry3k dataset.  The plot shows training accuracy, response length, and reflection ratios over training epochs.  Specifically, it displays the trends of training accuracy, response length, and several reflection ratio metrics (reflection ratio, correct ratio in reflection, ratio of reflection in correct answers, ratio of reflection in incorrect answers, and correct ratio in no reflection).  The shaded area represents the standard deviation across three independent runs.  It further details the usage trends of two specific reflection words (re-evaluate and verify), highlighting their role in the model's reflective reasoning process.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x12.png", "caption": "Figure 5: Validation and test accuracy curves across training epochs for different VLMs and datasets. Red lines denote RL, blue lines denote SFT (see\u00a0Sec.\u00a05.5), and green indicate untrained (Vanilla) performance. All curves are averaged over 3 runs, with shaded areas indicating standard deviation.", "description": "Figure 5 presents a detailed comparison of validation and test accuracies across multiple Vision-Language Models (VLMs) and datasets, trained using different methods.  The x-axis represents the training epochs, while the y-axis shows the accuracy.  Three lines are displayed for each model and dataset combination: a red line representing the performance after Reinforcement Learning (RL) training, a blue line showing Supervised Fine-Tuning (SFT) results, and a green line indicating the baseline performance of the untrained model (Vanilla).  Each line represents the average accuracy across three independent training runs, with shaded regions illustrating the standard deviation to show the variability in performance.", "section": "5.4 Validation & Test set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x13.png", "caption": "(a) Qwen2-VL-Instruct-7B@mm_math5k", "description": "This figure displays training set metrics for the Qwen2-VL-Instruct-7B model trained on the mm_math5k dataset.  The plots illustrate the accuracy curve over epochs, the average response length across generation steps, and the reflection ratios (the proportion of responses containing certain reflective words) over generation steps. Shaded areas indicate standard deviation across three independent runs.  The figure provides key insights into the learning dynamics of the model, revealing relationships between accuracy, response length, and reflective behavior during the training process.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x14.png", "caption": "(b) Qwen2.5-VL-Instruct-7B@mm_math5k", "description": "Training dynamics of the Qwen2.5-VL-Instruct-7B model on the mm_math5k dataset. The figure displays training accuracy, response length, and reflection ratios over training epochs and generation steps.  Shaded regions show standard deviation over three independent runs.  The dynamics of the two most frequent and dynamic reflection words, \"verify\" and \"recheck,\" are also plotted.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x15.png", "caption": "(c) Qwen2-VL-Instruct-7B@geometry3k", "description": "Training set metrics for the Qwen2.5-VL-Instruct-7B model on the geometry3k dataset.  The figure shows training accuracy and response length over training epochs,  as well as key reflection ratios (reflection_ratio, correct_ratio_in_reflection_texts, etc.) and the frequency of specific reflection words (e.g., \"re-evaluate\", \"verify\") during training. Shaded areas represent standard deviation across three independent runs.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x16.png", "caption": "(d) Qwen2.5-VL-Instruct-7B@geometry3k", "description": "This figure (Figure 4d in the paper) presents training set metrics for the Qwen2.5-VL-Instruct-7B model trained on the geometry3k dataset.  It displays four key metrics across training epochs: training accuracy, response length, reflection ratio, and the frequency of specific reflection words ('verify' and 're-evaluate'). The shaded areas represent standard deviation across three independent runs. This visualization allows for analysis of training dynamics and reveals correlations between response length, reflection, and accuracy.", "section": "5.2 Training Set Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2504.02587/x17.png", "caption": "Figure 6: Reflection Ratios", "description": "This figure visualizes the dynamics of five reflection ratios throughout the RL training process across four different experimental settings.  Each setting combines a specific VLM model (Qwen2-VL-Instruct-7B or Qwen2.5-VL-Instruct-7B) with a particular dataset (mm_math5k or geometry3k). The ratios displayed\u2014reflection ratio, reflection ratio in correct answers, reflection ratio in incorrect answers, correct ratio in reflection texts, and correct ratio in no reflection texts\u2014quantify the prevalence and impact of reflective behaviors in the model's responses. The graphs show how these metrics evolve across generation steps, revealing the interplay between reflection and the accuracy of the model's reasoning ability.", "section": "4 MAYE Scheme: Tracking Training Dynamics in RL for LLMs/VLMs"}, {"figure_path": "https://arxiv.org/html/2504.02587/x18.png", "caption": "(a) Qwen2-VL-Instruct-7B@mm_math5k", "description": "This figure displays training set metrics for the Qwen2-VL-Instruct-7B model trained on the mm_math5k dataset.  It presents four key metrics: training accuracy, reflection ratio, the count of two specific reflection words ('verify' and 'recheck'), and response length.  The plots show how these metrics change over the course of training epochs and generation steps, providing insights into the model's learning dynamics and behavior. Shaded regions represent standard deviations across three independent runs, illustrating the variability in training performance.", "section": "5.2 Training Set Results and Analysis"}]