{"references": [{"fullname_first_author": "Dao, T.", "paper_title": "Transformers are ssms: Generalized models and efficient algorithms through structured state space duality", "publication_date": "2024-05-21", "reason": "This paper introduces the Mamba-2 model, which is central to the proposed mmMamba architecture, providing the foundation for the linear-complexity decoder-only VLM."}, {"fullname_first_author": "Gu, A.", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-12-00", "reason": "This paper introduces the original Mamba model, a precursor to Mamba-2, establishing the base for linear-complexity sequence modeling that mmMamba builds upon."}, {"fullname_first_author": "Tao, C.", "paper_title": "HoVLE: Unleashing the power of monolithic vision-language models with holistic vision-language embedding", "publication_date": "2024-12-16", "reason": "HoVLE serves as the teacher model in the distillation process, providing the high-performing quadratic-complexity model from which mmMamba inherits knowledge."}, {"fullname_first_author": "Chen, Y.", "paper_title": "A single transformer for scalable vision-language modeling", "publication_date": "2024-07-06", "reason": "This paper introduces SOLO, whose training recipe is adapted in mmMamba's distillation process for effective knowledge transfer and training efficiency."}, {"fullname_first_author": "Bavishi, R.", "paper_title": "Introducing our multimodal models", "publication_date": "2023-00-00", "reason": "This paper introduces Fuyu-8B, a significant decoder-only VLM that demonstrates the potential of this architectural approach and is a key inspiration for the decoder-only strategy of mmMamba."}]}