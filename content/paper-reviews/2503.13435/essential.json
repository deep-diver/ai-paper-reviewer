{"importance": "This paper introduces **a new benchmark** for 4D reconstruction, which can encourage researchers to develop more robust and generalized 4D reconstruction methods. It also introduces a novel method to address the limitations of existing 4D reconstruction techniques, which can **serve as a solid foundation for future research** in this field.", "summary": "WideRange4D: A new benchmark & reconstruction method for high-quality 4D scenes with wide-range movements, pushing the boundaries of 4D reconstruction.", "takeaways": ["Introduces WideRange4D, a new 4D reconstruction benchmark with wide-range spatial movements and scenes.", "Presents Progress4D, a novel 4D reconstruction method that generates stable and high-quality 4D results.", "Progress4D outperforms existing state-of-the-art 4D reconstruction methods on the WideRange4D benchmark."], "tldr": "Existing 4D reconstruction methods are limited by their inability to handle wide-range spatial movements and the lack of suitable datasets for evaluation. Current benchmarks mainly focus on actions performed in place within limited scenarios, highlighting the need for datasets that include more complex spatial dynamics. Additionally, existing methods struggle with deformation fields for dynamics estimation, resulting in poor quality when dealing with wide-range movements.\n\nThis paper introduces **WideRange4D**, a novel 4D reconstruction benchmark designed to address these limitations. It features rich 4D scene data with large spatial variations, enabling a more comprehensive evaluation of 4D generation methods. The paper also presents **Progress4D**, a new 4D reconstruction method that divides the generation process into high-quality 3D scene reconstruction and progressive fitting of 4D dynamics, achieving stable and high-quality results in complex scenes.", "affiliation": "Peking University", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2503.13435/podcast.wav"}