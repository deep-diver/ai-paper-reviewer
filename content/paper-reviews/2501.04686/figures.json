[{"figure_path": "https://arxiv.org/html/2501.04686/x1.png", "caption": "Figure 1: We compare the reasoning ability of URSA-7B and other open-source MLLMs across different topics on MathVista and MathVerse, as well as their reasoning stability when faced with changes in modal information content.", "description": "This figure presents a radar chart comparing the performance of the URSA-7B model against several other open-source large language models (LLMs) on two benchmark datasets: MathVista and MathVerse.  Each axis represents a different category of mathematical reasoning problems (e.g., statistical reasoning, geometry reasoning). The lengths of the vectors emanating from the center of the chart represent the accuracy of each model on the corresponding task.  The chart also shows how the models perform when the type of input data (text-only, text-lite, etc.) is varied to assess their robustness when the type and amount of modal information change. The overall goal of the figure is to demonstrate the superior reasoning ability and stability of the URSA-7B model across various mathematical problems and different data conditions.", "section": "Related Work"}, {"figure_path": "https://arxiv.org/html/2501.04686/x2.png", "caption": "Figure 2: Data sources used by the URSA-7B model during the VL-alignment and SFT phases.", "description": "This figure shows the data sources used to train the URSA-7B model.  It breaks down the composition of the URSA-alignment-960K dataset used in the vision-language alignment phase and the MMathCoT-1M dataset used in the subsequent supervised fine-tuning (SFT) phase.  The figure visually represents the percentage contribution of each dataset to the overall training data.  It highlights the diversity of sources, including datasets focusing on various mathematical problem types and formats (e.g., geometry, word problems, and tables).", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x3.png", "caption": "Figure 3: CoT augmentation and verifying for multimodal mathematical data from three type of sources using Gemini-1.5-Flash-002.", "description": "This figure illustrates the process of generating high-quality chain-of-thought (CoT) reasoning data for multimodal mathematics. It uses Gemini-1.5-Flash-002 to augment existing datasets in three ways: CoT distillation, trajectory rewriting, and format unification.  The figure shows examples of how input data from three different sources is transformed using these techniques to create a more consistent and comprehensive CoT dataset for training and validating multimodal mathematical reasoning models.  Each step demonstrates how Gemini-1.5-Flash-002 is used to enhance the reasoning process, leading to a unified, improved CoT format suitable for fine-tuning.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x4.png", "caption": "Figure 4: Demonstration of Misinterpretation Insertion Engine.", "description": "This figure demonstrates the process of inserting misinterpretations into a reasoning chain. The example shows a chart about public opinion on labor unions, broken down by age, education level, and political leaning. The model initially extracts information correctly, identifying that certain groups have more favorable views toward unions. However, a misinterpretation is then introduced, such as incorrectly interpreting the data for one group. Following the misinterpretation, the model continues to reason and draw incorrect conclusions based on this flawed interpretation. This illustrates how the engine creates training data by highlighting logical errors stemming from visual misinterpretations.", "section": "3.2. CoT Augmentation in Multimodal Mathematics"}, {"figure_path": "https://arxiv.org/html/2501.04686/x5.png", "caption": "Figure 5: An illustration of the training process for URSA-7B and URSA-RM-7B, with data from the three stages coming from URSA-alignment-960K, MMathCoT-1M, and DualMath-1.1M, respectively. The modules that are frozen and those that need to be trained are distinguished in each stage.", "description": "This figure illustrates the three-stage training process for the URSA-7B and URSA-RM-7B models.  Stage 1 involves vision-language alignment using the URSA-alignment-960K dataset, focusing on aligning the vision encoder and language model. Stage 2 performs mathematical instruction fine-tuning on the MMathCoT-1M dataset, enhancing the model's chain-of-thought (CoT) reasoning capabilities.  Finally, Stage 3 employs dual-view process supervision using the DualMath-1.1M dataset, training a verifier model (URSA-RM-7B) to enhance the reasoning at test time.  The figure clearly shows which model components are frozen and which are trained during each stage.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x8.png", "caption": "Figure 6: Pass@N and Best-of-N results comparison on MathVerse and MathVista-GPS.", "description": "This figure compares the performance of different methods for improving the accuracy of chain-of-thought reasoning in mathematical problem-solving, specifically focusing on two benchmarks: MathVerse and MathVista-GPS.  It shows how the 'pass@N' metric (the percentage of times a model correctly answers a question within N attempts) and the 'best-of-N' metric (choosing the best answer among N attempts) change with the number of samples (N). The methods compared likely include the baseline model, a self-consistency approach, and the URSA-RM-7B verifier model, which are described in the paper. The results visualize how using multiple samples and the verifier can lead to significant improvements in accuracy compared to relying on a single answer.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2501.04686/x9.png", "caption": "Figure 7: Ablation Study w.r.t CoT Augmentation during Math SFT Stage on the MathVista testmini Set.", "description": "This figure presents the results of an ablation study investigating the impact of chain-of-thought (CoT) augmentation during the mathematical instruction fine-tuning (Math SFT) stage on the MathVista testmini dataset.  It shows how the performance of the model changes when CoT augmentation is removed, providing a quantitative analysis of the contribution of CoT reasoning to the model's capabilities on various subtasks within MathVista. This allows for a better understanding of the effectiveness of the CoT augmentation strategy.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x10.png", "caption": "Figure 8: Ablation Study w.r.t CoT Augmentation during Math SFT Stage on the MathVerse benchmark.", "description": "This figure shows the ablation study with respect to chain-of-thought (CoT) augmentation during the mathematical instruction fine-tuning (Math SFT) stage on the MathVerse benchmark.  It visually compares the performance of the model with and without CoT augmentation across various sub-tasks within the MathVerse benchmark. The graph likely shows accuracy or a similar performance metric on the y-axis, and different sub-tasks or aspects of the MathVerse benchmark on the x-axis. This allows readers to see how much the addition of CoT augmentation improves the model's performance on each MathVerse sub-task.", "section": "Experiment"}, {"figure_path": "https://arxiv.org/html/2501.04686/x11.png", "caption": "Figure 9: Prompt \ud835\udcab\ud835\udc9esubscript\ud835\udcab\ud835\udc9e\\mathcal{P}_{\\mathcal{C}}caligraphic_P start_POSTSUBSCRIPT caligraphic_C end_POSTSUBSCRIPT used for CoT distillation on answer-only source data.", "description": "Prompt  \ud835\udcab\ud835\udc9e for CoT distillation is used to generate chain-of-thought (CoT) reasoning from answer-only data. The prompt instructs the model to produce a step-by-step solution that leads to the given answer, emphasizing the importance of maintaining consistency between the generated reasoning and the provided answer.  The prompt also ensures that the model doesn't request additional information or express uncertainty, focusing instead on a clear and concise solution.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x12.png", "caption": "Figure 10: Prompt \ud835\udcab\u211bsubscript\ud835\udcab\u211b\\mathcal{P}_{\\mathcal{R}}caligraphic_P start_POSTSUBSCRIPT caligraphic_R end_POSTSUBSCRIPT used for CoT solution rewriting on analysis-formatted source data.", "description": "This figure shows the prompt used in the paper for the CoT solution rewriting task on analysis-formatted data. The prompt instructs the model to rewrite a given solution while maintaining the correctness of both the process and the final answer. It emphasizes the need for semantically coherent transcription and forbids the model from making requests or altering parts of the given solution.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x13.png", "caption": "Figure 11: Prompt \ud835\udcab\u2131subscript\ud835\udcab\u2131\\mathcal{P}_{\\mathcal{F}}caligraphic_P start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT used for unifying solution format across style-varied source data.", "description": "Prompt  \ud835\udcab\u2131 used for unifying solution format across style-varied source data. This prompt is used in the data synthesis process for the instruction fine-tuning of the URSA-7B model. The prompt instructs the model to convert a formal mathematical solution into a natural language explanation, ensuring clarity, conciseness, and adherence to the original solution's steps and final answer, avoiding modifications or reinterpretations.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x14.png", "caption": "Figure 12: Prompt used for checking CoT augmentation response based on consistency and correction.", "description": "This figure shows the prompt used for evaluating the quality of chain-of-thought (CoT) augmentation responses.  The prompt guides the evaluator to assess the response based on two key criteria: solution fidelity (whether the reasoning is sound and free of speculation, and whether the final conclusion matches the given standard answer) and solution consistency (whether the reasoning steps logically lead to the answer without discrepancies). The evaluator is instructed to provide a judgment of \"yes\" or \"no\" based on this evaluation.", "section": "3. Model Training Process"}, {"figure_path": "https://arxiv.org/html/2501.04686/x15.png", "caption": "Figure 13: Prompt used for inserting interpretation into geometry-related samples.", "description": "This figure presents the prompt used for the misinterpretation insertion engine in the Dual-view Process Supervised Data Synthesis stage.  The prompt instructs the model to introduce errors into a geometry problem solution by misreading the diagram and producing an incorrect answer. The process involves three stages: analyzing the correct solution, introducing a misinterpretation, and continuing reasoning with the misinterpretation to arrive at an incorrect answer.  The prompt emphasizes that the misreading should be integrated naturally into the solution without explicit statements about making a misinterpretation, and the final answer should be marked with '\u2020Answer:'.", "section": "3.3. Dual-view Process Supervised Data Synthesis"}, {"figure_path": "https://arxiv.org/html/2501.04686/x16.png", "caption": "Figure 14: Prompt used for inserting interpretation into function and statistics-related samples.", "description": "This figure shows the prompt used in the misinterpretation insertion engine for function and statistics related samples. The prompt instructs the model to introduce errors into a solution by misinterpreting a coordinate axis or chart.  The model must identify areas in the solution where diagram information is extracted, choose one area to introduce a misinterpretation, and continue the reasoning process to derive an incorrect answer.  The response should be natural and avoid explicitly mentioning misinterpretations. The prompt includes tags to mark correct and incorrect steps and specifies that the final answer should not be tagged. The misinterpretation action must be consistent with the plan outlined in the prompt. ", "section": "3.3. Dual-view Process Supervised Data Synthesis"}, {"figure_path": "https://arxiv.org/html/2501.04686/x17.png", "caption": "Figure 15: Case on MathVista-GPS.", "description": "This figure shows a geometry problem from the MathVista-GPS dataset. The problem involves a quadrilateral ABCD where AD = 6, AB = 4, and DE bisects angle ADC, intersecting BC at point E.  The question asks for the length of BE. The figure displays several different attempts to solve this problem using different methods. These attempts include a correct solution, and solutions produced by GPT-40, Gemini-1.5-Flash-002, MultiMath-7B, Math-LLaVA-13B, and URSA-7B.  The figure highlights the different approaches and results obtained by each method, illustrating the variety of reasoning paths used to solve geometry problems and the different levels of accuracy achieved.", "section": "4. Experiment"}, {"figure_path": "https://arxiv.org/html/2501.04686/x18.png", "caption": "Figure 16: Case on MathVerse.", "description": "The figure displays a geometry problem from the MathVerse benchmark dataset.  The problem involves a circle with a tangent line and several angles. The question asks for the length of a specific line segment (AP), given the length of another line segment (OP) and the measure of a particular angle (\u2220BOC).  Different models' solutions and their correctness are compared and illustrated.", "section": "4. Experiment"}]