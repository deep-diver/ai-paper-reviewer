[{"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T1.4\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1\" style=\"font-size:90%;\">Existing</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.2.1\" style=\"font-size:90%;\">GPU memory</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.3.1\" style=\"font-size:90%;\">Inference</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.4.1\" style=\"font-size:90%;\">Generation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.5.1\" style=\"font-size:90%;\">Solution</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S3.T1.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.2.1.1\" style=\"font-size:90%;\">solution</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.2.2.1\" style=\"font-size:90%;\">consumption</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.2.3.1\" style=\"font-size:90%;\">latency</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.2.4.1\" style=\"font-size:90%;\">quality</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.2.5.1\" style=\"font-size:90%;\">usability</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.4.3.1\"><span class=\"ltx_text\" id=\"S3.T1.4.3.1.1\" style=\"font-size:90%;\">\u2460</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.3.2\"><span class=\"ltx_text\" id=\"S3.T1.4.3.2.1\" style=\"font-size:90%;\">Large</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.3.3\"><span class=\"ltx_text\" id=\"S3.T1.4.3.3.1\" style=\"font-size:90%;\">High</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.3.4\"><span class=\"ltx_text\" id=\"S3.T1.4.3.4.1\" style=\"font-size:90%;\">Good</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.3.5\"><span class=\"ltx_text\" id=\"S3.T1.4.3.5.1\" style=\"font-size:90%;\">Good</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.4.4.1\"><span class=\"ltx_text\" id=\"S3.T1.4.4.1.1\" style=\"font-size:90%;\">\u2461</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.4.2\"><span class=\"ltx_text\" id=\"S3.T1.4.4.2.1\" style=\"font-size:90%;\">Large</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.4.3\"><span class=\"ltx_text\" id=\"S3.T1.4.4.3.1\" style=\"font-size:90%;\">Medium</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.4.4\"><span class=\"ltx_text\" id=\"S3.T1.4.4.4.1\" style=\"font-size:90%;\">Good</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.4.5\"><span class=\"ltx_text\" id=\"S3.T1.4.4.5.1\" style=\"font-size:90%;\">Medium</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.4.5.1\"><span class=\"ltx_text\" id=\"S3.T1.4.5.1.1\" style=\"font-size:90%;\">\u2462</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.5.2\"><span class=\"ltx_text\" id=\"S3.T1.4.5.2.1\" style=\"font-size:90%;\">Small</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.5.3\"><span class=\"ltx_text\" id=\"S3.T1.4.5.3.1\" style=\"font-size:90%;\">\u2014</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.5.4\"><span class=\"ltx_text\" id=\"S3.T1.4.5.4.1\" style=\"font-size:90%;\">Medium</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.4.5.5\"><span class=\"ltx_text\" id=\"S3.T1.4.5.5.1\" style=\"font-size:90%;\">Bad</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.4.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.1.1\" style=\"font-size:90%;\">AlayaDB</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.4.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.2.1\" style=\"font-size:90%;\">Small</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.4.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.3.1\" style=\"font-size:90%;\">Low</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.4.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.4.1\" style=\"font-size:90%;\">Good</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.4.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.5.1\" style=\"font-size:90%;\">Good</span></td>\n</tr>\n</table>", "caption": "Table 1. LLM inference solutions analysis", "description": "This table compares different Large Language Model (LLM) inference solutions across four key aspects: GPU memory consumption, inference latency, generation quality, and solution usability.  It helps to understand the trade-offs between different approaches to optimizing LLM inference, highlighting the advantages and disadvantages of coupled architectures, KV cache disaggregation, retrieval-based sparse attention, and the authors' proposed AlayaDB solution.", "section": "3. Analysis of Existing Solutions"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T2.4\">\n<tr class=\"ltx_tr\" id=\"S5.T2.4.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.4.1.1.1\">DB abstraction and provided APIs</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.2.1\"><code class=\"ltx_verbatim ltx_font_typewriter\" id=\"S5.T2.4.2.1.1\">DB.create_session(prompts) -&gt; Session, prompts</code></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.3.1\"><code class=\"ltx_verbatim ltx_font_typewriter\" id=\"S5.T2.4.3.1.1\">DB.import(prompts, kv_cache)</code></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.4.1\"><code class=\"ltx_verbatim ltx_font_typewriter\" id=\"S5.T2.4.4.1.1\">DB.store(session)</code></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.4.5.1.1\">Session abstraction and provided APIs</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.6.1\"><code class=\"ltx_verbatim ltx_font_typewriter\" id=\"S5.T2.4.6.1.1\">Session.attention(q, layer) -&gt; o</code></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.4.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.4.7.1\"><code class=\"ltx_verbatim ltx_font_typewriter\" id=\"S5.T2.4.7.1.1\">Session.update(q, k, v, layer) -&gt; k, v</code></td>\n</tr>\n</table>", "caption": "Table 2. AlayaDB APIs", "description": "This table lists the Application Programming Interfaces (APIs) provided by AlayaDB for interacting with its database and managing LLM sessions.  It details the functions for creating sessions, importing and storing data, and performing attention calculations within the context of a session.", "section": "System Overview of AlayaDB"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.F4.2\">\n<tr class=\"ltx_tr\" id=\"S5.F4.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.F4.1.1.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"348\" id=\"S5.F4.1.1.1.g1\" src=\"x4.png\" width=\"789\"/></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.F4.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.F4.2.3.1\"><span class=\"ltx_text\" id=\"S5.F4.2.3.1.1\" style=\"font-size:90%;\">(a) Original code using flash-attention and transformers</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.F4.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.F4.2.2.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"348\" id=\"S5.F4.2.2.1.g1\" src=\"x5.png\" width=\"789\"/></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.F4.2.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.F4.2.4.1\"><span class=\"ltx_text\" id=\"S5.F4.2.4.1.1\" style=\"font-size:90%;\">(b) Modified code using AlayaDB with transformers</span></td>\n</tr>\n</table>", "caption": "Table 3. The number k\ud835\udc58kitalic_k of required tokens in different tasks", "description": "This table presents the number of critical tokens (k) needed for different tasks in long-context large language model (LLM) inference to achieve the same accuracy as using all tokens.  The tasks represent various applications of LLMs, including question answering (Qasper, HotpotQA, TriviaQA), summarization (QMSum), code completion (LCC), and passage retrieval.  The table shows that the required number of tokens varies significantly across tasks, ranging from a small number (20 for TriviaQA) to a much larger number (350 for Qasper), reflecting the complexity of each task.", "section": "6.1 Dynamic Inner Product Range Query (DIPR)"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S6.T3.7\">\n<tr class=\"ltx_tr\" id=\"S6.T3.7.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_ll ltx_border_r ltx_border_t\" id=\"S6.T3.7.1.1\"><span class=\"ltx_text\" id=\"S6.T3.7.1.1.1\" style=\"font-size:90%;\">Task</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.1.2\"><span class=\"ltx_text\" id=\"S6.T3.7.1.2.1\" style=\"font-size:90%;\">k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S6.T3.7.1.3\"><span class=\"ltx_text\" id=\"S6.T3.7.1.3.1\" style=\"font-size:90%;\">proportion</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.1.4\"><span class=\"ltx_text\" id=\"S6.T3.7.1.4.1\" style=\"font-size:90%;\">Task</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.1.5\"><span class=\"ltx_text\" id=\"S6.T3.7.1.5.1\" style=\"font-size:90%;\">k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S6.T3.7.1.6\"><span class=\"ltx_text\" id=\"S6.T3.7.1.6.1\" style=\"font-size:90%;\">proportion</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.7.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_ll ltx_border_r ltx_border_tt\" id=\"S6.T3.7.2.1\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.2.1.1\" style=\"font-size:90%;\">Qasper</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S6.T3.7.2.2\"><span class=\"ltx_text\" id=\"S6.T3.7.2.2.1\" style=\"font-size:90%;\">350</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\" id=\"S6.T3.7.2.3\"><span class=\"ltx_text\" id=\"S6.T3.7.2.3.1\" style=\"font-size:90%;\">9.67%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S6.T3.7.2.4\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.2.4.1\" style=\"font-size:90%;\">LCC</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S6.T3.7.2.5\"><span class=\"ltx_text\" id=\"S6.T3.7.2.5.1\" style=\"font-size:90%;\">65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\" id=\"S6.T3.7.2.6\"><span class=\"ltx_text\" id=\"S6.T3.7.2.6.1\" style=\"font-size:90%;\">5.26%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.7.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_ll ltx_border_r ltx_border_t\" id=\"S6.T3.7.3.1\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.3.1.1\" style=\"font-size:90%;\">Passage R.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.3.2\"><span class=\"ltx_text\" id=\"S6.T3.7.3.2.1\" style=\"font-size:90%;\">250</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S6.T3.7.3.3\"><span class=\"ltx_text\" id=\"S6.T3.7.3.3.1\" style=\"font-size:90%;\">2.69%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.3.4\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.3.4.1\" style=\"font-size:90%;\">HotpotQA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T3.7.3.5\"><span class=\"ltx_text\" id=\"S6.T3.7.3.5.1\" style=\"font-size:90%;\">200</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S6.T3.7.3.6\"><span class=\"ltx_text\" id=\"S6.T3.7.3.6.1\" style=\"font-size:90%;\">2.19%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.7.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_ll ltx_border_r ltx_border_t\" id=\"S6.T3.7.4.1\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.4.1.1\" style=\"font-size:90%;\">QMSum</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S6.T3.7.4.2\"><span class=\"ltx_text\" id=\"S6.T3.7.4.2.1\" style=\"font-size:90%;\">150</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t\" id=\"S6.T3.7.4.3\"><span class=\"ltx_text\" id=\"S6.T3.7.4.3.1\" style=\"font-size:90%;\">1.41%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S6.T3.7.4.4\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S6.T3.7.4.4.1\" style=\"font-size:90%;\">TriviaQA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S6.T3.7.4.5\"><span class=\"ltx_text\" id=\"S6.T3.7.4.5.1\" style=\"font-size:90%;\">20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t\" id=\"S6.T3.7.4.6\"><span class=\"ltx_text\" id=\"S6.T3.7.4.6.1\" style=\"font-size:90%;\">0.24%</span></td>\n</tr>\n</table>", "caption": "Table 4. Characteristics of index types", "description": "This table compares different index types used in AlayaDB for efficient sparse attention computation in LLMs.  It shows how each index type (Coarse, Fine, and Flat) impacts GPU memory consumption, latency for both small and large numbers of required tokens (k), and the types of queries each supports (Top-k, Filter, DIPR). This helps to understand the trade-offs between memory usage, speed, and query capabilities when selecting an index for different LLM workloads and performance needs.", "section": "6.2 Query Optimizer in AlayaDB"}, {"content": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\" id=\"S6.F7.2\">\n<tr class=\"ltx_tr\" id=\"S6.F7.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.F7.1.1.1\">\u00a0\u00a0\u00a0 (a) <math alttext=\"|C|\\leq l_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S6.F7.1.1.1.m1.1\"><semantics id=\"S6.F7.1.1.1.m1.1a\"><mrow id=\"S6.F7.1.1.1.m1.1.2\" xref=\"S6.F7.1.1.1.m1.1.2.cmml\"><mrow id=\"S6.F7.1.1.1.m1.1.2.2.2\" xref=\"S6.F7.1.1.1.m1.1.2.2.1.cmml\"><mo id=\"S6.F7.1.1.1.m1.1.2.2.2.1\" stretchy=\"false\" xref=\"S6.F7.1.1.1.m1.1.2.2.1.1.cmml\">|</mo><mi id=\"S6.F7.1.1.1.m1.1.1\" xref=\"S6.F7.1.1.1.m1.1.1.cmml\">C</mi><mo id=\"S6.F7.1.1.1.m1.1.2.2.2.2\" stretchy=\"false\" xref=\"S6.F7.1.1.1.m1.1.2.2.1.1.cmml\">|</mo></mrow><mo id=\"S6.F7.1.1.1.m1.1.2.1\" xref=\"S6.F7.1.1.1.m1.1.2.1.cmml\">\u2264</mo><msub id=\"S6.F7.1.1.1.m1.1.2.3\" xref=\"S6.F7.1.1.1.m1.1.2.3.cmml\"><mi id=\"S6.F7.1.1.1.m1.1.2.3.2\" xref=\"S6.F7.1.1.1.m1.1.2.3.2.cmml\">l</mi><mn id=\"S6.F7.1.1.1.m1.1.2.3.3\" xref=\"S6.F7.1.1.1.m1.1.2.3.3.cmml\">0</mn></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.F7.1.1.1.m1.1b\"><apply id=\"S6.F7.1.1.1.m1.1.2.cmml\" xref=\"S6.F7.1.1.1.m1.1.2\"><leq id=\"S6.F7.1.1.1.m1.1.2.1.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.1\"></leq><apply id=\"S6.F7.1.1.1.m1.1.2.2.1.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.2.2\"><abs id=\"S6.F7.1.1.1.m1.1.2.2.1.1.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.2.2.1\"></abs><ci id=\"S6.F7.1.1.1.m1.1.1.cmml\" xref=\"S6.F7.1.1.1.m1.1.1\">\ud835\udc36</ci></apply><apply id=\"S6.F7.1.1.1.m1.1.2.3.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.3\"><csymbol cd=\"ambiguous\" id=\"S6.F7.1.1.1.m1.1.2.3.1.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.3\">subscript</csymbol><ci id=\"S6.F7.1.1.1.m1.1.2.3.2.cmml\" xref=\"S6.F7.1.1.1.m1.1.2.3.2\">\ud835\udc59</ci><cn id=\"S6.F7.1.1.1.m1.1.2.3.3.cmml\" type=\"integer\" xref=\"S6.F7.1.1.1.m1.1.2.3.3\">0</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.F7.1.1.1.m1.1c\">|C|\\leq l_{0}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.F7.1.1.1.m1.1d\">| italic_C | \u2264 italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.F7.2.2.3\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (b) Point pruning</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.F7.2.2.2\">\u00a0\u00a0 (c) <math alttext=\"\\bm{q}\\cdot\\bm{k}^{T}\\geq\\bm{q}\\cdot\\hat{\\bm{c}}^{T}-\\beta\" class=\"ltx_Math\" display=\"inline\" id=\"S6.F7.2.2.2.m1.1\"><semantics id=\"S6.F7.2.2.2.m1.1a\"><mrow id=\"S6.F7.2.2.2.m1.1.1\" xref=\"S6.F7.2.2.2.m1.1.1.cmml\"><mrow id=\"S6.F7.2.2.2.m1.1.1.2\" xref=\"S6.F7.2.2.2.m1.1.1.2.cmml\"><mi id=\"S6.F7.2.2.2.m1.1.1.2.2\" xref=\"S6.F7.2.2.2.m1.1.1.2.2.cmml\">\ud835\udc92</mi><mo id=\"S6.F7.2.2.2.m1.1.1.2.1\" lspace=\"0.222em\" rspace=\"0.222em\" xref=\"S6.F7.2.2.2.m1.1.1.2.1.cmml\">\u22c5</mo><msup id=\"S6.F7.2.2.2.m1.1.1.2.3\" xref=\"S6.F7.2.2.2.m1.1.1.2.3.cmml\"><mi id=\"S6.F7.2.2.2.m1.1.1.2.3.2\" xref=\"S6.F7.2.2.2.m1.1.1.2.3.2.cmml\">\ud835\udc8c</mi><mi id=\"S6.F7.2.2.2.m1.1.1.2.3.3\" xref=\"S6.F7.2.2.2.m1.1.1.2.3.3.cmml\">T</mi></msup></mrow><mo id=\"S6.F7.2.2.2.m1.1.1.1\" xref=\"S6.F7.2.2.2.m1.1.1.1.cmml\">\u2265</mo><mrow id=\"S6.F7.2.2.2.m1.1.1.3\" xref=\"S6.F7.2.2.2.m1.1.1.3.cmml\"><mrow id=\"S6.F7.2.2.2.m1.1.1.3.2\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.cmml\"><mi id=\"S6.F7.2.2.2.m1.1.1.3.2.2\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.2.cmml\">\ud835\udc92</mi><mo id=\"S6.F7.2.2.2.m1.1.1.3.2.1\" lspace=\"0.222em\" rspace=\"0.222em\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.1.cmml\">\u22c5</mo><msup id=\"S6.F7.2.2.2.m1.1.1.3.2.3\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.cmml\"><mover accent=\"true\" id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.cmml\"><mi id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.2\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.2.cmml\">\ud835\udc84</mi><mo id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.1\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.1.cmml\">^</mo></mover><mi id=\"S6.F7.2.2.2.m1.1.1.3.2.3.3\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.3.cmml\">T</mi></msup></mrow><mo id=\"S6.F7.2.2.2.m1.1.1.3.1\" xref=\"S6.F7.2.2.2.m1.1.1.3.1.cmml\">\u2212</mo><mi id=\"S6.F7.2.2.2.m1.1.1.3.3\" xref=\"S6.F7.2.2.2.m1.1.1.3.3.cmml\">\u03b2</mi></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.F7.2.2.2.m1.1b\"><apply id=\"S6.F7.2.2.2.m1.1.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1\"><geq id=\"S6.F7.2.2.2.m1.1.1.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.1\"></geq><apply id=\"S6.F7.2.2.2.m1.1.1.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2\"><ci id=\"S6.F7.2.2.2.m1.1.1.2.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.1\">\u22c5</ci><ci id=\"S6.F7.2.2.2.m1.1.1.2.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.2\">\ud835\udc92</ci><apply id=\"S6.F7.2.2.2.m1.1.1.2.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.3\"><csymbol cd=\"ambiguous\" id=\"S6.F7.2.2.2.m1.1.1.2.3.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.3\">superscript</csymbol><ci id=\"S6.F7.2.2.2.m1.1.1.2.3.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.3.2\">\ud835\udc8c</ci><ci id=\"S6.F7.2.2.2.m1.1.1.2.3.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.2.3.3\">\ud835\udc47</ci></apply></apply><apply id=\"S6.F7.2.2.2.m1.1.1.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3\"><minus id=\"S6.F7.2.2.2.m1.1.1.3.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.1\"></minus><apply id=\"S6.F7.2.2.2.m1.1.1.3.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2\"><ci id=\"S6.F7.2.2.2.m1.1.1.3.2.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.1\">\u22c5</ci><ci id=\"S6.F7.2.2.2.m1.1.1.3.2.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.2\">\ud835\udc92</ci><apply id=\"S6.F7.2.2.2.m1.1.1.3.2.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3\"><csymbol cd=\"ambiguous\" id=\"S6.F7.2.2.2.m1.1.1.3.2.3.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3\">superscript</csymbol><apply id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2\"><ci id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.1.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.1\">^</ci><ci id=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.2.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.2.2\">\ud835\udc84</ci></apply><ci id=\"S6.F7.2.2.2.m1.1.1.3.2.3.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.2.3.3\">\ud835\udc47</ci></apply></apply><ci id=\"S6.F7.2.2.2.m1.1.1.3.3.cmml\" xref=\"S6.F7.2.2.2.m1.1.1.3.3\">\ud835\udefd</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.F7.2.2.2.m1.1c\">\\bm{q}\\cdot\\bm{k}^{T}\\geq\\bm{q}\\cdot\\hat{\\bm{c}}^{T}-\\beta</annotation><annotation encoding=\"application/x-llamapun\" id=\"S6.F7.2.2.2.m1.1d\">bold_italic_q \u22c5 bold_italic_k start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT \u2265 bold_italic_q \u22c5 over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT - italic_\u03b2</annotation></semantics></math>\n</td>\n</tr>\n</table>", "caption": "Table 5. Generation quality of different sparse attention algorithms in \u221e\\infty\u221e-Bench. Each method used the number of [initial+last]+retrieved tokens for attention computation.", "description": "Table 5 presents a comparison of the generation quality achieved by different sparse attention algorithms within the \u221e-Bench benchmark.  The algorithms evaluated include Full Attention (the baseline), InfLLM, StreamingLLM, Top100, Top2000, and DIPRS (the authors' proposed method).  For each algorithm, the generation quality is assessed across eight tasks, encompassing various aspects of language understanding and generation.  The evaluation metric used for each task is not explicitly specified in the caption but appears to be a normalized score from 0-100 across various test cases. The number of tokens used for attention computation varies across methods, reflecting different approaches to managing the context window. This number is reported as the sum of initial tokens, last tokens, and the retrieved tokens, showing how much context was effectively used for each algorithm during attention calculation.", "section": "9.1 End-to-end Performance Evaluation"}]