{"references": [{"fullname_first_author": "Yuntao Bai", "paper_title": "Constitutional AI: Harmlessness from AI Feedback", "publication_date": "2022-12-22", "reason": "This paper is foundational to the field of AI alignment and introduces the concept of Constitutional AI, a technique used to improve the harmlessness of language models, directly relevant to the current research on automated evaluation."}, {"fullname_first_author": "Collin Burns", "paper_title": "Weak-to-Strong Generalization: Eliciting Strong Capabilities with Weak Supervision", "publication_date": "2023-12-22", "reason": "This research explores methods for improving the generalization capabilities of language models through weak supervision, which is crucial for developing robust and reliable automated evaluation methods."}, {"fullname_first_author": "Dawei Li", "paper_title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-Judge", "publication_date": "2024-11-24", "reason": "This paper directly addresses the LLM-as-a-judge approach, providing context and challenges for the current research, which focuses on improving the performance and reliability of such models."}, {"fullname_first_author": "Tu Vu", "paper_title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation", "publication_date": "2024-07-24", "reason": "This work introduces foundational autoraters, which are closely related to the current research's focus on creating general-purpose, high-performing language model evaluators."}, {"fullname_first_author": "Peifeng Wang", "paper_title": "Direct Judgement Preference Optimization", "publication_date": "2024-09-24", "reason": "This paper introduces a novel training approach (DPO) used to improve the model's performance, which is directly related to the methods used in the current research to train Selene Mini."}]}