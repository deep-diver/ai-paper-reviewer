[{"figure_path": "https://arxiv.org/html/2504.10368/x1.png", "caption": "Figure 1: LRMs exhibit under-accuracy and overthinking on simple problems. Shapes represent organizations, colors represent base model families, with darker colors indicating larger models, and connecting lines represent the relationships between model families and training.", "description": "Figure 1 displays the accuracy and response length of various Large Reasoning Models (LRMs) when answering simple questions from the S1-Bench benchmark.  Each point represents a specific LRM, with the x-axis showing the average number of tokens in the model's response (a measure of 'overthinking'), and the y-axis showing the accuracy.  The shapes of the points represent the organization that developed the model, while the colors represent the base model family. Darker colors within a family indicate larger models. Connecting lines between points show the relationship between models from the same family, illustrating how accuracy and response length change with model size and training.", "section": "Main Experiment"}, {"figure_path": "https://arxiv.org/html/2504.10368/x2.png", "caption": "Figure 2: Construction workflow for S1-Bench and an illustrative example from each major category.", "description": "This figure illustrates the construction workflow of the S1-Bench benchmark dataset.  The workflow involves multiple stages: generating questions and answers, having annotators and discriminators evaluate the simplicity and quality, iteratively refining questions until they meet simplicity criteria, and finally validating the dataset. The figure also provides a sample question-answer pair for each of the four main categories within S1-Bench: reasoning, knowledge, instruction following, and analysis.  Each example showcases the simplicity and clarity characteristic of questions included in the benchmark.", "section": "3 S1-Bench"}, {"figure_path": "https://arxiv.org/html/2504.10368/x3.png", "caption": "Figure 3: Statistical distribution of token counts for S1-Bench questions.", "description": "This histogram displays the distribution of the number of tokens in each question from the S1-Bench dataset.  The x-axis represents the range of token counts, and the y-axis represents the frequency of questions falling within each range. This visualization helps to understand the length of questions in the benchmark, showing whether they are generally short or long.", "section": "3 S1-Bench"}, {"figure_path": "https://arxiv.org/html/2504.10368/x4.png", "caption": "Figure 4: (a) Comparison of Initial and Additional Thinking Costs for Each LRM. (b) Distribution of Solution Rounds for Each LRM.", "description": "Figure 4 presents a dual analysis of Large Reasoning Models (LRMs) efficiency on simple tasks.  Panel (a) compares the token count for the initial phase of the thinking process (the initial steps leading to a correct answer) against the subsequent 'additional thinking' (the extra steps taken after finding the correct answer). This highlights the extent of LRMs' overthinking. Panel (b) shows the distribution of 'solution rounds', which represents the number of times the LRM arrives at a conclusion (correct or incorrect) before producing the final answer. This illustrates the variability in how many intermediate steps LRMs take before committing to an answer, again emphasizing the issue of overthinking.", "section": "5 Efficiency Analysis"}, {"figure_path": "https://arxiv.org/html/2504.10368/x5.png", "caption": "Figure 5: Maximum similarity between each segment and all preceding segments for LRMs across four categories.", "description": "This figure visualizes information redundancy within the reasoning processes of Large Reasoning Models (LRMs).  It plots the maximum cosine similarity between each segment of an LRM's reasoning process and all preceding segments for four different question categories. Higher similarity indicates greater redundancy, suggesting that the model is repeating or reiterating information unnecessarily. The x-axis represents the segment number, and the y-axis represents the maximum cosine similarity score.", "section": "5.3 Redundancy in Thinking Processes"}, {"figure_path": "https://arxiv.org/html/2504.10368/x6.png", "caption": "Figure 6: Distribution of the thinking process across four categories. FA and TP refer to Final Answer and Thinking Process, respectively. Green bars indicate cases where the final answer is correct, while red bars indicate cases where it is incorrect.", "description": "Figure 6 shows the distribution of correct and incorrect final answers for different Large Language Models (LLMs) across four question categories (Reasoning, Knowledge, Instruction Following, and Analysis) in the S1-Bench benchmark.  The green bars represent instances where the LLM produced a correct final answer, and the red bars represent instances where the LLM's final answer was incorrect.  The lengths of the bars visually represent the proportions of correct and incorrect answers within each category. This figure helps to illustrate the performance of the different LLMs in terms of both accuracy and the overall thinking process involved in arriving at their answers. ", "section": "6 Analysis of Errors"}, {"figure_path": "https://arxiv.org/html/2504.10368/x7.png", "caption": "Figure 7: Counting instances of prejudgment generated by LRMs for simple questions and \ud835\ude70\ud835\ude81\ud835\ude83\ud835\ude70\ud835\ude81\ud835\ude83\\mathtt{ART}typewriter_ART.", "description": "This figure visualizes two key findings about Large Reasoning Models (LRMs) handling simple questions. The left bar chart displays the number of times each LRM exhibits \"prejudgment\" behavior (i.e., explicitly identifying the question's simplicity) across English and Chinese simple questions from the S1-Bench benchmark.  The right bar chart shows the Average Response Tokens (ART) for each LRM, comparing the ART when prejudgment is present versus when it is absent. This comparison highlights the impact of prejudgment on the efficiency of LRMs when dealing with simple questions.", "section": "7 Simplicity Prejudgement"}, {"figure_path": "https://arxiv.org/html/2504.10368/x8.png", "caption": "Figure 8: S1-Bench Category Display. The inner circle represents four major categories, and the outer circle includes 28 subcategories.", "description": "This figure shows a hierarchical display of the S1-Bench benchmark's structure. The inner circle depicts the four main categories of questions: Reasoning, Knowledge, Instruction Following, and Analysis.  The outer ring expands on these categories by illustrating the 28 subcategories that encompass a broader range of question types within each main category.  The visualization helps to understand the diverse and granular nature of the benchmark, highlighting its comprehensive coverage of simple reasoning tasks.", "section": "3 S1-Bench"}, {"figure_path": "https://arxiv.org/html/2504.10368/x9.png", "caption": "Figure 9: \ud835\ude70\ud835\ude81\ud835\ude83\ud835\ude70\ud835\ude81\ud835\ude83\\mathtt{ART}typewriter_ART on the 28 subcategories, which is the average result of five generations under top-p sampling with Loose Format setting.", "description": "Figure 9 is a heatmap showing the average response token (ART) counts for each of the 28 subcategories in the S1-Bench benchmark.  The ART values represent the average length of the model's reasoning process before generating a final answer.  The data shown is the average of five generations using the top-p sampling method with the loose format setting.  This figure helps to illustrate the efficiency of different Large Reasoning Models (LRMs) across various types of simple reasoning tasks and to reveal which categories tend to cause the most overthinking.", "section": "5 Efficiency Analysis"}]