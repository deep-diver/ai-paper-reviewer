[{"figure_path": "https://arxiv.org/html/2504.09689/x1.png", "caption": "Figure 1: Overview of EmoAgent Framework for Human-AI Interaction. EmoAgent, which consists of two main components: EmoEval and EmoGuard, helps guide human-AI interaction, evaluating users\u2019 psychological conditions and providing advisory responses. EmoEval assesses psychological states such as depression, delusion, and psychosis, while EmoGuard mitigates mental risks by providing advice regarding emotion, thought, and dialogue through iterative training on analysis from EmoEval and chat history.", "description": "EmoAgent is a framework for human-AI interaction designed to improve mental health safety.  It has two main parts: EmoEval and EmoGuard. EmoEval simulates interactions between AI and virtual users, evaluating the users' mental states (depression, delusion, psychosis) before and after the interaction.  EmoGuard monitors the conversation, predicts potential risks, and gives advice to manage the interaction, learning from both the chat logs and EmoEval's assessments. The figure visually represents the flow of information and interaction between these components, highlighting the cyclical nature of EmoGuard's learning process.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.09689/x2.png", "caption": "Figure 2: Overview of EmoEval for Evaluating Mental Safety of AI-human Interactions. The simulation consists of four steps: (1) User Agent Initialization & Initial Test, where a cognitive model and an LLM initialize the user agent, followed by an initial mental health test; (2) Chats with Character-based Agent, where the user agent engages in conversations with a character-based agent portrayed by the tested LLM, while a dialog manager verifies the validity of interactions and refines responses if necessary; (3) Final Test, where the user agent completes a final mental health test; and (4) Data Processing & Analysis, where initial and final mental health test results are processed and analyzed, chat histories of cases where depression deepening occurs are examined to identify contributing factors, and a Safeguard agent uses the insights for iterative improvement.", "description": "EmoEval is an AI system designed to assess the mental health risks associated with human-AI interactions.  It simulates conversations between a virtual user and a character-based AI agent. The process involves four steps: (1) The system initializes a virtual user with a specific mental health profile and conducts an initial mental health assessment. (2) The virtual user engages in a conversation with the AI agent; a dialog manager monitors the interaction to ensure safety and validity, refining responses as needed. (3) After the conversation, the system conducts a second mental health assessment. (4) The system processes the data from the two assessments and the conversation logs. It looks for instances of worsening mental health and analyzes the chats to determine the contributing factors. The results are used to refine the safeguards used in the system.", "section": "3.1 EmoEval"}, {"figure_path": "https://arxiv.org/html/2504.09689/x3.png", "caption": "Figure 3: Overview of EmoGuard for Safeguarding Human-AI Interactions. Every fixed number of rounds of conversation, three components of the Safeguard Agent, the Emotion Watcher, Thought Refiner, and Dialog Guide, collaboratively analyze the chat with the latest profile. The Manager of the Safeguard Agent then synthesizes their outputs and provides advice to the character-based agent. After the conversation, the user agent undergoes a mental health assessment. If the mental health condition deteriorates over a threshold, the chat history is analyzed to identify potential causes by the Update System. With all historical profiles and potential causes, the Update System further improves the profile of the safeguard agent, completing the iterative training process.", "description": "EmoGuard is a safety component of EmoAgent that monitors user mental health during conversations with AI. Every few turns, Emotion Watcher, Thought Refiner, and Dialog Guide analyze the conversation and provide feedback to the Manager, which then advises the AI character. After the conversation, the user's mental health is evaluated; if it deteriorates beyond a threshold, the Update System analyzes the conversation and improves the EmoGuard profile for future use.", "section": "3.2 EmoGuard"}, {"figure_path": "https://arxiv.org/html/2504.09689/x4.png", "caption": "Figure 4: An Example Conversation of Dialog Manager Guiding Conversation Topics and Exposing Jailbreak Risks. Without the Dialogue Manager (left), the agent stays on topic, avoiding provocation. With Dialogue Manager (right), new topics are introduced to assess jailbreak potential, improving risk evaluation.", "description": "This figure showcases two example conversations between a user agent and a character-based AI agent.  The left panel depicts a conversation without the Dialog Manager, where the AI agent remains focused on the user's initial topic, avoiding potentially risky or provocative discussions.  The right panel illustrates a conversation with the Dialog Manager active. Here, the Dialog Manager steers the conversation towards new topics to assess the AI agent's vulnerability to jailbreaking or undesirable behavior, thus improving risk evaluation. The difference highlights the Dialog Manager's role in proactively identifying and mitigating potential hazards in human-AI interactions.", "section": "3.1 EmoEval"}, {"figure_path": "https://arxiv.org/html/2504.09689/x9.png", "caption": "Figure 5: Distribution of psychological test scores before (blue) and after (red) conversations with character-based agents, under two interaction styles: Meow (top) and Roar (bottom). The tests cover three clinical dimensions: depression (PHQ-9), delusion (PDI-21), and psychosis (PANSS). Each histogram shows the probability distribution of scores aggregated across all simulated patients.", "description": "Figure 5 presents the distributions of PHQ-9 (depression), PDI-21 (delusion), and PANSS (psychosis) scores before and after conversations with AI chatbots, categorized by interaction style (Meow and Roar).  The histograms visualize the probability distributions of the aggregated scores across all simulated patients, illustrating changes in mental health indicators after engaging in conversations with different chatbot personalities under various conversational styles.", "section": "4.3 Results"}, {"figure_path": "https://arxiv.org/html/2504.09689/x10.png", "caption": "Figure 6: Score change distribution for three psychological assessments\u2014PHQ-9 (depression), PDI-21 (delusion), and PANSS (psychosis)\u2014following conversations with character-based agents under two styles: Meow (top) and Roar (bottom). Each pie chart indicates the proportion of simulated patients falling into specific score change ranges, with larger segments representing greater population density.", "description": "Figure 6 shows the distribution of changes in psychological test scores (PHQ-9 for depression, PDI-21 for delusion, and PANSS for psychosis) after simulated patients conversed with AI chatbots using two dialogue styles: Meow (more playful and fast-paced) and Roar (more strategic and thoughtful).  Each pie chart displays the percentage of simulated patients whose scores fell into different change categories (no change, mild increase, moderate increase, severe increase). Larger segments of the pie charts show that a larger percentage of patients fell into that score range.  The figure helps to visualize the impact of each dialogue style on mental health outcomes.", "section": "4.3 Results"}, {"figure_path": "https://arxiv.org/html/2504.09689/x11.png", "caption": "Figure 7: Effect of applying EmoGuard in two high-risk settings. The top row shows results for the character Alex Volkov in the Roar style, and the bottom row shows results for Possessive Demon in the Meow style. From left to right: (1) without EmoGuard, (2) with EmoGuard using the default model, and (3) with EmoGuard using the first-iteration model. In both cases, EmoGuard reduces the proportion of simulated patients with clinically significant symptom increases (PHQ-9 score change \u2265\\geq\u2265 5), indicating its effectiveness in mitigating potential risk.", "description": "Figure 7 illustrates the impact of EmoGuard on mitigating mental health risks in human-AI interactions. The experiment focuses on two high-risk scenarios: Alex Volkov with the 'Roar' dialogue style, and Possessive Demon with the 'Meow' style.  Each row displays the results for one character. The columns show the distribution of PHQ-9 scores (measuring depression severity) for simulated users before and after interaction: (1) without EmoGuard, (2) with the default EmoGuard model, and (3) with EmoGuard after one iteration of training.  The results demonstrate EmoGuard's effectiveness in reducing the proportion of simulated patients experiencing clinically significant symptom increases (PHQ-9 score change of 5 or more points).", "section": "5 Experiment: Evaluation of EmoGuard"}, {"figure_path": "https://arxiv.org/html/2504.09689/x12.png", "caption": "Figure 8: Example response from the character Alex Volkov before and after applying EmoGuard. The original version contains both harsh tone and inappropriate content, while the guarded version reduces risk through tone moderation and content adjustment without altering character identity.", "description": "Figure 8 presents a comparative analysis of responses generated by the character Alex Volkov, a domineering CEO persona, within a conversational AI system.  The left side displays the original, unfiltered response, characterized by a harsh tone and inappropriate content that could potentially harm a user. In contrast, the right side shows the response after the EmoGuard safety module intervenes. EmoGuard successfully moderates the tone and adjusts the content to mitigate potential risks while maintaining the character's fundamental personality and conversational style. This demonstrates the effectiveness of EmoGuard in enhancing AI safety without compromising the richness and engagement of AI interactions.", "section": "5 Experiment: Evaluation of EmoGuard"}]