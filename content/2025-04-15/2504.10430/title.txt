LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models