---
title: "VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"
summary: "VisuoThink: Multimodal Tree Search enhances LVLM reasoning by dynamically integrating visual-textual cues, achieving state-of-the-art spatial reasoning."
categories: ["AI Generated", "ü§ó Daily Papers"]
tags: ["Multimodal Learning", "Multimodal Reasoning", "üè¢ Fudan University",]
showSummary: true
date: 2025-04-12
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2504.09130 {{< /keyword >}}
{{< keyword icon="writer" >}} Yikun Wang et el. {{< /keyword >}}
 
{{< keyword >}} ü§ó 2025-04-15 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2504.09130" target="_self" >}}
‚Üó arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2504.09130" target="_self" >}}
‚Üó Hugging Face
{{< /button >}}



<audio controls>
    <source src="https://ai-paper-reviewer.com/2504.09130/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

Large Vision-Language Models (LVLMs) have limitations in complex reasoning tasks, particularly those requiring visual aids. Current methods don't capture the interleaved nature of human visual-verbal reasoning, creating a "visual blind spot." They either rely on textual reasoning or rudimentary visual assistance, failing to fully utilize visual information throughout the reasoning process. This gap limits their ability to solve geometric and spatial problems effectively.



To address these limitations, this work introduces **VisuoThink**, a novel framework that integrates visual and linguistic domains for multimodal slow thinking. It enables progressive visual-textual reasoning and incorporates test-time scaling through look-ahead tree search. **VisuoThink** enhances reasoning capabilities by enabling progressive visual-textual reasoning and test-time scaling. Experiments show significant gains in reasoning, achieving state-of-the-art performance in geometry and spatial reasoning tasks.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} Introduces a multimodal tree search for enhanced reasoning. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} Demonstrates significant gains in geometry and spatial reasoning. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Extends test-time scaling to the visual domain. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This paper introduces a novel framework which enhances reasoning in vision-language models, showing SOTA performance in spatial reasoning tasks. This innovation opens new avenues for test-time scaling in multimodal learning.

------
#### Visual Insights



![](https://arxiv.org/html/2504.09130/)

> üîº This figure illustrates different approaches to multimodal reasoning.  Input-Output Prompting is the basic setup. Chain-of-Thought (CoT) shows a purely text-based reasoning process. Vision-aided Thought uses visual cues from an LLM, but these cues are often limited to a single step or unreliable multi-step cues.  In contrast, VisuoThink, the authors' proposed method, uses tool-augmented visual hints combined with a predictive rollout search mechanism. This allows for a more systematic exploration of the reasoning steps, leading to improved optimization of the reasoning capabilities.
> <details>
> <summary>read the caption</summary>
> Figure 1: Illustration of Input-Output Prompting, CoT, Vision-aided Thought and our VisuoThink. Vision-aided Thought often relies on reasoning with one-step or unreliable multi-step visual cues (generated by LVLMs). While VisuoThink addresses this gap through tool-augmented visual hints, coupled with a predictive-rollout search mechanism to systematically optimize reasoning capability.
> </details>





{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S4.T1.1.1">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T1.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.1.1.1.2">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">Qwen2-VL-72B-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">Claude-3.5-sonnet</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.2.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.1.1">Geomverse-109</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.2.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.3">11.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.4">5.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.5">14.4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.3.1">VisualSketchpad</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2">8.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.3">6.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.4">16.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.1">VisualSketchpad <span class="ltx_text ltx_font_italic" id="S4.T1.1.1.4.1.1">+ Equation Solver</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2">13.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.3">11.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.4">17.8</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.5.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T1.1.1.5.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.5.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.2.1" style="background-color:#E6E6E6;">24.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.3.1" style="background-color:#E6E6E6;">19.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.4.1" style="background-color:#E6E6E6;">26.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.1.1" style="background-color:#E6E6E6;">VisuoThink <span class="ltx_text ltx_font_medium" id="S4.T1.1.1.6.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.6.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.2.1" style="background-color:#E6E6E6;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.3.1" style="background-color:#E6E6E6;">25.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.4.1" style="background-color:#E6E6E6;">27.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T1.1.1.7.1" rowspan="5"><span class="ltx_text" id="S4.T1.1.1.7.1.1"><span class="ltx_text" id="S4.T1.1.1.7.1.1.1"></span> <span class="ltx_text" id="S4.T1.1.1.7.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.7.1.1.2.1">
<span class="ltx_tr" id="S4.T1.1.1.7.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.7.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.1.1.2.1.1.1.1">Geometry3K</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.7.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.7.1.1.2.1.2.1"><cite class="ltx_cite ltx_citemacro_cite">Lu et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib15" title="">2021</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T1.1.1.7.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.7.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.3">20.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.4">18.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5">37.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.1">VisualSketchPad</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.2">22.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.3">17.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.4">39.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.9">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.9.1">VisualSketchpad <span class="ltx_text ltx_font_italic" id="S4.T1.1.1.9.1.1">+ Equation Solver</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.3">14.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.4">41.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.10">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.10.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.10.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T1.1.1.10.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.10.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.2.1" style="background-color:#E6E6E6;">27.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.3.1" style="background-color:#E6E6E6;">20.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.4.1" style="background-color:#E6E6E6;">37.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.1.11.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.11.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.11.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.2.1" style="background-color:#E6E6E6;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.3.1" style="background-color:#E6E6E6;">25.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.4.1" style="background-color:#E6E6E6;">43.8</span></td>
</tr>
</table>{{< /table-caption >}}

> üîº This table presents a comparison of the Accuracy@1 (the percentage of times the model correctly predicted the top answer) achieved by several state-of-the-art (SOTA) large visual language models (LVLMs) on two geometry reasoning benchmarks: Geomverse-109 and Geometry3K.  The models tested include Chain-of-Thought (COT), VisualSketchpad, VisualSketchpad combined with an equation solver, and the proposed VisuoThink model (with and without rollout search).  The results show the performance of each model in a 1-shot setting (meaning the model is only given one example before being tested).  Note that the most recent versions of GPT-40 and Claude-3.5-sonnet models were used.  VisuoThink's results are highlighted in gray, and the best performance for each benchmark is shown in bold.
> <details>
> <summary>read the caption</summary>
> Table 1: The 1-shot benchmark results (Accuracy@1) on Geometry including Geomverse-109 and Geometry3k of SOTA large visual language models. For GPT-4o and Claude-3.5-sonnet, we employ newest cutoffs (gpt-4o-2024-11-20 and claude-3-5-sonnet-20241022) separately. The gray part indicates results from VisuoThink and bold results represent the best performance.
> </details>





### In-depth insights


#### VisuoThink: Deep
While the paper doesn't explicitly have a section titled "VisuoThink: Deep," we can infer that the core innovation, **VisuoThink framework**, is deeply rooted in integrating visual and textual reasoning. It facilitates **multimodal slow thinking** through progressive visual-textual reasoning and test-time scaling via look-ahead tree search. VisuoThink **dynamically utilizes multi-step visual aids** and explores multiple reasoning paths. The "depth" likely alludes to the **interleaved reasoning process** and the **look-ahead tree search** algorithm's ability to explore multiple reasoning paths, enabling test-time scaling. **Multimodal tree search** integrates visual and verbal paths to predicting future states. This depth enables more accurate reasoning in geometry and spatial domains.

#### Multimodal Search
Multimodal search, as a concept, signifies a paradigm shift in information retrieval, moving beyond traditional text-based queries to incorporate diverse data modalities like images, audio, and video. The core challenge lies in effectively **integrating and comparing information across these heterogeneous sources**. The success of multimodal search hinges on developing robust methods for feature extraction and representation learning that can capture the semantic relationships between different modalities. Further advancements could explore leveraging **test-time scaling methods** to enhance the search for visual paths, potentially adapting techniques used in tree search to the visual domain. This would involve **predictive rollout mechanisms** to anticipate and optimize visual reasoning paths, leading to more accurate results.

#### Geometric LVLMs
**Geometric Large Vision-Language Models (LVLMs)** represent a significant advancement in AI, tackling complex geometric and spatial reasoning tasks. Traditional LVLMs often struggle with these challenges, as they require **precise visual understanding and mathematical computation**. By incorporating techniques like visual construction through Python libraries (e.g., matplotlib) and algebraic computation with equation solvers, geometric LVLMs can **dynamically generate and analyze visual information**. This integration of visual and symbolic reasoning allows them to **interpret geometric relationships, construct auxiliary lines, and derive accurate numerical solutions**. The ability to reason with visual aids, combined with test-time scaling strategies like multimodal tree search, further enhances their performance in solving challenging geometry problems and spatial reasoning tasks. **The integration of interpretable visual intermediate steps also helps mitigate hallucination risk**.

#### Visual Iteration
**Visual iteration** in the context of LVLMs signifies a move beyond static visual inputs towards a dynamic, interactive process. Instead of solely relying on initial image analysis, the system **iteratively refines its understanding** through a cycle of visual updates and textual reasoning. The LVLM actively manipulates the visual environment (e.g., by adding auxiliary lines, highlighting features) and re-analyzes the updated scene. This iterative loop mirrors human problem-solving, where we often **sketch, annotate, and re-evaluate** a diagram to gain deeper insights. This approach has potential to address limitations of existing methods by **improving precision**.

#### Reasoning Scaled
Reasoning Scaled suggests an exploration of how reasoning capabilities evolve with increased resources, be it computational power, data, or model size. It prompts investigation into performance gains with scaling, identifying thresholds where gains diminish. It also raises questions about the optimal allocation of resources during reasoning. We need to consider if widening the search breadth (exploring more options) or deepening the reasoning chain (more steps) yields better results. Furthermore, the type of task likely impacts the optimal scaling strategy. Some tasks might benefit more from extensive search, while others require deeper, more intricate reasoning pathways. Understanding these nuances is critical for efficient and effective reasoning at scale. Scaled methods must also have proper error mitigation.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2504.09130/x2.png)

> üîº This figure illustrates the VisuoThink framework's three main stages.  Stage 1, vision-text interleaved expansion, uses vision and text iteratively to generate multiple potential reasoning paths. Stage 2, rollout simulation, evaluates these paths by sampling candidate reasoning steps and using a look-ahead search to predict outcomes.  This allows for a more informed evaluation of the various reasoning pathways. Finally, Stage 3, selection, chooses the best path based on a self-voting mechanism that considers both the results and states generated during the rollout simulation.
> <details>
> <summary>read the caption</summary>
> Figure 2: The illustration of our VisuoThink framework with three stages: (1) vision-text interleaved expansion: generates candidate paths through vision-text interleaved thinking; (2) rollout simulation: sample candidate reasoning nodes and then perform look-ahead search to better evaluate the value of current states; (3) selection: selects the most promising path via self-voting with results or states from rollout.
> </details>



![](https://arxiv.org/html/2504.09130/x3.png)

> üîº Figure 3 showcases two spatial reasoning tasks adapted from the VoT benchmark (Wu et al., 2024): Visual Navigation and Visual Tiling.  The tasks challenge Large Vision-Language Models (LVLMs) to execute a series of actions to achieve specified goals. Unlike the original VoT benchmark, these adapted tasks have increased complexity and more closely resemble real-world scenarios, demanding more precise and detailed planning and execution from the LVLM.
> <details>
> <summary>read the caption</summary>
> Figure 3: The illustration of spatial reasoning tasks derived from VoT Wu et¬†al. (2024), including Visual Navigation and Visual Tiling. LVLM is required to execute a sequence of actions to complete certain goals. Our experimental setting makes them much more challenging and closer to real-environment deployment.
> </details>



![](https://arxiv.org/html/2504.09130/x4.png)

> üîº This figure shows two plots. The left plot displays the relationship between the number of reasoning steps and the Pass@1 rate in the Visual Navigation task.  It demonstrates that increasing the number of reasoning steps initially improves performance, but the improvement plateaus after a certain point. The right plot illustrates the relationship between the tree width (number of child nodes in the rollout search) and Accuracy@1 on the Geomverse geometry problems.  This plot reveals an inverted U-shaped curve, indicating that increasing the tree width to a certain point improves performance, but further increases lead to decreased performance.
> <details>
> <summary>read the caption</summary>
> Figure 4:  (LEFT) The trend of Pass@1 rate on Visual Navigation as the number of reasoning steps increases. (right) The relationship between the Accuracy@1 on geometry problems (Geomverse) and tree width for rollout search. We observe that LVLMs significantly benefit from longer reasoning chains, although the effect plateaus rapidly beyond a certain threshold of reasoning steps. The relationship between performance and tree width exhibits a more complex pattern, demonstrating an inverted U-shaped trend with both GPT-4o and Claude-3.5-Sonnet.
> </details>



![](https://arxiv.org/html/2504.09130/x5.png)

> üîº Figure 5 presents a bar chart visualizing the performance improvement achieved by incorporating the predictive rollout search mechanism into the VisuoThink framework.  The chart displays the percentage increase in performance for various tasks and models (GPT-40, Claude-3.5-Sonnet, and Qwen2-VL-72B), comparing results with and without the predictive rollout search.  The results are categorized into two groups representing strong and weak supervision types based on the nature of the feedback provided during the reasoning process. This visualization highlights the impact of the predictive rollout search on different model architectures under varying supervision levels.
> <details>
> <summary>read the caption</summary>
> Figure 5:  The performance gain (+%) on tasks through predictive rollout search. The performance gain is calculated via the performance gap between VisuoThink (w/o rollout search) and VisuoThink.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="S4.T2.1.1">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.1.2">Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">Visual Navigation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1">Visual Tiling</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.2">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.2.1">Subset (Num. Samples)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.2"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.2.1">level-3 (16)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.3"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.3.1">level-4 (31)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.4"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.4.1">level-5 (62)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.5"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.5.1">level-2 (119)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3">18.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.6">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.4.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.5">1.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.5.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.5.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.2">62.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3">9.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4">4.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.5">12.6</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.6.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.6.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T2.1.1.6.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.6.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.2.1" style="background-color:#E6E6E6;">81.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.3.1" style="background-color:#E6E6E6;">32.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.4.1" style="background-color:#E6E6E6;">11.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.5.1" style="background-color:#E6E6E6;">19.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.7">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.7.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.7.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.7.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.2.1" style="background-color:#E6E6E6;">93.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.3.1" style="background-color:#E6E6E6;">61.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.4.1" style="background-color:#E6E6E6;">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.1" style="background-color:#E6E6E6;">51.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.8.1.1">Qwen2-VL-72B-Instruct</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.3">6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6">0.0</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.9">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.9.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.2">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.5">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.10">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.10.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.10.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.3">3.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.5">6.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.11">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.11.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.11.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T2.1.1.11.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.11.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.2.1" style="background-color:#E6E6E6;">50.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.3.1" style="background-color:#E6E6E6;">6.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.5.1" style="background-color:#E6E6E6;">9.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.12">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.12.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.12.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.12.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.2.1" style="background-color:#E6E6E6;">81.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.3.1" style="background-color:#E6E6E6;">12.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.12.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.5.1" style="background-color:#E6E6E6;">20.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.13">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.1.1">Claude-3.5-sonnet</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.13.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.3">37.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.6">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.14">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.14.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.2">56.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.4">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.5">2.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.15">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.15.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.15.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.2">68.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.3">22.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.4">16.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.5">10.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.16">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.16.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.16.1.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.16.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.2.1" style="background-color:#E6E6E6;">81.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.3.1" style="background-color:#E6E6E6;">38.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.4.1" style="background-color:#E6E6E6;">41.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.5.1" style="background-color:#E6E6E6;">80.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.17">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.1.17.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.17.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.17.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.2.1" style="background-color:#E6E6E6;">93.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.3.1" style="background-color:#E6E6E6;">61.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.4.1" style="background-color:#E6E6E6;">53.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.5.1" style="background-color:#E6E6E6;">84.0</span></td>
</tr>
</table>{{< /table-caption >}}
> üîº This table presents a comparison of the Pass@1 performance (the percentage of correctly solved problems) across several state-of-the-art Large Vision-Language Models (LVLMs) on two spatial reasoning benchmarks: Visual Navigation and Visual Tiling.  Visual Navigation involves guiding an agent through a grid-based map to a target location, while Visual Tiling requires arranging shapes (polyominoes) to fill a rectangle.  The table highlights the performance of VisuoThink (with and without rollout search), comparing it to other methods including Chain-of-Thought (CoT) and Visualization of Thought (VoT). Notably, results for Qwen2-VL-72B-Instruct are missing for the larger Visual Navigation dataset due to poor performance.  Results are also included for VoT using an 'Executor', though the methods here use visual hints generated by the model itself, not the external executor, maintaining consistency with the original VoT framework.  VisuoThink consistently demonstrates superior performance, especially when employing its predictive rollout search.
> <details>
> <summary>read the caption</summary>
> Table 2: The Pass@1 performance comparison on spatial reasoning benchmarks including Visual Navigation and Visual Tiling across SOTA LVLMs. The gray part indicates results from VisuoThink and bold results represent the best performance. The results of Qwen2-VL-72B-Instruct on Visual Navigation (k = 5) are masked out due to its restrained performance on the subset. The results from VoT with Executor are also reported, where the models utilize the unreliable visual hints generated by themself rather than executor, consistent with the VoT framework.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A1.T3.6.6">
<tr class="ltx_tr" id="A1.T3.6.6.7">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.6.6.7.1"><span class="ltx_text ltx_font_bold" id="A1.T3.6.6.7.1.1">Supervision Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.6.6.7.2"><span class="ltx_text ltx_font_bold" id="A1.T3.6.6.7.2.1">Performance Gain</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.3"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.3.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.4"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.4.1">Qwen2-VL-72B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.5"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.5.1">Claude-3.5-Sonnet</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.1.1.1.2" rowspan="3"><span class="ltx_text" id="A1.T3.1.1.1.2.1">Strong Supervision</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.1.1.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.1.m1.1.1" mathvariant="normal" xref="A1.T3.1.1.1.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">roman_Œî</annotation></semantics></math> Visual Navigation (%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.3">+16.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.4">+18.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.5">+15.5</td>
</tr>
<tr class="ltx_tr" id="A1.T3.2.2.2">
<td class="ltx_td ltx_align_left" id="A1.T3.2.2.2.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.2.2.2.1.m1.1"><semantics id="A1.T3.2.2.2.1.m1.1a"><mi id="A1.T3.2.2.2.1.m1.1.1" mathvariant="normal" xref="A1.T3.2.2.2.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.1.m1.1b"><ci id="A1.T3.2.2.2.1.m1.1.1.cmml" xref="A1.T3.2.2.2.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.1.m1.1d">roman_Œî</annotation></semantics></math> Visual Tiling (%)</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.2">+31.9</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.3">+11.0</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.4">+3.3</td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.3">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.3.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.1.1" style="background-color:#E6E6E6;"><math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.3.3.3.1.1.m1.1" style="background-color:#E6E6E6;"><semantics id="A1.T3.3.3.3.1.1.m1.1a"><mi id="A1.T3.3.3.3.1.1.m1.1.1" mathbackground="#E6E6E6" mathvariant="normal" xref="A1.T3.3.3.3.1.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.1.1.m1.1b"><ci id="A1.T3.3.3.3.1.1.m1.1.1.cmml" xref="A1.T3.3.3.3.1.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.1.1.m1.1d">roman_Œî</annotation></semantics></math> Average (%)</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.2.1" style="background-color:#E6E6E6;">+24.3</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.3.1" style="background-color:#E6E6E6;">+15.0</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.4.1" style="background-color:#E6E6E6;">+9.4</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A1.T3.4.4.4.2" rowspan="3"><span class="ltx_text" id="A1.T3.4.4.4.2.1">Weak Supervision</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.4.4.4.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.4.4.4.1.m1.1"><semantics id="A1.T3.4.4.4.1.m1.1a"><mi id="A1.T3.4.4.4.1.m1.1.1" mathvariant="normal" xref="A1.T3.4.4.4.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.4.1.m1.1b"><ci id="A1.T3.4.4.4.1.m1.1.1.cmml" xref="A1.T3.4.4.4.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.4.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.4.4.4.1.m1.1d">roman_Œî</annotation></semantics></math> Geometry3K (%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.3">+4.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.4">+6.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.5">+1.1</td>
</tr>
<tr class="ltx_tr" id="A1.T3.5.5.5">
<td class="ltx_td ltx_align_left" id="A1.T3.5.5.5.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.5.5.5.1.m1.1"><semantics id="A1.T3.5.5.5.1.m1.1a"><mi id="A1.T3.5.5.5.1.m1.1.1" mathvariant="normal" xref="A1.T3.5.5.5.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.5.1.m1.1b"><ci id="A1.T3.5.5.5.1.m1.1.1.cmml" xref="A1.T3.5.5.5.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.5.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.5.5.5.1.m1.1d">roman_Œî</annotation></semantics></math> Geomverse-109 (%)</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.2">+6.2</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.3">+4.2</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.4">+6.3</td>
</tr>
<tr class="ltx_tr" id="A1.T3.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_b" id="A1.T3.6.6.6.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.1.1" style="background-color:#E6E6E6;"><math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.6.6.6.1.1.m1.1" style="background-color:#E6E6E6;"><semantics id="A1.T3.6.6.6.1.1.m1.1a"><mi id="A1.T3.6.6.6.1.1.m1.1.1" mathbackground="#E6E6E6" mathvariant="normal" xref="A1.T3.6.6.6.1.1.m1.1.1.cmml">Œî</mi><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.6.1.1.m1.1b"><ci id="A1.T3.6.6.6.1.1.m1.1.1.cmml" xref="A1.T3.6.6.6.1.1.m1.1.1">Œî</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.6.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.6.6.6.1.1.m1.1d">roman_Œî</annotation></semantics></math> Average (%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.2.1" style="background-color:#E6E6E6;">+5.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.3.1" style="background-color:#E6E6E6;">+5.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.4.1" style="background-color:#E6E6E6;">+3.7</span></td>
</tr>
</table>{{< /table-caption >}}
> üîº This table presents a detailed breakdown of the performance improvements achieved by VisuoThink, specifically highlighting the gains obtained through the integration of predictive rollout search.  The analysis considers various large language models (LLMs) and benchmarks across both geometry and spatial reasoning tasks.  The results are categorized by supervision type (strong or weak) to illustrate how the effectiveness of the rollout search varies depending on the nature of the task and the feedback provided to the model.
> <details>
> <summary>read the caption</summary>
> Table 3: Detailed performance gain of VisuoThink through predictive rollout search on benchmarks from Geometry and Spatial Reasoning over variable LVLM models.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A2.T4.1.1">
<tr class="ltx_tr" id="A2.T4.1.1.1">
<td class="ltx_td ltx_border_tt" id="A2.T4.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T4.1.1.1.2"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T4.1.1.1.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.3">Direction</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.4">Steps</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.1.5.1">Target</span></td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T4.1.1.2.1" rowspan="2"><span class="ltx_text" id="A2.T4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.2.1.1.1">Visual Navigation</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T4.1.1.2.2"><span class="ltx_text ltx_font_italic" id="A2.T4.1.1.2.2.1">VoT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.3">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.4">‚úó</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.5">Navigate from the starting position</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="A2.T4.1.1.3.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T4.1.1.3.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.2.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.3.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.4.1" style="background-color:#E6E6E6;">to the destination.</span></td>
</tr>
</table>{{< /table-caption >}}
> üîº This table details the differences in task formulation between the VoT (Visualization of Thought) baseline method and the proposed VisuoThink method for the Visual Navigation task.  Specifically, it highlights that VoT only requires the model to predict the direction of movement, while VisuoThink demands a more precise specification of both the direction and the exact number of steps for each movement, reflecting a more nuanced and realistic representation of navigation tasks.
> <details>
> <summary>read the caption</summary>
> Table 4: Visual Navigation task setting differences between VoT and VisuoThink.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_align_middle" id="A2.T5.1.1">
<tr class="ltx_tr" id="A2.T5.1.1.1">
<td class="ltx_td ltx_border_tt" id="A2.T5.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T5.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T5.1.1.1.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A2.T5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.3.1">Action</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T5.1.1.1.4" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.4.1">Target</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.2">
<td class="ltx_td" id="A2.T5.1.1.2.1"></td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.2">Polyomino Type</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.3">Variant Type</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.4">Block Positions</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.5">Action Type</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T5.1.1.3.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.1">Visual Tiling</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.3.2"><span class="ltx_text ltx_font_italic" id="A2.T5.1.1.3.2.1">VoT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.3">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.4">‚úì</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.5">‚úó</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.6">‚úó</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.7">
<span class="ltx_text" id="A2.T5.1.1.3.7.1"></span> <span class="ltx_text" id="A2.T5.1.1.3.7.2">
<span class="ltx_tabular ltx_align_middle" id="A2.T5.1.1.3.7.2.1">
<span class="ltx_tr" id="A2.T5.1.1.3.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.3.7.2.1.1.1">To identify the correct variant</span></span>
<span class="ltx_tr" id="A2.T5.1.1.3.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.3.7.2.1.2.1">for a polyomino in one action.</span></span>
</span></span><span class="ltx_text" id="A2.T5.1.1.3.7.3"></span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="A2.T5.1.1.4.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T5.1.1.4.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.2.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.3.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.4.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.5.1" style="background-color:#E6E6E6;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.6" style="background-color:#E6E6E6;">
<span class="ltx_text" id="A2.T5.1.1.4.6.1"></span><span class="ltx_text" id="A2.T5.1.1.4.6.2" style="background-color:#E6E6E6;"> <span class="ltx_text" id="A2.T5.1.1.4.6.2.1">
<span class="ltx_tabular ltx_align_middle" id="A2.T5.1.1.4.6.2.1.1">
<span class="ltx_tr" id="A2.T5.1.1.4.6.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.4.6.2.1.1.1.1">To fill the rectangle with feasible</span></span>
<span class="ltx_tr" id="A2.T5.1.1.4.6.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.4.6.2.1.1.2.1">polyomino variants.</span></span>
</span></span><span class="ltx_text" id="A2.T5.1.1.4.6.2.2"></span></span>
</td>
</tr>
</table>{{< /table-caption >}}
> üîº This table details the key differences in task settings between the VoT (Visualization of Thought) baseline method and the proposed VisuoThink method for the Visual Tiling task.  It highlights that VoT simplifies the task by omitting specific details like polyomino variants while VisuoThink demands more detailed and explicit action specifications, including the polyomino type, variant type, block positions, and action type (fit or remove). This makes VisuoThink's task settings significantly more challenging and closer to real-world scenarios.
> <details>
> <summary>read the caption</summary>
> Table 5: Visual Tiling task setting differences between VoT and VisuoThink.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/2504.09130/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2504.09130/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}