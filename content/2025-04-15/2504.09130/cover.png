<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search</title>
<!--Generated on Sat Apr 12 08:35:59 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2504.09130v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S1" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S2" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S2.SS1" title="In 2 Related Work ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Text-centric Reasoning in LVLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S2.SS2" title="In 2 Related Work ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Vision-aided Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S2.SS3" title="In 2 Related Work ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Test-time Scaling with Tree Search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>VisuoThink</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3.SS1" title="In 3 VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Vision-Text Interleaved Thinking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3.SS2" title="In 3 VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Predictive Rollout Search</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3.SS2.SSS0.Px1" title="In 3.2 Predictive Rollout Search ‣ 3 VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Vision-Text Interleaved Expansion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3.SS2.SSS0.Px2" title="In 3.2 Predictive Rollout Search ‣ 3 VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Rollout Simulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S3.SS2.SSS0.Px3" title="In 3.2 Predictive Rollout Search ‣ 3 VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Selection</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Solving Geometry with VisuoThink</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS0.SSS0.Px1" title="In 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Task Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS0.SSS0.Px2" title="In 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Visual Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS0.SSS0.Px3" title="In 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Algebraic Computation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS1" title="In 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Empirical Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS1.SSS0.Px1" title="In 4.1 Empirical Results ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS1.SSS0.Px2" title="In 4.1 Empirical Results ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Spatial Reasoning with VisuoThink</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.SS0.SSS0.Px1" title="In 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Task Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.SS0.SSS0.Px2" title="In 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Visual Construction via <span class="ltx_text ltx_font_bold ltx_font_italic">Executor</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.SS1" title="In 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Empirical Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.SS1.SSS0.Px1" title="In 5.1 Empirical Results ‣ 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.SS1.SSS0.Px2" title="In 5.1 Empirical Results ‣ 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6.SS1" title="In 6 Discussion ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Could Longer Reasoning Chains Assist LVLMs in Reasoning?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6.SS2" title="In 6 Discussion ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Could Larger Tree Span Enhances <span class="ltx_text ltx_font_italic">VisuoThink</span>’s Performance?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6.SS3" title="In 6 Discussion ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Strong v.s. Weak Supervision in Predictive Rollout Search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S7" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#Sx2.SS0.SSS0.Px1" title="In Ethics and Reproducibility Statements ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Ethics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#Sx2.SS0.SSS0.Px2" title="In Ethics and Reproducibility Statements ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Reproducibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A1" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Performance Gain of <span class="ltx_text ltx_font_bold ltx_font_italic">VisuoThink</span> Through Predictive Rollout Search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A2" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>OKSpatial Reasoning Task Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A3" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Task Formulation of Spatial Reasoning Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A4" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Model and <span class="ltx_text ltx_font_bold ltx_font_italic">VisuoThink</span> Hyperparameters</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A4.SS0.SSS0.Px1" title="In Appendix D Model and VisuoThink Hyperparameters ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title">Model Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A4.SS0.SSS0.Px2" title="In Appendix D Model and VisuoThink Hyperparameters ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_text ltx_font_italic">VisuoThink</span> Hyperparameters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A5" title="In VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Geomverse-109 Problem Generation Trajectory</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_italic" id="id18.id1">VisuoThink</span>: Empowering LVLM Reasoning with Multimodal Tree Search</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yikun Wang<sup class="ltx_sup" id="id19.18.id1">1</sup><sup class="ltx_sup" id="id20.19.id2">2</sup>,  Siyin Wang<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span><sup class="ltx_sup" id="id21.20.id3">1</sup><sup class="ltx_sup" id="id22.21.id4">2</sup>,  Qinyuan Cheng<sup class="ltx_sup" id="id23.22.id5">1</sup>,  Zhaoye Fei<sup class="ltx_sup" id="id24.23.id6">1</sup>,  Liang Ding<sup class="ltx_sup" id="id25.24.id7">3</sup>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id12.12.5">  Qipeng Guo<sup class="ltx_sup" id="id12.12.5.1"><span class="ltx_text ltx_font_medium" id="id12.12.5.1.1">2</span></sup><sup class="ltx_sup" id="id12.12.5.2"><span class="ltx_text ltx_font_medium" id="id12.12.5.2.1">4</span></sup>,  Dacheng Tao<sup class="ltx_sup" id="id12.12.5.3"><span class="ltx_text ltx_font_medium" id="id12.12.5.3.1">5</span></sup>,  Xipeng Qiu<sup class="ltx_sup" id="id12.12.5.4"><span class="ltx_text ltx_font_medium" id="id12.12.5.4.1">1</span></sup><sup class="ltx_sup" id="id12.12.5.5"><span class="ltx_text ltx_font_medium" id="id12.12.5.5.1">2</span></sup>
<br class="ltx_break"/></span>
<sup class="ltx_sup" id="id26.25.id8">1</sup> Fudan University <sup class="ltx_sup" id="id27.26.id9">2</sup> Shanghai Innovation Institute 
<br class="ltx_break"/><sup class="ltx_sup" id="id28.27.id10">3</sup> The University of Sydney <sup class="ltx_sup" id="id29.28.id11">4</sup> Shanghai AI Laboratory <sup class="ltx_sup" id="id30.29.id12">5</sup> Nanyang Technological University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id31.30.id13">yikunwang19@fudan.edu.cn</span>
</span><span class="ltx_author_notes">Yikun and Siyin contributed equallyCorresponding Author</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id32.id1">Recent advancements in Large Vision-Language Models have showcased remarkable capabilities. However, they often falter when confronted with complex reasoning tasks that humans typically address through visual aids and deliberate, step-by-step thinking. While existing methods have explored text-based slow thinking or rudimentary visual assistance, they fall short of capturing the intricate, interleaved nature of human visual-verbal reasoning processes. To overcome these limitations and inspired by the mechanisms of slow thinking in human cognition, we introduce <span class="ltx_text ltx_font_bold ltx_font_italic" id="id32.id1.1">VisuoThink</span>, a novel framework that seamlessly integrates visuospatial and linguistic domains. <span class="ltx_text ltx_font_italic" id="id32.id1.2">VisuoThink</span> facilitates multimodal slow thinking by enabling progressive visual-textual reasoning and incorporates test-time scaling through look-ahead tree search. Extensive experiments demonstrate that <span class="ltx_text ltx_font_italic" id="id32.id1.3">VisuoThink</span> significantly enhances reasoning capabilities via inference-time scaling, even without fine-tuning, achieving state-of-the-art performance in tasks involving geometry and spatial reasoning. Our code has been open-sourced at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ekonwang/VisuoThink" title="">https://github.com/ekonwang/VisuoThink</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.17">
<p class="ltx_p" id="p1.17.18"><span class="ltx_text ltx_font_bold ltx_font_italic" id="p1.17.18.1">VisuoThink<span class="ltx_text ltx_font_upright" id="p1.17.18.1.1">: Empowering LVLM Reasoning with Multimodal Tree Search</span></span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.17.17" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.17.17.17" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.17.17.17.17">
<span class="ltx_tr" id="p1.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.7"><span class="ltx_text ltx_font_bold" id="p1.7.7.7.7.7.7.7">Yikun Wang<span class="ltx_note ltx_role_thanks" id="p1.7.7.7.7.7.7.7.1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Yikun and Siyin contributed equally</span></span></span><sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.2"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.2.1">1</span></sup><sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.3"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.3.1">2</span></sup>,  Siyin Wang<span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex2.1.1.1">1</span></span></span></span></span><sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.4"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.4.1">1</span></sup><sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.5"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.5.1">2</span></sup>,  Qinyuan Cheng<sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.6"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.6.1">1</span></sup>,  Zhaoye Fei<sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.7"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.7.1">1</span></sup>,  Liang Ding<sup class="ltx_sup" id="p1.7.7.7.7.7.7.7.8"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.7.7.8.1">3</span></sup>,</span></span></span>
<span class="ltx_tr" id="p1.12.12.12.12.12">
<span class="ltx_td ltx_align_center" id="p1.12.12.12.12.12.5" style="padding-bottom:5.0pt;"><span class="ltx_text ltx_font_bold" id="p1.12.12.12.12.12.5.5">  Qipeng Guo<sup class="ltx_sup" id="p1.12.12.12.12.12.5.5.1"><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.1.1">2</span></sup><sup class="ltx_sup" id="p1.12.12.12.12.12.5.5.2"><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.2.1">4</span></sup>,  Dacheng Tao<sup class="ltx_sup" id="p1.12.12.12.12.12.5.5.3"><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.3.1">5</span></sup>,  Xipeng Qiu<span class="ltx_note ltx_role_thanks" id="p1.12.12.12.12.12.5.5.4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.4.1">Corresponding Author</span></span></span></span><sup class="ltx_sup" id="p1.12.12.12.12.12.5.5.5"><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.5.1">1</span></sup><sup class="ltx_sup" id="p1.12.12.12.12.12.5.5.6"><span class="ltx_text ltx_font_medium" id="p1.12.12.12.12.12.5.5.6.1">2</span></sup></span></span></span>
<span class="ltx_tr" id="p1.14.14.14.14.14">
<span class="ltx_td ltx_align_center" id="p1.14.14.14.14.14.2"><sup class="ltx_sup" id="p1.14.14.14.14.14.2.1">1</sup> Fudan University <sup class="ltx_sup" id="p1.14.14.14.14.14.2.2">2</sup> Shanghai Innovation Institute</span></span>
<span class="ltx_tr" id="p1.17.17.17.17.17">
<span class="ltx_td ltx_align_center" id="p1.17.17.17.17.17.3"><sup class="ltx_sup" id="p1.17.17.17.17.17.3.1">3</sup> The University of Sydney <sup class="ltx_sup" id="p1.17.17.17.17.17.3.2">4</sup> Shanghai AI Laboratory <sup class="ltx_sup" id="p1.17.17.17.17.17.3.3">5</sup> Nanyang Technological University</span></span>
<span class="ltx_tr" id="p1.17.17.17.17.18">
<span class="ltx_td ltx_align_center" id="p1.17.17.17.17.18.1"><span class="ltx_text ltx_font_typewriter" id="p1.17.17.17.17.18.1.1">yikunwang19@fudan.edu.cn</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advances in Large Vision-Language Models (LVLMs) <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib18" title="">2024a</a>); Team (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib25" title="">2024</a>)</cite> have shown remarkable progress across a variety of tasks. However, these models often struggle with complex reasoning challenges, such as geometric problem-solving <cite class="ltx_cite ltx_citemacro_cite">Qiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib20" title="">2024</a>); Cherian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib3" title="">2024</a>)</cite> or spatial reasoning <cite class="ltx_cite ltx_citemacro_cite">Ramakrishnan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib21" title="">2024</a>); Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite>, where human problem-solving approaches typically rely on visual aids. For example, when solving geometry problems, humans often iteratively sketch auxiliary lines or visualize intermediate steps, while exploring different reasoning paths - a form of "slow thinking" <cite class="ltx_cite ltx_citemacro_cite">Kahneman (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib10" title="">2011</a>)</cite> that combines visual and verbal cognitive processes.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S1.F1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of Input-Output Prompting, <span class="ltx_text ltx_font_italic" id="S1.F1.4.1">CoT</span>, Vision-aided Thought and our <span class="ltx_text ltx_font_italic" id="S1.F1.5.2">VisuoThink</span>. Vision-aided Thought often relies on reasoning with one-step or unreliable multi-step visual cues (generated by LVLMs). While <span class="ltx_text ltx_font_italic" id="S1.F1.6.3">VisuoThink</span> addresses this gap through tool-augmented visual hints, coupled with a predictive-rollout search mechanism to systematically optimize reasoning capability.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">With the success of o1 series models <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib19" title="">2024b</a>)</cite>, researchers have explored language as a medium for implementing slow thinking, coupled with test-time scaling techniques <cite class="ltx_cite ltx_citemacro_cite">Zeng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib35" title="">2024</a>)</cite>.
Given the inherently multimodal nature of reality, early efforts <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib30" title="">2024</a>); Thawakar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib26" title="">2025</a>); Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib32" title="">2024</a>); Du et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib5" title="">2025</a>)</cite> have attempted to extend such deliberative thinking to multimodal reasoning.
However, even augmented with search strategy, these methods treat visual information merely as static input, relying solely on textual reasoning chains during the reasoning process - creating a "visual blind spot", where the potential for visual information throughout the reasoning process is largely ignored (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">1</span></a>a).
On the other hand, while approaches like VisualSketchpad <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib9" title="">2024</a>)</cite> and VoT <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite> have recognized the importance of visual information by incorporating visual aids in reasoning (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">1</span></a>b), they mainly focus on single-step assistance or simplified visual hints (e.g., emojis).
These methods lack the multi-step visual-textual interleaved reasoning process that characterizes human slow thinking, while failing to explore potential search strategies.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these limitations, we propose <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p3.1.1">VisuoThink</span>, a multimodal tree search framework that systematically explores multiple reasoning paths with vision-text interleaved thinking at each step.
Unlike previous approaches, Visuothink (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">1</span></a>c) enables multimodal slow thinking through two key innovations: (1) a step-by-step vision-text interleaved reasoning framework that dynamically utilizes multi-step visual aids from tool uses, and (2) a look-ahead tree search algorithm that explores multiple reasoning paths, enabling test-time scaling of the reasoning process.
Specifically, our look-ahead tree search incorporates a predictive rollout mechanism that simulates the likely outcomes of different reasoning states. This allows the model to prioritize more promising paths and avoid less ones, guiding the reasoning process toward the optimal solution. Through this test-time scaling capability, the model can thoroughly explore and optimize reasoning paths dynamically during inference.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Our empirical evaluation demonstrates that Visuothink significantly outperforms existing methods across various reasoning tasks, particularly in geometry and spatial reasoning domains.
On Geomeverse, Our methods achieves an accuracy@1 as high as <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">48.5</span>%, with an improvement of as high as <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">21.8</span>% over the state-of-the-art baseline, which particularly shows strong performance of VisuoThink on problems requiring multi-step visual reasoning.
Through extensive ablation studies, we show that each component of our framework contributes meaningfully to its overall performance.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, our contributions include:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a novel reasoning paradigm, multimodal tree search, for multimodal slow thinking that enables dynamic integration of visual and verbal reasoning paths throughout the problem-solving search process.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We extend test-time scaling methods to the visual domain by proposing a predictive rollout mechanism that explores and optimizes visual reasoning paths by predicting future states.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate substantial empirical improvements across multiple reasoning tasks, particularly in geometry and spatial reasoning, with detailed analyses revealing key insights about our approach.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Text-centric Reasoning in LVLMs</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">With the emergence of o1 models <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib19" title="">2024b</a>)</cite>, the importance of slow thinking has become increasingly evident <cite class="ltx_cite ltx_citemacro_cite">Zeng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib35" title="">2024</a>)</cite>.
Several works have attempted to extend this to LVLMs through methods like stage-wise reasoning <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib30" title="">2024</a>)</cite>, curriculum learning <cite class="ltx_cite ltx_citemacro_cite">Thawakar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib26" title="">2025</a>)</cite>, tree search-based data generation <cite class="ltx_cite ltx_citemacro_cite">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib32" title="">2024</a>)</cite>, and LLM distillation <cite class="ltx_cite ltx_citemacro_cite">Du et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib5" title="">2025</a>)</cite>.
However, these methods treat visual information as static input, relying only on textual data during reasoning, which limits their ability to fully leverage multimodal information for complex tasks.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The illustration of our <span class="ltx_text ltx_font_italic" id="S2.F2.2.1">VisuoThink</span> framework with three stages: (1) vision-text interleaved expansion: generates candidate paths through vision-text interleaved thinking; (2) rollout simulation: sample candidate reasoning nodes and then perform look-ahead search to better evaluate the value of current states; (3) selection: selects the most promising path via self-voting with results or states from rollout.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Vision-aided Reasoning</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Recent advancements in multimodal reasoning have demonstrated that incorporating visual information provides richer context and hints compared to text-only approaches.
Early studies adopted a two-stage approach, where visual information is first transformed and grounded into text <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib36" title="">2023</a>)</cite>, graph structures (e.g., scene graphs <cite class="ltx_cite ltx_citemacro_cite">Mitra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib16" title="">2023</a>)</cite> or knowledge graphs <cite class="ltx_cite ltx_citemacro_cite">Mondal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib17" title="">2024</a>)</cite>), or bounding boxes <cite class="ltx_cite ltx_citemacro_cite">Lei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib12" title="">2024</a>)</cite>, followed by reasoning. Other works leverage existing vision models (e.g., segmentation, detection) to process input images into valuable cues for perception, enabling more precise image-understanding with fine-grained visual information <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib31" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib38" title="">2024</a>); Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib7" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Another sequence of research focuses on intermediate visual representations to enhance reasoning. For instance, Visual Sketchpad <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib9" title="">2024</a>)</cite> employs Python-based drawing tools to generate sketches as intermediate visual aids for geometric problems, while VoT <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite> formalizes visual thinking by generating emoji-like textual representations. MVOT <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib13" title="">2025</a>)</cite> fine-tunes multimodal models to generate images during reasoning, allowing the model to create visual aids dynamically.
Despite these advancements, most existing methods rely on single-step or unreliable visual representations, lacking search mechanisms to test-time scaling through exploring multiple reasoning paths.
In contrast, we develop a multimodal tree search framework that both leverages multi-step visual cues during reasoning and systematically explores reasoning paths through tree search.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Test-time Scaling with Tree Search</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Scaling compute at test time has emerged as a powerful strategy to enhance LLMs’ reasoning capabilities without increasing model parameters <cite class="ltx_cite ltx_citemacro_cite">Snell et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib23" title="">2024</a>)</cite>.
Various approaches including BoN <cite class="ltx_cite ltx_citemacro_cite">Gui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib8" title="">2024</a>); Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib24" title="">2024</a>); Amini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib1" title="">2024</a>)</cite>, guided beam search <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib29" title="">2023</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib34" title="">2023</a>)</cite>, and Monte Carlo Tree Search (MCTS) <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib6" title="">2023</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib14" title="">2023</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib2" title="">2024</a>)</cite> have been explored for text models, demonstrating improved performance through different search strategies.
However, the exploration of test-time scaling in LVLMs remains limited. Prior work like AtomThink <cite class="ltx_cite ltx_citemacro_cite">Xiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib28" title="">2024</a>)</cite> has only investigated basic methods such as beam search, with text-only reasoning chains. In contrast, our method introduces vision-text interleaved thinking with look-ahead search, extending test-time scaling to multimodal reasoning.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>VisuoThink</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We propose <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p1.1.1">VisuoThink</span>, a novel framework for multimodal reasoning that dynamically integrates visual and textual information during the inference process. At its core, our framework implements multimodal slow thinking through a key mechanism: predictive rollout search that allows models to <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">think</span> ahead.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Vision-Text Interleaved Thinking</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Our framework facilitates vision-text interleaved reasoning through an iterative cycle of <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">Thought</span>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.2">Action</span>, and <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.3">Observation</span> like existing work <cite class="ltx_cite ltx_citemacro_cite">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib33" title="">2023</a>)</cite>, which enables natural and dynamic interactions with external tools.
(1) Thought phase: the model leverages visual information for textual reasoning (such as analyzing patterns based on previously added auxiliary lines) and determines the next step by planning what visual hints should be added to enhance understanding. (2) Action phase: the model executes the planned operations by calling external tools (like using <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.4">Python</span> code to draw auxiliary lines or highlight key features) to generate or modify visual information. (3) Observation phase: the model processes the visual feedback from the Action phase, incorporating these new visual hints into the next reasoning step.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The importance of visual information for LVLM reasoning is highlighted in <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">VisuoThink</span>,
which utilize tool invocations to construct <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">reliable</span> visual hints step by step in a visual construction process.
This tool-based design allows <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">VisuoThink</span> to flexibly adapt to various visual reasoning tasks. Moreover, unlike approaches (e.g. <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.4">VisualSketchpad</span>) that generate all visual aids at once, our step-by-step visual guidance naturally integrates with search techniques, enabling effective test-time scaling.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Predictive Rollout Search</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Based on tree search methods and inspired by MCTS, we propose a predictive rollout search mechanism that interleaves visual-text thinking. By anticipating the outcomes of intermediate states, the model can make timely corrections, enabling more accurate and powerful reasoning.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S2.F2" title="Figure 2 ‣ 2.1 Text-centric Reasoning in LVLMs ‣ 2 Related Work ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">2</span></a>, at each reasoning step, our framework first generates multiple candidate paths through vision-text interleaved thinking, then simulates these paths to predict their outcomes, and finally selects the most promising path through a self-voting mechanism.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Vision-Text Interleaved Expansion</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.4">In the whole reasoning chain <math alttext="\textbf{A}=\{\textbf{a}_{1},\textbf{a}_{2},\dots,\textbf{a}_{t}\}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.1.m1.4"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.4a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.4.4" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5a.cmml">A</mtext><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.4" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml"><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2a.cmml">a</mtext><mn id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.5" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2a.cmml">a</mtext><mn id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.6" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.7" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2a.cmml">a</mtext><mi id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.3.cmml">t</mi></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.4b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4"><eq id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.4"></eq><ci id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.5">A</mtext></ci><set id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.4.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2">a</mtext></ci><cn id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2">a</mtext></ci><cn id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">…</ci><apply id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.2">a</mtext></ci><ci id="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.4.4.3.3.3.3">𝑡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.4c">\textbf{A}=\{\textbf{a}_{1},\textbf{a}_{2},\dots,\textbf{a}_{t}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.1.m1.4d">A = { a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT }</annotation></semantics></math>, given the current node <math alttext="\textbf{a}_{t-1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2a.cmml">a</mtext><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">a</mtext></ci><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3"><minus id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.1"></minus><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2">𝑡</ci><cn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">\textbf{a}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.2.m2.1d">a start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math>, the model samples <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.3.m3.1d">italic_k</annotation></semantics></math> candidate nodes <math alttext="\textbf{S}_{t}=\{\textbf{s}_{t}^{1},\textbf{s}_{t}^{2},...,\textbf{s}_{t}^{k}\}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.4.m4.4"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.4a"><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.cmml"><msub id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2a.cmml">S</mtext><mi id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.3.cmml">t</mi></msub><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml"><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.4" stretchy="false" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml">{</mo><msubsup id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2a.cmml">s</mtext><mi id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.3.cmml">t</mi><mn id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.5" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml">,</mo><msubsup id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2a.cmml">s</mtext><mi id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.3.cmml">t</mi><mn id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.6" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml">,</mo><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" mathvariant="normal" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">…</mi><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.7" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml">,</mo><msubsup id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2a.cmml">s</mtext><mi id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.3.cmml">t</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.3.cmml">k</mi></msubsup><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.8" stretchy="false" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.4b"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4"><eq id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4"></eq><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.2">S</mtext></ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.3">𝑡</ci></apply><set id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.2">s</mtext></ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.2.3">𝑡</ci></apply><cn id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2">superscript</csymbol><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.2">s</mtext></ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.2.3">𝑡</ci></apply><cn id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">…</ci><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3">superscript</csymbol><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.2">s</mtext></ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.2.3">𝑡</ci></apply><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.3.3.3.3">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.4c">\textbf{S}_{t}=\{\textbf{s}_{t}^{1},\textbf{s}_{t}^{2},...,\textbf{s}_{t}^{k}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.4.m4.4d">S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT }</annotation></semantics></math>. Each candidate follows the vision-text interleaved thinking process described above, generating a sequence of Thought, Action, and Observation steps. This expansion creates a tree of possible reasoning paths, each representing a different problem-solving strategy.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Rollout Simulation</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.2">Visual reasoning often requires multiple steps to reach a conclusion, making it crucial to evaluate the full potential of each path. For each candidate node <math alttext="\textbf{s}_{t}^{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><msubsup id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2a.cmml">s</mtext><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.3.cmml">t</mi><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2a.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.2">s</mtext></ci><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">\textbf{s}_{t}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.1.m1.1d">s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>, the model simulates the complete reasoning process to predict final outcomes <math alttext="\textbf{r}_{t}^{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><msubsup id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2a.cmml">r</mtext><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.3.cmml">t</mi><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2a.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.2">r</mtext></ci><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">\textbf{r}_{t}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.2.m2.1d">r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>, rather than relying solely on immediate state evaluation.
Different from expansion, the simulation extends each candidate node with a single path of vision-text interleaved thinking until reaching a final result.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Selection</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px3.p1.1">The selection of the optimal path is performed through a self-voting mechanism. The model considers the task description, historical nodes, and the simulated path with predicted results for each candidate node. The selection process can be formalized as:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{Select}(\textbf{S}_{t})=\arg\max_{\textbf{s}_{t}^{i}\in\textbf{S}_{t}}%
\mathbf{Vote}(\textbf{A}_{t-1},\textbf{s}_{t}^{i},\textbf{r}_{t}^{i})" class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">𝐒𝐞𝐥𝐞𝐜𝐭</mi><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2a.cmml">S</mtext><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.5" xref="S3.E1.m1.4.4.5.cmml">=</mo><mrow id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.4.4.cmml"><mrow id="S3.E1.m1.4.4.4.5" xref="S3.E1.m1.4.4.4.5.cmml"><mi id="S3.E1.m1.4.4.4.5.1" xref="S3.E1.m1.4.4.4.5.1.cmml">arg</mi><mo id="S3.E1.m1.4.4.4.5a" lspace="0.167em" xref="S3.E1.m1.4.4.4.5.cmml">⁡</mo><mrow id="S3.E1.m1.4.4.4.5.2" xref="S3.E1.m1.4.4.4.5.2.cmml"><munder id="S3.E1.m1.4.4.4.5.2.1" xref="S3.E1.m1.4.4.4.5.2.1.cmml"><mi id="S3.E1.m1.4.4.4.5.2.1.2" xref="S3.E1.m1.4.4.4.5.2.1.2.cmml">max</mi><mrow id="S3.E1.m1.4.4.4.5.2.1.3" xref="S3.E1.m1.4.4.4.5.2.1.3.cmml"><msubsup id="S3.E1.m1.4.4.4.5.2.1.3.2" xref="S3.E1.m1.4.4.4.5.2.1.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.5.2.1.3.2.2.2" xref="S3.E1.m1.4.4.4.5.2.1.3.2.2.2a.cmml">s</mtext><mi id="S3.E1.m1.4.4.4.5.2.1.3.2.2.3" xref="S3.E1.m1.4.4.4.5.2.1.3.2.2.3.cmml">t</mi><mi id="S3.E1.m1.4.4.4.5.2.1.3.2.3" xref="S3.E1.m1.4.4.4.5.2.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.E1.m1.4.4.4.5.2.1.3.1" xref="S3.E1.m1.4.4.4.5.2.1.3.1.cmml">∈</mo><msub id="S3.E1.m1.4.4.4.5.2.1.3.3" xref="S3.E1.m1.4.4.4.5.2.1.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.5.2.1.3.3.2" xref="S3.E1.m1.4.4.4.5.2.1.3.3.2a.cmml">S</mtext><mi id="S3.E1.m1.4.4.4.5.2.1.3.3.3" xref="S3.E1.m1.4.4.4.5.2.1.3.3.3.cmml">t</mi></msub></mrow></munder><mo id="S3.E1.m1.4.4.4.5.2a" lspace="0.167em" xref="S3.E1.m1.4.4.4.5.2.cmml">⁡</mo><mi id="S3.E1.m1.4.4.4.5.2.2" xref="S3.E1.m1.4.4.4.5.2.2.cmml">𝐕𝐨𝐭𝐞</mi></mrow></mrow><mo id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.4.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.4.3.3" xref="S3.E1.m1.4.4.4.3.4.cmml"><mo id="S3.E1.m1.4.4.4.3.3.4" stretchy="false" xref="S3.E1.m1.4.4.4.3.4.cmml">(</mo><msub id="S3.E1.m1.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.1.1.1.2a.cmml">A</mtext><mrow id="S3.E1.m1.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.3.2" xref="S3.E1.m1.2.2.2.1.1.1.3.2.cmml">t</mi><mo id="S3.E1.m1.2.2.2.1.1.1.3.1" xref="S3.E1.m1.2.2.2.1.1.1.3.1.cmml">−</mo><mn id="S3.E1.m1.2.2.2.1.1.1.3.3" xref="S3.E1.m1.2.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.E1.m1.4.4.4.3.3.5" xref="S3.E1.m1.4.4.4.3.4.cmml">,</mo><msubsup id="S3.E1.m1.3.3.3.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.3.2.2.2.2.2" xref="S3.E1.m1.3.3.3.2.2.2.2.2a.cmml">s</mtext><mi id="S3.E1.m1.3.3.3.2.2.2.2.3" xref="S3.E1.m1.3.3.3.2.2.2.2.3.cmml">t</mi><mi id="S3.E1.m1.3.3.3.2.2.2.3" xref="S3.E1.m1.3.3.3.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.E1.m1.4.4.4.3.3.6" xref="S3.E1.m1.4.4.4.3.4.cmml">,</mo><msubsup id="S3.E1.m1.4.4.4.3.3.3" xref="S3.E1.m1.4.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.3.3.3.2.2" xref="S3.E1.m1.4.4.4.3.3.3.2.2a.cmml">r</mtext><mi id="S3.E1.m1.4.4.4.3.3.3.2.3" xref="S3.E1.m1.4.4.4.3.3.3.2.3.cmml">t</mi><mi id="S3.E1.m1.4.4.4.3.3.3.3" xref="S3.E1.m1.4.4.4.3.3.3.3.cmml">i</mi></msubsup><mo id="S3.E1.m1.4.4.4.3.3.7" stretchy="false" xref="S3.E1.m1.4.4.4.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.4.4.5"></eq><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">𝐒𝐞𝐥𝐞𝐜𝐭</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">S</mtext></ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S3.E1.m1.4.4.4.cmml" xref="S3.E1.m1.4.4.4"><times id="S3.E1.m1.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4"></times><apply id="S3.E1.m1.4.4.4.5.cmml" xref="S3.E1.m1.4.4.4.5"><arg id="S3.E1.m1.4.4.4.5.1.cmml" xref="S3.E1.m1.4.4.4.5.1"></arg><apply id="S3.E1.m1.4.4.4.5.2.cmml" xref="S3.E1.m1.4.4.4.5.2"><apply id="S3.E1.m1.4.4.4.5.2.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.5.2.1.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1">subscript</csymbol><max id="S3.E1.m1.4.4.4.5.2.1.2.cmml" xref="S3.E1.m1.4.4.4.5.2.1.2"></max><apply id="S3.E1.m1.4.4.4.5.2.1.3.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3"><in id="S3.E1.m1.4.4.4.5.2.1.3.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.1"></in><apply id="S3.E1.m1.4.4.4.5.2.1.3.2.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.5.2.1.3.2.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2">superscript</csymbol><apply id="S3.E1.m1.4.4.4.5.2.1.3.2.2.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.5.2.1.3.2.2.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2">subscript</csymbol><ci id="S3.E1.m1.4.4.4.5.2.1.3.2.2.2a.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.5.2.1.3.2.2.2.cmml" mathsize="70%" xref="S3.E1.m1.4.4.4.5.2.1.3.2.2.2">s</mtext></ci><ci id="S3.E1.m1.4.4.4.5.2.1.3.2.2.3.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2.2.3">𝑡</ci></apply><ci id="S3.E1.m1.4.4.4.5.2.1.3.2.3.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.2.3">𝑖</ci></apply><apply id="S3.E1.m1.4.4.4.5.2.1.3.3.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.5.2.1.3.3.1.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.3">subscript</csymbol><ci id="S3.E1.m1.4.4.4.5.2.1.3.3.2a.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.5.2.1.3.3.2.cmml" mathsize="70%" xref="S3.E1.m1.4.4.4.5.2.1.3.3.2">S</mtext></ci><ci id="S3.E1.m1.4.4.4.5.2.1.3.3.3.cmml" xref="S3.E1.m1.4.4.4.5.2.1.3.3.3">𝑡</ci></apply></apply></apply><ci id="S3.E1.m1.4.4.4.5.2.2.cmml" xref="S3.E1.m1.4.4.4.5.2.2">𝐕𝐨𝐭𝐞</ci></apply></apply><vector id="S3.E1.m1.4.4.4.3.4.cmml" xref="S3.E1.m1.4.4.4.3.3"><apply id="S3.E1.m1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.1.2a.cmml" xref="S3.E1.m1.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.2">A</mtext></ci><apply id="S3.E1.m1.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.3"><minus id="S3.E1.m1.2.2.2.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.3.1"></minus><ci id="S3.E1.m1.2.2.2.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.3.2">𝑡</ci><cn id="S3.E1.m1.2.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E1.m1.3.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2">superscript</csymbol><apply id="S3.E1.m1.3.3.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.3.2.2.2.2.2a.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.3.3.3.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.2">s</mtext></ci><ci id="S3.E1.m1.3.3.3.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.2.3">𝑡</ci></apply><ci id="S3.E1.m1.3.3.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.2.2.2.3">𝑖</ci></apply><apply id="S3.E1.m1.4.4.4.3.3.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.3.3.3.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3">superscript</csymbol><apply id="S3.E1.m1.4.4.4.3.3.3.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.3.3.3.2.1.cmml" xref="S3.E1.m1.4.4.4.3.3.3">subscript</csymbol><ci id="S3.E1.m1.4.4.4.3.3.3.2.2a.cmml" xref="S3.E1.m1.4.4.4.3.3.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.4.4.4.3.3.3.2.2.cmml" xref="S3.E1.m1.4.4.4.3.3.3.2.2">r</mtext></ci><ci id="S3.E1.m1.4.4.4.3.3.3.2.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3.2.3">𝑡</ci></apply><ci id="S3.E1.m1.4.4.4.3.3.3.3.cmml" xref="S3.E1.m1.4.4.4.3.3.3.3">𝑖</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\mathbf{Select}(\textbf{S}_{t})=\arg\max_{\textbf{s}_{t}^{i}\in\textbf{S}_{t}}%
\mathbf{Vote}(\textbf{A}_{t-1},\textbf{s}_{t}^{i},\textbf{r}_{t}^{i})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">bold_Select ( S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = roman_arg roman_max start_POSTSUBSCRIPT s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ∈ S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_Vote ( A start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px3.p3">
<p class="ltx_p" id="S3.SS2.SSS0.Px3.p3.4">where <math alttext="\textbf{A}_{t-1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p3.1.m1.1"><semantics id="S3.SS2.SSS0.Px3.p3.1.m1.1a"><msub id="S3.SS2.SSS0.Px3.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2a.cmml">A</mtext><mrow id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.1" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.3" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p3.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2a.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.2">A</mtext></ci><apply id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3"><minus id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.1"></minus><ci id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.2">𝑡</ci><cn id="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS0.Px3.p3.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p3.1.m1.1c">\textbf{A}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p3.1.m1.1d">A start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> represents the historical context, <math alttext="\textbf{s}^{i}_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p3.2.m2.1"><semantics id="S3.SS2.SSS0.Px3.p3.2.m2.1a"><msubsup id="S3.SS2.SSS0.Px3.p3.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2a.cmml">s</mtext><mi id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.3" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.3.cmml">t</mi><mi id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.3" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p3.2.m2.1b"><apply id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2a.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.2">s</mtext></ci><ci id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.SSS0.Px3.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p3.2.m2.1c">\textbf{s}^{i}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p3.2.m2.1d">s start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> for the candidate node, and <math alttext="\textbf{r}^{i}_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p3.3.m3.1"><semantics id="S3.SS2.SSS0.Px3.p3.3.m3.1a"><msubsup id="S3.SS2.SSS0.Px3.p3.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2a.cmml">r</mtext><mi id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.3" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.3.cmml">t</mi><mi id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.3" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p3.3.m3.1b"><apply id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1">subscript</csymbol><apply id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2a.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.2">r</mtext></ci><ci id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.SSS0.Px3.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p3.3.m3.1c">\textbf{r}^{i}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p3.3.m3.1d">r start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the predicted result or final state. The <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS2.SSS0.Px3.p3.4.1">Select</span> is a heuristic function served by the LVLM model to guide the process. This selection ensures the model pursues the most promising reasoning strategy.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Solving Geometry with VisuoThink</h2>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:390.3pt;height:96.5pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-207.4pt,51.0pt) scale(0.484713140851215,0.484713140851215) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T1.1.1">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T1.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.1.1.1.2">Model</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">Qwen2-VL-72B-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">Claude-3.5-sonnet</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.2.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.1.1">Geomverse-109</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.2.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.3">11.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.4">5.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.5">14.4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.3.1">VisualSketchpad</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2">8.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.3">6.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.4">16.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.1">VisualSketchpad <span class="ltx_text ltx_font_italic" id="S4.T1.1.1.4.1.1">+ Equation Solver</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2">13.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.3">11.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.4">17.8</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.5.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T1.1.1.5.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.5.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.2.1" style="background-color:#E6E6E6;">24.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.3.1" style="background-color:#E6E6E6;">19.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.5.4.1" style="background-color:#E6E6E6;">26.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.1.1" style="background-color:#E6E6E6;">VisuoThink <span class="ltx_text ltx_font_medium" id="S4.T1.1.1.6.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.6.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.2.1" style="background-color:#E6E6E6;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.3.1" style="background-color:#E6E6E6;">25.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.4.1" style="background-color:#E6E6E6;">27.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T1.1.1.7.1" rowspan="5"><span class="ltx_text" id="S4.T1.1.1.7.1.1"><span class="ltx_text" id="S4.T1.1.1.7.1.1.1"></span> <span class="ltx_text" id="S4.T1.1.1.7.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.7.1.1.2.1">
<span class="ltx_tr" id="S4.T1.1.1.7.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.7.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.1.1.2.1.1.1.1">Geometry3K</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.7.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.7.1.1.2.1.2.1"><cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib15" title="">2021</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T1.1.1.7.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.7.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.3">20.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.4">18.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5">37.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.8.1">VisualSketchPad</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.2">22.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.3">17.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.4">39.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.9">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.9.1">VisualSketchpad <span class="ltx_text ltx_font_italic" id="S4.T1.1.1.9.1.1">+ Equation Solver</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.3">14.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.4">41.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.10">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.10.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.10.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T1.1.1.10.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.10.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.2.1" style="background-color:#E6E6E6;">27.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.3.1" style="background-color:#E6E6E6;">20.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.10.4.1" style="background-color:#E6E6E6;">37.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.1.11.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T1.1.1.11.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T1.1.1.11.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.2.1" style="background-color:#E6E6E6;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.3.1" style="background-color:#E6E6E6;">25.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.4.1" style="background-color:#E6E6E6;">43.8</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The 1-shot benchmark results (<span class="ltx_text ltx_font_italic" id="S4.T1.9.1">Accuracy@1</span>) on Geometry including <span class="ltx_text ltx_font_bold" id="S4.T1.10.2">Geomverse-109</span> and <span class="ltx_text ltx_font_bold" id="S4.T1.11.3">Geometry3k</span> of SOTA large visual language models. For GPT-4o and Claude-3.5-sonnet, we employ newest cutoffs (<span class="ltx_text ltx_font_italic" id="S4.T1.12.4">gpt-4o-2024-11-20</span> and <span class="ltx_text ltx_font_italic" id="S4.T1.13.5">claude-3-5-sonnet-20241022</span>) separately. The <span class="ltx_text" id="S4.T1.14.6" style="color:#CCCCCC;">gray</span> part indicates results from VisuoThink and <span class="ltx_text ltx_font_bold" id="S4.T1.15.7">bold</span> results represent the best performance.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:411.9pt;height:229.2pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-69.8pt,38.7pt) scale(0.746864051763141,0.746864051763141) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T2.1.1">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.1.2">Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">Visual Navigation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1">Visual Tiling</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.2">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.2.1">Subset (Num. Samples)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.2"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.2.1">level-3 (16)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.3"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.3.1">level-4 (31)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.4"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.4.1">level-5 (62)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.2.5"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.2.5.1">level-2 (119)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3">18.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.6">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.4.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.4">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.5">1.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.5.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.5.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.2">62.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3">9.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4">4.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.5">12.6</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.6.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.6.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T2.1.1.6.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.6.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.2.1" style="background-color:#E6E6E6;">81.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.3.1" style="background-color:#E6E6E6;">32.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.4.1" style="background-color:#E6E6E6;">11.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.6.5.1" style="background-color:#E6E6E6;">19.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.7">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.7.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.7.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.7.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.2.1" style="background-color:#E6E6E6;">93.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.3.1" style="background-color:#E6E6E6;">61.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.4.1" style="background-color:#E6E6E6;">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.1" style="background-color:#E6E6E6;">51.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.8.1.1">Qwen2-VL-72B-Instruct</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.3">6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6">0.0</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.9">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.9.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.2">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.5">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.10">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.10.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.10.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.3">3.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.5">6.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.11">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.11.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.11.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search<span class="ltx_text ltx_font_medium" id="S4.T2.1.1.11.1.1.1" style="background-color:#E6E6E6;"> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.11.1.1.1.1" style="background-color:#E6E6E6;">ours</span>)</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.2.1" style="background-color:#E6E6E6;">50.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.3.1" style="background-color:#E6E6E6;">6.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.11.5.1" style="background-color:#E6E6E6;">9.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.12">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.12.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.12.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.12.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.2.1" style="background-color:#E6E6E6;">81.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.3.1" style="background-color:#E6E6E6;">12.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.12.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.5.1" style="background-color:#E6E6E6;">20.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.13">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.1" rowspan="5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.1.1">Claude-3.5-sonnet</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.13.2">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.3">37.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.4">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.6">0.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.14">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.14.1">VoT</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.2">56.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.3">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.4">0.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.5">2.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.15">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.15.1">VoT + <span class="ltx_text ltx_font_italic" id="S4.T2.1.1.15.1.1">Executer</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.2">68.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.3">22.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.4">16.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.5">10.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.16">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.16.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.16.1.1.1" style="background-color:#E6E6E6;">VisuoThink w/o rollout search</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.16.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.2.1" style="background-color:#E6E6E6;">81.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.3.1" style="background-color:#E6E6E6;">38.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.4.1" style="background-color:#E6E6E6;">41.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.16.5.1" style="background-color:#E6E6E6;">80.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.17">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.1.17.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.1.1.17.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span> (<span class="ltx_text ltx_font_italic" id="S4.T2.1.1.17.1.1.2" style="background-color:#E6E6E6;">ours</span>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.2" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.2.1" style="background-color:#E6E6E6;">93.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.3" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.3.1" style="background-color:#E6E6E6;">61.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.4.1" style="background-color:#E6E6E6;">53.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.17.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.5.1" style="background-color:#E6E6E6;">84.0</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The <span class="ltx_text ltx_font_italic" id="S4.T2.13.1">Pass@1</span> performance comparison on spatial reasoning benchmarks including <span class="ltx_text ltx_font_bold" id="S4.T2.14.2">Visual Navigation</span> and <span class="ltx_text ltx_font_bold" id="S4.T2.15.3">Visual Tiling</span> across <span class="ltx_text ltx_font_italic" id="S4.T2.16.4">SOTA</span> LVLMs. The <span class="ltx_text" id="S4.T2.17.5" style="color:#CCCCCC;">gray</span> part indicates results from VisuoThink and <span class="ltx_text ltx_font_bold" id="S4.T2.18.6">bold</span> results represent the best performance. The results of Qwen2-VL-72B-Instruct on Visual Navigation (<span class="ltx_text ltx_font_italic" id="S4.T2.19.7">k = 5</span>) are masked out due to its restrained performance on the subset. The results from <span class="ltx_text ltx_font_italic" id="S4.T2.20.8">VoT</span> with <span class="ltx_text ltx_font_italic" id="S4.T2.21.9">Executor</span> are also reported, where the models utilize the unreliable visual hints generated by themself rather than <span class="ltx_text ltx_font_italic" id="S4.T2.22.10">executor</span>, consistent with the <span class="ltx_text ltx_font_italic" id="S4.T2.23.11">VoT</span> framework.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The core of our methodology is rooted in multi-step visual information processing and search-based reasoning, enabling LVLMs to address strongly constrained mathematical problems (e.g., geometry challenges) and open-domain scenarios (such as visual navigation and visual tiling in section <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5" title="5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.4">We formalize geometry problem-solving as a two-phase process integrating <span class="ltx_text ltx_font_bold" id="S4.p2.4.1">visual construction</span> and <span class="ltx_text ltx_font_bold" id="S4.p2.4.2">algebraic computation</span>. In Phase I, the model generates auxiliary lines defined by geometric constraints, such as connecting points <math alttext="(x_{i},y_{i})" class="ltx_Math" display="inline" id="S4.p2.1.m1.2"><semantics id="S4.p2.1.m1.2a"><mrow id="S4.p2.1.m1.2.2.2" xref="S4.p2.1.m1.2.2.3.cmml"><mo id="S4.p2.1.m1.2.2.2.3" stretchy="false" xref="S4.p2.1.m1.2.2.3.cmml">(</mo><msub id="S4.p2.1.m1.1.1.1.1" xref="S4.p2.1.m1.1.1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.1.1.2" xref="S4.p2.1.m1.1.1.1.1.2.cmml">x</mi><mi id="S4.p2.1.m1.1.1.1.1.3" xref="S4.p2.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.p2.1.m1.2.2.2.4" xref="S4.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.p2.1.m1.2.2.2.2" xref="S4.p2.1.m1.2.2.2.2.cmml"><mi id="S4.p2.1.m1.2.2.2.2.2" xref="S4.p2.1.m1.2.2.2.2.2.cmml">y</mi><mi id="S4.p2.1.m1.2.2.2.2.3" xref="S4.p2.1.m1.2.2.2.2.3.cmml">i</mi></msub><mo id="S4.p2.1.m1.2.2.2.5" stretchy="false" xref="S4.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.2b"><interval closure="open" id="S4.p2.1.m1.2.2.3.cmml" xref="S4.p2.1.m1.2.2.2"><apply id="S4.p2.1.m1.1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.1.1.2">𝑥</ci><ci id="S4.p2.1.m1.1.1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.p2.1.m1.2.2.2.2.cmml" xref="S4.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.1.m1.2.2.2.2.1.cmml" xref="S4.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.p2.1.m1.2.2.2.2.2.cmml" xref="S4.p2.1.m1.2.2.2.2.2">𝑦</ci><ci id="S4.p2.1.m1.2.2.2.2.3.cmml" xref="S4.p2.1.m1.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.2c">(x_{i},y_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.2d">( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="(x_{j},y_{j})" class="ltx_Math" display="inline" id="S4.p2.2.m2.2"><semantics id="S4.p2.2.m2.2a"><mrow id="S4.p2.2.m2.2.2.2" xref="S4.p2.2.m2.2.2.3.cmml"><mo id="S4.p2.2.m2.2.2.2.3" stretchy="false" xref="S4.p2.2.m2.2.2.3.cmml">(</mo><msub id="S4.p2.2.m2.1.1.1.1" xref="S4.p2.2.m2.1.1.1.1.cmml"><mi id="S4.p2.2.m2.1.1.1.1.2" xref="S4.p2.2.m2.1.1.1.1.2.cmml">x</mi><mi id="S4.p2.2.m2.1.1.1.1.3" xref="S4.p2.2.m2.1.1.1.1.3.cmml">j</mi></msub><mo id="S4.p2.2.m2.2.2.2.4" xref="S4.p2.2.m2.2.2.3.cmml">,</mo><msub id="S4.p2.2.m2.2.2.2.2" xref="S4.p2.2.m2.2.2.2.2.cmml"><mi id="S4.p2.2.m2.2.2.2.2.2" xref="S4.p2.2.m2.2.2.2.2.2.cmml">y</mi><mi id="S4.p2.2.m2.2.2.2.2.3" xref="S4.p2.2.m2.2.2.2.2.3.cmml">j</mi></msub><mo id="S4.p2.2.m2.2.2.2.5" stretchy="false" xref="S4.p2.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.2b"><interval closure="open" id="S4.p2.2.m2.2.2.3.cmml" xref="S4.p2.2.m2.2.2.2"><apply id="S4.p2.2.m2.1.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.1.1.2.cmml" xref="S4.p2.2.m2.1.1.1.1.2">𝑥</ci><ci id="S4.p2.2.m2.1.1.1.1.3.cmml" xref="S4.p2.2.m2.1.1.1.1.3">𝑗</ci></apply><apply id="S4.p2.2.m2.2.2.2.2.cmml" xref="S4.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.2.2.2.2.1.cmml" xref="S4.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S4.p2.2.m2.2.2.2.2.2.cmml" xref="S4.p2.2.m2.2.2.2.2.2">𝑦</ci><ci id="S4.p2.2.m2.2.2.2.2.3.cmml" xref="S4.p2.2.m2.2.2.2.2.3">𝑗</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.2c">(x_{j},y_{j})</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.2d">( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math>, construct a perpendicular or parallel line to form line segments <math alttext="\textbf{L}=\{l_{i}\}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3a.cmml">L</mtext><mo id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">=</mo><mrow id="S4.p2.3.m3.1.1.1.1" xref="S4.p2.3.m3.1.1.1.2.cmml"><mo id="S4.p2.3.m3.1.1.1.1.2" stretchy="false" xref="S4.p2.3.m3.1.1.1.2.cmml">{</mo><msub id="S4.p2.3.m3.1.1.1.1.1" xref="S4.p2.3.m3.1.1.1.1.1.cmml"><mi id="S4.p2.3.m3.1.1.1.1.1.2" xref="S4.p2.3.m3.1.1.1.1.1.2.cmml">l</mi><mi id="S4.p2.3.m3.1.1.1.1.1.3" xref="S4.p2.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.p2.3.m3.1.1.1.1.3" stretchy="false" xref="S4.p2.3.m3.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><eq id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2"></eq><ci id="S4.p2.3.m3.1.1.3a.cmml" xref="S4.p2.3.m3.1.1.3"><mtext class="ltx_mathvariant_bold" id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">L</mtext></ci><set id="S4.p2.3.m3.1.1.1.2.cmml" xref="S4.p2.3.m3.1.1.1.1"><apply id="S4.p2.3.m3.1.1.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.1.1.1.2.cmml" xref="S4.p2.3.m3.1.1.1.1.1.2">𝑙</ci><ci id="S4.p2.3.m3.1.1.1.1.1.3.cmml" xref="S4.p2.3.m3.1.1.1.1.1.3">𝑖</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">\textbf{L}=\{l_{i}\}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">L = { italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }</annotation></semantics></math>. This phase terminates with a <span class="ltx_text ltx_font_typewriter" id="S4.p2.4.3">AUX-END</span> token, triggering Phase II, where geometric relationships are translated into solvable equations (e.g., <math alttext="ax+b=0" class="ltx_Math" display="inline" id="S4.p2.4.m4.1"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mrow id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml"><mrow id="S4.p2.4.m4.1.1.2.2" xref="S4.p2.4.m4.1.1.2.2.cmml"><mi id="S4.p2.4.m4.1.1.2.2.2" xref="S4.p2.4.m4.1.1.2.2.2.cmml">a</mi><mo id="S4.p2.4.m4.1.1.2.2.1" xref="S4.p2.4.m4.1.1.2.2.1.cmml">⁢</mo><mi id="S4.p2.4.m4.1.1.2.2.3" xref="S4.p2.4.m4.1.1.2.2.3.cmml">x</mi></mrow><mo id="S4.p2.4.m4.1.1.2.1" xref="S4.p2.4.m4.1.1.2.1.cmml">+</mo><mi id="S4.p2.4.m4.1.1.2.3" xref="S4.p2.4.m4.1.1.2.3.cmml">b</mi></mrow><mo id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">=</mo><mn id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><eq id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1"></eq><apply id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2"><plus id="S4.p2.4.m4.1.1.2.1.cmml" xref="S4.p2.4.m4.1.1.2.1"></plus><apply id="S4.p2.4.m4.1.1.2.2.cmml" xref="S4.p2.4.m4.1.1.2.2"><times id="S4.p2.4.m4.1.1.2.2.1.cmml" xref="S4.p2.4.m4.1.1.2.2.1"></times><ci id="S4.p2.4.m4.1.1.2.2.2.cmml" xref="S4.p2.4.m4.1.1.2.2.2">𝑎</ci><ci id="S4.p2.4.m4.1.1.2.2.3.cmml" xref="S4.p2.4.m4.1.1.2.2.3">𝑥</ci></apply><ci id="S4.p2.4.m4.1.1.2.3.cmml" xref="S4.p2.4.m4.1.1.2.3">𝑏</ci></apply><cn id="S4.p2.4.m4.1.1.3.cmml" type="integer" xref="S4.p2.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">ax+b=0</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m4.1d">italic_a italic_x + italic_b = 0</annotation></semantics></math>) through <span class="ltx_text ltx_font_typewriter" id="S4.p2.4.4">Python</span> code execution.</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Task Formulation</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.7">LVLM should produce the reasoning trajectory consisting of reasoning steps <math alttext="\mathbf{A}=\{\mathbf{a}_{t}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">𝐀</mi><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">=</mo><mrow id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.2.cmml">𝐚</mi><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1"><eq id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2"></eq><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.3">𝐀</ci><set id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1"><apply id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.2">𝐚</ci><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.3">𝑡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">\mathbf{A}=\{\mathbf{a}_{t}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.1.m1.1d">bold_A = { bold_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT }</annotation></semantics></math> that leads to the final result <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.SS0.SSS0.Px1.p1.7.1">r</span>, given the original problem <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px1.p1.3.m3.1a"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.3.m3.1b"><ci id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.3.m3.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.3.m3.1d">bold_Q</annotation></semantics></math> while taking into account the auxiliary lines <math alttext="\mathbf{L}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.4.m4.1"><semantics id="S4.SS0.SSS0.Px1.p1.4.m4.1a"><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">𝐋</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.4.m4.1b"><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1">𝐋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.4.m4.1c">\mathbf{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.4.m4.1d">bold_L</annotation></semantics></math>. The framework operates under a constraint <math alttext="\sum_{t=1}^{|A|}\|\mathbf{a}_{t}\|\leq\tau" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.5.m5.2"><semantics id="S4.SS0.SSS0.Px1.p1.5.m5.2a"><mrow id="S4.SS0.SSS0.Px1.p1.5.m5.2.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.cmml"><mrow id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.cmml"><msubsup id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.cmml"><mo id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.2.cmml">∑</mo><mrow id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.cmml"><mi id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.2.cmml">t</mi><mo id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.3" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.3.cmml">1</mn></mrow><mrow id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.1.cmml">|</mo><mi id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.cmml">A</mi><mo id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.2" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.1.cmml">|</mo></mrow></msubsup><mrow id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.2" lspace="0em" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.2.1.cmml">‖</mo><msub id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.2.cmml">𝐚</mi><mi id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.2.1.cmml">‖</mo></mrow></mrow><mo id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.2" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.2.cmml">≤</mo><mi id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.3" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.3.cmml">τ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.5.m5.2b"><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2"><leq id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.2"></leq><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1"><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2">superscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2">subscript</csymbol><sum id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.2"></sum><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3"><eq id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.1"></eq><ci id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.2">𝑡</ci><cn id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.3.cmml" type="integer" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.2.2.3.3">1</cn></apply></apply><apply id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.3"><abs id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1"></abs><ci id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.1.1">𝐴</ci></apply></apply><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1"><csymbol cd="latexml" id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.2">norm</csymbol><apply id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.2">𝐚</ci><ci id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.1.1.1.1.3">𝑡</ci></apply></apply></apply><ci id="S4.SS0.SSS0.Px1.p1.5.m5.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.2.2.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.5.m5.2c">\sum_{t=1}^{|A|}\|\mathbf{a}_{t}\|\leq\tau</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.5.m5.2d">∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_A | end_POSTSUPERSCRIPT ∥ bold_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∥ ≤ italic_τ</annotation></semantics></math>, where <math alttext="\mathbf{a}_{t}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.6.m6.1"><semantics id="S4.SS0.SSS0.Px1.p1.6.m6.1a"><msub id="S4.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">𝐚</mi><mi id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.2">𝐚</ci><ci id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.6.m6.1c">\mathbf{a}_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.6.m6.1d">bold_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> denotes visual-textual reasoning steps and <math alttext="\tau" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.7.m7.1"><semantics id="S4.SS0.SSS0.Px1.p1.7.m7.1a"><mi id="S4.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.7.m7.1b"><ci id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.7.m7.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.7.m7.1d">italic_τ</annotation></semantics></math> is the maximum step limit:</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{\textbf{A}}\sim\mathcal{P}\left(\{\mathbf{a}_{1},\dots,\mathbf{a}_{|A|%
},\textbf{r}\}\mid\mathbf{Q},\mathbf{L}\right)\\
\text{s.t.}~{}\sum_{t=1}^{|\textbf{A}|}\|\mathbf{a}_{i}\|\leq\tau" class="ltx_Math" display="block" id="S4.E2.m1.8"><semantics id="S4.E2.m1.8a"><mrow id="S4.E2.m1.8.8" xref="S4.E2.m1.8.8.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.8.8.4" xref="S4.E2.m1.8.8.4a.cmml">A</mtext><mo id="S4.E2.m1.8.8.5" xref="S4.E2.m1.8.8.5.cmml">∼</mo><mrow id="S4.E2.m1.8.8.2" xref="S4.E2.m1.8.8.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.8.8.2.4" xref="S4.E2.m1.8.8.2.4.cmml">𝒫</mi><mo id="S4.E2.m1.8.8.2.3" xref="S4.E2.m1.8.8.2.3.cmml">⁢</mo><mrow id="S4.E2.m1.7.7.1.1.1" xref="S4.E2.m1.7.7.1.1.1.1.cmml"><mo id="S4.E2.m1.7.7.1.1.1.2" xref="S4.E2.m1.7.7.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.7.7.1.1.1.1" xref="S4.E2.m1.7.7.1.1.1.1.cmml"><mrow id="S4.E2.m1.7.7.1.1.1.1.2.2" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml"><mo id="S4.E2.m1.7.7.1.1.1.1.2.2.3" stretchy="false" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml">{</mo><msub id="S4.E2.m1.7.7.1.1.1.1.1.1.1" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.7.7.1.1.1.1.1.1.1.2" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml">𝐚</mi><mn id="S4.E2.m1.7.7.1.1.1.1.1.1.1.3" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.E2.m1.7.7.1.1.1.1.2.2.4" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml">,</mo><mi id="S4.E2.m1.3.3" mathvariant="normal" xref="S4.E2.m1.3.3.cmml">…</mi><mo id="S4.E2.m1.7.7.1.1.1.1.2.2.5" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml">,</mo><msub id="S4.E2.m1.7.7.1.1.1.1.2.2.2" xref="S4.E2.m1.7.7.1.1.1.1.2.2.2.cmml"><mi id="S4.E2.m1.7.7.1.1.1.1.2.2.2.2" xref="S4.E2.m1.7.7.1.1.1.1.2.2.2.2.cmml">𝐚</mi><mrow id="S4.E2.m1.1.1.1.3" xref="S4.E2.m1.1.1.1.2.cmml"><mo id="S4.E2.m1.1.1.1.3.1" stretchy="false" xref="S4.E2.m1.1.1.1.2.1.cmml">|</mo><mi id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml">A</mi><mo id="S4.E2.m1.1.1.1.3.2" stretchy="false" xref="S4.E2.m1.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="S4.E2.m1.7.7.1.1.1.1.2.2.6" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4" xref="S4.E2.m1.4.4a.cmml">r</mtext><mo id="S4.E2.m1.7.7.1.1.1.1.2.2.7" stretchy="false" xref="S4.E2.m1.7.7.1.1.1.1.2.3.cmml">}</mo></mrow><mo id="S4.E2.m1.7.7.1.1.1.1.3" xref="S4.E2.m1.7.7.1.1.1.1.3.cmml">∣</mo><mrow id="S4.E2.m1.7.7.1.1.1.1.4.2" xref="S4.E2.m1.7.7.1.1.1.1.4.1.cmml"><mi id="S4.E2.m1.5.5" xref="S4.E2.m1.5.5.cmml">𝐐</mi><mo id="S4.E2.m1.7.7.1.1.1.1.4.2.1" xref="S4.E2.m1.7.7.1.1.1.1.4.1.cmml">,</mo><mi id="S4.E2.m1.6.6" xref="S4.E2.m1.6.6.cmml">𝐋</mi></mrow></mrow><mo id="S4.E2.m1.7.7.1.1.1.3" xref="S4.E2.m1.7.7.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E2.m1.8.8.2.3a" xref="S4.E2.m1.8.8.2.3.cmml">⁢</mo><mtext id="S4.E2.m1.8.8.2.5" xref="S4.E2.m1.8.8.2.5a.cmml">s.t.</mtext><mo id="S4.E2.m1.8.8.2.3b" lspace="0.497em" xref="S4.E2.m1.8.8.2.3.cmml">⁢</mo><mrow id="S4.E2.m1.8.8.2.2" xref="S4.E2.m1.8.8.2.2.cmml"><munderover id="S4.E2.m1.8.8.2.2.2" xref="S4.E2.m1.8.8.2.2.2.cmml"><mo id="S4.E2.m1.8.8.2.2.2.2.2" movablelimits="false" rspace="0em" xref="S4.E2.m1.8.8.2.2.2.2.2.cmml">∑</mo><mrow id="S4.E2.m1.8.8.2.2.2.2.3" xref="S4.E2.m1.8.8.2.2.2.2.3.cmml"><mi id="S4.E2.m1.8.8.2.2.2.2.3.2" xref="S4.E2.m1.8.8.2.2.2.2.3.2.cmml">t</mi><mo id="S4.E2.m1.8.8.2.2.2.2.3.1" xref="S4.E2.m1.8.8.2.2.2.2.3.1.cmml">=</mo><mn id="S4.E2.m1.8.8.2.2.2.2.3.3" xref="S4.E2.m1.8.8.2.2.2.2.3.3.cmml">1</mn></mrow><mrow id="S4.E2.m1.2.2.1.3" xref="S4.E2.m1.2.2.1.2.cmml"><mo id="S4.E2.m1.2.2.1.3.1" stretchy="false" xref="S4.E2.m1.2.2.1.2.1.cmml">|</mo><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.2.2.1.1" xref="S4.E2.m1.2.2.1.1a.cmml">A</mtext><mo id="S4.E2.m1.2.2.1.3.2" stretchy="false" xref="S4.E2.m1.2.2.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S4.E2.m1.8.8.2.2.1.1" xref="S4.E2.m1.8.8.2.2.1.2.cmml"><mo id="S4.E2.m1.8.8.2.2.1.1.2" stretchy="false" xref="S4.E2.m1.8.8.2.2.1.2.1.cmml">‖</mo><msub id="S4.E2.m1.8.8.2.2.1.1.1" xref="S4.E2.m1.8.8.2.2.1.1.1.cmml"><mi id="S4.E2.m1.8.8.2.2.1.1.1.2" xref="S4.E2.m1.8.8.2.2.1.1.1.2.cmml">𝐚</mi><mi id="S4.E2.m1.8.8.2.2.1.1.1.3" xref="S4.E2.m1.8.8.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S4.E2.m1.8.8.2.2.1.1.3" stretchy="false" xref="S4.E2.m1.8.8.2.2.1.2.1.cmml">‖</mo></mrow></mrow></mrow><mo id="S4.E2.m1.8.8.6" xref="S4.E2.m1.8.8.6.cmml">≤</mo><mi id="S4.E2.m1.8.8.7" xref="S4.E2.m1.8.8.7.cmml">τ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.8b"><apply id="S4.E2.m1.8.8.cmml" xref="S4.E2.m1.8.8"><and id="S4.E2.m1.8.8a.cmml" xref="S4.E2.m1.8.8"></and><apply id="S4.E2.m1.8.8b.cmml" xref="S4.E2.m1.8.8"><csymbol cd="latexml" id="S4.E2.m1.8.8.5.cmml" xref="S4.E2.m1.8.8.5">similar-to</csymbol><ci id="S4.E2.m1.8.8.4a.cmml" xref="S4.E2.m1.8.8.4"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.8.8.4.cmml" xref="S4.E2.m1.8.8.4">A</mtext></ci><apply id="S4.E2.m1.8.8.2.cmml" xref="S4.E2.m1.8.8.2"><times id="S4.E2.m1.8.8.2.3.cmml" xref="S4.E2.m1.8.8.2.3"></times><ci id="S4.E2.m1.8.8.2.4.cmml" xref="S4.E2.m1.8.8.2.4">𝒫</ci><apply id="S4.E2.m1.7.7.1.1.1.1.cmml" xref="S4.E2.m1.7.7.1.1.1"><csymbol cd="latexml" id="S4.E2.m1.7.7.1.1.1.1.3.cmml" xref="S4.E2.m1.7.7.1.1.1.1.3">conditional</csymbol><set id="S4.E2.m1.7.7.1.1.1.1.2.3.cmml" xref="S4.E2.m1.7.7.1.1.1.1.2.2"><apply id="S4.E2.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1.2">𝐚</ci><cn id="S4.E2.m1.7.7.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E2.m1.7.7.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3">…</ci><apply id="S4.E2.m1.7.7.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.7.7.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.7.7.1.1.1.1.2.2.2.1.cmml" xref="S4.E2.m1.7.7.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E2.m1.7.7.1.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.7.7.1.1.1.1.2.2.2.2">𝐚</ci><apply id="S4.E2.m1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.3"><abs id="S4.E2.m1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.3.1"></abs><ci id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1">𝐴</ci></apply></apply><ci id="S4.E2.m1.4.4a.cmml" xref="S4.E2.m1.4.4"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.4.4.cmml" xref="S4.E2.m1.4.4">r</mtext></ci></set><list id="S4.E2.m1.7.7.1.1.1.1.4.1.cmml" xref="S4.E2.m1.7.7.1.1.1.1.4.2"><ci id="S4.E2.m1.5.5.cmml" xref="S4.E2.m1.5.5">𝐐</ci><ci id="S4.E2.m1.6.6.cmml" xref="S4.E2.m1.6.6">𝐋</ci></list></apply><ci id="S4.E2.m1.8.8.2.5a.cmml" xref="S4.E2.m1.8.8.2.5"><mtext id="S4.E2.m1.8.8.2.5.cmml" xref="S4.E2.m1.8.8.2.5">s.t.</mtext></ci><apply id="S4.E2.m1.8.8.2.2.cmml" xref="S4.E2.m1.8.8.2.2"><apply id="S4.E2.m1.8.8.2.2.2.cmml" xref="S4.E2.m1.8.8.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.2.2.2.1.cmml" xref="S4.E2.m1.8.8.2.2.2">superscript</csymbol><apply id="S4.E2.m1.8.8.2.2.2.2.cmml" xref="S4.E2.m1.8.8.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.2.2.2.2.1.cmml" xref="S4.E2.m1.8.8.2.2.2">subscript</csymbol><sum id="S4.E2.m1.8.8.2.2.2.2.2.cmml" xref="S4.E2.m1.8.8.2.2.2.2.2"></sum><apply id="S4.E2.m1.8.8.2.2.2.2.3.cmml" xref="S4.E2.m1.8.8.2.2.2.2.3"><eq id="S4.E2.m1.8.8.2.2.2.2.3.1.cmml" xref="S4.E2.m1.8.8.2.2.2.2.3.1"></eq><ci id="S4.E2.m1.8.8.2.2.2.2.3.2.cmml" xref="S4.E2.m1.8.8.2.2.2.2.3.2">𝑡</ci><cn id="S4.E2.m1.8.8.2.2.2.2.3.3.cmml" type="integer" xref="S4.E2.m1.8.8.2.2.2.2.3.3">1</cn></apply></apply><apply id="S4.E2.m1.2.2.1.2.cmml" xref="S4.E2.m1.2.2.1.3"><abs id="S4.E2.m1.2.2.1.2.1.cmml" xref="S4.E2.m1.2.2.1.3.1"></abs><ci id="S4.E2.m1.2.2.1.1a.cmml" xref="S4.E2.m1.2.2.1.1"><mtext class="ltx_mathvariant_bold" id="S4.E2.m1.2.2.1.1.cmml" mathsize="70%" xref="S4.E2.m1.2.2.1.1">A</mtext></ci></apply></apply><apply id="S4.E2.m1.8.8.2.2.1.2.cmml" xref="S4.E2.m1.8.8.2.2.1.1"><csymbol cd="latexml" id="S4.E2.m1.8.8.2.2.1.2.1.cmml" xref="S4.E2.m1.8.8.2.2.1.1.2">norm</csymbol><apply id="S4.E2.m1.8.8.2.2.1.1.1.cmml" xref="S4.E2.m1.8.8.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.8.8.2.2.1.1.1.1.cmml" xref="S4.E2.m1.8.8.2.2.1.1.1">subscript</csymbol><ci id="S4.E2.m1.8.8.2.2.1.1.1.2.cmml" xref="S4.E2.m1.8.8.2.2.1.1.1.2">𝐚</ci><ci id="S4.E2.m1.8.8.2.2.1.1.1.3.cmml" xref="S4.E2.m1.8.8.2.2.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply><apply id="S4.E2.m1.8.8c.cmml" xref="S4.E2.m1.8.8"><leq id="S4.E2.m1.8.8.6.cmml" xref="S4.E2.m1.8.8.6"></leq><share href="https://arxiv.org/html/2504.09130v1#S4.E2.m1.8.8.2.cmml" id="S4.E2.m1.8.8d.cmml" xref="S4.E2.m1.8.8"></share><ci id="S4.E2.m1.8.8.7.cmml" xref="S4.E2.m1.8.8.7">𝜏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.8c">\mathbf{\textbf{A}}\sim\mathcal{P}\left(\{\mathbf{a}_{1},\dots,\mathbf{a}_{|A|%
},\textbf{r}\}\mid\mathbf{Q},\mathbf{L}\right)\\
\text{s.t.}~{}\sum_{t=1}^{|\textbf{A}|}\|\mathbf{a}_{i}\|\leq\tau</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.8d">A ∼ caligraphic_P ( { bold_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_a start_POSTSUBSCRIPT | italic_A | end_POSTSUBSCRIPT , r } ∣ bold_Q , bold_L ) s.t. ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | A | end_POSTSUPERSCRIPT ∥ bold_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ ≤ italic_τ</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p3.1">This formulation mirrors human problem-solving by decomposing proofs into executable visual-textual steps, validated via coordinate-based tools like matplotlib and equation solver.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Visual Construction</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">We emphasize the criticality of incremental visual information for accurate solutions, where multi-step graphical representations originate from the progressive construction of auxiliary lines. This multi-stage approach facilitates search algorithm-enhanced refinement of auxiliary line generation, significantly improving LVLM capabilities in geometric reasoning. Consistent with Sketchpad methodology, we exclusively utilize common <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px2.p1.1.1">Python</span> libraries (e.g., <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.1.2">matplotlib</span>) for diagram rendering.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Algebraic Computation</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">Unlike general tasks, solving geometry problems cannot rely solely on visual construction or the model’s inherent capabilities; instead, it necessitates the use of computational tools to achieve precise and accurate results. This requirement stems from the need for exact numerical solutions and the mitigation of potential errors in geometric reasoning. Through systematic integration, like VPD <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib37" title="">2023</a>)</cite>, and VisualStechpad <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib9" title="">2024</a>)</cite>, phase II employs Python code execution for precise computation to mitigate LVLM hallucination risks. Furthermore, the model constructs single-variable algebraic equations based on identified geometric relationships, subsequently invoking equation solvers for numerical resolution.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Empirical Results</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">We conduct comprehensive evaluations on the challenging Geometry3K and Geomverse-109 datasets to demonstrate the methodological superiority. Especially we detail the trajectory of Geomverse-109 dataset synthesis in appendix <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A5" title="Appendix E Geomverse-109 Problem Generation Trajectory ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">E</span></a>. SOTA closed-source models including <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.1">gpt-4o-2024-11-20</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.2">claude-3-5-sonnet-20241022</span> are leveraged for inference. To ensure architectural diversity, open-source model (e.g., <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.3">Qwen2-VL-72B</span>) were incorporated; however, smaller-parameter open-source variants were excluded due to their capability constraints. And we detail the model and algorithm hyperparameters in appendix <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A4" title="Appendix D Model and VisuoThink Hyperparameters ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="S4.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The illustration of spatial reasoning tasks derived from <span class="ltx_text ltx_font_italic" id="S4.F3.2.1">VoT</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite>, including Visual Navigation and Visual Tiling. LVLM is required to execute a sequence of actions to complete certain goals. Our experimental setting makes them much more challenging and closer to real-environment deployment.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">Our empirical results reveal that, even without rollout search augmentation, our strategy substantially enhances LVLM reasoning capabilities compared to Chain-of-Thought (CoT) <cite class="ltx_cite ltx_citemacro_cite">Mitra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib16" title="">2023</a>)</cite> and Visual Sketchpad <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib9" title="">2024</a>)</cite> baselines. Notably, on the Geomverse-109 <cite class="ltx_cite ltx_citemacro_cite">Kazemi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib11" title="">2023</a>)</cite> benchmark, <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.1" style="color:#333333;">VisuoThink outperforms CoT and Visual Sketchpad by an average of <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p1.1.1.1" style="color:#333333;">17.1</span>% and <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p1.1.1.2" style="color:#333333;">16.7</span>% across all evaluated models, and predictive rollout search further enhances models’ performance by an average of 4.1%</span>. Also, the employment of <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p1.1.2">equation solver</span> on Visual Sketchpad also increases an average performance of <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p1.1.3">3.3</span>%. This performance gap likely stems from Geomverse’s emphasis on geometric relationship construction, where our equation-solving framework help to accurately get intermediate answers and enables efficient resolution of structurally complex problems. The systematic integration of geometric analysis tools further mitigates error propagation inherent in conventional LVLM reasoning baselines.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Spatial Reasoning with VisuoThink</h2>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="647" id="S5.F4.1.g1" src="x4.png" width="831"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="652" id="S5.F4.2.g1" src="x5.png" width="830"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
(<span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S5.F4.8.1">LEFT</span>) The trend of <span class="ltx_text ltx_font_italic" id="S5.F4.9.2">Pass@1</span> rate on Visual Navigation as the number of reasoning steps increases. (<span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S5.F4.10.3">right</span>) The relationship between the <span class="ltx_text ltx_font_italic" id="S5.F4.11.4">Accuracy@1</span> on geometry problems (Geomverse) and tree width for rollout search. <span class="ltx_text ltx_font_bold" id="S5.F4.12.5" style="color:#808080;">We observe that LVLMs significantly benefit from longer reasoning chains, although the effect plateaus rapidly beyond a certain threshold of reasoning steps. The relationship between performance and tree width exhibits a more complex pattern, demonstrating an inverted U-shaped trend with both <span class="ltx_text ltx_font_italic" id="S5.F4.12.5.1">GPT-4o</span> and <span class="ltx_text ltx_font_italic" id="S5.F4.12.5.2">Claude-3.5-Sonnet</span>.</span>
</figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Spatial reasoning, defined as the cognitive capability to interpret spatial object relationships, motion dynamics, and environmental interactions, constitutes a foundational requirement for mission-critical applications such as robotic systems, autonomous navigation, and augmented reality. These domains demand robust integration of visual perception and precise manipulation of spatial-temporal constraints for optimal action planning.</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Task Formulation</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">Building upon the Visualization of Thought (<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1">VoT</span>) <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite> benchmarks, we design two challenging spatial reasoning benchmarks with enhanced complexity as shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.F3" title="Figure 3 ‣ Setup ‣ 4.1 Empirical Results ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">3</span></a>: Visual Navigation and Visual Tiling. We provide detailed materials of the differences between the original VoT benchmark setup and our experimental configuration in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A2" title="Appendix B OKSpatial Reasoning Task Setting ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">B</span></a> and additionally provide the mathematical task formulation in appendix <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A3" title="Appendix C Task Formulation of Spatial Reasoning Tasks ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Visual Construction via <span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS0.SSS0.Px2.1.1">Executor</span>
</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">During task execution, robots deployed in true environments typically receive environmental feedback following each action, which facilitates perception and subsequent decision-making processes. In our methodology, we leverage environmental interaction tools to enhance the model’s spatial reasoning capabilities. In each action, we employ an <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">executor</span> to implement the corresponding action, and return textual execution feedback and visuospatial hint (<span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.2">optional</span>) representing the map state. In the context of (1) Visual Navigation, the visual feedback corresponds to the map including agent’s current position; while in (2) Visual Tiling scenarios, it represents the current state of rectangle occupation patterns.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Empirical Results</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.2">We evaluate our framework on two spatial reasoning benchmarks: Visual Navigation and Visual Tiling. For Visual Navigation, we create three difficulty levels with increasing map complexity, where the level indicates the <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S5.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math> for Visual Navigation as shown in table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.T2" title="Table 2 ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">2</span></a>. For Visual Tiling, we focus on level-2 (i.e. <math alttext="k" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S5.SS1.SSS0.Px1.p1.2.m2.1a"><mi id="S5.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.m2.1b"><ci id="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.2.m2.1d">italic_k</annotation></semantics></math> = 2) problems with 119 samples. We compare our method against Chain-of-Thought (<span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.1">CoT</span>), Visualization of Thought (<span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.2">VoT</span>) <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite>. As table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.T2" title="Table 2 ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">2</span></a> indicates, the results from <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.3">VoT</span> with tool interactions (i.e. <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.4">Executor</span>) are also reported, where textual feedbacks are employed but the visual hints are still generated by the model rather from <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.5">executor</span>, consistent with the <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.6">VoT</span> framework. The source of visual hints distinguishes it from our method. We employ the same temperature and <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.2.7">VisuoThink</span> hyperparameters as section <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.SS1" title="4.1 Empirical Results ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">In spatial reasoning experiments, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.1">VisuoThink</span> demonstrates significant performance improvements over baseline methods, particularly when augmented with predictive rollout search. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4.T2" title="Table 2 ‣ 4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">2</span></a>, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.2">VisuoThink</span> achieves the highest accuracy across all tasks, outperforming both <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.3">CoT</span> and <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.4">VoT</span> baselines. For instance, on the Visual Navigation task, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.5">VisuoThink</span> on GPT-4o achieves a <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.6">93.8</span>% accuracy at level-3, compared to <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.7">62.5</span>% for VoT with an executor and <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.8">18.8</span>% for CoT. This trend is consistent across different model architectures, including <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.9">GPT-4o</span>, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.10">Qwen2-VL-72B-Instruct</span>, and <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p1.1.11">Claude-3.5-sonnet</span>, highlighting the robustness of our approach.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p2.1">Similar to the geometry experiments in Section <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S4" title="4 Solving Geometry with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">4</span></a>, the integration of tool interactions and multi-step visual reasoning plays a critical role in enhancing performance. The executor’s feedback mechanism, which provides visual updates after each action, mirrors the incremental visual refinement seen in geometry tasks, where auxiliary lines are progressively constructed.
For instance, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p2.1.1">VisuoThink</span> without rollout search demonstrates an average improvement of <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p2.1.2">34.7%</span> on Visual Tiling across diverse models. We observe that while VoT augmented with textual feedback achieves an average increase of <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p2.1.3">8.1%</span>, its performance gain is notably less pronounced compared to <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px2.p2.1.4">VisuoThink</span> without rollout search. This underscores the critical role of reliable visual cues in enhancing reasoning capabilities.
The dynamic interaction allows the model to iteratively refine its reasoning path, leading to more accurate solutions.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we analyze key aspects of <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">VisuoThink</span>’s performance. We examine how the length of reasoning chain affects spatial reasoning, the impact of child node expansion in rollout search, and the influence of supervision levels in predictive rollouts across tasks. These insights highlight <span class="ltx_text ltx_font_italic" id="S6.p1.1.2">VisuoThink</span>’s effectiveness and suggest future directions for multimodal reasoning frameworks.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Could Longer Reasoning Chains Assist LVLMs in Reasoning?</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">In practical applications of <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.1">LVLM</span>s for spatial reasoning tasks, each tool invocation can be seen as an agent attempting an action in the environment and receiving feedback. Although many attempts may be inaccurate, allowing the model more trial-and-error opportunities before achieving the final goal could potentially enhance its reasoning capabilities. By setting different upper limits on the number of reasoning steps in visual navigation tasks, <span class="ltx_text ltx_font_bold" id="S6.SS1.p1.1.2" style="color:#333333;">we observe a positive correlation between the number of reasoning steps and the model’s task completion rate. This suggests that the model indeed benefits from more tool invocations and longer reasoning.</span></p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">However, as the number of reasoning steps increases, the completion rate gradually converges, making further significant improvements challenging. As shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.F4" title="Figure 4 ‣ 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">4</span></a> (<span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.1">left</span>), for instance, increasing reasoning steps from 10 to 20 resulted in substantial performance gains (<span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.2">+54.1</span>% and <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.3">+48.4</span>%) across different LVLM architectures (GPT-4o and Claude-3.5-sonnet). However, when reasoning steps were increased from 20 to 40, the performance growth slowed dramatically, dropping to +<span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.4">6.5</span>% and +<span class="ltx_text ltx_font_italic" id="S6.SS1.p2.1.5">2.1</span>%, respectively. This phenomenon aligns with expectations, as merely increasing the number of tool invocations does not enable the model to better solve the most challenging samples. This underscores the necessity of techniques like rollout search within the broader context of test scaling.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Could Larger Tree Span Enhances <span class="ltx_text ltx_font_italic" id="S6.SS2.1.1">VisuoThink</span>’s Performance?</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">Predictive rollouts enhance the model’s reasoning capabilities, which can be viewed as a tangible outcome of successfully expanding the model’s reasoning search space. A natural question arises: Can we further improve the model’s reasoning performance on benchmarks simply by increasing the number of candidate child nodes at each selection step, i.e., expanding the <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.1">tree width</span>, thereby enhancing model’s reasoning capability? To investigate this, we conducted comparative experiments on geometry tasks using GPT-4o and Claude-3.5-sonnet, keeping the depth of the reasoning tree constant while varying the number of candidate child nodes.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">As presented in figure <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S5.F4" title="Figure 4 ‣ 5 Spatial Reasoning with VisuoThink ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">4</span></a> (<span class="ltx_text ltx_font_italic" id="S6.SS2.p2.1.1">right</span>), we observed an inverted U-shaped trend in overall performance as the number of candidate tree nodes increased across different model architectures. Notably, when the number of candidate child nodes equals 1, the model follows a single reasoning path, effectively bypassing predictive rollout search. Contrary to expectations, the performance trend initially rises and then declines. This counterintuitive result can be attributed to the inherent errors in the model’s evaluation of child nodes. <span class="ltx_text ltx_font_bold" id="S6.SS2.p2.1.2" style="color:#333333;">Simply and aggressively increasing the tree width leads to confusion in selecting child nodes, which in turn reduces overall reasoning efficiency.</span> Thus, an interesting conclusion emerges: we cannot expect to continuously improve model performance by merely increasing the number of child nodes in rollout search.</p>
</div>
<figure class="ltx_figure ltx_align_center" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="637" id="S6.F5.1.g1" src="x6.png" width="829"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>
The performance gain (<span class="ltx_text ltx_font_italic" id="S6.F5.5.1">+%</span>) on tasks through predictive rollout search. The performance gain is calculated via the performance gap between <span class="ltx_text ltx_font_italic" id="S6.F5.6.2">VisuoThink (w/o rollout search)</span> and <span class="ltx_text ltx_font_italic" id="S6.F5.7.3">VisuoThink</span>.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Strong v.s. Weak Supervision in Predictive Rollout Search</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">An intriguing observation is that the strength of guidance provided by predictive rollout results varies between geometry and spatial reasoning tasks. In geometry tasks, the model only receives the final numerical results of the problem, whereas in spatial reasoning tasks, the model has access to visual states of stronger supervision (e.g., <span class="ltx_text ltx_font_italic" id="S6.SS3.p1.1.1">the agent’s final position, the position of the destination, etc.</span>). In other word, predictive rollouts in geometry tasks offer weaker supervision, while those in spatial reasoning tasks provide stronger supervision.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">This observation aligns with the findings of the Deepseek R1 report, which highlights that outcome-based supervision in RL can significantly enhance Deepseek-R1-Zero’s reasoning capabilities <cite class="ltx_cite ltx_citemacro_cite">DeepSeek-AI (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib4" title="">2025</a>)</cite>. <span class="ltx_text ltx_font_bold" id="S6.SS3.p2.1.1" style="color:#333333;">The effectiveness of such supervision stems from its strong supervisory signal, and predictive rollouts with strong supervision are more effective in improving model reasoning performance.</span> This is further supported by our experimental results, as illustrated in figure <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6.F5" title="Figure 5 ‣ 6.2 Could Larger Tree Span Enhances VisuoThink’s Performance? ‣ 6 Discussion ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">5</span></a>, where predictive rollouts demonstrated more substantial performance gains in spatial reasoning tasks compared to geometry tasks, across both open-source and closed-source models. The detailed performance gain results are presented in appendix <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A1" title="Appendix A Performance Gain of VisuoThink Through Predictive Rollout Search ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We present <span class="ltx_text ltx_font_bold ltx_font_italic" id="S7.p1.1.1">VisuoThink</span>, a multimodal tree search framework enhancing LVLM reasoning through dynamic visual-textual interleaving and predictive rollout search.
Our approach demonstrates significant improvements across geometry and spatial reasoning tasks without requiring model fine-tuning.
Empirical results show substantial performance gains on geometry and spatial reasoning benchmarks.
Our analysis reveals key insights about tool interaction benefits, search space optimization, and supervision strength in multimodal reasoning.
These findings open new possibilities for advancing LVLM capabilities in complex reasoning tasks.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Despite its strong performance, <span class="ltx_text ltx_font_italic" id="Sx1.p1.1.1">VisuoThink</span> has several limitations. First, the predictive rollout search process introduces significant computational overhead, making it potentially impractical for real-time applications. Second, our approach particularly relies on tool interactions for stronger capability, which may require more effort in some specific deployment environments. Third, the framework’s effectiveness is constrained by the quality of the base VLM’s reasoning capabilities - while it enhances performance, it cannot overcome fundamental model limitations. Finally, our evaluation focuses primarily on geometric and spatial reasoning tasks.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethics and Reproducibility Statements</h2>
<section class="ltx_paragraph" id="Sx2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Ethics</h4>
<div class="ltx_para" id="Sx2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="Sx2.SS0.SSS0.Px1.p1.1">We take ethical considerations very seriously and strictly adhere to the ACL Ethics Policy. This paper proposes a test-time slow-thinking framework to improve the multimodal reasoning ability of current LVLMs. All evaluation datasets used in this paper will be publicly available or have been widely adopted by researchers. Thus, we believe that this research will not pose ethical issues.</p>
</div>
</section>
<section class="ltx_paragraph" id="Sx2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Reproducibility</h4>
<div class="ltx_para" id="Sx2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="Sx2.SS0.SSS0.Px2.p1.1">In this paper, we discuss the detailed experimental setup, such as hyper-parameters, implementation of algorithm, and statistic descriptions. More importantly, <span class="ltx_text ltx_font_bold ltx_font_italic" id="Sx2.SS0.SSS0.Px2.p1.1.1">we will open source our code and data in the future</span> to help reproduce the experimental results of this paper.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et al. (2024)</span>
<span class="ltx_bibblock">
Afra Amini, Tim Vieira, and Ryan Cotterell. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:271051300" title="">Variational best-of-n alignment</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">ArXiv</em>, abs/2407.06057.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Guoxin Chen, Minpeng Liao, Chengxi Li, and Kai Fan. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:269605484" title="">Alphamath almost zero: process supervision without process</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ArXiv</em>, abs/2405.03553.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherian et al. (2024)</span>
<span class="ltx_bibblock">
Anoop Cherian, Kuan-Chuan Peng, Suhas Lohit, Joanna Matthiesen, Kevin Smith, and Joshua B Tenenbaum. 2024.

</span>
<span class="ltx_bibblock">Evaluating large vision-and-language models on children’s mathematical olympiads.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2406.15736</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeepSeek-AI (2025)</span>
<span class="ltx_bibblock">
DeepSeek-AI. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2501.12948" title="">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Preprint</em>, arXiv:2501.12948.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2025)</span>
<span class="ltx_bibblock">
Yifan Du, Zikang Liu, Yifan Li, Wayne Xin Zhao, Yuqi Huo, Bingning Wang, Weipeng Chen, Zheng Liu, Zhongyuan Wang, and Jiahui Wen. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:275323902" title="">Virgo: A preliminary exploration on reproducing o1-like mllm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2023)</span>
<span class="ltx_bibblock">
Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, Weinan Zhang, and Jun Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:263310590" title="">Alphazero-like tree-search can guide large language model decoding and training</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">ArXiv</em>, abs/2309.17179.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Timin Gao, Peixian Chen, Mengdan Zhang, Chaoyou Fu, Yunhang Shen, Yan Zhang, Shengchuan Zhang, Xiawu Zheng, Xing Sun, Liujuan Cao, and Rongrong Ji. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:269362481" title="">Cantor: Inspiring multimodal chain-of-thought of mllm</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ArXiv</em>, abs/2404.16033.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gui et al. (2024)</span>
<span class="ltx_bibblock">
Lin Gui, Cristina Garbacea, and Victor Veitch. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:270213066" title="">Bonbon alignment for large language models and the sweetness of best-of-n sampling</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ArXiv</em>, abs/2406.00832.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2024)</span>
<span class="ltx_bibblock">
Yushi Hu, Weijia Shi, Xingyu Fu, Dan Roth, Mari Ostendorf, Luke S. Zettlemoyer, Noah A. Smith, and Ranjay Krishna. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:270440440" title="">Visual sketchpad: Sketching as a visual chain of thought for multimodal language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ArXiv</em>, abs/2406.09403.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahneman (2011)</span>
<span class="ltx_bibblock">
Daniel Kahneman. 2011.

</span>
<span class="ltx_bibblock">Thinking, fast and slow.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Farrar, Straus and Giroux</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kazemi et al. (2023)</span>
<span class="ltx_bibblock">
Mehran Kazemi, Hamidreza Alvari, Ankit Anand, Jialin Wu, Xi Chen, and Radu Soricut. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.12241" title="">Geomverse: A systematic evaluation of large models for geometric reasoning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2312.12241.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2024)</span>
<span class="ltx_bibblock">
Xuanyu Lei, Zonghan Yang, Xinrui Chen, Peng Li, and Yang Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:267750933" title="">Scaffolding coordinates to promote vision-language coordination in large multi-modal models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">International Conference on Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2025)</span>
<span class="ltx_bibblock">
Chengzu Li, Wenshan Wu, Huanyu Zhang, Yan Xia, Shaoguang Mao, Li Dong, Ivan Vuli’c, and Furu Wei. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:275471612" title="">Imagine while reasoning in space: Multimodal visualization-of-thought</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Jiacheng Liu, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, and Asli Celikyilmaz. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:262824527" title="">Don’t throw away your value model! generating more preferable text with value-guided monte-carlo tree search decoding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2021)</span>
<span class="ltx_bibblock">
Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-Chun Zhu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2105.04165" title="">Inter-gps: Interpretable geometry problem solving with formal language and symbolic reasoning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:2105.04165.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et al. (2023)</span>
<span class="ltx_bibblock">
Chancharik Mitra, Brandon Huang, Trevor Darrell, and Roei Herzig. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:265498786" title="">Compositional chain-of-thought prompting for large multimodal models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 14420–14431.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mondal et al. (2024)</span>
<span class="ltx_bibblock">
Debjyoti Mondal, Suraj Modi, Subhadarshi Panda, Rituraj Singh, and Godawari Sudhakar Rao. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:267095090" title="">Kam-cot: Knowledge augmented multimodal chain-of-thoughts reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">AAAI Conference on Artificial Intelligence</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024a)</span>
<span class="ltx_bibblock">
OpenAI. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2410.21276" title="">Gpt-4o system card</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arXiv:2410.21276.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024b)</span>
<span class="ltx_bibblock">
OpenAI. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openai.com/index/learning-to-reason-with-llms/" title="">Learning to reason with llms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiao et al. (2024)</span>
<span class="ltx_bibblock">
Runqi Qiao, Qiuna Tan, Guanting Dong, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, and 1 others. 2024.

</span>
<span class="ltx_bibblock">We-math: Does your large multimodal model achieve human-like mathematical reasoning?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2407.01284</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramakrishnan et al. (2024)</span>
<span class="ltx_bibblock">
Santhosh Kumar Ramakrishnan, Erik Wijmans, Philipp Kraehenbuehl, and Vladlen Koltun. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2410.06468" title="">Does spatial cognition emerge in frontier models?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:2410.06468.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et al. (2023)</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.11366" title="">Reflexion: Language agents with verbal reinforcement learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:2303.11366.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snell et al. (2024)</span>
<span class="ltx_bibblock">
Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:271719990" title="">Scaling llm test-time compute optimally can be more effective than scaling model parameters</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ArXiv</em>, abs/2408.03314.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2024)</span>
<span class="ltx_bibblock">
Hanshi Sun, Momin Haider, Ruiqi Zhang, Huitao Yang, Jiahao Qiu, Ming Yin, Mengdi Wang, Peter Bartlett, and Andrea Zanette. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:273654642" title="">Fast best-of-n decoding via speculative rejection</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">ArXiv</em>, abs/2410.20290.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024)</span>
<span class="ltx_bibblock">
Gemini Team. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.05530" title="">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2403.05530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thawakar et al. (2025)</span>
<span class="ltx_bibblock">
Omkar Thawakar, Dinura Dissanayake, Ketan More, Ritesh Thawkar, Ahmed Heakl, Noor Ahsan, Yuhao Li, Mohammed Zumri, Jean Lahoud, Rao Muhammad Anwer, Hisham Cholakkal, Ivan Laptev, Mubarak Shah, Fahad Shahbaz Khan, and Salman H. Khan. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:275458766" title="">Llamav-o1: Rethinking step-by-step visual reasoning in llms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Wenshan Wu, Shaoguang Mao, Yadong Zhang, Yan Xia, Li Dong, Lei Cui, and Furu Wei. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:268889526" title="">Mind’s eye of llms: Visualization-of-thought elicits spatial reasoning in large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et al. (2024)</span>
<span class="ltx_bibblock">
Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Runhui Huang, Haoxiang Fan, Hanhui Li, Weiran Huang, Yihan Zeng, Jianhua Han, Lanqing Hong, Hang Xu, and Xiaodan Liang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2411.11930" title="">Atomthink: A slow thinking framework for multimodal mathematical reasoning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Preprint</em>, arXiv:2411.11930.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2023)</span>
<span class="ltx_bibblock">
Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, MingSung Kan, Junxian He, and Qizhe Xie. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:258426922" title="">Self-evaluation guided beam search for reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Neural Information Processing Systems</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024)</span>
<span class="ltx_bibblock">
Guowei Xu, Peng Jin, Hao Li, Yibing Song, Lichao Sun, and Li Yuan. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:274116688" title="">Llava-cot: Let vision language models reason step-by-step</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">ArXiv</em>, abs/2411.10440.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:257637012" title="">Mm-react: Prompting chatgpt for multimodal reasoning and action</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">ArXiv</em>, abs/2303.11381.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2024)</span>
<span class="ltx_bibblock">
Huanjin Yao, Jiaxing Huang, Wenhao Wu, Jingyi Zhang, Yibo Wang, Shunyu Liu, Yingjie Wang, Yuxin Song, Haocheng Feng, Li Shen, and Dacheng Tao. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:274992111" title="">Mulberry: Empowering mllm with o1-like reasoning and reflection via collective monte carlo tree search</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">ArXiv</em>, abs/2412.18319.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023)</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.03629" title="">React: Synergizing reasoning and acting in language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Preprint</em>, arXiv:2210.03629.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Fei Yu, Anningzhe Gao, and Benyou Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:265221057" title="">Ovm, outcome-supervised value models for planning in mathematical reasoning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">NAACL-HLT</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2024)</span>
<span class="ltx_bibblock">
Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Bo Wang, Shimin Li, Yunhua Zhou, Qipeng Guo, Xuanjing Huang, and Xipeng Qiu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2412.14135" title="">Scaling of search and learning: A roadmap to reproduce o1 from reinforcement learning perspective</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Preprint</em>, arXiv:2412.14135.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alexander J. Smola. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:256504063" title="">Multimodal chain-of-thought reasoning in language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Trans. Mach. Learn. Res.</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, and Jiwen Lu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.02153" title="">Unleashing text-to-image diffusion models for visual perception</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Preprint</em>, arXiv:2303.02153.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Qiji Zhou, Ruochen Zhou, Zike Hu, Panzhong Lu, Siyang Gao, and Yue Zhang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:269982092" title="">Image-of-thought prompting for visual reasoning refinement in multimodal large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">ArXiv</em>, abs/2405.13872.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Performance Gain of <span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.1.1">VisuoThink</span> Through Predictive Rollout Search</h2>
<figure class="ltx_table" id="A1.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T3.6" style="width:346.9pt;height:100.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-45.6pt,13.1pt) scale(0.791725350040331,0.791725350040331) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T3.6.6">
<tr class="ltx_tr" id="A1.T3.6.6.7">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.6.6.7.1"><span class="ltx_text ltx_font_bold" id="A1.T3.6.6.7.1.1">Supervision Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.6.6.7.2"><span class="ltx_text ltx_font_bold" id="A1.T3.6.6.7.2.1">Performance Gain</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.3"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.3.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.4"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.4.1">Qwen2-VL-72B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T3.6.6.7.5"><span class="ltx_text ltx_font_italic" id="A1.T3.6.6.7.5.1">Claude-3.5-Sonnet</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.1.1.1.2" rowspan="3"><span class="ltx_text" id="A1.T3.1.1.1.2.1">Strong Supervision</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.1.1.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.1.m1.1.1" mathvariant="normal" xref="A1.T3.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">roman_Δ</annotation></semantics></math> Visual Navigation (%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.3">+16.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.4">+18.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.5">+15.5</td>
</tr>
<tr class="ltx_tr" id="A1.T3.2.2.2">
<td class="ltx_td ltx_align_left" id="A1.T3.2.2.2.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.2.2.2.1.m1.1"><semantics id="A1.T3.2.2.2.1.m1.1a"><mi id="A1.T3.2.2.2.1.m1.1.1" mathvariant="normal" xref="A1.T3.2.2.2.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.1.m1.1b"><ci id="A1.T3.2.2.2.1.m1.1.1.cmml" xref="A1.T3.2.2.2.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.1.m1.1d">roman_Δ</annotation></semantics></math> Visual Tiling (%)</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.2">+31.9</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.3">+11.0</td>
<td class="ltx_td ltx_align_center" id="A1.T3.2.2.2.4">+3.3</td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.3">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.3.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.1.1" style="background-color:#E6E6E6;"><math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.3.3.3.1.1.m1.1" style="background-color:#E6E6E6;"><semantics id="A1.T3.3.3.3.1.1.m1.1a"><mi id="A1.T3.3.3.3.1.1.m1.1.1" mathbackground="#E6E6E6" mathvariant="normal" xref="A1.T3.3.3.3.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.1.1.m1.1b"><ci id="A1.T3.3.3.3.1.1.m1.1.1.cmml" xref="A1.T3.3.3.3.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.1.1.m1.1d">roman_Δ</annotation></semantics></math> Average (%)</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.2.1" style="background-color:#E6E6E6;">+24.3</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.3.1" style="background-color:#E6E6E6;">+15.0</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.3.3.3.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.3.3.3.4.1" style="background-color:#E6E6E6;">+9.4</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A1.T3.4.4.4.2" rowspan="3"><span class="ltx_text" id="A1.T3.4.4.4.2.1">Weak Supervision</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.4.4.4.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.4.4.4.1.m1.1"><semantics id="A1.T3.4.4.4.1.m1.1a"><mi id="A1.T3.4.4.4.1.m1.1.1" mathvariant="normal" xref="A1.T3.4.4.4.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.4.1.m1.1b"><ci id="A1.T3.4.4.4.1.m1.1.1.cmml" xref="A1.T3.4.4.4.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.4.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.4.4.4.1.m1.1d">roman_Δ</annotation></semantics></math> Geometry3K (%)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.3">+4.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.4">+6.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.5">+1.1</td>
</tr>
<tr class="ltx_tr" id="A1.T3.5.5.5">
<td class="ltx_td ltx_align_left" id="A1.T3.5.5.5.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.5.5.5.1.m1.1"><semantics id="A1.T3.5.5.5.1.m1.1a"><mi id="A1.T3.5.5.5.1.m1.1.1" mathvariant="normal" xref="A1.T3.5.5.5.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.5.1.m1.1b"><ci id="A1.T3.5.5.5.1.m1.1.1.cmml" xref="A1.T3.5.5.5.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.5.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.5.5.5.1.m1.1d">roman_Δ</annotation></semantics></math> Geomverse-109 (%)</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.2">+6.2</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.3">+4.2</td>
<td class="ltx_td ltx_align_center" id="A1.T3.5.5.5.4">+6.3</td>
</tr>
<tr class="ltx_tr" id="A1.T3.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_b" id="A1.T3.6.6.6.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.1.1" style="background-color:#E6E6E6;"><math alttext="\Delta" class="ltx_Math" display="inline" id="A1.T3.6.6.6.1.1.m1.1" style="background-color:#E6E6E6;"><semantics id="A1.T3.6.6.6.1.1.m1.1a"><mi id="A1.T3.6.6.6.1.1.m1.1.1" mathbackground="#E6E6E6" mathvariant="normal" xref="A1.T3.6.6.6.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.6.1.1.m1.1b"><ci id="A1.T3.6.6.6.1.1.m1.1.1.cmml" xref="A1.T3.6.6.6.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.6.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="A1.T3.6.6.6.1.1.m1.1d">roman_Δ</annotation></semantics></math> Average (%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.2.1" style="background-color:#E6E6E6;">+5.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.3.1" style="background-color:#E6E6E6;">+5.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T3.6.6.6.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.6.6.6.4.1" style="background-color:#E6E6E6;">+3.7</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Detailed performance gain of <span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.T3.9.1">VisuoThink</span> through predictive rollout search on benchmarks from Geometry and Spatial Reasoning over variable <span class="ltx_text ltx_font_italic" id="A1.T3.10.2">LVLM</span> models.</figcaption>
</figure>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">This appendix quantifies the performance improvements achieved by integrating predictive rollout search into the <span class="ltx_text ltx_font_italic" id="A1.p1.1.1">VisuoThink</span> framework across geometry and spatial reasoning tasks. The performance gain through predictive rollout search is derived by subtracting the performance of <span class="ltx_text ltx_font_italic" id="A1.p1.1.2">VisuoThink (w/o rollout search)</span> from those of the <span class="ltx_text ltx_font_italic" id="A1.p1.1.3">VisuoThink</span> on models.</p>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A1.T3" title="Table 3 ‣ Appendix A Performance Gain of VisuoThink Through Predictive Rollout Search ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">3</span></a>, tasks with strong supervision (e.g., <span class="ltx_text ltx_font_bold" id="A1.p2.1.1">Visual Navigation</span> and <span class="ltx_text ltx_font_bold" id="A1.p2.1.2">Visual Tiling</span>) exhibit significantly higher gains compared to weak supervision tasks (e.g., <span class="ltx_text ltx_font_italic" id="A1.p2.1.3">Geometry3K</span> and <span class="ltx_text ltx_font_italic" id="A1.p2.1.4">Geomverse-109</span>). For instance, under strong supervision, Claude-3.5-Sonnet achieves a +<span class="ltx_text ltx_font_italic" id="A1.p2.1.5">25.1</span>% improvement in Visual Navigation, while GPT-4o attains +<span class="ltx_text ltx_font_italic" id="A1.p2.1.6">16.6</span>% in Visual Tiling. In contrast, weak supervision tasks like <span class="ltx_text ltx_font_bold" id="A1.p2.1.7">Geomverse-109</span> only show modest gains (e.g., +<span class="ltx_text ltx_font_italic" id="A1.p2.1.8">5.4</span>% for GPT-4o).</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>OKSpatial Reasoning Task Setting</h2>
<figure class="ltx_table" id="A2.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T4.1" style="width:346.9pt;height:44.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-37.4pt,4.8pt) scale(0.822788272604629,0.822788272604629) ;">
<table class="ltx_tabular ltx_align_middle" id="A2.T4.1.1">
<tr class="ltx_tr" id="A2.T4.1.1.1">
<td class="ltx_td ltx_border_tt" id="A2.T4.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T4.1.1.1.2"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T4.1.1.1.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.3">Direction</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.4">Steps</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.1.5.1">Target</span></td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T4.1.1.2.1" rowspan="2"><span class="ltx_text" id="A2.T4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.2.1.1.1">Visual Navigation</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T4.1.1.2.2"><span class="ltx_text ltx_font_italic" id="A2.T4.1.1.2.2.1">VoT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.4">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.1.2.5">Navigate from the starting position</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="A2.T4.1.1.3.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T4.1.1.3.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.2.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.3.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T4.1.1.3.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T4.1.1.3.4.1" style="background-color:#E6E6E6;">to the destination.</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold" id="A2.T4.5.1">Visual Navigation</span> task setting differences between <span class="ltx_text ltx_font_italic" id="A2.T4.6.2">VoT</span> and <span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T4.7.3">VisuoThink</span>. </figcaption>
</figure>
<figure class="ltx_table" id="A2.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T5.1" style="width:433.6pt;height:85.4pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-87.3pt,17.1pt) scale(0.712896486726305,0.712896486726305) ;">
<table class="ltx_tabular ltx_align_middle" id="A2.T5.1.1">
<tr class="ltx_tr" id="A2.T5.1.1.1">
<td class="ltx_td ltx_border_tt" id="A2.T5.1.1.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T5.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T5.1.1.1.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A2.T5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.3.1">Action</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T5.1.1.1.4" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.4.1">Target</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.2">
<td class="ltx_td" id="A2.T5.1.1.2.1"></td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.2">Polyomino Type</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.3">Variant Type</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.4">Block Positions</td>
<td class="ltx_td ltx_align_center" id="A2.T5.1.1.2.5">Action Type</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T5.1.1.3.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.3.1.1">Visual Tiling</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.3.2"><span class="ltx_text ltx_font_italic" id="A2.T5.1.1.3.2.1">VoT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.4">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.5">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.6">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.1.1.3.7">
<span class="ltx_text" id="A2.T5.1.1.3.7.1"></span> <span class="ltx_text" id="A2.T5.1.1.3.7.2">
<span class="ltx_tabular ltx_align_middle" id="A2.T5.1.1.3.7.2.1">
<span class="ltx_tr" id="A2.T5.1.1.3.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.3.7.2.1.1.1">To identify the correct variant</span></span>
<span class="ltx_tr" id="A2.T5.1.1.3.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.3.7.2.1.2.1">for a polyomino in one action.</span></span>
</span></span><span class="ltx_text" id="A2.T5.1.1.3.7.3"></span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_b" id="A2.T5.1.1.4.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.1.1" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T5.1.1.4.1.1.1" style="background-color:#E6E6E6;">VisuoThink</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.2.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.3.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.4.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="A2.T5.1.1.4.5.1" style="background-color:#E6E6E6;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T5.1.1.4.6" style="background-color:#E6E6E6;">
<span class="ltx_text" id="A2.T5.1.1.4.6.1"></span><span class="ltx_text" id="A2.T5.1.1.4.6.2" style="background-color:#E6E6E6;"> <span class="ltx_text" id="A2.T5.1.1.4.6.2.1">
<span class="ltx_tabular ltx_align_middle" id="A2.T5.1.1.4.6.2.1.1">
<span class="ltx_tr" id="A2.T5.1.1.4.6.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.4.6.2.1.1.1.1">To fill the rectangle with feasible</span></span>
<span class="ltx_tr" id="A2.T5.1.1.4.6.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A2.T5.1.1.4.6.2.1.1.2.1">polyomino variants.</span></span>
</span></span><span class="ltx_text" id="A2.T5.1.1.4.6.2.2"></span></span>
</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span><span class="ltx_text ltx_font_bold" id="A2.T5.5.1">Visual Tiling</span> task setting differences between <span class="ltx_text ltx_font_italic" id="A2.T5.6.2">VoT</span> and <span class="ltx_text ltx_font_bold ltx_font_italic" id="A2.T5.7.3">VisuoThink</span>.</figcaption>
</figure>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Our formulation extends beyond <span class="ltx_text ltx_font_italic" id="A2.p1.1.1">VoT</span>’s basic requirements by mandating LVLMs to generate comprehensive operational specifications - for instance, requiring explicit output of both movement directions and precise step counts at each decision node. This advancement creates more realistic and functionally grounded spatial reasoning evaluations (e.g., <span class="ltx_text ltx_font_italic" id="A2.p1.1.2">robotic navigation emulation in real world</span>).</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">This appendix details the task formulation differences between <span class="ltx_text ltx_font_italic" id="A2.p2.1.1">VisuoThink</span> and baseline methods (Table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A2.T4" title="Table 4 ‣ Appendix B OKSpatial Reasoning Task Setting ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A2.T5" title="Table 5 ‣ Appendix B OKSpatial Reasoning Task Setting ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">5</span></a>). For <span class="ltx_text ltx_font_bold" id="A2.p2.1.2">Visual Navigation</span>, <span class="ltx_text ltx_font_italic" id="A2.p2.1.3">VisuoThink</span> requires fine-grained, executable and explicit specification of both direction and step count in action sequences, whereas VoT focuses solely on direction navigation. This formulation mirrors real-world robotic navigation, where precise movement planning is critical. Similarly, in <span class="ltx_text ltx_font_bold" id="A2.p2.1.4">Visual Tiling</span>, <span class="ltx_text ltx_font_italic" id="A2.p2.1.5">VisuoThink</span> mandates detailed actions, including polyomino variant types, block positions, and action types (e.g., "fit" or "remove"), while <span class="ltx_text ltx_font_italic" id="A2.p2.1.6">VoT</span> simplifies the task by omitting variant specifications.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Task Formulation of Spatial Reasoning Tasks</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Building upon <span class="ltx_text ltx_font_italic" id="A3.p1.1.1">VoT</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib27" title="">2024</a>)</cite> framework, our challenging benchmarks comprise:</p>
</div>
<div class="ltx_para" id="A3.p2">
<ul class="ltx_itemize" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.8"><span class="ltx_text ltx_font_bold" id="A3.I1.i1.p1.8.1">Visual Navigation</span> evaluates LVLMs in a simulated 2D grid environment, where agents must navigate from initial position <math alttext="\textbf{s}_{0}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.1.m1.1"><semantics id="A3.I1.i1.p1.1.m1.1a"><msub id="A3.I1.i1.p1.1.m1.1.1" xref="A3.I1.i1.p1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.1.m1.1.1.2" xref="A3.I1.i1.p1.1.m1.1.1.2a.cmml">s</mtext><mn id="A3.I1.i1.p1.1.m1.1.1.3" xref="A3.I1.i1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.1.m1.1b"><apply id="A3.I1.i1.p1.1.m1.1.1.cmml" xref="A3.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.1.m1.1.1.1.cmml" xref="A3.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.1.m1.1.1.2a.cmml" xref="A3.I1.i1.p1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.1.m1.1.1.2.cmml" xref="A3.I1.i1.p1.1.m1.1.1.2">s</mtext></ci><cn id="A3.I1.i1.p1.1.m1.1.1.3.cmml" type="integer" xref="A3.I1.i1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.1.m1.1c">\textbf{s}_{0}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.1.m1.1d">s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> to destination <math alttext="\textbf{s}_{k}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.2.m2.1"><semantics id="A3.I1.i1.p1.2.m2.1a"><msub id="A3.I1.i1.p1.2.m2.1.1" xref="A3.I1.i1.p1.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.2.m2.1.1.2" xref="A3.I1.i1.p1.2.m2.1.1.2a.cmml">s</mtext><mi id="A3.I1.i1.p1.2.m2.1.1.3" xref="A3.I1.i1.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.2.m2.1b"><apply id="A3.I1.i1.p1.2.m2.1.1.cmml" xref="A3.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.2.m2.1.1.1.cmml" xref="A3.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.2.m2.1.1.2a.cmml" xref="A3.I1.i1.p1.2.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.2.m2.1.1.2.cmml" xref="A3.I1.i1.p1.2.m2.1.1.2">s</mtext></ci><ci id="A3.I1.i1.p1.2.m2.1.1.3.cmml" xref="A3.I1.i1.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.2.m2.1c">\textbf{s}_{k}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.2.m2.1d">s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> through obstacle-laden paths. The formal problem is defined by grid map <math alttext="\mathbf{M}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.3.m3.1"><semantics id="A3.I1.i1.p1.3.m3.1a"><mi id="A3.I1.i1.p1.3.m3.1.1" xref="A3.I1.i1.p1.3.m3.1.1.cmml">𝐌</mi><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.3.m3.1b"><ci id="A3.I1.i1.p1.3.m3.1.1.cmml" xref="A3.I1.i1.p1.3.m3.1.1">𝐌</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.3.m3.1c">\mathbf{M}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.3.m3.1d">bold_M</annotation></semantics></math> containing <math alttext="k" class="ltx_Math" display="inline" id="A3.I1.i1.p1.4.m4.1"><semantics id="A3.I1.i1.p1.4.m4.1a"><mi id="A3.I1.i1.p1.4.m4.1.1" xref="A3.I1.i1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.4.m4.1b"><ci id="A3.I1.i1.p1.4.m4.1.1.cmml" xref="A3.I1.i1.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.4.m4.1d">italic_k</annotation></semantics></math> interconnected edges <math alttext="\mathbf{E}=\{\textbf{e}(\textbf{s}_{0},\textbf{s}_{1}),\textbf{e}(\textbf{s}_{%
1},\textbf{s}_{2}),\dots,\textbf{e}(\textbf{s}_{k-1},\textbf{s}_{k})\}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.5.m5.4"><semantics id="A3.I1.i1.p1.5.m5.4a"><mrow id="A3.I1.i1.p1.5.m5.4.4" xref="A3.I1.i1.p1.5.m5.4.4.cmml"><mi id="A3.I1.i1.p1.5.m5.4.4.5" xref="A3.I1.i1.p1.5.m5.4.4.5.cmml">𝐄</mi><mo id="A3.I1.i1.p1.5.m5.4.4.4" xref="A3.I1.i1.p1.5.m5.4.4.4.cmml">=</mo><mrow id="A3.I1.i1.p1.5.m5.4.4.3.3" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml"><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.4" stretchy="false" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml">{</mo><mrow id="A3.I1.i1.p1.5.m5.2.2.1.1.1" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.4" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.4a.cmml">e</mtext><mo id="A3.I1.i1.p1.5.m5.2.2.1.1.1.3" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.3.cmml">⁢</mo><mrow id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.3.cmml"><mo id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.3" stretchy="false" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.3.cmml">(</mo><msub id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2a.cmml">s</mtext><mn id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.3" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.4" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.3.cmml">,</mo><msub id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2a.cmml">s</mtext><mn id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.3" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.3.cmml">1</mn></msub><mo id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.5" stretchy="false" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.5" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml">,</mo><mrow id="A3.I1.i1.p1.5.m5.3.3.2.2.2" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.4" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.4a.cmml">e</mtext><mo id="A3.I1.i1.p1.5.m5.3.3.2.2.2.3" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.3.cmml">⁢</mo><mrow id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.3.cmml"><mo id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.3" stretchy="false" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.3.cmml">(</mo><msub id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2a.cmml">s</mtext><mn id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.3" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.4" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.3.cmml">,</mo><msub id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2a.cmml">s</mtext><mn id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.3" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.5" stretchy="false" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.6" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml">,</mo><mi id="A3.I1.i1.p1.5.m5.1.1" mathvariant="normal" xref="A3.I1.i1.p1.5.m5.1.1.cmml">…</mi><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.7" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml">,</mo><mrow id="A3.I1.i1.p1.5.m5.4.4.3.3.3" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.4" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.4a.cmml">e</mtext><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.3.3" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.3.cmml">⁢</mo><mrow id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.3.cmml"><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.3" stretchy="false" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.3.cmml">(</mo><msub id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2a.cmml">s</mtext><mrow id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.cmml"><mi id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.2" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.2.cmml">k</mi><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.1" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.1.cmml">−</mo><mn id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.3" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.4" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.3.cmml">,</mo><msub id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2a.cmml">s</mtext><mi id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.3" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.3.cmml">k</mi></msub><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.5" stretchy="false" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.3.cmml">)</mo></mrow></mrow><mo id="A3.I1.i1.p1.5.m5.4.4.3.3.8" stretchy="false" xref="A3.I1.i1.p1.5.m5.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.5.m5.4b"><apply id="A3.I1.i1.p1.5.m5.4.4.cmml" xref="A3.I1.i1.p1.5.m5.4.4"><eq id="A3.I1.i1.p1.5.m5.4.4.4.cmml" xref="A3.I1.i1.p1.5.m5.4.4.4"></eq><ci id="A3.I1.i1.p1.5.m5.4.4.5.cmml" xref="A3.I1.i1.p1.5.m5.4.4.5">𝐄</ci><set id="A3.I1.i1.p1.5.m5.4.4.3.4.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3"><apply id="A3.I1.i1.p1.5.m5.2.2.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1"><times id="A3.I1.i1.p1.5.m5.2.2.1.1.1.3.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.3"></times><ci id="A3.I1.i1.p1.5.m5.2.2.1.1.1.4a.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.4"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.4.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.4">e</mtext></ci><interval closure="open" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.3.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2"><apply id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2a.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.2">s</mtext></ci><cn id="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.3.cmml" type="integer" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.1.1.1.3">0</cn></apply><apply id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.1.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2a.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.2">s</mtext></ci><cn id="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.3.cmml" type="integer" xref="A3.I1.i1.p1.5.m5.2.2.1.1.1.2.2.2.3">1</cn></apply></interval></apply><apply id="A3.I1.i1.p1.5.m5.3.3.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2"><times id="A3.I1.i1.p1.5.m5.3.3.2.2.2.3.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.3"></times><ci id="A3.I1.i1.p1.5.m5.3.3.2.2.2.4a.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.4"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.4.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.4">e</mtext></ci><interval closure="open" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.3.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2"><apply id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2a.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.2">s</mtext></ci><cn id="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.3.cmml" type="integer" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.1.1.1.3">1</cn></apply><apply id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.1.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2a.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.2">s</mtext></ci><cn id="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.3.cmml" type="integer" xref="A3.I1.i1.p1.5.m5.3.3.2.2.2.2.2.2.3">2</cn></apply></interval></apply><ci id="A3.I1.i1.p1.5.m5.1.1.cmml" xref="A3.I1.i1.p1.5.m5.1.1">…</ci><apply id="A3.I1.i1.p1.5.m5.4.4.3.3.3.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3"><times id="A3.I1.i1.p1.5.m5.4.4.3.3.3.3.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.3"></times><ci id="A3.I1.i1.p1.5.m5.4.4.3.3.3.4a.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.4"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.4.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.4">e</mtext></ci><interval closure="open" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.3.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2"><apply id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.1.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2a.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.2">s</mtext></ci><apply id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3"><minus id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.1.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.1"></minus><ci id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.2.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.2">𝑘</ci><cn id="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.3.cmml" type="integer" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.1.1.1.3.3">1</cn></apply></apply><apply id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.1.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2a.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.2">s</mtext></ci><ci id="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.3.cmml" xref="A3.I1.i1.p1.5.m5.4.4.3.3.3.2.2.2.3">𝑘</ci></apply></interval></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.5.m5.4c">\mathbf{E}=\{\textbf{e}(\textbf{s}_{0},\textbf{s}_{1}),\textbf{e}(\textbf{s}_{%
1},\textbf{s}_{2}),\dots,\textbf{e}(\textbf{s}_{k-1},\textbf{s}_{k})\}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.5.m5.4d">bold_E = { e ( s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , e ( s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , … , e ( s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT , s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) }</annotation></semantics></math>. The LVLM should generate a sequence of executable actions in <span class="ltx_text ltx_font_typewriter ltx_font_italic" id="A3.I1.i1.p1.8.2">json</span> format <math alttext="\mathbf{A}=\{(\textbf{d}_{0},\textbf{l}_{0}),(\textbf{d}_{1},\textbf{l}_{1}),%
\dots,(\textbf{d}_{|\mathbf{A}|-1},\textbf{l}_{|\mathbf{A}|-1})\}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.6.m6.6"><semantics id="A3.I1.i1.p1.6.m6.6a"><mrow id="A3.I1.i1.p1.6.m6.6.6" xref="A3.I1.i1.p1.6.m6.6.6.cmml"><mi id="A3.I1.i1.p1.6.m6.6.6.5" xref="A3.I1.i1.p1.6.m6.6.6.5.cmml">𝐀</mi><mo id="A3.I1.i1.p1.6.m6.6.6.4" xref="A3.I1.i1.p1.6.m6.6.6.4.cmml">=</mo><mrow id="A3.I1.i1.p1.6.m6.6.6.3.3" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml"><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.4" stretchy="false" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml">{</mo><mrow id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.3.cmml"><mo id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.3" stretchy="false" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.3.cmml">(</mo><msub id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2a.cmml">d</mtext><mn id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.3" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.3.cmml">0</mn></msub><mo id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.4" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.3.cmml">,</mo><msub id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2a.cmml">l</mtext><mn id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.3" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.3.cmml">0</mn></msub><mo id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.5" stretchy="false" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.3.cmml">)</mo></mrow><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.5" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml">,</mo><mrow id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.3.cmml"><mo id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.3" stretchy="false" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.3.cmml">(</mo><msub id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2a.cmml">d</mtext><mn id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.3" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.3.cmml">1</mn></msub><mo id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.4" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.3.cmml">,</mo><msub id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2a.cmml">l</mtext><mn id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.3" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.3.cmml">1</mn></msub><mo id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.5" stretchy="false" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.3.cmml">)</mo></mrow><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.6" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml">,</mo><mi id="A3.I1.i1.p1.6.m6.3.3" mathvariant="normal" xref="A3.I1.i1.p1.6.m6.3.3.cmml">…</mi><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.7" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml">,</mo><mrow id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.3.cmml"><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.3" stretchy="false" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.3.cmml">(</mo><msub id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2a.cmml">d</mtext><mrow id="A3.I1.i1.p1.6.m6.1.1.1" xref="A3.I1.i1.p1.6.m6.1.1.1.cmml"><mrow id="A3.I1.i1.p1.6.m6.1.1.1.3.2" xref="A3.I1.i1.p1.6.m6.1.1.1.3.1.cmml"><mo id="A3.I1.i1.p1.6.m6.1.1.1.3.2.1" stretchy="false" xref="A3.I1.i1.p1.6.m6.1.1.1.3.1.1.cmml">|</mo><mi id="A3.I1.i1.p1.6.m6.1.1.1.1" xref="A3.I1.i1.p1.6.m6.1.1.1.1.cmml">𝐀</mi><mo id="A3.I1.i1.p1.6.m6.1.1.1.3.2.2" stretchy="false" xref="A3.I1.i1.p1.6.m6.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="A3.I1.i1.p1.6.m6.1.1.1.2" xref="A3.I1.i1.p1.6.m6.1.1.1.2.cmml">−</mo><mn id="A3.I1.i1.p1.6.m6.1.1.1.4" xref="A3.I1.i1.p1.6.m6.1.1.1.4.cmml">1</mn></mrow></msub><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.4" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.3.cmml">,</mo><msub id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2a.cmml">l</mtext><mrow id="A3.I1.i1.p1.6.m6.2.2.1" xref="A3.I1.i1.p1.6.m6.2.2.1.cmml"><mrow id="A3.I1.i1.p1.6.m6.2.2.1.3.2" xref="A3.I1.i1.p1.6.m6.2.2.1.3.1.cmml"><mo id="A3.I1.i1.p1.6.m6.2.2.1.3.2.1" stretchy="false" xref="A3.I1.i1.p1.6.m6.2.2.1.3.1.1.cmml">|</mo><mi id="A3.I1.i1.p1.6.m6.2.2.1.1" xref="A3.I1.i1.p1.6.m6.2.2.1.1.cmml">𝐀</mi><mo id="A3.I1.i1.p1.6.m6.2.2.1.3.2.2" stretchy="false" xref="A3.I1.i1.p1.6.m6.2.2.1.3.1.1.cmml">|</mo></mrow><mo id="A3.I1.i1.p1.6.m6.2.2.1.2" xref="A3.I1.i1.p1.6.m6.2.2.1.2.cmml">−</mo><mn id="A3.I1.i1.p1.6.m6.2.2.1.4" xref="A3.I1.i1.p1.6.m6.2.2.1.4.cmml">1</mn></mrow></msub><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.5" stretchy="false" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.3.cmml">)</mo></mrow><mo id="A3.I1.i1.p1.6.m6.6.6.3.3.8" stretchy="false" xref="A3.I1.i1.p1.6.m6.6.6.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.6.m6.6b"><apply id="A3.I1.i1.p1.6.m6.6.6.cmml" xref="A3.I1.i1.p1.6.m6.6.6"><eq id="A3.I1.i1.p1.6.m6.6.6.4.cmml" xref="A3.I1.i1.p1.6.m6.6.6.4"></eq><ci id="A3.I1.i1.p1.6.m6.6.6.5.cmml" xref="A3.I1.i1.p1.6.m6.6.6.5">𝐀</ci><set id="A3.I1.i1.p1.6.m6.6.6.3.4.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3"><interval closure="open" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.3.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2"><apply id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2a.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.2">d</mtext></ci><cn id="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.3.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.1.1.3">0</cn></apply><apply id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.1.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2a.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2.cmml" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.2">l</mtext></ci><cn id="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.3.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.4.4.1.1.1.2.2.3">0</cn></apply></interval><interval closure="open" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.3.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2"><apply id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2a.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.2">d</mtext></ci><cn id="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.3.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.1.1.3">1</cn></apply><apply id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.1.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2a.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2.cmml" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.2">l</mtext></ci><cn id="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.3.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.5.5.2.2.2.2.2.3">1</cn></apply></interval><ci id="A3.I1.i1.p1.6.m6.3.3.cmml" xref="A3.I1.i1.p1.6.m6.3.3">…</ci><interval closure="open" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.3.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2"><apply id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2a.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.1.1.2">d</mtext></ci><apply id="A3.I1.i1.p1.6.m6.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.1.1.1"><minus id="A3.I1.i1.p1.6.m6.1.1.1.2.cmml" xref="A3.I1.i1.p1.6.m6.1.1.1.2"></minus><apply id="A3.I1.i1.p1.6.m6.1.1.1.3.1.cmml" xref="A3.I1.i1.p1.6.m6.1.1.1.3.2"><abs id="A3.I1.i1.p1.6.m6.1.1.1.3.1.1.cmml" xref="A3.I1.i1.p1.6.m6.1.1.1.3.2.1"></abs><ci id="A3.I1.i1.p1.6.m6.1.1.1.1.cmml" xref="A3.I1.i1.p1.6.m6.1.1.1.1">𝐀</ci></apply><cn id="A3.I1.i1.p1.6.m6.1.1.1.4.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.1.1.1.4">1</cn></apply></apply><apply id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2"><csymbol cd="ambiguous" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.1.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2">subscript</csymbol><ci id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2a.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2.cmml" xref="A3.I1.i1.p1.6.m6.6.6.3.3.3.2.2.2">l</mtext></ci><apply id="A3.I1.i1.p1.6.m6.2.2.1.cmml" xref="A3.I1.i1.p1.6.m6.2.2.1"><minus id="A3.I1.i1.p1.6.m6.2.2.1.2.cmml" xref="A3.I1.i1.p1.6.m6.2.2.1.2"></minus><apply id="A3.I1.i1.p1.6.m6.2.2.1.3.1.cmml" xref="A3.I1.i1.p1.6.m6.2.2.1.3.2"><abs id="A3.I1.i1.p1.6.m6.2.2.1.3.1.1.cmml" xref="A3.I1.i1.p1.6.m6.2.2.1.3.2.1"></abs><ci id="A3.I1.i1.p1.6.m6.2.2.1.1.cmml" xref="A3.I1.i1.p1.6.m6.2.2.1.1">𝐀</ci></apply><cn id="A3.I1.i1.p1.6.m6.2.2.1.4.cmml" type="integer" xref="A3.I1.i1.p1.6.m6.2.2.1.4">1</cn></apply></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.6.m6.6c">\mathbf{A}=\{(\textbf{d}_{0},\textbf{l}_{0}),(\textbf{d}_{1},\textbf{l}_{1}),%
\dots,(\textbf{d}_{|\mathbf{A}|-1},\textbf{l}_{|\mathbf{A}|-1})\}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.6.m6.6d">bold_A = { ( d start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , ( d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , … , ( d start_POSTSUBSCRIPT | bold_A | - 1 end_POSTSUBSCRIPT , l start_POSTSUBSCRIPT | bold_A | - 1 end_POSTSUBSCRIPT ) }</annotation></semantics></math>, where each tuple specifies movement direction <math alttext="\textbf{d}_{i}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.7.m7.1"><semantics id="A3.I1.i1.p1.7.m7.1a"><msub id="A3.I1.i1.p1.7.m7.1.1" xref="A3.I1.i1.p1.7.m7.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.7.m7.1.1.2" xref="A3.I1.i1.p1.7.m7.1.1.2a.cmml">d</mtext><mi id="A3.I1.i1.p1.7.m7.1.1.3" xref="A3.I1.i1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.7.m7.1b"><apply id="A3.I1.i1.p1.7.m7.1.1.cmml" xref="A3.I1.i1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.7.m7.1.1.1.cmml" xref="A3.I1.i1.p1.7.m7.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.7.m7.1.1.2a.cmml" xref="A3.I1.i1.p1.7.m7.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.7.m7.1.1.2.cmml" xref="A3.I1.i1.p1.7.m7.1.1.2">d</mtext></ci><ci id="A3.I1.i1.p1.7.m7.1.1.3.cmml" xref="A3.I1.i1.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.7.m7.1c">\textbf{d}_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.7.m7.1d">d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and exact step count <math alttext="\textbf{l}_{i}" class="ltx_Math" display="inline" id="A3.I1.i1.p1.8.m8.1"><semantics id="A3.I1.i1.p1.8.m8.1a"><msub id="A3.I1.i1.p1.8.m8.1.1" xref="A3.I1.i1.p1.8.m8.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.8.m8.1.1.2" xref="A3.I1.i1.p1.8.m8.1.1.2a.cmml">l</mtext><mi id="A3.I1.i1.p1.8.m8.1.1.3" xref="A3.I1.i1.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i1.p1.8.m8.1b"><apply id="A3.I1.i1.p1.8.m8.1.1.cmml" xref="A3.I1.i1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A3.I1.i1.p1.8.m8.1.1.1.cmml" xref="A3.I1.i1.p1.8.m8.1.1">subscript</csymbol><ci id="A3.I1.i1.p1.8.m8.1.1.2a.cmml" xref="A3.I1.i1.p1.8.m8.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i1.p1.8.m8.1.1.2.cmml" xref="A3.I1.i1.p1.8.m8.1.1.2">l</mtext></ci><ci id="A3.I1.i1.p1.8.m8.1.1.3.cmml" xref="A3.I1.i1.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i1.p1.8.m8.1c">\textbf{l}_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i1.p1.8.m8.1d">l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, governed by the policy:</p>
<table class="ltx_equation ltx_eqn_table" id="A3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{a_{t}}\sim\mathcal{P}\left(\mathbf{d}_{t},\mathbf{l}_{t}\mid\textbf{A}%
_{t-1},\mathbf{M}\right)" class="ltx_Math" display="block" id="A3.E3.m1.3"><semantics id="A3.E3.m1.3a"><mrow id="A3.E3.m1.3.3" xref="A3.E3.m1.3.3.cmml"><msub id="A3.E3.m1.3.3.4" xref="A3.E3.m1.3.3.4.cmml"><mi id="A3.E3.m1.3.3.4.2" xref="A3.E3.m1.3.3.4.2.cmml">𝐚</mi><mi id="A3.E3.m1.3.3.4.3" xref="A3.E3.m1.3.3.4.3.cmml">𝐭</mi></msub><mo id="A3.E3.m1.3.3.3" xref="A3.E3.m1.3.3.3.cmml">∼</mo><mrow id="A3.E3.m1.3.3.2" xref="A3.E3.m1.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A3.E3.m1.3.3.2.4" xref="A3.E3.m1.3.3.2.4.cmml">𝒫</mi><mo id="A3.E3.m1.3.3.2.3" xref="A3.E3.m1.3.3.2.3.cmml">⁢</mo><mrow id="A3.E3.m1.3.3.2.2.2" xref="A3.E3.m1.3.3.2.2.3.cmml"><mo id="A3.E3.m1.3.3.2.2.2.3" xref="A3.E3.m1.3.3.2.2.3.cmml">(</mo><msub id="A3.E3.m1.2.2.1.1.1.1" xref="A3.E3.m1.2.2.1.1.1.1.cmml"><mi id="A3.E3.m1.2.2.1.1.1.1.2" xref="A3.E3.m1.2.2.1.1.1.1.2.cmml">𝐝</mi><mi id="A3.E3.m1.2.2.1.1.1.1.3" xref="A3.E3.m1.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="A3.E3.m1.3.3.2.2.2.4" xref="A3.E3.m1.3.3.2.2.3.cmml">,</mo><mrow id="A3.E3.m1.3.3.2.2.2.2" xref="A3.E3.m1.3.3.2.2.2.2.cmml"><msub id="A3.E3.m1.3.3.2.2.2.2.3" xref="A3.E3.m1.3.3.2.2.2.2.3.cmml"><mi id="A3.E3.m1.3.3.2.2.2.2.3.2" xref="A3.E3.m1.3.3.2.2.2.2.3.2.cmml">𝐥</mi><mi id="A3.E3.m1.3.3.2.2.2.2.3.3" xref="A3.E3.m1.3.3.2.2.2.2.3.3.cmml">t</mi></msub><mo id="A3.E3.m1.3.3.2.2.2.2.2" xref="A3.E3.m1.3.3.2.2.2.2.2.cmml">∣</mo><mrow id="A3.E3.m1.3.3.2.2.2.2.1.1" xref="A3.E3.m1.3.3.2.2.2.2.1.2.cmml"><msub id="A3.E3.m1.3.3.2.2.2.2.1.1.1" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.E3.m1.3.3.2.2.2.2.1.1.1.2" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.2a.cmml">A</mtext><mrow id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.cmml"><mi id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.2" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.2.cmml">t</mi><mo id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.1" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.1.cmml">−</mo><mn id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.3" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="A3.E3.m1.3.3.2.2.2.2.1.1.2" xref="A3.E3.m1.3.3.2.2.2.2.1.2.cmml">,</mo><mi id="A3.E3.m1.1.1" xref="A3.E3.m1.1.1.cmml">𝐌</mi></mrow></mrow><mo id="A3.E3.m1.3.3.2.2.2.5" xref="A3.E3.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.E3.m1.3b"><apply id="A3.E3.m1.3.3.cmml" xref="A3.E3.m1.3.3"><csymbol cd="latexml" id="A3.E3.m1.3.3.3.cmml" xref="A3.E3.m1.3.3.3">similar-to</csymbol><apply id="A3.E3.m1.3.3.4.cmml" xref="A3.E3.m1.3.3.4"><csymbol cd="ambiguous" id="A3.E3.m1.3.3.4.1.cmml" xref="A3.E3.m1.3.3.4">subscript</csymbol><ci id="A3.E3.m1.3.3.4.2.cmml" xref="A3.E3.m1.3.3.4.2">𝐚</ci><ci id="A3.E3.m1.3.3.4.3.cmml" xref="A3.E3.m1.3.3.4.3">𝐭</ci></apply><apply id="A3.E3.m1.3.3.2.cmml" xref="A3.E3.m1.3.3.2"><times id="A3.E3.m1.3.3.2.3.cmml" xref="A3.E3.m1.3.3.2.3"></times><ci id="A3.E3.m1.3.3.2.4.cmml" xref="A3.E3.m1.3.3.2.4">𝒫</ci><interval closure="open" id="A3.E3.m1.3.3.2.2.3.cmml" xref="A3.E3.m1.3.3.2.2.2"><apply id="A3.E3.m1.2.2.1.1.1.1.cmml" xref="A3.E3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="A3.E3.m1.2.2.1.1.1.1.1.cmml" xref="A3.E3.m1.2.2.1.1.1.1">subscript</csymbol><ci id="A3.E3.m1.2.2.1.1.1.1.2.cmml" xref="A3.E3.m1.2.2.1.1.1.1.2">𝐝</ci><ci id="A3.E3.m1.2.2.1.1.1.1.3.cmml" xref="A3.E3.m1.2.2.1.1.1.1.3">𝑡</ci></apply><apply id="A3.E3.m1.3.3.2.2.2.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2"><csymbol cd="latexml" id="A3.E3.m1.3.3.2.2.2.2.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2.2">conditional</csymbol><apply id="A3.E3.m1.3.3.2.2.2.2.3.cmml" xref="A3.E3.m1.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="A3.E3.m1.3.3.2.2.2.2.3.1.cmml" xref="A3.E3.m1.3.3.2.2.2.2.3">subscript</csymbol><ci id="A3.E3.m1.3.3.2.2.2.2.3.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2.3.2">𝐥</ci><ci id="A3.E3.m1.3.3.2.2.2.2.3.3.cmml" xref="A3.E3.m1.3.3.2.2.2.2.3.3">𝑡</ci></apply><list id="A3.E3.m1.3.3.2.2.2.2.1.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1"><apply id="A3.E3.m1.3.3.2.2.2.2.1.1.1.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="A3.E3.m1.3.3.2.2.2.2.1.1.1.1.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1">subscript</csymbol><ci id="A3.E3.m1.3.3.2.2.2.2.1.1.1.2a.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.E3.m1.3.3.2.2.2.2.1.1.1.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.2">A</mtext></ci><apply id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3"><minus id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.1.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.1"></minus><ci id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.2.cmml" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.2">𝑡</ci><cn id="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.3.cmml" type="integer" xref="A3.E3.m1.3.3.2.2.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="A3.E3.m1.1.1.cmml" xref="A3.E3.m1.1.1">𝐌</ci></list></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.E3.m1.3c">\mathbf{a_{t}}\sim\mathcal{P}\left(\mathbf{d}_{t},\mathbf{l}_{t}\mid\textbf{A}%
_{t-1},\mathbf{M}\right)</annotation><annotation encoding="application/x-llamapun" id="A3.E3.m1.3d">bold_a start_POSTSUBSCRIPT bold_t end_POSTSUBSCRIPT ∼ caligraphic_P ( bold_d start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_l start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∣ A start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , bold_M )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.8"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.p1.8.1">Visual Tiling</span> is a classic geometric reasoning challenge, this task assesses polyomino composition capabilities within confined rectangular regions <span class="ltx_text ltx_markedasmath ltx_font_bold" id="A3.I1.i2.p1.8.2">R</span> masked by <math alttext="k" class="ltx_Math" display="inline" id="A3.I1.i2.p1.2.m2.1"><semantics id="A3.I1.i2.p1.2.m2.1a"><mi id="A3.I1.i2.p1.2.m2.1.1" xref="A3.I1.i2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.2.m2.1b"><ci id="A3.I1.i2.p1.2.m2.1.1.cmml" xref="A3.I1.i2.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.2.m2.1d">italic_k</annotation></semantics></math> distinct polyominoes <math alttext="\mathbf{MP}=\{\textbf{mp}_{1},\dots,\textbf{mp}_{k}\}" class="ltx_Math" display="inline" id="A3.I1.i2.p1.3.m3.3"><semantics id="A3.I1.i2.p1.3.m3.3a"><mrow id="A3.I1.i2.p1.3.m3.3.3" xref="A3.I1.i2.p1.3.m3.3.3.cmml"><mi id="A3.I1.i2.p1.3.m3.3.3.4" xref="A3.I1.i2.p1.3.m3.3.3.4.cmml">𝐌𝐏</mi><mo id="A3.I1.i2.p1.3.m3.3.3.3" xref="A3.I1.i2.p1.3.m3.3.3.3.cmml">=</mo><mrow id="A3.I1.i2.p1.3.m3.3.3.2.2" xref="A3.I1.i2.p1.3.m3.3.3.2.3.cmml"><mo id="A3.I1.i2.p1.3.m3.3.3.2.2.3" stretchy="false" xref="A3.I1.i2.p1.3.m3.3.3.2.3.cmml">{</mo><msub id="A3.I1.i2.p1.3.m3.2.2.1.1.1" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.3.m3.2.2.1.1.1.2" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.2a.cmml">mp</mtext><mn id="A3.I1.i2.p1.3.m3.2.2.1.1.1.3" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="A3.I1.i2.p1.3.m3.3.3.2.2.4" xref="A3.I1.i2.p1.3.m3.3.3.2.3.cmml">,</mo><mi id="A3.I1.i2.p1.3.m3.1.1" mathvariant="normal" xref="A3.I1.i2.p1.3.m3.1.1.cmml">…</mi><mo id="A3.I1.i2.p1.3.m3.3.3.2.2.5" xref="A3.I1.i2.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="A3.I1.i2.p1.3.m3.3.3.2.2.2" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.3.m3.3.3.2.2.2.2" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.2a.cmml">mp</mtext><mi id="A3.I1.i2.p1.3.m3.3.3.2.2.2.3" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.3.cmml">k</mi></msub><mo id="A3.I1.i2.p1.3.m3.3.3.2.2.6" stretchy="false" xref="A3.I1.i2.p1.3.m3.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.3.m3.3b"><apply id="A3.I1.i2.p1.3.m3.3.3.cmml" xref="A3.I1.i2.p1.3.m3.3.3"><eq id="A3.I1.i2.p1.3.m3.3.3.3.cmml" xref="A3.I1.i2.p1.3.m3.3.3.3"></eq><ci id="A3.I1.i2.p1.3.m3.3.3.4.cmml" xref="A3.I1.i2.p1.3.m3.3.3.4">𝐌𝐏</ci><set id="A3.I1.i2.p1.3.m3.3.3.2.3.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2"><apply id="A3.I1.i2.p1.3.m3.2.2.1.1.1.cmml" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.3.m3.2.2.1.1.1.1.cmml" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.3.m3.2.2.1.1.1.2a.cmml" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.3.m3.2.2.1.1.1.2.cmml" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.2">mp</mtext></ci><cn id="A3.I1.i2.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="A3.I1.i2.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="A3.I1.i2.p1.3.m3.1.1.cmml" xref="A3.I1.i2.p1.3.m3.1.1">…</ci><apply id="A3.I1.i2.p1.3.m3.3.3.2.2.2.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i2.p1.3.m3.3.3.2.2.2.1.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="A3.I1.i2.p1.3.m3.3.3.2.2.2.2a.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.3.m3.3.3.2.2.2.2.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.2">mp</mtext></ci><ci id="A3.I1.i2.p1.3.m3.3.3.2.2.2.3.cmml" xref="A3.I1.i2.p1.3.m3.3.3.2.2.2.3">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.3.m3.3c">\mathbf{MP}=\{\textbf{mp}_{1},\dots,\textbf{mp}_{k}\}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.3.m3.3d">bold_MP = { mp start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , mp start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math>. The LVLM must output action sequences <math alttext="\textbf{a}_{t}=(\textbf{p}_{t},\{\textbf{b}_{1},\dots,\textbf{b}_{|B|}\},%
\textbf{at}_{t})" class="ltx_Math" display="inline" id="A3.I1.i2.p1.4.m4.5"><semantics id="A3.I1.i2.p1.4.m4.5a"><mrow id="A3.I1.i2.p1.4.m4.5.5" xref="A3.I1.i2.p1.4.m4.5.5.cmml"><msub id="A3.I1.i2.p1.4.m4.5.5.5" xref="A3.I1.i2.p1.4.m4.5.5.5.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.5.5.5.2" xref="A3.I1.i2.p1.4.m4.5.5.5.2a.cmml">a</mtext><mi id="A3.I1.i2.p1.4.m4.5.5.5.3" xref="A3.I1.i2.p1.4.m4.5.5.5.3.cmml">t</mi></msub><mo id="A3.I1.i2.p1.4.m4.5.5.4" xref="A3.I1.i2.p1.4.m4.5.5.4.cmml">=</mo><mrow id="A3.I1.i2.p1.4.m4.5.5.3.3" xref="A3.I1.i2.p1.4.m4.5.5.3.4.cmml"><mo id="A3.I1.i2.p1.4.m4.5.5.3.3.4" stretchy="false" xref="A3.I1.i2.p1.4.m4.5.5.3.4.cmml">(</mo><msub id="A3.I1.i2.p1.4.m4.3.3.1.1.1" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.3.3.1.1.1.2" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.2a.cmml">p</mtext><mi id="A3.I1.i2.p1.4.m4.3.3.1.1.1.3" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.3.cmml">t</mi></msub><mo id="A3.I1.i2.p1.4.m4.5.5.3.3.5" xref="A3.I1.i2.p1.4.m4.5.5.3.4.cmml">,</mo><mrow id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml"><mo id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.3" stretchy="false" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml">{</mo><msub id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2a.cmml">b</mtext><mn id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.3" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.3.cmml">1</mn></msub><mo id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.4" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml">,</mo><mi id="A3.I1.i2.p1.4.m4.2.2" mathvariant="normal" xref="A3.I1.i2.p1.4.m4.2.2.cmml">…</mi><mo id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.5" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml">,</mo><msub id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2a.cmml">b</mtext><mrow id="A3.I1.i2.p1.4.m4.1.1.1.3" xref="A3.I1.i2.p1.4.m4.1.1.1.2.cmml"><mo id="A3.I1.i2.p1.4.m4.1.1.1.3.1" stretchy="false" xref="A3.I1.i2.p1.4.m4.1.1.1.2.1.cmml">|</mo><mi id="A3.I1.i2.p1.4.m4.1.1.1.1" xref="A3.I1.i2.p1.4.m4.1.1.1.1.cmml">B</mi><mo id="A3.I1.i2.p1.4.m4.1.1.1.3.2" stretchy="false" xref="A3.I1.i2.p1.4.m4.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.6" stretchy="false" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml">}</mo></mrow><mo id="A3.I1.i2.p1.4.m4.5.5.3.3.6" xref="A3.I1.i2.p1.4.m4.5.5.3.4.cmml">,</mo><msub id="A3.I1.i2.p1.4.m4.5.5.3.3.3" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.5.5.3.3.3.2" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.2a.cmml">at</mtext><mi id="A3.I1.i2.p1.4.m4.5.5.3.3.3.3" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.3.cmml">t</mi></msub><mo id="A3.I1.i2.p1.4.m4.5.5.3.3.7" stretchy="false" xref="A3.I1.i2.p1.4.m4.5.5.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.4.m4.5b"><apply id="A3.I1.i2.p1.4.m4.5.5.cmml" xref="A3.I1.i2.p1.4.m4.5.5"><eq id="A3.I1.i2.p1.4.m4.5.5.4.cmml" xref="A3.I1.i2.p1.4.m4.5.5.4"></eq><apply id="A3.I1.i2.p1.4.m4.5.5.5.cmml" xref="A3.I1.i2.p1.4.m4.5.5.5"><csymbol cd="ambiguous" id="A3.I1.i2.p1.4.m4.5.5.5.1.cmml" xref="A3.I1.i2.p1.4.m4.5.5.5">subscript</csymbol><ci id="A3.I1.i2.p1.4.m4.5.5.5.2a.cmml" xref="A3.I1.i2.p1.4.m4.5.5.5.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.5.5.5.2.cmml" xref="A3.I1.i2.p1.4.m4.5.5.5.2">a</mtext></ci><ci id="A3.I1.i2.p1.4.m4.5.5.5.3.cmml" xref="A3.I1.i2.p1.4.m4.5.5.5.3">𝑡</ci></apply><vector id="A3.I1.i2.p1.4.m4.5.5.3.4.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3"><apply id="A3.I1.i2.p1.4.m4.3.3.1.1.1.cmml" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.4.m4.3.3.1.1.1.1.cmml" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.4.m4.3.3.1.1.1.2a.cmml" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.3.3.1.1.1.2.cmml" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.2">p</mtext></ci><ci id="A3.I1.i2.p1.4.m4.3.3.1.1.1.3.cmml" xref="A3.I1.i2.p1.4.m4.3.3.1.1.1.3">𝑡</ci></apply><set id="A3.I1.i2.p1.4.m4.4.4.2.2.2.3.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2"><apply id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.1.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2a.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.2">b</mtext></ci><cn id="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.3.cmml" type="integer" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.1.1.3">1</cn></apply><ci id="A3.I1.i2.p1.4.m4.2.2.cmml" xref="A3.I1.i2.p1.4.m4.2.2">…</ci><apply id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.1.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2">subscript</csymbol><ci id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2a.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2.cmml" xref="A3.I1.i2.p1.4.m4.4.4.2.2.2.2.2.2">b</mtext></ci><apply id="A3.I1.i2.p1.4.m4.1.1.1.2.cmml" xref="A3.I1.i2.p1.4.m4.1.1.1.3"><abs id="A3.I1.i2.p1.4.m4.1.1.1.2.1.cmml" xref="A3.I1.i2.p1.4.m4.1.1.1.3.1"></abs><ci id="A3.I1.i2.p1.4.m4.1.1.1.1.cmml" xref="A3.I1.i2.p1.4.m4.1.1.1.1">𝐵</ci></apply></apply></set><apply id="A3.I1.i2.p1.4.m4.5.5.3.3.3.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3"><csymbol cd="ambiguous" id="A3.I1.i2.p1.4.m4.5.5.3.3.3.1.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3">subscript</csymbol><ci id="A3.I1.i2.p1.4.m4.5.5.3.3.3.2a.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.4.m4.5.5.3.3.3.2.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.2">at</mtext></ci><ci id="A3.I1.i2.p1.4.m4.5.5.3.3.3.3.cmml" xref="A3.I1.i2.p1.4.m4.5.5.3.3.3.3">𝑡</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.4.m4.5c">\textbf{a}_{t}=(\textbf{p}_{t},\{\textbf{b}_{1},\dots,\textbf{b}_{|B|}\},%
\textbf{at}_{t})</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.4.m4.5d">a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , { b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , b start_POSTSUBSCRIPT | italic_B | end_POSTSUBSCRIPT } , at start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, where <math alttext="\textbf{p}_{t}" class="ltx_Math" display="inline" id="A3.I1.i2.p1.5.m5.1"><semantics id="A3.I1.i2.p1.5.m5.1a"><msub id="A3.I1.i2.p1.5.m5.1.1" xref="A3.I1.i2.p1.5.m5.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.5.m5.1.1.2" xref="A3.I1.i2.p1.5.m5.1.1.2a.cmml">p</mtext><mi id="A3.I1.i2.p1.5.m5.1.1.3" xref="A3.I1.i2.p1.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.5.m5.1b"><apply id="A3.I1.i2.p1.5.m5.1.1.cmml" xref="A3.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.5.m5.1.1.1.cmml" xref="A3.I1.i2.p1.5.m5.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.5.m5.1.1.2a.cmml" xref="A3.I1.i2.p1.5.m5.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.5.m5.1.1.2.cmml" xref="A3.I1.i2.p1.5.m5.1.1.2">p</mtext></ci><ci id="A3.I1.i2.p1.5.m5.1.1.3.cmml" xref="A3.I1.i2.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.5.m5.1c">\textbf{p}_{t}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.5.m5.1d">p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{B}=\{\textbf{b}_{1},\dots,\textbf{b}_{|\mathbf{B}|}\}" class="ltx_Math" display="inline" id="A3.I1.i2.p1.6.m6.4"><semantics id="A3.I1.i2.p1.6.m6.4a"><mrow id="A3.I1.i2.p1.6.m6.4.4" xref="A3.I1.i2.p1.6.m6.4.4.cmml"><mi id="A3.I1.i2.p1.6.m6.4.4.4" xref="A3.I1.i2.p1.6.m6.4.4.4.cmml">𝐁</mi><mo id="A3.I1.i2.p1.6.m6.4.4.3" xref="A3.I1.i2.p1.6.m6.4.4.3.cmml">=</mo><mrow id="A3.I1.i2.p1.6.m6.4.4.2.2" xref="A3.I1.i2.p1.6.m6.4.4.2.3.cmml"><mo id="A3.I1.i2.p1.6.m6.4.4.2.2.3" stretchy="false" xref="A3.I1.i2.p1.6.m6.4.4.2.3.cmml">{</mo><msub id="A3.I1.i2.p1.6.m6.3.3.1.1.1" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.6.m6.3.3.1.1.1.2" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.2a.cmml">b</mtext><mn id="A3.I1.i2.p1.6.m6.3.3.1.1.1.3" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.3.cmml">1</mn></msub><mo id="A3.I1.i2.p1.6.m6.4.4.2.2.4" xref="A3.I1.i2.p1.6.m6.4.4.2.3.cmml">,</mo><mi id="A3.I1.i2.p1.6.m6.2.2" mathvariant="normal" xref="A3.I1.i2.p1.6.m6.2.2.cmml">…</mi><mo id="A3.I1.i2.p1.6.m6.4.4.2.2.5" xref="A3.I1.i2.p1.6.m6.4.4.2.3.cmml">,</mo><msub id="A3.I1.i2.p1.6.m6.4.4.2.2.2" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.6.m6.4.4.2.2.2.2" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2.2a.cmml">b</mtext><mrow id="A3.I1.i2.p1.6.m6.1.1.1.3" xref="A3.I1.i2.p1.6.m6.1.1.1.2.cmml"><mo id="A3.I1.i2.p1.6.m6.1.1.1.3.1" stretchy="false" xref="A3.I1.i2.p1.6.m6.1.1.1.2.1.cmml">|</mo><mi id="A3.I1.i2.p1.6.m6.1.1.1.1" xref="A3.I1.i2.p1.6.m6.1.1.1.1.cmml">𝐁</mi><mo id="A3.I1.i2.p1.6.m6.1.1.1.3.2" stretchy="false" xref="A3.I1.i2.p1.6.m6.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="A3.I1.i2.p1.6.m6.4.4.2.2.6" stretchy="false" xref="A3.I1.i2.p1.6.m6.4.4.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.6.m6.4b"><apply id="A3.I1.i2.p1.6.m6.4.4.cmml" xref="A3.I1.i2.p1.6.m6.4.4"><eq id="A3.I1.i2.p1.6.m6.4.4.3.cmml" xref="A3.I1.i2.p1.6.m6.4.4.3"></eq><ci id="A3.I1.i2.p1.6.m6.4.4.4.cmml" xref="A3.I1.i2.p1.6.m6.4.4.4">𝐁</ci><set id="A3.I1.i2.p1.6.m6.4.4.2.3.cmml" xref="A3.I1.i2.p1.6.m6.4.4.2.2"><apply id="A3.I1.i2.p1.6.m6.3.3.1.1.1.cmml" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.6.m6.3.3.1.1.1.1.cmml" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.6.m6.3.3.1.1.1.2a.cmml" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.6.m6.3.3.1.1.1.2.cmml" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.2">b</mtext></ci><cn id="A3.I1.i2.p1.6.m6.3.3.1.1.1.3.cmml" type="integer" xref="A3.I1.i2.p1.6.m6.3.3.1.1.1.3">1</cn></apply><ci id="A3.I1.i2.p1.6.m6.2.2.cmml" xref="A3.I1.i2.p1.6.m6.2.2">…</ci><apply id="A3.I1.i2.p1.6.m6.4.4.2.2.2.cmml" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2"><csymbol cd="ambiguous" id="A3.I1.i2.p1.6.m6.4.4.2.2.2.1.cmml" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2">subscript</csymbol><ci id="A3.I1.i2.p1.6.m6.4.4.2.2.2.2a.cmml" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.6.m6.4.4.2.2.2.2.cmml" xref="A3.I1.i2.p1.6.m6.4.4.2.2.2.2">b</mtext></ci><apply id="A3.I1.i2.p1.6.m6.1.1.1.2.cmml" xref="A3.I1.i2.p1.6.m6.1.1.1.3"><abs id="A3.I1.i2.p1.6.m6.1.1.1.2.1.cmml" xref="A3.I1.i2.p1.6.m6.1.1.1.3.1"></abs><ci id="A3.I1.i2.p1.6.m6.1.1.1.1.cmml" xref="A3.I1.i2.p1.6.m6.1.1.1.1">𝐁</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.6.m6.4c">\mathbf{B}=\{\textbf{b}_{1},\dots,\textbf{b}_{|\mathbf{B}|}\}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.6.m6.4d">bold_B = { b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , b start_POSTSUBSCRIPT | bold_B | end_POSTSUBSCRIPT }</annotation></semantics></math> respectively indicate the selected polyomino type and the coordinates of the placement blocks. <math alttext="\textbf{at}_{t}\in\{\textit{\text{fit}},\textit{\text{remove}}\}" class="ltx_Math" display="inline" id="A3.I1.i2.p1.7.m7.2"><semantics id="A3.I1.i2.p1.7.m7.2a"><mrow id="A3.I1.i2.p1.7.m7.2.3" xref="A3.I1.i2.p1.7.m7.2.3.cmml"><msub id="A3.I1.i2.p1.7.m7.2.3.2" xref="A3.I1.i2.p1.7.m7.2.3.2.cmml"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.7.m7.2.3.2.2" xref="A3.I1.i2.p1.7.m7.2.3.2.2a.cmml">at</mtext><mi id="A3.I1.i2.p1.7.m7.2.3.2.3" xref="A3.I1.i2.p1.7.m7.2.3.2.3.cmml">t</mi></msub><mo id="A3.I1.i2.p1.7.m7.2.3.1" xref="A3.I1.i2.p1.7.m7.2.3.1.cmml">∈</mo><mrow id="A3.I1.i2.p1.7.m7.2.3.3.2" xref="A3.I1.i2.p1.7.m7.2.3.3.1.cmml"><mo id="A3.I1.i2.p1.7.m7.2.3.3.2.1" stretchy="false" xref="A3.I1.i2.p1.7.m7.2.3.3.1.cmml">{</mo><mtext class="ltx_mathvariant_italic" id="A3.I1.i2.p1.7.m7.1.1" xref="A3.I1.i2.p1.7.m7.1.1a.cmml">fit</mtext><mo id="A3.I1.i2.p1.7.m7.2.3.3.2.2" xref="A3.I1.i2.p1.7.m7.2.3.3.1.cmml">,</mo><mtext class="ltx_mathvariant_italic" id="A3.I1.i2.p1.7.m7.2.2" xref="A3.I1.i2.p1.7.m7.2.2a.cmml">remove</mtext><mo id="A3.I1.i2.p1.7.m7.2.3.3.2.3" stretchy="false" xref="A3.I1.i2.p1.7.m7.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.7.m7.2b"><apply id="A3.I1.i2.p1.7.m7.2.3.cmml" xref="A3.I1.i2.p1.7.m7.2.3"><in id="A3.I1.i2.p1.7.m7.2.3.1.cmml" xref="A3.I1.i2.p1.7.m7.2.3.1"></in><apply id="A3.I1.i2.p1.7.m7.2.3.2.cmml" xref="A3.I1.i2.p1.7.m7.2.3.2"><csymbol cd="ambiguous" id="A3.I1.i2.p1.7.m7.2.3.2.1.cmml" xref="A3.I1.i2.p1.7.m7.2.3.2">subscript</csymbol><ci id="A3.I1.i2.p1.7.m7.2.3.2.2a.cmml" xref="A3.I1.i2.p1.7.m7.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="A3.I1.i2.p1.7.m7.2.3.2.2.cmml" xref="A3.I1.i2.p1.7.m7.2.3.2.2">at</mtext></ci><ci id="A3.I1.i2.p1.7.m7.2.3.2.3.cmml" xref="A3.I1.i2.p1.7.m7.2.3.2.3">𝑡</ci></apply><set id="A3.I1.i2.p1.7.m7.2.3.3.1.cmml" xref="A3.I1.i2.p1.7.m7.2.3.3.2"><ci id="A3.I1.i2.p1.7.m7.1.1a.cmml" xref="A3.I1.i2.p1.7.m7.1.1"><mtext class="ltx_mathvariant_italic" id="A3.I1.i2.p1.7.m7.1.1.cmml" xref="A3.I1.i2.p1.7.m7.1.1">fit</mtext></ci><ci id="A3.I1.i2.p1.7.m7.2.2a.cmml" xref="A3.I1.i2.p1.7.m7.2.2"><mtext class="ltx_mathvariant_italic" id="A3.I1.i2.p1.7.m7.2.2.cmml" xref="A3.I1.i2.p1.7.m7.2.2">remove</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.7.m7.2c">\textbf{at}_{t}\in\{\textit{\text{fit}},\textit{\text{remove}}\}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.7.m7.2d">at start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ { fit , remove }</annotation></semantics></math> indicates the action type modifying rectangular state <math alttext="\mathbf{R}_{t}" class="ltx_Math" display="inline" id="A3.I1.i2.p1.8.m8.1"><semantics id="A3.I1.i2.p1.8.m8.1a"><msub id="A3.I1.i2.p1.8.m8.1.1" xref="A3.I1.i2.p1.8.m8.1.1.cmml"><mi id="A3.I1.i2.p1.8.m8.1.1.2" xref="A3.I1.i2.p1.8.m8.1.1.2.cmml">𝐑</mi><mi id="A3.I1.i2.p1.8.m8.1.1.3" xref="A3.I1.i2.p1.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A3.I1.i2.p1.8.m8.1b"><apply id="A3.I1.i2.p1.8.m8.1.1.cmml" xref="A3.I1.i2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A3.I1.i2.p1.8.m8.1.1.1.cmml" xref="A3.I1.i2.p1.8.m8.1.1">subscript</csymbol><ci id="A3.I1.i2.p1.8.m8.1.1.2.cmml" xref="A3.I1.i2.p1.8.m8.1.1.2">𝐑</ci><ci id="A3.I1.i2.p1.8.m8.1.1.3.cmml" xref="A3.I1.i2.p1.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.I1.i2.p1.8.m8.1c">\mathbf{R}_{t}</annotation><annotation encoding="application/x-llamapun" id="A3.I1.i2.p1.8.m8.1d">bold_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, thus formalized as:</p>
</div>
<div class="ltx_para" id="A3.I1.i2.p2">
<table class="ltx_equation ltx_eqn_table" id="A3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{a}_{t}\sim\mathcal{P}\left(\textbf{p}_{t},\mathbf{B},\textbf{at}_{t}%
\mid\mathbf{R}_{t-1},\mathbf{MP},\textbf{A}_{t-1}\}\right)" class="ltx_math_unparsed" display="block" id="A3.E4.m1.2"><semantics id="A3.E4.m1.2a"><mrow id="A3.E4.m1.2b"><msub id="A3.E4.m1.2.3"><mtext class="ltx_mathvariant_bold" id="A3.E4.m1.2.3.2">a</mtext><mi id="A3.E4.m1.2.3.3">t</mi></msub><mo id="A3.E4.m1.2.4">∼</mo><mi class="ltx_font_mathcaligraphic" id="A3.E4.m1.2.5">𝒫</mi><mrow id="A3.E4.m1.2.6"><mo id="A3.E4.m1.2.6.1">(</mo><msub id="A3.E4.m1.2.6.2"><mtext class="ltx_mathvariant_bold" id="A3.E4.m1.2.6.2.2">p</mtext><mi id="A3.E4.m1.2.6.2.3">t</mi></msub><mo id="A3.E4.m1.2.6.3">,</mo><mi id="A3.E4.m1.2.2">𝐁</mi><mo id="A3.E4.m1.2.6.4">,</mo><msub id="A3.E4.m1.2.6.5"><mtext class="ltx_mathvariant_bold" id="A3.E4.m1.2.6.5.2">at</mtext><mi id="A3.E4.m1.2.6.5.3">t</mi></msub><mo id="A3.E4.m1.2.6.6" lspace="0em" rspace="0.167em">∣</mo><msub id="A3.E4.m1.2.6.7"><mi id="A3.E4.m1.2.6.7.2">𝐑</mi><mrow id="A3.E4.m1.2.6.7.3"><mi id="A3.E4.m1.2.6.7.3.2">t</mi><mo id="A3.E4.m1.2.6.7.3.1">−</mo><mn id="A3.E4.m1.2.6.7.3.3">1</mn></mrow></msub><mo id="A3.E4.m1.2.6.8">,</mo><mi id="A3.E4.m1.1.1">𝐌𝐏</mi><mo id="A3.E4.m1.2.6.9">,</mo><msub id="A3.E4.m1.2.6.10"><mtext class="ltx_mathvariant_bold" id="A3.E4.m1.2.6.10.2">A</mtext><mrow id="A3.E4.m1.2.6.10.3"><mi id="A3.E4.m1.2.6.10.3.2">t</mi><mo id="A3.E4.m1.2.6.10.3.1">−</mo><mn id="A3.E4.m1.2.6.10.3.3">1</mn></mrow></msub><mo id="A3.E4.m1.2.6.11" stretchy="false">}</mo></mrow><mo id="A3.E4.m1.2.7">)</mo></mrow><annotation encoding="application/x-tex" id="A3.E4.m1.2c">\textbf{a}_{t}\sim\mathcal{P}\left(\textbf{p}_{t},\mathbf{B},\textbf{at}_{t}%
\mid\mathbf{R}_{t-1},\mathbf{MP},\textbf{A}_{t-1}\}\right)</annotation><annotation encoding="application/x-llamapun" id="A3.E4.m1.2d">a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∼ caligraphic_P ( p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_B , at start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∣ bold_R start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , bold_MP , A start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT } )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="A3.I1.i2.p3">
<p class="ltx_p" id="A3.I1.i2.p3.1">Though the required actions are polyomino variant-aware as shown in table <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#A2.T5" title="Table 5 ‣ Appendix B OKSpatial Reasoning Task Setting ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">5</span></a>. As the polyomino variant type is implicitly expressed in the block positions, LVLM does not need to explicitly output it in actions anymore.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Model and <span class="ltx_text ltx_font_bold ltx_font_italic" id="A4.1.1">VisuoThink</span> Hyperparameters</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We detail the model and <span class="ltx_text ltx_font_italic" id="A4.p1.1.1">VisuoThink</span> Hyperparameters:</p>
</div>
<section class="ltx_paragraph" id="A4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Model Hyperparameters</h4>
<div class="ltx_para" id="A4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A4.SS0.SSS0.Px1.p1.1">To ensure experimental fairness, we uniformly constrained the number of reasoning steps (i.e., <math alttext="\tau" class="ltx_Math" display="inline" id="A4.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="A4.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="A4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A4.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="A4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A4.SS0.SSS0.Px1.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS0.SSS0.Px1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A4.SS0.SSS0.Px1.p1.1.m1.1d">italic_τ</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px1.p1.1.1">the depth of the reasoning tree</span>) to <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px1.p1.1.2">10</span> across all experiments. During predictive rollout search, we set the number of sampled child nodes to <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px1.p1.1.3">3</span>, and we discuss its impact in section <a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#S6.SS2" title="6.2 Could Larger Tree Span Enhances VisuoThink’s Performance? ‣ 6 Discussion ‣ VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search"><span class="ltx_text ltx_ref_tag">6.2</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">
<span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.1.1">VisuoThink</span> Hyperparameters</h4>
<div class="ltx_para" id="A4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A4.SS0.SSS0.Px2.p1.1">While <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.1">VisuoThink</span> employed a temperature of <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.2">0.8</span> when sampling child nodes, all other model invocations, including the baselines (e.g. <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.3">CoT</span>, <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.4">VoT</span>, <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.5">VisualSketchpad</span>, <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.6">VisuoThink</span> w/o rollout search), were conducted with temperature set to <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.7">0</span> for frontier performance. During the voting phase, we similarly maintained a temperature of <span class="ltx_text ltx_font_italic" id="A4.SS0.SSS0.Px2.p1.1.8">0</span> and implemented single-vote sampling, which not only reduced computational overhead in terms of model calls but also achieved comparable performance.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Geomverse-109 Problem Generation Trajectory</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">We establish a pipeline translating textual problems into problems with matplotlib-executable code. Beyond the <span class="ltx_text ltx_font_bold" id="A5.p1.1.1">Geometry3K</span> <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib15" title="">2021</a>)</cite> dataset (<span class="ltx_text ltx_font_italic" id="A5.p1.1.2">48 problems</span>) utilized in Sketchpad, we incorporate the D2 subset of Geomverse <cite class="ltx_cite ltx_citemacro_cite">Kazemi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib11" title="">2023</a>)</cite> to construct an slightly bigger dataset <span class="ltx_text ltx_font_bold" id="A5.p1.1.3">Geomverse-109</span> (<span class="ltx_text ltx_font_italic" id="A5.p1.1.4">90 problems</span>). The original Geomverse dataset crucially includes annotated point coordinates essential for systematic problem synthesis. During the data synthesis phase, we first randomly choose 109 problems, then LVLMs generate corresponding high-quality Python code through LLM self-reflection <cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.09130v1#bib.bib22" title="">2023</a>)</cite>, then we filter out problems with poor diagram quality.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Apr 12 08:35:59 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
