{"importance": "This paper introduces RewardRanker, enhancing code generation by combining code generation model with a reranker model, and demonstrates effectiveness through strong experimental results and a novel iterative self-training approach. This approach allows smaller models to outperform larger ones and has comparable performance to GPT-4.", "summary": "RewardRanker: A novel self-training approach leveraging PPO to refine code generation by improving reranking accuracy.", "takeaways": ["RewardRanker, a novel approach for reward model optimization, refines code reranking through iterative self-training, enhancing precision and code generation quality.", "The approach enables smaller models to outperform larger ones, offering a resource-efficient solution for high code generation and reranking performance.", "Training with correct and hard negative examples improves model generalization and reranking decisions across coding tasks."], "tldr": "Current decoder-based models often produce stochastic outputs, leading to challenges in generating high-quality code for complex programming tasks. Even minor errors can break the entire solution, but leveraging multiple sampled solutions can significantly improve the overall output quality. Code generation can be enhanced by pairing a code generation model with a reranker model, which selects the best solution from the generated samples.\n\nTo solve the issue, this paper introduces **RewardRanker**, a novel iterative self-training approach for self-training reranker models using Proximal Policy Optimization (PPO). This method improves both reranking accuracy and the overall code generation process. The model refines the training dataset by re-evaluating outputs and incorporating high-scoring negative examples. Evaluation on the MultiPL-E dataset shows that RewardRanker outperforms larger models and is faster, achieving performance comparable to GPT-4.", "affiliation": "MTS AI", "categories": {"main_category": "Natural Language Processing", "sub_category": "Text Generation"}, "podcast_path": "2504.09643/podcast.wav"}