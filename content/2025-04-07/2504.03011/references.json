{"references": [{"fullname_first_author": "Leon A Gatys", "paper_title": "Image style transfer using convolutional neural networks", "publication_date": "2016-01-01", "reason": "This paper is a foundation for many style transfer techniques, which are used in the guided refinement process of this comprehensive relighting approach."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This paper is the original work on NeRF which enables novel view synthesis under varying lighting conditions in videos; this is relevant as the human body is an integral part of a scene."}, {"fullname_first_author": "Phillip Isola", "paper_title": "Image-to-image translation with conditional adversarial networks", "publication_date": "2017-01-01", "reason": "This paper provides the basis for image-to-image translation used in background harmonization, a key aspect of the Comprehensive Relighting work."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-01-01", "reason": "This paper introduces latent diffusion models, which are used as a general image prior in this Comprehensive Relighting model."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper builds on diffusion models and uses ControlNet for applying spatial control for human relighting."}]}