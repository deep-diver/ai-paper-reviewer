{"references": [{"fullname_first_author": "Abe Davis", "paper_title": "The visual microphone: Passive recovery of sound from video", "publication_date": "2014-01-01", "reason": "This paper introduces the concept of recovering sound from subtle vibrations in video, laying the foundation for the field and is used as a primary baseline in the paper."}, {"fullname_first_author": "Charles Dorn", "paper_title": "Efficient full-field vibration measurements and operational modal analysis using neuromorphic event-based imaging", "publication_date": "2018-07-01", "reason": "As a foundational work in event-based visual vibration analysis, this paper is directly relevant to the methodology used in the current work, providing a comparative baseline."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "publication_date": "2023-12-01", "reason": "This paper is a core component of the proposed method for temporal modeling, which is key to their approach in recovering sound information."}, {"fullname_first_author": "A Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "The attention mechanism, which is introduced in this paper, serves as the base for the spatial aggregation block used by the author, and is critical to the method used in the new study."}, {"fullname_first_author": "Yi Luo", "paper_title": "Conv-TasNet: Surpassing ideal time-frequency magnitude masking for speech separation", "publication_date": "2019-08-01", "reason": "This work is important because the Scale-invariant source-to-noise ratio (SISNR) loss described here is a key component of the loss function used to train the model."}]}