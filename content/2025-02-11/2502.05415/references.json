{"references": [{"fullname_first_author": "Jonathan Heek", "paper_title": "Multistep consistency models", "publication_date": "2024-03-06", "reason": "This paper proposes a refined consistency distillation method that improves model convergence and accelerates diffusion models, which is directly relevant to the core method of Show-o Turbo."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-03-01", "reason": "This is a foundational paper introducing the concept of consistency distillation for diffusion model acceleration, providing inspiration for the main method of Show-o Turbo."}, {"fullname_first_author": "Siqi Kou", "paper_title": "CLLMs: Consistency large language models", "publication_date": "2024-03-01", "reason": "This paper extends consistency distillation to large language models (LLMs), which shares similarities with Show-o Turbo's approach for multimodal models."}, {"fullname_first_author": "Jinheng Xie", "paper_title": "Show-o: One single transformer to unify multimodal understanding and generation", "publication_date": "2024-08-12", "reason": "This is the main reference to Show-o, which serves as the foundation for Show-o Turbo and is the primary target for acceleration."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This is a highly influential work on high-resolution image synthesis using diffusion models, providing background information for the image generation aspect of Show-o and Show-o Turbo."}]}