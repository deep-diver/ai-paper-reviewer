{"references": [{"fullname_first_author": "Saaket Agashe", "paper_title": "Agent S: an open agentic framework that uses computers like a human.", "publication_date": "2024-10-08", "reason": "This paper introduces Agent S, an open agentic framework that uses computers like a human, which serves as a foundation for the current research and is frequently referenced throughout the document."}, {"fullname_first_author": "Tianbao Xie", "paper_title": "Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments.", "publication_date": "2024-04-07", "reason": "This paper introduces the OSWorld benchmark, which is the primary environment used for evaluating the proposed Agent S2 and is thus very important."}, {"fullname_first_author": "Yujia Qin", "paper_title": "UI-TARS: pioneering automated GUI interaction with native agents.", "publication_date": "2025-01-12", "reason": "This paper introduces UI-TARS, a significant baseline for computer use agents, and the UI-TARS-72B-DPO model is utilized as the visual grounding expert in Agent S2."}, {"fullname_first_author": "Rogerio Bonatti", "paper_title": "Windows agent arena: Evaluating multi-modal OS agents at scale.", "publication_date": "2024-09-08", "reason": "This paper introduces the WindowsAgentArena benchmark, one of the primary benchmarks used to evaluate Agent S2, and the Navi Agent result is used for comparison."}, {"fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents.", "publication_date": "2024-05-14", "reason": "This paper introduces the AndroidWorld benchmark, used to evaluate Agent S2's generalizability to smartphone use, and the results of other models from this paper are used for comparison."}]}