{"references": [{"fullname_first_author": "Agostinelli", "paper_title": "Musiclm: Generating music from text", "publication_date": "2023-01-01", "reason": "This paper is one of the pioneering works in text-to-music generation, providing a baseline for subsequent research, and is also used for evaluation in the current paper."}, {"fullname_first_author": "Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduced the Transformer architecture, which is fundamental to the SongGen model and many other sequence modeling tasks, particularly those based on cross-attention."}, {"fullname_first_author": "D\u00e9fossez", "paper_title": "High fidelity neural audio compression", "publication_date": "2022-10-01", "reason": "This paper presents an approach to audio compression, and X-Codec the improved codec has been used for the encoder and decoder."}, {"fullname_first_author": "Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces the T5 model, whose encoder is used for text conditioning."}, {"fullname_first_author": "Copet", "paper_title": "Simple and controllable music generation", "publication_date": "2024-01-01", "reason": "This paper offers a simple model for music generation that is based on transformer-based models, provides a baseline for the evaluation."}]}