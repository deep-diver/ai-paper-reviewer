[{"figure_path": "https://arxiv.org/html/2502.13347/x1.png", "caption": "Figure 1: Graph traverse process of a traditional graph-connectivity-based crawler (green) and Craw4LLM (red) starting from a same seed URL (star).", "description": "This figure illustrates the difference in web graph traversal between a traditional graph-connectivity-based crawler and the proposed CRAW4LLM method.  Both crawlers begin from the same seed URL (represented by a star). The traditional crawler (green) explores the web graph by prioritizing pages based on graph connectivity metrics (such as PageRank or harmonic centrality). This leads to a broad, but potentially inefficient, search of the web. Conversely, CRAW4LLM (red) prioritizes pages based on their relevance to LLM pretraining, focusing its search on a more targeted subset of web pages relevant for training large language models. This targeted approach is visualized by the red path which focuses on a smaller set of interconnected nodes.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.13347/x2.png", "caption": "(a) Pretraining (-0.11).", "description": "The figure shows the correlation between pretraining influence scores and indegrees on randomly sampled ClueWeb22-B documents.  Specifically, subplot (a) displays a weak negative correlation between pretraining influence scores and indegrees, indicating that documents with many incoming links are not necessarily the most influential for pretraining. The Spearman correlation coefficient is reported as -0.11, suggesting that a higher indegree does not strongly imply higher pretraining influence.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13347/x3.png", "caption": "(b) PageRank (0.88).", "description": "The figure shows the correlation between the pretraining influence scores and PageRank scores.  The scatter plot visually represents the relationship between these two metrics, calculated on a randomly sampled subset of documents from the ClueWeb22-B dataset. The Spearman correlation coefficient (0.88) indicates a strong positive correlation, suggesting that documents with high PageRank scores tend to also have high pretraining influence scores.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13347/x4.png", "caption": "Figure 2: Correlations between pretraining influence scores from DCLM fastText\u00a0(Li et\u00a0al., 2024) and PageRank to indegrees, on randomly sampled ClueWeb22-B documents\u00a0(Overwijk et\u00a0al., 2022). Spearman correlation coefficients are reported in parentheses.", "description": "This figure displays scatter plots illustrating the correlation between pretraining influence scores and other metrics on a subset of documents from the ClueWeb22-B dataset.  The pretraining influence scores are derived from the DCLM fastText model.  The plots visually compare the relationships between these scores and PageRank, as well as the relationship between PageRank and the number of inlinks (indegree). Spearman correlation coefficients are provided to quantify the strength of each correlation.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2502.13347/x5.png", "caption": "(a) Extended crawling.", "description": "This figure shows the efficiency of different crawling methods in achieving comparable performance to the oracle method. The x-axis represents the pool size (relative to the oracle), indicating how much more data the crawlers processed than the oracle. The y-axis shows the performance of the LLMs trained on the data collected by each crawler. CRAW4LLM achieves nearly the same performance as the oracle by crawling significantly less data, while the other methods, including extended indegree and random crawling, require much larger amounts of data to reach comparable performance.", "section": "4.2 Analysis"}, {"figure_path": "https://arxiv.org/html/2502.13347/x6.png", "caption": "(b) Visited documents.", "description": "Figure 3(b) shows the number of documents visited and crawled by the CRAW4LLM crawler and baseline crawlers (Indegree and Random).  It compares the number of documents crawled (P) to achieve a certain performance level against the number of documents visited (V) during the crawling process. This visualization highlights the efficiency of CRAW4LLM in achieving comparable performance with significantly fewer crawled and visited documents than traditional methods.", "section": "4.2 Analysis"}, {"figure_path": "https://arxiv.org/html/2502.13347/x7.png", "caption": "Figure 3: Efficiency of crawlers. (a) shows the performance of LLMs trained on selected data crawled by Craw4LLM and extended baseline crawlers. (b) presents the number of crawled (\ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P) and visited (\ud835\udcb1\ud835\udcb1\\mathcal{V}caligraphic_V) documents for Craw4LLM, along with the estimated number of crawled documents required for indegree-based crawler to match Craw4LLM\u2019s performance.", "description": "Figure 3 delves into the efficiency of different web crawling methods.  Subfigure (a) compares the performance of Large Language Models (LLMs) trained using data collected by Craw4LLM and traditional crawlers (extended baselines).  The traditional crawlers are extended to crawl more data in an attempt to match Craw4LLM's results. Subfigure (b) shows a quantitative comparison of the number of web pages crawled and visited by Craw4LLM versus the estimated number a traditional, indegree-based crawler would need to crawl to achieve similar LLM performance.  This demonstrates Craw4LLM's effectiveness in selecting high-quality data with far fewer crawls.", "section": "4.2 Analysis"}, {"figure_path": "https://arxiv.org/html/2502.13347/x8.png", "caption": "Figure 4: Precision (left) and recall (right) of the oracle documents among the documents crawled by Craw4LLM, indegree, and random crawler. The upper bound represents always crawling the oracle documents.", "description": "Figure 4 illustrates the effectiveness of CRAW4LLM in identifying high-quality documents for LLM pretraining.  The left panel shows the precision (the percentage of truly valuable documents among those identified by each method) while the right panel shows the recall (the percentage of valuable documents found by each method).  CRAW4LLM demonstrates high precision, quickly identifying nearly all the best documents.  In contrast, the indegree-based and random crawling methods perform significantly worse. The upper bound line represents a hypothetical ideal scenario where only the best documents are collected.", "section": "4.2 Analysis"}]