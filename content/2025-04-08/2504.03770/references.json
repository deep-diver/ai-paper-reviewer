{"references": [{"fullname_first_author": "Yi et al.", "paper_title": "Temporal coherent test-time optimization for robust video classification", "publication_date": "2023-02-14", "reason": "It explores test-time optimization to adapt models to distribution shifts during testing, which relates to the JAILDAM's dynamic adaptation strategy."}, {"fullname_first_author": "Wang et al.", "paper_title": "Cogvlm: Visual expert for pretrained language models", "publication_date": "2023-01-01", "reason": "It introduces CogVLM, a visual language model used for assessing defense performance, making it highly relevant for comparative experiments."}, {"fullname_first_author": "Liu et al.", "paper_title": "Visual instruction tuning", "publication_date": "2023-01-01", "reason": "It introduces LLaVA, an influential visual instruction tuning model used for experiments."}, {"fullname_first_author": "Radford et al.", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "It introduces CLIP (Contrastive Language-Image Pre-training), a core component of the JAILDAM framework for encoding visual and textual information."}, {"fullname_first_author": "Achiam et al.", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-01", "reason": "It utilizes GPT-4 for generating harmful concepts and guiding the detection process."}]}