[{"figure_path": "https://arxiv.org/html/2504.02882/x1.png", "caption": "Figure 1: Visualization of five internal states of TA-LLMs and state trajectories for three different query types. User queries are shown in green message bubbles, while other conversational turns are displayed in blue. OOT (Out-of-Tools) queries represent requests for functionality not available in the teal-colored \"Tools\" list. Slot-Filling QAs denote conversational turns aimed at gathering required fields for tool execution. Tool calls represent messages where the assistant invokes a tool, tool responses show the returned execution results, and completion messages demonstrate the assistant\u2019s final response using the tool output. For optimal visualization of the state transitions and message types, we recommend viewing this figure in color. Icons from Flaticon222http://www.flaticon.comare used in this diagram.", "description": "This figure visualizes the five internal states a tool-augmented large language model (TA-LLM) can be in during a conversation and how these states connect to create different conversational flows (trajectories) for three different types of user queries.  The states are represented by colored bubbles: green for user queries, blue for other conversational turns, and teal for the 'Tools' list (showing tools available to the system).  The diagram shows how the TA-LLM transitions between states, depending on whether it needs to ask for more information (slot filling), invoke a tool, or reject a tool call because no suitable tool exists for the given query.  Each trajectory shows the sequence of states visited during the conversation for each query type. The illustration highlights how the model determines whether to ask follow-up questions, make tool calls, or reject tool calls, showcasing its conversational control capabilities.", "section": "3 Preliminaries"}, {"figure_path": "https://arxiv.org/html/2504.02882/extracted/6322723/figures/subplot_horizontal.png", "caption": "Figure 2: Effects of hyperparameters on model performance metrics. (a) Impact of DPO regularization parameter (\u03b2\ud835\udefd\\betaitalic_\u03b2) ranging from 0.1 to 0.5. (b) Impact of reward scaling factor (\u03b3\ud835\udefe\\gammaitalic_\u03b3) from 0.1 to 0.9. (c) Impact of reward gap margin (\u03c1\ud835\udf0c\\rhoitalic_\u03c1) from 0 to 5. All experiments measure six different performance metrics: call accuracy, completion accuracy, slot accuracy, relevance accuracy, and micro/macro-averaged scores.", "description": "This figure displays the effects of three hyperparameters (\u03b2, \u03b3, \u03c1) on the performance of a model.  Each hyperparameter is varied across a range of values, and the resulting performance is measured using six metrics: call accuracy, completion accuracy, slot accuracy, relevance accuracy, micro-averaged score, and macro-averaged score.  Subplots (a), (b), and (c) show the impact of \u03b2, \u03b3, and \u03c1 respectively. The results illustrate how adjusting these hyperparameters can affect the model's performance across multiple dimensions.", "section": "6 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.02882/x2.png", "caption": "Figure 3: Comparison of responses between SFT-Only and SFT + DiaTool-DPO models. The \u2018Messages\u2019 shows the user\u2019s initial query, and \u2018Tools\u2019 presents the tool specification required to resolve the user\u2019s query. For brevity, we omit the remaining 4-6 candidate tools in Tools.\nWhile the tool specification includes \u2018min\u2019 and \u2018max\u2019 as required fields, the user only specifies the \u2018min\u2019 value in the query. The SFT-Only model proceeds to call the tool using only the min value, whereas SFT + DiaTool-DPO model engages in slot-filling by asking for the missing \u2018max\u2019 value.", "description": "This figure compares the responses of two different models, SFT-Only and SFT + DiaTool-DPO, to a user query that requires a tool call.  The 'Messages' section displays the conversation between the user and each model. The 'Tools' section shows the available tools and their specifications, including required parameters. The user's query only provides the minimum value for the input range ('min'), while the tool requires both minimum and maximum values ('min' and 'max'). The SFT-Only model ignores the missing 'max' value and proceeds with the tool call using only the provided 'min' value. In contrast, the SFT + DiaTool-DPO model demonstrates more robust behavior by engaging in slot-filling; it asks the user for the missing 'max' value before initiating the tool call.", "section": "6 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.02882/x3.png", "caption": "Figure 4: Comparison of responses between SFT-Only and SFT + DiaTool-DPO models. The \u2018Messages\u2019 shows the user\u2019s initial query, and \u2018Tools\u2019 presents the tool specification required to resolve the user\u2019s query. For brevity, we omit the remaining 4-6 candidate tools in Tools.\nWhile the tool specification lists \u2018amount\u2019, \u2018from_currency\u2019, and \u2018to_currency\u2019 as required fields, the user\u2019s query lacks the \u2018amount\u2019 information. The SFT-Only model hallucinates a value of 1,000 for the amount field, whereas the SFT + DiaTool-DPO model engages in slot-filling by asking a question to determine the missing amount value.", "description": "This figure compares the responses of two models, one trained with only supervised fine-tuning (SFT) and another trained with SFT and the DiaTool-DPO method, to a user query requiring a currency conversion.  The tool requires 'amount', 'from_currency', and 'to_currency' as inputs. The user's query omits the 'amount'.  The SFT-only model incorrectly assumes an amount of 1000, while the SFT + DiaTool-DPO model correctly engages in a slot-filling dialogue to obtain the missing information from the user. This highlights DiaTool-DPO's ability to handle incomplete queries.", "section": "6 Experiments"}, {"figure_path": "https://arxiv.org/html/2504.02882/x4.png", "caption": "Figure 5: Comparison of responses between SFT-Only and SFT + DiaTool-DPO models. The \u2018Messages\u2019 shows the user\u2019s initial query, and \u2018Tools\u2019 presents the tool specification required to resolve the user\u2019s query. For brevity, we omit the remaining 4-6 candidate tools in Tools. While the tool specification lists \u2018bill_amount\u2019 and \u2018tip_percentage\u2019 as required fields, the user\u2019s query does not specify the \u2018tip_percentage\u2019. The SFT-Only model generates a comment assuming a 10% tip percentage, whereas the SFT + DiaTool-DPO model generates a slot-filling question to determine the tip percentage value.", "description": "This figure compares the responses of two different models, one trained using only supervised fine-tuning (SFT) and another trained using SFT combined with the DiaTool-DPO method.  The user asks to calculate a tip given a bill amount, but omits the necessary tip percentage.  The SFT-only model assumes a 10% tip without asking for clarification, while the SFT + DiaTool-DPO model correctly identifies the missing information and requests the tip percentage from the user, demonstrating the improvement in handling incomplete user queries.", "section": "6 Experiments"}]