[{"figure_path": "https://arxiv.org/html/2504.04155/extracted/6338362/Workflow.png", "caption": "Figure 1: Workflow of GlotEval", "description": "This figure illustrates the workflow of the GlotEval framework.  It starts with the user selecting benchmarks and languages for evaluation.  The system then loads the relevant data and applies the chosen prompting strategy (single or multilingual).  Model inference is performed using an appropriate backend (Hugging Face Transformers or vLLM, depending on task type), and finally, evaluation metrics are computed and results visualized.", "section": "3 GlotEval"}, {"figure_path": "https://arxiv.org/html/2504.04155/extracted/6338362/Data_loader.png", "caption": "Figure 2: GlotEval benchmark data loader", "description": "The GlotEval benchmark data loader is a key component of the GlotEval framework, responsible for managing and processing data from various multilingual benchmarks.  It takes as input a user's choices for benchmarks and languages.  It then retrieves data from a prompt library (containing language-specific prompt templates), aligns benchmark language identifiers to the unified ISO 639-3 format, and prepares multilingual prompts.  The loader also integrates with different model backends depending on the task type (generative or non-generative).  The final output is processed data ready for model inference and evaluation. The figure visually depicts the workflow and highlights the language ID alignment and multilingual prompt builder processes.", "section": "3 GlotEval"}, {"figure_path": "https://arxiv.org/html/2504.04155/extracted/6338362/Component_A.png", "caption": "(a)", "description": "This figure shows the language ID alignment process within the GlotEval benchmark data loader.  It illustrates how GlotEval unifies inconsistent language codes from various benchmarks into a standardized ISO 639-3_Script format.  The process involves using the iso639-lang Python package to map different language codes to their ISO 639-3 equivalents and identifying the dominant script using the GlotScript library. The result is a consistent language identification system used across all benchmarks.", "section": "3.3 A Deeper Look in Benchmark Data Loader"}, {"figure_path": "https://arxiv.org/html/2504.04155/extracted/6338362/Component_B.png", "caption": "(b)", "description": "This figure shows the multilingual prompt builder component of the GlotEval benchmark data loader.  It illustrates how a single prompt template in one language (e.g., English) is translated into multiple languages (130+) using Microsoft Translator. The resulting translated prompts, aligned with language and script codes, are stored in a multilingual prompt library for easy access during evaluation. This allows for language-specific evaluations by running the same tasks with prompts tailored to the language being evaluated.", "section": "3.3 A Deeper Look in Benchmark Data Loader"}, {"figure_path": "https://arxiv.org/html/2504.04155/extracted/6338362/Translation.png", "caption": "Figure 3: Benchmark data loader components: (a) Language ID alignment process and (b) multilingual prompt generation.", "description": "Figure 3 illustrates the two main components of GlotEval's benchmark data loader.  (a) shows the language ID alignment process, where GlotEval standardizes language codes from different benchmarks into a unified ISO 639-3 format to ensure consistent language identification across datasets.  (b) depicts the multilingual prompt generation process, which uses Microsoft Translator to automatically create and adapt prompt templates for different languages based on a single source language prompt. This ensures consistent, language-specific evaluation across all supported languages.", "section": "3 GlotEval"}]