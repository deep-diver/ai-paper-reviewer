[{"figure_path": "https://arxiv.org/html/2503.11849/x1.png", "caption": "Figure 1: Overview of our efforts towards a unified Copernicus foundation model, from pretraining to benchmarking.", "description": "This figure illustrates the overall architecture of the proposed unified Copernicus foundation model for Earth vision.  It starts with a massive pretraining dataset called Copernicus-Pretrain, which integrates data from various Copernicus Sentinel missions, encompassing the Earth's surface and atmosphere. This data is used to train the Copernicus-FM foundation model, designed for processing diverse sensor modalities (spectral or non-spectral) using dynamic hypernetworks.  Finally, this model is evaluated on a comprehensive benchmark, Copernicus-Bench, which includes various downstream tasks across multiple Sentinel missions.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.11849/x2.png", "caption": "Figure 2: Schematic of the Copernicus-Pretrain dataset. N\ud835\udc41Nitalic_N is the number of local patches. Grid cells are upscaled for ease of visualization.", "description": "This figure illustrates the structure of the Copernicus-Pretrain dataset, a crucial component of the research.  The dataset is composed of 0.25\u00b0 \u00d7 0.25\u00b0 grid cells covering the globe. Each grid cell contains multiple aligned images from various Copernicus Sentinel missions, including Sentinel-1 (SAR), Sentinel-2 (multispectral), Sentinel-3 (multispectral), Sentinel-5P (atmospheric), and a digital elevation model (DEM).  The 'N' in the caption represents the number of image patches extracted from each grid cell, reflecting the varying resolutions and data density across different sensors. The grid cells are shown upscaled in the figure for better visualization, as the actual resolution of individual grid cells are much finer.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/union_dist_new.png", "caption": "Figure 3: Global distribution of the Copernicus-Pretrain dataset.", "description": "The figure displays a world map illustrating the global distribution of the Copernicus-Pretrain dataset.  The color intensity indicates the density of data points, with darker regions representing areas with more data samples and lighter regions indicating areas with fewer samples.  This visualization helps to understand the geographical coverage and data density of the dataset, which is crucial for evaluating the representativeness and potential biases of the training data used for developing Earth Observation foundation models.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x3.png", "caption": "Figure 4: The general pretraining pipeline of Copernicus-FM. One image for each modality is sampled from a common grid cell in Copernicus-Pretrain, which is then patchified with kernel weights generated by the spectral or variable hypernetwork, based on the modality\u2019s spectral response or variable name. Further, Fourier-encoded metadata encodings are incorporated into the patch tokens. We conduct masked image modeling with auxiliary continual distillation for pretraining: masking and reconstructing masked-out patches for each modality, and distilling S1/2 or S2-derived RGB representations from powerful specialized teachers such as DINOv2\u00a0[48].", "description": "The figure illustrates the training process of the Copernicus-FM model.  The model takes as input images from various Copernicus Sentinel missions (S1-S5P, DEM) sampled from a common grid cell. These images are first processed using dynamic hypernetworks to generate patch embeddings specific to the modality (spectral response for spectral data, or variable name for non-spectral data). Then, metadata (geolocation, area, and time) is incorporated using Fourier encodings. Masked Image Modeling (MIM) is employed, masking out parts of the input and training the model to reconstruct these masked parts.  Simultaneously, auxiliary continual distillation is used by training the model to produce outputs similar to those from powerful teacher models such as DINOv2, trained on a subset of the data (RGB images derived from S1/S2).", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/x4.png", "caption": "Figure 5: Dynamic patch embedding (left) and metadata integration (right) of Copernicus-FM.", "description": "This figure illustrates the architecture of Copernicus-FM, specifically focusing on two key components: dynamic patch embedding and metadata integration. The left panel details how the model processes different image modalities (e.g., Sentinel-1 SAR, Sentinel-2 multispectral) with varying spatial resolutions.  A hypernetwork dynamically generates kernel weights for a 2D convolution patch embedding layer, adapting to the unique spectral characteristics of each sensor. The right panel shows how metadata (geolocation, area, and time) is integrated into the model.  Fourier encoding converts metadata into vectors that are added to patch tokens, providing additional context to the model during processing. The use of a unified architecture allows the model to handle various modalities and metadata in a flexible and scalable manner.", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/joint_dist_new.png", "caption": "Figure 6: Global distribution of the joint subset of the Copernicus-Pretrain dataset.", "description": "This figure shows a world map highlighting the geographical distribution of the Copernicus-Pretrain dataset's \"joint subset\".  The \"joint subset\" refers to the portion of the dataset containing complete data from all eight Sentinel missions and the Copernicus DEM GLO-30, ensuring comprehensive coverage across various modalities. The map uses color intensity to represent the density of grid cells included in the joint subset, providing a visual representation of data coverage.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x5.png", "caption": "Figure 7: Histogram of local patch numbers for S1 and S2 (union).", "description": "This figure shows two histograms, one each for Sentinel-1 (S1) and Sentinel-2 (S2) data.  The histograms illustrate the distribution of the number of local image patches extracted from each of the 0.25\u00b0 x 0.25\u00b0 grid cells that compose the Copernicus-Pretrain dataset. The data shown represents the 'union' dataset, encompassing all grid cells with at least one sensor modality. The x-axis of each histogram shows the number of local patches and the y-axis shows the number of grids containing that many patches.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x6.png", "caption": "Figure 8: Histogram of local patch numbers for S1 and S2 (joint).", "description": "This histogram shows the distribution of the number of local image patches within each of the 0.25\u00b0 x 0.25\u00b0 grid cells for Sentinel-1 (S1) and Sentinel-2 (S2) data.  The data used is the 'joint' subset of the Copernicus-Pretrain dataset, which means only grid cells containing data from all available sensor modalities are included. The x-axis represents the number of patches and the y-axis represents the number of grid cells with that many patches.  The figure helps visualize the patch density variability across different regions in the dataset.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x7.png", "caption": "Figure 9: Histogram of time series lengths for S1 and S2 (union).", "description": "This figure shows the distribution of time series lengths for Sentinel-1 (S1) and Sentinel-2 (S2) data within the Copernicus-Pretrain dataset. The term 'union' signifies that this analysis includes all available data, regardless of whether a specific grid cell contains data from all sensor modalities.  The histograms display the frequency of different time series lengths, providing insights into data availability and temporal coverage for both sensors.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x8.png", "caption": "Figure 10: Histogram of time series lengths for S1 and S2 (joint).", "description": "This figure shows two histograms illustrating the distribution of time series lengths for Sentinel-1 (S1) and Sentinel-2 (S2) data within the 'joint' subset of the Copernicus-Pretrain dataset.  The 'joint' subset contains only grid cells where all eight data modalities are available.  Each histogram displays the frequency of different time series lengths (number of observations over time), providing insights into the temporal coverage consistency for each sensor within this specific subset of the dataset.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x11.png", "caption": "Figure 11: Histogram of time series lengths for S3 (left: union; right: joint).", "description": "This figure shows two histograms that visualize the distribution of time series lengths for Sentinel-3 data.  The left histogram displays the data from the full Copernicus-Pretrain dataset (referred to as 'union'), while the right histogram focuses on the subset of the data where all modalities are present ('joint'). Each bar represents a specific number of time stamps, and the height of each bar indicates how many Sentinel-3 data samples have that number of time stamps in the dataset. Comparing the two histograms allows for an understanding of how data completeness and availability changes when considering the full dataset versus a more restricted dataset where all modalities are included.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x12.png", "caption": "Figure 12: Histogram of time series lengths for S5P (union).", "description": "This figure shows the distribution of the number of time series observations available for each grid cell across various Sentinel-5P atmospheric variables (CO, NO2, SO2, and O3) in the Copernicus-Pretrain dataset.  The dataset is called 'union' because it includes all grid cells with at least one available sensor modality. The x-axis represents the number of time stamps (months) and the y-axis represents the number of grid cells with that many observations. This visualization helps to understand the temporal coverage of the Sentinel-5P data within the Copernicus-Pretrain dataset and can inform the choices for model training.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/fourier_encoding_vis.png", "caption": "Figure 13: Histogram of time series lengths for S5P (joint).", "description": "This figure presents histograms showing the distribution of time series lengths for each of the four atmospheric variables (CO, NO2, SO2, and O3) from the Sentinel-5P mission within the Copernicus-Pretrain dataset.  The data shown represents only the subset of data where all eight modalities are available for each grid cell. The x-axis shows the number of time stamps and the y-axis shows the number of grid cells.", "section": "3. Copernicus-Pretrain"}, {"figure_path": "https://arxiv.org/html/2503.11849/x13.png", "caption": "Figure 14: Fourier encoding visualization for wavelengths and bandwidths of S2 and S1.", "description": "This figure visualizes the Fourier encoding of wavelengths and bandwidths used in the Copernicus-FM model for Sentinel-2 (S2) and Sentinel-1 (S1) data.  The Fourier encoding transforms the wavelength and bandwidth values into higher-dimensional vectors which are used to dynamically generate the kernel weights for patch embedding within the model. The visualization helps illustrate how the model represents spectral information, enabling it to process different spectral sensors in a unified architecture.", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/fourier_encoding_location.png", "caption": "Figure 15: t-SNE visualization of the language encodings of different variable names.", "description": "This t-SNE plot visualizes how a large language model (LLM) encodes different variable names used in the Copernicus-Pretrain dataset.  The plot shows the relative distances between these encoded names in a lower-dimensional space.  Variables with similar semantic meanings or relationships are clustered closer together, while dissimilar ones are further apart.  This visualization demonstrates the LLM's ability to capture the semantic relationships between the different variables, suggesting that it can effectively integrate metadata information into the Copernicus-FM model.", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/x22.png", "caption": "Figure 16: Fourier encoding visualization for geolocation (longitudes and latitudes).", "description": "This figure visualizes the Fourier encoding applied to geolocation data (longitude and latitude).  It shows how these geographical coordinates are transformed into a multi-dimensional vector representation using a Fourier encoding technique. The visualization helps illustrate how the encoding captures the spatial relationships and variations across different geographic locations, enabling the model to effectively learn representations sensitive to location.", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/x25.png", "caption": "Figure 17: Fourier encoding visualization for area (left) and time (right).", "description": "This figure visualizes the Fourier encoding of area and time metadata used in the Copernicus-FM model.  The left panel shows the Fourier encoding for area, while the right panel displays the Fourier encoding for time.  The color intensity represents the magnitude of the encoding vector, demonstrating how different values of area and time are represented within the model's embedding space.", "section": "4. Copernicus-FM"}, {"figure_path": "https://arxiv.org/html/2503.11849/x31.png", "caption": "Figure 18: Copernicus-Bench-Cloud-S2.", "description": "This figure shows example images and their corresponding cloud masks from the Copernicus-Bench Cloud-S2 dataset.  The dataset is a subset of the CloudSEN12+ dataset and contains Sentinel-2 multispectral imagery with labels indicating cloud and cloud shadow. The images illustrate the diverse cloud cover conditions present in the dataset, including varying degrees of cloud cover and shadow.", "section": "5. Copernicus-Bench"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/climate_pred.png", "caption": "Figure 19: Copernicus-Bench-Cloud-S3. Left: \u201cmulti-class\u201d mode. Right: \u201cbinary\u201d mode.", "description": "This figure shows a comparison of the cloud segmentation results obtained from the Copernicus-Bench-Cloud-S3 dataset using two different approaches: a multi-class model and a binary classification model. The left side displays the results of the multi-class model, indicating multiple types of clouds and cloud-related features (e.g., clear, cloud-sure, cloud ambiguous, cloud shadow, snow-ice). The right side shows the results of the binary model, providing a simpler classification, distinguishing only between cloud/non-cloud. The images illustrate the difference in granularity and detail provided by the two models.", "section": "5. Copernicus-Bench"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/climate_error.png", "caption": "Figure 20: Copernicus-Bench-EuroSAT-S1 and Copernicus-Bench-EuroSAT-S2.", "description": "This figure displays sample images from the EuroSAT-S1 and EuroSAT-S2 datasets within the Copernicus-Bench benchmark.  EuroSAT-S1 provides synthetic aperture radar (SAR) imagery, while EuroSAT-S2 offers multispectral imagery.  The figure showcases the visual differences between these two data modalities for the same geographic location. This visual comparison is helpful in understanding the contrast between the information captured by different sensor types. Each image is labeled with the corresponding land cover class.", "section": "5. Copernicus-Bench"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/climate_std_pred.png", "caption": "Figure 21: Copernicus-Bench-BigEarth-S1 and Copernicus-Bench-BigEarth-S2.", "description": "This figure displays sample images from the BigEarthNet-S1 and BigEarthNet-S2 datasets, which are part of the Copernicus-Bench benchmark.  BigEarthNet-S1 provides SAR imagery, while BigEarthNet-S2 offers multispectral data. The images are paired, showing the same geographical location but with different spectral properties. The corresponding ground truth labels for land cover classification are also shown, illustrating the variety of land cover types present in the datasets.", "section": "5. Copernicus-Bench"}, {"figure_path": "https://arxiv.org/html/2503.11849/extracted/6281005/figures/appendix/climate_std_error.png", "caption": "Figure 22: Copernicus-Bench-LC100Cls-S3 and Copernicus-Bench-LC100Seg-S3. By default we pick one image per time series as \u201cstatic\u201d mode.", "description": "This figure displays sample images from the Copernicus-Bench dataset, specifically focusing on the LC100Cls-S3 and LC100Seg-S3 datasets.  These datasets utilize Sentinel-3 OLCI images and Copernicus Global Land Service (CGLS) land cover maps for classification and segmentation tasks. The images illustrate the multi-temporal aspect of the data, showing multiple images from a time series per location. The caption notes that by default, only one image per time series (the 'static' mode) is used for each location in the benchmark.", "section": "5. Copernicus-Bench"}]