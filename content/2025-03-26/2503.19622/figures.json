[{"figure_path": "https://arxiv.org/html/2503.19622/x1.png", "caption": "Figure 1: Construction protocol of HAVEN. The left section outlines the three dimensions of data construction and the associated categories within each, while the right section details the evaluation process and metrics.", "description": "This figure illustrates the construction protocol used to create the HAVEN benchmark dataset for evaluating hallucinations in large multimodal models for video understanding.  The left side shows the three dimensions used to categorize the data: hallucination causes (conflict with prior knowledge, in-context conflict, capability deficiency), hallucination aspects (object, scene, event), and question format (binary-choice, multiple-choice, short-answer). Each dimension has several sub-categories, visualized in the diagram. The right side displays the evaluation process and metrics used, which involves using an LLM (Large Language Model) to judge the correctness of the model's responses and calculating metrics such as the hallucination rate and consistency.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x2.png", "caption": "(a) Duration Time", "description": "This figure shows the distribution of video durations in the HAVEN benchmark dataset. The x-axis represents the duration of videos in seconds, and the y-axis represents the frequency or count of videos with that duration. The histogram visually depicts the concentration of video lengths in the dataset, providing insights into the temporal characteristics of the videos used for evaluating LMMs.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x3.png", "caption": "(b) Frame Count", "description": "The figure shows a histogram representing the distribution of the number of frames across different videos in the HAVEN benchmark dataset.  It visualizes the frequency with which videos of varying lengths (measured by frame count) are represented in the dataset. This helps to understand the range of video durations considered and the potential impact of video length on the results of the hallucination evaluation.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x4.png", "caption": "(c) Question Length", "description": "This histogram shows the distribution of the number of tokens in the questions used in the HAVEN benchmark.  The x-axis represents the number of tokens, and the y-axis shows the frequency of questions with that token count.  It illustrates the length distribution of the questions, indicating the complexity and detail level of the queries.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x5.png", "caption": "Figure 2: Distribution of duration time, frame count, and question length.", "description": "This figure presents three histograms showing the distributions of duration time, frame count, and question length in the HAVEN dataset.  The duration time histogram shows that most videos are relatively short, with a significant peak between 0 and 20 seconds.  The frame count histogram indicates that the majority of videos have between 0 and 400 frames. Finally, the question length histogram demonstrates the distribution of the number of tokens in each question, highlighting that the majority of questions are concise, with the number of tokens typically ranging from 10 to 15.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x6.png", "caption": "Figure 3: Question format distribution. Percentage share of each format-binary-choice (T/F), multiple-choice (MC), and short-answer (SA)\u2014and the proportion occupied by the detailed answer.", "description": "This figure shows the distribution of question types in the HAVEN benchmark dataset.  It visually represents the percentage of questions that fall into each of three categories: binary-choice (True/False), multiple-choice, and short-answer.  Furthermore, it indicates the proportion of questions within each category for which detailed answers were provided.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x7.png", "caption": "(a) Duration Time", "description": "This figure shows the distribution of video durations in the HAVEN benchmark dataset. The x-axis represents the duration of videos in seconds, and the y-axis represents the frequency or count of videos with that duration. The histogram visually displays the concentration of video durations within the dataset, revealing whether the dataset contains mostly short videos, long videos, or a mix of both.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x8.png", "caption": "(b) Frame Count", "description": "The figure shows the distribution of the number of frames in videos used in the HAVEN benchmark.  The x-axis represents the number of frames, and the y-axis represents the frequency or count of videos with that number of frames.  The histogram visually displays the frequency distribution, showing how many videos contain a specific number of frames. This information is important for understanding the characteristics of the video dataset used in evaluating large multimodal models.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x9.png", "caption": "(c) Question Length", "description": "This figure shows the distribution of the number of tokens in the questions used in the HAVEN benchmark.  The x-axis represents the number of tokens, and the y-axis represents the frequency or count of questions with that token length. The distribution shows that most questions have a length between 20 and 30 tokens.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x10.png", "caption": "Figure 4: The impact of video duration, frame count, and question length on LLM hallucination.", "description": "This figure visualizes the effects of video duration, frame count, and question length on the accuracy of Large Language Models (LLMs) in video understanding tasks.  Each subplot shows a heatmap illustrating the relationship between one of these factors and the LLM's accuracy in avoiding hallucinations.  The x-axis represents the value of the factor (duration, frame count, or question length), and the y-axis represents the accuracy, which is likely a percentage or a similar metric reflecting the correctness of the LLM's answers.  The heatmap's color intensity shows the strength of the relationship - warmer colors represent higher accuracy (less hallucination), while cooler colors indicate lower accuracy (more hallucination).  The figure helps to understand how these factors influence the performance of LLM models in avoiding incorrect responses.", "section": "4. Analysis of Video Hallucination"}, {"figure_path": "https://arxiv.org/html/2503.19622/x11.png", "caption": "(a) Causes-Aspects", "description": "This heatmap visualizes the relationship between hallucination causes and aspects in a video understanding task.  The three causes of hallucination are conflict with prior knowledge, in-context conflict, and capability deficiency. The three aspects are object, scene, and event. Each cell in the heatmap represents the accuracy (percentage) of model responses for a specific combination of cause and aspect.  For instance, a high value in the cell corresponding to 'Prior Conflict' and 'Object' indicates high model accuracy when the hallucination is due to prior knowledge conflict and relates to an object in the video.", "section": "3.5 Evaluation Metrics"}, {"figure_path": "https://arxiv.org/html/2503.19622/extracted/6308336/fram.png", "caption": "(b) Formats-Aspects", "description": "This heatmap visualizes the accuracy of Large Multimodal Models (LMMs) in video understanding tasks, broken down by question format and hallucination aspect.  The x-axis represents the three question formats used in the HAVEN benchmark: True/False (T/F), Multiple Choice (MC), and Short Answer (SA). The y-axis represents the three hallucination aspects: Object, Scene, and Event. Each cell in the heatmap shows the average accuracy across all models for that specific combination of question format and hallucination aspect. This allows for a detailed analysis of model performance across different question types and the types of hallucinations they struggle with.", "section": "3. HAVEN Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.19622/x12.png", "caption": "(c) Formats-Causes", "description": "This heatmap visualizes the relationship between question formats (binary-choice, multiple-choice, short-answer) and hallucination causes (prior knowledge conflict, in-context conflict, capability deficiency) in terms of model accuracy.  Each cell represents the average accuracy across all models for a specific combination of question format and hallucination cause.  It provides a concise overview of how different question types and hallucination sources affect model performance, allowing for a comparison of accuracy across different scenarios. Warmer colors indicate higher accuracy.", "section": "3.5 Evaluation Metrics"}, {"figure_path": "https://arxiv.org/html/2503.19622/x13.png", "caption": "Figure 5: Accuracy heatmap along two dimensions.", "description": "This figure presents three heatmaps, each visualizing the accuracy of Large Multimodal Models (LMMs) across two dimensions.  The first heatmap shows accuracy based on the cause of hallucination (Prior Conflict, In-context Conflict, Capability Deficiency) and the aspect of hallucination (Object, Scene, Event). The second heatmap shows accuracy based on question format (True/False, Multiple-Choice, Short-Answer) and the aspect of hallucination. The third heatmap shows accuracy based on question format and the cause of hallucination.  The heatmaps use color intensity to represent accuracy, with warmer colors indicating higher accuracy.", "section": "3.5 Evaluation Metrics"}, {"figure_path": "https://arxiv.org/html/2503.19622/x14.png", "caption": "Figure 6: Relationship between number of sampling frames and model performance.", "description": "This figure visualizes the impact of the number of sampled frames on the performance of various large multimodal models (LMMs) in video understanding tasks.  It shows that increasing the number of sampled frames initially improves model accuracy, but beyond a certain point, the performance starts to decline.  The figure also displays the bias score for each model, showing the consistency of responses across different variants of the same question. The x-axis represents the number of sampled frames, and the y-axis shows the accuracy and bias scores for each model.", "section": "4.5 On Sampling Number of Frames"}, {"figure_path": "https://arxiv.org/html/2503.19622/x15.png", "caption": "(a) Hallucination", "description": "This figure visualizes the relationship between model size and the performance of different models on two metrics: hallucination and consistency.  The x-axis represents the model size, categorized into 3B, 7B, 13B, and 34B parameter models. The y-axis for the left graph shows accuracy, while the y-axis for the right graph shows bias score (a measure of consistency). For each model size category, multiple models are included, and the graph displays their mean accuracy and bias scores, along with standard deviation error bars. This visualization helps assess how model size impacts both hallucination rates (higher accuracy means lower hallucination) and consistency (lower bias score indicates higher consistency) in multimodal video understanding tasks.", "section": "4.6 On Model Size"}, {"figure_path": "https://arxiv.org/html/2503.19622/x16.png", "caption": "(b) Consistency", "description": "The figure visualizes the consistency evaluation results, specifically showcasing bias scores for different models across various sizes. Lower bias scores indicate better consistency in model responses.  It compares performance across different model sizes (3B, 7B, 13B, 34B parameters) for multiple model types, highlighting the relationship between model size and response consistency. ", "section": "4.3. Consistency Evaluation"}, {"figure_path": "https://arxiv.org/html/2503.19622/x17.png", "caption": "Figure 7: Relationship between model size and performance.", "description": "This figure visualizes the correlation between the size of large multimodal models (LMMs) and their performance on video understanding tasks, specifically focusing on reducing hallucinations.  It shows how accuracy and bias scores (indicating consistency of responses) change as the number of model parameters increases.  The plot includes regression lines for different model categories, highlighting overall trends despite some individual model variations.  Larger models generally exhibit higher accuracy and lower bias, suggesting a positive relationship between model scale and performance in mitigating hallucinations.", "section": "4.6 On Model Size"}]