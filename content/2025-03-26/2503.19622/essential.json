{"importance": "This paper is important for researchers because it introduces **HAVEN**, a novel benchmark to evaluate video understanding LMMs, addressing a critical gap in hallucination assessment. It offers **insights into the impact of various factors on model performance**, aiding in targeted improvements and mitigation strategies. The **thinking-based training approach** opens new avenues for enhancing LMMs' reasoning and reducing inaccuracies.", "summary": "HAVEN: A new benchmark to tackle the hallucination issue in video understanding of large multimodal models!", "takeaways": ["Introduces HAVEN, a comprehensive benchmark for evaluating hallucinations in video understanding LMMs.", "Identifies and analyzes key factors influencing hallucinations in LMMs, such as video length, question complexity, and model size.", "Proposes a video-thinking model with supervised reasoning fine-tuning and direct preference optimization to mitigate hallucinations."], "tldr": "Large multimodal models (LMMs) often produce incorrect responses that seem correct, a phenomenon called hallucination, which limits their reliability. This is especially challenging in video understanding due to the dynamic nature of video data compared to static images. Existing benchmarks mainly focus on image understanding and do not fully address the complexities of video content. Therefore, the paper introduces **HAVEN**, a new benchmark designed to evaluate the hallucination issue in video understanding. \n\nThe paper proposes a thinking-based training strategy to reduce hallucinations by enhancing the LMM's reasoning capabilities, dividing this strategy into two steps: supervised reasoning fine-tuning (SRFT) and thinking-based direct preference optimization (TDPO). Experiments on 16 LMMs using HAVEN reveal insights into factors affecting hallucination and demonstrate the effectiveness of the proposed training methodology. Results shows that it can improve the baseline by 7.65% in accuracy on hallucination evaluation and reduces the bias score by 4.5%.", "affiliation": "University of Chinese Academy of Sciences", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "2503.19622/podcast.wav"}