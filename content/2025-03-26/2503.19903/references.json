{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-03-05", "reason": "This paper introduced CLIP, a foundational model for vision-language pre-training, which is essential for the paper's approach to scaling vision pre-training."}, {"fullname_first_author": "Kaiming He", "paper_title": "Deep Residual Learning For Image Recognition", "publication_date": "2016-02-07", "reason": "This paper introduces ResNet architecture, a significant advancement in deep learning that serves as a basis for other models."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An Image Is Worth 16x16 Words: Transformers For Image Recognition At Scale", "publication_date": "2020-10-12", "reason": "This paper introduces the Vision Transformer (ViT) architecture, a key component used in this new model for feature extraction."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-24", "reason": "This paper presents LLaMA, an open language model that serves as a foundation for other models described in the paper."}, {"fullname_first_author": "Xiaohua Zhai", "paper_title": "Sigmoid Loss for Language Image Pre-Training", "publication_date": "2023-02-22", "reason": "This paper introduces SigLIP, a vision-language pre-training approach that provides a strong baseline model used as a foundation for the new work in the paper."}]}