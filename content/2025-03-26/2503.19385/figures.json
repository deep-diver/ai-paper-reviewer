[{"figure_path": "https://arxiv.org/html/2503.19385/x2.png", "caption": "Figure 1: Diverse applications of our inference-time scaling method. Our inference-time scaling method extends the capabilities of a pretrained flow model\u00a0[25] to generate images that more precisely align with user preferences. More computation during inference improves alignment, reducing Residual Sum of Squares (RSS) over time (top row). Our flow-based method outperforms diffusion models, even with five times fewer number of function evaluations (NFEs) (top-right).\nFor compositional text-to-image generation applications (\u201clogical\u201d, \u201ccomparison\u201d, \u201cspatial relation\u201d), we use the reward from VQAScore\u00a0[28] to ensure precise alignment with the input text, where the description is particularly challenging for typical text-to-image generative models to satisfy (see the results on the left side of each case).\nWe use the object detection score\u00a0[31] for the \"counting\" application and the aesthetic score\u00a0[44] for the \"aesthetic\" application.\nFor \u201cconcept erasure\u201d, the reward is the number of removed concepts computed using VLM\u00a0[3] queries.\nThe red box denotes the results of our method.", "description": "Figure 1 demonstrates the versatility of the proposed inference-time scaling method applied to a pretrained flow model.  The top row showcases how increased computational resources during inference (measured by Number of Function Evaluations, NFEs) lead to improved image generation more closely matching user preferences, as quantified by a reduction in Residual Sum of Squares (RSS). The top-right panel highlights the superiority of the flow-based approach over diffusion models, achieving comparable results with significantly fewer NFEs. The remaining panels illustrate applications to diverse tasks: compositional text-to-image generation (using VQAScore for reward), counting (using object detection scores), aesthetic image generation (using aesthetic scores), and concept erasure (using VLM to quantify removed concepts).  The red boxes indicate results produced using the novel method.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2503.19385/extracted/6307485/Figures/search_schematic/Methods_Schematic.png", "caption": "Figure 2: Comparison of Linear-SDE and VP-SDE. Starting from the same initial noise latent, we generate 50505050 samples using Linear-ODE, Linear-SDE, and VP-SDE.", "description": "This figure compares the sampling trajectories and resulting sample variance of three different methods: Linear-ODE, Linear-SDE, and VP-SDE.  All three methods start from the same initial noise latent.  Linear-ODE is deterministic, resulting in all samples collapsing to a single point. Linear-SDE introduces stochasticity, leading to some sample variance. VP-SDE utilizes a variance-preserving interpolant, resulting in significantly higher sample diversity and a wider spread of samples. This visually demonstrates how VP-SDE enhances the exploration of the sample space, which is crucial for effective inference-time scaling.", "section": "SDE-Based Generation Using Flow Models"}]