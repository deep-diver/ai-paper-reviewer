[{"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/round_performance_qwq_32b.png", "caption": "Figure 1: Benchmark performance of QwQ-32B using Multi-round Thinking.", "description": "This figure displays the performance of the QwQ-32B language model across four rounds of reasoning using the Multi-round Thinking approach.  It shows the accuracy (or pass@1 rate) on four different benchmarks: AIME 2024, MATH-500, GPQA-Diamond, and LiveCodeBench.  The bars represent the accuracy achieved at each round of reasoning, demonstrating the improvement in performance with each subsequent round.", "section": "3.2 Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/round_performance_R1.png", "caption": "Figure 2: Benchmark performance of DeepSeek-R1 using Multi-round Thinking.", "description": "This figure presents the performance comparison of DeepSeek-R1 model on four benchmarks (AIME 2024, MATH-500, GPQA Diamond, and LiveCodeBench) across two rounds of reasoning.  Round 1 shows the model's initial performance without multi-round thinking, while Round 2 demonstrates the improvement achieved by incorporating multi-round test-time thinking. Each benchmark is represented by a bar graph displaying the pass@1 accuracy. The results highlight the consistent improvement in accuracy after implementing the multi-round thinking approach.", "section": "3.2 Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/word_frequence_all.png", "caption": "Figure 3: Overall change in word frequency across all AIME 2024 examples.", "description": "This figure shows the overall change in frequency of four specific words (but, wait, maybe, therefore) from Round 1 to Round 2 of the Multi-round Thinking process across all examples from the AIME 2024 dataset.  It illustrates how the use of these words, indicative of uncertainty or hesitation versus decisiveness, changes as the model iteratively refines its reasoning.", "section": "3.2.2 Analysis of Word Frequency Changes"}, {"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/word_frequence_merge.png", "caption": "Figure 4: Changes in average word frequency across different reasoning trajectories. Each subplot shows the average frequency of four indicative words \u2014 but, wait, maybe, and therefore \u2014 in Round 1 vs. Round 2, grouped by response type:\nI-C (Incorrect \u2192 Correct), I-I (Incorrect \u2192 Incorrect), C-C (Correct \u2192 Correct), and C-I (Correct \u2192 Incorrect).", "description": "This figure analyzes how the usage frequency of four specific words ('but', 'wait', 'maybe', and 'therefore') changes between the first and second reasoning rounds of the Multi-round Thinking model.  The analysis is broken down by four categories of reasoning trajectories: I-C (Incorrect to Correct), I-I (Incorrect to Incorrect), C-C (Correct to Correct), and C-I (Correct to Incorrect). Each subplot in the figure represents one of these trajectory types, showing how frequently each of the four words appears in the model's reasoning process for that trajectory type in Round 1 versus Round 2. This helps to understand the model's shift in confidence and its reasoning process over multiple rounds.", "section": "3.2.2 Analysis of Word Frequency Changes"}, {"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/answer_length_variation.png", "caption": "Figure 5: Changes in response length across reasoning rounds on the AIME 2024 dataset (QwQ-32B model). Labels represent the correctness trajectory from Round 1 to Round 2: \u201cC\u201d = Correct, \u201cI\u201d = Incorrect. For example, \u201cC\u2013I\u201d indicates responses that were correct initially but became incorrect in the next round.", "description": "Figure 5 displays the changes in response length for the QwQ-32B model across multiple reasoning rounds on the AIME 2024 dataset.  The x-axis represents the different correctness trajectories from Round 1 to Round 2: C-C (correct in both rounds), C-I (correct in Round 1, incorrect in Round 2), I-C (incorrect in Round 1, correct in Round 2), and I-I (incorrect in both rounds). The y-axis shows the average response length (number of tokens) for each trajectory.  This figure helps visualize how the model's response length changes as it iteratively refines its answers and whether the changes are related to whether the answer is correct or incorrect.", "section": "3.2.3 Analysis of Response Length"}, {"figure_path": "https://arxiv.org/html/2503.19855/extracted/6309504/20250325-232442.jpeg", "caption": "Figure 6: Illustration of the \u201cThink Twice\u201d Strategy in Multi-round Reasoning.", "description": "The figure illustrates how the Think Twice method works.  The model initially provides an incorrect response based on flawed reasoning. Then, the Think Twice strategy prompts the model to reconsider its previous answer. In the second round of thinking, the model identifies and corrects its initial error, ultimately arriving at the correct solution. The example highlights the effectiveness of iterative reasoning and self-correction enabled by the Think Twice approach.", "section": "3 Experiments"}]