[{"figure_path": "https://arxiv.org/html/2504.06949/x1.png", "caption": "Figure 1: Illustration of Forgetting Attention with and without ACP. Each cell represents a block in the FlashAttention algorithm. Darker colors represent decay bias values farther below 00 and thus stronger decay. The arrows indicate the set of blocks that would be visited (in the indicated order) in the FlashAttention iterations.", "description": "Figure 1 illustrates the concept of Forgetting Attention, a mechanism in the Forgetting Transformer (FoX), and how Adaptive Computation Pruning (ACP) optimizes it.  The figure uses a visual representation of the FlashAttention algorithm, showing the computation as a grid of blocks.  Each block represents a calculation involving input-output dependencies. Darker colors indicate stronger decay (i.e., the forget gate significantly reduces the importance of the connection).  The left side shows a standard FlashAttention computation, visiting all blocks in sequence. The right side demonstrates ACP, showing how the algorithm identifies a 'pruning boundary' to skip calculations of less important dependencies (indicated by the lighter colors and the pruned blocks not visited). The arrows show the order of operations in each version of the algorithm, highlighting the significant reduction in computations achieved with ACP. This optimization enhances speed and efficiency without sacrificing performance.", "section": "1 Introduction"}]