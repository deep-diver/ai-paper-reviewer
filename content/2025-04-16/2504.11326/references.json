{"references": [{"fullname_first_author": "Haobo Yuan", "paper_title": "Sa2va: Marrying sam2 with llava for dense grounded understanding of images and videos.", "publication_date": "2025-01-04", "reason": "Sa2VA is used as the baseline for the MeViS Track in the PVUW 2025 challenge, and is cited numerous times throughout the paper."}, {"fullname_first_author": "Nikhila Ravi", "paper_title": "SAM 2: Segment anything in images and videos.", "publication_date": "2024-08-01", "reason": "SAM2 is a foundational model leveraged by many of the participating methods for both the MOSE and MeViS tracks, enabling strong generalization capabilities."}, {"fullname_first_author": "Henghui Ding", "paper_title": "MeViS: A large-scale benchmark for video segmentation with motion expressions.", "publication_date": "2023-01-01", "reason": "The MeViS dataset serves as the foundation of the MeViS track in the PVUW 2025 Challenge, making the corresponding paper on MeViS very important."}, {"fullname_first_author": "Henghui Ding", "paper_title": "MOSE: A new dataset for video object segmentation in complex scenes.", "publication_date": "2023-01-01", "reason": "The MOSE dataset serves as the foundation of the MOSE track in the PVUW 2025 Challenge, making the corresponding paper on MOSE very important."}, {"fullname_first_author": "Shilong Liu", "paper_title": "Grounding DINO: Marrying dino with grounded pre-training for open-set object detection.", "publication_date": "2024-01-01", "reason": "GroundingDINO is the base architecture behind ReferDINO and is mentioned in the description of the second-best MeViS solution."}]}