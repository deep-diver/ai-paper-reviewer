{"references": [{"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper introduces Diffusion Transformer (DiT), a key architecture that the current paper aims to improve upon by addressing its limitations in handling varying information densities across image regions."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper presents Latent Diffusion Models (LDMs), a foundational approach that performs the diffusion process in a low-dimensional latent space, enhancing efficiency and which D2iT builds upon."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces VQGAN, which is used for compressing images into a latent space; this compression strategy is relevant to the current paper's discussion of dynamic compression."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This paper presents Denoising Diffusion Probabilistic Models, providing the core formulation for diffusion models, which is the basis of the current paper's approach."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-01-01", "reason": "This paper introduces DALL-E, showcasing a milestone in generative models, which prompted additional research efforts in that domain."}]}