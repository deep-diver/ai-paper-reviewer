{"references": [{"fullname_first_author": "Bradley Brown", "paper_title": "Large language monkeys: Scaling inference compute with repeated sampling.", "publication_date": "2024-07-21", "reason": "This paper explores scaling inference compute with repeated sampling, a technique relevant to Heimdall's approach."}, {"fullname_first_author": "Ahmed El-Kishky", "paper_title": "Competitive programming with large reasoning models.", "publication_date": "2025-02-06", "reason": "This paper highlights the potential of LLMs in solving competitive problems, which is related to the challenges Heimdall addresses."}, {"fullname_first_author": "Daya Guo", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.", "publication_date": "2025-01-12", "reason": "This paper mentions using DeepSeek-R1, which is relevant, because Heimdall uses DeepSeek-R1-Distill-Qwen-32B as the policy model to generate solutions in the experimentation section."}, {"fullname_first_author": "Jia Li", "paper_title": "Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions.", "publication_date": "2024-09-01", "reason": "This paper highlights the dataset that Heimdall uses, as the the data synthesis work NuminaMath is used as the procedure of automatically proposing new problems and corresponding solutions in the experiment section."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms.", "publication_date": "2017-07-06", "reason": "This paper describes the PPO algorithm, which is used as one of the major components of the Heimdall implementation."}]}