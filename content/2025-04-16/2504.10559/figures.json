[{"figure_path": "https://arxiv.org/html/2504.10559/x1.png", "caption": "Figure 1: \nAverage F1 score on ProcessBench\u00a0(Zheng et\u00a0al., 2024) versus estimated annotation cost.\nActPRM outperforms prior SOTA models while requiring merely 20% of the annotation costs.", "description": "This figure illustrates the trade-off between model performance and annotation cost in training Process Reward Models (PRMs) on the ProcessBench dataset.  The x-axis represents the estimated annotation cost (in generated tokens), reflecting the amount of human effort required for data labeling. The y-axis shows the average F1 score, a metric evaluating the model's accuracy.  The figure compares ACTPRM (the proposed active learning approach) against several state-of-the-art (SOTA) PRM models.  ACTPRM demonstrates superior performance compared to the other models, achieving a similar or even better F1 score while requiring only 20% of the annotation costs.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2504.10559/x5.png", "caption": "Figure 2: (a) Comparison of the average F1 score on ProcessBench between ActPRM and random selection, plotted against the normalized budget positively correlated the number of labeled data instances consumed. The semi-transparent points represent all results in grid searching w.r.t. \u03b4p\u2062r\u2062e\u2062dsubscript\ud835\udeff\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc51\\delta_{pred}italic_\u03b4 start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d end_POSTSUBSCRIPT and \u03b4s\u2062t\u2062dsubscript\ud835\udeff\ud835\udc60\ud835\udc61\ud835\udc51\\delta_{std}italic_\u03b4 start_POSTSUBSCRIPT italic_s italic_t italic_d end_POSTSUBSCRIPT. For the highlighted ActPRM curve in the figure, \u03b4p\u2062r\u2062e\u2062d=0.95subscript\ud835\udeff\ud835\udc5d\ud835\udc5f\ud835\udc52\ud835\udc510.95\\delta_{pred}=0.95italic_\u03b4 start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d end_POSTSUBSCRIPT = 0.95 and \u03b4s\u2062t\u2062d=0.005subscript\ud835\udeff\ud835\udc60\ud835\udc61\ud835\udc510.005\\delta_{std}=0.005italic_\u03b4 start_POSTSUBSCRIPT italic_s italic_t italic_d end_POSTSUBSCRIPT = 0.005.\n(b) Ablation: uncertainty estimation strategies.\n(c) Ablation: number of ensemble PRM heads.", "description": "Figure 2 presents a comparison of ActPRM's performance against random data selection for process reward model training.  Subfigure (a) shows that ActPRM matches full data training performance while using only half the annotation budget. The semi-transparent points illustrate results from a grid search across various uncertainty thresholds (\u03b4p\u2062r\u2062e\u2062d and \u03b4s\u2062t\u2062d). The highlighted line shows results using specific thresholds (\u03b4p\u2062r\u2062e\u2062d = 0.95 and \u03b4s\u2062t\u2062d = 0.005). Subfigure (b) shows an ablation study comparing different uncertainty estimation strategies, while (c) presents an ablation study on the effect of varying the number of ensemble PRM heads on the model's performance.", "section": "5.1 Pool-Based Active Learning"}, {"figure_path": "https://arxiv.org/html/2504.10559/x6.png", "caption": "Figure 3: Estimated annotation costs (generated tokens) comparison between ActPRM and popular methods, including Ensemble Prompting\u00a0(Tan et\u00a0al., 2025), MathShepherd\u00a0(Wang et\u00a0al., 2024) and Consensus Filtering\u00a0(Zhang et\u00a0al., 2025).", "description": "Figure 3 compares the estimated annotation costs (in terms of generated tokens) of ActPRM with three other methods: Ensemble Prompting (Tan et al., 2025), MathShepherd (Wang et al., 2024), and Consensus Filtering (Zhang et al., 2025).  It visually represents the significant cost reduction achieved by ActPRM. The bar chart shows that ActPRM requires substantially fewer generated tokens compared to the other methods, highlighting its efficiency in reducing annotation costs for training Process Reward Models (PRMs).", "section": "5.2 Achieving New SOTA Performance on ProcessBench (75.0%) with Solely 6% Annotation Cost"}]