{"importance": "This paper presents Distillation-DPO, a novel diffusion distillation framework for 3D LiDAR scene completion. It achieves higher-quality scene completion with faster speeds, marking a significant advancement. This work opens new avenues for preference-aligned distillation and provides insights for future research, accelerating developments in autonomous driving, robotics, and augmented reality.", "summary": "Distillation-DPO: Efficient 3D LiDAR scene completion via diffusion distillation with direct preference optimization.", "takeaways": ["Distillation-DPO, a novel framework, significantly accelerates LiDAR scene completion using preference alignment.", "The method achieves higher completion quality and speed compared to state-of-the-art diffusion models.", "The paper introduces preference learning in distillation, offering insights for future research."], "tldr": "3D LiDAR scene completion has been boosted by diffusion models, but their slow sampling hinders real-world application. Score distillation can speed up sampling, but it leads to performance drops. To solve these, reward models could help mitigate the performance degradation from distillation, but they are hard to optimize directly due to challenges in obtaining large-scale labeled data and non-differentiable evaluation metrics.\n\nTo address these challenges, this paper introduces **Distillation-DPO**, a novel diffusion distillation framework for LiDAR scene completion with preference alignment. It generates completion scenes with different initial noises, uses LiDAR scene evaluation metrics as preference to construct winning/losing sample pairs and optimizes the student model by exploiting the difference in score functions. The results show higher completion quality and over 5x faster speeds.", "affiliation": "Zhejiang University", "categories": {"main_category": "Computer Vision", "sub_category": "3D Vision"}, "podcast_path": "2504.11447/podcast.wav"}