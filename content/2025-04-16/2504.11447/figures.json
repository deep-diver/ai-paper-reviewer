[{"figure_path": "https://arxiv.org/html/2504.11447/x2.png", "caption": "Figure 1: \nAn example demonstration of Distillation-DPO for LiDAR scene completion on SemanticKITTI dataset. (a) The input sparse LiDAR scan. (b) The corresponding ground truth scene. (c) Completion results of the existing state-of-the-art (SOTA) model, LiDiff\u00a0[21]. (d) Completion results of the proposed Distillation-DPO. Compared to LiDiff, Distillation-DPO can complete a scene more than 5 times faster while achieving higher completion quality (lower Chamfer Distance).", "description": "Figure 1 showcases a comparison of LiDAR scene completion methods on the SemanticKITTI dataset.  Subfigure (a) displays a sparse LiDAR input scan, representing the incomplete data. Subfigure (b) shows the corresponding ground truth, representing the complete scene. Subfigure (c) presents the completion result using LiDiff, a state-of-the-art model, which serves as a baseline for comparison.  Subfigure (d) demonstrates the superior result obtained with the proposed Distillation-DPO method. The key takeaway is that Distillation-DPO achieves higher completion quality (measured by Chamfer Distance) with a significant increase in speed; it is more than 5 times faster than LiDiff.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2504.11447/x3.png", "caption": "Figure 2: The overall structure of Distillation-DPO. (1) The student model generates the completed scene with different initial noise level \u03bb\ud835\udf06\\lambdaitalic_\u03bb based on the sparse scan. (2) Choosing the winning sample \ud835\udca2twsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc64\\mathcal{G}_{t}^{w}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT and losing samples \ud835\udca2tlsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc59\\mathcal{G}_{t}^{l}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT. (3) The sparse scan, \ud835\udca2twsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc64\\mathcal{G}_{t}^{w}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT and \ud835\udca2tlsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc59\\mathcal{G}_{t}^{l}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT are input to \u03f5\u03b8subscriptbold-italic-\u03f5\ud835\udf03\\boldsymbol{\\epsilon}_{\\theta}bold_italic_\u03f5 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT, \u03f5\u03d5wsuperscriptsubscriptbold-italic-\u03f5italic-\u03d5\ud835\udc64\\boldsymbol{\\epsilon}_{\\phi}^{w}bold_italic_\u03f5 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT and \u03f5\u03d5lsuperscriptsubscriptbold-italic-\u03f5italic-\u03d5\ud835\udc59\\boldsymbol{\\epsilon}_{\\phi}^{l}bold_italic_\u03f5 start_POSTSUBSCRIPT italic_\u03d5 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT.\n(4) The model \u03f5\u03b8wsuperscriptsubscriptbold-italic-\u03f5\ud835\udf03\ud835\udc64\\boldsymbol{\\epsilon}_{\\theta}^{w}bold_italic_\u03f5 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT and \u03f5\u03b8lsuperscriptsubscriptbold-italic-\u03f5\ud835\udf03\ud835\udc59\\boldsymbol{\\epsilon}_{\\theta}^{l}bold_italic_\u03f5 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT are optimized on \ud835\udca2twsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc64\\mathcal{G}_{t}^{w}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT and \ud835\udca2tlsuperscriptsubscript\ud835\udca2\ud835\udc61\ud835\udc59\\mathcal{G}_{t}^{l}caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT, separately. (5) The student model is optimized by the DPO gradient.", "description": "Figure 2 illustrates the Distillation-DPO framework.  The student model, given a sparse LiDAR scan, produces completed scenes using different initial noise levels (\u03bb). These results are then evaluated to identify winning and losing samples based on LiDAR metrics. The winning and losing samples, along with the original sparse scan, are then fed into three different models: the teacher model (\u03f5\u03b8), and two teaching assistant models (\u03f5\u03d5w for winning samples, and \u03f5\u03d5l for losing samples).  These models are then used to generate gradients which are used to optimize the student model using DPO. This process repeats iteratively.", "section": "3. Method"}]