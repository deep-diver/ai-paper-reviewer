{"references": [{"fullname_first_author": "Hu et al.", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "publication_date": "2022-04-25", "reason": "This paper introduces the LoRA technique, which is fundamental to the study as it serves as the basis for the fine-tuning approach used to integrate new knowledge into LLMs."}, {"fullname_first_author": "Hendrycks et al.", "paper_title": "Measuring Massive Multitask Language Understanding", "publication_date": "2021-05-05", "reason": "This paper presents the MMLU benchmark, which is a key extrinsic evaluation metric used to assess the reasoning abilities of the fine-tuned LLMs, making it essential for quantifying performance changes."}, {"fullname_first_author": "Lin et al.", "paper_title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods", "publication_date": "2022-05-22", "reason": "This paper introduces the TruthfulQA benchmark, which is used as an additional extrinsic metric to evaluate the truthfulness of the LLMs after fine-tuning, crucial for identifying potential degradation in factual recall."}, {"fullname_first_author": "Lewis et al.", "paper_title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "publication_date": "2020-12-06", "reason": "This paper describes Retrieval-Augmented Generation (RAG), which is a relevant method to incorporating new data that this paper argues against."}, {"fullname_first_author": "Allen-Zhu and Li", "paper_title": "Physics of Language Models: Part 3.2, Knowledge Manipulation", "publication_date": "2024-09-19", "reason": "This reference helps to argue how new data can be less disruptive to LLMs when augmented with various prompts."}]}