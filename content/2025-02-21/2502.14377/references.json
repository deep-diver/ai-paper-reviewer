{"references": [{"fullname_first_author": "Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper is important as it introduces the Diffusion Transformer (DiT) architecture, which serves as the foundation for many subsequent works in text-to-image generation."}, {"fullname_first_author": "Chen", "paper_title": "PixArt-a: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "publication_date": "2023-01-01", "reason": "This paper is essential as it presents PixArt-\u03b1, a fast training method for diffusion transformers, and is a model that RelaCtrl is compared against in the original paper."}, {"fullname_first_author": "Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-01-01", "reason": "This paper is a critical reference as it introduces ControlNet, a method for adding conditional control to text-to-image diffusion models, which is fundamental to the controllable generation aspect of RelaCtrl."}, {"fullname_first_author": "Yu", "paper_title": "Metaformer is actually what you need for vision", "publication_date": "2022-01-01", "reason": "This paper introduces the MetaFormer architecture, which provides theoretical insights into the effectiveness of Transformers and is relevant to the design of RelaCtrl, particularly the token and channel mixing strategy."}, {"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper is included because it introduces CLIP (Contrastive Language-Image Pre-training), a model that's widely used to get text embeddings used for diffusion, used also as a metric of image and text consistence."}]}