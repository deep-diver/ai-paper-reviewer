[{"figure_path": "https://arxiv.org/html/2502.12769/extracted/6219631/images/estimation_pipeline.png", "caption": "Figure 1: Illustration of our approach for estimating hallucination rates in the wild. Hallucination Detection and Model Evaluation (left side): (1) We automatically translate the English FAVA Mishra et\u00a0al. (2024) dataset to 30 languages and train our multilingual hallucination detection (HD) model on this (noisy) multilingual training data; (2) We synthesize a silver multilingual hallucination evaluation dataset by prompting a state-of-the-art LLM (GPT-4) to introduce hallucinations in its answers to knowledge-seeking questions; for a subset of five high-resource languages, we additionally collect gold (i.e., human) hallucination annotations; we dub this 30-language evaluation benchmark mFAVA. We use mFAVA to estimate HD model\u2019s per-language performances (precision and recall). Hallucination Rate Estimation in the Wild (right side): (3) We estimate the hallucination rates for all 30 languages and six different LLM families from the number of detections of the HD model and its performance.", "description": "This figure illustrates the methodology used in the paper to estimate the hallucination rates of large language models (LLMs) across multiple languages. The process involves two main stages: (1) Hallucination detection model training and evaluation, and (2) Hallucination rate estimation.  The left side depicts the development of a multilingual hallucination detection model trained on translated data, then evaluated using a newly created benchmark called mFAVA. mFAVA includes both machine-generated (silver) and human-annotated (gold) data for a subset of languages. The right side shows how hallucination rates are estimated for 30 languages and 6 LLM families using the trained detection model's performance on a large-scale knowledge-intensive QA dataset.", "section": "3 Hallucination Detection"}, {"figure_path": "https://arxiv.org/html/2502.12769/x1.png", "caption": "Figure 2: 1) Inter-annotator agreement (IAA) for hallucination span detection (Binary; blue bars) and classification (Category; orange bars) for five high-resource languages; 2) Hallucination span and class agreement between human labels and GPT-4 generated hallucinations (Silver-Gold; agreement on spans only: red bars; agreement on spans and hallucination type: green bars).", "description": "Figure 2 presents a comparison of inter-annotator agreement (IAA) and the agreement between human annotations and GPT-4 generated hallucinations for a task involving hallucination detection.  The left part shows IAA scores for both binary (span detection) and categorical (hallucination type classification) annotation schemes across five high-resource languages. The right part displays the agreement between human annotators and GPT-4's hallucination labels, showing separate scores for agreement on spans alone and for agreement on both spans and hallucination types.", "section": "3 Hallucination Detection"}, {"figure_path": "https://arxiv.org/html/2502.12769/x2.png", "caption": "Figure 3: Comparison of hallucination rate estimates \ud835\udc3b\ud835\udc45est,lsubscript\ud835\udc3b\ud835\udc45est\ud835\udc59\\mathit{HR}_{\\text{est},l}italic_HR start_POSTSUBSCRIPT est , italic_l end_POSTSUBSCRIPT (mean \u00b1plus-or-minus\\pm\u00b1 std over five LLM runs) for Arabic (AR), Chinese (ZH), German (DE), Russian (RU), and Turkish (TR) for 3 LLMs based on the estimates of Plsubscript\ud835\udc43\ud835\udc59\\mathit{P}_{l}italic_P start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT and Rlsubscript\ud835\udc45\ud835\udc59\\mathit{R}_{l}italic_R start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT of the Multi (Bidirect) model on (1) mFAVA-Silver (top row) and (2) mFAVA-Gold (bottom row). The two sets of estimates are highly correlated (r=0.83,p=1.26\u2062e\u221204)formulae-sequence\ud835\udc5f0.83\ud835\udc5d1.26\ud835\udc5204(r=0.83,p=1.26e-04)( italic_r = 0.83 , italic_p = 1.26 italic_e - 04 ).", "description": "Figure 3 displays a comparison of hallucination rates across five languages (Arabic, Chinese, German, Russian, and Turkish) for three different Large Language Models (LLMs).  Hallucination rates (\ud835\udc3b\ud835\udc45est,l) are calculated using precision (Pl) and recall (Rl) estimates from a multilingual hallucination detection model. The figure presents two sets of results: one using a silver standard (mFAVA-Silver), created by automatically translating an English dataset and another using a gold standard (mFAVA-Gold) with human annotations for a subset of the languages.  The top row shows results based on the mFAVA-Silver dataset, and the bottom row shows results based on the mFAVA-Gold dataset. A strong positive correlation (r = 0.83, p = 1.26e-04) is observed between the two sets of hallucination rate estimates, indicating that the silver standard provides a reasonable approximation of the gold standard.", "section": "4.1 From Model Performance to Hallucination Rates Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x3.png", "caption": "Figure 4: Mean estimates of in-the-wild hallucination rates (\u00b1plus-or-minus\\pm\u00b1 std) for 30 languages and 11 LLMs. Each mean score is an average of 15 \ud835\udc3b\ud835\udc45est,lsubscript\ud835\udc3b\ud835\udc45est\ud835\udc59\\mathit{HR}_{\\text{est},l}italic_HR start_POSTSUBSCRIPT est , italic_l end_POSTSUBSCRIPT estimates, (3 different HD model instances applied to 5 different LLM responses). Average rates increase from top to bottom (over languages) and from left to right (over LLMs).", "description": "This figure displays the average hallucination rates for 30 different languages across 11 large language models (LLMs). Each data point represents the mean hallucination rate calculated from 15 individual estimates.  These estimates were derived by applying three separate instances of a hallucination detection model to five different sets of responses generated by each LLM for each language.  The figure visually represents how these hallucination rates vary across different languages (arranged vertically) and LLMs (arranged horizontally). Generally, the hallucination rates increase from the top to the bottom and from left to right.", "section": "Estimating Hallucination in the Wild"}, {"figure_path": "https://arxiv.org/html/2502.12769/x4.png", "caption": "(a)", "description": "This figure displays the correlation between the number of hallucinations and the average response length for smaller language models.  Each subplot represents a different language model, showing a scatter plot of average response length against the number of hallucinated tokens. A trend line is also included to visually represent the correlation.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x5.png", "caption": "(b)", "description": "This figure displays the correlation between the average response length and the number of hallucinations detected by the model for larger language models.  It shows scatter plots for each of several models, with the x-axis representing average response length and the y-axis representing the number of hallucinated tokens. The lines of best fit for each model are also shown to visualize the trend between response length and hallucination count.  The Pearson correlation coefficient and p-value are provided for each model, indicating the statistical significance of the relationship.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x6.png", "caption": "(c)", "description": "Figure 7c displays the correlation between the number of hallucinated tokens and the average response length for larger language models.  It shows scatter plots and Pearson correlation coefficients for several different LLMs, revealing a strong positive correlation for most models. This suggests that longer responses tend to contain more hallucinated tokens, although the rate of hallucination (per token) may not necessarily increase.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x7.png", "caption": "Figure 5: 5(a) Larger models hallucinate significantly less than smaller ones. Bars are labeled with p\ud835\udc5dpitalic_p-values from t\ud835\udc61titalic_t-test. 5(b) Correlation between hallucination rates (averaged over all 30 languages) and the officially declared number of supported languages. 5(c) On average, as response length increases, so do the absolute hallucinations Hdetected,lsubscript\ud835\udc3bdetected\ud835\udc59\\mathit{H}_{\\text{detected},l}italic_H start_POSTSUBSCRIPT detected , italic_l end_POSTSUBSCRIPT.", "description": "Figure 5 presents a threefold analysis of hallucination rates in large language models (LLMs).  Panel (a) compares hallucination rates between smaller and larger versions of the same LLMs, showing that larger models exhibit significantly lower hallucination rates (as indicated by the p-values from t-tests displayed on the bars).  Panel (b) illustrates a positive correlation between the number of languages supported by an LLM and its overall hallucination rate (averaged across all 30 languages examined). This suggests that models supporting more languages tend to hallucinate more often. Finally, panel (c) demonstrates that, on average, longer LLM responses contain more absolute hallucinated tokens (H<sub>detected,l</sub>), although the rate of hallucination per token might not show a significant trend.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x8.png", "caption": "Figure 6: Distribution of 6 labels across 30 languages in mFava-Silver dataset.", "description": "This figure shows a bar chart visualizing the distribution of six different types of hallucinations across 30 languages in the mFAVA-Silver dataset.  Each bar represents a language, and the height of each colored segment within the bar corresponds to the proportion of hallucinations of a specific type (Entity, Relation, Invented, Contradictory, Unverifiable, Subjective) in that language. This provides a visual comparison of the prevalence of various hallucination categories across diverse languages within the synthetic dataset.", "section": "3.1 MFAVA Benchmark"}, {"figure_path": "https://arxiv.org/html/2502.12769/x9.png", "caption": "(a) Hallucinations vs response length correlation of smaller models.", "description": "This figure displays the correlation between the number of hallucinations and the average response length generated by smaller language models.  Each subplot represents a different language model, showing the relationship as a scatter plot with a regression line. The Pearson correlation coefficient and p-value are provided for each model, indicating the strength and statistical significance of the correlation.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/x10.png", "caption": "(b) Hallucinations vs response length correlation of bigger models.", "description": "This figure displays the correlation between the number of hallucinations and the average response length for larger language models.  It visually represents how the length of a model's response relates to the frequency of hallucinations within those responses.  Each data point likely represents a specific language, or possibly an average across a group of languages, with larger language models used to generate the responses.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/extracted/6219631/images/annotation_instruction.png", "caption": "(c) Hallucinations vs response length correlation of bigger models.", "description": "This figure shows the correlation between the number of hallucinations and the average response length for larger language models.  It visually represents the relationship between the length of text generated by the models and how many factual errors or inconsistencies they contain. The results from several large language models are presented, allowing for a comparison of their performance in terms of both the length of their output and its accuracy.", "section": "4.2 Final Estimates"}, {"figure_path": "https://arxiv.org/html/2502.12769/extracted/6219631/images/annotation_instruction_2.png", "caption": "Figure 7: Per model correlations between hallucinations and response length.", "description": "This figure displays scatter plots illustrating the correlation between the average length of LLM responses and the number of hallucinations detected within those responses.  The plots are separated by LLM model, allowing for a comparison of the relationship across different models (both smaller and larger models are included). Each plot shows the Pearson correlation coefficient (r) and p-value, indicating the strength and statistical significance of the correlation.", "section": "4.2 Final Estimates"}]