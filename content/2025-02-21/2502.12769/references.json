{"references": [{"fullname_first_author": "Ji", "paper_title": "Survey of hallucination in natural language generation", "publication_date": "2023-01-01", "reason": "It provides a comprehensive survey of hallucination in natural language generation, offering a broad overview of the issue."}, {"fullname_first_author": "Manakul", "paper_title": "SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models", "publication_date": "2023-01-01", "reason": "It introduces SelfCheckGPT, a zero-resource method for detecting hallucinations, which is relevant for assessing generated content without external resources."}, {"fullname_first_author": "Mishra", "paper_title": "Fine-grained hallucination detection and editing for language models", "publication_date": "2024-01-01", "reason": "It offers a methodology for fine-grained detection of hallucinations, contributing to the development of precise evaluation metrics."}, {"fullname_first_author": "Wei", "paper_title": "Long-form factuality in large language models", "publication_date": "2024-03-01", "reason": "It investigates factuality in long-form text generation, particularly relevant for assessing the performance of LLMs in producing accurate extended outputs."}, {"fullname_first_author": "Zhou", "paper_title": "Detecting hallucinated content in conditional neural sequence generation", "publication_date": "2021-01-01", "reason": "It is about detecting hallucinated content in neural sequence generation which is foundational for understanding and addressing the problem of hallucination."}]}