[{"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/100M_benchmark_graph.png", "caption": "Figure 1: Comparison results on academic benchmarks for Shakti-100M, Boomer-634M[14], SmolLM-135M[12], SmolLM-360M[12], and AMD-Llama-135M[45], which are in the same parameter range.", "description": "Figure 1 presents a comparative analysis of the Shakti-100M model's performance against other similar-sized language models across various academic benchmarks.  The benchmarks assess performance on diverse natural language processing tasks.  The figure visually compares the scores achieved by Shakti-100M to those of Boomer-634M, SmolLM-135M, SmolLM-360M, and AMD-Llama-135M, all of which fall within a similar parameter range, allowing for a fair comparison based on model size.", "section": "6.1 Comparative Performance Analysis"}, {"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/250M_benchmark_graph.png", "caption": "Figure 2: Comparison results on academic benchmarks for Shakti-250M, Boomer-1B[13], Boomer-634M[14], Qwen2.5-0.5B[47], SmolLM-360M[12], and Llama 3.2 1B[46].", "description": "This figure compares the performance of Shakti-250M against other large language models (LLMs) across various academic benchmarks.  The benchmarks assess performance on diverse tasks, allowing for a comprehensive comparison of the model's capabilities. The LLMs included in the comparison are Boomer-1B, Boomer-634M, Qwen2.5-0.5B, SmolLM-360M, and Llama 3.2 1B, providing context for evaluating Shakti-250M's performance relative to established models.  Each bar in the chart represents the score achieved by each model on a specific benchmark task.", "section": "6.1 Comparative Performance Analysis"}, {"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/500M_benchmark_graph.png", "caption": "Figure 3: Comparison results on academic benchmarks for Shakti-500M, Boomer-1B[13], Boomer-634M[14], Qwen2.5-0.5B[47], and Llama 3.2 1B[46].", "description": "Figure 3 presents a comparative analysis of the Shakti-500M model's performance against other prominent large language models (LLMs) across various academic benchmarks.  These benchmarks assess performance on diverse natural language processing (NLP) tasks, allowing for a comprehensive evaluation of the model's capabilities. The comparison includes Boomer-1B, Boomer-634M, Qwen2.5-0.5B, and Llama 3.2 1B, providing a nuanced understanding of Shakti-500M's strengths and weaknesses relative to models with similar and larger parameter counts.", "section": "6.1 Comparative Performance Analysis"}, {"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/domain_specific_benchmark_250M.png", "caption": "Figure 4: Comparison results on medical and finance domain benchmarks for Shakti-250M, Phi-1.5-1.3B[48], Gemma-2B[49], and Opt-2.7B[50] models, specifically for the Medical domain.", "description": "Figure 4 presents a comparative analysis of the performance of several large language models (LLMs) on medical domain benchmark tasks.  The LLMs compared include Shakti-250M, Phi-1.5-1.3B, Gemma-2B, and Opt-2.7B. The figure specifically highlights performance on tasks relevant to the medical field. The results are likely displayed using bar charts or similar visualizations, showing each model's score on each benchmark task to allow for direct comparison.", "section": "6.2 Domain Specific Performance Analysis"}, {"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/raw_quantized_model_size.png", "caption": "Figure 5: Model size comparison before and after quantization. FP32 represents the original model size, while Q8, Q5, and Q4 represent increasingly aggressive quantization levels. Note the substantial reduction in memory footprint, with Q4 models requiring approximately 8x less memory than their FP32 counterparts.", "description": "This figure compares the memory usage of several language models before and after applying different quantization techniques.  The original, unquantized model size is represented by 'FP32'.  The levels of quantization are shown by 'Q8', 'Q5', and 'Q4', where Q4 uses the most aggressive quantization and reduces the model's memory footprint the most. The bar chart visually demonstrates how much smaller the quantized models are compared to their original size.  Specifically, it shows that using Q4 quantization results in models requiring approximately 8 times less memory than the original FP32 versions.", "section": "8 Quantization"}, {"figure_path": "https://arxiv.org/html/2503.01933/extracted/6246866/token_performance_hardware_v1.png", "caption": "Figure 6: Performance comparison (tokens per second) of Shakti models across different hardware platforms. The graph demonstrates how our models maintain high throughput even on resource-constrained devices compared to similar-sized competitors.", "description": "Figure 6 presents a comparative analysis of the Shakti models' performance (measured in tokens per second) across various hardware platforms, ranging from high-performance GPUs to resource-constrained devices like Raspberry Pi and mobile phones.  The bar chart visually represents the throughput achieved by Shakti-100M, Shakti-250M, and Shakti-500M, in their quantized versions (Q4), compared to similar-sized competitor models on each platform.  This comparison highlights the Shakti models' ability to maintain high processing speeds even on devices with limited computational resources.", "section": "8.3 Performance Across Hardware Platforms"}]