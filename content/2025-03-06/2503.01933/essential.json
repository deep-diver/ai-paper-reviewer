{"importance": "This paper introduces a series of small language models optimized for edge devices, paving the way for **efficient and privacy-preserving AI applications**. The models address limitations of large language models and offer researchers insights into designing compact, high-performance models. **It enables further exploration of edge AI**.", "summary": "Shakti SLMs: Fine-tuning compact language models for efficient, domain-specific AI on edge devices.", "takeaways": ["Shakti SLMs (100M, 250M, 500M parameters) achieve strong performance on edge devices by combining efficient architectures and quantization.", "Domain-specific fine-tuning enhances the models' applicability in specialized areas like healthcare, finance, and legal.", "Responsible AI principles are integrated through bias mitigation techniques and on-device processing for data privacy."], "tldr": "Large-scale language models face challenges in edge deployment due to high computational demands, energy consumption, and privacy risks.  To address these issues, this work explores **Small Language Models (SLMs)**. Edge AI runs models directly on local hardware, reducing reliance on remote servers. However, scaling down large models often compromises language understanding, and this motivates SLMs that balance performance and resource constraints. Techniques such as efficient architectures and quantization help SLMs maintain performance under tight constraints.\n\nTo achieve the benefits of the SLMs, this paper introduces the **Shakti Small Language Models (SLMs): Shakti-100M, Shakti-250M, and Shakti-500M**.  The Shakti series combines efficient architectures, quantization, and responsible AI for on-device intelligence. They provide design insights, training pipelines, and benchmark results for general and specialized tasks. The study illustrates that compact models can meet and often exceed expectations in real-world edge-AI scenarios. The Shakti models incorporate mechanisms to mitigate bias, handle data privately, and reduce carbon footprints through on-device inference.", "affiliation": "SandLogic Technologies Pvt Ltd", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "2503.01933/podcast.wav"}