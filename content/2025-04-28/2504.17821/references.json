{"references": [{"fullname_first_author": "Xu", "paper_title": "Video question answering via gradually refined attention over appearance and motion", "publication_date": "2017-01-01", "reason": "This video question answering work is crucial because it presents a method for video question answering that utilizes gradually refined attention over appearance and motion, making it fundamental to the development of video understanding benchmarks."}, {"fullname_first_author": "Yu", "paper_title": "ActivityNet-QA: A dataset for understanding complex web videos via question answering", "publication_date": "2019-01-01", "reason": "As one of the early video evaluation benchmark, this work is crucial for introducing a video question answering dataset designed to promote understanding of complex web videos."}, {"fullname_first_author": "Lei", "paper_title": "Tvqa: Localized, compositional video question answering", "publication_date": "2018-01-01", "reason": "This localized compositional video question answering work is crucial because it presents an early benchmark designed to enable video question answering tasks."}, {"fullname_first_author": "Xiao", "paper_title": "NEXT-QA: Next phase of question-answering to explaining temporal actions", "publication_date": "2021-01-01", "reason": "This next-phase question answering work is crucial for presenting an approach to explaining temporal actions, furthering video reasoning capabilities."}, {"fullname_first_author": "Liu", "paper_title": "Grounding dino: Marrying dino with grounded pre-training for open-set object detection", "publication_date": "2023-01-01", "reason": "This is fundamental to this work as it utilizes Grounding DINO for bounding box prediction."}]}