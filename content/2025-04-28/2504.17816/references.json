{"references": [{"fullname_first_author": "Yuming Jiang", "paper_title": "Videobooth: Diffusion-based video generation with image prompts", "publication_date": "2024-06-01", "reason": "This paper is a key reference as it directly relates to the subject of subject-driven video generation, providing a baseline comparison method for the proposed approach."}, {"fullname_first_author": "Zhenxiong Tan", "paper_title": "Ominicontrol: Minimal and universal control for diffusion transformer", "publication_date": "2024-11-21", "reason": "This paper provides image customization data that the project uses for zero-shot S2V training, removing the need for expensive and hard-to-obtain S2V datasets."}, {"fullname_first_author": "Ziqi Huang", "paper_title": "VBench: Comprehensive benchmark suite for video generative models", "publication_date": "2024-06-01", "reason": "This paper provides a benchmark used to evaluate the performance of the model, thus offering a standardized way to compare against other methods."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper provides a framework that addresses a key problem of generating scalable diffusion models with transformers."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper provides an architecture that the project builds upon in this research."}]}