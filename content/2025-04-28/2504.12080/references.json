{"references": [{"fullname_first_author": "A. Kirillov", "paper_title": "Segment anything", "publication_date": "2023-01-01", "reason": "This paper introduces the Segment Anything Model (SAM), which is the foundation and basis for the DC-SAM framework presented in the given paper, making it fundamentally important."}, {"fullname_first_author": "Z. Tian", "paper_title": "Prior guided feature enrichment network for few-shot segmentation", "publication_date": "2020-01-01", "reason": "This paper's approach to few-shot segmentation is foundational to the development of DC-SAM and is therefore one of the most important references."}, {"fullname_first_author": "T.-Y. Lin", "paper_title": "Microsoft coco: Common objects in context", "publication_date": "2014-01-01", "reason": "The COCO dataset, presented in this paper, is extensively used for training and evaluating models, making it a crucial resource for experiments and comparisons."}, {"fullname_first_author": "Y. Sun", "paper_title": "Vrp-sam: Sam with visual reference prompt", "publication_date": "2024-01-01", "reason": "This paper provides a strong baseline for comparison as VRP-SAM provides initial research into prompting SAM and SAM2 through vision."}, {"fullname_first_author": "K. He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-01-01", "reason": "This paper introduces ResNet which serves as an important building block for feature extraction of their architecture."}]}