{"importance": "This paper introduces **DC-SAM, a novel approach for in-context segmentation** which is seamlessly extended to the video domain. The creation of IC-VOS, the **first benchmark for in-context video segmentation**, offers a valuable resource for the community, addressing a gap in existing benchmarks and fostering further research in video semantic understanding. DC-SAM achieves SOTA on IC-VOS,COCO, and PASCAL, demonstrating the potential impact of the research.", "summary": "DC-SAM: Adapting Segment Anything Model for in-context image and video segmentation with dual consistency.", "takeaways": ["DC-SAM improves in-context segmentation by incorporating SAM features, using dual positive/negative prompts, and cyclic-consistent cross-attention.", "A new benchmark, IC-VOS, is introduced to evaluate in-context video object segmentation.", "Extensive experiments show state-of-the-art performance of DC-SAM on image and video in-context segmentation tasks."], "tldr": "Recent Segment Anything Models (SAMs) have shown remarkable performance in interactive segmentation but struggle with in-context segmentation, where the goal is to segment objects based on a single example. Existing methods often rely on backbone features alone, overlooking the distinctive properties of SAM-derived representations. This limitation impacts the accuracy, particularly in scenarios with limited semantic priors. Moreover, there is a lack of benchmarks for evaluating in-context video segmentation capabilities, hindering progress in this area. \n\nThis paper presents Dual Consistency SAM (DC-SAM), a prompt-tuning method to adapt SAM for in-context segmentation in images and videos. It enhances SAM's prompt encoder by providing high-quality visual prompts and using a cycle-consistent cross-attention mechanism to ensure consistency between features and visual prompts. DC-SAM introduces a dual-branch design to leverage discriminative positive and negative prompts, and adapts this to video by mask-tube training. The authors introduce the first In-Context Video Object Segmentation (IC-VOS) benchmark to evaluate performance.", "affiliation": "Beijing University of Posts and Telecommunications", "categories": {"main_category": "Computer Vision", "sub_category": "Image Segmentation"}, "podcast_path": "2504.12080/podcast.wav"}