{"references": [{"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with clip latents", "publication_date": "2022-04-01", "reason": "This paper is highly influential for introducing a CLIP-based approach to hierarchical text-to-image generation, a core concept used as guidance in various diffusion based text-guided image editing."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This reference is important for introducing latent diffusion models, which are used in modern text-to-image generation and editing techniques, providing a means for generating high-resolution images from textual descriptions."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This is an influential paper for introducing CLIP (Contrastive Language-Image Pre-training), a model used for aligning images and text, serving as a fundamental component in many text-guided image editing methods."}, {"fullname_first_author": "Narek Tumanyan", "paper_title": "Plug-and-play diffusion features for text-driven image-to-image translation", "publication_date": "2023-01-01", "reason": "This paper is a key reference for introducing the use of plug-and-play diffusion features, demonstrating a way to manipulate images guided by text prompts through image-to-image translation."}, {"fullname_first_author": "Fei Yang", "paper_title": "Dynamic prompt learning: Addressing cross-attention leakage for text-based image editing", "publication_date": "2023-01-01", "reason": "This paper is key for its contributions to addressing cross-attention leakage in text-based image editing, by applying dynamic prompt learning which mitigates issues in preserving local details during editing"}]}