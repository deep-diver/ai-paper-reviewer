{"references": [{"fullname_first_author": "Qwen", "paper_title": "Qwen2.5 technical report", "publication_date": "2025-00-00", "reason": "This paper introduces the foundational language model used in LIMO, providing crucial context for understanding LIMO's capabilities."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-00-00", "reason": "This paper describes the large language model foundation upon which LIMO is built, explaining the knowledge base that LIMO leverages."}, {"fullname_first_author": "Daya Guo", "paper_title": "DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning", "publication_date": "2025-01-00", "reason": "This paper introduces a key comparison model (DeepSeek-R1) which LIMO is compared against, offering a benchmark against which LIMO's performance is measured."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "DeepSeekMath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-00", "reason": "This paper discusses a relevant dataset used for training and evaluating mathematical reasoning capabilities, which is directly relevant to LIMO's evaluation methodology."}, {"fullname_first_author": "Chunting Zhou", "paper_title": "LIMA: Less is more for alignment", "publication_date": "2024-00-00", "reason": "This paper introduces the foundational concept of \"Less is More\" in language models, which is expanded upon and applied to mathematical reasoning by LIMO."}]}