{"importance": "**SURVEYFORGE** enhances automated survey writing by improving outline quality, reference accuracy, and offering a new evaluation benchmark, boosting research efficiency and opening new research avenues.", "summary": "SURVEYFORGE automates survey generation, improving quality and evaluation.", "takeaways": ["SURVEYFORGE enhances outline structure and coherence.", "The framework employs a memory-driven scholar navigation agent for high-quality reference retrieval.", "SurveyBench offers a multi-dimensional evaluation benchmark for AI-generated surveys."], "tldr": "Survey papers are vital for researchers, but creating them is tough due to the flood of publications. Automated tools using LLMs exist, yet they often lack quality, especially in outlines and citations. **This work introduces SURVEYFORGE to solve these issues.** It improves outline generation by studying human-written outlines and using domain-related articles. The system then retrieves and refines content using high-quality papers found via a scholar navigation agent. Also a new benchmark, SurveyBench, offers a comprehensive evaluation across reference, outline, and content quality.\n\n**SURVEYFORGE uses a two-stage process:** first, it creates outlines by learning from existing human-written outlines and relevant literature. Then, it uses a scholar navigation agent to fetch high-quality papers for each subsection, generating and refining content accordingly. The paper also introduces SurveyBench, a new evaluation tool. Experiments show that this approach outperforms previous methods like AutoSurvey. The authors highlight the tool\u2019s ability to generate well-structured outlines and retrieve high-quality references.", "affiliation": "Shanghai Artificial Intelligence Laboratory", "categories": {"main_category": "Multimodal Learning", "sub_category": "Multimodal Generation"}, "podcast_path": "2503.04629/podcast.wav"}