[{"figure_path": "https://arxiv.org/html/2503.07605/x1.png", "caption": "Figure 1: Visualization of hidden states h\u2062(P)\u210e\ud835\udc43h(P)italic_h ( italic_P ) from different tasks. Each point represents the activation of a hidden state in the model for a specific task. The clustering patterns illustrate how tasks with similar requirements tend to activate similar regions in the model.", "description": "This figure visualizes the activation patterns of hidden states within a large language model (LLM) across various tasks. Each point represents a specific hidden state's activation level for a particular task.  The x and y coordinates represent the dimensionality reduction of the high-dimensional hidden states.  Crucially, the plot reveals distinct clusters of points corresponding to different task categories. Tasks with similar semantic or reasoning requirements tend to cluster together, indicating that these tasks activate similar regions within the LLM's hidden state space. This supports the hypothesis that the LLM's internal representations for various tasks are not uniformly distributed but are instead organized in task-specific clusters. This observation is fundamental to the paper's proposed method.", "section": "Motivation Discovery"}, {"figure_path": "https://arxiv.org/html/2503.07605/x2.png", "caption": "Figure 2: Framework of the SEAP approach. The left side shows the Motivation Discovery phase, where task-specific activation patterns are identified by analyzing hidden states and neuron activations extracted from the task corpus. The right side illustrates the Training-free Sparse Expert Activation Pruning process, consisting of five main steps described in Section 2.1.", "description": "This figure provides a detailed overview of the SEAP (Sparse Expert Activation Pruning) approach. The left side focuses on the 'Motivation Discovery' phase, illustrating how task-specific activation patterns are identified. This is achieved by analyzing the hidden states and neuron activations extracted from a carefully constructed task corpus.  The right side of the figure details the five main steps involved in the 'Training-free Sparse Expert Activation Pruning' process itself, as described in Section 2.1 of the paper.  Each step is shown visually to clarify the process of pruning based on task-specific activation patterns.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2503.07605/extracted/6267883/figures/l2norms.png", "caption": "Figure 3: Heatmaps of dimension-wise average normalized \u2113\u2113\\ellroman_\u21132 norms for different tasks. Each row corresponds to a layer or module, and each column represents a dimension in the hidden state space. The top and bottom parts of the figure show activation patterns from two randomly selected subsets of the same task. Consistent color patterns appear within tasks of the same type, while distinctly different tasks exhibit unique activation signatures, supporting our hypothesis that tasks selectively activate specific dimensions.", "description": "This figure visualizes the activation patterns of different tasks within a language model.  Heatmaps display the average \u21132 norm of each dimension in the hidden state across multiple layers or modules. Each row represents a layer/module, and each column represents a dimension.  The top and bottom halves of each heatmap show activation patterns from two different, randomly selected subsets of prompts from the *same* task. Consistent color patterns within each task's heatmaps illustrate that similar tasks activate similar dimensions, while distinctly different tasks show unique activation patterns.  This supports the study's hypothesis that tasks selectively activate specific dimensions of the hidden state.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2503.07605/x3.png", "caption": "Figure 4: Illustration of how neurons are pruned based on importance scores.", "description": "This figure illustrates the process of neuron pruning in SEAP. Neurons with low importance scores (indicated by color) are pruned, while those with high scores are retained. This selective pruning enhances computational efficiency while preserving model performance.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2503.07605/extracted/6267883/figures/mmlu_rm_test.png", "caption": "Figure 5: Impact of pruning on MMLU performance at different layers and sparsity levels. Early layers are more sensitive to pruning.", "description": "This figure shows how performance on the MMLU (Massive Multitask Language Understanding) benchmark changes when different layers of a large language model are pruned at varying sparsity levels (0%, 20%, 50%, 100%).  The x-axis represents the layer index, indicating the depth of the layer within the model, with higher values corresponding to later layers. The y-axis displays the accuracy achieved on the MMLU task after pruning.  Different lines represent different sparsity levels, illustrating the effect of removing increasing proportions of parameters. The results indicate that early layers (those with lower indices) are much more sensitive to pruning than later layers.  A significant drop in accuracy is observed for early layers even at lower sparsity levels, whereas later layers exhibit greater resilience to pruning.", "section": "3.2 Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2503.07605/extracted/6267883/figures/piqa_rm_test.png", "caption": "Figure 6: Impact of pruning on PIQA performance at different layers and sparsity levels. Deeper layers are more robust to pruning.", "description": "This figure displays the results of an experiment that evaluated the impact of pruning on the PIQA task's performance across different layers and sparsity levels within a large language model (LLM).  The x-axis represents the index of the pruned layer, indicating the depth of the layer within the model. The y-axis represents the accuracy achieved on the PIQA task. Multiple lines are plotted, each representing a different sparsity level (percentage of the network pruned).  The key observation is that deeper layers (higher layer indices) show greater robustness to pruning; they maintain higher accuracy even at increased sparsity levels compared to shallower layers. This suggests that the model's crucial information for this specific task is concentrated in the deeper layers of the network.", "section": "3 Experiment and Results Analysis"}, {"figure_path": "https://arxiv.org/html/2503.07605/extracted/6267883/figures/ppl.png", "caption": "Figure 7: Perplexity (PPL) results under different pruning ratios. A lower\u2193 perplexity indicates better performance.", "description": "This figure displays the perplexity (PPL) scores achieved by different LLMs (Llama-2-7B and Llama-2-13B) under various pruning ratios (0%, 20%, and 50%).  Perplexity is a metric that evaluates how well a language model predicts the next word in a sequence; lower perplexity indicates better performance. The graph visually demonstrates the trade-off between model compression (through pruning) and language modeling quality.  It shows that as the pruning ratio increases, the perplexity generally increases, suggesting a slight degradation in the model's ability to predict words accurately.  However, the increase remains relatively small, particularly at lower pruning ratios, indicating that the proposed pruning methods maintain reasonably good language modeling capabilities even with significant model compression.", "section": "Additional Experiments"}]