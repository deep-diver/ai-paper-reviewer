[{"Alex": "Welcome to the podcast, everyone! Today, we're diving into a mind-bending topic: How to make AI think faster by writing less. Forget those verbose AI models \u2013 we're talking about the 'Chain of Draft' \u2013 the secret weapon for efficient AI reasoning. I'm Alex, your host, and with me is Jamie, ready to explore this game-changing research.", "Jamie": "Hey Alex, thanks for having me! 'AI thinking faster by writing less?' That sounds like a productivity hack for robots. I\u2019m intrigued. So, where do we even start with this 'Chain of Draft' thing?"}, {"Alex": "Great question, Jamie. Think of how humans solve problems. We don't always write out every single detail; we jot down the essentials. 'Chain of Draft,' or CoD, is inspired by that. It\u2019s a novel prompting strategy where we encourage Large Language Models \u2013 LLMs \u2013 to generate minimalistic, yet informative, reasoning outputs.", "Jamie": "So, it\u2019s about getting AI to cut to the chase? Umm, I guess that makes sense. But how is this different from how AI currently reasons, like with 'Chain-of-Thought'?"}, {"Alex": "That's the core of it. 'Chain-of-Thought,' or CoT, emphasizes verbose, step-by-step reasoning. While effective, it's computationally expensive and time-consuming. CoD, on the other hand, focuses on critical insights, reducing verbosity significantly.", "Jamie": "Okay, I'm following. CoT is like showing your work in math class, even the obvious stuff. And CoD is just the key steps. So, what kind of tasks are we talking about here? Is it just math?"}, {"Alex": "Not at all! The research explored arithmetic reasoning, like the GSM8K dataset, but also common sense reasoning and even symbolic reasoning, using coin flip scenarios. The aim was to see if CoD could match or surpass CoT's accuracy across various complex reasoning tasks.", "Jamie": "Coin flips? Hmm, interesting. So, how exactly did you guys test this out? What was the setup like?"}, {"Alex": "We compared three prompting strategies: Standard prompting as a baseline, then Chain-of-Thought, and finally, our Chain of Draft. We used popular models like GPT-40 from OpenAI and Claude 3.5 Sonnet from Anthropic, giving them the same tasks with different prompting styles.", "Jamie": "And you saw, CoD was superior? Really, how superior are we talking here? Give me specific numbers!"}, {"Alex": "In the GSM8K arithmetic reasoning task, standard prompting gave us around 53% to 64% accuracy. CoT jumped that to over 95%. CoD? It matched that accuracy, staying above 91%, but here\u2019s the kicker: it used only about 40 tokens per response compared to CoT's 200!", "Jamie": "Whoa, that's a massive difference! Eighty percent less token count? That's gotta save a lot of processing power and time. What about those other tasks?"}, {"Alex": "Similar results. In common sense reasoning, CoD often outperformed CoT in accuracy, especially with Claude 3.5 Sonnet. And, in symbolic reasoning, like the coin flip task, both CoT and CoD achieved perfect accuracy, but CoD slashed the token usage.", "Jamie": "So, not only is it faster, but it's also sometimes more accurate? Hmm, I wonder why that is? Is CoT too verbose, maybe leading the AI down the wrong path sometimes?"}, {"Alex": "That\u2019s our hypothesis, Jamie. Overthinking can indeed be a problem. By focusing on only the essential information, CoD helps the LLM stay on track, avoiding unnecessary detours in reasoning.", "Jamie": "That makes a lot of sense. So how exactly did you enforce that to five-word reasoning steps? You cannot just politely ask, right?"}, {"Alex": "That's right, Jamie. We didn't enforce it strictly with code, but it was used a general guideline to promte short reasoning steps by wording it in the prompt. The models were asked to think step by step and only keep a minimum draft for each step with 5 words at most.", "Jamie": "And that was enough to get the models to comply? That's amazing! I would imagine the latency saving is also incredible, right? What are we talking, specifically?"}, {"Alex": "It is! We found some of our evaluation results show that CoD helps significantly reduces both latency and cost by generating considerably fewer tokens in responses compared to CoT. Like In sports understanding tasks, where CoD reduces the average output tokens from 189.4 to 14.3, that is a 92.4% reduction.", "Jamie": "That\u2019s amazing! "}, {"Alex": "Exactly! The latency savings are significant. For instance, in the GSM8K task, CoD cut the average latency by 76.2% and 48.4% compared to CoT, depending on the model. That's a game-changer for real-time applications.", "Jamie": "Wow. That's really important, it also open up so many real-world possibilities. I would imagine it requires also less energy?"}, {"Alex": "Definitely! That's one of our primary motivations of this approach is to align more closely with human reasoning by pri-oritizing efficiency and minimalism.", "Jamie": "This is starting to sound like a no-brainer. So, why isn't everyone already doing this? What are the limitations?"}, {"Alex": "That's what we were thinking as well. The limitation is that other more complex tasks would be require self-correction, or external knowledge retrieval may be necessary during the reasoning process. ", "Jamie": "Okay, so it's not a perfect solution for every situation. But it sounds pretty darn good for many. What kind of impact could this have on the future of LLMs?"}, {"Alex": "CoD shows us that effective reasoning in LLMs doesn't necessarily require lengthy outputs. This opens up possibilities for combining CoD with other latency-reducing methods or training models with compact reasoning data. It's about making AI more efficient and practical.", "Jamie": "It\u2019s like teaching AI to be a minimalist, only keeping what's essential. What's next for CoD? What are you planning to explore in future research?"}, {"Alex": "We're eager to explore combining CoD with other latency-reducing methods, such as adaptive parallel reasoning or multi-pass validation, to further optimize performance across different application domains. Also, we hope our work can inspire new strategies to improve reasoning models by training with compact reasoning data, while maintaining interpretability and efficiency in LLMs.", "Jamie": "This is really exciting stuff, Alex. It sounds like this research could really change the game for AI applications that need to be fast and efficient."}, {"Alex": "That's the goal, Jamie. We believe CoD can help bridge the gap between research-driven improvements in reasoning and the practical demands of real-world systems.", "Jamie": "What do you think would be most exciting use case?"}, {"Alex": "It's hard to pick just one! I think it would be very exciting to see how this approach could be applied to more complex tasks with self-correction. Also it would be nice to see if our models can be efficiently fine-tuned using CoD approach.", "Jamie": "That sounds really cool. I am pretty exciting to see that as well."}, {"Alex": "Awesome! I am glad that you are just as excited as I am. One exciting implication is that CoD helps bridge the gap between research-driven improvements in reasoning and the practical demands of real-world systems.", "Jamie": "That is very true. Are there any open-source options available for people that want to try it out? Or is it just a concept?"}, {"Alex": "Great question. We do not have any open-source options for this yet. But we are actively thinking if we could create some templates available to try. We can also create a new version of this open-source soon.", "Jamie": "That's awesome! "}, {"Alex": "Absolutely, Jamie! So, to wrap things up, we've explored 'Chain of Draft,' a novel prompting strategy that allows LLMs to reason faster by writing less. By focusing on essential information, CoD matches or surpasses 'Chain-of-Thought' accuracy while significantly reducing token usage and latency. It's a promising step toward more efficient and practical AI systems. Thanks for joining me, Jamie!", "Jamie": "Thanks, Alex! It was great learning about this exciting research!"}]