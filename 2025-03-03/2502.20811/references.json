{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a Visual Language Model for Few-Shot Learning", "publication_date": "2022-01-01", "reason": "This paper introduces the Flamingo model, a visual language model important for few-shot learning, which is a significant area in multimodal understanding."}, {"fullname_first_author": "Max Bain", "paper_title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval", "publication_date": "2021-01-01", "reason": "The work provides a joint video and image encoder which acts as the foundational source for retrieving data for video understanding which HAICTrain dataset is built from."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Improved Baselines with Visual Instruction Tuning", "publication_date": "2024-01-01", "reason": "It is a foundational paper that proposes using visual instruction tuning, a methodology for improving the baselines for multimodal models."}, {"fullname_first_author": "Agrim Gupta", "paper_title": "Embodied Intelligence via Learning and Evolution", "publication_date": "2021-01-01", "reason": "This work is a foundational paper that provides crucial insights into embodied intelligence, focusing on methods to better understand downstream tasks like human-computer interaction and human video generation."}, {"fullname_first_author": "Mu Cai", "paper_title": "TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models", "publication_date": "2024-01-01", "reason": "This paper introduces TemporalBench which assesses temporal understanding to serve as a key evaluation benchmark used in comparing performance of the created dataset."}]}