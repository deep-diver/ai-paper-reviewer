<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-28s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/</link><description>Recent content in 2025-02-28s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 27 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/index.xml" rel="self" type="application/rss+xml"/><item><title>Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20378/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20378/</guid><description>EDGS: Achieves faster, high-quality dynamic scene rendering by sparse time-variant attribute modeling and intelligent static area filtering.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20378/cover.png"/></item><item><title>LongRoPE2: Near-Lossless LLM Context Window Scaling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20082/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20082/</guid><description>LongRoPE2: Extends LLM context windows while preserving performance and reducing training costs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20082/cover.png"/></item><item><title>Mobius: Text to Seamless Looping Video Generation via Latent Shift</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20307/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20307/</guid><description>Mobius generates seamless looping videos from text using latent shift, repurposing pre-trained models without training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20307/cover.png"/></item><item><title>Multimodal Representation Alignment for Image Generation: Text-Image Interleaved Control Is Easier Than You Think</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20172/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20172/</guid><description>DREAM ENGINE: Text-image interleaved control made easy, unifying text and visual cues for creative image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20172/cover.png"/></item><item><title>R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19735/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19735/</guid><description>R1-T1: RL-driven framework incentivizing translation capability in LLMs via reasoning learning, achieving superior performance in multiple languages &amp;amp; domains.</description></item><item><title>R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20395/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20395/</guid><description>R2-T2: Boost multimodal MoE performance by re-routing experts in test-time, no retraining needed!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20395/cover.png"/></item><item><title>SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20127/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20127/</guid><description>SoRFT enhances LLMs for issue resolving via subtask-oriented reinforced fine-tuning, outperforming other open-source models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20127/cover.png"/></item><item><title>UniTok: A Unified Tokenizer for Visual Generation and Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20321/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20321/</guid><description>UniTok: A unified tokenizer bridging the visual generation and understanding gap via multi-codebook quantization, achieving SOTA in MLLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.20321/cover.png"/></item><item><title>Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19459/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19459/</guid><description>ArtGS: Achieves state-of-the-art, efficient interactable replicas of complex articulated objects via Gaussian Splatting.</description></item><item><title>NeoBERT: A Next-Generation BERT</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19587/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19587/</guid><description>NeoBERT: A new encoder that enhances bidirectional language understanding with cutting-edge architecture, data, and training, achieving SOTA results with only 250M parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19587/cover.png"/></item><item><title>Self-rewarding correction for mathematical reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19613/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.19613/</guid><description>LLM can now reason and correct itself using self-generated data, achieving performance on par with external reward models!</description></item><item><title>Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.16944/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.16944/</guid><description>DVPO: A lean RLHF framework that decouples value &amp;amp; policy optimization with global value guidance, cutting GPU use by 40% and training time by 35%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-28/2502.16944/cover.png"/></item></channel></rss>