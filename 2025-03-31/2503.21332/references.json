{"references": [{"fullname_first_author": "Madaan", "paper_title": "Self-refine: Iterative refinement with self-feedback", "publication_date": "2024-01-01", "reason": "This paper is highly cited as a key work on using self-feedback for iterative text refinement, a core concept related to the current paper's focus on refinement."}, {"fullname_first_author": "Wadhwa", "paper_title": "Learning to refine with fine-grained natural language feedback", "publication_date": "2024-01-01", "reason": "This paper is consistently referenced when discussing refinement pipelines and the use of feedback, making it a core reference in the field."}, {"fullname_first_author": "Song", "paper_title": "FineSurE: Fine-grained summarization evaluation using llms", "publication_date": "2024-01-01", "reason": "This paper provides the evaluation framework (FineSurE) used extensively in the current paper to assess faithfulness, completeness, and conciseness."}, {"fullname_first_author": "Lee", "paper_title": "UniSumEval: Towards unified, fine-grained, multi-dimensional summarization evaluation for llms", "publication_date": "2024-01-01", "reason": "This is a key evaluation benchmark (UniSumEval) used in the experiments, providing a foundation for comparing different refinement pipelines across multiple dimensions."}, {"fullname_first_author": "Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2022-01-01", "reason": "LoRA is used to fine-tune LLaMA-3, making it an important reference as it outlines how the model in the paper was fine-tuned."}]}