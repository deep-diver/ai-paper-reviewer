<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-31s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/</link><description>Recent content in 2025-03-31s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/index.xml" rel="self" type="application/rss+xml"/><item><title>Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/</guid><description>This paper enhances Reinforcement Learning from Human Feedback (RLHF) by tackling reward hacking and response diversity issues through improved data construction methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/cover.png"/></item><item><title>Hi3DGen: High-fidelity 3D Geometry Generation from Images via Normal Bridging</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22236/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22236/</guid><description>Hi3DGen: High-fidelity 3D geometry generation from images via normal bridging.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22236/cover.png"/></item><item><title>ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22194/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22194/</guid><description>ORIGEN: First zero-shot 3D orientation grounding in text-to-image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22194/cover.png"/></item><item><title>Segment Any Motion in Videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22268/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22268/</guid><description>New method for moving object segmentation by combining long-range motion cues, semantic features, and SAM2, achieving state-of-the-art performance in challenging scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22268/cover.png"/></item><item><title>Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22675/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22675/</guid><description>ReaRec: Unleashing latent reasoning power for sequential recommendation through inference-time multi-step reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22675/cover.png"/></item><item><title>A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21614/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21614/</guid><description>Survey on improving efficiency in large reasoning models across language, multimodality, and beyond.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21614/cover.png"/></item><item><title>Reconstructing Humans with a Biomechanically Accurate Skeleton</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21751/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21751/</guid><description>HSMR: Reconstructing 3D humans with a biomechanically accurate skeleton model from a single image, enhancing pose realism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21751/cover.png"/></item><item><title>ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21332/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21332/</guid><description>ReFeed enhances multi-dimensional summarization by using reflective reasoning on feedback, mitigating trade-offs between dimensions and improving robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21332/cover.png"/></item><item><title>SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21732/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21732/</guid><description>SparseFlex: Achieves high-res, arbitrary-topology 3D shape modeling via sparse isosurface representation and sectional voxel training. Revolutionizing 3D generative AI!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21732/cover.png"/></item><item><title>X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time Tomographic Reconstruction</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21779/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21779/</guid><description>X2-Gaussian enables continuous-time 4D CT reconstruction via dynamic radiative Gaussian splatting and self-supervised respiratory motion learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21779/cover.png"/></item><item><title>Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20785/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20785/</guid><description>Free4D: Tuning-free 4D scene generation with spatial-temporal consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20785/cover.png"/></item><item><title>Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20308/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20308/</guid><description>New metrics and representation enhance 3D talking head realism by focusing on perceptual lip synchronization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.20308/cover.png"/></item><item><title>PHYSICS: Benchmarking Foundation Models on University-Level Physics Problem Solving</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21821/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.21821/</guid><description>PHYSICS: A new benchmark reveals foundation models struggle with university-level physics, highlighting needs for improved reasoning and knowledge integration.</description></item><item><title>4D-Bench: Benchmarking Multi-modal Large Language Models for 4D Object Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.17827/</link><pubDate>Sat, 22 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.17827/</guid><description>4D-Bench: The first benchmark for assessing MLLMs in 4D object understanding, revealing weak temporal understanding and the need for advancements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.17827/cover.png"/></item><item><title>MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/</link><pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/</guid><description>MedAgent-Pro: An evidence-based reasoning agentic system for reliable multi-modal medical diagnosis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/cover.png"/></item><item><title>OThink-MR1: Stimulating multimodal generalized reasoning capabilities via dynamic reinforcement learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.16081/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.16081/</guid><description>OThink-MR1 enhances MLLM reasoning via dynamic reinforcement learning, achieving remarkable cross-task generalization!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.16081/cover.png"/></item></channel></rss>