{"references": [{"fullname_first_author": "DeepSeek-AI", "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.", "publication_date": "2025-01-01", "reason": "This paper introduces DeepSeek-R1, a model that exhibits test-time scaling, and the current paper uses it as one of its evaluated models, making it crucial for understanding the experimental setup."}, {"fullname_first_author": "Niklas Muennighoff", "paper_title": "s1: Simple test-time scaling.", "publication_date": "2025-01-01", "reason": "Similar to DeepSeek-AI's paper, this paper introduces the s1 model, and the current study uses this model alongside DeepSeek-R1, making it indispensable for comprehending the experimental design and comparative results."}, {"fullname_first_author": "Yonatan Geifman", "paper_title": "Selective classification for deep neural networks.", "publication_date": "2017-01-01", "reason": "This paper is foundational because it introduces the concept of selective classification, which is central to the current study's exploration of models abstaining from answering when lacking confidence."}, {"fullname_first_author": "D. A. Ferrucci", "paper_title": "Introduction to \"this is watson\".", "publication_date": "2012-01-01", "reason": "Ferrucci's paper provides crucial context by introducing Watson, a system that balances answering questions with measuring costs for incorrect responses, thus illustrating the practical importance of selective question answering."}, {"fullname_first_author": "Jordan Boyd-Graber", "paper_title": "What question answering can learn from trivia nerds.", "publication_date": "2020-01-01", "reason": "Boyd-Graber's work offers insights into what question answering systems can learn, emphasizing the nuances of costs and rewards associated with correct and incorrect answers, which closely aligns with the risk-sensitive evaluation in this paper."}]}