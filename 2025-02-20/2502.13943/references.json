{"references": [{"fullname_first_author": "Wei", "paper_title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "publication_date": "2023-01-01", "reason": "This paper is important because it introduces the Chain-of-Thought (CoT) prompting method, a foundational approach for improving reasoning in LLMs."}, {"fullname_first_author": "Wang", "paper_title": "Math-Shepherd: Verify and Reinforce LLMs Step-by-Step Without Human Annotations", "publication_date": "2024-01-01", "reason": "This paper is important because it is the open-source baseline against which the paper is trying to improve, and offers a heuristic annotation method for reducing PRM annotation costs."}, {"fullname_first_author": "Lightman", "paper_title": "Let's Verify Step by Step", "publication_date": "2023-05-01", "reason": "This paper is important because it demonstrates that step-by-step feedback improves the reasoning reliability and reduces logical errors, a principle the current paper builds upon."}, {"fullname_first_author": "Yu", "paper_title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "publication_date": "2023-09-01", "reason": "This paper is important because it is used to train Mistral-V0.1 and Llama-3.1-8B, the models used in this work."}, {"fullname_first_author": "Guo", "paper_title": "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence", "publication_date": "2024-01-01", "reason": "This paper is important because the model 'Deepseek-Coder-Base' is trained to generate code PRM training data and is used as one of the baseline comparison models."}]}