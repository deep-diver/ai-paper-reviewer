[{"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/Name-bias-eg.png", "caption": "Figure 1: Example of an interaction with an LLM with an identity presumption based on the name", "description": "The figure displays a conversation between a user and a large language model (LLM). The user's name, Raj, is used to infer his cultural background.  Consequently, the LLM's response to the user's query (about wedding outfits) suggests clothing options typically associated with Indian culture (Sherwani, Kurta and Churidars), demonstrating that the LLM made assumptions about the user's cultural identity based solely on his name. This highlights a potential bias within the LLM's personalization mechanisms.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/name-bias-setup.png", "caption": "Figure 2: Experimental Setup", "description": "This figure illustrates the experimental setup used in the study to analyze cultural presumptions in Large Language Model (LLM) responses.  The process begins with selecting names and associated cultures from a dataset, which are then paired with information-seeking questions. These prompts, including names, are fed to four different LLMs, generating responses. The responses are then evaluated using two methods: an LLM-as-a-judge approach, and a method comparing responses to pre-defined cultural assertions.  The outcome assesses the extent of cultural presumptions made by the LLMs based on the names provided in the prompts.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2502.11995/x1.png", "caption": "Figure 3: Default Bias values averaged over Models and Facets. For details refer to subsection\u00a03.8.", "description": "This figure displays the average default bias across different LLMs and cultural facets (food, clothing, tradition & rituals).  Default bias refers to the inherent cultural biases present in LLM responses even *without* any user name provided in the prompt.  Higher values indicate a stronger predisposition towards certain cultures in the generated text.", "section": "4 Results"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/vertical_bias_plots.png", "caption": "Figure 4: Bias across models above the default bais. For calculation of bais refer to section 3.8", "description": "This figure displays the cultural bias exhibited by four different large language models (LLMs) when presented with names from various cultural backgrounds.  The bias is calculated as the difference between the bias observed with names and the default bias without names, as described in section 3.8 of the paper.  Each bar represents a country, and its height indicates the degree of cultural bias for that country across all evaluated models and aspects (food, clothing, and rituals). Positive values suggest that the model displays a stronger bias towards associating the given names with the respective culture than would be expected based on default bias. Conversely, negative values indicate a weaker association than expected.", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/aspect_boxplot.png", "caption": "Figure 5: Box plot showing comparison of bias for countries values (averaged over 4 models) for each facet.", "description": "This box plot visualizes the cultural bias in Large Language Model (LLM) responses, broken down by facet (clothing, food, rituals & traditions).  For each facet, the plot shows the average bias for different countries across four different LLMs. The bias score represents how often the model's responses reflect culturally specific aspects of the named country, compared to responses where no country is explicitly mentioned. Higher values indicate stronger cultural bias towards that country.", "section": "4.2 Cultural presumptions based on names"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/overall_diff_heatmap.png", "caption": "Figure 6: Cross-cultural bias heatmap for bias values over the default (3.8). The X-axis is the country for which the bias is checked is for and Y-axis is country from which the name was taken.", "description": "This heatmap visualizes the cross-cultural bias in Large Language Model (LLM) responses when names from different countries are used in prompts.  Each cell in the heatmap represents the bias score (calculated as the difference between bias with and without names; see Section 3.8) for a given pair of countries. The X-axis shows the country being investigated for bias in the LLM's response, while the Y-axis shows the country of origin for the name used in the prompt. Warmer colors indicate stronger biases, meaning the LLM's response shows a stronger association with a specific culture when a name from that culture is present in the prompt.  Cooler colors show weaker biases or even negative biases, suggesting the name may not strongly trigger cultural assumptions.", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/names_biased_responses_plot.png", "caption": "Figure 7: Distribution of biased responses per name [Names are omitted from the x-axis to avoid clutter]", "description": "This figure shows the distribution of the number of biased responses generated by LLMs for each of the names used in the study.  The x-axis represents the individual names used in the prompts (omitted for clarity), and the y-axis shows the count of biased responses associated with each name. The distribution is heavily skewed, indicating that a relatively small number of names account for a large proportion of the biased responses while the majority of the names have very few or no biased responses.", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/grouped_percentage_comparison.png", "caption": "Figure 8: Percentage contribution of each word\u2019s biased responses relative to the overall number of biased responses", "description": "This figure shows the percentage of biased responses containing each specific word, relative to the total number of biased responses across all words. It helps to understand which words contribute most strongly to the cultural bias observed in the model's responses when names are included in prompts.", "section": "Facet-based comparison"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/country_differences_baroai.png", "caption": "Figure 9: OpenAI GPT-4o-mini name bias over the default responses", "description": "This figure displays a bar chart illustrating the degree to which OpenAI's GPT-40-mini model exhibits cultural biases when names are included in prompts, compared to responses without names (default bias).  The chart showcases the difference in bias for various countries, indicating the extent to which the model associates specific names with particular cultures, thereby demonstrating the cultural presumptions embedded within the model's responses.", "section": "Results"}, {"figure_path": "https://arxiv.org/html/2502.11995/extracted/6211043/figures/grid_bias_plots_base.png", "caption": "Figure 10: Default Bias across models, for calculation and discussion about default bias refer to section 3.8", "description": "This figure presents a comparison of default bias across four different large language models (LLMs).  Default bias refers to the inherent biases exhibited by LLMs in their responses even without any user-provided names or identifying information.  Each bar in the chart represents a country, and the height of the bar shows the average default bias score for that country across various facets (food, clothing, tradition) considered in the study.  The figure helps to visualize how different LLMs display varying levels of default bias towards different cultures, providing insights into the underlying biases present in the models' training data.", "section": "Results"}]