[{"figure_path": "https://arxiv.org/html/2502.01105/x2.png", "caption": "Figure 1. LayerTracer enables the creation of cognitive-aligned layered SVGs, either from text prompts or by converting images into layer-wise SVGs.", "description": "This figure demonstrates the core functionality of LayerTracer, a novel framework for generating layered Scalable Vector Graphics (SVGs).  It shows two primary input methods:  text prompts and input images.  In both cases, the system produces a multi-layered SVG. The text prompt pathway simulates a designer's cognitive process, generating a series of design steps that are then vectorized into a layered SVG. The image pathway converts a given image into a layered SVG, mimicking the process of tracing an image, while preserving structural integrity. The cognitive alignment aspect implies the generated layered SVGs retain the logical structure and hierarchical organization typically found in professionally-designed SVGs, making them more editable and intuitive for designers.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2502.01105/x3.png", "caption": "Figure 2. The LayerTracer architecture comprises three key components: (1) Layer-wise Model: Pretrained on our proposed dataset to generate layered pixel sequences from text prompt; (2) Image2Layers Model: Merges LoRA with the Flux base DiT, enabling image-conditioned generation through VAE-encoded latent tokens; (3) Layer-wise Vectorization: Converts raster sequences to SVGs via differential analysis between adjacent layers, followed by B\u00e9zier optimization using vtracer to eliminate redundant paths while preserving structural fidelity.", "description": "LayerTracer's architecture consists of three main components.  The first is the Layer-wise Model, a diffusion transformer pretrained on a novel dataset of sequentially generated layered SVGs. This model takes text prompts as input and outputs a sequence of layered raster images, simulating the steps a designer might take to create an SVG. The second is the Image2Layers Model, which uses a pre-trained diffusion transformer combined with Low-Rank Adaptation (LoRA) and a Variational Autoencoder (VAE). This model takes a raster image as input, encodes it into latent tokens using the VAE, and then leverages the LoRA fine-tuning to generate a sequence of layered raster images that mimic how a designer might have created the input image.  Finally, the third component is Layer-wise Vectorization, which processes the raster image sequences generated by the previous two components. Using differential analysis, this component identifies changes between consecutive layers, converting the raster images to clean, editable SVG vector graphics.  B\u00e9zier optimization with vtracer removes redundant paths, ensuring structural fidelity and professional quality.", "section": "3 METHOD"}, {"figure_path": "https://arxiv.org/html/2502.01105/x4.png", "caption": "Figure 3. Given a text prompt, LayerTracer generates cognitive-aligned layered SVGs that mimic human design cognition.", "description": "This figure showcases the LayerTracer model's ability to generate layered SVGs from text prompts.  The examples illustrate the model's capacity to produce complex, multi-layered designs that closely resemble the way a human designer would approach the task, following a logical sequence and spatial reasoning. Each image demonstrates a sequence of SVG generation steps, starting from basic shapes and gradually adding details, mirroring the iterative process of human design. The cognitive alignment is emphasized by the structured, layered output, highlighting LayerTracer's ability to model the human design cognition.", "section": "3.6 Layer-Wise Vectorization"}, {"figure_path": "https://arxiv.org/html/2502.01105/x5.png", "caption": "Figure 4. Given a raster image of an icon as input, LayerTracer predicts how the icon was created layer by layer, achieving cognitive-aligned layered vectorization.", "description": "Figure 4 presents an example of LayerTracer's image-to-layered-SVG conversion.  A raster image (a simple icon) is provided as input.  LayerTracer analyzes the image and infers the likely step-by-step process a human designer would have followed to create it. The output isn't just a single vectorized version of the input; it is a series of layered SVGs, each representing a stage in the construction.  This layered output mimics the way a designer builds complexity, with each layer adding detail or refinement, demonstrating the model's understanding of cognitive design processes. The final result shows how LayerTracer breaks down the complex image into its constituent layers, reflecting a logical and editable SVG.", "section": "4.2 Generation Results"}, {"figure_path": "https://arxiv.org/html/2502.01105/x6.png", "caption": "Figure 5. Compare with baseline methods in Text-to-SVG generation task.", "description": "This figure compares the performance of LayerTracer against three baseline methods (SVGDreamer, Vecfusion, and DiffSketcher) in generating SVGs from text prompts.  It visually showcases the outputs generated by each method for a set of example prompts, highlighting LayerTracer's ability to produce more coherent and less cluttered SVGs compared to the baselines. The prompts focus on iconic illustrations, demonstrating the models' ability to generate meaningful and editable vector graphics from text.", "section": "4.3 Comparison and Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.01105/x7.png", "caption": "Figure 6. Compare with baseline methods in layer-wise vectorization task. Our results are more concise and exhibit more logical layering.", "description": "Figure 6 presents a comparison of layer-wise vectorization results between LayerTracer and several baseline methods.  It showcases the superior performance of LayerTracer by demonstrating more concise and logically layered vector graphics outputs compared to the less coherent and cluttered results produced by the baseline methods.  The figure visually highlights the improved quality and organization of layers achieved by LayerTracer, emphasizing its ability to maintain structure and editability.", "section": "4.3 Comparison and Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.01105/x8.png", "caption": "Figure 7. Ablation study of Serpentine Layout Strategy.", "description": "This ablation study investigates the impact of the serpentine layout strategy on the performance of LayerTracer.  The serpentine layout arranges the sequence of frames (representing the steps in SVG creation) in a grid pattern to encourage the model to learn the temporal relationships between the frames.  The figure likely shows comparative results of the model's performance, metrics such as MSE and SSIM on training and testing datasets, when trained with and without the serpentine layout. The results would demonstrate the effectiveness of this layout strategy in improving the coherence and quality of the generated SVG sequences.", "section": "4.4 Ablation Study of Serpentine Layout Strategy"}]