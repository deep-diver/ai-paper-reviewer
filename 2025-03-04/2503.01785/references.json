{"references": [{"fullname_first_author": "Daya Guo", "paper_title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning", "publication_date": "2025-01-12", "reason": "This paper is important because it introduces DeepSeek-R1, a model that enhances reasoning capabilities in LLMs through reinforcement learning, which is a key inspiration and baseline comparison for this work."}, {"fullname_first_author": "Agrim Gupta", "paper_title": "Lvis: A dataset for large vocabulary instance segmentation", "publication_date": "2019-01-01", "reason": "This paper is important as it introduces the LVIS dataset, which is used in this work to evaluate the generalization capabilities of Visual-RFT, especially in open vocabulary object detection."}, {"fullname_first_author": "Xin Lai", "paper_title": "Lisa: Reasoning segmentation via large language model", "publication_date": "2024-01-01", "reason": "This paper is important because LISA provides a reasoning grounding task used to evaluate the model's ability to ground objects according to user needs and is also used as a baseline comparison for this work."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-03", "reason": "This paper is important as it details the GRPO algorithm for policy optimization which is used to guide policy optimization in Visual-RFT."}, {"fullname_first_author": "Peng Wang", "paper_title": "Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution", "publication_date": "2024-09-12", "reason": "This paper is important as it details the Qwen2-VL model used as a baseline and foundation for this work and is used to train and evaluate the performance of Visual-RFT on various visual perception tasks."}]}