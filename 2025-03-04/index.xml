<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-04s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/</link><description>Recent content in 2025-03-04s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 03 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/index.xml" rel="self" type="application/rss+xml"/><item><title>CodeArena: A Collective Evaluation Platform for LLM Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01295/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01295/</guid><description>CodeArena: Collective evaluation for LLM code generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01295/cover.png"/></item><item><title>DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/</guid><description>DiffRhythm: Fast &amp;amp; Simple End-to-End Song Generation via Latent Diffusion, creating full songs (4+ mins) with vocal &amp;amp; accompaniment in seconds!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/cover.png"/></item><item><title>Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01774/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01774/</guid><description>DIFIX3D+ improves 3D reconstructions by reducing artifacts via single-step diffusion models, enhancing novel-view synthesis quality and consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01774/cover.png"/></item><item><title>Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01103/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01103/</guid><description>Likelihood-based generative models get a GAN-like boost via a new Direct Discriminative Optimization, ditching the joint training complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01103/cover.png"/></item><item><title>Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01370/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01370/</guid><description>Kiss3DGen generates 3D assets by repurposing 2D diffusion models, enabling efficient 3D editing and enhancement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01370/cover.png"/></item><item><title>Large-Scale Data Selection for Instruction Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01807/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01807/</guid><description>RDS+ is the unsung hero for scaling instruction tuning data selection!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01807/cover.png"/></item><item><title>Liger: Linearizing Large Language Models to Gated Recurrent Structures</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01496/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01496/</guid><description>Liger: LLMs linearized to gated recurrent models, enabling efficient deployment via key matrix repurposing and LoRA fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01496/cover.png"/></item><item><title>Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01743/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01743/</guid><description>Phi-4: Compact Multimodal Language Models via Mixture-of-LoRAs</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01743/cover.png"/></item><item><title>SampleMix: A Sample-wise Pre-training Data Mixing Strategey by Coordinating Data Quality and Diversity</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01506/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01506/</guid><description>SampleMix: Sample-wise Pre-training Data Mixing by Coordinating Data Quality and Diversity</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01506/cover.png"/></item><item><title>VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01739/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01739/</guid><description>VideoUFO: A new user-focused, million-scale dataset that improves text-to-video generation by aligning training data with real user interests and preferences!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01739/cover.png"/></item><item><title>Visual-RFT: Visual Reinforcement Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01785/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01785/</guid><description>Visual-RFT: Enhance LVLMs&amp;rsquo; visual reasoning via reinforcement learning with verifiable rewards, achieving strong performance with limited data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01785/cover.png"/></item><item><title>When an LLM is apprehensive about its answers -- and when its uncertainty is justified</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01688/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01688/</guid><description>This paper investigates when LLMs are apprehensive and when their uncertainty is justified.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01688/cover.png"/></item><item><title>Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01714/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01714/</guid><description>LLMs primarily rely on word form, unlike humans, when reconstructing semantics, indicating a need for context-aware mechanisms to enhance LLMs&amp;rsquo; adaptability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01714/cover.png"/></item><item><title>CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00729/</link><pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00729/</guid><description>CLEA: Enhancing task execution in dynamic environments with a closed-loop embodied agent.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00729/cover.png"/></item><item><title>DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00784/</link><pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00784/</guid><description>DuoDecoding: Accelerating LLM inference by strategically deploying draft &amp;amp; target models on CPU &amp;amp; GPU for parallel decoding and dynamic drafting.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00784/cover.png"/></item><item><title>Speculative Ad-hoc Querying</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00714/</link><pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00714/</guid><description>SpeQL: Near-instant results for ad-hoc queries using LLMs to predict and precompute, dramatically improving user experience.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00714/cover.png"/></item><item><title>Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00501/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00501/</guid><description>Qilin: A multimodal dataset with APP-level user sessions for advancing search and recommendation systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.00501/cover.png"/></item><item><title>From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence Generation up to 100K Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18890/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18890/</guid><description>TokenSwift: Accelerate LLM ultra-long sequence generation up to 100K tokens with &amp;gt;3x speedup and lossless accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18890/cover.png"/></item><item><title>OneRec: Unifying Retrieve and Rank with Generative Recommender and Iterative Preference Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18965/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18965/</guid><description>OneRec: A unified generative model that replaces the traditional retrieve-and-rank strategy, significantly improving recommendation quality in real-world scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.18965/cover.png"/></item><item><title>Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.16779/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.16779/</guid><description>Plane-DUSt3R: Leveraging pre-trained models for unposed sparse views room layout reconstruction, enhancing robustness and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2502.16779/cover.png"/></item></channel></rss>