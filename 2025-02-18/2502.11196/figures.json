[{"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/illustration.png", "caption": "Figure 1: Illustration of our findings: Phase shift from formation to optimization in the evolution of knowledge circuits, each phase characterized by distinct features at the performance, topology, and component levels.", "description": "This figure illustrates the key findings of the paper regarding the evolution of knowledge circuits in large language models (LLMs) during continual pre-training.  It highlights a phase shift in the circuit evolution, transitioning from a 'formation phase' to an 'optimization phase'. Each phase is characterized by specific traits related to model performance (e.g., Hit@10 accuracy), the topology of the knowledge circuits (e.g., the connectivity and structural organization of the circuit), and their components (e.g., the types and roles of attention heads). The figure visually depicts how these characteristics evolve and change between the two phases. This provides a concise overview of the paper's central argument about how LLMs acquire and integrate new knowledge.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/hit_at_10.png", "caption": "Figure 2: Hit@10 of the performance of knowledge circuits in GPT-2 Small, GPT-2 Medium and Phi-1.5 throughout training. Left: Performance for circuits discovered by different types of knowledge, where K_rel and K_compl represent relevant new knowledge and completely new knowledge, respectively. Right: Performance for circuits discovered by different frequencies of knowledge, where Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively. Note that we smooth the curves using a window size of 3 epochs for all settings.", "description": "Figure 2 presents the Hit@10 performance of knowledge circuits across three different language models (GPT-2 Small, GPT-2 Medium, and Phi-1.5) during continual pre-training.  The left side shows how the performance of circuits differs depending on whether the knowledge they represent is \n*relevant new knowledge* (K_rel; knowledge already known to the model but requiring further refinement), or\n*completely new knowledge* (K_compl; entirely novel knowledge not previously present in the model). The right side illustrates how circuit performance varies based on the frequency of the knowledge within the training data: low-frequency (Low-freq; [1,2)), medium-frequency (Medium-freq; [2,5]), and high-frequency (High-freq; (5,27]).  The curves are smoothed using a 3-epoch window for improved readability.", "section": "Analyzing the Evolution of Knowledge Circuits throughout Training"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/similarity_entropy.png", "caption": "Figure 3: Top: Edges Jaccard Similarity of intermediate knowledge circuits with the circuits at the final checkpoint. Bottom: Knowledge Cutcuit Entropy of knowledge circuits throughout training. K_rel and K_compl represent relevant new knowledge and completely new knowledge, respectively. Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively.", "description": "Figure 3 visualizes the evolution of knowledge circuits during continual pre-training. The top panel displays the Jaccard similarity between edge sets of intermediate knowledge circuits and the final circuit.  This metric quantifies the structural consistency of circuits throughout the training process. The bottom panel shows the knowledge circuit entropy, measuring the concentration of edge importance within the circuits. Lower entropy indicates higher centralization, signifying fewer, more critical edges driving the knowledge processing.  Different lines represent the evolution of circuits related to different types of knowledge (relevant vs. completely new) and knowledge frequencies (low, medium, high). This allows observation of how different factors influence the structural stabilization and information flow within the circuits over time.", "section": "4.2 Topology Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/specific_circuit_performance.png", "caption": "Figure 4: Hit@10 of the performance of aligned knowledge circuits in GPT-2 Small throughout training. Init, Before, After, Last represents the circuits whose topologies align with those at the initial checkpoint, the checkpoint before the phase shift, the checkpoint after the phase shift, and the final checkpoint, respectively. Original represents the original knowledge circuits at each checkpoint. Note that we smooth the curves using a window size of 3 epochs.", "description": "This figure displays the performance (Hit@10) of knowledge circuits in GPT-2 Small throughout continual pre-training.  Four sets of aligned circuits are compared against the original circuits. 'Init' represents circuits aligned with the initial checkpoint's topology, 'Before' with the topology before the observed phase shift, 'After' after the shift, and 'Last' at the final checkpoint.  The curves are smoothed using a 3-epoch window for better visualization. The comparison shows how circuit performance changes as the model's knowledge circuits evolve and stabilize.", "section": "4 Analyzing the Evolution of Knowledge Circuits throughout Training"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/specialized_components.png", "caption": "Figure 5: Proportion of specialized attention heads in all nodes of the knowledge circuits throughout training for GPT-2 Small and GPT-2 Medium. Note that we smooth the curves using a window size of 3 epochs.", "description": "This figure visualizes the evolution of specialized attention heads within knowledge circuits during the continual pre-training process of GPT-2 Small and GPT-2 Medium language models.  The proportion of three types of specialized attention heads \u2013 mover heads, relation heads, and mixture heads \u2013 are tracked across training epochs for all nodes within the identified knowledge circuits. The curves are smoothed using a 3-epoch window for better visualization of trends. The plot shows the dynamic shift in the prominence of different head types during the training process, offering insights into the mechanisms by which LLMs acquire and process new knowledge.", "section": "4.3 Components Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_heads_distribution.png", "caption": "Figure 6: Top: Layer distribution of mover head in the knowledge circuits in GPT-2 Small throughout training. Bottom: Layer distribution of relation head in the knowledge circuits in GPT-2 Small throughout training.", "description": "This figure visualizes the distribution of \"mover\" and \"relation\" attention heads across different layers of GPT-2 Small's neural network during the continual pre-training process.  The top panel shows the layer-wise distribution of mover heads, illustrating their prevalence at different layers throughout training. The bottom panel presents the corresponding distribution for relation heads, similarly showing their presence across layers during training. This visualization helps in understanding how these specialized attention heads contribute to knowledge acquisition and processing within the model, and how their distribution changes over time.", "section": "4.3 Component Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_activation_ratio.png", "caption": "Figure 7: Layer distribution of the edges activation ratio within the knowledge circuits in GPT-2 Small.", "description": "This figure shows how the activation of edges within knowledge circuits varies across different layers of the GPT-2 Small model.  It visualizes the proportion of activated edges originating from each layer, providing insights into the flow of information through the knowledge circuit. This is useful for understanding the roles of different layers in knowledge processing and how information is integrated within the circuit.", "section": "4.3 Components Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_rank_and_prob.png", "caption": "Figure 8: Top: Rank of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for GPT-2 Small. Bottom: The corresponding probability of the target attribute token.", "description": "This figure visualizes the evolution of two key metrics related to the target attribute token during the training process of GPT-2 Small. The \"Rank\" subplot (top) illustrates the ranking of the target attribute token among all predicted tokens at the last token position, as calculated by unembedding the intermediate layers' outputs into the vocabulary space.  The \"Probability\" subplot (bottom) displays the probability of the target attribute token being predicted at the same last token position. The plots show these values across different layers and training epochs, offering insights into how the model's predictions for the target attribute evolve during learning.", "section": "4.3 Components Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/accuracy.png", "caption": "Figure 9: Accuracy curves across continual pre-training. K_rel and K_compl represent relevant new knowledge and completely new knowledge, respectively. First-token Acc stands for the model\u2019s next-token prediction accuracy on the first token of each attribute, while Query Acc stands for the generation accuracy on downstream query tasks for each attribute.", "description": "This figure displays the accuracy of two different metrics across continual pre-training of language models.  The models are trained on two types of new knowledge: relevant new knowledge (K_rel), which builds upon existing knowledge, and completely new knowledge (K_compl), which is unrelated to prior knowledge.  The 'First-token Acc' metric measures the model's accuracy in predicting the next token, specifically the first token of an attribute in a knowledge triple (subject, relation, attribute). This assesses the immediate acquisition and memorization of the new knowledge. The 'Query Acc' metric evaluates the model's overall accuracy when generating complete answers to downstream queries about these attributes.  This shows the model's ability to use the newly acquired knowledge to answer complex questions. The plots show that, for both metrics, accuracy improves over time during training, and accuracy is generally higher for relevant knowledge (K_rel) than for completely new knowledge (K_compl).", "section": "4 Analyzing the Evolution of Knowledge Circuits throughout Training"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/transfer_hit_at_10.png", "caption": "Figure 10: Hit@10 of the transfer performance of knowledge circuits in GPT-2 Small and GPT-2 Medium throughout training. Low-freq Circuit, Medium-freq Circuit, and High-freq Circuit represent knowledge circuits identified by knowledge with the frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively. Note that we smooth the curves using a window size of 3 epochs for all settings.", "description": "This figure displays the performance of knowledge circuits (evaluated using Hit@10 metric) when transferred to test sets with different knowledge frequencies.  Three types of circuits were used: those identified using low-frequency knowledge (1-2 occurrences), medium-frequency knowledge (2-5 occurrences), and high-frequency knowledge (5-27 occurrences).  The results show how well these circuits generalize to data outside of their training frequency range. Curves are smoothed using a 3-epoch window for better visualization.", "section": "4 Analyzing the Evolution of Knowledge Circuits throughout Training"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/nodes_similarity.png", "caption": "Figure 11: Nodes Jaccard Similarity of intermediate knowledge circuits with the circuits at the final checkpoint. K_rel and K_compl represent relevant new knowledge and completely new knowledge, respectively. Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively.", "description": "This figure displays the Jaccard similarity between the edge sets of intermediate knowledge circuits and the final knowledge circuits, across different models (GPT-2 Small, GPT-2 Medium, TinyLlama, and Phi-1.5).  The Jaccard similarity, a measure of set similarity, quantifies the overlap in edges between the intermediate circuits at various training checkpoints and the final, fully formed circuits.  Separate lines represent different types of newly acquired knowledge (K_rel - relevant new knowledge, K_compl - completely new knowledge) and different frequencies of knowledge entities within the training data (Low-freq, Medium-freq, High-freq). The x-axis represents the training epoch, illustrating the evolution of knowledge circuit structure during the training process.  The y-axis shows the Jaccard similarity score, with a higher score indicating greater similarity between the intermediate and final knowledge circuits. The figure illustrates how the structure of the knowledge circuits evolves and stabilizes over time, and how this process might differ based on the type and frequency of new information.", "section": "4.2 Topology Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_medium_activation_ratio.png", "caption": "Figure 12: Layer distribution of the edges activation ratio within the knowledge circuits in GPT-2 Medium.", "description": "This heatmap visualizes the distribution of edge activation ratios across different layers within the knowledge circuits of the GPT-2 Medium language model.  The x-axis represents training epochs, the y-axis represents layers in the model, and the color intensity of each cell corresponds to the activation ratio. Darker colors indicate higher activation ratios, showing which layers contribute more to the knowledge circuit's activation during training.  The figure provides insights into how the importance of different layers for knowledge processing evolves throughout continual pre-training.", "section": "4.3 Components Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_medium_heads_distribution.png", "caption": "Figure 13: Left: Layer distribution of mover head in the knowledge circuits in GPT-2 Medium throughout training. Right: Layer distribution of relation head in the knowledge circuits in GPT-2 Medium throughout training.", "description": "This figure visualizes the distribution of mover and relation heads within the knowledge circuits of the GPT-2 Medium model across different layers throughout the training process.  The left panel shows the distribution of mover heads, while the right panel displays the distribution of relation heads. Each panel shows how the number of heads varies across different layers at various training epochs, offering insight into the evolution of these specialized attention heads during knowledge acquisition.", "section": "4.3 Component Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_forget.png", "caption": "Figure 14: Edges Jaccard Similarity of intermediate knowledge circuits with the circuits at the final checkpoint of the previous knowledge acquisition experiment.", "description": "This figure displays the Jaccard similarity between the edge sets of intermediate knowledge circuits and the final knowledge circuit from a prior knowledge acquisition experiment.  The Jaccard Similarity measures the overlap between two sets, in this case, the sets of edges in the knowledge circuits. A higher Jaccard similarity indicates that the structure of the intermediate knowledge circuits is more similar to the final knowledge circuit. The x-axis shows the number of training steps, while the y-axis represents the Jaccard similarity.  Different lines represent different replay ratios, showing how often previous training data is reintroduced during continual learning. This visualization helps understand how the topology of the knowledge circuits evolves and stabilizes throughout the continual learning process, and the impact of replaying previous data on that stability.", "section": "4.2 Topology Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_all_rank_and_prob.png", "caption": "Figure 15: Top: Rank of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for GPT-2 Small. Bottom: Probability of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for GPT-2 Small. Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively.", "description": "This figure visualizes the change in the rank and probability of the target attribute token at the final token position during the unembedding process for GPT-2 Small model across different training epochs.  The visualizations are separated into top (rank) and bottom (probability) sections, each further divided into three sub-plots based on the frequency of the knowledge: low, medium, and high. The x-axis represents training epochs, and the y-axis represents the layer number, with color intensity reflecting the rank or probability values.  The color scale helps to easily identify patterns in rank and probability variations as the model trains across different knowledge frequencies.", "section": "4.3 Components Analysis"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/gpt2_medium_rank_and_prob.png", "caption": "Figure 16: Top: Rank of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for GPT-2 Medium. Bottom: Probability of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for GPT-2 Medium. Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively.", "description": "This figure shows the rank and probability of the target attribute token at different layers of GPT-2 Medium throughout the training process.  The top part displays the rank, while the bottom displays the probability.  The results are broken down for three different frequencies of knowledge in the training data: low-frequency, medium-frequency, and high-frequency.  The analysis helps in understanding how the model accesses and retrieves the knowledge at different stages of learning.", "section": "4.3.2 Changes in Vocabulary Space"}, {"figure_path": "https://arxiv.org/html/2502.11196/extracted/6191678/figures/tinyllama_rank_and_prob.png", "caption": "Figure 17: Top: Rank of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for TinyLlama. Bottom: Probability of the target attribute token when unembedding the intermediate layer\u2019s output into vocabulary space at the last token position throughout training for TinyLlama. Low-freq, Medium-freq, and High-freq represent knowledge with frequencies in the ranges [1,2)12[1,2)[ 1 , 2 ), [2,5]25[2,5][ 2 , 5 ] and (5,27]527(5,27]( 5 , 27 ], respectively.", "description": "This figure displays the evolution of knowledge circuits in TinyLlama during continual pre-training. The top half shows the rank of the target attribute token at the last token position as it is unembedded from the intermediate layers into the vocabulary space at different training epochs.  The bottom half shows the probability of that same target token at the same point. Different colors represent different frequencies of knowledge, ranging from low frequency to high frequency. This visualization helps in understanding how the model's ability to access and utilize knowledge evolves over time and how that's affected by knowledge frequency.", "section": "4.3 Components Analysis"}]