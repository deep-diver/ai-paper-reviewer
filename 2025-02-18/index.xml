<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-18s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/</link><description>Recent content in 2025-02-18s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 17 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/index.xml" rel="self" type="application/rss+xml"/><item><title>Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11901/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11901/</guid><description>PoPilot, a novel proof-oriented programming LLM, outperforms GPT-40 by 64% under data scarcity by using synthetic data augmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11901/cover.png"/></item><item><title>Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12146/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12146/</guid><description>Diffusion-Sharpening enhances diffusion model fine-tuning by optimizing sampling trajectories, achieving faster convergence and high inference efficiency without extra NFEs, leading to improved alignm&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12146/cover.png"/></item><item><title>HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12148/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12148/</guid><description>HermesFlow seamlessly bridges the understanding-generation gap in MLLMs using a novel Pair-DPO framework and self-play optimization on homologous data, achieving significant performance improvements.</description></item><item><title>Intuitive physics understanding emerges from self-supervised pretraining on natural videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11831/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11831/</guid><description>AI models learn intuitive physics from self-supervised video pretraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11831/cover.png"/></item><item><title>Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11578/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11578/</guid><description>LLMs&amp;rsquo; performance on language complexity tasks (LIX &amp;amp; ADD) reveals a strong correlation with general capabilities, suggesting complexity metrics as noisy zero-shot proxies for model evaluation.</description></item><item><title>Large Language Models and Mathematical Reasoning Failures</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11574/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11574/</guid><description>Large language models struggle with mathematical word problems, demonstrating flaws in reasoning despite achieving high accuracy; a new study highlights these persistent gaps in generalization abiliti&amp;hellip;</description></item><item><title>Learning Getting-Up Policies for Real-World Humanoid Robots</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12152/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12152/</guid><description>HUMANUP: A novel two-stage reinforcement learning framework enables real-world humanoid robots to autonomously recover from falls on various terrains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12152/cover.png"/></item><item><title>MagicArticulate: Make Your 3D Models Articulation-Ready</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12135/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12135/</guid><description>MagicArticulate automates 3D model animation preparation by generating skeletons and skinning weights, overcoming prior manual methods&amp;rsquo; limitations, and introducing Articulation-XL, a large-scale benc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12135/cover.png"/></item><item><title>PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12054/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12054/</guid><description>PhysReason benchmark evaluates physics-based reasoning in LLMs, revealing critical limitations and guiding future improvements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.12054/cover.png"/></item><item><title>SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11438/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11438/</guid><description>SAFE-SQL boosts Text-to-SQL accuracy by intelligently generating and filtering self-augmented examples for in-context learning, surpassing existing methods in challenging scenarios.</description></item><item><title>System Message Generation for User Preferences using Open-Source Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11330/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11330/</guid><description>SYSGEN: A novel pipeline generates effective system messages for LLMs using open-source models, improving model responses and addressing data scarcity in supervised fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11330/cover.png"/></item><item><title>video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11775/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11775/</guid><description>video-SALMONN-01: An open-source audio-visual LLM enhances video understanding with a novel reasoning-intensive dataset and the pDPO method, achieving significant accuracy gains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11775/cover.png"/></item><item><title>Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11275/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11275/</guid><description>Cuckoo: a novel information extraction (IE) model leverages LLM pre-training data, achieving superior performance in few-shot settings by reframing next-token prediction as token extraction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11275/cover.png"/></item><item><title>Dyve: Thinking Fast and Slow for Dynamic Process Verification</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11157/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11157/</guid><description>Dyve: A novel dynamic process verifier boosts LLM reasoning accuracy by cleverly combining fast, immediate checks with deeper, slower analyses for complex steps, achieving significant performance gain&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11157/cover.png"/></item><item><title>How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11196/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11196/</guid><description>LLMs&amp;rsquo; knowledge acquisition is unveiled through the lens of evolving knowledge circuits, revealing how new knowledge integration depends on relevance to existing knowledge, exhibiting distinct phases &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11196/cover.png"/></item><item><title>Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11089/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11089/</guid><description>NSA: a novel sparse attention mechanism achieves efficient long-context modeling by combining algorithmic innovations with hardware-aligned optimizations, surpassing full attention models across vario&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11089/cover.png"/></item><item><title>Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11098/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11098/</guid><description>TalkHier, a novel framework for LLM multi-agent systems, uses structured communication and hierarchical refinement to achieve state-of-the-art performance on various tasks, improving collaboration and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11098/cover.png"/></item><item><title>Towards Data-Efficient Pretraining for Atomic Property Prediction</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11085/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11085/</guid><description>High-quality, task-relevant pretraining data surpasses large-scale pretraining in atomic property prediction, achieving comparable performance at 1/24th the computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.11085/cover.png"/></item><item><title>Memory, Benchmark &amp; Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10550/</link><pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10550/</guid><description>MIKASA, a new benchmark for memory-intensive reinforcement learning, provides a unified framework for evaluating memory capabilities in diverse scenarios, including complex robotic manipulation tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10550/cover.png"/></item><item><title>CRANE: Reasoning with constrained LLM generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.09061/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.09061/</guid><description>CRANE: A novel constrained decoding algorithm boosts LLM reasoning accuracy by strategically alternating between unconstrained reasoning and constrained generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.09061/cover.png"/></item><item><title>Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.09083/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.09083/</guid><description>Fact-checkers need explainable AI: This study reveals how AI tools can better support fact-checkers by providing explanations tailored to their workflows, addressing unmet needs, and improving the eff&amp;hellip;</description></item><item><title>Better Embeddings with Coupled Adam</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.08441/</link><pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.08441/</guid><description>Coupled Adam: A novel optimizer fixes anisotropic word embeddings in LLMs, boosting model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.08441/cover.png"/></item><item><title>I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10458/</link><pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10458/</guid><description>ThinkDiff empowers text-to-image diffusion models with multimodal reasoning by aligning vision-language models to an LLM decoder, achieving state-of-the-art results on in-context reasoning benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10458/cover.png"/></item><item><title>One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10454/</link><pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10454/</guid><description>New benchmark COUNTERMATH enhances LLMs&amp;rsquo; mathematical reasoning using counterexample-driven proofs, revealing current models&amp;rsquo; limitations and paving the way for improved mathematical capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-18/2502.10454/cover.png"/></item></channel></rss>