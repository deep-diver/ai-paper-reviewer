[{"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/pull_figure.png", "caption": "Figure 1: Pretraining on a High-Quality, Task-Relevant Dataset. Pretraining on a carefully selected high-quality dataset achieves comparable or superior mean absolute error (MAE) across tasks while reducing computational cost by a factor of 24 compared to JMP-S, which is pretrained on all upstream datasets. Lower MAE indicates better performance.", "description": "This figure demonstrates the effectiveness of using a high-quality, task-relevant dataset for pretraining in atomic property prediction.  By carefully selecting a smaller, relevant dataset, the model achieves comparable or even better performance (measured by Mean Absolute Error, MAE) compared to a model (JMP-S) pretrained on a significantly larger, more diverse dataset that includes the smaller dataset.  Importantly, this improvement comes with a 24-fold reduction in computational cost.  Lower MAE values indicate better predictive accuracy.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/pipeline.png", "caption": "Figure 2: Pipeline Overview. Our paradigm for pretraining and finetuning consists of two new components: (1) Dataset Selection Stage, where a distance metric \u03b4\ud835\udeff\\deltaitalic_\u03b4 is employed to identify the dataset that is most similar to our downstream task dataset \ud835\udc9fdsubscript\ud835\udc9f\ud835\udc51\\mathcal{D}_{d}caligraphic_D start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, in this case \ud835\udc9fu(1)superscriptsubscript\ud835\udc9f\ud835\udc621\\mathcal{D}_{u}^{(1)}caligraphic_D start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT. This selected dataset is then used for pretraining the model. (2) Limited Budget Pretraining, where we impose a training budget by subsampling \ud835\udca9\ud835\udca9\\mathcal{N}caligraphic_N random samples from \ud835\udc9fu(1)superscriptsubscript\ud835\udc9f\ud835\udc621\\mathcal{D}_{u}^{(1)}caligraphic_D start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT and training the model for \u2130\u2130\\mathcal{E}caligraphic_E epochs. This results in a computational budget of \ud835\udc9e=\u2130\u00d7\ud835\udca9\ud835\udc9e\u2130\ud835\udca9\\mathcal{C}=\\mathcal{E}\\times\\mathcal{N}caligraphic_C = caligraphic_E \u00d7 caligraphic_N. The pretrained backbone \u03b8b(1)\u2063\u2217superscriptsubscript\ud835\udf03\ud835\udc4f1\\theta_{b}^{(1)*}italic_\u03b8 start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) \u2217 end_POSTSUPERSCRIPT is subsequently finetuned on the downstream task dataset \ud835\udc9fdsubscript\ud835\udc9f\ud835\udc51\\mathcal{D}_{d}caligraphic_D start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT to obtain the final model parameters \u03b8d\u2217superscriptsubscript\ud835\udf03\ud835\udc51\\theta_{d}^{*}italic_\u03b8 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT.", "description": "This figure illustrates the pipeline for pretraining and finetuning a model for atomic property prediction.  It highlights a two-stage process.  First, a dataset selection stage uses a distance metric (\u03b4) to choose the most relevant upstream dataset (from a set of candidate datasets D<sup>(1)</sup>, D<sup>(2)</sup>,...D<sup>(K)</sup>) for pretraining, based on its similarity to the downstream task dataset (D<sub>d</sub>). Second, a limited budget pretraining stage is employed, where a subset of N samples are randomly selected from the chosen upstream dataset and trained for E epochs, resulting in a computational budget of C = E * N.  The pretrained backbone (\u03b8<sup>(1)*</sup><sub>b</sub>) from this process is then fine-tuned using the downstream dataset to get the final model parameters (\u03b8*<sub>d</sub>).", "section": "3. Formulation and Setup"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/CSI_bar_balanced_flat_equiformerV2_ID.png", "caption": "Figure 3: Alignment Between Upstream and Downstream Using CSI. We assess how well the extracted representations from each upstream dataset align with downstream tasks using our CSI metric, where lower values indicate stronger alignment. ANI-1x demonstrates the closest feature alignment with downstream tasks, whereas OC20 and OC22 show the weakest alignment.", "description": "This figure displays the Chemical Similarity Index (CSI) values, which measure the alignment between different upstream datasets and various downstream tasks. Lower CSI values represent stronger alignment.  The results show that ANI-1x exhibits the strongest alignment with all downstream tasks, indicating its high relevance for pretraining. Conversely, OC20 and OC22 demonstrate the weakest alignment, suggesting that they might be less suitable for these specific downstream tasks. This highlights the importance of selecting task-relevant upstream datasets for effective pretraining.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/highCSI.png", "caption": "Figure 4: Impact of Adding Less Relevant Pretraining Data. Adding 1\u2062M1\ud835\udc401M1 italic_M OC22 samples to a 2\u2062M2\ud835\udc402M2 italic_M-sample ANI-1x baseline worsens downstream performance despite a larger pretraining budget. This highlights the importance of dataset relevance and the CSI metric for effective pretraining.", "description": "This figure demonstrates the effect of adding less relevant pretraining data to a model already pretrained on a relevant dataset.  Specifically, it shows the downstream performance of a model pretrained on 2 million samples from the ANI-1x dataset (a high-quality dataset highly relevant to the downstream tasks), and then further pretrained with an additional 1 million samples from the OC22 dataset (a less relevant dataset).  Despite the increase in the total amount of training data (a larger pretraining budget), the inclusion of the OC22 data negatively impacts the model's performance on downstream tasks.  This result underlines the importance of selecting relevant pretraining data and highlights the Chemical Similarity Index (CSI) as a valuable metric for evaluating data relevance and guiding effective pretraining.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/CSI_bar_balanced_flat_equiformerV2_OOD.png", "caption": "Figure 5: CSI Between Upstream and OOD Downstream Tasks. CSI values predict that ANI-1x is the best pretraining choice for QMOF, while OC20 and OC22 are best for MatBench.", "description": "Figure 5 illustrates the Chemical Similarity Index (CSI) values for various upstream datasets in relation to out-of-distribution (OOD) downstream tasks: QMOF and MatBench.  CSI, a metric assessing dataset relevance, indicates the predicted best upstream dataset for each OOD task.  For the QMOF task, the CSI suggests ANI-1x as the most suitable pretraining dataset. However, for the MatBench task, the CSI suggests that OC20 and OC22 are more appropriate choices. This visualization highlights the ability of CSI to predict the best-performing upstream dataset for various downstream tasks, even those outside the initial training distribution.", "section": "5. Beyond In-Distribution"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/CSI_bar_balanced_mean_equiformerV2_ID.png", "caption": "Figure 6: Impact of using mean aggregation instead of flattening on CSI values. We notice that the mean pooling incorrectly reduced the score for OC22 potentially due to over-smoothing.", "description": "This figure compares the results of using two different aggregation methods for calculating the Chemical Similarity Index (CSI): flattening and mean pooling.  The CSI is a metric used to measure the similarity between upstream (pretraining) and downstream (target task) datasets.  The results show that using mean pooling to aggregate node features before computing the CSI leads to a lower score for the OC22 dataset than when using flattening. This suggests that the mean pooling method may be over-smoothing the features in OC22, which reduces its apparent similarity to the downstream datasets. This is an important finding because it highlights the potential impact of the feature aggregation method on the overall CSI results. This implies the need for careful consideration when choosing feature aggregation methods for the computation of CSI.", "section": "3.2 The Chemical Similarity Index (CSI)"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/CSI_bar_random_flat_equiformerV2_ID.png", "caption": "Figure 7: Impact of using random sampling strategy instead of class-balanced sampling. As highlighted in the long-tail analysis in Appendix C, random sampling can lead to class underrepresentation, potentially affecting the correlation between upstream and downstream tasks. Notably, both ANI-1x and Transition-1x exhibit different patterns compared to the class-balanced values reported in the main paper.", "description": "This figure compares the results of using two different sampling methods: random sampling and class-balanced sampling, to create subsets of upstream datasets for the CSI calculation.  It shows that random sampling, due to its non-uniform nature, can create subsets with significant class imbalances. This imbalance impacts the subsequent CSI scores, which measure dataset similarity. The figure highlights how the CSI values obtained using random sampling differ significantly from those obtained using class-balanced sampling, particularly for ANI-1x and Transition-1x.  The class-balanced sampling, employed in the main study, is shown to produce more robust and reliable CSI scores.", "section": "B. Additional Analysis on the Metric Design"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/CSI_bar_balanced_flat_JMP_ID.png", "caption": "Figure 8: The impact of using another backbone. We use JMP pretrained model and show that similar insights are obtained where Ani-1x is shown as the most similar.", "description": "This figure explores the robustness of the Chemical Similarity Index (CSI) metric by using a different backbone model (the JMP pretrained model) for calculating CSI values. The results are compared against the CSI values obtained using the original backbone in the paper. The comparison shows that using a different backbone model still yields similar insights, demonstrating the consistency and reliability of CSI in identifying the most relevant upstream datasets for pretraining, where ANI-1x consistently demonstrates the highest similarity across different downstream tasks.", "section": "B. Additional Analysis on the Metric Design"}, {"figure_path": "https://arxiv.org/html/2502.11085/extracted/6207443/images/upstream_sampling.png", "caption": "Figure 9: Impact of sampling strategies on subset construction for feature extraction. We sample 10K instances for each upstream task, highlighting the differences in class coverage between random and class-balanced sampling.", "description": "This figure compares two sampling methods for selecting subsets of upstream datasets used in pretraining: random sampling and class-balanced sampling.  Both methods aim to select 10,000 instances from each upstream dataset (ANI-1x, Transition-1x, OC20, OC22). The bar charts show the distribution of the number of unique molecular structures (classes) represented in the selected subset for each dataset and sampling method. Class-balanced sampling aims for more even coverage across all classes, whereas random sampling may over-represent common structures and under-represent rare ones. This is important because class imbalance can affect the performance of machine learning models.", "section": "C. Long-Tail Analysis"}]