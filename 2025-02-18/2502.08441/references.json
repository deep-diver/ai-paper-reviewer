{"references": [{"fullname_first_author": "Sanjeev Arora", "paper_title": "A latent variable model approach to PMI-based word embeddings", "publication_date": "2016-MM-DD", "reason": "This paper is foundational in understanding the latent variable models approach to word embeddings, which is relevant to the paper's focus on anisotropic embeddings and their improvement."}, {"fullname_first_author": "Daniel Bi\u015b", "paper_title": "Too much in common: Shifting of embeddings in transformer language models and its implications", "publication_date": "2021-MM-DD", "reason": "This paper identifies the collective shift of embedding vectors as a key cause of anisotropy, which is a central problem addressed in the current paper."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-MM-DD", "reason": "This highly influential paper introduces the GPT-3 model, which is used as a baseline model for the large-scale experiments in the present paper."}, {"fullname_first_author": "Jun Gao", "paper_title": "Representation degeneration problem in training natural language generation models", "publication_date": "2019-MM-DD", "reason": "This paper first described the anisotropy issue, or representation degeneration problem, providing initial insights into the limitations of embedding vectors and motivating the current study."}, {"fullname_first_author": "Diederik Kingma", "paper_title": "Adam: A method for stochastic optimization", "publication_date": "2014-MM-DD", "reason": "This paper introduces the Adam optimizer, which is the primary optimization algorithm used and improved upon in the current paper, forming the foundation for the proposed Coupled Adam optimization algorithm."}]}