<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ National University of Singapore on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-national-university-of-singapore/</link><description>Recent content in üè¢ National University of Singapore on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 20 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-national-university-of-singapore/index.xml" rel="self" type="application/rss+xml"/><item><title>InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.15027/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.15027/</guid><description>InterFeedback: LMMs need better human feedback to enhance AI assistants!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.15027/cover.png"/></item><item><title>PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.14397/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.14397/</guid><description>PhotoDoodle: Mimicking artistic image editing with personalized decorative elements through learning from few-shot pairwise data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-24/2502.14397/cover.png"/></item><item><title>LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.13922/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.13922/</guid><description>LongPO: Self-evolve LLMs to excel in long contexts via short-to-long preference optimization, boosting performance without sacrificing short-context skills.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.13922/cover.png"/></item><item><title>NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.12638/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.12638/</guid><description>NExT-Mol: Combines 1D language models with 3D diffusion for molecule generation, achieving state-of-the-art performance and validity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-20/2502.12638/cover.png"/></item><item><title>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/</guid><description>CoT-Valve dynamically adjusts reasoning chain lengths based on task difficulty, significantly reducing inference costs in large language models without substantial accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/cover.png"/></item><item><title>Enhance-A-Video: Better Generated Video for Free</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/</guid><description>Enhance-A-Video boosts video generation quality without retraining, by enhancing cross-frame correlations in diffusion transformers, resulting in improved coherence and visual fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/cover.png"/></item><item><title>GuardReasoner: Towards Reasoning-based LLM Safeguards</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/</link><pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/</guid><description>GuardReasoner enhances LLM safety with reasoning-based guardrails, improving performance, explainability, and generalization on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/cover.png"/></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</guid><description>CLEAR: Conv-Like Linearization boosts pre-trained Diffusion Transformers, achieving 6.3x faster 8K image generation with minimal quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/cover.png"/></item><item><title>TinyFusion: Diffusion Transformers Learned Shallow</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/</link><pubDate>Mon, 02 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/</guid><description>TinyFusion, a novel learnable depth pruning method, crafts efficient shallow diffusion transformers with superior post-fine-tuning performance, achieving a 2x speedup with less than 7% of the original&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/cover.png"/></item><item><title>Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/</link><pubDate>Tue, 26 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/</guid><description>Collaborative Decoding (CoDe) dramatically boosts visual auto-regressive model efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/cover.png"/></item><item><title>OminiControl: Minimal and Universal Control for Diffusion Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/</guid><description>OminiControl: A minimal, universal framework efficiently integrates image conditions into diffusion transformers, enabling diverse and precise control over image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/cover.png"/></item><item><title>When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/</link><pubDate>Wed, 20 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/</guid><description>AnchorAttention enhances long-context LLMs by mitigating BFloat16&amp;rsquo;s disruptive effects on RoPE, improving performance and speeding up training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/cover.png"/></item><item><title>Balancing Pipeline Parallelism with Vocabulary Parallelism</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/</link><pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/</guid><description>Boost large language model training speed by 51% with Vocabulary Parallelism, a novel technique that balances computation and memory usage across pipeline stages.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/cover.png"/></item><item><title>GenXD: Generating Any 3D and 4D Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</guid><description>GenXD: A unified model generating high-quality 3D &amp;amp; 4D scenes from any number of images, advancing the field of dynamic scene generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/cover.png"/></item></channel></rss>