<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ National University of Singapore on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-national-university-of-singapore/</link><description>Recent content in üè¢ National University of Singapore on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Sat, 29 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-national-university-of-singapore/index.xml" rel="self" type="application/rss+xml"/><item><title>Efficient Inference for Large Reasoning Models: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/</link><pubDate>Sat, 29 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/</guid><description>Survey on efficient inference methods for Large Reasoning Models, focusing on mitigating token inefficiency while preserving quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23077/cover.png"/></item><item><title>LogQuant: Log-Distributed 2-Bit Quantization of KV Cache with Superior Accuracy Preservation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.19950/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.19950/</guid><description>LogQuant: 2-bit quantization for KV cache, superior accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.19950/cover.png"/></item><item><title>MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/</link><pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/</guid><description>MedAgent-Pro: An evidence-based reasoning agentic system for reliable multi-modal medical diagnosis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.18968/cover.png"/></item><item><title>1000+ FPS 4D Gaussian Splatting for Dynamic Scene Rendering</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16422/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16422/</guid><description>4DGS-1K: Achieves 1000+ FPS for dynamic scene rendering via a compact, memory-efficient framework, offering a 41x storage reduction and 9x faster speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16422/cover.png"/></item><item><title>Improving Autoregressive Image Generation through Coarse-to-Fine Token Prediction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16194/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16194/</guid><description>Coarse-to-Fine Token Prediction improves autoregressive image generation by assigning the same coarse label for similar tokens, balancing generation quality and computational efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16194/cover.png"/></item><item><title>Ultra-Resolution Adaptation with Ease</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16322/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16322/</guid><description>URA: Ultra-resolution adaptation made easy! Uses synthetic data &amp;amp; minor weight tuning for efficient, high-res text-to-image diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16322/cover.png"/></item><item><title>Impossible Videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14378/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14378/</guid><description>Impossible videos expose AI limits!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14378/cover.png"/></item><item><title>TPDiff: Temporal Pyramid Video Diffusion Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.09566/</link><pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.09566/</guid><description>TPDiff accelerates video diffusion by progressively increasing frame rates during diffusion, optimizing computational efficiency with a novel stage-wise training strategy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.09566/cover.png"/></item><item><title>PE3R: Perception-Efficient 3D Reconstruction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.07507/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.07507/</guid><description>PE3R: Achieves fast and accurate 3D scene reconstruction from 2D images by enhanced perception and efficiency.</description></item><item><title>Words or Vision: Do Vision-Language Models Have Blind Faith in Text?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02199/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02199/</guid><description>VLMs often disproportionately trust text over visual data, leading to performance drops and safety concerns.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02199/cover.png"/></item><item><title>Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20378/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20378/</guid><description>EDGS: Achieves faster, high-quality dynamic scene rendering by sparse time-variant attribute modeling and intelligent static area filtering.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20378/cover.png"/></item><item><title>InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15027/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15027/</guid><description>InterFeedback: LMMs need better human feedback to enhance AI assistants!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15027/cover.png"/></item><item><title>PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14397/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14397/</guid><description>PhotoDoodle: Mimicking artistic image editing with personalized decorative elements through learning from few-shot pairwise data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14397/cover.png"/></item><item><title>LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13922/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13922/</guid><description>LongPO: Self-evolve LLMs to excel in long contexts via short-to-long preference optimization, boosting performance without sacrificing short-context skills.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13922/cover.png"/></item><item><title>NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/</guid><description>NExT-Mol: Combines 1D language models with 3D diffusion for molecule generation, achieving state-of-the-art performance and validity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/cover.png"/></item><item><title>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/</guid><description>CoT-Valve dynamically adjusts reasoning chain lengths based on task difficulty, significantly reducing inference costs in large language models without substantial accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09601/cover.png"/></item><item><title>Enhance-A-Video: Better Generated Video for Free</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/</guid><description>Enhance-A-Video boosts video generation quality without retraining, by enhancing cross-frame correlations in diffusion transformers, resulting in improved coherence and visual fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07508/cover.png"/></item><item><title>GuardReasoner: Towards Reasoning-based LLM Safeguards</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/</link><pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/</guid><description>GuardReasoner enhances LLM safety with reasoning-based guardrails, improving performance, explainability, and generalization on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.18492/cover.png"/></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</guid><description>CLEAR: Conv-Like Linearization boosts pre-trained Diffusion Transformers, achieving 6.3x faster 8K image generation with minimal quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/cover.png"/></item><item><title>TinyFusion: Diffusion Transformers Learned Shallow</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/</link><pubDate>Mon, 02 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/</guid><description>TinyFusion, a novel learnable depth pruning method, crafts efficient shallow diffusion transformers with superior post-fine-tuning performance, achieving a 2x speedup with less than 7% of the original&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01199/cover.png"/></item><item><title>Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/</link><pubDate>Tue, 26 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/</guid><description>Collaborative Decoding (CoDe) dramatically boosts visual auto-regressive model efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17787/cover.png"/></item><item><title>OminiControl: Minimal and Universal Control for Diffusion Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/</guid><description>OminiControl: A minimal, universal framework efficiently integrates image conditions into diffusion transformers, enabling diverse and precise control over image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15098/cover.png"/></item><item><title>When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/</link><pubDate>Wed, 20 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/</guid><description>AnchorAttention enhances long-context LLMs by mitigating BFloat16&amp;rsquo;s disruptive effects on RoPE, improving performance and speeding up training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13476/cover.png"/></item><item><title>Balancing Pipeline Parallelism with Vocabulary Parallelism</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/</link><pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/</guid><description>Boost large language model training speed by 51% with Vocabulary Parallelism, a novel technique that balances computation and memory usage across pipeline stages.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05288/cover.png"/></item><item><title>GenXD: Generating Any 3D and 4D Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</guid><description>GenXD: A unified model generating high-quality 3D &amp;amp; 4D scenes from any number of images, advancing the field of dynamic scene generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/cover.png"/></item></channel></rss>