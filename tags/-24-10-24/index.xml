<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-24 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-24/</link><description>Recent content in ðŸ¤— 24-10-24 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Wed, 23 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-24/index.xml" rel="self" type="application/rss+xml"/><item><title>DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18084/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18084/</guid><description>DynamicCity generates large-scale, high-quality 4D LiDAR scenes capturing dynamic environments, improving autonomous driving system development.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18084/cover.png"/></item><item><title>Lightweight Neural App Control</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17883/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17883/</guid><description>LiMAC, a lightweight neural app control architecture, uses a hybrid approach combining a small Action Transformer with a fine-tuned vision-language model for precise, real-time mobile app control, out&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17883/cover.png"/></item><item><title>MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17637/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17637/</guid><description>MIA-DPO boosts large vision-language model performance on multi-image tasks by cleverly augmenting single-image data and using attention mechanisms to filter out inaccurate responses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17637/cover.png"/></item><item><title>Scalable Ranked Preference Optimization for Text-to-Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18013/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18013/</guid><description>Researchers created a scalable method for aligning text-to-image models using synthetic preference datasets and a novel ranking-based optimization, significantly improving image quality and prompt-fol&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18013/cover.png"/></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17891/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17891/</guid><description>Researchers efficiently adapt large autoregressive language models into competitive diffusion language models, overcoming previous scalability challenges and demonstrating improved performance on vari&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17891/cover.png"/></item><item><title>TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18071/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18071/</guid><description>TP-Eval unveils the hidden potential of MLLMs by customizing prompts to mitigate evaluation bias caused by prompt sensitivity, leading to a more accurate assessment of model capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18071/cover.png"/></item><item><title>WorldSimBench: Towards Video Generation Models as World Simulators</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18072/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18072/</guid><description>WorldSimBench: A new benchmark rigorously evaluates video generation models&amp;rsquo; ability to simulate realistic, actionable videos, advancing embodied AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18072/cover.png"/></item><item><title>LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17434/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17434/</guid><description>LongVU: A novel spatiotemporal compression method enables efficient long-video understanding by selectively reducing redundant video frames and tokens, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17434/cover.png"/></item><item><title>LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17242/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17242/</guid><description>LVSM, a novel transformer-based model, achieves state-of-the-art novel view synthesis by eliminating 3D inductive biases, leading to superior quality, scalability, and zero-shot generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17242/cover.png"/></item><item><title>M-RewardBench: Evaluating Reward Models in Multilingual Settings</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15522/</link><pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15522/</guid><description>M-REWARDBENCH: A new multilingual benchmark reveals significant performance gaps in reward models across languages, highlighting the need for improved cross-lingual alignment in LLMs.</description></item><item><title>ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</guid><description>ARKit LabelMaker creates a massive, real-world 3D dataset with dense semantic labels, automatically generated to boost indoor scene understanding model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/cover.png"/></item><item><title>MedINST: Meta Dataset of Biomedical Instructions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</guid><description>MEDINST: a massive biomedical instruction dataset (133 tasks, 7M samples) improves LLM cross-task generalization in medical analysis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/cover.png"/></item><item><title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</guid><description>Value-Guided Policy Steering (V-GPS) significantly boosts the performance of generalist robotic policies by re-ranking actions via offline RL, without retraining, improving both precision and robustne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/cover.png"/></item></channel></rss>