<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Applications on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/ai-applications/</link><description>Recent content in AI Applications on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 05 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/ai-applications/index.xml" rel="self" type="application/rss+xml"/><item><title>Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04455/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04455/</guid><description>Code-as-Monitor (CaM) uses vision-language models and constraint-aware visual programming to achieve both reactive and proactive robotic failure detection in real-time, improving success rates and red&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04455/cover.png"/></item><item><title>DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15139/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15139/</guid><description>DiffusionDrive: a novel truncated diffusion model achieves real-time, high-quality end-to-end autonomous driving by leveraging multi-mode action distributions and significantly reducing computational &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15139/cover.png"/></item><item><title>WildLMa: Long Horizon Loco-Manipulation in the Wild</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15131/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15131/</guid><description>WildLMa enables robots to perform complex, long-horizon manipulation tasks in unstructured environments by combining language-conditioned imitation learning, a whole-body controller for efficient tele&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15131/cover.png"/></item><item><title>Soft Robotic Dynamic In-Hand Pen Spinning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12734/</link><pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12734/</guid><description>SWIFT, a new system, enables a soft robotic hand to learn dynamic pen spinning via real-world trial-and-error, achieving 100% success across diverse pen properties without explicit object modeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12734/cover.png"/></item><item><title>The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.10323/</link><pubDate>Fri, 15 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.10323/</guid><description>Claude 3.5 Computer Use: A groundbreaking AI model offering public beta graphical user interface (GUI) agent for computer use is comprehensively analyzed in this research. This study provides an out-o&amp;hellip;</description></item><item><title>Hermes: A Large Language Model Framework on the Journey to Autonomous Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06490/</link><pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06490/</guid><description>Hermes, a novel LLM-based framework, automates cellular network modeling by generating explainable &amp;lsquo;blueprints&amp;rsquo; for constructing Network Digital Twins (NDTs), paving the way for fully autonomous netwo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06490/cover.png"/></item><item><title>DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04999/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04999/</guid><description>DynaMem empowers robots with online dynamic spatio-semantic memory, achieving a 2x improvement in pick-and-drop success rate on non-stationary objects compared to static systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04999/cover.png"/></item><item><title>DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/</guid><description>DeeR-VLA dynamically adjusts the size of a multimodal large language model based on task difficulty, significantly reducing computational cost and memory usage in robotic control without compromising &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/cover.png"/></item><item><title>Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24032/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24032/</guid><description>Collaborative Assistant for Personalized Exploration (CARE) enhances LLM chatbots for exploratory tasks by combining a multi-agent framework with a structured interface, delivering tailored solutions &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24032/cover.png"/></item></channel></rss>