<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Image Generation on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/image-generation/</link><description>Recent content in Image Generation on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Fri, 15 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/image-generation/index.xml" rel="self" type="application/rss+xml"/><item><title>FitDiT: Advancing the Authentic Garment Details for High-fidelity Virtual Try-on</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.10499/</link><pubDate>Fri, 15 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.10499/</guid><description>FitDiT boosts virtual try-on realism by enhancing garment details via Diffusion Transformers, improving texture and size accuracy for high-fidelity virtual fashion.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.10499/cover.png"/></item><item><title>MagicQuill: An Intelligent Interactive Image Editing System</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.09703/</link><pubDate>Thu, 14 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.09703/</guid><description>MagicQuill: an intelligent interactive image editing system enabling intuitive, precise image edits via brushstrokes and real-time intent prediction by a multimodal LLM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.09703/cover.png"/></item><item><title>Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07232/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07232/</guid><description>Add-it: Training-free object insertion in images using pretrained diffusion models by cleverly balancing information from the scene, text prompt, and generated image, achieving state-of-the-art result&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07232/cover.png"/></item><item><title>Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07126/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07126/</guid><description>Edify Image: groundbreaking pixel-perfect photorealistic image generation using cascaded pixel-space diffusion models with a novel Laplacian diffusion process, enabling diverse applications including &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07126/cover.png"/></item><item><title>OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07199/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07199/</guid><description>OmniEdit, a novel instruction-based image editing model, surpasses existing methods by leveraging specialist supervision and high-quality data, achieving superior performance across diverse editing ta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07199/cover.png"/></item><item><title>StdGEN: Semantic-Decomposed 3D Character Generation from Single Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05738/</link><pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05738/</guid><description>StdGEN: Generate high-quality, semantically decomposed 3D characters from a single image in minutes, enabling flexible customization for various applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05738/cover.png"/></item><item><title>SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04989/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04989/</guid><description>SG-I2V: Zero-shot controllable image-to-video generation using a self-guided approach that leverages pre-trained models for precise object and camera motion control.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04989/cover.png"/></item><item><title>SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05007/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05007/</guid><description>SVDQuant boosts 4-bit diffusion models by absorbing outliers via low-rank components, achieving 3.5x memory reduction and 3x speedup on 12B parameter models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05007/cover.png"/></item><item><title>Training-free Regional Prompting for Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02395/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02395/</guid><description>Training-free Regional Prompting for FLUX boosts compositional text-to-image generation by cleverly manipulating attention mechanisms, achieving fine-grained control without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02395/cover.png"/></item><item><title>Constant Acceleration Flow</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00322/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00322/</guid><description>Constant Acceleration Flow (CAF) dramatically speeds up diffusion model generation by using a constant acceleration equation, outperforming state-of-the-art methods with improved accuracy and few-step&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00322/cover.png"/></item><item><title>Randomized Autoregressive Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00776/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00776/</guid><description>Randomized Autoregressive Modeling (RAR) sets a new state-of-the-art in image generation by cleverly introducing randomness during training to improve the model&amp;rsquo;s ability to learn from bidirectional c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00776/cover.png"/></item><item><title>In-Context LoRA for Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.23775/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.23775/</guid><description>In-Context LoRA empowers existing text-to-image models for high-fidelity multi-image generation by simply concatenating images and using minimal task-specific LoRA tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.23775/cover.png"/></item><item><title>HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.22901/</link><pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.22901/</guid><description>HelloMeme enhances text-to-image models by integrating spatial knitting attentions, enabling high-fidelity meme video generation while preserving model generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.22901/cover.png"/></item></channel></rss>