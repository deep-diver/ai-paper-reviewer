<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-23 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-23/</link><description>Recent content in ðŸ¤— 24-10-23 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Tue, 22 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-23/index.xml" rel="self" type="application/rss+xml"/><item><title>Aligning Large Language Models via Self-Steering Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17131/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17131/</guid><description>Self-Steering Optimization (SSO) autonomously generates high-quality preference signals for aligning LLMs, eliminating manual annotation and improving model performance significantly.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17131/cover.png"/></item><item><title>Frontiers in Intelligent Colonoscopy</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17241/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17241/</guid><description>Revolutionizing colonoscopy, this study introduces ColonINST, a massive multimodal dataset, and ColonGPT, a powerful language model, enabling interactive, AI-assisted colonoscopy and improving diagnos&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17241/cover.png"/></item><item><title>JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17250/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17250/</guid><description>JMMMU, a new Japanese benchmark, provides a comprehensive culture-aware evaluation for Large Multimodal Models, revealing significant performance gaps and highlighting the need for culturally diverse &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17250/cover.png"/></item><item><title>Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16930/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16930/</guid><description>Math Neurosurgery precisely isolates LLMs&amp;rsquo; math skills using only forward passes, boosting their math performance significantly without affecting other abilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16930/cover.png"/></item><item><title>MiniPLM: Knowledge Distillation for Pre-Training Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17215/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17215/</guid><description>MINIPLM: A novel knowledge distillation framework boosts smaller language models&amp;rsquo; performance during pre-training by efficiently refining training data distributions with a teacher model&amp;rsquo;s knowledge, &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17215/cover.png"/></item><item><title>PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17247/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17247/</guid><description>PyramidDrop accelerates large vision-language models by efficiently reducing visual redundancy in deeper layers, achieving significant speedups in training and inference without performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17247/cover.png"/></item><item><title>SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17249/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17249/</guid><description>SpectroMotion reconstructs dynamic specular scenes with photorealistic accuracy by combining 3D Gaussian Splatting, physically-based rendering, and deformation fields, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17249/cover.png"/></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16266/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16266/</guid><description>3DGS-Enhancer boosts realistic 3D scene generation from limited viewpoints by cleverly using 2D video diffusion priors to improve 3D view consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16266/cover.png"/></item><item><title>Improve Vision Language Model Chain-of-thought Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16198/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16198/</guid><description>Researchers enhanced vision-language model reasoning by distilling rationales from GPT-4, fine-tuning models, and applying reinforcement learning, achieving significant improvements in complex reasoni&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16198/cover.png"/></item><item><title>LLM-based Optimization of Compound AI Systems: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16392/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16392/</guid><description>This survey explores using LLMs to optimize compound AI systems, offering a unified framework based on program analysis to understand and improve LLM-based optimization strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16392/cover.png"/></item><item><title>Mitigating Object Hallucination via Concentric Causal Attention</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15926/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15926/</guid><description>Concentric Causal Attention (CCA) significantly reduces object hallucination in Large Vision Language Models by mitigating the negative effects of long-term decay in Rotary Position Encoding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15926/cover.png"/></item><item><title>xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16267/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16267/</guid><description>BLIP-3-Video achieves state-of-the-art video question answering with only 32 visual tokens, drastically reducing computational costs while maintaining high accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16267/cover.png"/></item><item><title>EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14649/</link><pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14649/</guid><description>EvoPress uses evolutionary search to optimize dynamic LLM compression, proving optimality and surpassing existing methods in accuracy and efficiency.</description></item></channel></rss>