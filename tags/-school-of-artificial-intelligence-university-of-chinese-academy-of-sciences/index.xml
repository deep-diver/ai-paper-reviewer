<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ School of Artificial Intelligence, University of Chinese Academy of Sciences on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-school-of-artificial-intelligence-university-of-chinese-academy-of-sciences/</link><description>Recent content in üè¢ School of Artificial Intelligence, University of Chinese Academy of Sciences on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Fri, 07 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-school-of-artificial-intelligence-university-of-chinese-academy-of-sciences/index.xml" rel="self" type="application/rss+xml"/><item><title>GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05689/</link><pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05689/</guid><description>GoalFlow: A novel approach to enhance multimodal trajectory generation for autonomous driving using goal-driven flow matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05689/cover.png"/></item><item><title>MRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07856/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07856/</guid><description>MRS: a novel, training-free sampler, drastically speeds up controllable image generation using Mean Reverting Diffusion, achieving 10-20x speedup across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07856/cover.png"/></item><item><title>RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</guid><description>First benchmark for RAG reward models reveals their limitations and the need for preference-aligned training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/cover.png"/></item><item><title>DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04905/</link><pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04905/</guid><description>DEMO benchmark revolutionizes dialogue modeling by focusing on fine-grained elements (Prelude, Interlocution, Epilogue), enabling comprehensive evaluation and superior agent performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04905/cover.png"/></item></channel></rss>