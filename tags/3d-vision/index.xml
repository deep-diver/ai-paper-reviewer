<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>3D Vision on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/3d-vision/</link><description>Recent content in 3D Vision on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 21 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/3d-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>Novel View Extrapolation with Video Diffusion Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14208/</link><pubDate>Thu, 21 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14208/</guid><description>ViewExtrapolator leverages Stable Video Diffusion to realistically extrapolate novel views far beyond training data, dramatically improving the quality of 3D scene generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14208/cover.png"/></item><item><title>Generative World Explorer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11844/</link><pubDate>Mon, 18 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11844/</guid><description>Generative World Explorer (Genex) enables agents to imaginatively explore environments, updating beliefs with generated observations for better decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.11844/cover.png"/></item><item><title>GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08033/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08033/</guid><description>GaussianAnything: Interactive point cloud latent diffusion enables high-quality, editable 3D models from images or text, overcoming existing 3D generation limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08033/cover.png"/></item><item><title>Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08017/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08017/</guid><description>WaLa: a billion-parameter 3D generative model using wavelet encodings achieves state-of-the-art results, generating high-quality 3D shapes in seconds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.08017/cover.png"/></item><item><title>SAMPart3D: Segment Any Part in 3D Objects</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/</guid><description>SAMPart3D: Zero-shot 3D part segmentation across granularities, scaling to large datasets &amp;amp; handling part ambiguity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/cover.png"/></item><item><title>KMM: Key Frame Mask Mamba for Extended Motion Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06481/</link><pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06481/</guid><description>KMM: Key Frame Mask Mamba generates extended, diverse human motion from text prompts by innovatively masking key frames in the Mamba architecture and using contrastive learning for improved text-motio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.06481/cover.png"/></item><item><title>DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04928/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04928/</guid><description>DimensionX generates photorealistic 3D and 4D scenes from a single image via controllable video diffusion, enabling precise manipulation of spatial structure and temporal dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.04928/cover.png"/></item><item><title>GarVerseLOD: High-Fidelity 3D Garment Reconstruction from a Single In-the-Wild Image using a Dataset with Levels of Details</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.03047/</link><pubDate>Tue, 05 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.03047/</guid><description>GarVerseLOD introduces a novel dataset and framework for high-fidelity 3D garment reconstruction from a single image, achieving unprecedented robustness via a hierarchical approach and leveraging a ma&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.03047/cover.png"/></item><item><title>GenXD: Generating Any 3D and 4D Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/</guid><description>GenXD: A unified model generating high-quality 3D &amp;amp; 4D scenes from any number of images, advancing the field of dynamic scene generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02319/cover.png"/></item><item><title>DreamPolish: Domain Score Distillation With Progressive Geometry Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.01602/</link><pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.01602/</guid><description>DreamPolish: A new text-to-3D model generates highly detailed 3D objects with polished surfaces and realistic textures using progressive geometry refinement and a novel domain score distillation tech&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.01602/cover.png"/></item><item><title>DELTA: Dense Efficient Long-range 3D Tracking for any video</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24211/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24211/</guid><description>DELTA: A new method efficiently tracks every pixel in 3D space from monocular videos, enabling accurate motion estimation across entire videos with state-of-the-art accuracy and over 8x speed improvem&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24211/cover.png"/></item></channel></rss>