<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2024-10-23 on AI Paper Reviews by AI</title>
    <link>http://localhost:1313/ai-paper-reviewer/tags/2024-10-23/</link>
    <description>Recent content in 2024-10-23 on AI Paper Reviews by AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Â© 2024 AI Paper Reviews by AI</copyright>
    <lastBuildDate>Wed, 23 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/ai-paper-reviewer/tags/2024-10-23/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language Tuning</title>
      <link>http://localhost:1313/ai-paper-reviewer/posts/2410.17779/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/posts/2410.17779/</guid>
      <description>ADEM-VL is a novel vision-language tuning framework that achieves high efficiency by using a parameter-free cross-attention mechanism, multiscale visual features, and adaptive fusion.  It outperforms &amp;hellip;..</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/posts/2410.17779/cover.png" />
    </item>
    
    <item>
      <title>Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models</title>
      <link>http://localhost:1313/ai-paper-reviewer/posts/2410.18252/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/posts/2410.18252/</guid>
      <description>This paper proposes asynchronous off-policy RLHF, separating LLM generation and training to enable concurrent processing.  It demonstrates that Online DPO is robust to off-policy data, allowing for ef&amp;hellip;..</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/posts/2410.18252/cover.png" />
    </item>
    
    <item>
      <title>Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits</title>
      <link>http://localhost:1313/ai-paper-reviewer/posts/2410.18234/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/posts/2410.18234/</guid>
      <description>This paper proposes a novel multi-draft speculative sampling method for faster LLM decoding. It introduces a two-step optimal token selection architecture (importance sampling and single-draft specula&amp;hellip;..</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/posts/2410.18234/cover.png" />
    </item>
    
    <item>
      <title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title>
      <link>http://localhost:1313/ai-paper-reviewer/posts/2410.17897/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/posts/2410.17897/</guid>
      <description>To address attention concentration in deep Transformers, this paper proposes ResFormer, which uses residual connections from the first layer&amp;rsquo;s values, and SVFormer, which shares value embeddings acros&amp;hellip;..</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/posts/2410.17897/cover.png" />
    </item>
    
    <item>
      <title>ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment</title>
      <link>http://localhost:1313/ai-paper-reviewer/posts/2410.18194/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-paper-reviewer/posts/2410.18194/</guid>
      <description>ZIP-FIT is a novel data selection method that uses gzip compression to efficiently select task-relevant data for fine-tuning LLMs.  It outperforms existing methods by achieving faster convergence and &amp;hellip;..</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/ai-paper-reviewer/posts/2410.18194/cover.png" />
    </item>
    
  </channel>
</rss>
