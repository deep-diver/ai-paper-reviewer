<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Speech and Audio on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/speech-and-audio/</link><description>Recent content in Speech and Audio on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 06 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/speech-and-audio/index.xml" rel="self" type="application/rss+xml"/><item><title>FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/</link><pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/</guid><description>FocalCodec: a single codebook, low-bitrate speech codec using focal modulation, achieves competitive performance in speech resynthesis and voice conversion.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-12/2502.04465/cover.png"/></item><item><title>Emilia: A Large-Scale, Extensive, Multilingual, and Diverse Dataset for Speech Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.15907/</link><pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.15907/</guid><description>Emilia-Pipe and its resulting datasets, Emilia and Emilia-Large, offer the largest open-source, multilingual speech corpus, enabling more natural and spontaneous AI speech generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.15907/cover.png"/></item><item><title>HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.10045/</link><pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.10045/</guid><description>HiFi-SR: A unified generative network achieves high-fidelity speech super-resolution, outperforming existing methods by seamlessly integrating transformer and convolutional components for end-to-end a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.10045/cover.png"/></item><item><title>XMusic: Towards a Generalized and Controllable Symbolic Music Generation Framework</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08809/</link><pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08809/</guid><description>XMusic: A new framework generates high-quality, emotionally controllable symbolic music from various prompts (images, videos, text, tags, humming).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08809/cover.png"/></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT, a hybrid audio LLM, improves music/speech generation by combining audio waveforms and text.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item></channel></rss>