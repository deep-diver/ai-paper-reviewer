<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ”– 24-10-17 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/</link><description>Recent content in ðŸ”– 24-10-17 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 17 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/index.xml" rel="self" type="application/rss+xml"/><item><title>ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</guid><description>ARKit LabelMaker creates the largest real-world 3D dataset with dense semantic annotations, boosting 3D scene understanding models&amp;rsquo; performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/cover.png"/></item><item><title>CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/</guid><description>New CBT-BENCH benchmark rigorously evaluates LLMs&amp;rsquo; potential in assisting Cognitive Behavioral Therapy, revealing strengths and limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/cover.png"/></item><item><title>Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/</guid><description>CIA Suite enables reliable multilingual LLM evaluation by training an evaluator LLM on English references, achieving human-level performance across diverse languages.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/cover.png"/></item><item><title>DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/</guid><description>DAWN generates realistic talking-head videos at high speed using a novel non-autoregressive diffusion model, exceeding prior methods in quality and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/cover.png"/></item><item><title>Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/</guid><description>Image-guided diffusion models create a synthetic-to-real data spectrum for curriculum learning, boosting long-tail classification and low-quality image learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/cover.png"/></item><item><title>DPLM-2: A Multimodal Diffusion Protein Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/</guid><description>DPLM-2, a new multimodal protein model, simultaneously generates protein sequences and 3D structures, improving upon previous separate-modality approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/cover.png"/></item><item><title>FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/</guid><description>FiTv2, an enhanced vision transformer, generates high-resolution images with diverse aspect ratios, exceeding existing models in speed and resolution adaptability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/cover.png"/></item><item><title>In-context learning and Occam's razor</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14086/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14086/</guid><description>In-context learning implicitly minimizes model complexity and training error, aligning with Occam&amp;rsquo;s Razor, thus improving generalization, especially in data-scarce scenarios.</description></item><item><title>Looking Inward: Language Models Can Learn About Themselves by Introspection</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/</guid><description>LLMs can learn about themselves through introspection, outperforming other models in predicting their own behavior, as demonstrated by experiments with GPT-4 and other LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/cover.png"/></item><item><title>MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/</guid><description>MagicTailor empowers text-to-image models with component-level control, enabling precise visual concept personalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/cover.png"/></item><item><title>MedINST: Meta Dataset of Biomedical Instructions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</guid><description>MedINST, a massive biomedical instruction dataset with 133 tasks and 7M samples, boosts LLM cross-task generalization in medical analysis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/cover.png"/></item><item><title>PUMA: Empowering Unified MLLM with Multi-granular Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/</guid><description>PUMA: A unified MLLM mastering diverse image generation &amp;amp; understanding through multi-granular visual features, balancing diversity and controllability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/cover.png"/></item><item><title>Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/</guid><description>Router-Tuning and MindSkip revolutionize Transformers: dynamic depth is achieved via efficient router fine-tuning, boosting speed and cutting training costs without compromising accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/cover.png"/></item><item><title>SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/</guid><description>SeerAttention learns attention sparsity, boosting LLMs&amp;rsquo; efficiency and scalability via a learnable gate and customized FlashAttention, achieving near-lossless accuracy with high sparsity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/cover.png"/></item><item><title>SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/</guid><description>SEMIEVOL boosts LLM performance by cleverly combining labeled and unlabeled data using a two-stage knowledge propagation and selection approach, achieving significant improvements across diverse tasks&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/cover.png"/></item><item><title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</guid><description>Boosting robot performance, Value-Guided Policy Steering (V-GPS) re-ranks actions from generalist policies using a value function, significantly improving task success across multiple robots and polic&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/cover.png"/></item><item><title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/</guid><description>UCFE benchmark dynamically evaluates LLMs&amp;rsquo; financial expertise via human-aligned, multi-round interactions, revealing performance discrepancies and highlighting the potential of mid-sized models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/cover.png"/></item><item><title>Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/</guid><description>Boosting web agents&amp;rsquo; efficiency, new World-Model-Augmented agents simulate action outcomes, improving policy selection and outperforming tree-search methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/cover.png"/></item></channel></rss>