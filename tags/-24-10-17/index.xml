<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-17 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/</link><description>Recent content in ðŸ¤— 24-10-17 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Wed, 16 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/index.xml" rel="self" type="application/rss+xml"/><item><title>DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12628/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12628/</guid><description>DocLayout-YOLO: Blazing-fast document layout analysis via diverse synthetic data and adaptive perception, exceeding state-of-the-art speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12628/cover.png"/></item><item><title>Exploring Model Kinship for Merging Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12613/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12613/</guid><description>Researchers improve large language model capabilities by introducing &amp;lsquo;model kinship&amp;rsquo; â€“ a metric measuring LLM similarity, which guides a novel merging strategy for enhanced performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12613/cover.png"/></item><item><title>HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12381/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12381/</guid><description>HumanEval-V: A new benchmark rigorously evaluates large multimodal models&amp;rsquo; visual understanding and reasoning abilities through carefully designed coding tasks, revealing significant limitations in cu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12381/cover.png"/></item><item><title>Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12491/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12491/</guid><description>Researchers used inverse reinforcement learning to reveal hidden reward functions in large language models, achieving up to 80% accuracy in predicting human preferences and offering new insights into &amp;hellip;</description></item><item><title>ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12405/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12405/</guid><description>ProSA assesses LLM prompt sensitivity using a new metric, revealing that larger models are more robust but subjective evaluations are also affected by prompt variations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12405/cover.png"/></item><item><title>Revealing the Barriers of Language Agents in Planning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12409/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12409/</guid><description>Language agents struggle with planning due to limited constraint understanding and the diminishing influence of goals, hindering human-level performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12409/cover.png"/></item><item><title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12490/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12490/</guid><description>By stabilizing the latent space using a novel discrete image tokenizer, researchers achieve superior performance in image autoregressive modeling, surpassing previous state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12490/cover.png"/></item><item><title>The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12787/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12787/</guid><description>Large multimodal models are prone to hallucinations; this work systematically investigates these, pinpointing key causes and introducing a benchmark for improved model reliability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12787/cover.png"/></item><item><title>Tracking Universal Features Through Fine-Tuning and Model Merging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12391/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12391/</guid><description>Researchers tracked feature evolution in small language models through fine-tuning and model merging, discovering surprising feature instability and uncovering interpretable persistent features like v&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12391/cover.png"/></item><item><title>WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12722/</link><pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12722/</guid><description>WorldMedQA-V: a new multilingual, multimodal medical exam dataset helps fairly evaluate AI&amp;rsquo;s performance in diverse healthcare settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12722/cover.png"/></item><item><title>Improving Long-Text Alignment for Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11817/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11817/</guid><description>LongAlign enhances text-to-image diffusion models by introducing segment-level encoding and decomposed preference optimization, achieving superior long-text alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11817/cover.png"/></item><item><title>OMCAT: Omni Context Aware Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12109/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12109/</guid><description>OMCAT, a new model, excels at cross-modal temporal understanding by using a novel dataset (OCTAV) and ROTE, an enhanced version of RoPE, achieving state-of-the-art results on AVQA tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.12109/cover.png"/></item><item><title>VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11623/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11623/</guid><description>VidEgoThink: A new benchmark reveals that current large language models struggle with egocentric video understanding, highlighting the need for advancements in embodied AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11623/cover.png"/></item><item><title>FLARE: Faithful Logic-Aided Reasoning and Exploration</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11900/</link><pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11900/</guid><description>FLARE, a novel interpretable approach, leverages LLMs and logic programming to achieve state-of-the-art results in complex reasoning tasks by enhancing model faithfulness and providing insights into r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11900/cover.png"/></item><item><title>Large Language Model Evaluation via Matrix Nuclear-Norm</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.10672/</link><pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.10672/</guid><description>Researchers developed Matrix Nuclear-Norm, a fast, accurate LLM evaluation metric that efficiently measures information compression, surpassing the computationally expensive Matrix Entropy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.10672/cover.png"/></item><item><title>Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11081/</link><pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11081/</guid><description>Researchers stabilize &amp;amp; scale continuous-time consistency models for faster, high-quality image generation, achieving state-of-the-art results on ImageNet.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11081/cover.png"/></item><item><title>ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09870/</link><pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09870/</guid><description>Researchers developed CHROKNOWBENCH, a new benchmark, and CHROKNOWLEDGE, a framework, to effectively evaluate and enhance large language models&amp;rsquo; understanding of chronological knowledge across various&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09870/cover.png"/></item><item><title>Taming Overconfidence in LLMs: Reward Calibration in RLHF</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09724/</link><pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09724/</guid><description>Researchers introduce novel reward calibration methods for RLHF, effectively reducing LLM overconfidence and enhancing reliability without sacrificing performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.09724/cover.png"/></item><item><title>Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08968/</link><pubDate>Fri, 11 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08968/</guid><description>Controllable Safety Alignment (CoSA) lets large language models adapt to diverse safety needs at inference time without retraining, boosting practical use.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08968/cover.png"/></item><item><title>ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification and KV Cache Compression</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08584/</link><pubDate>Fri, 11 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08584/</guid><description>ZipVL boosts large vision-language model efficiency by 2.6x via dynamic token sparsfication and 50% memory reduction using KV cache compression, all while maintaining minimal accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.08584/cover.png"/></item><item><title>DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.07722/</link><pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.07722/</guid><description>DyVo boosts learned sparse retrieval by dynamically adding Wikipedia entities to the vocabulary, significantly improving accuracy and relevance in entity-rich datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.07722/cover.png"/></item><item><title>Neural Metamorphosis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11878/</link><pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11878/</guid><description>NeuMeta learns a continuous weight manifold for neural networks, enabling the generation of any-sized network without retraining, even for unseen configurations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11878/cover.png"/></item><item><title>From Commands to Prompts: LLM-based Semantic File System for AIOS</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11843/</link><pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11843/</guid><description>Researchers developed LSFS, an LLM-based semantic file system for AIOS, enabling natural language file management via prompts, significantly improving user experience and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.11843/cover.png"/></item></channel></rss>