<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ”– 24-10-17 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/</link><description>Recent content in ðŸ”– 24-10-17 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 17 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-17/index.xml" rel="self" type="application/rss+xml"/><item><title>ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/</guid><description>ARKit LabelMaker creates a massive, real-world 3D dataset with dense semantic labels, automatically generated to boost indoor scene understanding model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13924/cover.png"/></item><item><title>CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/</guid><description>CBT-BENCH: A new benchmark systematically evaluates LLMs&amp;rsquo; potential for assisting Cognitive Behavioral Therapy (CBT), revealing strengths and weaknesses in various CBT tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13218/cover.png"/></item><item><title>Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/</guid><description>The CIA Suite, a novel extensible framework, enables cross-lingual evaluation of multilingual LLMs using evaluator LLMs and a new multilingual benchmark dataset.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13394/cover.png"/></item><item><title>DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/</guid><description>DAWN: a novel non-autoregressive diffusion framework for all-at-once generation of dynamic talking head videos, achieving higher quality and speed than autoregressive methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13726/cover.png"/></item><item><title>Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/</guid><description>Diffusion Curriculum Learning (DisCL) generates high-quality synthetic data via image-guided diffusion, significantly boosting accuracy in long-tail and low-quality data classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13674/cover.png"/></item><item><title>DPLM-2: A Multimodal Diffusion Protein Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/</guid><description>DPLM-2: a new multimodal model revolutionizes protein design by simultaneously generating protein sequences and 3D structures, surpassing existing methods in accuracy and diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13782/cover.png"/></item><item><title>FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/</guid><description>FiTv2, an enhanced vision transformer, enables efficient and high-quality image generation at arbitrary resolutions and aspect ratios, surpassing existing diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13925/cover.png"/></item><item><title>In-context learning and Occam's razor</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14086/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14086/</guid><description>This study reveals that in-context learning implicitly minimizes model complexity alongside training error, providing a theoretical basis for Occam&amp;rsquo;s Razor in modern sequence models.</description></item><item><title>Looking Inward: Language Models Can Learn About Themselves by Introspection</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/</guid><description>Language models can learn about themselves through introspection, outperforming other models in self-prediction tasks, showcasing a surprising new capability and challenging prevailing assumptions abo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13787/cover.png"/></item><item><title>MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/</guid><description>MagicTailor empowers text-to-image models with component-level control, enabling precise customization of generated images by modifying specific visual elements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13370/cover.png"/></item><item><title>MedINST: Meta Dataset of Biomedical Instructions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/</guid><description>MEDINST: a massive biomedical instruction dataset (133 tasks, 7M samples) improves LLM cross-task generalization in medical analysis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13458/cover.png"/></item><item><title>PUMA: Empowering Unified MLLM with Multi-granular Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/</guid><description>PUMA: a unified multi-granular MLLM mastering diverse visual tasks by seamlessly integrating image generation and understanding, achieving both high diversity and precise controllability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13861/cover.png"/></item><item><title>Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/</guid><description>Router-Tuning and MindSkip boost Transformer efficiency by dynamically skipping less crucial layers, achieving a 21% speedup with minimal performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13184/cover.png"/></item><item><title>SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/</guid><description>SeerAttention learns to automatically identify and leverage inherent attention sparsity in LLMs, drastically boosting inference speed and scalability while maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13276/cover.png"/></item><item><title>SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/</guid><description>SEMIEVOL: A novel semi-supervised fine-tuning framework boosts LLM performance by cleverly integrating labeled and unlabeled data via knowledge propagation and adaptive selection, enabling efficient m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14745/cover.png"/></item><item><title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/</guid><description>Value-Guided Policy Steering (V-GPS) significantly boosts the performance of generalist robotic policies by re-ranking actions via offline RL, without retraining, improving both precision and robustne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13816/cover.png"/></item><item><title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/</guid><description>UCFE benchmark realistically evaluates LLMs&amp;rsquo; financial expertise via user-centric design and dynamic interactions, revealing performance gaps and highlighting the need for more robust, human-aligned m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.14059/cover.png"/></item><item><title>Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/</guid><description>Boosting LLM-based web agents&amp;rsquo; performance, this study introduces World-Model-Augmented agents that simulate action outcomes for improved decision-making in complex web navigation tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.13232/cover.png"/></item></channel></rss>