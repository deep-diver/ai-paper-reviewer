<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Embodied AI on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/embodied-ai/</link><description>Recent content in Embodied AI on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Tue, 18 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/embodied-ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/</guid><description>Cosmos-Reason1: Physical AI models that reason and act in the real world, bridging the gap between perception and embodied decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/cover.png"/></item><item><title>Free-form language-based robotic reasoning and grasping</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13082/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13082/</guid><description>FreeGrasp: enabling robots to grasp by interpreting instructions and reasoning about object spatial relationships.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13082/cover.png"/></item><item><title>Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.12533/</link><pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.12533/</guid><description>Being-0: A humanoid robot agent achieves complex tasks by integrating a vision-language model with modular skills, enhancing efficiency and real-time performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.12533/cover.png"/></item><item><title>UniGoal: Towards Universal Zero-shot Goal-oriented Navigation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10630/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10630/</guid><description>UniGoal: A novel framework for universal zero-shot goal-oriented navigation, outperforming task-specific methods with a unified approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10630/cover.png"/></item><item><title>World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10480/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10480/</guid><description>D2PO: World modeling enhances embodied task planning by jointly optimizing state prediction and action selection, leading to more efficient execution.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10480/cover.png"/></item><item><title>CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.00729/</link><pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.00729/</guid><description>CLEA: Enhancing task execution in dynamic environments with a closed-loop embodied agent.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.00729/cover.png"/></item><item><title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14282/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14282/</guid><description>PC-Agent: A new hierarchical framework that significantly improves complex task automation on PCs by 32%!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14282/cover.png"/></item><item><title>Magma: A Foundation Model for Multimodal AI Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13130/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13130/</guid><description>Magma: a new foundation model for multimodal AI agents excels at bridging verbal and spatial intelligence, achieving state-of-the-art performance across various tasks, including UI navigation and robo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13130/cover.png"/></item><item><title>GenEx: Generating an Explorable World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</guid><description>GenEx generates explorable 3D worlds from a single image, enabling embodied AI agents to explore and learn.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/cover.png"/></item></channel></rss>