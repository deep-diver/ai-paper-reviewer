<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Huazhong University of Science &amp; Technology on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-huazhong-university-of-science--technology/</link><description>Recent content in üè¢ Huazhong University of Science &amp; Technology on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Tue, 11 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-huazhong-university-of-science--technology/index.xml" rel="self" type="application/rss+xml"/><item><title>OmniMamba: Efficient and Unified Multimodal Understanding and Generation via State Space Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-12/2503.08686/</link><pubDate>Tue, 11 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-12/2503.08686/</guid><description>OmniMamba: Efficient multimodal understanding and generation via SSMs, trained on 2M image-text pairs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-12/2503.08686/cover.png"/></item><item><title>RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13144/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13144/</guid><description>RAD: 3DGS-based RL advances autonomous driving, achieving a 3x lower collision rate!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13144/cover.png"/></item></channel></rss>