<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Stanford University on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-stanford-university/</link><description>Recent content in üè¢ Stanford University on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Tue, 25 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-stanford-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/</link><pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/</guid><description>Opt-CWM: Self-supervised motion learning via counterfactual optimization, achieving state-of-the-art without labels!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-27/2503.19953/cover.png"/></item><item><title>MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13399/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13399/</guid><description>MicroVQA: A new benchmark to test visual-question-answering in microscopy-based research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13399/cover.png"/></item><item><title>BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05652/</link><pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05652/</guid><description>BRS: Streamlining real-world whole-body manipulation for household activities. It introduces a robot suite tackling robot dexterity with bimanual coordination, navigation, and end-effector reach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05652/cover.png"/></item><item><title>CrossOver: 3D Scene Cross-Modal Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15011/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15011/</guid><description>CrossOver: Flexible scene-level cross-modal alignment via modality-agnostic embeddings, unlocking robust 3D scene understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15011/cover.png"/></item><item><title>Auditing Prompt Caching in Language Model APIs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07776/</link><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07776/</guid><description>Researchers expose widespread prompt caching in LLMs via novel timing attacks, highlighting significant privacy risks and model architecture leakage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.07776/cover.png"/></item><item><title>Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.06060/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.06060/</guid><description>Language models learn effective social deduction strategies in a virtual game by using their goal to predict useful information as a dense reward signal, doubling win rates compared to standard RL.</description></item><item><title>Temporal Preference Optimization for Long-Form Video Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13919/</link><pubDate>Thu, 23 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13919/</guid><description>Boosting long-form video understanding, Temporal Preference Optimization (TPO) enhances video-LLMs by leveraging preference learning. It achieves this through a self-training method using preference &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13919/cover.png"/></item><item><title>BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/</guid><description>BoxingGym: A new benchmark rigorously evaluates AI agents&amp;rsquo; ability to design experiments and discover scientific models, revealing current LLMs&amp;rsquo; limitations and highlighting fertile research avenues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/cover.png"/></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT, a hybrid audio LLM, improves music/speech generation by combining audio waveforms and text.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item><item><title>FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07674/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07674/</guid><description>FiVA dataset and its adaptation framework enable unprecedented fine-grained control over visual attributes in text-to-image generation, empowering users to craft highly customized images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07674/cover.png"/></item><item><title>SegBook: A Simple Baseline and Cookbook for Volumetric Medical Image Segmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14525/</link><pubDate>Thu, 21 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14525/</guid><description>SegBook: a large-scale benchmark, reveals that fine-tuning full-body CT pre-trained models significantly improves performance on various downstream medical image segmentation tasks, particularly for s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14525/cover.png"/></item><item><title>RedPajama: an Open Dataset for Training Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/</link><pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/</guid><description>RedPajama, two massive open-source datasets, are released for training LLMs, improving transparency and facilitating the development of high-performing open-source models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.12372/cover.png"/></item></channel></rss>