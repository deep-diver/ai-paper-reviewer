<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reinforcement Learning on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/reinforcement-learning/</link><description>Recent content in Reinforcement Learning on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 31 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Expanding RL with Verifiable Rewards Across Diverse Domains</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/</guid><description>RL with Verifiable Rewards is now expanding to diverse domains like medicine!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.23829/cover.png"/></item><item><title>Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/</link><pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/</guid><description>Open-Reasoner-Zero pioneers scalable, accessible RL training for reasoning in LLMs, achieving superior performance with a minimalist approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-04-01/2503.24290/cover.png"/></item><item><title>Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/</guid><description>This paper enhances Reinforcement Learning from Human Feedback (RLHF) by tackling reward hacking and response diversity issues through improved data construction methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-31/2503.22230/cover.png"/></item><item><title>Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16219/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16219/</guid><description>RL fine-tuning enhances reasoning in small LLMs, achieving competitive performance with limited resources, despite optimization &amp;amp; length challenges.</description></item><item><title>DAPO: An Open-Source LLM Reinforcement Learning System at Scale</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14476/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14476/</guid><description>DAPO: Open-sources a LLM reinforcement learning system that achieves SOTA AIME scores, fostering reproducible research at scale.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14476/cover.png"/></item><item><title>Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.07572/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.07572/</guid><description>LLMs can now reason more efficiently!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.07572/cover.png"/></item><item><title>Language Models can Self-Improve at State-Value Estimation for Better Search</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02878/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02878/</guid><description>Self-Taught Lookahead improves LLM search via self-supervision, matching costly methods at a fraction of the compute!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02878/cover.png"/></item><item><title>Learning from Failures in Multi-Attempt Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04808/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04808/</guid><description>Multi-attempt RL refines LLMs, significantly boosting accuracy on math tasks by enabling them to learn from failures through user feedback.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04808/cover.png"/></item><item><title>MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01935/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01935/</guid><description>MultiAgentBench: A benchmark for evaluating collaboration and competition in LLM agents across diverse, interactive scenarios with novel metrics and protocols.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01935/cover.png"/></item><item><title>Self-rewarding correction for mathematical reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.19613/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.19613/</guid><description>LLM can now reason and correct itself using self-generated data, achieving performance on par with external reward models!</description></item><item><title>Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.16944/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.16944/</guid><description>DVPO: A lean RLHF framework that decouples value &amp;amp; policy optimization with global value guidance, cutting GPU use by 40% and training time by 35%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.16944/cover.png"/></item><item><title>TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15425/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15425/</guid><description>TAG: A decentralized framework for scalable multi-agent hierarchical reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15425/cover.png"/></item><item><title>Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14768/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14768/</guid><description>Logic-RL unlocks LLM reasoning via rule-based reinforcement learning, generalizing to math problems after training on logic puzzles.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14768/cover.png"/></item><item><title>MLGym: A New Framework and Benchmark for Advancing AI Research Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14499/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14499/</guid><description>MLGYM: A new framework &amp;amp; benchmark to advance AI Research Agents</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14499/cover.png"/></item><item><title>AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13943/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13943/</guid><description>AdaptiveStep: Divides reasoning steps automatically through model confidence, enhancing PRM training &amp;amp; performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13943/cover.png"/></item><item><title>S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12853/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12853/</guid><description>S2R: Teaches LLMs to self-verify and self-correct, boosting reasoning with efficient reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12853/cover.png"/></item><item><title>Memory, Benchmark &amp; Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10550/</link><pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10550/</guid><description>MIKASA, a new benchmark for memory-intensive reinforcement learning, provides a unified framework for evaluating memory capabilities in diverse scenarios, including complex robotic manipulation tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10550/cover.png"/></item><item><title>Agency Is Frame-Dependent</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04403/</link><pubDate>Thu, 06 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04403/</guid><description>Agency, a key concept in AI, is shown to be relative to the observer&amp;rsquo;s perspective (frame-dependent), challenging traditional binary definitions and necessitating a more nuanced approach for AI system&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04403/cover.png"/></item><item><title>ACECODER: Acing Coder RL via Automated Test-Case Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01718/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01718/</guid><description>AceCoder uses automated test-case synthesis to create a large-scale dataset for training reward models, enabling effective reinforcement learning to significantly boost code generation model performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01718/cover.png"/></item><item><title>Improving Transformer World Models for Data-Efficient RL</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01591/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01591/</guid><description>AI agents now master complex tasks with improved Transformer World Models, achieving a new state-of-the-art in data-efficient reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.01591/cover.png"/></item><item><title>SRMT: Shared Memory for Multi-agent Lifelong Pathfinding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13200/</link><pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13200/</guid><description>SRMT: Shared Recurrent Memory Transformer boosts multi-agent coordination by implicitly sharing information via a global memory, significantly outperforming baselines in complex pathfinding tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.13200/cover.png"/></item></channel></rss>