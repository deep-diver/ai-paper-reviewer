<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Hong Kong on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-hong-kong/</link><description>Recent content in üè¢ University of Hong Kong on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 20 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-hong-kong/index.xml" rel="self" type="application/rss+xml"/><item><title>Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16430/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16430/</guid><description>TokenBridge bridges continuous and discrete tokens for autoregressive visual generation, achieving high-quality synthesis with simple autoregressive modeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16430/cover.png"/></item><item><title>Sonata: Self-Supervised Learning of Reliable Point Representations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16429/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16429/</guid><description>Sonata: Reliable 3D point cloud self-supervised learning through self-distillation, achieving SOTA with less data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.16429/cover.png"/></item><item><title>UniTok: A Unified Tokenizer for Visual Generation and Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20321/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20321/</guid><description>UniTok: A unified tokenizer bridging the visual generation and understanding gap via multi-codebook quantization, achieving SOTA in MLLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20321/cover.png"/></item><item><title>Goku: Flow Based Video Generative Foundation Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04896/</link><pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04896/</guid><description>Goku: a novel family of joint image-and-video generation models uses rectified flow Transformers, achieving industry-leading performance with a robust data pipeline and training infrastructure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.04896/cover.png"/></item><item><title>Teaching Language Models to Critique via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03492/</link><pubDate>Wed, 05 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03492/</guid><description>LLMs learn to critique and refine their output via reinforcement learning, significantly improving code generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.03492/cover.png"/></item><item><title>GameFactory: Creating New Games with Generative Interactive Videos</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08325/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08325/</guid><description>GameFactory uses AI to generate entirely new games within diverse, open-domain scenes by learning action controls from a small dataset and transferring them to pre-trained video models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.08325/cover.png"/></item><item><title>FashionComposer: Compositional Fashion Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</guid><description>FashionComposer revolutionizes fashion image creation through flexible composition of garments, faces, and poses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/cover.png"/></item><item><title>UniReal: Universal Image Generation and Editing via Learning Real-world Dynamics</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07774/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07774/</guid><description>UniReal: a universal framework for image generation and editing, unifying diverse tasks via learning real-world dynamics from video data, achieving highly realistic and versatile results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07774/cover.png"/></item><item><title>Moto: Latent Motion Token as the Bridging Language for Robot Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04445/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04445/</guid><description>Moto: Bridging language for robot manipulation using latent motion tokens, achieving superior performance with limited data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.04445/cover.png"/></item><item><title>TEXGen: a Generative Diffusion Model for Mesh Textures</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14740/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14740/</guid><description>TEXGen: A groundbreaking generative diffusion model creates high-resolution 3D mesh textures directly from text and image prompts, exceeding prior methods in quality and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.14740/cover.png"/></item><item><title>SAMPart3D: Segment Any Part in 3D Objects</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/</guid><description>SAMPart3D: Zero-shot 3D part segmentation across granularities, scaling to large datasets &amp;amp; handling part ambiguity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.07184/cover.png"/></item></channel></rss>