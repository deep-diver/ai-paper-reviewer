<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Yonsei University on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-yonsei-university/</link><description>Recent content in üè¢ Yonsei University on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 24 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-yonsei-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Latent Space Super-Resolution for Higher-Resolution Image Generation with Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.18446/</link><pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.18446/</guid><description>LSRNA: Super-resolution in latent space enhances image generation with diffusion models, achieving faster speeds and improved detail.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.18446/cover.png"/></item><item><title>AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04504/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04504/</guid><description>AnyAnomaly: LVLM for customizable zero-shot video anomaly detection, adapting to diverse environments without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04504/cover.png"/></item><item><title>Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17407/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17407/</guid><description>Test-time scaling isn&amp;rsquo;t a universal solve-all for multilingual math reasoning, unlike pre-training scaling, shows MCLM benchmark.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17407/cover.png"/></item><item><title>DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19527/</link><pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19527/</guid><description>DisCoRD: Rectified flow decodes discrete motion tokens into continuous, natural movement, balancing faithfulness and realism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19527/cover.png"/></item><item><title>MaskRIS: Semantic Distortion-aware Data Augmentation for Referring Image Segmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19067/</link><pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19067/</guid><description>MaskRIS revolutionizes referring image segmentation by using novel masking and contextual learning to enhance data augmentation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19067/cover.png"/></item></channel></rss>