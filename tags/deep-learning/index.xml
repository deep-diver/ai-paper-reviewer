<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/deep-learning/</link><description>Recent content in Deep Learning on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 24 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Verbal Process Supervision Elicits Better Coding Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-25/2503.18494/</link><pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-25/2503.18494/</guid><description>CURA: Verbal process supervision improves coding agents.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-25/2503.18494/cover.png"/></item><item><title>Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/</guid><description>UAE-3D: A unified latent space approach for efficient &amp;amp; high-quality 3D molecular generation, outperforming existing methods in accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/cover.png"/></item><item><title>Frac-Connections: Fractional Extension of Hyper-Connections</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14125/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14125/</guid><description>Frac-Connections: An efficient alternative to Hyper-Connections that divides hidden states into fractions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.14125/cover.png"/></item><item><title>Charting and Navigating Hugging Face's Model Atlas</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10633/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10633/</guid><description>Navigating millions of models is hard. This paper charts Hugging Face, revealing model relationships and attribute predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10633/cover.png"/></item><item><title>Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10632/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10632/</guid><description>KArAt: Can Learnable Attention Beat Standard Attention in Vision Transformers?</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10632/cover.png"/></item><item><title>Transformers without Normalization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10622/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10622/</guid><description>Transformers can achieve state-of-the-art performance without normalization layers via Dynamic Tanh (DyT), offering a simpler and more efficient alternative.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.10622/cover.png"/></item><item><title>BlackGoose Rimer: Harnessing RWKV-7 as a Simple yet Superior Replacement for Transformers in Large-Scale Time Series Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.06121/</link><pubDate>Sat, 08 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.06121/</guid><description>Rimer: RWKV-7 empowers superior time series modeling, offering a simple yet effective alternative to Transformers with fewer parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.06121/cover.png"/></item><item><title>Benchmarking AI Models in Software Engineering: A Review, Search Tool, and Enhancement Protocol</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05860/</link><pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05860/</guid><description>This paper reviews AI4SE benchmarks, introduces BenchScout for benchmark discovery, and proposes BenchFrame for benchmark enhancement, demonstrated via HumanEvalNext.</description></item><item><title>LoRACode: LoRA Adapters for Code Embeddings</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05315/</link><pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05315/</guid><description>LoRACode enhances code embeddings using LoRA, achieving SOTA in code retrieval with minimal computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.05315/cover.png"/></item><item><title>KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02951/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02951/</guid><description>KODCODE: A new synthetic coding dataset with verified solutions and tests, enabling state-of-the-art performance for coding LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02951/cover.png"/></item><item><title>Identifying Sensitive Weights via Post-quantization Integral</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01901/</link><pubDate>Fri, 28 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01901/</guid><description>PQI: Accurately identify sensitive weights in post-quantization to enhance LLM compression &amp;amp; performance!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01901/cover.png"/></item><item><title>SoS1: O1 and R1-Like Reasoning LLMs are Sum-of-Square Solvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20545/</link><pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20545/</guid><description>SoS1: O1 and R1-Like Reasoning LLMs are Sum-of-Square Solvers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.20545/cover.png"/></item><item><title>Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17055/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17055/</guid><description>Stable-SPAM stabilizes 4-bit LLM training, outperforming Adam.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.17055/cover.png"/></item><item><title>MONSTER: Monash Scalable Time Series Evaluation Repository</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15122/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15122/</guid><description>MONSTER: Large datasets for time series classification!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15122/cover.png"/></item><item><title>One-step Diffusion Models with $f$-Divergence Distribution Matching</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/</guid><description>f-distill: One-step diffusion models through f-divergence minimization, outperforming reverse-KL with better mode coverage and lower variance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/cover.png"/></item><item><title>ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14637/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14637/</guid><description>ReQFlow: Efficiently generate high-quality protein backbones with rectified quaternion flow, outperforming existing methods in speed and designability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14637/cover.png"/></item><item><title>S*: Test Time Scaling for Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14382/</link><pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14382/</guid><description>S*: Hybrid test-time scaling for code generation, boosting both coverage and selection accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.14382/cover.png"/></item><item><title>NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/</guid><description>NExT-Mol: Combines 1D language models with 3D diffusion for molecule generation, achieving state-of-the-art performance and validity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12638/cover.png"/></item><item><title>Small Models Struggle to Learn from Strong Reasoners</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12143/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12143/</guid><description>Small language models struggle to learn complex reasoning from large models, but a novel &amp;lsquo;Mix Distillation&amp;rsquo; method balances complexity for effective capability transfer.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12143/cover.png"/></item><item><title>Thinking Preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13173/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13173/</guid><description>ThinkPO improves LLM reasoning by preferring longer CoT, boosting performance without new data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.13173/cover.png"/></item><item><title>AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10235/</link><pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10235/</guid><description>AdaPTS effectively adapts pre-trained univariate time series models to probabilistic multivariate forecasting, improving accuracy and uncertainty quantification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.10235/cover.png"/></item><item><title>Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09619/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09619/</guid><description>ProbeLog: Zero-shot model search directly from weights, boosting efficiency and accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09619/cover.png"/></item><item><title>Weak-to-Strong Diffusion with Reflection</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.00473/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.00473/</guid><description>W2SD: A novel framework boosts diffusion model quality by using the difference between weak and strong models to refine sampling trajectories, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.00473/cover.png"/></item><item><title>PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/</link><pubDate>Sun, 08 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/</guid><description>Physics-Informed Gaussians (PIGs) revolutionize PDE solving by using adaptive, learnable Gaussian functions for superior accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05994/cover.png"/></item><item><title>Best of Both Worlds: Advantages of Hybrid Graph Sequence Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15671/</link><pubDate>Sat, 23 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15671/</guid><description>Hybrid Graph Sequence Model (GSM++) outperforms existing models by using hierarchical sequences and a hybrid architecture of Transformers and recurrent models, effectively capturing both local and glo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15671/cover.png"/></item><item><title>Improving the detection of technical debt in Java source code with an enriched dataset</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05457/</link><pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05457/</guid><description>Enriched dataset TESORO improves technical debt detection by combining self-admitted comments and Java source code, advancing state-of-the-art models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05457/cover.png"/></item><item><title>SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00233/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00233/</guid><description>SambaMixer: A novel state-space model accurately predicts Li-ion battery health using efficient Mamba architecture and innovative resampling techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.00233/cover.png"/></item></channel></rss>