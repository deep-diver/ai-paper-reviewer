<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ NVIDIA on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-nvidia/</link><description>Recent content in üè¢ NVIDIA on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 03 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-nvidia/index.xml" rel="self" type="application/rss+xml"/><item><title>Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01774/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01774/</guid><description>DIFIX3D+ improves 3D reconstructions by reducing artifacts via single-step diffusion models, enhancing novel-view synthesis quality and consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.01774/cover.png"/></item><item><title>One-step Diffusion Models with $f$-Divergence Distribution Matching</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/</guid><description>f-distill: One-step diffusion models through f-divergence minimization, outperforming reverse-KL with better mode coverage and lower variance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.15681/cover.png"/></item><item><title>V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09980/</link><pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09980/</guid><description>V2V-LLM leverages multi-modal LLMs for safer cooperative autonomous driving by fusing perception data from multiple vehicles, answering driving-related questions, and improving trajectory planning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09980/cover.png"/></item><item><title>VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01822/</link><pubDate>Mon, 02 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01822/</guid><description>VLSI: Verbalized Layers-to-Interactions efficiently transfers knowledge from large to small VLMs using layer-wise natural language distillation, achieving significant performance gains without scaling&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.01822/cover.png"/></item><item><title>Puzzle: Distillation-Based NAS for Inference-Optimized LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19146/</link><pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19146/</guid><description>Puzzle: a novel framework accelerates large language model inference by using neural architecture search and knowledge distillation, achieving a 2.17x speedup on a single GPU while preserving 98.4% ac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19146/cover.png"/></item><item><title>Star Attention: Efficient LLM Inference over Long Sequences</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17116/</link><pubDate>Tue, 26 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17116/</guid><description>Star Attention: 11x faster LLM inference on long sequences with 95-100% accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17116/cover.png"/></item><item><title>Hymba: A Hybrid-head Architecture for Small Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13676/</link><pubDate>Wed, 20 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13676/</guid><description>Hymba: Hybrid-head architecture boosts small language model performance by 11.67x cache size reduction and 3.49x throughput, surpassing existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.13676/cover.png"/></item></channel></rss>