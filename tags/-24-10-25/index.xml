<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-25 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-25/</link><description>Recent content in ðŸ¤— 24-10-25 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 24 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-25/index.xml" rel="self" type="application/rss+xml"/><item><title>CAMEL-Bench: A Comprehensive Arabic LMM Benchmark</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/</guid><description>CAMEL-Bench: A new Arabic LMM benchmark with 29K+ questions across 8 diverse domains, revealing significant room for improvement in Arabic LLM development.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/cover.png"/></item><item><title>CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/</guid><description>CCI3.0-HQ: A new, high-quality 500GB Chinese dataset significantly improves large language model performance, outperforming existing datasets on multiple benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/cover.png"/></item><item><title>Data Scaling Laws in Imitation Learning for Robotic Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/</guid><description>Robotic manipulation policies achieve near-human performance using surprisingly little data when training with diverse environments and objects, demonstrating power-law scaling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/cover.png"/></item><item><title>DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/</guid><description>DeCoRe: A novel, training-free decoding method significantly reduces LLM hallucinations by contrasting outputs from masked and unmasked retrieval heads, boosting accuracy on various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/cover.png"/></item><item><title>Distill Visual Chart Reasoning Ability from LLMs to MLLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/</guid><description>Code-as-Intermediary Translation synthesizes chart Q&amp;amp;A data, boosting MLLM visual reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/cover.png"/></item><item><title>Framer: Interactive Frame Interpolation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/</guid><description>FRAMER lets users creatively control video frame interpolation by adjusting keypoint trajectories, producing smooth transitions and handling complex scenarios with an &amp;lsquo;autopilot&amp;rsquo; mode for automated tr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/cover.png"/></item><item><title>LOGO -- Long cOntext aliGnment via efficient preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/</guid><description>LOGO optimizes long-context model alignment via efficient preference optimization, achieving comparable performance to GPT-4 on real-world tasks with only 0.3B training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/cover.png"/></item><item><title>MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/</guid><description>MotionCLR enables training-free interactive human motion editing by leveraging attention mechanisms for versatile generation and explainable control.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/cover.png"/></item><item><title>Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/</guid><description>VINE, a novel watermarking method, significantly improves robustness against image editing by leveraging a pretrained diffusion model and blurring distortions as surrogate attacks during training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/cover.png"/></item><item><title>Should We Really Edit Language Models? On the Evaluation of Edited Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/</guid><description>Model editing boosts LLMs, but scaling edits hurts performance and safety!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/cover.png"/></item><item><title>Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/</guid><description>Skywork-Reward boosts LLM reward modeling by curating a smaller, high-quality preference dataset and employing advanced training techniques, achieving top performance on RewardBench.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/cover.png"/></item><item><title>SMITE: Segment Me In TimE</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/</guid><description>SMITE: a novel video segmentation method using few reference images to achieve temporally consistent, flexible-granularity segmentations outperforming state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/cover.png"/></item><item><title>Stable Consistency Tuning: Understanding and Improving Consistency Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/</guid><description>Stable Consistency Tuning (SCT) boosts image generation speed and quality in consistency models by reducing training variance and discretization errors, achieving new state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/cover.png"/></item><item><title>Taipan: Efficient and Expressive State Space Language Models with Selective Attention</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/</guid><description>Taipan: A new language model efficiently handles extremely long text sequences by cleverly combining a memory-efficient architecture with selective attention, outperforming current state-of-the-art mo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/cover.png"/></item><item><title>The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18441/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18441/</guid><description>This paper enhances generative AI&amp;rsquo;s Transformer models by applying probabilistic optimization to sub-word encoding, hyperparameter tuning, attention mechanisms, and quantization, improving efficiency &amp;hellip;</description></item><item><title>Unbounded: A Generative Infinite Game of Character Life Simulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/</guid><description>UNBOUNDED: a generative infinite game uses AI to create an open-ended character life simulation, transcending traditional game boundaries.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/cover.png"/></item><item><title>Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/</guid><description>ScaleQuest generates 1M high-quality math problems from scratch using small LLMs, boosting open-source model performance by 29.2%-46.4% on MATH.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/cover.png"/></item><item><title>WAFFLE: Multi-Modal Model for Automated Front-End Development</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/</guid><description>WAFFLE, a novel fine-tuning strategy, significantly improves UI design-to-HTML code generation by using structure-aware attention and contrastive learning, outperforming current methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/cover.png"/></item><item><title>Why Does the Effective Context Length of LLMs Fall Short?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/</guid><description>Boosting LLMs&amp;rsquo; long-context performance, STRING, a training-free method, shifts position embeddings to overcome undertraining on long-range dependencies, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/cover.png"/></item><item><title>ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/</guid><description>ADEM-VL boosts vision-language model efficiency by using parameter-free cross-attention and adaptive fusion, significantly improving accuracy while reducing computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/cover.png"/></item><item><title>Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/</guid><description>Boosting language model training speed by 40%, this research introduces asynchronous RLHF, separating sample generation and learning for greater efficiency and compute optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/cover.png"/></item><item><title>Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/</guid><description>This paper proposes a novel two-step approach to multi-draft speculative sampling, improving large language model decoding efficiency and achieving higher token rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/cover.png"/></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/</guid><description>ResFormer and SVFormer mitigate attention concentration in deep Transformers, improving performance and reducing KV cache by almost half.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/cover.png"/></item><item><title>ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/</guid><description>ZIP-FIT revolutionizes data selection for language models by using gzip compression to identify task-aligned data, drastically improving model performance and training efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/cover.png"/></item><item><title>Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/</guid><description>Inf-CL breaks the memory barrier in contrastive learning, enabling near-infinite batch size training with linear memory scaling and maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/cover.png"/></item><item><title>Can Knowledge Editing Really Correct Hallucinations?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/</guid><description>HalluEditBench: A new benchmark reveals knowledge editing&amp;rsquo;s true potential in fixing LLM hallucinations, highlighting strengths and limitations across various methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/cover.png"/></item><item><title>Language Models are Symbolic Learners in Arithmetic</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/</guid><description>LLMs learn arithmetic symbolically, not through calculation; they identify patterns, challenging the assumption of numerical computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/cover.png"/></item><item><title>Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/</guid><description>Pantograph boosts machine-assisted theorem proving by creating a seamless Lean 4 interface for efficient proof search and high-level reasoning, facilitating advanced AI model training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/cover.png"/></item><item><title>Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/</guid><description>SPARE, a novel training-free method, uses sparse autoencoders to precisely control LLMs&amp;rsquo; knowledge selection, improving accuracy in open-domain question answering.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/cover.png"/></item></channel></rss>