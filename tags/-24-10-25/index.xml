<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-25 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-25/</link><description>Recent content in ðŸ¤— 24-10-25 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Thu, 24 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-25/index.xml" rel="self" type="application/rss+xml"/><item><title>CAMEL-Bench: A Comprehensive Arabic LMM Benchmark</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/</guid><description>CAMEL-Bench: a new open-source benchmark rigorously evaluates Arabic LMMs across 8 diverse domains and 38 sub-domains, revealing significant room for improvement even in top models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18976/cover.png"/></item><item><title>CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/</guid><description>CCI3.0-HQ: A new 500GB high-quality Chinese dataset significantly boosts large language model performance, surpassing existing datasets on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18505/cover.png"/></item><item><title>Data Scaling Laws in Imitation Learning for Robotic Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/</guid><description>Robotic manipulation policies achieve near 90% success in novel environments and with unseen objects using a data-driven approach that leverages power-law scaling relationships.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18647/cover.png"/></item><item><title>DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/</guid><description>DeCoRe, a novel training-free decoding strategy, significantly reduces LLM hallucinations by contrasting outputs from masked and unmasked retrieval heads, improving accuracy on various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18860/cover.png"/></item><item><title>Distill Visual Chart Reasoning Ability from LLMs to MLLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/</guid><description>Researchers synthesize a new multimodal dataset, REACHQA, using code as an intermediary to efficiently distill visual chart reasoning abilities from LLMs to MLLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18798/cover.png"/></item><item><title>Framer: Interactive Frame Interpolation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/</guid><description>Framer: an interactive frame interpolation tool lets users customize video transitions by adjusting keypoints, yielding smooth, creative resultsâ€”even handling complex scenarios with an &amp;lsquo;autopilot&amp;rsquo; mod&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18978/cover.png"/></item><item><title>LOGO -- Long cOntext aliGnment via efficient preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/</guid><description>LOGO, a novel training strategy, significantly boosts long-context model performance by efficiently optimizing preference alignment, achieving comparable results to GPT-4 with minimal data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18533/cover.png"/></item><item><title>MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/</guid><description>MotionCLR: Training-free, interactive human motion editing via attention mechanism manipulation. Versatile editing, good generation quality, and strong explainability achieved.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18977/cover.png"/></item><item><title>Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/</guid><description>VINE, a novel watermarking method, significantly improves robustness against advanced image editing using generative priors, outperforming existing methods in both image quality and robustness, as val&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18775/cover.png"/></item><item><title>Should We Really Edit Language Models? On the Evaluation of Edited Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/</guid><description>Contrary to popular belief, current language model editing techniques cause inevitable performance decline and safety issues when scaling edits, urging the need for more practical methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18785/cover.png"/></item><item><title>Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/</guid><description>Skywork-Reward achieves state-of-the-art results on RewardBench using a novel data-centric approach, developing high-performing reward models with a significantly smaller dataset (80K pairs) than exis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18451/cover.png"/></item><item><title>SMITE: Segment Me In TimE</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/</guid><description>SMITE: a new video segmentation method achieving temporally consistent, fine-grained segmentations using only a few reference images, outperforming state-of-the-art alternatives.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18538/cover.png"/></item><item><title>Stable Consistency Tuning: Understanding and Improving Consistency Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/</guid><description>Stable Consistency Tuning (SCT) significantly boosts consistency model training, achieving state-of-the-art results by reducing variance and improving sampling efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18958/cover.png"/></item><item><title>Taipan: Efficient and Expressive State Space Language Models with Selective Attention</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/</guid><description>Taipan, a novel hybrid language model, achieves superior performance and efficiency in handling extremely long text sequences by selectively applying attention, combining the strengths of State Space &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18572/cover.png"/></item><item><title>The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18441/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18441/</guid><description>This paper enhances generative AI Transformer models by introducing probabilistic optimization solutions for subword encoding, hyperparameter tuning, attention mechanisms, and quantization, resulting &amp;hellip;</description></item><item><title>Unbounded: A Generative Infinite Game of Character Life Simulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/</guid><description>UNBOUNDED, a generative infinite game, uses AI to create a continuously evolving character life simulation with open-ended interactions and real-time visual generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18975/cover.png"/></item><item><title>Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/</guid><description>ScaleQuest: a novel data synthesis method unleashes LLMs&amp;rsquo; reasoning power by generating a massive, high-quality mathematical reasoning dataset from scratch using efficient, open-source models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18693/cover.png"/></item><item><title>WAFFLE: Multi-Modal Model for Automated Front-End Development</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/</guid><description>WAFFLE: a new fine-tuning method dramatically improves UI design-to-HTML code generation by using structure-aware attention and contrastive learning, outperforming current state-of-the-art models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18362/cover.png"/></item><item><title>Why Does the Effective Context Length of LLMs Fall Short?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/</guid><description>Researchers unveil STRING, a training-free method that boosts large language models&amp;rsquo; long-context performance by cleverly shifting position embeddings, achieving state-of-the-art results on open-sourc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18745/cover.png"/></item><item><title>ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/</guid><description>ADEM-VL boosts vision-language model efficiency by using a parameter-free cross-attention mechanism and an adaptive fusion scheme, achieving state-of-the-art accuracy with reduced computational demand&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17779/cover.png"/></item><item><title>Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/</guid><description>Asynchronous off-policy RLHF accelerates LLM training by 40% without sacrificing performance, achieving compute-optimal scaling by decoupling generation and learning phases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18252/cover.png"/></item><item><title>Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/</guid><description>Researchers boost large language model inference speed by 10x using a novel multi-draft speculative sampling method with theoretical performance guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18234/cover.png"/></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/</guid><description>ResFormer and SVFormer alleviate Transformer attention concentration, boosting training speed and accuracy by introducing residual value connections and single-layer value sharing, respectively.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17897/cover.png"/></item><item><title>ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/</guid><description>ZIP-FIT uses gzip compression to efficiently select task-relevant training data for language models, drastically improving fine-tuning speed and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18194/cover.png"/></item><item><title>Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/</guid><description>Inf-CL shatters memory limits in contrastive learning, enabling training with massive batch sizes (millions) using a novel tile-based computation strategy for unprecedented accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.17243/cover.png"/></item><item><title>Can Knowledge Editing Really Correct Hallucinations?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/</guid><description>HalluEditBench: A new benchmark reveals knowledge editing&amp;rsquo;s limitations in truly fixing LLM hallucinations, offering valuable insights for future improvements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16251/cover.png"/></item><item><title>Language Models are Symbolic Learners in Arithmetic</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/</guid><description>LLMs don&amp;rsquo;t calculate; they&amp;rsquo;re symbolic learners in arithmetic, mastering tasks through subgroup pattern recognition, prioritizing easy-to-hard pattern selection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15580/cover.png"/></item><item><title>Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/</guid><description>Pantograph: a new Lean 4 interface boosts machine-assisted theorem proving by enabling efficient proof search and high-level reasoning via novel features, including draft-sketch-proof (DSP) support.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.16429/cover.png"/></item><item><title>Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/</link><pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/</guid><description>SPARE, a training-free method, uses sparse autoencoders to precisely steer LLMs&amp;rsquo; knowledge selection, resolving context-memory conflicts and significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.15999/cover.png"/></item></channel></rss>