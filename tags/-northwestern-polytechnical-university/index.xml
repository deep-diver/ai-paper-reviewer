<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Northwestern Polytechnical University on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-northwestern-polytechnical-university/</link><description>Recent content in üè¢ Northwestern Polytechnical University on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 03 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-northwestern-polytechnical-university/index.xml" rel="self" type="application/rss+xml"/><item><title>DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/</guid><description>DiffRhythm: Fast &amp;amp; Simple End-to-End Song Generation via Latent Diffusion, creating full songs (4+ mins) with vocal &amp;amp; accompaniment in seconds!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-04/2503.01183/cover.png"/></item><item><title>Exploring the Potential of Encoder-free Architectures in 3D LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09620/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09620/</guid><description>Encoder-free 3D LMMs outperform state-of-the-art, achieving comparable results to significantly larger models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09620/cover.png"/></item><item><title>Rethinking Token Reduction in MLLMs: Towards a Unified Paradigm for Training-Free Acceleration</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17686/</link><pubDate>Tue, 26 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17686/</guid><description>FiCoCo: A unified paradigm accelerates Multimodal Large Language Model (MLLM) inference by up to 82.4% with minimal performance loss, surpassing state-of-the-art training-free methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.17686/cover.png"/></item><item><title>Material Anything: Generating Materials for Any 3D Object via Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15138/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15138/</guid><description>Material Anything: Generate realistic materials for ANY 3D object via diffusion!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.15138/cover.png"/></item></channel></rss>