<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Illinois Urbana-Champaign on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-illinois-urbana-champaign/</link><description>Recent content in üè¢ University of Illinois Urbana-Champaign on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 03 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-illinois-urbana-champaign/index.xml" rel="self" type="application/rss+xml"/><item><title>MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-05/2503.01935/</link><pubDate>Mon, 03 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-05/2503.01935/</guid><description>MultiAgentBench: A benchmark for evaluating collaboration and competition in LLM agents across diverse, interactive scenarios with novel metrics and protocols.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-05/2503.01935/cover.png"/></item><item><title>Self-rewarding correction for mathematical reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.19613/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.19613/</guid><description>LLM can now reason and correct itself using self-generated data, achieving performance on par with external reward models!</description></item><item><title>Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.11901/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.11901/</guid><description>PoPilot, a novel proof-oriented programming LLM, outperforms GPT-40 by 64% under data scarcity by using synthetic data augmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.11901/cover.png"/></item><item><title>Learning Getting-Up Policies for Real-World Humanoid Robots</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12152/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12152/</guid><description>HUMANUP: A novel two-stage reinforcement learning framework enables real-world humanoid robots to autonomously recover from falls on various terrains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.12152/cover.png"/></item><item><title>CRANE: Reasoning with constrained LLM generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09061/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09061/</guid><description>CRANE: A novel constrained decoding algorithm boosts LLM reasoning accuracy by strategically alternating between unconstrained reasoning and constrained generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2502.09061/cover.png"/></item><item><title>Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.11733/</link><pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.11733/</guid><description>Mobile-Agent-E: A self-evolving mobile assistant conquering complex tasks with hierarchical agents and a novel self-evolution module, significantly outperforming prior approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.11733/cover.png"/></item><item><title>Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</guid><description>MMAudio achieves state-of-the-art video-to-audio synthesis by jointly training on audio-visual and text-audio data, enabling high-quality, semantically and temporally aligned audio generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/cover.png"/></item></channel></rss>