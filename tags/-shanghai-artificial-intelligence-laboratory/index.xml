<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Shanghai Artificial Intelligence Laboratory on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-shanghai-artificial-intelligence-laboratory/</link><description>Recent content in üè¢ Shanghai Artificial Intelligence Laboratory on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Wed, 19 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-shanghai-artificial-intelligence-laboratory/index.xml" rel="self" type="application/rss+xml"/><item><title>Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-26/2503.14905/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-26/2503.14905/</guid><description>FakeVLM: A multimodal model &amp;amp; artifact-annotated dataset for detecting synthetic images with interpretable explanations, setting a new benchmark.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-26/2503.14905/cover.png"/></item><item><title>Infinite Mobility: Scalable High-Fidelity Synthesis of Articulated Objects via Procedural Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13424/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13424/</guid><description>Infinite Mobility: Procedural generation of high-fidelity articulated objects for scalable embodied AI training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.13424/cover.png"/></item><item><title>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04629/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04629/</guid><description>SURVEYFORGE automates survey generation, improving quality and evaluation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.04629/cover.png"/></item><item><title>Iterative Value Function Optimization for Guided Decoding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02368/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02368/</guid><description>IVO: Iterative Value Function Optimization for Guided Decoding</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2503.02368/cover.png"/></item><item><title>InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.12368/</link><pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.12368/</guid><description>InternLM-XComposer2.5-Reward: A novel multi-modal reward model boosting Large Vision Language Model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.12368/cover.png"/></item><item><title>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</guid><description>Introducing Evaluation Agent, a faster, more flexible human-like framework for evaluating visual generative AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/cover.png"/></item><item><title>Chimera: Improving Generalist Model with Domain-Specific Experts</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05983/</link><pubDate>Sun, 08 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05983/</guid><description>Chimera boosts large multimodal models&amp;rsquo; performance on specialized tasks by cleverly integrating domain-specific expert models, achieving state-of-the-art results on multiple benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.05983/cover.png"/></item><item><title>VLSBench: Unveiling Visual Leakage in Multimodal Safety</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19939/</link><pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19939/</guid><description>VLSBench exposes visual leakage in MLLM safety benchmarks, creating a new, leak-free benchmark to evaluate true multimodal safety.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.19939/cover.png"/></item></channel></rss>