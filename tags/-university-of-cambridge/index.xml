<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Cambridge on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-cambridge/</link><description>Recent content in üè¢ University of Cambridge on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 13 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-university-of-cambridge/index.xml" rel="self" type="application/rss+xml"/><item><title>ZeroBench: An Impossible Visual Benchmark for Contemporary Large Multimodal Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-17/2502.09696/</link><pubDate>Thu, 13 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-17/2502.09696/</guid><description>ZeroBench: a new visual reasoning benchmark, proves impossible for current large multimodal models, pushing the boundaries of AI visual understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-17/2502.09696/cover.png"/></item><item><title>Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.04144/</link><pubDate>Tue, 07 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.04144/</guid><description>Chirpy3D: Generating creative, high-quality 3D birds with intricate details by learning a continuous part latent space from 2D images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.04144/cover.png"/></item><item><title>FAM Diffusion: Frequency and Attention Modulation for High-Resolution Image Generation with Stable Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.18552/</link><pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.18552/</guid><description>FAM Diffusion: Generate high-res images seamlessly from pre-trained diffusion models, solving structural and texture inconsistencies without retraining!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.18552/cover.png"/></item><item><title>Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05000/</link><pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05000/</guid><description>Can LLMs effectively handle information spread across vast, almost million-scale datasets? This research investigates this question by evaluating 17 LLMs on novel ‚Äòneedle threading‚Äô tasks. These task&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.05000/cover.png"/></item></channel></rss>