<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 2024-10-24 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-2024-10-24/</link><description>Recent content in ðŸ¤— 2024-10-24 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Wed, 23 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-2024-10-24/index.xml" rel="self" type="application/rss+xml"/><item><title>DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18084/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18084/</guid><description>DynamicCity is a new framework for generating large-scale, high-quality 4D LiDAR scenes from dynamic scenes. It uses a VAE to learn a compact 4D representation (HexPlane) and a DiT-based diffusion mod&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18084/cover.png"/></item><item><title>Lightweight Neural App Control</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17883/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17883/</guid><description>LiMAC, a novel mobile app control architecture, leverages a lightweight transformer and fine-tuned VLM to efficiently handle text-based instructions and app interactions on Android devices. It signif&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17883/cover.png"/></item><item><title>MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17637/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17637/</guid><description>MIA-DPO enhances Large Vision-Language Models&amp;rsquo; (LVLMs) multi-image understanding by cleverly augmenting existing single-image datasets with additional, unrelated images. This reduces annotation costs&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17637/cover.png"/></item><item><title>Scalable Ranked Preference Optimization for Text-to-Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18013/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18013/</guid><description>This paper proposes a scalable method for aligning text-to-image models with human preferences using synthetically generated ranked preference data and a novel ranking-based optimization technique (Ra&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18013/cover.png"/></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17891/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17891/</guid><description>This paper presents a novel method for efficiently scaling diffusion language models (DLMs) by adapting pre-trained autoregressive language models. The proposed technique, which unifies the modeling &amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17891/cover.png"/></item><item><title>TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18071/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18071/</guid><description>Current Multimodal Large Language Model (MLLM) evaluation benchmarks are flawed due to prompt sensitivity, leading to underestimation of model performance. This paper introduces TP-Eval, a novel eval&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18071/cover.png"/></item><item><title>WorldSimBench: Towards Video Generation Models as World Simulators</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18072/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18072/</guid><description>WorldSimBench is a new benchmark for evaluating video generation models as world simulators, classifying them hierarchically and assessing them via Explicit Perceptual Evaluation (visual quality) and &amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.18072/cover.png"/></item><item><title>LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17434/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17434/</guid><description>Long video understanding is limited by LLM context size. LongVU, a novel spatiotemporal adaptive compression method, addresses this by reducing video tokens while preserving visual details using cross&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17434/cover.png"/></item><item><title>LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17242/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17242/</guid><description>The Large View Synthesis Model (LVSM) achieves state-of-the-art novel view synthesis by using a transformer-based approach that minimizes 3D inductive bias. Its decoder-only variant shows superior ge&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.17242/cover.png"/></item><item><title>M-RewardBench: Evaluating Reward Models in Multilingual Settings</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.15522/</link><pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.15522/</guid><description>The paper introduces M-REWARDBENCH, a multilingual reward model benchmark showing that current models underperform significantly on non-English languages compared to English, highlighting the impact o&amp;hellip;..</description></item><item><title>ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13924/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13924/</guid><description>ARKit LabelMaker creates a massive, real-world 3D dataset with dense semantic labels using an automated pipeline, showing that large-scale real-world data significantly improves 3D scene understanding&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13924/cover.png"/></item><item><title>MedINST: Meta Dataset of Biomedical Instructions</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13458/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13458/</guid><description>This paper introduces MedINST, a large and comprehensive meta-dataset of biomedical instructions designed to improve the training of large language models (LLMs) for biomedical applications. The data&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13458/cover.png"/></item><item><title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13816/</link><pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13816/</guid><description>Value-Guided Policy Steering (V-GPS) improves pre-trained generalist robotic policies by re-ranking actions based on a value function learned from offline RL, leading to consistent performance gains a&amp;hellip;..</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/posts/2410.13816/cover.png"/></item></channel></rss>