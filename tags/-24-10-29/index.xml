<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ðŸ¤— 24-10-29 on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-29/</link><description>Recent content in ðŸ¤— 24-10-29 on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Mon, 28 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-24-10-29/index.xml" rel="self" type="application/rss+xml"/><item><title>LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21264/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21264/</guid><description>LARP: a novel video tokenizer using learned holistic queries and an autoregressive prior, achieves state-of-the-art video generation, bridging the gap between reconstruction and generation fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21264/cover.png"/></item><item><title>Relaxed Recursive Transformers: Effective Parameter Sharing with Layer-wise LoRA</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20672/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20672/</guid><description>Recursive Transformers, a novel LLM compression method, achieves comparable performance to larger models using efficient parameter sharing and low-rank adaptation, enabling significant throughput gain&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20672/cover.png"/></item><item><title>Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21220/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21220/</guid><description>Vision Search Assistant empowers vision-language models as robust multimodal search engines by effectively integrating web agents for real-time information retrieval, significantly improving performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21220/cover.png"/></item><item><title>GrounDiT: Grounding Diffusion Transformers via Noisy Patch Transplantation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20474/</link><pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20474/</guid><description>GrounDiT achieves precise spatial grounding in text-to-image generation using a novel training-free approach that transplants denoised image patches into specified regions, significantly improving spa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20474/cover.png"/></item><item><title>Language Models And A Second Opinion Use Case: The Pocket Professional</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20636/</link><pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20636/</guid><description>LLMs show promise as second opinion tools for complex medical cases, exceeding human accuracy in straightforward cases but demonstrating limitations with nuanced diagnoses; a new benchmark is establis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20636/cover.png"/></item><item><title>Fast Best-of-N Decoding via Speculative Rejection</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20290/</link><pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20290/</guid><description>Speculative Rejection: A novel algorithm achieves fast, high-quality LLM decoding by strategically rejecting low-scoring partial generations, offering 16-32x speedup over Best-of-N.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20290/cover.png"/></item><item><title>MarDini: Masked Autoregressive Diffusion for Video Generation at Scale</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20280/</link><pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20280/</guid><description>MarDini: Asymmetric video diffusion model scales video generation by integrating masked autoregression for temporal planning and diffusion models for spatial generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20280/cover.png"/></item><item><title>Neural Fields in Robotics: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20220/</link><pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20220/</guid><description>Neural Fields revolutionize robotics by enabling robots to perceive and interact with their environment more accurately, opening new avenues for perception, planning, and control.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20220/cover.png"/></item><item><title>COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19313/</link><pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19313/</guid><description>COAT achieves memory-efficient FP8 training by compressing optimizer states and activations, resulting in 1.54x memory footprint reduction and 1.43x speedup.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19313/cover.png"/></item><item><title>GPT-4o System Card</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21276/</link><pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21276/</guid><description>GPT-40, an advanced multimodal AI model, boasts impressive speed and capabilities across various modalities, yet faces challenges in safety and bias mitigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.21276/cover.png"/></item><item><title>AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18603/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18603/</guid><description>AgentStore dynamically integrates diverse AI agents for superior task automation, outperforming previous systems by enhancing both generalization and specialization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18603/cover.png"/></item><item><title>Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18481/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18481/</guid><description>Dialog2Flow (D2F) pre-trains soft-contrastive action-driven sentence embeddings to automatically extract dialog workflows, achieving superior performance on diverse datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18481/cover.png"/></item><item><title>DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18666/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18666/</guid><description>DreamClear: a high-capacity image restoration model, uses a dual-prompt learning pipeline to create a large-scale dataset and achieves photorealistic restoration of real-world low-quality images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.18666/cover.png"/></item><item><title>VideoWebArena: Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19100/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19100/</guid><description>VideoWebArena benchmark evaluates long-context multimodal agents&amp;rsquo; video understanding abilities via 2021 web tasks, revealing significant performance gaps compared to humans and highlighting key areas&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.19100/cover.png"/></item><item><title>Bi-Level Motion Imitation for Humanoid Robots</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.01968/</link><pubDate>Wed, 02 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.01968/</guid><description>Bi-Level Motion Imitation (BMI) enhances humanoid robot policy learning by cleverly modifying human motion capture data to be physically feasible, resulting in more robust and realistic robot movement&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.01968/cover.png"/></item><item><title>Leveraging Locality to Boost Sample Efficiency in Robotic Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.10615/</link><pubDate>Sat, 15 Jun 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.10615/</guid><description>SGRv2: Action locality boosts sample efficiency in robot manipulation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.10615/cover.png"/></item></channel></rss>