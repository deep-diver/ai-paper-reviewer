{"importance": "This paper introduces a new trajectory-controllable video generation framework which allows researchers to flexibly control object movements, create high-quality videos, and easily evaluate models. The dataset and benchmark can help the development of future video generation tasks.", "summary": "MagicMotion: A controllable video generation framework enabling precise object motion control through dense-to-sparse trajectory guidance.", "takeaways": ["MagicMotion enables flexible trajectory control from dense masks to sparse boxes.", "MagicData, the first public dataset for trajectory-controlled video generation, is introduced.", "MagicBench, a new benchmark, assesses video quality and trajectory accuracy across different object numbers."], "tldr": "**Recent progress in video generation enables trajectory control for precise object motion**, however, existing methods struggle with complex movements, multi-object control, imprecise trajectory adherence, and poor object consistency. **Current trajectory control is limited to a single format, restricting applicability.** There is a lack of datasets and benchmarks tailored for trajectory-controllable video generation, hindering progress.", "affiliation": "Fudan University", "categories": {"main_category": "Computer Vision", "sub_category": "Image Generation"}, "podcast_path": "2503.16421/podcast.wav"}