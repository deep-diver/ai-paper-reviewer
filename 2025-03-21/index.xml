<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-03-21s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/</link><description>Recent content in 2025-03-21s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Thu, 20 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/index.xml" rel="self" type="application/rss+xml"/><item><title>1000+ FPS 4D Gaussian Splatting for Dynamic Scene Rendering</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16422/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16422/</guid><description>4DGS-1K: Achieves 1000+ FPS for dynamic scene rendering via a compact, memory-efficient framework, offering a 41x storage reduction and 9x faster speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16422/cover.png"/></item><item><title>AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16091/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16091/</guid><description>AIMI: A system leveraging future knowledge &amp;amp; personalized data for accurate treatment adherence forecasting, paving the way for timely mobile interventions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16091/cover.png"/></item><item><title>CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16356/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16356/</guid><description>CaKE: Editing LLMs to Enhance Knowledge Generalization Across Reasoning Tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16356/cover.png"/></item><item><title>CLS-RL: Image Classification with Rule-Based Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16188/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16188/</guid><description>CLS-RL: Rule-based RL tackles catastrophic forgetting in MLLM image classification, outperforming SFT with better generalization and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16188/cover.png"/></item><item><title>Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16031/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16031/</guid><description>New dataset bridges fabricated claims with humor for spotting online deception!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16031/cover.png"/></item><item><title>Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16057/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16057/</guid><description>Expert Race: A flexible routing strategy for scaling diffusion transformer with mixture of experts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16057/cover.png"/></item><item><title>Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16252/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16252/</guid><description>Fin-R1: Financial reasoning via RL.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16252/cover.png"/></item><item><title>Improving Autoregressive Image Generation through Coarse-to-Fine Token Prediction</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16194/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16194/</guid><description>Coarse-to-Fine Token Prediction improves autoregressive image generation by assigning the same coarse label for similar tokens, balancing generation quality and computational efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16194/cover.png"/></item><item><title>InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16418/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16418/</guid><description>InfU: A new framework for flexible photo re-creation while preserving identity using Diffusion Transformers(DiTs).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16418/cover.png"/></item><item><title>JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16365/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16365/</guid><description>ActVLP: Enhancing VLMs through visual-linguistic guidance for superior action-based decision-making in interactive environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16365/cover.png"/></item><item><title>M3: 3D-Spatial MultiModal Memory</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16413/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16413/</guid><description>M3: Gaussian-integrated memory system for multimodal 3D scene understanding with foundation models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16413/cover.png"/></item><item><title>MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16421/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16421/</guid><description>MagicMotion: A controllable video generation framework enabling precise object motion control through dense-to-sparse trajectory guidance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16421/cover.png"/></item><item><title>MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16212/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16212/</guid><description>MathFusion: Instruction Fusion enhances LLM&amp;rsquo;s math problem-solving!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16212/cover.png"/></item><item><title>NuiScene: Exploring Efficient Generation of Unbounded Outdoor Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16375/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16375/</guid><description>NuiScene: Enables efficient &amp;amp; unbounded outdoor scene generation by encoding scene chunks as uniform vector sets and outpainting.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16375/cover.png"/></item><item><title>Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16257/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16257/</guid><description>VidKV: Achieves 1.5x-bit KV cache quantization for VideoLLMs, maintaining performance without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16257/cover.png"/></item><item><title>Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16219/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16219/</guid><description>RL fine-tuning enhances reasoning in small LLMs, achieving competitive performance with limited resources, despite optimization &amp;amp; length challenges.</description></item><item><title>SALT: Singular Value Adaptation with Low-Rank Transformation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16055/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16055/</guid><description>SALT: Fine-tuning SAM for medical images using Singular Value Adaptation with Low-Rank Transformation for efficient, robust segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16055/cover.png"/></item><item><title>Scale-wise Distillation of Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16397/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16397/</guid><description>SWD: Scale-wise distillation of diffusion models achieves faster image generation by upscaling resolution during denoising, outperforming counterparts with similar computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16397/cover.png"/></item><item><title>Sonata: Self-Supervised Learning of Reliable Point Representations</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16429/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16429/</guid><description>Sonata: Reliable 3D point cloud self-supervised learning through self-distillation, achieving SOTA with less data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16429/cover.png"/></item><item><title>Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16419/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16419/</guid><description>LLMs survey: Model, output, and prompt-based strategies for efficient reasoning, mitigating &amp;lsquo;overthinking&amp;rsquo; for faster, cheaper, and real-world applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16419/cover.png"/></item><item><title>Survey on Evaluation of LLM-based Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16416/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16416/</guid><description>A comprehensive survey on evaluation methodologies for LLM-based agents, analyzing benchmarks and frameworks across key dimensions like capabilities, applications, and generalist performance.</description></item><item><title>Tokenize Image as a Set</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16425/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16425/</guid><description>TokenSet: Tokenizing images as unordered sets for dynamic capacity allocation and robust generation, breaking from fixed-position latent codes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16425/cover.png"/></item><item><title>Ultra-Resolution Adaptation with Ease</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16322/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16322/</guid><description>URA: Ultra-resolution adaptation made easy! Uses synthetic data &amp;amp; minor weight tuning for efficient, high-res text-to-image diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16322/cover.png"/></item><item><title>Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16278/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16278/</guid><description>Uni-3DAR: Autoregressive framework unifies 3D generation/understanding, compressing spatial tokens for faster, versatile AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16278/cover.png"/></item><item><title>Unleashing Vecset Diffusion Model for Fast Shape Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16302/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16302/</guid><description>FlashVDM enables fast 3D shape generation by accelerating both VAE decoding and diffusion sampling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16302/cover.png"/></item><item><title>VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15855/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15855/</guid><description>VideoRFSplat: Direct text-to-3D Gaussian Splatting with flexible pose and multi-view joint modeling, bypassing SDS refinement!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15855/cover.png"/></item><item><title>XAttention: Block Sparse Attention with Antidiagonal Scoring</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16428/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16428/</guid><description>XAttention: Antidiagonal scoring unlocks block-sparse attention, slashing compute costs in long-context Transformers without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.16428/cover.png"/></item><item><title>Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15851/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15851/</guid><description>Zero-1-to-A: Animatable avatars from a single image using video diffusion, robust to spatial &amp;amp; temporal inconsistencies!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15851/cover.png"/></item><item><title>BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15242/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15242/</guid><description>BIGO(Bench) can help LLMs generate code with controlled time/space complexity, addressing the gap in current evaluations and encouraging further exploration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15242/cover.png"/></item><item><title>MotionStreamer: Streaming Motion Generation via Diffusion-based Autoregressive Model in Causal Latent Space</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15451/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15451/</guid><description>MotionStreamer: Streaming motion generation w/ diffusion-based autoregressive model in causal latent space.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15451/cover.png"/></item><item><title>Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/</guid><description>UAE-3D: A unified latent space approach for efficient &amp;amp; high-quality 3D molecular generation, outperforming existing methods in accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15567/cover.png"/></item><item><title>Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/</guid><description>Cosmos-Reason1: Physical AI models that reason and act in the real world, bridging the gap between perception and embodied decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.15558/cover.png"/></item><item><title>DiffMoE: Dynamic Token Selection for Scalable Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.14487/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.14487/</guid><description>DiffMoE: Dynamically selects tokens for scalable diffusion transformers, unlocking new efficiency levels in image generation.</description></item><item><title>Make Your Training Flexible: Towards Deployment-Efficient Video Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.14237/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.14237/</guid><description>FluxViT: Flexible video models via adaptive token selection for efficient deployment!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.14237/cover.png"/></item><item><title>See-Saw Modality Balance: See Gradient, and Sew Impaired Vision-Language Balance to Mitigate Dominant Modality Bias</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13834/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13834/</guid><description>BALGRAD mitigates dominant modality bias in vision-language models by reweighting gradients and aligning task directions for balanced learning and improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13834/cover.png"/></item><item><title>Why Do Multi-Agent LLM Systems Fail?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13657/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13657/</guid><description>Multi-Agent Systems (MAS) often underperform despite enthusiasm. This paper analyzes 5 popular frameworks across 150+ tasks, identifying 14 failure modes categorized into specification/design, inter-a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.13657/cover.png"/></item><item><title>MagicID: Hybrid Preference Optimization for ID-Consistent and Dynamic-Preserved Video Customization</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.12689/</link><pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.12689/</guid><description>MagicID: ID-consistent &amp;amp; dynamic-preserved video customization via hybrid preference optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.12689/cover.png"/></item><item><title>LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.10625/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.10625/</guid><description>LHM: Animatable 3D avatars from a single image in seconds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-03-21/2503.10625/cover.png"/></item></channel></rss>