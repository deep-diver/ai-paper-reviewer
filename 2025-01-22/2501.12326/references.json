{"references": [{"fullname_first_author": "Aaron Hurst", "paper_title": "GPT-40 system card", "publication_date": "2024-10-21", "reason": "This paper is a technical report describing GPT-40, a large language model that is frequently compared to UI-TARS throughout the paper for performance benchmarks and serves as a key competitor."}, {"fullname_first_author": "Anas Awadalla", "paper_title": "MINT-1T: Scaling open-source multimodal data by 10x: A multimodal dataset with one trillion tokens", "publication_date": "2024-06-11", "reason": "This paper introduces the MINT-1T dataset, a crucial component for training the enhanced perception capabilities of UI-TARS, providing a substantial amount of data for visual understanding."}, {"fullname_first_author": "Boyu Gou", "paper_title": "Navigating the digital world as humans do: Universal visual grounding for GUI agents", "publication_date": "2024-10-05", "reason": "This paper focuses on visual grounding in GUI agents, a core capability of UI-TARS, and its findings directly inform the design and evaluation of UI-TARS's grounding capabilities."}, {"fullname_first_author": "Zhiyong Wu", "paper_title": "OS-Atlas: A foundation action model for generalist GUI agents", "publication_date": "2024-10-23", "reason": "This work presents OS-Atlas, a key competitor model to UI-TARS, whose architecture and performance on various benchmarks are frequently referenced and compared to UI-TARS."}, {"fullname_first_author": "Tianbao Xie", "paper_title": "OSWorld: Benchmarking multimodal agents for open-ended tasks in real computer environments", "publication_date": "2024-04-07", "reason": "This paper introduces OSWorld, a benchmark heavily used to evaluate UI-TARS and its performance is frequently compared to that of UI-TARS throughout the paper, highlighting its importance."}]}