{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduces NeRF, a foundational method for novel view synthesis using neural radiance fields, which is heavily built upon in the current research regarding 3D avatar reconstruction."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian splatting, a key technique used in the current work for efficient and high-quality 3D scene representation, particularly for head avatars."}, {"fullname_first_author": "Ayaan Haque", "paper_title": "Instruct-nerf2nerf: Editing 3D scenes with instructions", "publication_date": "2023-00-00", "reason": "This paper introduces a method for text-driven editing of NeRFs, providing a crucial foundation for the current work's text-driven editing approach applied to Gaussian head avatars."}, {"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "This paper presents InstructPix2Pix, a model used in the current research for 2D image editing based on text instructions, which is integrated into the 3D avatar editing pipeline."}, {"fullname_first_author": "Shenhan Qian", "paper_title": "GaussianAvatars: Photorealistic head avatars with rigged 3D Gaussians", "publication_date": "2023-00-00", "reason": "This paper introduces GaussianAvatars, a method for creating animatable Gaussian head avatars, which serves as the basis for the current work's editing framework."}]}