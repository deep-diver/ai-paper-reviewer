[{"figure_path": "https://arxiv.org/html/2501.08970/x1.png", "caption": "Figure 1: Practical Example of TCME\u00a0in Damage Monitoring: TCME\u00a0can be used to monitor potential damage to business space while preserving privacy. The system, utilizing a pre-agreed model and prompt, analyzes camera recordings. It is restricted to output only \"YES\" if significant damage is detected, ensuring minimal intrusion.", "description": "This figure illustrates a practical application of Trusted Capable Model Environments (TCMEs) in damage monitoring.  A landlord wants to monitor their property for damage without infringing on renters' privacy.  A pre-agreed machine learning model within a TCME analyzes camera recordings. The model is constrained to only output \"YES\" if significant damage is detected, thus balancing the landlord's security needs with the renters' privacy.  The system includes input and output constraints to protect private information. The only information revealed is whether or not significant damage has occurred.", "section": "4. Examples"}, {"figure_path": "https://arxiv.org/html/2501.08970/x2.png", "caption": "Figure 2: TCME can be used to perform auditing of private code and models that are deployed in the TEE and participate in the \u2018attestation\u2019 that includes private components.", "description": "Figure 2 illustrates a system where a Trusted Capable Model Environment (TCME) is used to audit private code and models residing within a Trusted Execution Environment (TEE).  The process involves an agreement between the user and an attestation provider on specific auditing prompts. These prompts are then used by the TCME, which leverages a large, public model to analyze the private code. The TCME provides an output indicating whether the code meets the specified criteria. This process allows for verification of private code components without compromising the confidentiality of the proprietary code.", "section": "4.4. Practical Example 4: Private Code Auditor in TEE Attestation"}, {"figure_path": "https://arxiv.org/html/2501.08970/x3.png", "caption": "Figure 3: Graph coloring verification performed by Gemini-1.5-Flash. The model generally has a high precision (83%) and low recall (14%).", "description": "The figure shows the performance of the Gemini-1.5-Flash large language model (LLM) in verifying graph 3-colorings.  The model was given an adjacency matrix representing a graph and a proposed 3-coloring. The model then determined whether the coloring was valid (meaning no two adjacent nodes shared the same color). The confusion matrix shows that while the model had high precision (83%, meaning that when it predicted a coloring was correct, it was usually correct), it had low recall (14%, meaning that it only correctly identified a small percentage of the actually correct colorings). This indicates that the model is better at identifying when a coloring is incorrect than identifying when a coloring is correct.", "section": "5.2 Comparing with ZKPs"}]