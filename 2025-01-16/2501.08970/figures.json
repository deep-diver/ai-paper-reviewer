[{"figure_path": "https://arxiv.org/html/2501.08970/x1.png", "caption": "Figure 1: Practical Example of TCME\u00a0in Damage Monitoring: TCME\u00a0can be used to monitor potential damage to business space while preserving privacy. The system, utilizing a pre-agreed model and prompt, analyzes camera recordings. It is restricted to output only \"YES\" if significant damage is detected, ensuring minimal intrusion.", "description": "This figure illustrates a practical application of Trusted Capable Model Environments (TCMEs) in damage monitoring.  A landlord wants to check for damage to their property without constantly monitoring tenants or violating their privacy.  The system uses a pre-agreed machine learning model and a specific prompt.  The model analyzes camera recordings at the end of the day and outputs only \"YES\" if significant damage is detected, thus preserving tenant privacy and only alerting the landlord to significant problems.", "section": "Examples"}, {"figure_path": "https://arxiv.org/html/2501.08970/x2.png", "caption": "Figure 2: TCME can be used to perform auditing of private code and models that are deployed in the TEE and participate in the \u2018attestation\u2019 that includes private components.", "description": "This figure illustrates a scenario where a Trusted Capable Model Environment (TCME) is used to audit private code and models residing within a Trusted Execution Environment (TEE).  A platform provider uses a TCME, employing a public model, to verify if private code (or models) comply with certain security constraints specified by the platform user. The TCME interacts with the private code within the TEE, without directly accessing it. The outcome of the TCME's analysis is then used in the attestation process, providing a guarantee that the private code meets the security criteria without revealing the details of the code itself.", "section": "4. Examples"}, {"figure_path": "https://arxiv.org/html/2501.08970/x3.png", "caption": "Figure 3: Graph coloring verification performed by Gemini-1.5-Flash. The model generally has a high precision (83%) and low recall (14%).", "description": "The figure shows the performance of the Gemini-1.5-Flash large language model (LLM) in verifying graph 3-colorings.  The model was given adjacency matrices representing graphs and corresponding color assignments. It then determined whether the assignment was a valid 3-coloring (meaning no adjacent nodes have the same color). The results are displayed in a confusion matrix, showing that the model exhibits high precision (83%) but low recall (14%).  This means that when the model predicts a valid coloring, it is often correct, but it frequently fails to identify valid colorings.", "section": "5.2 Comparing with ZKPs"}]