[{"figure_path": "https://arxiv.org/html/2501.08970/x1.png", "caption": "Figure 1: Practical Example of TCME\u00a0in Damage Monitoring: TCME\u00a0can be used to monitor potential damage to business space while preserving privacy. The system, utilizing a pre-agreed model and prompt, analyzes camera recordings. It is restricted to output only \"YES\" if significant damage is detected, ensuring minimal intrusion.", "description": "This figure illustrates a practical application of Trusted Capable Model Environments (TCMEs) in damage monitoring.  A landlord wants to check for damage to their property without constantly monitoring tenants or invading their privacy.  A pre-agreed machine learning model within the TCME analyzes camera recordings of the business space.  The model is designed with strict input and output constraints; it only outputs \"YES\" if significant damage is detected. This ensures minimal intrusion while alerting the landlord to potential problems.", "section": "4. Examples"}, {"figure_path": "https://arxiv.org/html/2501.08970/x2.png", "caption": "Figure 2: TCME can be used to perform auditing of private code and models that are deployed in the TEE and participate in the \u2018attestation\u2019 that includes private components.", "description": "This figure illustrates how a Trusted Capable Model Environment (TCME) can be utilized for auditing private code and models deployed within a Trusted Execution Environment (TEE).  The process involves a TCME that interacts with both public and private code/model components.  The TCME utilizes a large open model and defined auditing prompts to check the private code for specific characteristics (e.g., presence of networking capabilities, discriminatory conditional branches, or backdoors).  The TEE then uses the TCME's output to perform the attestation process, effectively leveraging the TCME to verify the security of the private components without directly exposing them.", "section": "4. Examples"}, {"figure_path": "https://arxiv.org/html/2501.08970/x3.png", "caption": "Figure 3: Graph coloring verification performed by Gemini-1.5-Flash. The model generally has a high precision (83%) and low recall (14%).", "description": "This figure shows the performance of the Gemini-1.5-Flash large language model (LLM) in verifying graph 3-colorings.  The confusion matrix displays the model's predictions (positive/negative) against the actual correctness of the provided graph coloring.  The model exhibits high precision (83%), meaning that when it predicts a correct coloring, it's usually right. However, it has low recall (14%), indicating it misses many actually correct colorings.  This suggests the model struggles to identify correct solutions but is quite accurate when it does find one.", "section": "5.2 Comparing with ZKPs"}]