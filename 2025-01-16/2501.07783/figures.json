[{"figure_path": "https://arxiv.org/html/2501.07783/x1.png", "caption": "Figure 1: Different multi-resolution designs in visual perception and multimodal understanding.\n(a)(e) Plain network without multi-scale features.\n(b)(c)(f) Inefficient image pyramid networks using equivalently large models for all scales, either with shared weights or with separate weights and interactions.\n(d) Parameter-direct image pyramid network which processes high-resolution images with large models, leading to high computational cost.\n(g) Multi-resolution approaches on multimodal tasks based on grid partition.\n(h) Our efficient and effective parameter-inverted image pyramid network (PIIP), which pairs models of increasing parameter sizes inversely with images of decreasing resolution. It achieves better performance with much lower computational cost.", "description": "Figure 1 illustrates various multi-resolution approaches used in visual perception and multimodal understanding tasks.  (a) and (e) show basic network architectures lacking multi-scale feature processing.  (b), (c), and (f) depict traditional image pyramid methods, which use the same large model across all image resolutions, leading to high computational costs.  This is done either through weight sharing or with separate weights for each resolution, with some sort of feature interaction. (d) demonstrates a parameter-direct approach using large models for high-resolution images, again causing high computational costs.  (g) presents multi-resolution strategies applied to multimodal understanding, often involving image partitioning.  Finally, (h) introduces the authors' proposed Parameter-Inverted Image Pyramid Network (PIIP), which uses smaller models for higher-resolution images and larger models for lower-resolution images, leading to improved efficiency and performance.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2501.07783/x2.png", "caption": "Figure 2: Overall architecture of PIIP. We use multi-resolution branches to process images of different resolutions, where larger images are handled by smaller models. Each branch leverages pretrained ViTs or CNNs. Interaction units build connections between adjacent branches. Branch merging is inserted after all the blocks or within certain intermediate blocks to combine the features of all branches.", "description": "The figure illustrates the architecture of Parameter-Inverted Image Pyramid Networks (PIIP).  PIIP uses multiple branches to process images at different resolutions, a key innovation being that higher resolution images are processed by smaller models to optimize computational efficiency. Each branch employs a pre-trained Vision Transformer (ViT) or Convolutional Neural Network (CNN).  Interaction units connect adjacent branches to facilitate information exchange across different scales. A branch merging mechanism combines the features from all branches, either at the end of all processing blocks or at intermediate stages, depending on the specific task. This design balances computational cost and performance by using smaller, less computationally expensive models on the high-resolution inputs where a smaller receptive field is sufficient to extract important details and larger, richer models for lower resolution data which provides more contextual information.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.07783/x3.png", "caption": "Figure 3: Illustration of PIIP-LLaVA for multimodal understanding.\nWe use one projector after each branch to align the visual features with the language embedding space of the LLM, and combine the features to obtain the visual features.", "description": "PIIP-LLaVA is a multimodal large language model that uses a parameter-inverted image pyramid network for efficient and effective high-resolution understanding.  The figure illustrates the architecture.  Visual input is passed through multiple branches of the network, each handling a different resolution of the image. Lower resolution images are processed by higher capacity branches, while higher resolution images are processed by smaller capacity branches. This parameter-inverted design balances computational cost and performance. Each branch uses a projector to align the resulting features with the language embedding space of a large language model (LLM). The aligned features from all branches are then combined to produce a comprehensive visual representation for the LLM to use in multimodal understanding tasks.", "section": "III. METHODOLOGY"}, {"figure_path": "https://arxiv.org/html/2501.07783/x4.png", "caption": "Figure 4: Detailed structure of the interaction unit. It consists of two deformable attentions with fully-connect layers and feed-forward networks.", "description": "This figure details the architecture of the interaction unit, a crucial component within the Parameter-Inverted Image Pyramid Network (PIIP).  The interaction unit facilitates communication and feature integration between adjacent branches of the PIIP, which process images at different resolutions. As shown, the unit employs two deformable attention mechanisms. Each deformable attention mechanism consists of a fully-connected layer (FC) for feature projection, the deformable attention operation itself, and a feed-forward network (FFN) for channel-wise feature fusion. This multi-step process ensures that features from different scales are effectively combined, improving the overall representational power of the network.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.07783/x5.png", "caption": "Figure 5: Detailed design of branch merging in different tasks. For detection, segmentation and multimodal understanding, output features from all branches are fused together with projection and upsampling, and fed into the subsequent FPN or LLM. For classification, we employ the original classification heads to compute logits, and average them as the final prediction.", "description": "Figure 5 illustrates how feature maps from multiple branches of the Parameter-Inverted Image Pyramid Network (PIIP) are integrated for different downstream tasks.  In object detection, segmentation, and multimodal understanding, features from each branch undergo projection and upsampling to match dimensions before being combined and fed into a Feature Pyramid Network (FPN) or a Large Language Model (LLM). This fusion step leverages the complementary information extracted from various resolutions.  For image classification, however, the original classification heads of each branch are used independently, and their predictions are averaged to produce the final result.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.07783/extracted/6128466/figures/interaction_types/inter_type_v4.png", "caption": "(a) Object detection", "description": "This figure displays qualitative results of object detection using the proposed Parameter-Inverted Image Pyramid Networks (PIIP).  The images showcase the model's ability to accurately detect objects at various scales, even small ones, as demonstrated by the bounding boxes around objects in several images.", "section": "IV. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2501.07783/x6.png", "caption": "(b) Instance segmentation", "description": "This figure displays instance segmentation results from the PIIP-SBL model.  The images showcase the model's ability to accurately identify and delineate the boundaries of multiple objects within complex scenes.  High-resolution processing allows the model to detect even small objects, which are clearly identified and outlined with masks. The results demonstrate a high degree of accuracy and detail in segmenting different objects, highlighting the model's effectiveness in instance segmentation tasks.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.07783/x7.png", "caption": "Figure 6: Performance of different PIIP variants by adjusting input resolutions on object detection and instance segmentation.", "description": "This figure shows the performance of different Parameter-Inverted Image Pyramid Network (PIIP) variants on object detection and instance segmentation tasks.  The x-axis represents the computational cost (GFLOPS), and the y-axis shows the performance in terms of Average Precision (AP) for both box AP (APb) and mask AP (APm).  Different colors represent different PIIP network configurations (with varying model sizes and input image resolutions). The figure demonstrates the impact of adjusting input image resolutions on the overall performance and computational cost for different PIIP models, showcasing a tradeoff between computational efficiency and accuracy.", "section": "IV. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.07783/x8.png", "caption": "TABLE V: Experiments of initializing with different pre-trained weights on COCO val2017 with PIIP-SBL 1568/1120/672.", "description": "Table V presents the results of experiments conducted to assess the impact of using different pre-trained weights on the performance of the Parameter-Inverted Image Pyramid Networks (PIIP) model.  Specifically, the table focuses on the PIIP-SBL model configuration with a resolution of 1568/1120/672.  This configuration is one of the multiple variations of the PIIP model.  The table shows how using different pre-trained ViT weights (from various sources like AugReg, DeiT III, MAE, Uni-Perceiver, DINOv2, and BEiTv2) as initial weights affected the model's performance on the COCO val2017 dataset for object detection. The performance is measured in terms of Average Precision (AP) for both bounding boxes (APb) and masks (APm).  By comparing the APb and APm scores across different pre-trained weights, the study aimed to determine the influence of the initial weight choice on the final model's accuracy and efficiency.", "section": "IV. Experiments"}]