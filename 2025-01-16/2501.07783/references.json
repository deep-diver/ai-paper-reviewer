{"references": [{"fullname_first_author": "H. Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-MM-DD", "reason": "This paper is foundational for the efficient training of image transformers, a core component of the proposed PIIP network."}, {"fullname_first_author": "H. Touvron", "paper_title": "Deit iii: Revenge of the vit", "publication_date": "2022-MM-DD", "reason": "This paper presents DeiT III, a significant improvement upon the original Vision Transformer architecture, directly used as a building block within PIIP."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "CLIP, introduced in this paper, is a foundational model for multimodal understanding, and its pretrained weights are leveraged by PIIP-LLaVA."}, {"fullname_first_author": "Z. Chen", "paper_title": "Vision transformer adapter for dense predictions", "publication_date": "2023-MM-DD", "reason": "This paper proposes the ViT-Adapter, a multi-scale approach that directly inspired the design of PIIP's multi-resolution branches and cross-branch interactions."}, {"fullname_first_author": "W. Wang", "paper_title": "Internimage: Exploring large-scale vision foundation models with deformable convolutions", "publication_date": "2023-MM-DD", "reason": "InternImage, a large-scale vision foundation model, is used as a baseline and is improved upon by PIIP, demonstrating the effectiveness of the proposed method on a strong existing model."}]}