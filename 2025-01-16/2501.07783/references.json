{"references": [{"fullname_first_author": "H. Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-MM-DD", "reason": "This paper introduces data-efficient training methods for image transformers, a crucial technique used in many of the models evaluated in this paper."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "This paper introduces CLIP, a model that learns transferable visual models from natural language supervision, which is foundational to the multimodal understanding tasks considered in this work."}, {"fullname_first_author": "K. He", "paper_title": "Mask R-CNN", "publication_date": "2017-MM-DD", "reason": "Mask R-CNN is a highly influential object detection model used as a baseline for comparison in the experimental evaluation."}, {"fullname_first_author": "Z. Chen", "paper_title": "Vision transformer adapter for dense predictions", "publication_date": "2023-MM-DD", "reason": "This paper proposes a method to adapt vision transformers for dense prediction tasks, a technique relevant to the design of the proposed approach."}, {"fullname_first_author": "W. Wang", "paper_title": "InternImage: Exploring large-scale vision foundation models with deformable convolutions", "publication_date": "2023-MM-DD", "reason": "InternImage is a large-scale vision foundation model used in this paper's experiments, making it an important point of comparison for the proposed model."}]}