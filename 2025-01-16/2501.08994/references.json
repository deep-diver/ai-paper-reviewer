{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper is foundational for transformer-based diffusion models, which are central to the RepVideo approach."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This work is highly influential in text-to-image generation, paving the way for text-to-video generation and demonstrating the power of diffusion models."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduced denoising diffusion probabilistic models (DDPMs), a core technology used in RepVideo for video generation."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper significantly advanced diffusion models by using latent representations, a technique also used by RepVideo to improve efficiency and quality."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2022-09-14", "reason": "This paper demonstrates the feasibility of text-to-video generation using diffusion models, providing a strong foundation and inspiration for the RepVideo model."}]}