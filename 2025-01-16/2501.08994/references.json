{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper is foundational for the use of transformers in high-resolution image generation, a core technique that RepVideo builds upon."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This paper introduced a groundbreaking approach to text-to-image generation, which directly inspired the application of diffusion models to video generation."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This work laid the theoretical foundation for diffusion models, which are central to many recent advances in image and video generation."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper significantly advanced diffusion models by enabling the generation of high-resolution images, paving the way for similar improvements in video generation."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2022-09-14", "reason": "This paper is a direct precursor to RepVideo, demonstrating the potential of diffusion models for text-to-video generation and highlighting the challenges in generating coherent and high-quality videos."}]}