{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper introduced a novel approach using transformers for high-resolution image synthesis, which significantly advanced the field of image generation and inspired similar techniques in video generation."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This paper introduced a method for zero-shot text-to-image generation, demonstrating the potential of generative models in producing realistic images from textual descriptions and influencing the development of text-to-video models."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This foundational paper introduced denoising diffusion probabilistic models, which laid the groundwork for many subsequent advancements in image and video generation."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduced latent diffusion models, improving the efficiency and scalability of diffusion models and providing the basis for many recent video generation techniques."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2022-09-14", "reason": "This work is among the first to achieve text-to-video generation without using paired text and video data, significantly advancing the field and setting a benchmark for subsequent research."}]}