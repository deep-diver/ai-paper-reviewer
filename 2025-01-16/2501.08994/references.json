{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-MM-DD", "reason": "This paper is foundational for transformer-based diffusion models, a key architecture for high-resolution image generation which is directly relevant to this work."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-MM-DD", "reason": "This paper introduces a major advancement in text-to-image generation using diffusion models, setting the stage for similar methods in video generation."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-MM-DD", "reason": "This is a seminal paper introducing denoising diffusion probabilistic models (DDPMs), which are fundamental to many recent advances in image and video generation."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-MM-DD", "reason": "This paper presents a key improvement in diffusion models through the use of latent spaces, improving efficiency and scalability, and is highly relevant to this work."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2022-MM-DD", "reason": "This is a highly influential paper in the field of text-to-video generation, introducing a method that does not require paired text-video data for training"}]}