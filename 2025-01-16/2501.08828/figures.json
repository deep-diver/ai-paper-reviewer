[{"figure_path": "https://arxiv.org/html/2501.08828/x1.png", "caption": "Figure 1. MMDocIR comprises 313 lengthy documents across 10 different domains, along with 1,685 questions. For each question, page-level annotations are provided via selected screenshots. Red boundary boxes represent layout-level annotations.", "description": "This figure illustrates the MMDocIR dataset, which includes 313 long documents spanning 10 diverse domains and a total of 1,685 associated questions.  Each question is meticulously annotated at the page level, using selected screenshots to indicate the relevant page.  Furthermore, the figure highlights layout-level annotations, represented by red boundary boxes, signifying more precise pinpointings of information within each page compared to simple page-level annotations. This detailed annotation makes MMDocIR a robust benchmark for evaluating multi-modal document retrieval systems.", "section": "3 MMDocIR: Evaluation Set"}, {"figure_path": "https://arxiv.org/html/2501.08828/x2.png", "caption": "Figure 2. Area ratio of different modalities (1) in overall and (2) by domains in MMLongBench-Doc benchmark\u00a0(Ma et\u00a0al., 2024b). Note that the white spaces, headers, and footers are removed from the area counting.", "description": "This figure shows a comparison of the area occupied by different modalities (text, images, tables) within documents from the MMLongBench-Doc benchmark.  The first bar chart presents the overall distribution across all document types in the benchmark. The subsequent bar charts break down this area distribution for each individual document domain (Research Report, Administration & Industry, etc.) included in the MMLongBench-Doc dataset. This visualization highlights the prevalence of non-textual content (images and tables) in many document types and the variability across different domains. Note that the calculations exclude white spaces, headers, and footers to focus on the actual content area.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2501.08828/x3.png", "caption": "(a) Avg word length", "description": "This figure presents a comparative analysis of the average word length and word length distribution for OCR-extracted text and VLM-generated text from tables and figures within the MMDocIR dataset.  The subfigure (a) shows a bar chart comparing the average word length for OCR text versus VLM text in tables and images separately. Subfigure (b) displays the distribution of word lengths as histograms for both OCR and VLM text in tables and images.", "section": "Analysis of OCR and VLM Text"}, {"figure_path": "https://arxiv.org/html/2501.08828/x4.png", "caption": "(b) Distribution density of word length", "description": "The figure shows the distribution density of word lengths for OCR and VLM texts extracted from tables and images within the MMDocIR dataset.  It illustrates the difference in word length characteristics between the raw text from OCR and the more descriptive text generated by a Vision Language Model (VLM).  The VLM text is considerably longer than the OCR text, especially for images.", "section": "Analysis of OCR and VLM Text"}]