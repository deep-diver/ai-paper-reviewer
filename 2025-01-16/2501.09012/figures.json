[{"figure_path": "https://arxiv.org/html/2501.09012/x1.png", "caption": "Figure 1: The MM-StyleBench dataset. (a) The distribution of different attributes in MM-StyleBench. the proposed dataset contains diverse images and text prompts with detailed attribute annotations. (b) Examples of content (top) and style (bottom) instances in MM-StyleBench.", "description": "Figure 1 illustrates the MM-StyleBench dataset, a novel resource for multimodal stylization research. Panel (a) presents a statistical overview of the dataset's attributes, highlighting its diversity in terms of content, style, and associated annotations.  This visualization demonstrates the comprehensive nature of the dataset, which includes detailed textual and visual information for each instance. Panel (b) provides concrete examples from the MM-StyleBench, showing both content images (top) and style examples (bottom). This showcases the wide range of artistic styles and content represented within the dataset, emphasizing its suitability for benchmarking multimodal stylization models and related research.", "section": "III. MM-STYLEBENCH"}, {"figure_path": "https://arxiv.org/html/2501.09012/x2.png", "caption": "Figure 2: Overview of our alignment evaluation pipeline. First, (a) we sample content and style from MM-StyleBench for stylization, and construct 2AFC comparison sets by sampling from all possible candidate comparisons. (b) Human preference data is collected and filtered with two heuristic indicators, which is finally aggregated as global rankings. (c) We propose ArtCoT, which involves three art-specific phases to reduce MLLMs\u2019 hallucinations. Finally, we calculate the correlation of rankings from MLLMs and humans as indicators of aesthetic alignment.", "description": "This figure illustrates the three main stages of the aesthetic alignment evaluation pipeline.  First, content and style pairs are sampled from the MM-StyleBench dataset, and various stylization models are used to generate stylized images. These results are then compared pairwise using a two-alternative forced choice (2AFC) methodology, creating a large set of comparisons (a). Human preferences are collected from these comparisons, applying filters for inconsistencies and non-transitive preferences, which are then aggregated into global rankings (b). Finally, the ArtCoT prompting method is applied to three Multimodal Large Language Models (MLLMs) which aims to reduce subjective biases and improve aesthetic alignment with human preferences. The correlation between the MLLM rankings and the human rankings is then calculated as a measure of aesthetic alignment (c).", "section": "IV. MODELING HUMAN PREFERENCE"}, {"figure_path": "https://arxiv.org/html/2501.09012/x3.png", "caption": "Figure 3: Fine-grained comparison of different MLLM prompting scheme. We show the spearman\u2019s \u03c1\ud835\udf0c\\rhoitalic_\u03c1 for per-instance alignment, grouped by representative attribute provided by MM-StyleBench. ArtCoT elicits aesthetic reasoning for all scenarios, especially for instances with long and detailed prompts.", "description": "This figure presents a fine-grained analysis of how different prompting methods affect the alignment of Multimodal Large Language Models (MLLMs) aesthetic evaluations with human preferences.  The Spearman's rank correlation (\u03c1) is shown for per-instance rankings across various attributes from the MM-StyleBench dataset.  The results are grouped by attribute to highlight how different prompting strategies impact alignment across various content and style complexities. The figure demonstrates that the ArtCoT prompting method consistently leads to better alignment compared to baseline and zero-shot Chain-of-Thought (CoT) prompting approaches, particularly when dealing with long and detailed prompts.", "section": "VI. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2501.09012/extracted/6127957/Fig/UI-min.png", "caption": "Figure 4: User Interface for Preference Annotation. We present user with the source image (top), 2AFC (middle) and style prompt (bottom). The user is required to choose the preferred one by clicking on the \u201cleft\u201d or \u201cright\u201d button.", "description": "This figure illustrates the user interface design for collecting human preference data in a two-alternative forced choice (2AFC) task. The interface presents users with three elements: the original content image at the top, two stylized versions of the image in the middle, and the style prompt at the bottom. Users indicate their preferred version by clicking either the 'left' or 'right' button. This design allows for efficient and objective collection of human aesthetic preference.", "section": "IV. MODELING HUMAN PREFERENCE"}, {"figure_path": "https://arxiv.org/html/2501.09012/x4.png", "caption": "Algorithm\u00a01 Sample a Connected Subgraph with Uniform Degree Distribution", "description": "This algorithm samples a connected subgraph from a complete graph, ensuring a uniform distribution of node degrees.  It begins by creating a minimum spanning tree using Kruskal's algorithm to guarantee connectivity. Then, it iteratively adds edges to the subgraph, prioritizing those that minimize the degree imbalance between nodes. This process continues until a specified number of edges are included, resulting in a subgraph with a relatively uniform distribution of node degrees, making it suitable for generating balanced pairwise comparisons in preference ranking tasks.", "section": "IV. MODELING HUMAN PREFERENCE"}, {"figure_path": "https://arxiv.org/html/2501.09012/x5.png", "caption": "Figure 5: Examples of Stylized Image. We show two uncurated examples from different stylization results, the image order are randomized. The styles are impressionist and cubism, respectively. The results covers a wide range of stylization performance, setting a realistic and challenging task for artistic evaluation.", "description": "This figure showcases the diversity of stylization results obtained from various methods. Two examples are displayed, each representing a different style: Impressionism and Cubism.  The images demonstrate the varying levels of success achieved in stylizing a single content image. This variability highlights the complexity of artistic evaluation and the challenge of developing robust quantitative metrics for assessing aesthetic quality. The range of stylization results, from near-perfect to highly inaccurate, underscores the realistic difficulty of the task.", "section": "III. MM-StyleBench"}]