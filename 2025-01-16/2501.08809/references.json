{"references": [{"fullname_first_author": "A. Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-MM-DD", "reason": "This paper introduced the Transformer architecture, a crucial component of the XMusic framework for symbolic music generation."}, {"fullname_first_author": "Z. Dai", "paper_title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "publication_date": "2019-MM-DD", "reason": "This paper improved upon the Transformer architecture, enabling better handling of long-range dependencies within music sequences."}, {"fullname_first_author": "C. -Z. A. Huang", "paper_title": "Music Transformer: Generating Music with Long-Term Structure", "publication_date": "YYYY-MM-DD", "reason": "This paper was among the first to successfully apply the Transformer architecture for generating long symbolic music sequences."}, {"fullname_first_author": "W. -Y. Hsiao", "paper_title": "Compound Word Transformer: Learning to Compose Full-Song Music Over Dynamic Directed Hypergraphs", "publication_date": "2021-MM-DD", "reason": "This paper introduced a novel tokenization technique which the authors of the current paper enhanced upon for better controllability and efficiency in symbolic music generation."}, {"fullname_first_author": "H. -T. Hung", "paper_title": "EMOPIA: A Multi-Modal Pop Piano Dataset for Emotion Recognition and Emotion-Based Music Generation", "publication_date": "2021-MM-DD", "reason": "This paper presented a dataset of symbolic music with emotion labels, which was used for training and evaluation in the XMusic framework."}]}