<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2025-02-25s on HF Daily Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/</link><description>Recent content in 2025-02-25s on HF Daily Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 Hugging Face Daily Papers</copyright><lastBuildDate>Mon, 24 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/index.xml" rel="self" type="application/rss+xml"/><item><title>Benchmarking Temporal Reasoning and Alignment Across Chinese Dynasties</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16922/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16922/</guid><description>CTM: A new benchmark for assessing temporal reasoning in LLMs across Chinese dynastic history.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16922/cover.png"/></item><item><title>DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17157/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17157/</guid><description>DICEPTION: A generalist diffusion model for visual perceptual tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17157/cover.png"/></item><item><title>GCC: Generative Color Constancy via Diffusing a Color Checker</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17435/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17435/</guid><description>GCC: Color constancy through diffusion, inpainting a color checker for stable illumination estimation.</description></item><item><title>Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17407/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17407/</guid><description>Test-time scaling isn&amp;rsquo;t a universal solve-all for multilingual math reasoning, unlike pre-training scaling, shows MCLM benchmark.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17407/cover.png"/></item><item><title>Make LoRA Great Again: Boosting LoRA with Adaptive Singular Values and Mixture-of-Experts Optimization Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16894/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16894/</guid><description>GOAT: Adaptively boosts LoRA with SVD &amp;amp; MoE alignment, closing the gap with Full FT.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16894/cover.png"/></item><item><title>Mobile-Agent-V: Learning Mobile Device Operation Through Video-Guided Multi-Agent Collaboration</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17110/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17110/</guid><description>Mobile-Agent-V: Automating mobile tasks using video guidance for efficient, scalable operation, outperforming existing frameworks by 30%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17110/cover.png"/></item><item><title>Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17055/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17055/</guid><description>Stable-SPAM stabilizes 4-bit LLM training, outperforming Adam.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17055/cover.png"/></item><item><title>VideoGrain: Modulating Space-Time Attention for Multi-grained Video Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17258/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17258/</guid><description>VideoGrain: Fine-grained video editing via space-time attention!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17258/cover.png"/></item><item><title>X-Dancer: Expressive Music to Human Dance Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17414/</link><pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17414/</guid><description>X-Dancer: Expressive dance video generation from music and a single image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.17414/cover.png"/></item><item><title>Beyond Release: Access Considerations for Generative AI Systems</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16701/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16701/</guid><description>AI system access is more than just release; it&amp;rsquo;s about how accessible system components are, impacting benefits, risks, and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16701/cover.png"/></item><item><title>CodeCriticBench: A Holistic Code Critique Benchmark for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16614/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16614/</guid><description>CodeCriticBench: A new benchmark for holistic code critique by Large Language Models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16614/cover.png"/></item><item><title>Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16707/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16707/</guid><description>Reflect VLM: Improving robotic manipulation via vision-language models with a novel reflection mechanism and a diffusion model for imagined futures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16707/cover.png"/></item><item><title>Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16033/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16033/</guid><description>MMIR: A new benchmark to assess and improve multimodal reasoning models&amp;rsquo; ability to detect inconsistencies in real-world content.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.16033/cover.png"/></item><item><title>Forecasting Open-Weight AI Model Growth on Hugging Face</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15987/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15987/</guid><description>Predicting open-weight AI model growth on Hugging Face using a citation-style model, revealing adoption dynamics and influencing factors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15987/cover.png"/></item><item><title>M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15167/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15167/</guid><description>M3-AGIQA: A multimodal AI solution that comprehensively assesses AI-generated image quality, achieving state-of-the-art performance by distilling online MLLM capabilities into a local model.</description></item><item><title>MONSTER: Monash Scalable Time Series Evaluation Repository</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15122/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15122/</guid><description>MONSTER: Large datasets for time series classification!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15122/cover.png"/></item><item><title>TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15425/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15425/</guid><description>TAG: A decentralized framework for scalable multi-agent hierarchical reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15425/cover.png"/></item><item><title>Can Community Notes Replace Professional Fact-Checkers?</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.14132/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.14132/</guid><description>Community moderation success relies on fact-checking!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.14132/cover.png"/></item><item><title>Slamming: Training a Speech Language Model on One GPU in a Day</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15814/</link><pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15814/</guid><description>Slam: Train SLMs on one GPU in a day!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.15814/cover.png"/></item><item><title>The snake in the Brownian sphere</title><link>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.13074/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.13074/</guid><description>Unveiling the Brownian snake within the Brownian sphere! This research constructs the inverse of the CVS bijection, mapping the sphere back to its underlying snake.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/2025-02-25/2502.13074/cover.png"/></item></channel></rss>