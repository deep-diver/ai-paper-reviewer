[{"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.tab1.1.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.tab1.1.1.1.1.1\">\\rowcolor</span>gray!50 <span class=\"ltx_text ltx_font_bold\" id=\"S6.tab1.1.1.1.1.2\">Cluster ID</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.tab1.1.1.1.2.1\">Models</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.1.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.tab1.1.1.1.3.1\">Main Categories</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.1.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.tab1.1.1.1.4.1\">Error Pattern</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.tab1.1.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.2.2.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.1.1.1\">gpt-4o</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.2.1.1\">DeepSeek-V3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.3.1.1\">o1-mini</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">Culture and the arts</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.tab1.1.1.2.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.2.4.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(1) Challenging in Chronological Analysis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(2) Unfamiliar with Locational Details</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(3) Issues in Pattern Recognition</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.4\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(4) Inaccurate Data Synthesis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.5\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(5) Collaborative and Relational Patterns</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S6.tab1.1.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S6.tab1.1.1.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.2.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.1.1.1\">Qwen2.5-72B-Instruct</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.2.1.1\">Llama-3.3-70B-Instruct</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.3.1.1\">R1-Distill-Llama-70B</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S6.tab1.1.1.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.3.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.3.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Health and fitness</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.3.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Natural and physics science</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S6.tab1.1.1.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.4.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(1) Challenges with Chronological and Historical Data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(2) Issues with Contextual and Performance-Related Information</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(3) Inaccurate Interpretation of Patterns and Trends</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.4\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(4) Over-reliance on Assumptions and Generalizations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.5\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(5) Difficulty with Contextual Associations and Identifications</td>\n</tr>\n</table>\n</td>\n</tr>\n</table>", "caption": "Table 1:  Error patterns for models in cluster 3 and 5 in Fig.\u00a06. We aggregate error patterns from the question level to the paragraph level and finally to the model level.", "description": "This table presents an analysis of error patterns exhibited by different language models within two specific clusters (3 and 5) identified in Figure 6.  The analysis is hierarchical: it starts by examining individual question-level errors, aggregates them into paragraph-level patterns, and ultimately summarizes these patterns at the model level. This provides a detailed understanding of the types of knowledge deficiencies and systematic weaknesses present in each model within the clusters.", "section": "6 Analyzing LLMs from the Discovery Results"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.2.2.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.1.1.1\">gpt-4o</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.2.1.1\">DeepSeek-V3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.2.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.2.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.2.2.1.3.1.1\">o1-mini</span></td>\n</tr>\n</table>", "caption": "Table 2:  Question generation cost, inference cost, and output tokens at inference time across 20 steps (results in Fig.3; 20,000 questions in total). We can see a significant gap between reasoning models (DeepSeek-R1, R1-Distill-Llama-70B, and o1-mini) and other non-reasoning models.", "description": "This table presents a detailed breakdown of the computational costs associated with running eight different large language models (LLMs) over 20,000 questions.  The costs are categorized into question generation costs, inference costs (the cost of the model processing the questions), and the number of output tokens generated by each model.  A key observation is the significant difference in cost between LLMs with reasoning capabilities (DeepSeek-R1, R1-Distill-Llama-70B, and o1-mini) and those without.  Reasoning models show substantially higher costs, particularly in inference, highlighting the increased computational demands of their enhanced reasoning abilities.", "section": "4 Comparing Stochastic Error Ascent with Baselines"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.2.4.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(1) Challenging in Chronological Analysis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(2) Unfamiliar with Locational Details</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(3) Issues in Pattern Recognition</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.4\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(4) Inaccurate Data Synthesis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.2.4.1.5\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.2.4.1.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(5) Collaborative and Relational Patterns</td>\n</tr>\n</table>", "caption": "Table 3: Example 1 for query 4. The correct doctoral year is \"2000\", but the misinformation incorrectly states \"1998\". The incorrect information has been highlighted using underlines.", "description": "This table presents an example from the study that illustrates a case where a large language model (LLM) provides misinformation. The example focuses on a question about James B. Stump's doctoral degree year. The correct year is 2000, but the LLM incorrectly states 1998.  The table highlights the incorrect information using underlines for emphasis. This case demonstrates the types of knowledge deficiencies the research method aims to uncover and analyze.", "section": "A Extra Analysis and Case Studies"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.2.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.1.1.1\">Qwen2.5-72B-Instruct</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.2.1.1\">Llama-3.3-70B-Instruct</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.2.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.2.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_typewriter\" id=\"S6.tab1.1.1.3.2.1.3.1.1\">R1-Distill-Llama-70B</span></td>\n</tr>\n</table>", "caption": "Table 4: Example 2 for query 4. The proper event is \"African Photography Encounters,\" yet the misinformation erroneously identifies it as the \"2019 Whitney Biennial\". The incorrect information has been highlighted using underlines.", "description": "This table presents an example of a question from the SEA method's evaluation, demonstrating a case where the LLM (Large Language Model) produced misinformation. The question asked in which event a specific photographic series was included. The correct answer is \"African Photography Encounters\", but the LLM incorrectly identified the event as the \"2019 Whitney Biennial\".  The table highlights the LLM's incorrect response by underlining the erroneous information. This example illustrates the type of knowledge deficiencies SEA is designed to uncover.", "section": "A Extra Analysis and Case Studies"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.3.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.3.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Health and fitness</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.3.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">Natural and physics science</td>\n</tr>\n</table>", "caption": "Table 5: Example 3 for query 4. It shows that the true artist and medium are \"Robert Delaunay, oil on cardboard\", while the misinformation wrongly lists \"Marcel Janco\" and \"oil on canvas\". The incorrect information has been highlighted using underlines.", "description": "Table 5 presents an example from Query 4 of the paper's experimental setup.  It showcases a question about the artist and medium of the painting \"Portrait of Tristan Tzara.\" The table contrasts the correct answer (Robert Delaunay, oil on cardboard) with an incorrect response generated by a language model (Marcel Janco, oil on canvas). The incorrect parts of the language model's answer are underlined in the table to highlight the misinformation.", "section": "A Extra Analysis and Case Studies"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S6.tab1.1.1.3.4.1\">\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.1.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(1) Challenges with Chronological and Historical Data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(2) Issues with Contextual and Performance-Related Information</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.3\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(3) Inaccurate Interpretation of Patterns and Trends</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.4\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(4) Over-reliance on Assumptions and Generalizations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.tab1.1.1.3.4.1.5\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S6.tab1.1.1.3.4.1.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">(5) Difficulty with Contextual Associations and Identifications</td>\n</tr>\n</table>", "caption": "Table 6: Example 4 for query 4. In Example 4, the accurate venue is \"Deutsches Hygiene-Museum, Dresden\", but the misinformation mistakenly mentions \"Kunstmuseum Bern\". The incorrect information has been highlighted using underlines.", "description": "This table presents an example (Example 4) of a question about the venue that hosted the exhibition \"Six Feet Under\" during 2007 and 2008.  The correct answer is Deutsches Hygiene-Museum, Dresden. However, the language model incorrectly identified Kunstmuseum Bern as the venue. The table shows the original question, the correct answer, the modified question for improved clarity, and the incorrect answer given by the language model, highlighting the misinformation with underlines.", "section": "A Extra Analysis and Case Studies"}, {"content": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.tab1.1.1\">\n<tr class=\"ltx_tr\" id=\"A2.tab1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.tab1.1.1.1.1.1\">\\rowcolor</span>gray!50 <span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.1.2\">Model Cost</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.2\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.2.1\">DeepSeek-R1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.3\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.3.1\">R1-Distill-Llama-70B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.4\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.4.1\">o1-mini</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.5\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.5.1\">DeepSeek-V3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.6\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.6.1\">Llama-3.3-70B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.7\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.7.1\">Qwen2.5-72B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.8\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.8.1\">gpt-4o-mini</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.1.9\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.tab1.1.1.1.9.1\">gpt-4o</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.tab1.1.1.2\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.1.1\" style=\"background-color:#FFFFFF;\">Generation Cost (US $)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.2\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.2.1\" style=\"background-color:#FFFFFF;\">28.163</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.3\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.3.1\" style=\"background-color:#FFFFFF;\">28.660</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.4\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.4.1\" style=\"background-color:#FFFFFF;\">31.094</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.5\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.5.1\" style=\"background-color:#FFFFFF;\">30.208</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.6\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.6.1\" style=\"background-color:#FFFFFF;\">29.776</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.7\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.7.1\" style=\"background-color:#FFFFFF;\">29.542</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.8\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.8.1\" style=\"background-color:#FFFFFF;\">28.243</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.tab1.1.1.2.9\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.2.9.1\" style=\"background-color:#FFFFFF;\">32.897</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.tab1.1.1.3\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.1.1\" style=\"background-color:#E6E6E6;\">Inference Cost (US $)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.2\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.2.1\" style=\"background-color:#E6E6E6;\">48.360</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.3\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.3.1\" style=\"background-color:#E6E6E6;\">7.888</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.4\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.4.1\" style=\"background-color:#E6E6E6;\">39.708</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.5\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.5.1\" style=\"background-color:#E6E6E6;\">1.261</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.6\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.6.1\" style=\"background-color:#E6E6E6;\">0.868</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.7\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.7.1\" style=\"background-color:#E6E6E6;\">0.37</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.8\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.8.1\" style=\"background-color:#E6E6E6;\">0.347</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.tab1.1.1.3.9\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.3.9.1\" style=\"background-color:#E6E6E6;\">7.905</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.tab1.1.1.4\" style=\"background-color:#FFFFFF;\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.1\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.1.1\" style=\"background-color:#FFFFFF;\">Inference Output Tokens</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.2\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.2.1\" style=\"background-color:#FFFFFF;\">19,608,736</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.3\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.3.1\" style=\"background-color:#FFFFFF;\">10,836,882</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.4\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.4.1\" style=\"background-color:#FFFFFF;\">8,507,015</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.5\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.5.1\" style=\"background-color:#FFFFFF;\">380,099</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.6\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.6.1\" style=\"background-color:#FFFFFF;\">1,024,942</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.7\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.7.1\" style=\"background-color:#FFFFFF;\">272,566</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.8\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.8.1\" style=\"background-color:#FFFFFF;\">125,117</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"A2.tab1.1.1.4.9\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span class=\"ltx_text\" id=\"A2.tab1.1.1.4.9.1\" style=\"background-color:#FFFFFF;\">308,145</span></td>\n</tr>\n</table>", "caption": "Table 7: Example 5 for query 4. Original testing process correctly names the venue as \"Kunst Raum Riehen\", in contrast to the misinformation\u2019s incorrect attribution to \"VITRINE\".The incorrect information has been highlighted using underlines.", "description": "Table 7 presents an example related to Query 4 of the study, which investigates whether LLMs produce misinformation when encountering unknown knowledge.  The table focuses on an instance where an LLM incorrectly identifies the venue of an art exhibition.  Specifically, the original question asks for the venue of Clare Kenny's \"If I Was a Rich Girl\" exhibition in 2019. The correct answer is \"Kunst Raum Riehen.\" However, the LLM incorrectly states that the exhibition was held at \"VITRINE.\" The table highlights the LLM's incorrect response in underlines for clarity.", "section": "A Extra Analysis and Case Studies"}]