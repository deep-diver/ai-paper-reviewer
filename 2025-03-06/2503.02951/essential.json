{"importance": "This work introduces a **large-scale, diverse, and verifiable synthetic dataset** that boosts coding LLM performance, offering a **new benchmark** and directions for future research.", "summary": "KODCODE: A new synthetic coding dataset with verified solutions and tests, enabling state-of-the-art performance for coding LLMs.", "takeaways": ["KODCODE is a diverse and challenging synthetic dataset for coding, comprising 447K verified question-solution-test triplets.", "The dataset is systematically validated via a self-verification procedure, ensuring high-quality training data.", "Models fine-tuned on KODCODE achieve state-of-the-art performance on coding benchmarks, surpassing existing models."], "tldr": "Large Language Models for coding are powerful, but require high-quality, verifiable training data. Current code resources fail to cover a broad range of coding tasks, from simple to algorithmic, and often lack verifiable correctness, such as unit tests. This presents a challenge for training robust and reliable coding models. Datasets are either limited in scale, lack diversity and complexity, or don't offer reliable response verification, hindering the development of truly capable coding assistants. \n\nTo address this, this paper introduces KODCODE, a synthetic dataset of 447K coding questions with verified solutions and unit tests. KODCODE uses a three-step pipeline: question synthesis from 12 sources, solution and test generation with self-verification, and post-training data synthesis to diversify questions. It evaluates its effectiveness on coding benchmarks, demonstrating state-of-the-art performance surpassing models such as Qwen2.5-Coder and DeepSeek-R1, showing its potential to advance SFT and RL post-training pipelines.", "affiliation": "Microsoft GenAI", "categories": {"main_category": "Machine Learning", "sub_category": "Deep Learning"}, "podcast_path": "2503.02951/podcast.wav"}