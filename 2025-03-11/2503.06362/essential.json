{"importance": "This paper is important for researchers because it introduces a novel approach to AVSR that balances accuracy and computational efficiency, making it applicable to resource-constrained scenarios. It leverages MRL, and provides a flexible way to tune the model based on the tasks/datasets, leading to **new research directions in multimodal LLMs**. This approach paves the way for deploying more sophisticated AVSR systems in real-world applications.", "summary": "Llama-MTSK:  AVSR via Matryoshka LLMs, adapting to computational limits without sacrificing accuracy! ", "takeaways": ["Llama-MTSK, the first Matryoshka-based Multimodal LLM, can dynamically adjust the number of tokens processed during inference.", "Llama-MTSK achieves state-of-the-art results on LRS2 and LRS3 datasets.", "Three LoRA-based Matryoshka strategies are introduced to efficiently fine-tune the pre-trained LLM."], "tldr": "Audio-Visual Speech Recognition (AVSR) improves speech recognition, especially in noisy conditions, by utilizing both audio and video. Large Language Models (LLMs) have improved this task, but integrating speech representations into LLMs increases computational costs. Current solutions compress speech data before feeding it to LLMs, which degrades performance with higher compression. This creates a trade-off between efficiency and accuracy. \n\nThis paper introduces Llama-MTSK for AVSR, a Matryoshka-based Multimodal LLM that **flexibly adapts token allocation based on computational constraints** while preserving performance. It encodes audio-visual data at multiple granularities, eliminating the need for separate models for different compression levels. Three LoRA-based Matryoshka strategies are introduced for efficient fine-tuning. Evaluations show Llama-MTSK achieves state-of-the-art results matching or surpassing models trained independently at fixed compression levels.", "affiliation": "Imperial College London", "categories": {"main_category": "Multimodal Learning", "sub_category": "Audio-Visual Learning"}, "podcast_path": "2503.06362/podcast.wav"}