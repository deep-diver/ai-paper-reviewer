[{"figure_path": "https://arxiv.org/html/2503.06121/extracted/6262278/rimer3.png", "caption": "Figure 1: The benchmarks reveal that Rimer, with a significantly reduced parameter count of just 1.6 million, consistently outperforms or matches the performance of Timer, which relies on a much larger 37.8 million parameters, across multiple metrics.", "description": "The bar chart compares the performance of two time series models, Rimer and Timer, across four datasets (ELC, ETTH, Traffic, and Weather).  Rimer, despite having significantly fewer parameters (1.6 million vs. Timer's 37.8 million), demonstrates comparable or superior performance across multiple evaluation metrics (RMSE, MAE, MAPE, and R2).  This highlights Rimer's efficiency and effectiveness in large-scale time series modeling.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2503.06121/extracted/6262278/rwkv-7-architecture.jpg", "caption": "Figure 2: The RWKV-7 architecture is a RNN model that processes sequences using repeated RWKV blocks, each containing:1.A time mix block to blend current and past information.2.WKV heads for attention-like processing with an internal state to maintain memory.A channel mix block to transform the data further.", "description": "The RWKV-7 architecture is depicted as a recurrent neural network (RNN) composed of repeating RWKV blocks.  Each block incorporates three key components: a time mix block to integrate past and present information; WKV heads, which perform attention-like operations and retain an internal state to store memory; and a channel mix block, which further processes and transforms the data.", "section": "3 Methodology"}]