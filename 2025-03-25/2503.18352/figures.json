[{"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/metric.jpg", "caption": "Figure 1: Example results synthesized by our Diffusion-4K, emphasizing exceptional fine details in generated 4K images.", "description": "This figure showcases example images generated using the Diffusion-4K model.  The images highlight the model's ability to synthesize ultra-high-resolution (4K) images with exceptional detail and realism, emphasizing the fine textures and intricate features that are often lost in lower-resolution image generation methods.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2503.18352/x1.png", "caption": "Figure 2: Analysis of GLCM Score\u2191\u2191\\uparrow\u2191 / Compression Ratio\u2193\u2193\\downarrow\u2193. Our indicators demonstrate strong alignment with human-centric perceptual cognition at the level of local patches.", "description": "Figure 2 presents a correlation analysis between the Gray Level Co-occurrence Matrix (GLCM) Score and the Compression Ratio, metrics designed to evaluate fine details in images, specifically at 4K resolution.  The GLCM score measures textural richness by analyzing the spatial distribution of gray levels in local image patches, while the compression ratio assesses the preservation of detail by measuring how well the image compresses using lossy compression (JPEG).  The results indicate a strong positive correlation between higher GLCM scores (indicating richer texture) and lower compression ratios (indicating better preservation of fine details), showing strong alignment with human perception of image quality.  Human observers tend to rate images with high textural detail and well-preserved fine details more favorably.  The analysis is done at the patch level to show the alignment at local feature level.", "section": "3.1 Aesthetic-4K Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.18352/x2.png", "caption": "(a) Image-text samples in training set.", "description": "This figure displays examples of image-text pairs from the Aesthetic-4K training dataset.  The images are high-quality, ultra-high-resolution (4K) images, and the accompanying text captions were generated using GPT-40. This showcases the high standard of the dataset used to train the Diffusion-4K model, emphasizing both visual quality and precise textual descriptions for improved model performance.", "section": "3.1. Aesthetic-4K Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/vae.jpg", "caption": "(b) Image-text samples in evaluation set.", "description": "This figure shows example image-text pairs from the evaluation subset of the Aesthetic-4K dataset.  These examples illustrate the high-quality images and precise text prompts characteristic of this dataset, which is specifically designed for evaluating ultra-high-resolution (4K) image synthesis models.  The images demonstrate a variety of subjects and visual styles, showcasing the diversity of the dataset.", "section": "3.1. Aesthetic-4K Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.18352/x3.png", "caption": "Figure 3: Illustration of image-text samples in the Aesthetic-4K dataset, which includes high-quality images and precise text prompts generated by GPT-4o, distinguished by high aesthetics and fine details.", "description": "Figure 3 presents examples from the Aesthetic-4K dataset.  The dataset contains high-resolution images (4K) paired with detailed captions generated by the GPT-40 language model. These image-caption pairs are carefully selected to represent a high standard of visual aesthetics and showcase fine details.  The figure aims to illustrate the quality and precision of the data within the Aesthetic-4K benchmark, which is designed for evaluating and training ultra-high-resolution image synthesis models.", "section": "3.1 Aesthetic-4K Benchmark"}, {"figure_path": "https://arxiv.org/html/2503.18352/x4.png", "caption": "Figure 4: Reconstruction results of 4K images with partitioned VAEs of F=16\ud835\udc3916F=16italic_F = 16.", "description": "This figure displays the reconstruction results of 4K images using partitioned Variational Autoencoders (VAEs) with a downsampling factor of F=16.  The partitioned VAE approach is a key component of the Diffusion-4K framework, designed to address the computational challenges of handling ultra-high-resolution images. By partitioning the VAE, the model efficiently manages the memory requirements during training and inference. The figure visually demonstrates the quality of reconstruction achieved by the partitioned VAEs, showcasing the effectiveness of this method for ultra-high resolution image processing.", "section": "3. Methods"}, {"figure_path": "https://arxiv.org/html/2503.18352/x6.png", "caption": "Figure 5: Qualitative 4K images synthesis of Diffusion-4K. Prompts are from Sora\u00a0[30].", "description": "This figure showcases example images generated by the Diffusion-4K model, demonstrating its ability to synthesize high-quality, photorealistic 4K images from various text prompts. The prompts used to generate the images are sourced from the Sora [30] dataset, showcasing the model's ability to translate text descriptions into detailed and visually appealing images.  Each image depicts a diverse range of scenes, subjects, and artistic styles, highlighting the model's versatility and capacity to generate high-resolution images across multiple categories.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18352/x7.png", "caption": "Figure 6: Human and GPT-4o preference evaluation.", "description": "Figure 6 is a bar chart comparing human preferences against those of GPT-40 for various aspects of image quality.  The chart displays the percentage of times each model preferred different aspects of four different generated images:  Visual Aesthetics, Prompt Adherence, Fine Details, and Human Preference.  This allows a comparison to show how well the AI model's preferences align with human preferences for these image qualities in the context of 4K image generation.", "section": "4.2. Experiment Results"}, {"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/demo_supplement.jpg", "caption": "Figure 7: \nWe present comparisons with PixArt-\u03a3\u03a3\\Sigmaroman_\u03a3\u00a0[9] using identical prompts, with images from PixArt-\u03a3\u03a3\\Sigmaroman_\u03a3 displayed on the left and those synthesized by our Diffusion-4K shown on the right.\nOur approach demonstrates significant superiority over PixArt-\u03a3\u03a3\\Sigmaroman_\u03a3 in fine details, as evidenced by the yellow patches vs. the red patches.", "description": "This figure compares the image generation results of Diffusion-4K and PixArt-\u03a3 using the same prompts.  The left side shows images generated by PixArt-\u03a3, while the right side displays images from Diffusion-4K.  Yellow highlighted patches in the Diffusion-4K images indicate areas with superior fine detail compared to the red-highlighted areas in PixArt-\u03a3 images, demonstrating Diffusion-4K's improved performance in generating high-resolution images with intricate details.", "section": "7. Comparisons"}, {"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/demo_seed_supplement.jpg", "caption": "Figure 8: Comparisons with Sana\u00a0[49].", "description": "This figure displays a comparison of image generation results between the Diffusion-4K model and the Sana [49] model.  Each pair of images shows the same prompt rendered by both models, allowing for a visual assessment of the differences in image quality, detail, and adherence to the prompt.  It highlights the relative strengths of Diffusion-4K in producing ultra-high-resolution images with fine details.", "section": "7. Comparisons"}, {"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/demo_diffusion_4k_supplement.jpg", "caption": "Figure 9: Ablation study on WLF.", "description": "This figure displays an ablation study comparing the performance of the Wavelet-based Fine-tuning (WLF) method. It visually demonstrates the effect of WLF on generating high-resolution images by showing samples of images generated with and without WLF. This allows for a direct comparison and highlights the improvements achieved through the use of WLF in terms of image detail and quality.", "section": "3.2. Wavelet-based Fine-tuning"}, {"figure_path": "https://arxiv.org/html/2503.18352/x8.png", "caption": "Figure 10: High-quality images synthesized by our Diffusion-4k.", "description": "This figure showcases several high-quality images generated by the Diffusion-4K model.  Each image demonstrates the model's ability to synthesize diverse scenes with high-fidelity details and accurate representation of textures, including nature scenes, cityscapes, animals, and fantasy elements. The images highlight the model's proficiency in capturing realistic light and shadows, fine textures, and overall photorealism at 4K resolution.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18352/x9.png", "caption": "Figure 11: Synthesized images with different aspect ratios and random seeds.", "description": "This figure showcases the versatility of Diffusion-4K in generating high-resolution images at various aspect ratios and with different random seeds.  The results demonstrate the model's ability to maintain image quality and coherence across diverse settings, highlighting its robustness and adaptability.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18352/extracted/6304121/figures/demo_data_supplement.jpg", "caption": "Figure 12: Synthesized images with spelled texts.", "description": "Figure 12 displays examples of images generated by the Diffusion-4K model where the text prompts included intentionally misspelled words. This showcases the model's ability to generate coherent images even when the input text contains errors, highlighting its robustness and potential for creative applications.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2503.18352/x10.png", "caption": "Figure 13: Histograms of image height and width in Aesthetic-4K.", "description": "This figure shows the distribution of image heights and widths within the Aesthetic-4K dataset.  Two histograms are presented, one for height and one for width.  Each histogram displays the frequency of images at different height and width values, giving insight into the size and aspect ratio variations present in the dataset. This is important for understanding the characteristics of the dataset and its suitability for training and evaluating ultra-high-resolution image synthesis models.", "section": "3.1 Aesthetic-4K Benchmark"}]