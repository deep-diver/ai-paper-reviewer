{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-01-01", "reason": "This paper introduces Flamingo, a visual language model relevant as MetaSpatial aims to enhance spatial reasoning in vision-language models."}, {"fullname_first_author": "Yuntao Bai", "paper_title": "Training a helpful and harmless assistant with reinforcement learning from human feedback", "publication_date": "2022-04-01", "reason": "This paper explores reinforcement learning from human feedback, a relevant technique in MetaSpatial which also uses RL."}, {"fullname_first_author": "Boyuan Chen", "paper_title": "Spatialvlm: Endowing vision-language models with spatial reasoning capabilities", "publication_date": "2024-01-01", "reason": "This paper is directly related, as it also attempts to enhance spatial reasoning in vision-language models."}, {"fullname_first_author": "Weixi Feng", "paper_title": "Layoutgpt: Compositional visual planning and generation with large language models", "publication_date": "2023-01-01", "reason": "This paper is relevant because it explores using large language models for layout generation, which is the core problem MetaSpatial addresses."}, {"fullname_first_author": "Jingyi Zhang", "paper_title": "Vision-language models for vision tasks: A survey", "publication_date": "2024-01-01", "reason": "This paper provides a survey of vision-language models, providing relevant background as MetaSpatial focuses on this area."}]}