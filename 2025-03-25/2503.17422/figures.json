[{"figure_path": "https://arxiv.org/html/2503.17422/extracted/6298833/images/Framework.png", "caption": "Figure 1: From left: optimization flow and contributions. SG2042 block diagram. Pseudocode of the proposed kernel.", "description": "This figure provides a comprehensive overview of the optimization process and its components. The leftmost panel illustrates the optimization flow, detailing the steps involved in accelerating LLM reasoning on RISC-V platforms. This includes kernel optimization, compilation toolchain selection, and memory allocation strategies.  The central panel presents a block diagram of the Sophon SG2042, a many-core RISC-V CPU, highlighting its key architectural features.  Finally, the rightmost panel shows the pseudocode of the optimized kernel developed for this work, which is central to improving the performance of LLM inference on this platform.", "section": "2 Methods"}, {"figure_path": "https://arxiv.org/html/2503.17422/x1.png", "caption": "Figure 2: Matrix vector multiplication size scalability test", "description": "This figure shows the scalability of matrix-vector multiplication performance as the size of the square matrix increases.  Different methods are compared, including OpenBLAS's sgemm (general matrix multiplication) and sgemv (matrix-vector multiplication), a scalar GGML implementation, a GGML implementation using RISC-V vector instructions (RVV), and the authors' optimized approach. The x-axis represents the size of the square matrix, and the y-axis represents the GOPS (gigaflops per second), a measure of computational performance.  The graph illustrates how the performance of each method scales with the matrix size, highlighting the efficiency gains achieved by the authors' optimized kernel.", "section": "3 Results"}, {"figure_path": "https://arxiv.org/html/2503.17422/x2.png", "caption": "Figure 3: Compilers comparison scaling the n. of threads for DeepSeek\u2019s 8B model token gen., Bar, and prefill, Line.", "description": "This figure compares the performance of two different compilers, GCC 13.2 and Clang 19.0, when compiling the code for DeepSeek's 8B model on the Sophon SG2042. The x-axis represents the number of threads used, and the y-axis shows the throughput in tokens per second.  Two sets of data are displayed. Bars represent the token generation throughput, while the line shows the prefill throughput. The results indicate that Clang 19.0 consistently outperforms GCC 13.2 across various thread counts, highlighting its advantage in optimizing the code for this particular model and hardware.", "section": "3 Results"}, {"figure_path": "https://arxiv.org/html/2503.17422/x3.png", "caption": "Figure 4: NUMA policies exploration on DeepSeek\u2019s 8B model. Token generation shown with bars, prefill with lines.", "description": "This figure shows the impact of different NUMA (Non-Uniform Memory Access) policies on the performance of DeepSeek's 8B model.  It compares four different NUMA configuration strategies: NUMA balancing enabled, NUMA balancing disabled, NUMA balancing disabled with core binding, and NUMA balancing disabled with memory interleaving.  The performance is measured in terms of token generation (bars) and prefill (lines) throughput in tokens per second across different numbers of threads.  This illustrates how different NUMA policies affect parallel processing efficiency and the resulting impact on speed of processing tokens during model operation.", "section": "3 Results"}]