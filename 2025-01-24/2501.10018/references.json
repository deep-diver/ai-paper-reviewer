{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2022-11-00", "reason": "This paper is foundational for image editing with diffusion models, a key concept in the target paper."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70M: Captioning 70M videos with multiple cross-modality teachers", "publication_date": "2024-00-00", "reason": "This dataset is crucial for training and evaluating video inpainting models, directly impacting the experiments in the target paper."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen Video: High definition video generation with diffusion models", "publication_date": "2022-00-00", "reason": "This is a seminal work in video generation using diffusion models, providing a strong theoretical basis for the target paper's approach."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-00-00", "reason": "This paper significantly advanced the capabilities of diffusion models for high-resolution image generation, which is leveraged in the target paper's video inpainting model."}, {"fullname_first_author": "Minhyeok Lee", "paper_title": "Video diffusion models are strong video inpainter", "publication_date": "2024-00-00", "reason": "This paper directly addresses video inpainting with diffusion models, offering a comparative approach and results for the target paper."}]}