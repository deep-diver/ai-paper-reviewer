[{"figure_path": "https://arxiv.org/html/2502.12018/x1.png", "caption": "Figure 1: Comparison of computational resource allocation in test-time scaling methods. Traditional test-time scaling methods allocate computational resources partially to process historical information, while AoT dedicates all computational resources to reasoning directly related to the current atomic question state.", "description": "This figure compares how different test-time scaling methods utilize computational resources. Traditional methods dedicate some resources to processing past reasoning steps (historical information), which can be inefficient and potentially hinder accurate reasoning. In contrast, Atom of Thoughts (AoT) focuses all computational resources on the current reasoning step, treating each step as an independent 'atomic' question. This targeted approach aims for improved efficiency and better reasoning outcomes.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.12018/x2.png", "caption": "Figure 2: The overview of AoT. The left portion illustrates our Markov process where each state Qisubscript\ud835\udc44\ud835\udc56Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents an atomic reasoning state derived through DAG decomposition and contraction from its predecessor. The right portion demonstrates AoT\u2019s integration capability with existing test-time scaling methods (e.g., CoT, ToT). A key feature of this integration is that any intermediate state Qisubscript\ud835\udc44\ud835\udc56Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT from our Markov process can serve as an entry point (Q0subscript\ud835\udc440Q_{0}italic_Q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) for other methods, enabling flexible composition while maintaining answer equivalence with the original question. This design allows AoT to function both as a standalone iterative framework and as a preprocessing module that can enhance existing approaches through structural optimization.", "description": "Figure 2 illustrates the Atom of Thoughts (AoT) framework. The left side shows how AoT uses a Markov process, where each state represents a simplified sub-problem (atomic question) derived from the previous state through a decomposition and contraction process. This process continues until the problem is broken down into easily solvable atomic questions. The right side shows that AoT can be integrated with existing test-time scaling methods (like Chain of Thoughts and Tree of Thoughts).  Any intermediate state in AoT's Markov process can be used as a starting point for other methods, allowing for flexible combination while ensuring the final answer remains consistent. AoT is designed to be used either as a stand-alone framework or as a pre-processing module to improve the reasoning capability of other methods.", "section": "3 An Overview of AOT"}, {"figure_path": "https://arxiv.org/html/2502.12018/x3.png", "caption": "Figure 3: Performance scaling with transition times on MATH dataset. Darker blue indicates larger sample sizes at shallower depths, as most problems are solved with fewer decomposition steps.", "description": "This figure illustrates how the performance of the Atom of Thoughts (AOT) model scales with the number of reasoning steps (depth) on the MATH dataset.  The x-axis represents the depth of the reasoning process, and the y-axis shows the model's accuracy.  The color intensity (darker blue) corresponds to the number of data points at each depth; darker shades indicate a larger number of problems solved at that depth. The graph demonstrates that while performance continues to improve with more reasoning steps, a significant portion of problems can be solved efficiently with relatively few steps, highlighting the efficiency of AOT.", "section": "5.2 Experimental Results and Analysis"}, {"figure_path": "https://arxiv.org/html/2502.12018/x4.png", "caption": "Figure 4: Performance comparison on MATH dataset showing computational efficiency. The green line shows FoT scaling with varying tree numbers (2k,k=0,1,2,\u2026formulae-sequencesuperscript2\ud835\udc58\ud835\udc58012\u20262^{k},k=0,1,2,...2 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , italic_k = 0 , 1 , 2 , \u2026), while the gray trend line (representing other baseline methods) together demonstrate the trade-off between performance gains and computational costs. AoT (d\ud835\udc51ditalic_d=1) combined with FoT(n\ud835\udc5bnitalic_n=2) achieves slightly better performance to standalone FoT(n\ud835\udc5bnitalic_n=8) while requiring substantially less computation.", "description": "Figure 4 illustrates the computational efficiency of Atom of Thoughts (AOT) in comparison to other reasoning methods on the MATH dataset. The x-axis represents the computational cost (log scale), and the y-axis represents the accuracy. The green line shows the performance of the Forest of Thoughts (FoT) method with varying numbers of trees (2^k, where k = 0, 1, 2...). The gray trend line represents the performance of other baseline methods. The figure demonstrates that AOT, when combined with FoT, achieves slightly better accuracy than FoT alone while using significantly less computation.", "section": "5 Experiments"}, {"figure_path": "https://arxiv.org/html/2502.12018/x5.png", "caption": "Figure 5: Distribution of solution depths across questions. Darker orange bars indicate depths that appear more frequently in the dataset.", "description": "This figure displays a histogram showing the frequency distribution of solution depths across a set of questions. The x-axis represents the depth of the solution, and the y-axis represents the number of questions with that solution depth. Darker shades of orange indicate that a particular depth occurred more frequently in the dataset.", "section": "Analysis of structural diversity"}, {"figure_path": "https://arxiv.org/html/2502.12018/x6.png", "caption": "Figure 6: Distribution of subquestion counts across questions. Darker green bars represent more common subquestion counts in the solutions.", "description": "This bar chart visualizes the frequency distribution of the number of subquestions generated during the decomposition phase of the Atom of Thoughts (AOT) framework,  for each question in the MATH dataset. The x-axis represents the count of subquestions, and the y-axis shows the number of questions resulting in that specific subquestion count. The darker the green color of a bar, the more frequently that particular subquestion count appears in the solutions.", "section": "Analysis of structural diversity"}, {"figure_path": "https://arxiv.org/html/2502.12018/x7.png", "caption": "Figure 7: Number of subquestions vs accuracy. Color intensity (green) reflects data density - darker points represent more frequent patterns.", "description": "This figure illustrates the relationship between the number of subquestions generated during the decomposition phase of the Atom of Thoughts (AOT) framework and the accuracy of the final answers.  The x-axis represents the number of subquestions, and the y-axis represents the accuracy. Each point represents a question from the dataset. The color intensity of the points indicates the frequency of occurrence of that particular combination of subquestion count and accuracy; darker points signify more frequent patterns in the data. This visualization helps in understanding how the complexity of question decomposition, as measured by the number of subquestions, affects the overall accuracy of the AOT framework.", "section": "A Analysis of structural diversity"}, {"figure_path": "https://arxiv.org/html/2502.12018/x8.png", "caption": "Figure 8: Solution depth vs accuracy. Color intensity (orange) reflects data density - darker points represent more frequent patterns.", "description": "Figure 8 visualizes the correlation between the depth of the solution graph (number of reasoning steps) and the accuracy of the solution.  The x-axis represents the solution depth, while the y-axis shows the accuracy. The color intensity of the data points indicates data density; darker points represent more frequently observed combinations of depth and accuracy. The figure reveals a trend of decreasing accuracy as the depth increases, suggesting that more complex reasoning processes (deeper graphs) are more prone to errors.", "section": "Analysis of structural diversity"}]