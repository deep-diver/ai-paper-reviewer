{"references": [{" publication_date": "2023", "fullname_first_author": "Maksym Bekuzarov", "paper_title": "Xmem++: Production-level video segmentation from few annotated frames", "reason": "This paper is highly relevant because it directly addresses the challenge of video segmentation from limited annotations, a central theme of the target paper.  The focus on production-level video segmentation aligns with the target paper's emphasis on practical applications, such as VFX production.  Comparing the methods and results with XMem++ provides a benchmark for evaluating the performance of the proposed model.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Aliasghar Khani", "paper_title": "Slime: Segment like me", "reason": "This paper is highly relevant as it introduces the concept of flexible granularity segmentation and WAS maps, which are directly adopted and extended in the target paper's methodology.  The use of WAS maps for achieving high quality segmentation is significant.  The authors address similar challenges in flexible granularity image segmentation, forming the base of the proposed approach in the target paper.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "reason": "This paper introduces SAM, a foundation model for open-vocabulary part segmentation, highly relevant to the target paper's focus on flexible granularity segmentation.  The ability of SAM to segment parts without explicit text descriptions is a key advancement that influenced the target paper's approach, moving beyond the limitations of solely text-based methods in open-vocabulary part segmentation.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Tianhe Ren", "paper_title": "Grounded sam: Assembling open-world models for diverse visual tasks", "reason": "This paper builds upon the SAM model, introducing Grounded SAM, which extends the capabilities to video data.  This is directly relevant to the target paper's work on video segmentation.  The ability of Grounded SAM to adapt to videos further motivates the work of the target paper by suggesting a framework for generalizing the methodology from images to videos.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "reason": "This foundational paper introduces the concept of denoising diffusion probabilistic models, a core technology underlying the target paper's use of latent diffusion models for video segmentation.  The understanding of diffusion models is essential to grasping the mechanism of generating segmentation masks in the target paper.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "reason": "This work is highly relevant because it details the architecture and training of Latent Diffusion Models (LDMs), which serve as the foundation for the target paper's method.  The target paper leverages the LDM framework, modifying it for video processing, and the knowledge of LDMs is essential for understanding the proposed methodology.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Qian Wang", "paper_title": "Zero-shot video semantic segmentation based on pre-trained diffusion models", "reason": "This paper explores zero-shot video semantic segmentation using pre-trained diffusion models. The approach is similar in spirit to the target paper, however, this paper directly uses the video data for segmentation whereas the target paper employs a reference image based approach which is more efficient and scalable.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Nikita Karaev", "paper_title": "Cotracker: It is better to track together", "reason": "This paper introduces the CoTracker algorithm, which is directly utilized in the target paper's tracking module for temporal consistency.  The choice of CoTracker for the tracking task is essential as it is an efficient and robust method for tracking points in videos. Understanding CoTracker is vital to comprehending the target paper's approach to maintaining temporal coherence in segmentations.", "section_number": 4}, {" publication_date": "2015", "fullname_first_author": "Olaf Ronneberger", "paper_title": "U-net: Convolutional networks for biomedical image segmentation", "reason": "This paper is highly relevant as it introduces the U-Net architecture which is modified to handle video data in the target paper.  The U-Net architecture is the backbone of the latent diffusion model and serves as the basis for the modifications made in the inflated U-Net of the target paper's methodology. The familiarity with U-Net is vital for understanding the architecture of the target paper.", "section_number": 3}, {" publication_date": "2022", "fullname_first_author": "Guillaume Le Moing", "paper_title": "Ccvs: context-aware controllable video synthesis", "reason": "While not directly related to segmentation, this paper provides insights into video generation using diffusion models. The target paper builds upon video generation techniques, adapting them to the video segmentation task and applying temporal consistency.  The knowledge of video generation methods is necessary for understanding the target paper's approach to handling temporal information in video data.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "reason": "This paper is fundamental as it showcases the capabilities of text-to-image diffusion models, which are a crucial component of the target paper.   The target paper builds upon these techniques, extending them to handle video data for flexible granularity segmentation.  Understanding text-to-image generation is crucial for comprehending the target paper's approach and the way it incorporates text embeddings to guide the segmentation process.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Zhenqi Dai", "paper_title": "One-shot in-context part segmentation", "reason": "This paper is relevant to the target paper as it explores one-shot part segmentation. The goal of one-shot segmentation aligns with the target paper's ambition of reducing annotation burden, moving towards flexible granularity segmentation.   The techniques and findings presented in this paper serve as a comparison point for evaluating the efficiency of the target paper's method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Shoufa Chen", "paper_title": "Gentron: Delving deep into diffusion transformers for image and video generation", "reason": "This paper explores video generation using diffusion transformers.  The target paper is also based on diffusion models but focuses on segmentation.  The insights on video generation techniques from this paper help to understand the background and challenges in applying such techniques for flexible granularity video segmentation.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "reason": "This paper is highly relevant to the target paper's use of latent diffusion models for video segmentation. This work shows how to use latent diffusion models for high-resolution video synthesis, while the target paper applies similar approaches to video segmentation. Understanding the details of latent diffusion models is crucial for grasping the target paper's approach.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Dmitry Baranchuk", "paper_title": "Label-efficient semantic segmentation with diffusion models", "reason": "This paper focuses on label-efficient semantic segmentation using diffusion models, which is a related topic to the target paper's work on video segmentation. The efficiency aspect is important, aligning with the target paper's goal of reducing annotation burden. The techniques and results are useful for comparison and provide insights into the potential of diffusion models for label-efficient video segmentation.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "reason": "This paper presents a highly impactful model for photorealistic text-to-image generation using diffusion models, which forms the basis of many subsequent works, including the target paper.  The target paper leverages the advances in text-to-image diffusion models for achieving flexible granularity video segmentation. The techniques and achievements in this work are essential to the target paper's approach.", "section_number": 3}, {" publication_date": "2017", "fullname_first_author": "Liang-Chieh Chen", "paper_title": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "reason": "This paper is a foundational work in semantic image segmentation which is highly relevant as video segmentation methods often build upon image segmentation techniques.  The DeepLab model's architecture and methods form a basis for understanding subsequent advancements in semantic segmentation, including the work presented in the target paper.  The target paper extends similar concepts to videos with the challenge of flexible granularity.", "section_number": 2}, {" publication_date": "2016", "fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "reason": "While focused on image recognition, this paper introduces the ResNet architecture, which is a fundamental building block in many computer vision models, including those used in the target paper's approach.  The ResNet architecture provides a backbone for the deep learning models and understanding its contribution is crucial for analyzing the performance of the target paper's method.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Hengshuang Zhao", "paper_title": "Pyramid scene parsing network", "reason": "This paper introduces the Pyramid Scene Parsing Network (PSPNet), which is relevant as it is a widely used architecture for semantic segmentation. While this paper does not directly focus on video segmentation, its architectural design and techniques have influenced many subsequent works in semantic segmentation, including the target paper's inflated U-Net architecture.  Understanding PSPNet is helpful for grasping the evolution and advancement of segmentation techniques in general.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Xizhou Zhu", "paper_title": "Deep feature flow for video recognition", "reason": "This paper is significant as it focuses on video recognition and it's highly relevant as it shows how to use feature flow which is vital for understanding the motion and temporal consistency in videos.  The target paper addresses the challenge of temporal consistency in video segmentation, and understanding methods for handling temporal dynamics in videos is critical for achieving accurate and temporally coherent segmentation.", "section_number": 2}]}