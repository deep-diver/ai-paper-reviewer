{"reason": "Long Video Understanding is challenging due to the context limitations of LLMs. This paper introduces LongVU, a spatiotemporal adaptive compression method that efficiently processes long videos by leveraging cross-modal queries and inter-frame dependencies.  LongVU reduces the number of video tokens while preserving visual details, leading to state-of-the-art video understanding performance across various benchmarks, particularly in hour-long video tasks. The method scales effectively to smaller LLMs, suggesting practicality and broader accessibility.", "takeaways": ["LongVU, a novel spatiotemporal adaptive compression mechanism, efficiently processes long videos for LLMs by intelligently reducing the number of video tokens while preserving visual details.", "LongVU consistently outperforms existing methods across various video understanding benchmarks, especially on hour-long video tasks, demonstrating its effectiveness and efficiency.", "LongVU scales effectively to smaller LLMs, suggesting its practicality and potential for broader use in video understanding applications."], "tldr": "Long video understanding is limited by LLM context size. LongVU, a novel spatiotemporal adaptive compression method, addresses this by reducing video tokens while preserving visual details using cross-modal queries and inter-frame dependencies.  LongVU surpasses existing methods on various video understanding benchmarks, especially hour-long ones, and scales effectively to smaller LLMs."}