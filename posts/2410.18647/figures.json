[{"figure_path": "2410.18647/figures/figures_2_0.png", "caption": "Figure 1: Illustrations of all tasks. We derive the data scaling laws through extensive experiments on Pour Water and Mouse Arrangement, and further validate these findings on additional tasks, including Fold Towels and Unplug Charger.", "description": "The figure displays four images showing a robotic arm interacting with different objects in diverse environments for four different manipulation tasks.  The top left image shows the task of pouring water from a bottle into a mug; the top right shows the task of arranging a computer mouse on a mouse pad; the bottom left shows the task of folding a towel; and the bottom right shows the task of unplugging a charger from a power strip. Each image shows the robot arm's gripper near the object involved in the specific task, illustrating the variety of environments and object types encountered in the experiments.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18647/figures/figures_16_0.png", "caption": "Figure 12: Testing environments. These 8 environments are not included in the training data and are used across all tasks.", "description": "This figure shows 16 images of 8 different unseen testing environments. Each environment contains various objects in different settings.  The images appear to be from a fisheye camera, giving a wide-angle view of each scene. These environments are used for testing the generalization capability of the robot policies trained across all four tasks (Pour Water, Mouse Arrangement, Fold Towels, and Unplug Charger). The environments are not included in the data used to train the robot policies.", "section": "A ENVIRONMENT AND OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_16_1.png", "caption": "Figure 8: Training environments for Pour Water. We sample 12 environments from our collected training data. See Appendix D.1 for task details.", "description": "The figure shows 12 images, each depicting a different environment used to collect training data for the Pour Water task.  Each image appears to be a fisheye lens view of a table or desk area, with varying backgrounds and levels of clutter.  The consistent element is the presence of a purplish-pink coaster. The variability in lighting, objects present in the background, table surfaces, and overall arrangement are intended to demonstrate the diversity of the training environments and the robot's ability to generalize to unseen settings.", "section": "A.1 ENVIRONMENT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_17_0.png", "caption": "Figure 8: Training environments for Pour Water. We sample 12 environments from our collected training data. See Appendix D.1 for task details.", "description": "The figure shows twelve 360-degree fisheye images depicting the training environments used for the Pour Water task. Each image showcases a distinct indoor setting, featuring various backgrounds, lighting conditions, and the presence of distractor objects.  The environments vary, including office spaces, living rooms, and libraries. A magenta colored triangle is visible in the bottom-right corner of each image, seemingly marking a consistent point of interest.", "section": "A.1 Environment Visualizations"}, {"figure_path": "2410.18647/figures/figures_17_1.png", "caption": "Figure 12: Testing environments. These 8 environments are not included in the training data and are used across all tasks.", "description": "The figure shows 16 images arranged in a 4x4 grid. Each image is a fisheye view of a different indoor environment. These scenes are diverse, with varying furniture, lighting, and clutter. The environments are intended for testing the generalization capabilities of robot manipulation policies trained on data from different environments.  A small purple triangle is visible in the lower right corner of each image.", "section": "A ENVIRONMENT AND OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_17_2.png", "caption": "Figure 8: Training environments for Pour Water. We sample 12 environments from our collected training data. See Appendix D.1 for task details.", "description": "The figure shows twelve 360\u00b0 fisheye images, each depicting a different environment used for training a robot to pour water. The environments vary in terms of background, lighting, and the presence of distractor objects on the table.  Each scene features a table with a bottle of water, a mug, and a red coaster. The arrangement of the objects varies slightly in each image, illustrating the diversity of training settings.", "section": "A.1 ENVIRONMENT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_18_0.png", "caption": "Objects for Pour Water. All of our experiments include a total of 64 training bottles and mugs, as well as 16 unseen testing bottles and mugs.", "description": "The figure shows a total of 80 images, divided into two parts: training objects and testing objects. The training objects section contains 64 images of various bottles and mugs, showcasing a wide variety of shapes, sizes, colors, and patterns. Each image displays a single bottle and mug.  The testing objects section displays 16 similar images, featuring unseen bottles and mugs, and maintaining the same style and composition as the training set.", "section": "A.2 OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_19_0.png", "caption": "Objects for Mouse Arrangement. All of our experiments include a total of 64 training mice and mouse pads, as well as 16 unseen testing mice and mouse pads.", "description": "The figure shows a total of 80 images of mouses and mouse pads. The top half shows 64 images of training objects, while the bottom half shows 16 unseen testing objects. Each image shows a mouse pad with a mouse on it. The mouse pads and mouses vary in color, shape, and design. There is a variety of designs from simple to elaborate. The arrangement of the objects is in a grid format. The figure is well-organized and easy to understand.", "section": "A.2 OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_20_0.png", "caption": "Objects for Fold Towels. All of our experiments include a total of 32 training towels, as well as 16 unseen testing towels.", "description": "The figure shows a total of 48 towels, divided into two sets: training and testing.  The training set consists of 32 towels with varying colors, patterns, textures, and sizes, laid out in a grid.  Below the training set is the testing set of 16 towels, similarly arranged. The testing towels have different visual features than the training towels to evaluate the generalization ability of the model trained on the training set.", "section": "A.2 OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_21_0.png", "caption": "Objects for Unplug Charger. All of our experiments include a total of 32 training chargers and power strips, as well as 16 unseen testing chargers and power strips.", "description": "The figure shows a total of 48 images divided into two sections: \"Training Objects\" and \"Testing Objects\".  The \"Training Objects\" section displays 32 different chargers and power strips used for training the robot policy, showcasing a variety of colors, shapes, sizes, and configurations. The \"Testing Objects\" section shows 16 different unseen chargers and power strips used for testing the generalization capabilities of the trained policy; these also demonstrate considerable diversity in their designs.", "section": "A.2 OBJECT VISUALIZATIONS"}, {"figure_path": "2410.18647/figures/figures_29_0.png", "caption": "Figure 18: UMI hand-held grippers. We do not install side mirrors on the grippers.", "description": "The figure shows four UMI (Universal Manipulation Interface) hand-held grippers arranged in a row against a white background. Each gripper consists of a white body with purple soft fingers and a black GoPro Hero 10 camera mounted on top.  The grippers are designed for data collection in robotic manipulation tasks, and the cameras provide visual data for policy learning.", "section": "F Hardware Setup"}, {"figure_path": "2410.18647/figures/figures_29_1.png", "caption": "Figure 19: Deployment hardware setup.", "description": "The figure shows the hardware setup used for the robotic manipulation experiments.  A Franka Emika Panda robot arm with a Weiss WSG-50 gripper (modified with a 90-degree rotation adapter and soft fingers) is mounted on a movable lifting table. A GoPro Hero 10 camera is attached to the gripper for vision.  The system is powered by a mobile power supply (EcoFlow DELTA 2 Max) and connected to a workstation for policy inference. The setup allows for testing in various real-world environments.", "section": "F Hardware Setup"}]