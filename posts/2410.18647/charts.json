[{"figure_path": "2410.18647/charts/charts_6_0.png", "caption": "Figure 2: Object generalization. Each curve corresponds to a different fraction of demonstrations used, with normalized scores shown as a function of the number of training objects.", "description": "This figure shows the results of object generalization experiments for two robotic manipulation tasks, Pour Water and Mouse Arrangement.  The horizontal axis represents the number of training objects, while the vertical axis represents the normalized score, a measure of the policy's performance on unseen objects. Separate curves are shown for different fractions of the total available demonstrations used during training (3.125%, 6.25%, 12.5%, 25%, 50%, 100%).  The chart illustrates how performance on unseen objects improves as the number of training objects increases and how this improvement is further enhanced when more training data is used. ", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/charts/charts_6_1.png", "caption": "Figure 3: Environment generalization. Each curve corresponds to a different fraction of demonstrations used, with normalized scores shown as a function of the number of training environments.", "description": "This chart displays the results of an experiment investigating environment generalization in robotic manipulation.  It shows how the normalized success score of a robot policy varies with the number of training environments, while controlling for the fraction of training demonstrations used. Two different tasks, Pour Water and Mouse Arrangement are presented.  Each curve represents a different fraction of demonstrations (from 3.125% to 100%), illustrating how the number of demonstrations impacts generalization performance.  The x-axis represents the number of training environments (1, 2, 4, 8, 16, 32), and the y-axis represents the normalized success score (0-1). The chart indicates that increasing the number of training environments improves generalization performance, particularly when a larger fraction of training demonstrations is available.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/charts/charts_7_0.png", "caption": "Generlization across environments and objects. Each curve corresponds to a different fraction of demonstrations used, with normalized scores shown as a function of the number of training environment-object pairs.", "description": "This chart displays the results of an experiment evaluating the generalization performance of a robotic manipulation policy across both unseen environments and objects.  The x-axis represents the number of training environment-object pairs, while the y-axis shows the normalized score achieved by the policy on unseen environment-object pairs.  Multiple curves are plotted, each representing a different fraction of the total available demonstrations used for training (3.125%, 6.25%, 12.5%, 25%, 50%, and 100%). The chart shows that increasing the number of training environment-object pairs leads to better generalization performance, and that the diversity of the training data is more important than the absolute number of demonstrations.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/charts/charts_7_1.png", "caption": "Power-law relationship. Dashed lines represent power-law fits, with the equations provided in the legend. All axes are shown on a logarithmic scale. The correlation coefficient r indicates a power-law relationship between the policy generalization ability and the number of objects, environments, and environment-object pairs. See Appendix G.1 for data scaling laws on MSE.", "description": "This chart visually represents the power-law relationships observed between the policy's generalization ability and the number of training objects, environments, or environment-object pairs. It displays separate plots for each of the two tasks (Pour Water and Mouse Arrangement), with each plot showing three subplots. These subplots represent object generalization (x-axis: number of training objects), environment generalization (x-axis: number of training environments), and generalization across both environments and objects (x-axis: number of training environment-object pairs). The y-axis in all subplots represents the optimality gap, displayed on a logarithmic scale, indicating the difference between the maximum possible score (1) and the actual normalized score.  Dashed lines depict the power-law fits for each relationship, along with their corresponding equations and correlation coefficients (r). The correlation coefficients highlight the strength of the power-law relationship for each scenario. ", "section": "4.2 POWER-LAW FITTING AND QUANTITATIVE ANALYSIS"}, {"figure_path": "2410.18647/charts/charts_8_0.png", "caption": "Multiple objects per environment. Brighter colors indicate higher normalized scores.", "description": "This heatmap visualizes the impact of varying the number of environments (M) and the number of objects per environment (N/M) on the policy's performance for two manipulation tasks, Pour Water and Mouse Arrangement.  Each cell in the heatmap represents the average normalized score achieved across a number of trials, with darker colors indicating lower performance and lighter colors indicating higher performance. The x-axis represents the number of environments, while the y-axis shows the number of objects per environment, allowing for analysis of how different combinations of M and N/M affect the policy's generalization ability in unseen environments and objects.  The results reveal that performance generally increases with increasing numbers of environments and objects, suggesting a relationship between data diversity and policy generalization.", "section": "4.3 EFFICIENT DATA COLLECTION STRATEGY"}, {"figure_path": "2410.18647/charts/charts_9_0.png", "caption": "Figure 7: Number of demonstrations. Left: In the setting where we collect the maximum number of demonstrations, we examine whether the policy's performance follows a power-law relationship with the total number of demonstrations. The correlation coefficients for Pour Water and Mouse Arrangement are -0.62 and -0.79, respectively, suggesting only a weak power-law relationship. Right: For varying environment-object pairs, the policy performance increases with the total number of demonstrations at first, and then reaches saturation.", "description": "This figure displays two sets of line graphs showing the relationship between the number of demonstrations and the normalized score achieved in two robotic manipulation tasks: Pour Water and Mouse Arrangement. The left panel shows that when the maximum number of demonstrations is used, there is a weak power-law relationship between the number of demonstrations and the normalized score.  The right panel shows the normalized score for different numbers of training environment-object pairs, demonstrating that performance improves initially with increasing numbers of demonstrations before reaching saturation.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}, {"figure_path": "2410.18647/charts/charts_27_0.png", "caption": "Comparison between normalized score and MSE. Left: In the object generalization experiment, the inverse correlation between MSE and normalized score is weak. Right: In the generalization experiment across both environments and objects, the inverse correlation between MSE and normalized score is very strong. Correlation coefficients (Pearson's r and Spearman's \u03c1) are shown in the bottom right.", "description": "This chart compares two evaluation metrics, Normalized Score and MSE, across different numbers of training objects (left panel) and training environment-object pairs (right panel) for the Pour Water task.  The left panel shows a weak negative correlation between MSE and Normalized Score during object generalization, while the right panel demonstrates a strong negative correlation between the metrics during generalization across both environments and objects, indicating that MSE might be a more reliable metric in the latter scenario but less so in the former.  Correlation coefficients (Pearson's r and Spearman's \u03c1) are provided to quantify the strength of these correlations.", "section": "E.1 Comparison of Evaluation Metrics"}, {"figure_path": "2410.18647/charts/charts_30_0.png", "caption": "Figure 20: Data scaling laws on MSE. Dashed lines represent power-law fits, with the equations provided in the legend. All axes are shown on a logarithmic scale.", "description": "This chart visualizes the relationship between mean squared error (MSE) and the number of training objects, environments, or environment-object pairs for two manipulation tasks: Pour Water and Mouse Arrangement.  It presents three subplots for each task, showing MSE plotted against the number of training objects, training environments, and training environment-object pairs respectively. Each subplot includes a dashed line representing a power-law fit, along with the equation of the fit and its correlation coefficient (r). The x-axis is shown on a logarithmic scale, representing the number of training items, while the y-axis is also logarithmic, showing the MSE.  The charts aim to demonstrate the scaling laws for MSE (a different evaluation metric than primarily used in the paper) in order to see if similar power-law relationships hold. ", "section": "G.1 Data Scaling Laws on MSE"}, {"figure_path": "2410.18647/charts/charts_31_0.png", "caption": "Figure 21: Object generalization. Each curve corresponds to a different total numbers of demonstrations used, with normalized scores shown as a function of the number of training objects.", "description": "This chart displays the results of an experiment on object generalization in robotic manipulation.  It shows the relationship between the number of training objects and the normalized score achieved by a policy, while keeping the total number of demonstrations relatively consistent across different data usage levels (2x, 4x, 8x, 16x, 32x). The chart presents two subplots, one for the \"Pour Water\" task and another for the \"Mouse Arrangement\" task.  Each subplot features multiple lines representing different total numbers of demonstrations, demonstrating how performance on unseen objects changes with the number of training objects and the total number of training demonstrations.", "section": "G.2 KEEPING THE TOTAL NUMBER OF DEMONSTRATIONS CONSTANT"}, {"figure_path": "2410.18647/charts/charts_31_1.png", "caption": "Figure 22: Environment generalization. Each curve corresponds to a different total numbers of demonstrations used, with normalized scores shown as a function of the number of training environments.", "description": "This chart displays the results of an experiment on environment generalization in robotic manipulation.  It shows how a policy's normalized score (a measure of success) changes as the number of training environments increases, while keeping the total number of demonstrations relatively constant across different conditions.  Two separate charts present results for Pour Water and Mouse Arrangement tasks.  Within each chart, multiple lines represent different amounts of data used for training (2x, 4x, 8x, 16x, 32x), demonstrating how performance changes with increasing training data and number of environments. The x-axis represents the number of training environments, and the y-axis represents the normalized score.", "section": "G.2 KEEPING THE TOTAL NUMBER OF DEMONSTRATIONS CONSTANT"}, {"figure_path": "2410.18647/charts/charts_31_2.png", "caption": "Generalization across environments and objects. Each curve corresponds to a different fraction of demonstrations used, with normalized scores shown as a function of the number of training environment-object pairs.", "description": "This chart visualizes the results of an experiment investigating how the number of training environment-object pairs affects a robot's policy generalization ability to new environments and objects. The horizontal axis represents the number of training environment-object pairs (1,2,4,8,16,32), while the vertical axis represents the normalized score achieved by the robot policy on unseen environment-object pairs. Each line on the chart represents a different fraction of the collected demonstration data used for training the robot policy (3.125%, 6.25%, 12.5%, 25%, 50%, 100%).  The chart shows that as the number of training environment-object pairs increases, the robot policy's performance in novel situations improves, with higher percentages of training data leading to better results.  The lines show diminishing returns as the fraction of demonstrations increase, and almost overlap at 100%, suggesting that once a threshold of training data is reached, additional data does not greatly improve performance.", "section": "4.1 RESULTS AND QUALITATIVE ANALYSIS"}]