[{"figure_path": "2410.17883/tables/table_7_0.md", "caption": "Comparison of models in terms of average inference time and overall accuracy on the AitW and AndroidControl datasets. The table presents the size of each model, the average inference time (in seconds, lower is better), and the overall accuracy (higher is better) for both datasets.", "description": "This table compares the performance of several models on two mobile app control datasets: AitW and AndroidControl.  For each model, it lists the model size, average inference time in seconds (lower is better indicating faster processing), and the overall accuracy (higher is better representing better performance) on both datasets.  The models include baseline approaches using prompt engineering with GPT-4 (SeeActchoice, SeeActann, T3A, M3A), and fine-tuned Vision Language Models (VLMs) such as Florence2 and Qwen2-VL, both with and without the proposed LiMAC architecture.  The table allows for a comparison of the speed and accuracy of different methods, highlighting the performance improvements achieved with the LiMAC framework.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.17883/tables/table_8_0.md", "caption": "Comparison of models in terms of average inference time and overall accuracy on the AitW and AndroidControl datasets. The table presents the size of each model, the average inference time (in seconds, lower is better), and the overall accuracy (higher is better) for both datasets.", "description": "This table compares the performance of different models on two datasets, AitW and AndroidControl, in terms of average inference time and overall accuracy.  It lists several models including SeeActchoice, SeeActann, T3A, M3A, Florence2, and Qwen2-VL, along with LiMAC variants using these models. For each model, the table shows the model size (in parameters), the average inference time in seconds (lower is better), and the overall accuracy on both datasets (higher is better).  The table highlights that LiMAC consistently outperforms other models, achieving a higher overall accuracy and faster inference times.", "section": "4.1 Experimental Setup"}, {"figure_path": "2410.17883/tables/table_9_0.md", "caption": "Comparison of models in terms of average inference time and overall accuracy on the AitW and AndroidControl datasets. The table presents the size of each model, the average inference time (in seconds, lower is better), and the overall accuracy (higher is better) for both datasets.", "description": "The table compares various models for mobile app control on two datasets: AitW and AndroidControl. For each model, it lists the model size, average inference time in seconds, and overall accuracy on both datasets.  The models include several baseline methods (SeeActchoice, SeeActann, T3A, M3A) and Vision Language Models (VLMs) such as Florence2 and Qwen2-VL, both with and without integration into the LiMAC architecture (indicated as \"ours\").  The table shows the performance improvements achieved by the proposed LiMAC approach, demonstrating shorter inference times and higher accuracy compared to baseline models.", "section": "4.1 Experimental Setup"}, {"figure_path": "2410.17883/tables/table_9_1.md", "caption": "Table 1: Comparison of models in terms of average inference time and overall accuracy on the AitW and AndroidControl datasets. The table presents the size of each model, the average inference time (in seconds, lower is better), and the overall accuracy (higher is better) for both datasets.", "description": "This table compares the performance of several models on two mobile phone control datasets, AitW and AndroidControl.  For each model, it shows the model size (in parameters), average inference time in seconds (lower is better), and overall accuracy (higher is better) for each dataset. The models compared include various baselines using prompt engineering with GPT-4, fine-tuned versions of open-source vision-language models (Florence2 and Qwen2-VL), and the proposed LiMAC architecture with both Florence2 and Qwen2-VL.  The table highlights LiMAC's improved inference time and accuracy compared to the baselines.", "section": "4.1 EXPERIMENTAL SETUP"}]