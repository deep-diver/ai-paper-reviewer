{"references": [{" publication_date": "2023", "fullname_first_author": "Rohan Anil", "paper_title": "Palm 2 technical report", "reason": "This paper is crucial because it introduces PaLM 2, a large language model used as a baseline for comparison in the paper's experiments.  Understanding PaLM 2's capabilities and limitations is essential for evaluating the performance of LiMAC, the model introduced in the paper.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Hao Bai", "paper_title": "Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning", "reason": "This paper presents DigiRL, a reinforcement learning-based approach for training device control agents. It serves as a key comparison point for LiMAC, highlighting the trade-offs between different training paradigms and their effects on the performance and efficiency of mobile app control agents.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "reason": "This paper introduces Qwen-VL, a vision-language model used in LiMAC. Understanding Qwen-VL's architecture and capabilities is vital for evaluating the effectiveness of LiMAC, especially since Qwen-VL is one of the core components within LiMAC.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "reason": "This paper is important because it introduces Decision Transformer, a sequence modeling approach applied in reinforcement learning. This technique is relevant to understanding how LiMAC models sequential interactions within the mobile app environment.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Xiang Deng", "paper_title": "Mind2web: Towards a generalist agent for the web", "reason": "This paper introduces Mind2Web, a general-purpose web agent.  Understanding the capabilities and limitations of Mind2Web provides context for evaluating LiMAC, helping to clarify the relative advancements and limitations of the techniques used in both systems.", "section_number": 5}, {" publication_date": "2018", "fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "reason": "This paper introduces BERT, a crucial pre-trained language model. BERT's embeddings are used within LiMAC, and understanding BERT's impact on the performance of LiMAC is essential to a complete understanding of the architecture and experimental results.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Izzeddin Gur", "paper_title": "A real-world webagent with planning, long context understanding, and program synthesis", "reason": "This paper is significant for highlighting the capabilities and complexity of real-world web agents. It provides a contrast and comparison with LiMAC, helping to emphasize LiMAC's relative efficiency and focus on resource-constrained mobile environments.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Wenyi Hong", "paper_title": "Cogagent: A visual language model for gui agents", "reason": "CogAgent is a similar mobile app control agent based on a visual language model.  This paper provides a comparative analysis point to LiMAC, highlighting the differences in model architecture, efficiency, and performance.", "section_number": 5}, {" publication_date": "2021", "fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "reason": "This paper describes LoRA, a technique used for efficient fine-tuning of large language models. LiMAC utilizes LoRA for fine-tuning its vision-language model, so understanding this technique is critical to understanding how LiMAC achieves efficiency and accuracy.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Wei Li", "paper_title": "On the effects of data scale on computer control agents", "reason": "This paper is highly relevant because it directly addresses the impact of dataset size on the performance of computer control agents. Understanding this effect is critical for assessing LiMAC's performance, especially given the use of different datasets with varying scales.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "Evan Zheran Liu", "paper_title": "Reinforcement learning on web interfaces using workflow-guided exploration", "reason": "This paper is important for its focus on reinforcement learning in the context of web interface control. The techniques discussed are relevant to understanding LiMAC's approach to learning and interacting with mobile application user interfaces.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ilya Loshchilov", "paper_title": "Fixing weight decay regularization in adam", "reason": "This paper is significant because it addresses AdamW, the optimization algorithm employed in the training of LiMAC. This technical detail directly impacts the performance of LiMAC, making this paper crucial to understanding the model's training process and results.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "reason": "This paper is foundational because it details the CLIP model, which is used extensively within LiMAC.  Understanding CLIP's capabilities and limitations is critical for evaluating LiMAC's overall performance and understanding the contributions of different modules within the framework.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidinthewild: A large-scale dataset for android device control", "reason": "This paper introduces the Android-in-the-Wild dataset, one of the key datasets used to evaluate LiMAC.  The characteristics of this dataset, including its size and the need for OCR processing, are critical for understanding the results and generalizability of LiMAC's performance.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Christopher Rawles", "paper_title": "Androidworld: A dynamic benchmarking environment for autonomous agents", "reason": "This paper presents a dynamic benchmarking environment that is used to assess LiMAC's performance against other similar models.  It is crucial for understanding how LiMAC performs in comparison to the state-of-the-art and identifying its relative strengths and weaknesses.", "section_number": 5}, {" publication_date": "2017", "fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "reason": "This is highly influential because it introduces the Transformer architecture. This is the foundation of LiMAC's Action Transformer (AcT), so understanding its principles is vital to understanding LiMAC's design and performance.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration", "reason": "This paper introduces Mobile-Agent-V2, another mobile device control agent.  Comparing LiMAC against this agent, specifically noting performance differences, is important for highlighting LiMAC's improvements in accuracy and efficiency.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception", "reason": "This paper introduces Mobile-Agent, an earlier version of the agent described in the previous citation. Including this paper allows for a temporal comparison, assessing how improvements in Mobile-Agent-V2 relate to the advances made by LiMAC.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Bin Xiao", "paper_title": "Florence-2: Advancing a unified representation for a variety of vision tasks", "reason": "This paper introduces Florence-2, a key vision language model. LiMAC leverages Florence-2 in its architecture, and understanding the capabilities of Florence-2 is therefore essential for grasping the design and performance of LiMAC.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Zhao Yang", "paper_title": "Appagent: Multimodal agents as smartphone users", "reason": "This paper is important because it introduces Appagent, a multimodal agent for smartphone control.  Comparing the architectures and performance of LiMAC and Appagent helps provide context and insight into the relative advancements and contributions made by each approach.", "section_number": 5}]}