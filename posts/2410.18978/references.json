{"references": [{" publication_date": "2023", "fullname_first_author": "Alyaa Aloraibi", "paper_title": "Image morphing techniques: A review", "reason": "This paper provides a comprehensive overview of image morphing techniques, a closely related field to video frame interpolation.  Understanding various image morphing techniques is essential for developing effective frame interpolation methods, especially those that involve significant changes in object appearance or shape between frames.  The review provides background knowledge necessary for evaluating the novelty and effectiveness of the proposed Framer approach in relation to existing image transformation techniques.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Fitsum A. Reda", "paper_title": "FILM: frame interpolation for large motion", "reason": "This paper is highly relevant because it directly addresses a key challenge in video frame interpolation: handling large motions between frames. The authors introduce a method that effectively interpolates frames even with significant motion.  Understanding FILM's strengths and weaknesses is crucial for evaluating the effectiveness of Framer, which also aims to improve the handling of challenging motion scenarios but does so by incorporating user interaction, which FILM does not.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Jiong Dong", "paper_title": "Video frame interpolation: A comprehensive survey", "reason": "This survey paper provides a broad overview of the existing video frame interpolation techniques, which helps to place Framer within the broader context of current research.  It highlights the challenges and limitations of existing methods, setting the stage for appreciating the novelty and potential impact of Framer's interactive approach. The survey also helps to identify the gaps in the existing research, which Framer aims to address.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Jinbo Xing", "paper_title": "Tooncrafter: Generative cartoon interpolation", "reason": "This paper is relevant because it explores the use of generative models for cartoon interpolation, a specific application of frame interpolation that Framer also addresses. By studying Tooncrafter, we gain valuable insights into the challenges and opportunities of applying generative techniques to frame interpolation, particularly in stylized image domains.  The comparison helps to assess Framer's performance in this niche domain.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "reason": "This paper introduces a significant advancement in video generation using diffusion models.  Framer builds upon this foundation by leveraging a pre-trained video diffusion model to generate interpolated frames.  Therefore, understanding the capabilities and limitations of this model is essential for assessing Framer's potential and its contributions to the field.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Duolikun Danier", "paper_title": "LDMVFI: video frame interpolation with latent diffusion models", "reason": "This paper is highly relevant because it directly applies diffusion models to the problem of video frame interpolation. It represents a state-of-the-art approach in generative video frame interpolation. Framer is compared against LDMVFI in the experiments and can be considered a direct competitor as both methods are generative, however, Framer incorporates interactive user controls which LDMVFI lacks.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Siddhant Jain", "paper_title": "Video interpolation with diffusion models", "reason": "This paper explores the use of cascaded diffusion models for video frame interpolation.  Similar to LDMVFI, this is a state-of-the-art generative method which Framer builds upon, however it is contrasted by its lack of user interactivity.  By understanding VIDIM's performance and limitations, we can better evaluate the advantages of Framer's interactive approach.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "reason": "This paper explores diffusion models for video generation, providing a strong foundation for Framer's approach, which leverages a pre-trained video diffusion model for interpolation.  The analysis of Videocrafter1's architecture and capabilities is essential for understanding how Framer integrates and extends those capabilities to support interactive frame interpolation.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "Huaizu Jiang", "paper_title": "Super slomo: High quality estimation of multiple intermediate frames for video interpolation", "reason": "This paper represents a seminal work in video frame interpolation, proposing a method known as Super SloMo. This method is an important baseline for comparison in the paper. It is notable for its high quality of interpolated frames.  Understanding the limitations of Super SloMo in handling complex motions and appearance changes helps to highlight Framer's contributions.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Simon Niklaus", "paper_title": "Softmax splatting for video frame interpolation", "reason": "This paper introduces a novel method, Softmax Splatting, for video frame interpolation.  This method offers a different approach to the problem compared to optical flow-based or generative methods, and thus serves as an important point of comparison in understanding the capabilities and limitations of different VFI techniques.  Comparing it against Framer provides valuable insights into the relative strengths and weaknesses of various interpolation techniques.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Xingang Pan", "paper_title": "Drag your GAN: interactive point-based manipulation on the generative image manifold", "reason": "This paper is important because it demonstrates the feasibility of using point-based controls for manipulating image generation.  This concept is directly relevant to Framer's design, where users provide point trajectories to control the interpolation process. By understanding Drag your GAN, we can better evaluate the effectiveness of using point trajectories as control signals for video interpolation.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Weijia Wu", "paper_title": "Draganything: Motion control for anything using entity representation", "reason": "This paper is closely related to Framer as both papers focus on controlling the video generation process through point trajectories. By understanding Draganything, we can put Framer's approach in perspective and compare their effectiveness in handling various types of motions and in achieving high-quality interpolation. The similar techniques used in both make it relevant to include.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Nikita Karaev", "paper_title": "Cotracker: It is better to track together", "reason": "This paper is highly relevant because it provides the point tracking algorithm used in Framer's implementation. Understanding the capabilities and limitations of Cotracker is crucial for assessing the reliability and accuracy of Framer's trajectory estimation, which plays a central role in its ability to produce high-quality interpolated frames. The algorithm helps determine the trajectories and is foundational to Framer's operation.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Kepan Nan", "paper_title": "Openvid-1m: A large-scale high-quality dataset for text-to-video generation", "reason": "This paper introduces a large-scale dataset, OpenVid-1M, which is used for training Framer.  The quality and characteristics of this dataset significantly influence the model's performance.  Understanding the dataset composition and its properties is therefore crucial for evaluating Framer's training process and its generalization capabilities.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Liying Lu", "paper_title": "Video frame interpolation with transformer", "reason": "This paper is relevant as it represents a state-of-the-art approach in video frame interpolation using transformer models, which are known for their capacity to handle long-range dependencies.  The comparison of Framer with this transformer-based method highlights Framer's ability to handle large motions and complex scene dynamics using a different approach, involving a diffusion model. Thus, comparing both methods gives insight into different approaches.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Yihao Liu", "paper_title": "Enhanced quadratic video interpolation", "reason": "This paper is relevant because it introduces a method for video interpolation based on enhancing the quadratic interpolation approach. This method is used as a baseline for comparison in the evaluation section. It demonstrates a method that is used as a comparison in evaluating Framer's effectiveness. The comparison provides context for Framer\u2019s improvements.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "Xingang Xu", "paper_title": "Enhanced quadratic video interpolation", "reason": "This paper proposes an enhanced quadratic video interpolation method that serves as a strong baseline for comparison against Framer. Understanding this method's strengths and limitations is important for contextualizing Framer's advancements and for demonstrating the improvement Framer offers.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "reason": "This paper explores the integration of conditional control signals into text-to-image diffusion models. This is directly relevant to Framer's approach, which incorporates point trajectory control signals into a video diffusion model.  Understanding the techniques for incorporating control signals is essential for analyzing Framer's methodology and for evaluating its effectiveness.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "Wenbo Bao", "paper_title": "Depth-aware video frame interpolation", "reason": "This paper proposes a depth-aware video frame interpolation method, offering another perspective on the problem compared to optical-flow or generative methods. This method is used as a comparison in the evaluation section. This serves as a point of comparison for Framer's performance. Comparing it helps to understand the effectiveness of Framer's approach relative to other techniques.", "section_number": 4}]}