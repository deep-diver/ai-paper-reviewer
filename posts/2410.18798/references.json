{"references": [{" publication_date": "2024", "fullname_first_author": "Wei He", "paper_title": "Distrill Visual Chart Reasoning Ability From LLMs To MLLMs", "reason": "This is the main paper of the study, introducing the core methodology (CIT) and dataset (REACHQA).  It establishes the problem of visual reasoning in LLMs, proposes a novel solution, and demonstrates its effectiveness through experiments.", "section_number": 1}, {" publication_date": "2022", "fullname_first_author": "Ahmed Masry", "paper_title": "ChartQA: A Benchmark for Question Answering About Charts with Visual and Logical Reasoning", "reason": "ChartQA is a well-established benchmark frequently cited in the paper.  It provides baseline results for evaluating visual reasoning capabilities and helps to define the state-of-the-art performance in the field. It's crucial to the paper's methodology and evaluation.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Pan Lu", "paper_title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "reason": "MathVista serves as a key general multimodal reasoning benchmark for the paper's experiments.  Its use allows comparison of the improved reasoning abilities gained by training with REACHQA, demonstrating transfer learning beyond chart-specific tasks.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Yizhong Wang", "paper_title": "Self-Instruct: Aligning Language Models With Self-Generated Instructions", "reason": "Self-Instruct is a key technique used for data synthesis in REACHQA.  It provides a method for creating diverse chart-plotting codes through LLMs, enhancing the diversity and complexity of the generated dataset.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Can Xu", "paper_title": "WizardLM: Empowering Large Pre-trained Language Models to Follow Complex Instructions", "reason": "Evol-Instruct, a technique inspired by WizardLM, is used in the paper to increase the complexity of the generated chart codes. It provides the theoretical foundation for one part of the data creation method.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Chaoyou Fu", "paper_title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models", "reason": "MME provides additional general multimodal benchmarks for evaluating models trained using REACHQA. This helps assess the broader impact of improved visual reasoning skills.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Takeshi Kojima", "paper_title": "Large Language Models are Zero-Shot Reasoners", "reason": "This paper provides theoretical support for the use of chain-of-thought prompting in evaluating model performance, a key element of the experimental design in the paper.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Edward J. Hu", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "reason": "LoRA is the fine-tuning technique used for the general open-source models, allowing for efficient adaptation with limited computational resources.  It provides the practical implementation details of the experimental methodology.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Yuan Yao", "paper_title": "MiniCPM-V: A GPT-4V Level MLLM On Your Phone", "reason": "MiniCPM-V2.5-Llama3 is one of the models used for multimodal validation, helping to ensure the quality and consistency of the generated data in REACHQA. Its description is an important aspect of the methodology.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Bohao Li", "paper_title": "Seed-bench: Benchmarking Multimodal LLMs with Generative Comprehension", "reason": "SeedBench is one of the general multimodal benchmarks used in evaluating the generalized performance of models trained using REACHQA.  This provides further evidence of the transfer learning capacity improved by REACHQA.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Ke Wang", "paper_title": "Measuring Multimodal Mathematical Reasoning with Math-Vision Dataset", "reason": "MATH-Vision is another key general multimodal reasoning benchmark dataset.  The paper uses it to assess whether improved performance on chart-related tasks transfers to other complex reasoning tasks.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Yucheng Han", "paper_title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation", "reason": "ChartLlama is a chart-focused model providing a comparison baseline for evaluating REACHQA's performance. It represents the state of the art in chart-related open-source models before the introduction of REACHQA.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Ahmed Masry", "paper_title": "ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning", "reason": "ChartInstruct is one of the chart-augmented models providing an important comparison baseline against the models trained using REACHQA.  It shows the advantage of using the proposed method in this study.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Fanqing Meng", "paper_title": "ChartAssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning", "reason": "ChartAssistant is another chart-augmented model, providing a comparison point for evaluating the effectiveness of the methods and dataset presented in the main paper.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Ahmed Masry", "paper_title": "ChartGemma: Visual Instruction-Tuning for Chart Reasoning in the Wild", "reason": "ChartGemma is yet another chart-focused model offering a useful baseline comparison. It provides an alternative approach to visual reasoning in LLMs that is evaluated against REACHQA.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Renqiu Xia", "paper_title": "ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning", "reason": "ChartX is another important benchmark dataset used for evaluating the models.  It complements ChartQA and ChartBench, providing a broader range of chart-related tasks for performance assessment.", "section_number": 5}, {" publication_date": "2023", "fullname_first_author": "Zhengzhuo Xu", "paper_title": "ChartBench: A Benchmark for Complex Visual Reasoning in Charts", "reason": "ChartBench is a key benchmark used in the experiments.  It provides a robust and comprehensive benchmark focusing on visual reasoning capabilities of the models.  It allows evaluating performance specifically on recognition-focused tasks.", "section_number": 5}, {" publication_date": "2024", "fullname_first_author": "Zirui Wang", "paper_title": "CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs", "reason": "CharXiv is a crucial benchmark for evaluating the combined recognition and reasoning capabilities.  This benchmark dataset helps evaluate whether improvements gained from training with REACHQA generalize to more complex, real-world scenarios.", "section_number": 5}, {" publication_date": "1986", "fullname_first_author": "Michael Zarechnak", "paper_title": "The Intermediary Language for Multilanguage Translation", "reason": "This paper provides the theoretical background and inspiration for the Code-as-Intermediary Translation (CIT) method. It is a foundational paper that inspires the main method of the study.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Wei He", "paper_title": "Self-Demos: Eliciting Out-of-Distribution Generalizability in Large Language Models", "reason": "This paper provides theoretical support and inspiration for the approach of using LLMs for generating a large scale of diverse datasets. It is relevant to the methodology applied in the main study.", "section_number": 3}]}