{"references": [{" publication_date": "2020", "fullname_first_author": "Leo Gao", "paper_title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", "reason": "This paper is foundational in introducing The Pile, a significant benchmark dataset in the field of large language models.  Its influence on the development and advancement of LLMs is undeniable, serving as a key reference for both the methodology and the challenges in creating large-scale, high-quality datasets, particularly its size and diversity, directly relevant to the discussion in Section 1 on the need for high-quality datasets and the shift towards larger datasets in LLM training.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "An Yang", "paper_title": "Qwen2 technical report", "reason": "This report is crucial for understanding the capabilities of the Qwen2-72B-Instruct model, a key component in the High-Quality Processing pipeline described in Section 2. The report provides essential details regarding the model's architecture, training methods, and performance characteristics.  This information is essential for understanding the rationale behind the design choices made in the paper's data processing pipeline, especially the use of Qwen2 for identifying high-quality samples and training the quality classifier.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 herd of models", "reason": "This paper is highly relevant to the context of large language model development and the importance of high-quality training data, as highlighted in Section 1.  The Llama 3 models, while not directly compared to, represent a competing framework and their success emphasizes the importance of the broader trend of improving both scale and quality of training data, the main focus of the paper.", "section_number": 1}, {" publication_date": "2020", "fullname_first_author": "Common Crawl", "paper_title": "Common Crawl Corpus", "reason": "This dataset serves as a crucial open-source data source for many large language models, including those used for comparisons in the paper (Section 1). Its scale and diversity are frequently cited as key factors influencing the direction of LLM research.  The paper highlights the ongoing limitations of rule-based filtering of this dataset and the benefits of using model-based approaches, so understanding its role is crucial.", "section_number": 1}, {" publication_date": "2024", "fullname_first_author": "Guilherme Penedo", "paper_title": "The FineWeb datasets: Decanting the web for the finest text data at scale", "reason": "This paper introduces FineWeb, a large-scale dataset.  It's critically important to Section 2, because of the use of its methodology in the paper's high-quality processing stage. This dataset and its annotation approach (FineWeb-edu) is directly adopted and compared to in the experimental evaluation (Section 3).", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Together Computer", "paper_title": "Redpajama: An open source recipe to reproduce Llama training dataset", "reason": "This is a significant contribution in the field of LLM training, emphasizing the need for open-source datasets as discussed in Section 1. The paper's focus on reproducibility aligns with the broader concerns of the current work related to transparency and replicability of results within the LLM community.", "section_number": 1}, {" publication_date": "2021", "fullname_first_author": "Sha Yuan", "paper_title": "Wudaocorpora: A super large-scale chinese corpora for pre-training language models", "reason": "This is one of the existing Chinese datasets mentioned in Section 1 as having limited scale and quality compared to the dataset presented in this paper (CCI3.0-HQ). Including this work highlights the existing landscape of datasets for training Chinese LLMs and emphasizes the CCI3.0-HQ's improvements.", "section_number": 1}, {" publication_date": "2023", "fullname_first_author": "Tianwen Wei", "paper_title": "Skywork: A more open bilingual foundation model", "reason": "SkyPile is another significant dataset for training LLMs, directly referenced and compared against in Section 3 of the current paper.  This provides an essential benchmark for comparing the performance of the proposed CCI3.0-HQ dataset, highlighting its advantages.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Conghui He", "paper_title": "Wanjuan: A comprehensive multimodal dataset for advancing english and chinese large models", "reason": "This dataset (WanjuanV1), which is compared in Section 3, provides a relevant benchmark to illustrate the improvements in the quality and performance of the CCI3.0-HQ dataset. The inclusion allows for a detailed comparative analysis, highlighting the superiority of the proposed dataset.", "section_number": 3}, {" publication_date": "1997", "fullname_first_author": "A. Broder", "paper_title": "On the resemblance and containment of documents", "reason": "This paper describes the MinHash algorithm used for document-level deduplication in Section 2, a crucial step in the data processing pipeline.  The MinHash algorithm is a fundamental technique in data cleaning and its inclusion is important for understanding the technical aspects of the dataset creation process.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Jianghao Chen", "paper_title": "ChineseWebText: Large-scale high-quality chinese web text extracted with effective evaluation model", "reason": "ChineseWebText is used in the initial quality filtering process in Section 2. This dataset is relevant as it serves as the foundation for the initial assessment of data quality before more sophisticated techniques are used in later stages.  Therefore, understanding its role in the pipeline is vital for evaluating the improvements brought about by the subsequent quality-enhancing steps.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Woosuk Kwon", "paper_title": "Efficient memory management for large language model serving with pagedattention", "reason": "This paper describes the vLLM technology used for efficient annotation of samples by Qwen2-72B-Instruct model in Section 2. The efficient use of the large language model is crucial for the feasibility of the annotation process within the high-quality processing pipeline.  The methodology is also relevant for improving efficiency in building large language models.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Jianlv Chen", "paper_title": "Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation", "reason": "This is relevant because the model BGE-M3 is used in section 2.2.2 for efficient training of quality classifiers, reducing computational cost and resources required for high quality data labeling.  The choice and modification of this pre-trained model is a key part of the high-quality processing pipeline.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Raymond Li", "paper_title": "StarCoder: may the source be with you!", "reason": "StarCoder is included in the mixed dataset experiment (Section 3).  Understanding the characteristics of this code dataset, as well as its inclusion criteria, are crucial for assessing the robustness and generalizability of the CCI3.0-HQ dataset in handling diverse data types.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Cl\u00e9mentine Fourrier", "paper_title": "Lighteval: A lightweight framework for llm evaluation", "reason": "Lighteval is the evaluation library used for the experiments (Section 3). It plays a crucial role in ensuring consistency and comparability across various metrics. This paper explains the specific metrics used and allows for a proper interpretation and evaluation of the results, crucial for demonstrating the improvement in the quality of CCI3.0-HQ.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Yuzhen Huang", "paper_title": "C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models", "reason": "C-eval is one of the evaluation metrics in the Chinese-specific experiment (Section 3). Understanding the characteristics of this metric, and other metrics, allows for a proper interpretation and evaluation of the improvements gained by using CCI3.0-HQ in the training of language models.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Haonan Li", "paper_title": "CMMLU: Measuring massive multitask language understanding in chinese", "reason": "CMMLU is used as an evaluation metric in the experiments section (Section 3). Understanding the nuances of this evaluation metric is crucial for assessing the performance of models trained on CCI3.0-HQ.  Its use in the experiment provides a more comprehensive and detailed evaluation of the models' ability to handle various linguistic tasks.", "section_number": 3}, {" publication_date": "2018", "fullname_first_author": "Peter Clark", "paper_title": "Think you have solved question answering? try arc, the ai2 reasoning challenge", "reason": "ARC (ARC-C and ARC-E) is used as an evaluation metric in Section 3.  ARC is a challenging benchmark frequently used to assess the reasoning capabilities of LLMs.  The inclusion of ARC provides critical context for evaluating the performance improvements gained from using CCI3.0-HQ, adding weight to the claims of performance improvements from the training dataset.", "section_number": 3}, {" publication_date": "2019", "fullname_first_author": "Rowan Zellers", "paper_title": "Hellaswag: Can a machine really finish your sentence?", "reason": "HellaSwag is a benchmark dataset used in the evaluation section (Section 3).  This dataset tests the common sense reasoning abilities of LLMs and its inclusion adds further depth to the evaluation of the CCI3.0-HQ dataset, demonstrating its ability to improve the overall performance of models, especially in common-sense reasoning tasks.", "section_number": 3}]}