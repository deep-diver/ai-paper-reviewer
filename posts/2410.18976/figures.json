[{"figure_path": "2410.18976/figures/figures_1_0.png", "caption": "Figure 1. The proposed CAMEL-Bench covers eight diverse and challenging domains: multimodal understanding and reasoning, OCR and documents, charts and diagrams, videos, cultural-specific content, medical images, agricultural images, and remote sensing understanding in Arabic. CAMEL-Bench covers 38 sub-domains with over 29K questions carefully curated by native Arabic speakers to rigorously evaluate essential skills desired in Arabic LMMs.", "description": "The figure is a visual representation of the CAMEL-Bench benchmark, depicted as a circular diagram.  The outermost ring lists eight main domains (Multimodal Understanding & Reasoning, OCR & Document Understanding, Chart & Diagram Understanding, Video Understanding, Cultural-Specific Understanding, Medical Image Understanding, Agricultural Image Understanding, and Remote Sensing Understanding). Each of these domains is further divided into multiple sub-domains (e.g., Multi-image understanding, Handwriting, Medical Diagnosis, etc.), which are listed in the inner ring.  A camel is situated in the center of the diagram, symbolizing the Arabic focus of the benchmark.  The diagram visually illustrates the comprehensive and diverse nature of CAMEL-Bench, encompassing a wide range of tasks and visual data types relevant to the Arabic language.", "section": "1. Introduction"}, {"figure_path": "2410.18976/figures/figures_2_0.png", "caption": "Figure 1. The proposed CAMEL-Bench covers eight diverse and challenging domains: multimodal understanding and reasoning, OCR and documents, charts and diagrams, videos, cultural-specific content, medical images, agricultural images, and remote sensing understanding in Arabic. CAMEL-Bench covers 38 sub-domains with over 29K questions carefully curated by native Arabic speakers to rigorously evaluate essential skills desired in Arabic LMMs.", "description": "The figure is a visual representation of the CAMEL-Bench, a comprehensive Arabic LMM benchmark. It's a circular diagram divided into eight main domains, each representing a different area of multimodal understanding (e.g., multimodal understanding & reasoning, OCR & document understanding, etc.). Each domain is further subdivided into multiple sub-domains, illustrated by the colored segments within each domain.  The number of questions in the benchmark (over 29,000) is mentioned, highlighting the scale of the evaluation.  The diagram effectively communicates the breadth and depth of the benchmark, emphasizing its focus on diverse and challenging Arabic language tasks.", "section": "1. Introduction"}, {"figure_path": "2410.18976/figures/figures_4_0.png", "caption": "Figure 3. The CAMEL-Bench Filtering and Verification Pipeline consists of two paths: Original Arabic and translated Arabic. For original Arabic (top row), a 20% random sample undergoes manual verification; if errors are below 40%, the data passes; otherwise, the entire sub-category is reviewed. For Translated Arabic (bottom row), We employ Qwen7B model [8] to assess semantic similarity between the original and translated question-answer pairs on fuzzy-basis evaluation. Pairs passing the evaluation proceed, while those that fail undergo manual review. Based on this, data may require Manual Handling for manual re-translation, Refine & Verify for refinement through the model, or Non-Translated Review where the data is re-sent for translation due to the absence of an Arabic version.", "description": "This flowchart illustrates the two-path data filtering and verification process for the CAMEL-Bench dataset.  The top path shows the process for originally Arabic data, involving a 20% random sample manual verification. If errors exceed 40%, the entire sub-category is manually reviewed. The bottom path details the process for translated Arabic data, using the Qwen7B model for fuzzy semantic similarity evaluation between original English and translated Arabic question-answer pairs.  Data failing this evaluation undergoes manual review, potentially leading to manual re-translation, refinement via the model, or resubmission for translation if an Arabic version is lacking. The final output of both paths is the CAMEL-Bench dataset.", "section": "2. CAMEL-Bench"}, {"figure_path": "2410.18976/figures/figures_5_0.png", "caption": "Figure 2. CAMEL-Bench examples spanning eight diverse domains, encompassing a wide range of visual data types and tasks.", "description": "Figure 2 presents a diverse collection of examples from the CAMEL-Bench dataset, showcasing the breadth of visual data types and tasks covered.  It displays sample questions and corresponding images from eight different domains: Multimodal Understanding & Reasoning, Chart & Diagram Understanding, Cultural-Specific Understanding, Medical Image Understanding, Remote Sensing Understanding, and Agricultural Image Understanding.  The examples illustrate the variety of visual inputs used (such as diagrams, charts, videos, medical images, satellite images, and agricultural images), and the complexity of the questions asked, covering several sub-domains.  The figure highlights the dataset's comprehensiveness and ability to evaluate models across a range of modalities and reasoning abilities in the Arabic language.", "section": "2. CAMEL-Bench"}, {"figure_path": "2410.18976/figures/figures_5_1.png", "caption": "Figure 2. CAMEL-Bench examples spanning eight diverse domains, encompassing a wide range of visual data types and tasks.", "description": "Figure 2 presents a collection of example questions from the CAMEL-Bench benchmark, showcasing the diversity of tasks and visual data types covered. Each example visual is accompanied by a question and multiple-choice answers, reflecting the eight domains included in the benchmark: Multimodal Understanding and Reasoning, OCR and Document Understanding, Chart and Diagram Understanding, Video Understanding, Cultural-Specific Understanding, Medical Image Understanding, Agricultural Image Understanding, and Remote Sensing Understanding.  The examples illustrate tasks like identifying objects in images, answering questions based on chart data, understanding handwritten Arabic text, determining the nationality of a person from an image, diagnosing medical conditions from medical scans, identifying plant diseases, and interpreting satellite imagery for land use analysis.  These examples highlight the comprehensive nature of CAMEL-Bench and the wide range of Arabic language and visual understanding skills it assesses.", "section": "2. CAMEL-Bench"}]