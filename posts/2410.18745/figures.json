[{"figure_path": "2410.18745/figures/figures_17_0.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "Figure 2 is composed of two subfigures. Figure 2(a) shows the relationship between effective context length and consumed tokens during the training process for two TinyLlama models with different context window sizes (2K and 4K).  It demonstrates that using a larger context window during training requires fewer tokens to achieve the same effective context length. Figure 2(b) illustrates the correlation between effective context length and position frequency. It reveals that models achieve similar effective context lengths when they've been exposed to similar frequencies of position indices, regardless of maximum training length differences.", "section": "A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/figures/figures_17_1.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "This figure contains two subfigures, (a) and (b). Subfigure (a) shows the relationship between the effective context length and the number of consumed tokens during training for two different models, TinyLlama-1.3b-4k and TinyLlama-1.3b-2k.  The x-axis represents consumed tokens, and the y-axis represents effective length. Subfigure (b) displays the correlation between effective context length and position frequency for the same two models. Here, the x-axis shows effective length, and the y-axis indicates the position frequency f(i). Both subfigures illustrate how the effective context length relates to both the consumed tokens during training and the position frequency distribution.", "section": "3 A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}, {"figure_path": "2410.18745/figures/figures_19_0.png", "caption": "Analyzing effective context length of LLMs pretrained on SlimPajama with respect to training length, token consumption, and position frequency. In Figure 2b, we use the model effective length as the X-axis, and the Y-axis indicates the number of times the model was exposed to that specific position during training.", "description": "This figure displays two subplots.  The first subplot (a) shows the relationship between effective context length and consumed tokens for two models, TinyLlama-1.3b, trained with different training lengths (2K and 4K). It demonstrates that a larger training context window leads to a greater effective context length when the same number of tokens are consumed. The second subplot (b) shows the relationship between effective context length and position frequency for the same two models. It illustrates that models achieve similar effective context lengths when they have been exposed to similar frequencies of position indices, regardless of differences in their maximum training lengths.", "section": "3 A PROBING EXPERIMENT ON POSITION FREQUENCY AND MODEL EFFECTIVE LENGTH"}]