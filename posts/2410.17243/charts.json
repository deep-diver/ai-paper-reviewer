[{"figure_path": "2410.17243/charts/charts_1_0.png", "caption": "Figure 1: GPU memory usage comparison between Inf-CL and previous methods (CLIP, OpenCLIP). The dashed line marks the common GPU memory limit. Memory costs exceeding the bottleneck of 80G A800 are estimated by curve fitting. Left: With 8\u00d7A800, CLIP and OpenCLIP's memory consumption increases quadratically, while Inf-CL achieves linear growth, reducing memory costs by 78\u00d7 at a batch size of 256k. Right: At a batch size of 1024k, even with 128 GPUs, previous methods exceed memory limits, whereas Inf-CL reduces memory demand by 281\u00d7.", "description": "This figure compares the GPU memory usage of three contrastive learning methods: CLIP, OpenCLIP, and Inf-CL (the proposed method). The left panel shows the memory usage as a function of batch size (from 64k to 1024k) when using 8 GPUs. CLIP and OpenCLIP exhibit a quadratic increase in memory usage with increasing batch size, hitting the 80GB A800 GPU memory limit. In contrast, Inf-CL shows linear growth and significantly reduces memory costs by 78x at a batch size of 256k. The right panel shows the memory usage at a fixed batch size of 1024k with varying number of GPUs (from 1 to 128).  Again, CLIP and OpenCLIP exceed the memory limit, even with 128 GPUs, whereas Inf-CL substantially lowers memory demand by a factor of 281x.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17243/charts/charts_8_0.png", "caption": "Figure 4: Training Speed of ViT-L/14 CLIP on 8\u00d7A800 for Varying Batch Sizes. The left figure shows the time per iteration step, while the right displays the time per epoch. Loss calculation contributes minimally to the total iteration time, making Inf-CL\u2019s iteration time comparable to previous methods. Furthermore, the iteration time of Inf-CL scales linearly with batch size, leading to a stable training duration of approximately 59 hours per epoch.", "description": "This chart presents a comparison of the training speed for the ViT-L/14 CLIP model across different batch sizes (32k, 64k, 128k, 256k) using 8 A800 GPUs. It is a dual-axis chart showing both iteration time (in seconds) and total training time (in hours) on the y-axis, and the batch size on the x-axis. The left panel displays the iteration time for each method (CLIP, OpenCLIP, Inf-CL), while the right panel shows the total training time, demonstrating the linear scalability of Inf-CL.  The chart highlights that Inf-CL achieves comparable speed to CLIP and OpenCLIP, with a linear scaling in training time as the batch size increases, unlike the quadratic scaling observed with CLIP and OpenCLIP, reaching out of memory (OOM) errors at 256k batch size.", "section": "4 EXPERIMENTS"}, {"figure_path": "2410.17243/charts/charts_15_0.png", "caption": "Figure 5: Performance of ViT-B/32 across Varying Batch Sizes. Except batch size, other experiment settings are consistent. In Figure, the most suitable batch size is increasing with data scale.", "description": "This chart displays the relationship between batch size and accuracy delta for the ViT-B/32 model across three datasets: CC3M, CC12M, and Laion400M.  The x-axis represents the batch size (in thousands), and the y-axis shows the change in accuracy. Each dataset is represented by a different colored line, showing that the optimal batch size (the peak point) increases with the size of the dataset.  The chart also highlights the lowest point, indicating the point where performance begins to decrease as the batch size becomes excessively large.  The figure indicates a clear trend showing the optimal batch size increasing with the size of the dataset.", "section": "4 EXPERIMENTS"}]