[{"figure_path": "2410.17243/figures/figures_2_0.png", "caption": "Figure 2: (a) Vanilla implementation of contrastive loss gathers features to all devices to calculate all similarity simultaneously, where the similarity with squared complexity are repeatedly stored in all devices, causing huge memory costs for loss calculation when batch size increases. (b) Our Inf-CL significant decreases the memory cost by serial and distributed tile-wise computation.", "description": "The figure is composed of two subfigures, (a) and (b), illustrating the vanilla implementation of contrastive loss and the proposed Inf-CL method, respectively. Subfigure (a) shows that the vanilla implementation aggregates image and text features from all devices to calculate the similarity matrix, which has a quadratic complexity O(b\u00b2) and requires a large amount of memory. In contrast, subfigure (b) depicts Inf-CL's approach, where computation is divided into tiles, reducing memory usage and improving efficiency. Inf-CL uses serial and distributed tile-wise computation, which significantly decreases memory cost.  The memory usage of both methods is provided for ViT-B/16 with a batch size of 64k.", "section": "2.2 VANILLA IMPLEMENTATION OF CONTRASTIVE LOSS"}, {"figure_path": "2410.17243/figures/figures_2_1.png", "caption": "Figure 2: (a) Vanilla implementation of contrastive loss gathers features to all devices to calculate all similarity simultaneously, where the similarity with squared complexity are repeatedly stored in all devices, causing huge memory costs for loss calculation when batch size increases. (b) Our Inf-CL significant decreases the memory cost by serial and distributed tile-wise computation.", "description": "This figure is a comparison of two approaches to contrastive loss calculation. Figure 2(a) shows the 'Vanilla Implementation' where all devices gather features to compute the entire similarity matrix, leading to a quadratic memory cost with O(b\u00b2) complexity, where b is the batch size.  In contrast, Figure 2(b) illustrates the proposed Inf-CL method. Inf-CL employs serial and distributed tile-wise computation, significantly reducing memory usage. It partitions the calculation into smaller blocks, avoiding the full materialization of the similarity matrix, which reduces the complexity to O(b/n\u00b2), where n is the number of GPUs.", "section": "2.2 VANILLA IMPLEMENTATION OF CONTRASTIVE LOSS"}, {"figure_path": "2410.17243/figures/figures_4_0.png", "caption": "Figure 1: GPU memory usage comparison between Inf-CL and previous methods (CLIP, Open-CLIP). The dashed line marks the common GPU memory limit. Memory costs exceeding the bottleneck of 80G A800 are estimated by curve fitting. Left: With 8\u00d7A800, CLIP and OpenCLIP's memory consumption increases quadratically, while Inf-CL achieves linear growth, reducing memory costs by 78\u00d7 at a batch size of 256k. Right: At a batch size of 1024k, even with 128 GPUs, previous methods exceed memory limits, whereas Inf-CL reduces memory demand by 281\u00d7.", "description": "This figure compares the GPU memory usage of three contrastive loss methods: CLIP, OpenCLIP, and Inf-CL (the proposed method).  The left panel shows that, with 8 A800 GPUs, the memory usage of CLIP and OpenCLIP increases quadratically with batch size, hitting a memory bottleneck of 80GB per GPU,  while Inf-CL shows a linear increase, using significantly less memory. The right panel shows that at a batch size of 1024k, CLIP and OpenCLIP exceed the memory limits even when using 128 GPUs, whereas Inf-CL still operates within limits.", "section": "ABSTRACT"}, {"figure_path": "2410.17243/figures/figures_5_0.png", "caption": "Figure 3: Multi-level tiling strategy. Top: for cross-GPU tiling, each GPU is assigned with multiple rows. The computation and the column-wise communication are performed asynchronously to reduce the cost. Bottom: for in-GPU tiling, the calculations in each GPU are further divided into tiles and the row-wise calculation is distributed to multiple CUDA cores. The accumulative operations of each row are merged into one kernel for reducing I/O times between SRAM and HBM.", "description": "This figure illustrates the multi-level tiling strategy used in Inf-CL for efficient contrastive loss computation with large batch sizes. The top half shows the cross-GPU tiling where each GPU handles multiple rows of the similarity matrix, performing computations and asynchronous column-wise communication to reduce overhead. The bottom half depicts the in-GPU tiling, where each GPU further divides its computation into tiles, distributing row-wise calculations across CUDA cores and merging accumulative operations into a single kernel to minimize I/O between SRAM and HBM.  This multi-level approach balances memory reduction and computational speed.", "section": "3.2 MULTI-LEVEL TILING"}]