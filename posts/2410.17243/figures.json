[{"figure_path": "2410.17243/figures/figures_2_0.png", "caption": "Figure 2: (a) Vanilla implementation of contrastive loss gathers features to all devices to calculate all similarity simultaneously, where the similarity with squared complexity are repeatedly stored in all devices, causing huge memory costs for loss calculation when batch size increases. (b) Our Inf-CL significant decreases the memory cost by serial and distributed tile-wise computation.", "description": "This figure illustrates the memory cost differences between the vanilla implementation of contrastive loss and the proposed Inf-CL method.  The left panel (a) shows the vanilla approach, where all devices gather features to calculate the full similarity matrix, resulting in quadratic memory growth with respect to batch size. The high memory cost is mainly due to the repeated storage of the similarity matrix across all devices.  The right panel (b) depicts Inf-CL, which significantly reduces memory usage by employing a tile-wise computation strategy.  This strategy computes and stores the similarity matrix in smaller, serial tiles, distributing the computation across devices and reducing the total memory demand.  The illustration highlights that Inf-CL addresses the memory bottleneck of the vanilla contrastive loss implementation. ", "section": "2.2 VANILLA IMPLEMENTATION OF CONTRASTIVE LOSS"}, {"figure_path": "2410.17243/figures/figures_2_1.png", "caption": "Figure 2: (a) Vanilla implementation of contrastive loss gathers features to all devices to calculate all similarity simultaneously, where the similarity with squared complexity are repeatedly stored in all devices, causing huge memory costs for loss calculation when batch size increases. (b) Our Inf-CL significant decreases the memory cost by serial and distributed tile-wise computation.", "description": "This figure is a comparison of two methods for calculating contrastive loss: a vanilla implementation and the proposed Inf-CL method.  The vanilla implementation (a) shows that all devices gather features and compute the entire similarity matrix simultaneously, leading to a quadratic memory complexity. The Inf-CL method (b) illustrates a tile-wise computation strategy.  The similarity matrix calculation is broken down into smaller blocks, which are distributed across devices, reducing memory costs by performing computations serially. The loss calculation is performed on these smaller blocks in a distributed fashion.", "section": "1 METHOD"}, {"figure_path": "2410.17243/figures/figures_4_0.png", "caption": "Figure 1: GPU memory usage comparison between Inf-CL and previous methods (CLIP, Open-CLIP). The dashed line marks the common GPU memory limit. Memory costs exceeding the bottleneck of 80G A800 are estimated by curve fitting. Left: With 8\u00d7A800, CLIP and OpenCLIP's memory consumption increases quadratically, while Inf-CL achieves linear growth, reducing memory costs by 78\u00d7 at a batch size of 256k. Right: At a batch size of 1024k, even with 128 GPUs, previous methods exceed memory limits, whereas Inf-CL reduces memory demand by 281\u00d7.", "description": "This figure compares the GPU memory usage of three contrastive loss methods: CLIP, OpenCLIP, and Inf-CL (the proposed method). The left panel shows that with 8 A800 GPUs, CLIP and OpenCLIP exhibit a quadratic increase in memory usage as the batch size increases, hitting a memory bottleneck. In contrast, Inf-CL displays a linear increase, resulting in a 78x reduction in memory cost at a batch size of 256k. The right panel demonstrates that, even with 128 GPUs, CLIP and OpenCLIP exceed memory limits at a batch size of 1024k; Inf-CL significantly reduces memory demand by 281x under the same conditions.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.17243/figures/figures_5_0.png", "caption": "Figure 3: Multi-level tiling strategy. Top: for cross-GPU tiling, each GPU is assigned with multiple rows. The computation and the column-wise communication are performed asynchronously to reduce the cost. Bottom: for in-GPU tiling, the calculations in each GPU are further divided into tiles and the row-wise calculation is distributed to multiple CUDA cores. The accumulative operations of each row are merged into one kernel for reducing I/O times between SRAM and HBM.", "description": "This figure illustrates the multi-level tiling strategy used in Inf-CL for efficient contrastive loss calculation. The top panel shows the cross-GPU tiling, where each GPU handles multiple rows of the similarity matrix. Computations are distributed across GPUs, and column-wise communication happens asynchronously to minimize overhead. The bottom panel details the in-GPU tiling. Here, each GPU divides its calculations into tiles, and row-wise computations are parallelized across CUDA cores.  These individual LSE values are then merged within the GPU using an accumulator.  This two-stage tiling method balances memory efficiency and computational performance.", "section": "3.2 MULTI-LEVEL TILING"}]