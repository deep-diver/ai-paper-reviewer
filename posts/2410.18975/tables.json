[{"figure_path": "2410.18975/tables/table_9_0.md", "caption": "Table 1: Comparison of UNBOUNDED and other methods for maintaining environment consistency and character consistency. UNBOUNDED achieves the best performance in maintaining consistency, while maintaining comparable semantic alignment with the text prompt. Best scores are in bold.", "description": "Table 1 compares UNBOUNDED with three other methods (IP-Adapter, IP-Adapter-Instruct, and Story Diffusion) across three metrics: environment consistency (measured using CLIP-I, DINO, and DreamSim), character consistency (also using CLIP-I, DINO, and DreamSim), and semantic alignment with the text prompt (using CLIP-T).  For each metric, the table presents the performance score of each method.  The scores show that UNBOUNDED significantly outperforms the other methods in terms of environment and character consistency, and maintains comparable semantic alignment with the prompt.  Best scores for each metric are shown in bold.", "section": "4.1 Evaluation Benchmarks"}, {"figure_path": "2410.18975/tables/table_9_1.md", "caption": "Table 1: Comparison of UNBOUNDED and other methods for maintaining environment consistency and character consistency. UNBOUNDED achieves the best performance in maintaining consistency, while maintaining comparable semantic alignment with the text prompt. Best scores are in bold.", "description": "Table 1 compares UNBOUNDED against three other methods (IP-Adapter, IP-Adapter-Instruct, and Story Diffusion) across three evaluation metrics: environment consistency, character consistency, and semantic alignment.  Environment and character consistency are each assessed using three metrics (CLIP-I, DINO, and DreamSim), measuring the similarity between generated images and reference images. Semantic alignment uses CLIP-T, evaluating how well the generated image aligns with the provided text prompt.  The table presents numerical scores for each method and metric, highlighting UNBOUNDED's superior performance in maintaining both environment and character consistency while achieving comparable semantic alignment.  Visual examples of the generated images are also included to showcase the differences in the quality of environment and character consistency across the different methods.", "section": "4.1 Evaluation Benchmarks"}, {"figure_path": "2410.18975/tables/table_10_0.md", "caption": "Comparison of UNBOUNDED and other methods for maintaining environment consistency and character consistency. UNBOUNDED achieves the best performance in maintaining consistency, while maintaining comparable semantic alignment with the text prompt. Best scores are in bold.", "description": "The table compares UNBOUNDED with three other methods (IP-Adapter, IP-Adapter-Instruct, Story Diffusion) across three evaluation metrics: environment consistency, character consistency, and semantic alignment.  Environment consistency is measured using CLIP-I, DINO, and DreamSim scores; character consistency uses the same metrics with a different subscript; and semantic alignment is measured using CLIP-T.  For each method, the table shows the scores for each of these metrics, highlighting the best scores in bold.  The table visually demonstrates UNBOUNDED's superior performance in maintaining environment and character consistency while achieving comparable semantic alignment.", "section": "4.1 Evaluation Benchmarks"}, {"figure_path": "2410.18975/tables/table_11_0.md", "caption": "Table 3: Comparison of UNBOUNDED and different LLMs on serving as game engines for open-ended interactions and integrated game mechanics. We use GPT-4 to provide pairwise scores between our model and other LLMs.", "description": "This table compares the performance of UNBOUNDED and four different large language models (LLMs) as game engines for open-ended interactions and integrated game mechanics.  The comparison is based on scores from GPT-4 across five aspects: overall performance, state update accuracy, environment relevance, story coherence, and instruction following.  For each LLM, scores are provided for a baseline and UNBOUNDED model.  A smaller version of UNBOUNDED (Ours-1k) is also included, demonstrating the performance improvements with increased training data.", "section": "5.3 EFFECTIVENESS OF DISTILLING SPECIALIZED LARGE LANGUAGE MODEL"}]