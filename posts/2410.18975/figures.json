[{"figure_path": "2410.18975/figures/figures_1_0.png", "caption": "Figure 1: An example of UNBOUNDED. We follow the life of Archibus, the user's custom wizard character. The user can interact with the generative game using natural language, and Archibus' hunger, energy and fun meters update accordingly. A spontaneous and unconstrained story unfolds while the user playing, and the character can explore new environments with a myriad of possible actions and unexpected interactions. The game runs in interactive speeds, refreshing every second.", "description": "The figure shows three panels illustrating a sequence of events in the UNBOUNDED game. Each panel displays a cartoon-style image within a simulated game interface, showing a wizard character named Archibus in different scenarios. The top left panel shows Archibus in a classroom setting, interacting with students.  Below this image, there's text describing the action and the wizard's state (getting hungry). The middle panel depicts Archibus in a flowery meadow, eating pears. The bottom text describes the action and Archibus's updated state (content but bored). The rightmost panel shows Archibus back in the classroom, opening a book.  Below each image are example text interactions, showing how the user directs Archibus's actions using natural language.", "section": "ABSTRACT"}, {"figure_path": "2410.18975/figures/figures_3_0.png", "caption": "Figure 2: Example of UNBOUNDED. Based on an initial user input, UNBOUNDED sets up game simulation environments, and generates character actions in the environments. Users can interact with the character with natural language instructions, exploring the game with unlimited options.", "description": "The figure shows a flowchart illustrating the gameplay of UNBOUNDED. It starts with a user providing input, such as specifying a character (e.g., a young witch) and a game topic (e.g., dragon hunting).  The system then generates game environments (forest, pond, village, mountain) and character actions within those environments, depicted as a series of images. The user interacts with the character using natural language instructions, leading to a branching storyline with multiple possibilities.  Each step shows the updated character's state (hunger, energy, fun meters) and the environments generated based on user input. The process is iterative and continues with no fixed endpoint.", "section": "3 METHOD"}, {"figure_path": "2410.18975/figures/figures_4_0.png", "caption": "Figure 3: Generative game examples of UNBOUNDED. The user can insert a custom character into the game, engage with the character through natural language instructions, bring the character to different environments, and interact with it to maintain a healthy state under the games' mechanics.", "description": "Figure 3 presents five distinct scenarios within the UNBOUNDED game, each showcasing a different character (a witch, a wizard, a puppy, a cat, and a panda) in diverse virtual environments (a dreamy landscape, a mysterious underground world, floating islands, a city, and a vibrant rainforest).  Each character's current status (hunger, energy, fun, and hygiene) is represented by a corresponding progress bar. The figure demonstrates the game's ability to generate diverse and visually engaging environments in real-time, responding to user interactions specified in natural language and creating a personalized and dynamic gaming experience.", "section": "3 METHOD"}, {"figure_path": "2410.18975/figures/figures_5_0.png", "caption": "Figure 4: (a) Our overall image generation method. We achieve real-time image generation with LCM LORA, maintain character consistency with DreamBooth LoRAs, and introduce a regional IP-Adapter (shown in (c)) for improved environment and character consistency. (b) Our proposed dynamic mask genreation separating the environment and character conditioning, preventing interference between the two.", "description": "This figure illustrates the overall framework and the components of the image generation method used in UNBOUNDED.  Panel (a) shows the overall architecture, highlighting the use of LCM LoRA, DreamBooth LoRAs, and a regional IP-Adapter. Panel (b) details the dynamic mask generation process, which separates environment and character conditioning to prevent interference. Panel (c) provides a detailed breakdown of the regional IP-Adapter, demonstrating its use of character and environment IP-Adapters along with a block drop strategy to further improve consistency in generating images that accurately represent both elements. The dynamic mask is crucial for ensuring the character is integrated seamlessly within the environment.", "section": "3 METHOD"}, {"figure_path": "2410.18975/figures/figures_7_0.png", "caption": "Figure 6: Overview of our user-simulation data collection process for LLM distillation. (a) We begin by collecting diverse topic and character data, filtered using ROUGE-L for diversity. (b) The World LLM and User LLM interact to generate user-simulation data through multi-round exchanges.", "description": "This figure illustrates the two-stage process for collecting user-simulation data used in distilling a large language model (LLM) into a smaller, more efficient model for the UNBOUNDED game.  Panel (a) shows the topic collection process, where diverse topics and characters are generated by an LLM, filtered using ROUGE-L to ensure diversity, and then added to a topic pool. Panel (b) depicts the user-simulation data collection, where a World LLM and a User LLM interact through multiple rounds of exchanges to generate game environments, character actions, game mechanics, and interaction data.  This interaction data forms the basis for training the smaller, more efficient LLM.", "section": "3.3.2 FRAMEWORK FOR SMALL LLM DISTILLATION"}]