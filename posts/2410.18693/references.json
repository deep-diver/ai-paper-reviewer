{"references": [{" publication_date": "2023", "fullname_first_author": "Zhangir Azerbayev", "paper_title": "Llemma: An open language model for mathematics", "reason": "This paper introduces Llemma, a significant contribution to the field of mathematical reasoning in LLMs.  Its focus on open-source models and its potential to improve the performance of LLMs on mathematical tasks make it highly relevant to the current research and contribute to a better understanding of the challenges and opportunities in this area. The model's potential for improving the performance of LLMs on mathematical tasks makes it a highly relevant reference for the paper's contribution to scalable and cost-effective data synthesis.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Zheng Cai", "paper_title": "Internlm2 technical report", "reason": "This technical report details InternLM2, a powerful LLM relevant to the paper's discussion of leveraging pre-trained models for data synthesis. The report's insights into the architecture, training, and capabilities of InternLM2 are valuable for understanding how large language models can be used in the context of creating high-quality datasets for improving LLM reasoning.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Jiaao Chen", "paper_title": "Skills-in-context prompting: Unlocking compositionality in large language models", "reason": "This paper explores the concept of \"Skills-in-context prompting,\" a technique that can be used to enhance the reasoning capabilities of large language models. The method is highly relevant to the paper's work on question generation and dataset construction, as it provides a potential approach for prompting models to generate high-quality questions for mathematical reasoning.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Wenhu Chen", "paper_title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks", "reason": "This work introduces the \"Program of Thoughts\" prompting approach, a technique that can be used to elicit detailed reasoning steps from LLMs.  This is highly relevant to the paper's focus on creating datasets that encourage step-by-step reasoning in models, as \"Program of Thoughts\" prompting can be used to generate more detailed and explainable reasoning in question-answer pairs.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Yew Ken Chia", "paper_title": "Contrastive chain-of-thought prompting", "reason": "This paper introduces contrastive chain-of-thought prompting, which provides a valuable technique for prompting LLMs to generate more accurate and reliable reasoning. The method is relevant to this paper's work on question generation and dataset construction, as it helps enhance the accuracy of the reasoning process, thereby improving the quality of synthetic datasets.", "section_number": 4}, {" publication_date": "2021", "fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "reason": "This paper is foundational in addressing mathematical reasoning in LLMs and is crucial for the presented research as it introduces a dataset (GSM8K) that is used in this paper.  Its focus on creating more effective instruction datasets for LLMs makes it a key reference in the field. The development and use of GSM8K and its impact on LLM development are central to the context of this paper.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Aniket Didolkar", "paper_title": "Metacognitive capabilities of llms: An exploration in mathematical problem solving", "reason": "This paper explores metacognitive capabilities of LLMs, providing insights into the limitations of current LLMs in mathematical problem-solving and contributing to the understanding of advanced reasoning capabilities.  This understanding informs the approaches and challenges tackled by the current work.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "reason": "This paper introduces the Llama 3 family of models, which are highly relevant to the current research's goal of improving reasoning capabilities of LLMs.  The models' performance on reasoning tasks and their open-source nature make them a key benchmark for evaluating and comparing this paper's proposed methods.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Run-Ze Fan", "paper_title": "Reformatted alignment", "reason": "This work explores a method for reformatting existing datasets to improve their use in training LLMs. It directly addresses the challenges of data diversity and scarcity that are highlighted in this paper, providing a potential method for supplementing the dataset created by the authors.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Luyu Gao", "paper_title": "Pal: Program-aided language models", "reason": "This paper explores the use of program-aided language models (PALs) for enhancing reasoning capabilities in LLMs. This is highly relevant to this paper, as PALs offer a potential avenue for creating more sophisticated and complex problems for evaluating LLMs' reasoning skills.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Zhibin Gou", "paper_title": "Tora: A tool-integrated reasoning agent for mathematical problem solving", "reason": "This paper introduces TORA, a tool-integrated reasoning agent, a technique used to improve LLMs' ability to solve complex mathematical problems. This is relevant to the paper's discussion of approaches for enhancing the reasoning capabilities of LLMs, and the tool-integration approach may offer potential improvements to the data synthesis process.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Chaoqun He", "paper_title": "Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems", "reason": "This paper introduces a challenging benchmark dataset (Olympiad Bench) specifically designed to evaluate advanced reasoning capabilities of LLMs. Using this benchmark provides a strong validation for the performance of the ScaleQuest dataset, especially in more difficult mathematical reasoning tasks.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "reason": "This paper is highly relevant to this research because it introduces the MATH dataset, which is used as a benchmark for evaluating the effectiveness of the ScaleQuest dataset. The MATH dataset is a widely recognized and respected benchmark for evaluating the mathematical reasoning capabilities of LLMs. Using MATH as a benchmark provides a robust and objective comparison of the ScaleQuest dataset's performance against existing methods.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Hakan Inan", "paper_title": "Llama guard: Llm-based input-output safeguard for human-ai conversations", "reason": "This paper introduces a safety mechanism for LLMs which is relevant to the discussion of safe and responsible AI development.  While not directly related to data synthesis, ensuring safety is important and this paper provides insight into how to build safeguards into LLMs, which could be applied during data generation or subsequent use of the dataset.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Albert Q Jiang", "paper_title": "Mistral 7b", "reason": "This paper introduces the Mistral 7B model, which is used as a benchmark model in the paper's experiments. The model's open-source nature and performance on mathematical reasoning tasks make it a highly relevant and important benchmark model for evaluating the effectiveness of the ScaleQuest dataset.", "section_number": 3}, {" publication_date": "2021", "fullname_first_author": "Mario Michael Krell", "paper_title": "Efficient sequence packing without cross-contamination: Accelerating large language models without impacting performance", "reason": "This work focuses on optimizing the efficiency of large language models, a factor relevant to the development of scalable data synthesis techniques.  While not directly related to the creation of datasets, reducing the computational costs associated with generating large datasets is an important consideration for scaling up data synthesis efforts, especially for open-source initiatives.", "section_number": 3}, {" publication_date": "2023", "fullname_first_author": "Woosuk Kwon", "paper_title": "Efficient memory management for large language model serving with pagedattention", "reason": "This paper discusses the challenges of memory management in large language models, which is relevant to the paper's discussion of the scalability and efficiency of the data synthesis process.  The techniques mentioned could improve the efficiency of generating large-scale datasets for training LLMs.", "section_number": 3}, {" publication_date": "2024", "fullname_first_author": "Xin Lai", "paper_title": "Step-dpo: Stepwise preference optimization for long-chain reasoning of llms", "reason": "This paper focuses on improving the long-chain reasoning capabilities of LLMs which is highly relevant to improving reasoning capabilities of LLMs using data synthesis. It improves the quality of the dataset by incorporating techniques that encourage detailed and step-by-step reasoning in the models.  This is relevant to the paper's work on QPO and the dataset's overall impact on improving LLM reasoning capabilities.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Aitor Lewkowycz", "paper_title": "Solving quantitative reasoning problems with language models", "reason": "This foundational paper addresses the core challenge of quantitative reasoning in LLMs, which is directly addressed by this paper.  The insights from this earlier work on reasoning capabilities help frame the challenges and opportunities in improving LLM reasoning, and the methods explored in this paper are relevant to the development of more effective data synthesis approaches.", "section_number": 4}]}