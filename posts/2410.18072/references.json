{"references": [{" publication_date": "2023", "fullname_first_author": "Josh Achiam", "paper_title": "Gpt-4 technical report", "reason": "This paper is foundational for understanding the capabilities and limitations of large language models, which are increasingly used in predictive modeling.  It provides a detailed technical description of GPT-4, a key model in many state-of-the-art predictive systems,  helping contextualize the advancements and limitations discussed in the WorldSimBench paper.  The performance and capabilities of GPT-4 serve as a benchmark against which other models are compared in the paper.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (vpt): Learning to act by watching unlabeled online videos", "reason": "This paper is crucial as it introduces Video PreTraining (VPT), a significant advancement in using videos for training embodied agents, directly addressing the core focus of WorldSimBench which evaluates models generating actionable videos.  The methods and results presented in this paper are highly relevant to understanding the development of highly embodied predictive models.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Kevin Black", "paper_title": "Zero-shot robotic manipulation with pretrained image-editing diffusion models", "reason": "This paper showcases a significant advance in zero-shot robotic manipulation, highlighting how pre-trained models can achieve high performance in complex tasks. This is directly relevant to WorldSimBench as it demonstrates the potential of advanced models to perform complex actions without explicit training, which is also a goal of WorldSimBench.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "reason": "This work demonstrates an advancement in image generation models that can follow specific instructions, a capability essential for generating videos that align with given tasks, which is directly relevant to the evaluation criteria of WorldSimBench, especially its Explicit Perceptual Evaluation that looks at visual quality and alignment with instructions.", "section_number": 2}, {" publication_date": "2020", "fullname_first_author": "Holger Caesar", "paper_title": "nuscenes: A multimodal dataset for autonomous driving", "reason": "This paper introduces the nuScenes dataset, a significant resource for autonomous driving research.  As autonomous driving is one of the three embodied scenarios evaluated in WorldSimBench, the availability and quality of this dataset directly affect the scope and reliability of the evaluation.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Yi Chen", "paper_title": "Egoplan-bench: Benchmarking egocentric embodied planning with multimodal large language models", "reason": "This paper is highly relevant because it introduces a benchmark focused on egocentric embodied planning using large language models. This is directly related to the evaluation of predictive models that perform task planning, a capability that is relevant to the hierarchy of predictive models (stages S0-S3) presented in the WorldSimBench paper. It provides context for understanding the state-of-the-art in this area.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Zeren Chen", "paper_title": "Rh20t-p: A primitive-level robotic dataset towards composable generalization agents", "reason": "This paper introduces a new dataset for robotic manipulation that contains detailed descriptions and annotations of actions and interactions. This is important because the paper uses Robot Manipulation as one of its testing environments and the quality of the dataset directly impacts the robustness and reliability of the results.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Wei-Lin Chiang", "paper_title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality", "reason": "This paper is relevant because it showcases the development of open-source chatbots, indicating the trend towards wider accessibility and adoption of advanced language models.  This is indirectly related to WorldSimBench since large language models are increasingly used in creating the text instructions that drive the video generation models in the benchmark. These open-source chatbots could be potentially utilized in future work for generating prompts.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "Carla: An open urban driving simulator", "reason": "This paper introduces CARLA, an open-source simulator widely used for autonomous driving research. As autonomous driving is one of the three embodied scenarios evaluated in WorldSimBench, the paper's influence on autonomous driving research is highly relevant and directly impacts the evaluation results.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Danny Driess", "paper_title": "Palm-e: An embodied multimodal language model", "reason": "This paper presents Palm-E, an embodied multimodal language model. This is highly relevant because WorldSimBench focuses on evaluating models that operate effectively in embodied environments and integrate multimodal data.  Palm-E, which combines language understanding and action execution, helps to contextualize the capabilities that WorldSimBench aims to assess.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yilun Du", "paper_title": "Video language planning", "reason": "This paper focuses on video language planning, directly addressing the challenges faced by models generating actionable videos for embodied AI, which is the very focus of WorldSimBench. The techniques and challenges discussed in this paper are highly relevant to the development and evaluation of World Simulators.", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Yilun Du", "paper_title": "Learning universal policies via text-guided video generation", "reason": "This paper is important because it directly addresses the use of text-guided video generation for learning universal policies in robotics.  This aligns with the core objective of WorldSimBench, which aims to evaluate models capable of generating actionable videos that integrate physical understanding and can be used to guide the actions of embodied agents.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Frederik Ebert", "paper_title": "Bridge data: Boosting generalization of robotic skills with cross-domain datasets", "reason": "This paper directly addresses the challenge of improving generalization in robotic skills by using cross-domain datasets. This is critical because WorldSimBench aims to evaluate models that perform well in diverse environments and situations, requiring a high degree of generalization.", "section_number": 2}, {" publication_date": "2017", "fullname_first_author": "Raghav Goyal", "paper_title": "The\u201c something something\u201d video database for learning and evaluating visual common sense", "reason": "This paper introduces the 'Something-Something' video dataset, a valuable resource for research on visual common sense. Although not directly used in WorldSimBench, it provides context for evaluating the performance of models that generate videos; the availability of large-scale video datasets is crucial for training effective video generation models. Understanding this context enhances the appreciation of the importance of the HF-Embodied Dataset created for this work.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Kristen Grauman", "paper_title": "Ego4d: Around the world in 3,000 hours of egocentric video", "reason": "This paper presents Ego4D, a large-scale egocentric video dataset, and its relevance to WorldSimBench is indirect but significant.  The availability of large-scale, high-quality video datasets is crucial for training robust video generation models. This paper highlights the context of video data used for training and evaluation in video-related tasks, providing essential background for the work.", "section_number": 2}, {" publication_date": "2018", "fullname_first_author": "David Ha", "paper_title": "World models", "reason": "This foundational paper on world models is highly relevant to the concept of World Simulators, which are central to WorldSimBench. The work on world models provides theoretical and practical context for understanding the design and capabilities of advanced models that can generate actionable videos reflecting a realistic understanding of the environment's dynamics.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Michael Janner", "paper_title": "Planning with diffusion for flexible behavior synthesis", "reason": "This work focuses on planning with diffusion models, a technique relevant to generating high-quality, coherent videos that reflect realistic physical interactions. This is important for WorldSimBench as the framework evaluates models that generate such videos, and understanding advanced planning techniques helps to interpret the capabilities and limitations of the models being assessed.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper is highly influential because it highlights the capabilities of large language models as unsupervised multitask learners.  This is relevant to WorldSimBench because large language models are often used to generate the textual descriptions that drive the video generation models, and understanding their capabilities and limitations is crucial for interpreting the results of the benchmark. ", "section_number": 2}, {" publication_date": "2024", "fullname_first_author": "Hao Shao", "paper_title": "Lmdrive: Closed-loop end-to-end driving with large language models", "reason": "This paper is directly relevant because it explores using large language models for end-to-end autonomous driving, which is one of the three embodied scenarios used in WorldSimBench.  The techniques and findings presented in this paper are important for understanding the challenges and potential solutions associated with integrating language models into embodied systems and are directly relevant to the evaluation of World Simulators.", "section_number": 4}]}