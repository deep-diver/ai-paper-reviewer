{"references": [{" publication_date": "2023", "fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "reason": "This paper is foundational to the work, as it provides a detailed technical report on GPT-4, a large language model used in the instruction prompt generation. The model's capabilities are crucial for expanding the meta-prompts and generating diverse task instructions.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (vpt): Learning to act by watching unlabeled online videos", "reason": "This paper introduces the VPT dataset and training method, which is a large-scale dataset of Minecraft demonstrations and is used as a foundation for generating and evaluating embodied videos in the Open-Ended Embodied Environment scenario. The dataset is essential for the construction of the HF-Embodied Dataset.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Kevin Black", "paper_title": "Zero-shot robotic manipulation with pretrained image-editing diffusion models", "reason": "This paper explores zero-shot robotic manipulation, which is highly relevant to the Robot Manipulation scenario in WorldSimBench. The techniques and models presented in this paper are valuable for the development of the video-to-action models used in the Implicit Manipulative Evaluation.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "reason": "This paper proposes a method for image editing based on instructions. This method is important as a reference for generating high-quality images in video generation which is essential for evaluating the visual quality of the videos in the Explicit Perceptual Evaluation.", "section_number": 4}, {" publication_date": "2020", "fullname_first_author": "Holger Caesar", "paper_title": "nuscenes: A multimodal dataset for autonomous driving", "reason": "This paper introduces the nuScenes dataset, a large-scale autonomous driving dataset that is used for training and evaluating the autonomous driving models. The dataset is crucial for evaluating the performance of the models in the Autonomous Driving scenario.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Yi Chen", "paper_title": "Egoplan-bench: Benchmarking egocentric embodied planning with multimodal large language models", "reason": "This paper introduces a benchmark for evaluating egocentric embodied planning capabilities, which is related to the Open-Ended Embodied Environment scenario.  The benchmark provides valuable insights for designing the evaluation metrics for WorldSimBench.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Zeren Chen", "paper_title": "Rh20t-p: A primitive-level robotic dataset towards composable generalization agents", "reason": "This paper introduces a robotic dataset that is used for evaluating the performance of robotic manipulation models. The dataset provides essential information for developing the video-to-action models used in the Implicit Manipulative Evaluation.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Wei-Lin Chiang", "paper_title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality", "reason": "This paper describes Vicuna, a large language model used as a key component in generating instruction prompts for the HF-Embodied dataset.  The model's capabilities are important for creating diverse and high-quality instructions for video generation.", "section_number": 4}, {" publication_date": "2017", "fullname_first_author": "Alexey Dosovitskiy", "paper_title": "Carla: An open urban driving simulator", "reason": "This paper introduces the CARLA simulator, which is used for evaluating the autonomous driving models in the Implicit Manipulative Evaluation. The simulator provides a realistic and comprehensive environment for evaluating the performance of the models.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Danny Driess", "paper_title": "Palm-e: An embodied multimodal language model", "reason": "This paper introduces Palm-E, a multimodal large language model capable of performing complex embodied tasks. This model is relevant to the work as it is a representative example of an embodied AI model which the proposed work aims to evaluate.", "section_number": 2}, {" publication_date": "2023", "fullname_first_author": "Yilun Du", "paper_title": "Video language planning", "reason": "This paper introduces video language planning models which are highly relevant to the work as it represents the state-of-the-art in video generation. The authors explore the capability of models to generate videos based on textual descriptions.", "section_number": 2}, {" publication_date": "2021", "fullname_first_author": "Frederik Ebert", "paper_title": "Bridge data: Boosting generalization of robotic skills with cross-domain datasets", "reason": "This paper introduces a method for improving the generalization of robotic skills by using cross-domain datasets. This method is important for the Robot Manipulation scenario in WorldSimBench as it can improve the performance of the video-to-action models.", "section_number": 4}, {" publication_date": "2017", "fullname_first_author": "Raghav Goyal", "paper_title": "The\u201csomething something\u201dvideo database for learning and evaluating visual common sense", "reason": "This paper introduces a large-scale video dataset that is used for training and evaluating the video generation models in the Explicit Perceptual Evaluation. The dataset is important for evaluating the visual quality of the generated videos.", "section_number": 4}, {" publication_date": "2022", "fullname_first_author": "Kristen Grauman", "paper_title": "Ego4d: Around the world in 3,000 hours of egocentric video", "reason": "This paper introduces the Ego4D dataset, a large-scale egocentric video dataset that provides a rich source of data for training and evaluating embodied models. The dataset is relevant to the work as it can be used to improve the performance of the models in the Open-Ended Embodied Environment scenario.", "section_number": 4}, {" publication_date": "2019", "fullname_first_author": "William H Guss", "paper_title": "Minerl: A large-scale dataset of minecraft demonstrations", "reason": "This paper introduces the MineRL dataset, which is a large-scale dataset of Minecraft demonstrations. The dataset is used for training and evaluating the models in the Open-Ended Embodied Environment scenario.  It is important for evaluating the performance of the models in complex and dynamic environments.", "section_number": 4}, {" publication_date": "2023", "fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "reason": "This paper introduces a method for animating images using diffusion models. The method is important for generating high-quality videos in the video generation models, which is essential for evaluating the visual quality of the videos in the Explicit Perceptual Evaluation.", "section_number": 4}, {" publication_date": "2018", "fullname_first_author": "David Ha", "paper_title": "World models", "reason": "This paper introduces the concept of world models, which are used for generating predictions about the future states of the world. The concept is important for the work as it is a key component in the development of World Simulators.", "section_number": 2}, {" publication_date": "2022", "fullname_first_author": "Michael Janner", "paper_title": "Planning with diffusion for flexible behavior synthesis", "reason": "This paper introduces a method for planning with diffusion models, which is highly relevant to the work as it represents the state-of-the-art in video generation.  The use of diffusion models is particularly relevant to the generation of high-quality and realistic videos.", "section_number": 2}, {" publication_date": "2019", "fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "reason": "This paper is foundational as it introduces language models which are utilized in many aspects of the work including the instruction prompt generation and for the Human Preference Evaluator. The language models are crucial for expanding the meta-prompts and generating diverse task instructions.", "section_number": 4}, {" publication_date": "2024", "fullname_first_author": "Hao Shao", "paper_title": "Lmdrive: Closed-loop end-to-end driving with large language models", "reason": "This paper introduces LMdrive, a language-guided autonomous driving model which is used in the Implicit Manipulative Evaluation. The model is relevant to the work as it is a representative example of an embodied AI model which the proposed work aims to evaluate.", "section_number": 4}]}