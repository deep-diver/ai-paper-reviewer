[{"figure_path": "2410.15522/charts/charts_1_0.png", "caption": "Figure 1: Performance gap between RewardBench (English) and the average M-REWARDBENCH scores across 23 languages for various reward models (Pearson r: 0.92, Spearman p: 0.89). All models underperform on our multilingual benchmark compared to their performance on the corresponding English benchmark.", "description": "The scatter plot displays the performance of various reward models on two benchmarks: RewardBench (English) and M-REWARDBENCH (multilingual).  The x-axis represents RewardBench scores, while the y-axis represents M-REWARDBENCH scores. Each point represents a reward model, colored according to its type (Classifier, Generative, or Implicit). A dashed diagonal line indicates equal performance on both benchmarks.  The plot shows that all reward models perform worse on the multilingual benchmark (M-REWARDBENCH) than on the English benchmark (RewardBench), indicating a significant performance gap between English and non-English languages.", "section": "1 Introduction"}, {"figure_path": "2410.15522/charts/charts_4_0.png", "caption": "Figure 2: Label agreement, as measured by Cohen's k, of various RMs with respect to RewardBench (English) averaged across 23 languages. No model achieves complete agreement (\u043a = 1) between other languages and English, with some exhibiting greater volatility across languages and others demonstrating more stability.", "description": "The bar chart displays the average inner-model agreement across 23 languages for various reward models (RMs), using Cohen's kappa to measure the level of agreement.  The models are grouped by type: Classifier RM, Generative RM, and Implicit RM, and are ordered from lowest to highest average kappa score. Error bars represent the standard deviation of the kappa values across the 23 languages. The chart shows that no model exhibits perfect agreement (kappa = 1) with the English RewardBench across all languages;  some models show more consistent performance across languages than others, indicated by shorter error bars.", "section": "5 Results"}, {"figure_path": "2410.15522/charts/charts_5_0.png", "caption": "Figure 3: (Top) Distribution of label agreement, as measured by Cohen's \u03ba, across the six Generative RMs in the top ten (Table 2) with respect to RewardBench (English) on Indonesian. Interpretation of Cohen's k scores is based on McHugh (2012). (Bottom) Percentage of categories in M-REWARDBENCH for each bin in the histogram.", "description": "This figure is a combined histogram and stacked bar chart visualizing label agreement, measured by Cohen's kappa (\u03ba), across six generative reward models. The top histogram shows the distribution of \u03ba values for Indonesian, categorized into levels of agreement: high disagreement to no agreement, minimal to weak agreement, and moderate to perfect agreement. The bottom stacked bar chart breaks down the percentage of each agreement level across four categories: Chat, Chat Hard, Safety, and Reasoning.  The figure illustrates how model agreement varies across different task categories and agreement levels within a single language, providing insights into the consistency and robustness of reward models in multilingual settings.", "section": "5 Results"}, {"figure_path": "2410.15522/charts/charts_6_0.png", "caption": "Figure 4: Performance of ten selected reward models across different RM types on a version of M-REWARDBENCH translated using NLLB 3.3B (Costa-juss\u00e0 et al., 2022) and the Google Translate API. The performance of RMs improves when they are provided with higher-quality translations.", "description": "The bar chart visualizes the performance of ten reward models, categorized into Classifier RMs, Generative RMs, and Implicit RMs, on a subset of the M-REWARDBENCH dataset.  The dataset was translated using two different methods: NLLB 3.3B and Google Translate, which represent different translation qualities. The chart displays the performance scores of each model for both translations. Each model is represented by a bar, with the height representing its performance score.  The chart reveals that higher-quality translations (Google Translate) lead to improved performance across most models.  The models are presented in descending order of performance using Google Translate.", "section": "6 Analysis"}, {"figure_path": "2410.15522/charts/charts_7_0.png", "caption": "Figure 5: Performance across different linguistic dimensions: resource availability, language family, and script. Resource availability is based on Joshi et al. (2020)'s language categorization, with higher-numbered classes having more data resources. Information on language family and script are based on Aryabumi et al. (2024).", "description": "This figure presents a comparative analysis of Reward Model (RM) performance across three linguistic dimensions: resource availability, language family, and script.  It displays three bar charts, each representing one of these dimensions. The 'Resource Availability' chart shows performance grouped into three classes based on data resource abundance, with Class 5 showing the highest scores. The 'Family' chart shows performance for various language families, indicating that Indo-European and Sino-Tibetan families demonstrate higher RM performance. Lastly, the 'Script' chart presents performance based on the writing system, with Latin and Cyrillic scripts showing higher scores than other scripts.", "section": "6 Analysis"}]