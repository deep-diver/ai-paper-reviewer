[{"figure_path": "2410.18572/charts/charts_2_0.png", "caption": "Figure 1: Model Performance Comparison. a) Perplexity across different context lengths. Lower perplexity indicates better performance. b) Latency comparison of models at various generation lengths. Taipan exhibits significantly lower latency and superior scaling compared to other strong baselines for longer sequences.", "description": "The chart displays a performance comparison of four language models: Transformer, Jamba, Mamba, and Taipan across varying context lengths.  Sub-figure (a) shows perplexity, a measure of model uncertainty, across different context lengths ranging from 1K to 128K tokens. Taipan consistently demonstrates the lowest perplexity, indicating superior performance.  Sub-figure (b) illustrates latency (time taken for generation) at various generation lengths. Again, Taipan exhibits the lowest latency and better scaling compared to other models, demonstrating its efficiency in handling longer sequences. Note that Transformer runs out of memory (OOM) at higher context lengths.", "section": "1 INTRODUCTION"}, {"figure_path": "2410.18572/charts/charts_2_1.png", "caption": "Figure 1: Model Performance Comparison. a) Perplexity across different context lengths. Lower perplexity indicates better performance. b) Latency comparison of models at various generation lengths. Taipan exhibits significantly lower latency and superior scaling compared to other strong baselines for longer sequences.", "description": "The chart is a two-part figure showing model performance comparisons. Part (a) presents a line graph illustrating perplexity across various context lengths (from 1K to 128K tokens).  It compares the perplexity of four models: Transformer, Mamba, Jamba, and Taipan. Taipan demonstrates the lowest perplexity, indicating superior performance, especially as context length increases. Part (b) displays another line graph illustrating latency across generation lengths (from 1K to 32K tokens) for the same four models. Taipan shows significantly lower latency than the other models, with its latency scaling much more efficiently at longer generation lengths.", "section": "Model Performance Comparison"}, {"figure_path": "2410.18572/charts/charts_5_0.png", "caption": "Figure 3: Attention mechanisms in Taipan's Selective Attention Layers. White areas indicate no attention. (a) Full Causal Attention (b) Sliding Window Attention (w = 4) (c) Selective Attention (C = 0.3, w = 5)", "description": "This chart illustrates three different attention mechanisms: (a) shows full causal attention where each token attends to all previous tokens, resulting in a triangular attention pattern. (b) depicts sliding window attention with a window size of 4, limiting the attention scope to a smaller window around each token. (c) presents the selective attention mechanism used in Taipan, where only a subset of tokens (indicated by light blue) are selected for attention, creating a sparse attention pattern.  The selective attention mechanism strategically focuses computational resources on key tokens, balancing efficiency with the ability to capture long-range dependencies.", "section": "3.1 SELECTIVE ATTENTION LAYERS"}, {"figure_path": "2410.18572/charts/charts_9_0.png", "caption": "Figure 5: Effect of Attention Budget Capacity C on Taipan's Performance", "description": "This figure displays the impact of varying attention budget capacity (C) on Taipan's performance across two tasks: SWDE (structured data extraction) and HellaSwag (commonsense reasoning).  The chart presents accuracy results at different training steps (2k, 7k, 10k, and 24k) for four different capacity values (0.1, 0.15, 0.2, and 0.25).  For both tasks, accuracy generally increases as the training progresses.  The optimal performance is observed around C = 0.15 for both SWDE and HellaSwag, indicating that a capacity of 0.15 provides a balance between model efficiency and performance.  Increasing or decreasing C from this value shows reduced accuracy.", "section": "5.1 EFFECT OF ATTENTION BUDGET CAPACITY"}, {"figure_path": "2410.18572/charts/charts_10_0.png", "caption": "Figure 6: Perplexity comparison of Taipan variants with and without Positional Embeddings across different context lengths. Lower perplexity indicates better performance.", "description": "The chart displays the perplexity scores of two Taipan model variants across various sequence lengths. One variant incorporates Rotary Positional Embeddings, while the other does not.  Both models show similar perplexity for sequence lengths similar to or shorter than the training context length (4096 tokens). However, as the sequence length increases beyond the training length, the perplexity of the model without positional embeddings remains consistently lower than the model with positional embeddings, indicating better generalization to longer unseen sequences. This suggests that the absence of positional embeddings allows the model to rely more heavily on attention representation rather than positional biases, leading to improved extrapolation capabilities.", "section": "5.2 IMPACT OF POSITIONAL EMBEDDINGS"}]